<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2017 小结</title>
    <url>/2018/01/02/2017%20%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<p>一个多月没写文章了，这个月主要是被各种焦头烂额的事情所烦扰：比赛、数据的采集与筛选、各种无聊的报告等等。一眨眼就踏入了2018，本来也不打算写年度总结，但是后来想想还是做一下简单的记录，一是因为自己本来就有总结的习惯，要不也不会一直在写这个博客；二是因为不总结下，都不知道自己这一年过得有多烂（捂脸）。言归正传，下面主要写一下在这一年里干了啥。</p>
<span id="more"></span>
<h2 id="关于课程">关于课程</h2>
<p>研究生的第一年还是以上课为主，当初从电信转到计算机一个原因就是对计算机更有兴趣，所以这一年的课程也是学得挺顺利的。计算机的基本素养课程：操作系统、计算机网络和数据库都有，虽然本科上过，但是研究生的课是对某些知识点进行了更深入的讲解，操作系统和计算机网络都在本站点上做了相应的总结，虽说当时总结起来一顿操作猛如虎，考试也考了90+，但是现在的内容却忘得七七八八了，似乎是水过鸭背。但我还是觉得这个东西虽然不能被我清晰记起，但是当要再次捡起来的时候，还是会比较快的。现在回想如果我本科时候没那么认真学习操作系统和计算机网络，研究生这两门课也不会学得这么顺利，知乎有个高票答案就说到<strong>知识或者技能这种东西，学到了就跟你一辈子</strong>，也许说的就是这种情况吧。</p>
<p>除了这几门常规课，其他让我觉得最有用的两门课就是 <a
href="http://wulc.me/2017/02/01/%E6%9C%80%E4%BC%98%E5%8C%96%E8%AE%A1%E7%AE%97%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/">最优化基础</a>
和 <a
href="http://wulc.me/2017/05/20/%E5%87%B8%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/">凸优化</a>了，两门都是关于优化的数学课，以往基本没接触过，搞数学建模的时候接触过一点线性规划，这里则是更详细地介绍了各种优化问题和解决方法。非常有用的两门课，尤其是对于我这种接触过机器学习和计算广告的人，因为从本质上来讲，这种优化思想在生活中无处不在：<strong>资源往往是有限的，我们总是想借助着有限的资源来最大化我们所希望的获取的利益。</strong>
将这类问题量化成一个最优化的问题，就有了一个目标，然后通过优化算法，就有了一个方向，这样或早或晚都能走到局部最优或全局最优。</p>
<p>还有一门就是模式分类，这门课是跟本科生一起上的，因此讲的内容并不是很深入，都是传统的机器学习算法，但是让我收获最大的是课程论文的阅读，读的论文是12年提出AlexNet
的经典论文 ImageNet Classification with Deep Convolutional Neural
Networks，当时为了讲好 <a
href="http://wulc.me/files/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks.pdf">PPT</a>，做了较多的调研，还写了<a
href="http://wulc.me/2017/05/15/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a>，这篇论文涵盖了很多深度学习的重要概念，毕竟是开山之作。详细了解了这篇论文后使得我后面上手深度学习的项目时比较快，还是印证了前面的那句话：知识或者技能这种东西，学到了就跟你一辈子。</p>
<p>学校安排的课程中，能被我记住的基本就是上面提到的，其他的那些如上得不痛不痒的数据库，让人备受煎熬的中特，都没有多大印象了。这一年的课程成绩也还可以，最后的评优中虽然没有专利、活动之类的加分，但是因为成绩优势，最终也拿了一等奖学金，比刚入学时候的二等奖学金要好了，虽然我觉得如果我不跨院保研的话入学的时候也能拿一等（捂脸逃）。</p>
<p>除了学校的课程，主要还学习了与机器学习和计算广告相关的课程。</p>
<p>机器学习的几门课程包括<a
href="http://open.163.com/special/opencourse/machinelearning.html">吴恩达在斯坦福的公开课</a>，台大林轩田的<a
href="https://www.bilibili.com/video/av12463015/">机器学习基石</a>和<a
href="https://www.bilibili.com/video/av6991226/">机器学习技法</a>；这几门课都是理论为主，数学偏多，硬着头皮也算啃了下来，其中让我印象最为深刻的不是各种各样的模型算法，而是
NFL(No Free Lunch) 定理和 VC 维理论，NFL
定理指出了模型之间并的差距必须要到某一个具体的数据集上才能体现出来，也就是说要解决一个机器学习问题时，必须要先对数据的分布等信息有较好的理解，才能选出适合这个数据的模型；VC
维理论需给我们揭示了一个很直观的概念：要取得较好的泛化能力，用于训练模型的样本数目应该至少是模型参数数目的10倍。这个能够很好的解释复杂模型容易过拟合的问题。但是对于目前如火如荼的深度学习，VC
维理论并不适用，因此 2017 ICLR 的最佳论文 Understanding deep learning
requires rethinking generalization
通过实验指出了这个问题，同时深度学习目前也还没有公认的理论基础，因此这个问题也是亟需解决。</p>
<p>计算广告算是今年看到的一门比较新的课程，之前对广告的认知只限于弹窗、强制推送等，后来看了刘鹏的<a
href="http://study.163.com/c/ad">计算广告学</a>，才发现这门学科集理论知识（主要是优化方面）和工程技法于一体，而且广告可以说是大数据为数不多的正真落地的一个产业。看了视频后又买了跟视频配套的书计算广告又看了一遍，对于书中众多概念及需要解决问题才有了初步了解。</p>
<p>这两方面的课程的内容虽然都看完了一遍，也做了一些笔记，但是还是感觉理解得还不够深入，还要重温一遍。</p>
<h2 id="关于项目">关于项目</h2>
<p>研一基本在上课，直到研一的暑假才被大老板叫去做项目，之前一直是跟小老板做
NLP
方向的研究，但是大老板的项目是图像相关的，具体的就是做人脸的表情识别。由于很久没接触图像相关知识了，刚开始还有点害怕做不来。但是后来才发现有了一些机器学习的知识，上手也是挺快的。</p>
<p>在这个过程中，对比了人工特征+传统机器学习方法和深度学习方法，传统的人工特征基本就是人脸的68个特征点以及特征点衍生出来的特征，在几个数据集上深度学习的效果基本上都要优于传统的机器学习方法，也许是我们提特征不够好，但是这也是深度学习的强大之处，将特征抽取和分类器的训练融合到一个模型中。</p>
<p>暑假做了大概一个月的算法研究，开学后被派去搭建系统了，主要就是实现从监控获取图像，对图像中的人脸进行表情识别并可实时观察具体的识别效果。首先要解决的是数据传输问题，就是图像从摄像头传到服务器，服务器处理后送到展示端，展示端为了维护的便利性，采用的网页展示方式。因为之前已经听说过
kafka
这个工具，知道这个工具的大概作用，因此这里就做了一下调研，没想到这个工具还是挺好用的，吞吐量高且拓展性强，部署起来也不麻烦，因此系统中有数据传输的部分都用了
kafka，需要存储的部分用了redis，在数据传输存储中将图像按照 base64
编码后，能够避免很多问题。而网页端的显示则是用了
<code>multipart/x-mixed-replace</code> 这个content type，简单来说这个
content type
能够替换掉原位置上的数据，如果将图像一帧一帧地传过来，便可达到动态视频的效果。</p>
<p>下面是具体效果</p>
<figure>
<img src="https://wulc.me/imgs/image_1c4dltqj0t9o1h31jiq1gp01strp.png"
alt="FER demo" />
<figcaption aria-hidden="true">FER demo</figcaption>
</figure>
<p>在这个过程中需要用到人脸检测、图像处理的工具，因此也接触了 opencv，
dlib 这两个功能强大的库， 在人脸检测上 dlib 的效果要优于 opencv，opencv
则主要用在图像处理，如标注、裁剪等。</p>
<p>后面由于模型在已有的数据集(如CK+,
KDEF等)上的效果很好，但是人肉测试时效果并不好，因此就考虑数据扩充，除了常规的在已有的数据集上进行裁剪、翻转、颜色抖动等操作。还通过爬虫在网上采集人脸数据库，主要就是通过关键词在谷歌中搜索对应的图片，然后获取其下载链接并下载图片，这个小工具已开源，具体地址见</p>
<p>https://github.com/WuLC/GoogleImagesDownloader</p>
<p>通过这个工具搜集了一定数量的图片，通过预处理和人工筛选后得到最终的图片，其中人工筛选过这个步骤由于每个人的标准都不一样，因此最后出现某些类别很少的情况。但是在一定程度上也算是扩充了原有的数据集（7种类别仅有2000多张图片）</p>
<figure>
<img src="https://wulc.me/imgs/image_1c4dokvsa113g1so6urgcradc29.png"
alt="图片数量" />
<figcaption aria-hidden="true">图片数量</figcaption>
</figure>
<p>因为之前的测试都是内部的测试，没有一个对比的标准，因为我们做的这个项目是以实用性为主，而目前提供表情识别服务且比较有名公司有
<a
href="https://azure.microsoft.com/zh-cn/services/cognitive-services/emotion/">微软</a>、<a
href="https://cloud.google.com/vision/">谷歌</a>、<a
href="https://www.faceplusplus.com.cn/emotion-recognition/">Face++</a>、<a
href="http://www.emotibot.com/zh-cn/face_detection.html?n=63">竹间智能</a>等，因此就想到到了构建一个公有的数据集，来对比一下我们的模型和商用的差距。经过讨论后，决定去采集真实的人脸表情，这样一来所有的模型都不可能接触过这些数据集，因而能够比较公平地验证各个模型的泛化能力。因此就用
python 写了一个采集程序，去采集一个人的 7
种表情，并以视频形式存储。下图是采集的页面</p>
<figure>
<img src="https://wulc.me/imgs/446475948.jpg" alt="采集程序" />
<figcaption aria-hidden="true">采集程序</figcaption>
</figure>
<p>采集完了需要将视频转为图像帧序列，然后人工选出若干帧作为表情变化序列进行后续操作。不得不说人工筛选就是累。</p>
<p>采集完验证集后，测试了上述的四个提供表情识别服务的公司的 API
在验证集上的准确率，结果显示准确率大概在 52%～58%（七分类）
，我们的模型最好的效果能达到 61%，且通过 confusion matrix
可以看到所有模型基本上都有这个问题，就是 angry、fear、disgust、sad
这几类表情被误分为
neutral，原因就是正常人在做这些表情的时候幅度并不会太大，而训练集中的数据却都是动作幅度较大，表情比较明显。</p>
<p>最后，还需要将从监控中获取到的不同人脸分来，就是一个人脸聚类问题。最开始采用的是人脸识别经典做法，就是每个人采用已知的人脸图片，然后通过预训练的
FaceNet 抽取图像的 128 维特征，对于未知的人脸图片，也用 FaceNet 抽取出
128 维特征，并和已知人脸的 128
维特征计算相似度，这种做法对于人脸的角度鲁棒性不好，就是只能识别出与已知的人脸图片中人脸角度差别不大的人脸。后来改用了
<a href="https://en.wikipedia.org/wiki/Chinese_whispers">Chinese
whispers</a> 聚类算法，同样也是要通过预训练的 FaceNet 抽取图像的 128
维特征，但是不需要提供已知的人脸图片，且算法对于人脸角度的鲁棒性较好。</p>
<p>去年就只做了这个项目，虽然做的内容比较杂，但是也算是学到了不少东西。</p>
<h2 id="关于比赛">关于比赛</h2>
<p>上课的时候参加了一些比赛，但是由于课程作业、考试等原因，基本都半途而废；暑假以后主要参加了两个比赛：AI
Challenger 的<a
href="https://challenger.ai/competition/caption">图像中文描述</a> 和 <a
href="http://www.datafountain.cn/projects/2017CCF/">CCF
的计算智能大赛</a>。</p>
<p>参加第一个比赛主要是这个方向可能是我的毕设方向，通过这个比赛，也算是基本入门了这个方向，代码主要是参考了
tensorflow 中提供的 im2txt 例子，基本看懂后做了一些改动，代码见<a
href="https://github.com/WuLC/ImageCaption">这里</a>，参数没有细调，因为到后面去搞
CCF 的比赛了,最后 B 榜大概 30 名左右 。</p>
<p>CCF
的比赛中主要参加了法海风控的比赛，做的是命名实体识别+文本分类，我主要负责的是文本分类，就是判断抽取出来的实体到底是正向、负向还是中性的，尝试了一些开源的工具，也实现了一些模型如
TextCNN 等，综合效率和准确率，<a
href="https://fasttext.cc/">fastText</a>
是最好的，了解这个工具也是我觉得是比赛中一个较大的收获。比赛过程很繁琐，最终以
Top5 的成绩去了江苏答辩，最后第四名，也算是收获了一个奖项。</p>
<p>总的来说，2017
年里主要完成的就是上面这三个方面的事了，其他琐碎的也基本记不起。2018
就要找工了，时间真的过得好快, 希望在2018里能够继续保持
<code>stay hungry，stay foolish</code> 的状态吧。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>2020 小结</title>
    <url>/2021/01/02/2020%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<p>很久没更新技术文章了，草稿箱里还有几篇半成品一直被我以工作日事情太多、周六日需要休息为由
delay 了好几周；而现在站在 2021 年的起点，望着 2020
年的尾巴，不禁感慨一年就这么呲溜一下就过去了，总想写点东西来复盘一下
2020 这一年，还记得上次写的这种年度总结的文章是 <a
href="http://wulc.me/2018/01/02/2017%20%E5%B0%8F%E7%BB%93/">2017
小结</a>，那会还在上研一，现在回看这篇文章还是略有感慨，还是比较佩服当年那个充满激情与精力、对各种知识都充满好奇的自己；趁着元旦放假有空这几天，还是决定简单地对
2020 年做个总结，几年后再回头看看，或许会有不同的感悟。</p>
<span id="more"></span>
<h2 id="关于工作">关于工作</h2>
<p>工作后到目前为止学习到的关于 presentation
的最重要的一点是：<strong>要有总结，甚至可以先把结论放在开头</strong>，所以这里简单概括工作后目前为止做的两个事情</p>
<ol type="1">
<li>多目标出价的推导与实验</li>
<li>联邦学习的探索与落地</li>
</ol>
<p>多目标出价的推导与实验是刚进来的时候被派去做的一个调研工作，现在想起来感觉还是挺绝望的：对业务不熟悉，身边没有人能给予相关的指导，硬生生靠着自己一个人去推公式、读代码，还得随时提防开实验的时候线上搞出个事故。且因为业务的特殊性，这个实验只能开一天且需要在凌晨开启，所以经常出现的现象是我在凌晨掐表开实验，观察个几十分钟，然后才敢去睡觉，但是半夜冷不丁还会因为数据有波动报警电话直接把你吵醒，那会真的是相当的绝望。不过最终一遍遍尝试与
debug 代码，也总算是通过实验验证了推导出来的结果，因为 infra
等原因，反转实验一直被 delay，后面架构调整，这块业务也就不再跟进了。</p>
<p>这里的技术细节因为涉及保密就不详细展开讲了，不过大概几个月后意外发现了这篇
paper，Bid Optimization by Multivariable Control in Display
Advertising，然后我套用里面的方法来推导我之前的问题，发现结果跟我之前推出来的是一样的！！！，所以我也更加肯定了上面那个没开反转的实验是能带来收益的，这篇
paper 我也特意写了一篇阅读笔记<a
href="http://wulc.me/2020/07/19/%E3%80%8ABid%20Optimization%20by%20Multivariable%20Control%20in%20Display%20Advertising%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Bid
Optimization by Multivariable Control in Display
Advertising》阅读笔记</a></p>
<p>如果说前面的事情是一个纯粹的探索，没
kick-off，没人力支持，那联邦学习算是我参与的第一个正式的项目，在这个项目里跟
infra、产品、运营、法务跟多团队都有合作。这个事情简单来说，就是要去<strong>探索如果在保护数据隐私前提下利用多方的数据进行建模与落地</strong>，中间的方案迭代了好几版，也踩过非常多的坑，但是最后也算是把这个业务在几个行业落地了，关于这一块的细节可以参考这篇文章
<a
href="https://mp.weixin.qq.com/s/mLLkLvO0MWBLYRmLMQquHA">字节跳动联邦学习平台Fedlearner：4个月落地开源，投放增效200%+</a></p>
<p>这一年算是工作的第二年了，在毕业后也算顺利进入了自己规划的广告技术行业，工作这一年多的时间里，也对总体的广告系统有了初步的认识，也做出来了一些成果，总体来讲，So
far so good 吧。</p>
<h2 id="关于学习">关于学习</h2>
<p>工作后的学习时间肯定不如读书的时间那么充裕，因为得对自己的业务负责，而且当前的业务涉及到的事情巨多。。。但是本着
stay hungry，stay foolish
的心态，这一年利用节假日和下班时间还是学习了一下所负责的业务以外的知识</p>
<ol type="1">
<li>基本上看完了 <a
href="https://www.coursera.org/learn/jisuanji-xitong">程序的表示、转换与链接</a>这门课，还有
<a href="https://book.douban.com/subject/3652388/">链接、装载与库</a>
这本书</li>
<li>读了一些关于出价、召回、精排的 paper</li>
<li>了解了一个广告系统内涉及到的模块、算法等原理</li>
</ol>
<p>学习第一部分内容一个原因是兴趣驱动，因为一直对编译和运行这些原理不太懂，这两部分内容跟《深度了解计算机系统》这本书的内容很相似且更通俗，相关的总结我也放到的站点上；另一个原因就是我一直觉得在业界的算法工程师首先得是个工程师，而当前的我认为一个工程师是需要能大概了解代码运行的原理、能看懂别人的代码并在别人的代码基础上添加新的功能、甚至能重新造一个轮子，而不是仅仅局限于改一下模型结构、调一下超参但是不考虑实际落地的开销。当然，这只是现在的我的看法，几年后再回头看看，也许会有变化。</p>
<p>第二部分则可以算作是广告和推荐领域的一些比较前沿或经典的工作了，总体感觉收获比较大的工作也总结写在了博客里，可以概括为一下几个部分</p>
<ul>
<li><strong>出价</strong>: 这部分收获较大的 paper 是 Bid Optimization by
Multivariable Control in Display Advertising ，这是阿里发表在 kdd 的
paper，给出了一种方法来推导出价公式和构建出价控制器，且普适性较高，详细内容可以参考本博客的
<a
href="http://wulc.me/2020/07/19/%E3%80%8ABid%20Optimization%20by%20Multivariable%20Control%20in%20Display%20Advertising%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">这篇文章</a></li>
<li><strong>召回</strong>: 这部分收获较大的 paper 是 Embedding-based
Retrieval in Facebook Search，这是FB 发表的一篇基于 embedding 召回的
paper，描述了他们如何从 0 到 1 构建一个召回系统，当中有不少经验值得借鉴
，详细内容可以参考本博客的 <a
href="http://wulc.me/2020/08/30/%E3%80%8AEmbedding-based%20Retrieval%20in%20Facebook%20Search%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">这篇文章</a></li>
<li><strong>精排</strong>：这部分收获较大的 paper 是 Real-time
Personalization using Embeddings for Search Ranking at Airbnb，这是
Airbnb 发表的一篇构造 embedding 且把 embedding 应用至 search ranking
的系统，里面有很多从业务出发来设计算法的细节，这种思想我认为是比较值得借鉴的，而不是生搬硬套一个方法/模型过来，详细内容可以参考本博客的
<a
href="http://wulc.me/2020/06/20/%E3%80%8AReal-time%20Personalization%20using%20Embeddings%20for%20Search%20Ranking%20at%20Airbnb%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">这篇文章</a></li>
<li>Delay FeedBack：这部分主要是广告领域的 cvr
模型面临的问题，那就是转化是有延迟的，点击后的样本不能马上当做负样本，而等待足够长的时间让
label
回流的时间又太长，因此有了这一领域的研究，关于这部分做了一个调研，可参考这篇文章
<a
href="http://wulc.me/2020/12/05/Delay%20FeedBack%20In%20Computational%20Advertising/">Delay
FeedBack In Computational Advertising</a></li>
</ul>
<p>第三部分则主要是得益于团队内部良好的分享传统，经常有分享介绍广告系统涉及到的各个模块的功能及其原理，同时也能了解到要上线的各个策略/算法，也算是对广告系统有一个初步了解，因为涉及到内部的机密信息，这部分也不便于公开了</p>
<p>学习是一个有阵痛感的过程，因为要接触的可能是一个全新的领域，你要从浩瀚的知识库中筛选出觉得有用的部分并消化掉，而且这些东西并不像游戏或其他东西能获得即时的回报，甚至在很长一段时间内看不到任何变化。</p>
<p>每每想到这，都会感觉有点松懈(而最近的确也有点。。。)；但就在我写这篇总结的时候，我也反问了自己这些问题，而且在自我思考和自我剖析后，还是觉得要坚持，主要有两个原因，原因之一是这能让自己保持一种快速学习的能力，原因之二是说不定哪一天这些知识就排上用场了呢？如同乔布斯所说的
connectting the dots
一样，当然还是得设定一定范围来进行学习的，有目的性其实能让学习速度更快，比如现在的我会问自己“如果让我去构建一个广告系统，需要怎样的工程能力？算法能力？业务能力？”，当然不太可能做到面面俱到，而是要考虑如何在深度和广度之间做
trade-off，而这个 trade-off 的度，得在实践中慢慢摸索。</p>
<p>总之，还是希望自己能够继续保持持续学习的状态，做能做一个 lifelong
learner 吧。</p>
<h2 id="关于生活与心态">关于生活与心态</h2>
<p>这一年基本都是在宿舍和公司过着两点一线的生活，独自一人在北京，处于一种
“一人吃饱，全家不饿” 的状态，每天上班都激情满满，直到最近的 11
月，洗头的时候发现自己居然有脱发的痕迹，不禁感慨“自己都还没变强，怎么就秃了”，同时脸上疯狂长痘，几乎要毁容。</p>
<p>于是去看医生，还没等我描述完病情，医生就打断我说这个问题很常见，就只是压力太大，然后有熬夜之类的不良习惯之类导致的；后来细细回想，那段时间的确是过于担心项目的进展，同时每天都被各方催，晚上经常有熬夜，也导致了那一段时间相当焦虑，焦虑时饮食又不节制，吃了不少辛辣油腻的东西（但公司的食堂除了健身餐其实也基本都是辛辣和油腻的。。。。）</p>
<p>于是告诉自己健康重要，强行让自己不要那么焦虑，同时加强锻炼，尽量不熬夜、保持饮食清淡，前面提到的脱发的迹象也慢慢有了改善；后来在网上看到了下面这句话，感觉写到了心里,就摘录下来(出处忘了，侵删)</p>
<blockquote>
<p>在历史的发展面前，个人的力量微不足道；作为我们这些普通老百姓呢，要调整好心理预期，尽量顺势而为，不要逆天而行。你当然可以继续努力工作，但千万不要抱有那种「趁年轻拼一把」的心态，事业发展是一场马拉松，健康可持续才是最重要的</p>
</blockquote>
<p>希望自己后续无论工作多忙，项目多赶，还是能够保持这种心态吧</p>
<h2 id="小结">小结</h2>
<p>写这篇总结文章的过程，也是一个不断的自我剖析和自我反思的过程，剖析自我到底想成为一个什么样的人，反思自我还能不能做得更好，里面的很多观点也是当下年少气盛的我的一些看法，也许有偏颇，等到而立之年再回头看看这篇文章，看一下是否会嘲笑当年的幼稚想法，问一下自己“当初的愿望实现了吗，事到如今只好祭奠吗”。</p>
<p>最后，希望自己在新的一年里能继续保持 stay hungry，stay foolish
的状态吧，也祝愿各位新年快乐，心想事成。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>2021 小结</title>
    <url>/2022/01/03/2021%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<p>2022
年如期而至，如果说上一年还是在犹豫是否要写年度总结，今年则是早有规划要写一下这一年的总结。因为笔者逐渐意识到，<strong>记录过去的自己是一件很有意义的事情</strong>，这个话题说大了可以上升到各种哲学领域，但对于笔者来说，最重要的意义是能看到过去的自己是一个什么样的人，如今有了什么样的变化，发生了什么事情让自己有了这样的变化，这种跨度一年的自我觉察还是很有意思的。</p>
<p>而比起 vlog
等形式，笔者更倾向于用文字这种形式来记录，因为在写作过程中，会启动大脑的“慢系统”，能更细致地去回顾和组织过去发生的事情，正好趁着放假的时间去梳理这一年的各种事情。</p>
<span id="more"></span>
<h2 id="关于工作">关于工作</h2>
<p>今年在工作上主要推进的事情还是之前一直跟进的联邦学习的业务，这部分在去年的
<a href="https://wulc.me/2021/01/02/2020%E5%B0%8F%E7%BB%93/">2020
小结</a> 中也有提过，如果说去年还是在打造 showcase
的阶段，今年则是将这部分业务规模化推广</p>
<p>规模化做的事情一定程度上是在减少边际成本，所以设计方案时会更多地考虑到方案的易用性和拓展性，最终也在两个比较重要的业务场景验证并上线了，其中一个业务场景针对的是中腰部的客户，另一个业务场景则是针对头部的客户，两者的技术能力、可利用的数据等差异较大，因此也设计了不同的方案来适配不同类型的客户。虽然现在描述起来似乎是轻描淡写，方案本质上也不复杂，但是因为项目的性质，合作涉及到两个公司，而且联系还比较紧密（比如说模型需要双方联合跨公网训练），所以在协作、沟通、debug
等成本上是比较高的</p>
<p>在这个过程也踩了不少的坑，比如说前期设计出价公式时，只是基于业务表象进行设计，没有深入挖掘业务需求，加了一些不必要的约束，导致设计出来的公式并没有取得业务上最优效果；建模上由于转化时间非常长，业务上决定了数据分布有一定周期性，在周期转换的时候如果模型不及时更新，效果会变得很差；另外，也克服了工程上的一些挑战，比如说由于
ranking 的过程涉及到和外部的机房的交互(类似 <a
href="https://zhuanlan.zhihu.com/p/125464058">rta</a>
模式)，需要保证延迟上可用等</p>
<p>在这两个 launch
后，联邦学习提供的基本方案基本能涵盖当前不同类型客户的需求了。而历时大概
1 年半，笔者也算是经历了这个项目从 “<strong>脑暴 -&gt; 出方案 -&gt;
拉客户 -&gt; 出 showcase -&gt; 平台化与规模化</strong>”
的过程，在这个过程除了跟产品有较多讨论，与销售、法务等部门也有不少接触，也从更大的视角上窥探了商业系统运作的一隅。在联邦学习基本稳定后，为了寻找一些新的挑战，在内部进行了一次转岗，后续会探索一些与生态相关的事情,
也算是一个新的旅途了
(打个小广告，目前所在的大部门是巨量千川，字节闭环电商的变现部门，整个部门目前的业务增速还算比较快，也欢迎感兴趣的同学联系我了解)</p>
<p>另一个让我印象比较深刻的事情，则是在上一年总结里提到的多目标出价公式的推导，虽然离线和实验验证了有收益，但是由于种种原因，最终没上线；没想到今年在
lr
会上听到了非中国区的类似业务使用了不同的方法，但是推导出来的结果是一样的，最终也上线了，也算是进一步验证了这个方法的有效性~</p>
<p>另外，在这一年的工作里，无时无刻不觉得过去的自己非常的愚蠢：考虑问题不够周全、汇报没有重点、容易被情绪而不是结果驱动等，想起来都觉得当时的老板对自己是多么的包容；此外，由于业务发展非常快，所以不可避免地有很多调整，在这个过程中特别感谢遇到过的老板们，从他们身上学习到了很多东西，如技术判断力、团队管理能力、沟通能力等。</p>
<h2 id="关于学习">关于学习</h2>
<p>这部分要单独来讲述，是因为笔者慢慢在生活中体会到那句耳熟能详的“学习是一生的事情”是朴素而正确的道理，这里的学习不是狭义上的上课、背书、考试，而是更广义上的对不了解的东西逐渐熟悉的过程。这个过程起因往往是工作需要或者好奇心驱使，而且往往后者比前者更加容易且可持久，因为这个过程是滋养你的，而学习如果由这两个原因同时驱动，那无疑是非常难得的。如同乔帮主的
05 年的<a
href="https://news.stanford.edu/2005/06/14/jobs-061505/">演讲</a>上说到的下面这段话</p>
<blockquote>
<p>You’ve got to find what you love. And that is as true for your work
as it is for your lovers. Your work is going to fill a large part of
your life, and the only way to be truly satisfied is to do what you
believe is great work. And the only way to do great work is to love what
you do. If you haven’t found it yet, keep looking. Don’t settle. As with
all matters of the heart, you’ll know when you find it. And, like any
great relationship, it just gets better and better as the years roll on.
So keep looking until you find it. Don’t settle.</p>
</blockquote>
<p>幸运的是，目前的工作所在的领域还是我所感兴趣的，所以今年基于对当前工作的的一些粗浅了解写了这篇文章
<a
href="https://wulc.me/2021/05/05/An%20Overview%20Of%20Ad%20System/">An
Overview Of An Ad
System</a>，从几个视角(技术、业务、产品)去介绍了对广告系统的一点理解，在这个过程中也算是将自己学习过的一些零碎知识串联起来了。后面没想到的是还有几位字节的同学看到并在内部
IM 软件
上联系到我，得知为自己写的文章同时对其他人起到一定帮助作用，也是比较欣慰了；除了技术，还发现了一门由产品经理讲授的课，总体听下来，也是让我从更多视角去了解去了解商业化这个事情，详见<a
href="https://wulc.me/2021/10/30/%E3%80%8A%E5%95%86%E4%B8%9A%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E7%9A%84%E5%AE%9E%E6%88%98%E4%BF%AE%E7%82%BC%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">《商业产品经理的实战修炼》学习笔记</a></p>
<p>除了与本职工作所需技能相关的学习,也特意去看了其他一些通用能力相关的教程和书籍，因为笔者渐渐意识到，思维方式和习惯对一个人的影响是巨大的，这些内容在知乎上也有不少相关的回答，而在这个过程中，笔者认为影响比较深刻且成体系的内容主要有以下
2 部分，同时也写了相应的文章来记录</p>
<ul>
<li><a
href="https://wulc.me/2021/07/25/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB%E9%AB%98%E6%89%8B/">《如何成为快速阅读高手》</a>：这个是在找资料过程中找到的一个干货，从心态到方法，都给出了非常详细的指导，其中的摆正阅读心态那部分让笔者印象深刻</li>
<li><a
href="https://book.douban.com/subject/34793488/">《认知红利》</a>：这是知乎上一个高赞作者写的一本书，单纯讨论书的内容，对笔者的启发还是非常大的，全书有
2
部分内容，第一部分提供了更多视角去看待财富、自己和世界，第二部分则提供了具体的一些方法论，笔者针对这部分也分别写了阅读笔记，即<a
href="https://wulc.me/2021/08/22/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E6%A6%82%E5%BF%B5%E9%87%8D%E5%A1%91/">《认知红利》阅读笔记(1)-概念重塑</a>和
<a
href="https://wulc.me/2021/10/05/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%282%29-%E5%A4%A7%E8%84%91%E5%8D%87%E7%BA%A7/">《认知红利》阅读笔记(2)-大脑升级</a></li>
</ul>
<p>在学完这些理论知识后，更深刻感受到了“为什么懂得那么多道理，依然过不好这一生”，因为<strong>知行合一实在是非常的难</strong>，也许在看书的时候会非常认可书里的道理，但是转头还是被习惯驱使着做事情；那怎么破？笔者当前觉得<strong>也许有效的方法是不断重温这些内容，加上刻意练习，最终形成习惯</strong></p>
<p>最后学习的一大部分内容则是投资了，虽然在上学那会就开始定投了指数基金，但是金额不大，都是小打小闹；而工作了一段时间，兜里有了少许可供支配的钱，对于我这种生活比较简单的人，一个比较好的去处便是投资了。</p>
<p>于是便开始较为系统性的学习投资相关的事宜，虽说是系统性，但是并没有啃那些大部头，因为笔者很清楚自己不是那种专职投资者，所以基本都是看一些通俗的文章，学习一些基本概念，后来发现了一门个人投资课，里面讲到的一些投资理念和方法特别适合我这种上班族，针对这部分也系统性地写了如下三篇笔记，细节这里不赘述了，其中影响比较深刻的观点是：<strong>投资是一场无限游戏</strong></p>
<ul>
<li><a
href="https://wulc.me/2021/11/14/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%281%29-%E5%B8%82%E5%9C%BA%E8%A7%84%E5%BE%8B/">张潇雨的个人投资课(1)-市场规律</a></li>
<li><a
href="https://wulc.me/2021/11/20/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%282%29-%E6%8A%95%E8%B5%84%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%87%AA%E6%88%91%E5%B1%80%E9%99%90/">张潇雨的个人投资课(2)-投资工具与自我局限</a></li>
<li><a
href="https://wulc.me/2021/11/28/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%283%29-%E6%8A%95%E8%B5%84%E7%BB%84%E5%90%88%E6%9E%84%E5%BB%BA/">张潇雨的个人投资课(3)-投资组合构建</a></li>
</ul>
<p>上面的课程的主讲人张潇雨，其实是笔者通过 <a
href="https://www.xiaoyuzhoufm.com/podcast/5e74543a418a84a046c4e50e">得意忘形</a>
这个播客认识的，因为下半年开始，住的地方离公司远了一些,通勤时间也变长了，于是便开始听播客，其中一个印象比较深刻的播客便是得意忘形，里面的一些观点对比着还是挺有启发的，值得一听，这个播客的简介如下
&gt;
《得意忘形》是一个主张追求个体自由与探寻真理的媒体计划。我们见证了第一次工业革命以来科技对人类社会的极大推动与助益，但也意识到资本主义与市场经济不可避免地催生了消费文化、剥夺了个人价值、并窃取了大众时间。带着对生命的有限性与无目的性的敬畏，我们试图为读者与听众提供更全面的觉察自我与认知世界的工具，以不断重建当下的方式穿越时间、抵达生活的本质。</p>
<p>后来顺藤摸瓜，找到了孟岩的播客<a
href="https://www.xiaoyuzhoufm.com/podcast/611719d3cb0b82e1df0ad29e">无人知晓</a>，同时了解他所打造到<a
href="https://qieman.com/">且慢</a>这个产品的过程，以及后续离开且慢后独立创业所做的产品<a
href="https://youzhiyouxing.cn/">有知有形</a>，这也是笔者近期使用较为频繁的一个
app</p>
<p>最后，在学些这些看起来跨度有点广的内容过程中，笔者觉得有一点是在各个领域都适用的，那就是<strong>不要盲信各种观点和知识，而是要保持独立思考的能力，要时刻思考这些内容是否合理，放到今天是否还适用，放到自己身上是否适用，毕竟尽信书不如无书</strong></p>
<h2 id="关于生活">关于生活</h2>
<p>这一年基本也还是在公司和住的地方之间穿梭，过着两点一线生活；虽然来北京
2
年多了，但那些著名的景点基本都没去过，以至于我妈每次跟我打电话都跟说我白去北京了~</p>
<p>由于周六日经常回公司健身、看书/paper、刷知乎/b站、写文章(这一年写的文章基本都是周六日+各种节假日写的，因为上班真的很忙。。。)，以至于一些不明真相的人都觉得我“卷”（hhh，这个词属实是被滥用了），但是他们可能不知道的是，我周六日会公司都会把
lark
给关了，不会用工作上的事情去打扰别人，也不希望别人打扰自己，专心做那些自己很想做但是由于在工作日太忙而无法去做的事情</p>
<p>我也常常问自己：你是有在体验生活吗？你是在做苦行僧吗？但后来我慢慢发现，<strong>撸铁跑步带给我的满足感，并不亚于去探店吃到了心仪已久的美食；写完一篇文章、看到博客又记录了自己的变化所带来的的成就感，并不亚于去攀登了一座险峻的高峰；了解到一些表面现象背后的本质原因所带来的震撼，并不亚于看到了光怪陆离的自然风光；AC
一道题目所带来的快感，也不亚于通关一款制作精良的游戏。</strong></p>
<p>说了这么多，并不是说前者就比后者好，恰恰相反，我觉得上面提到的很多“不亚于”的事情，都是很有意义的。只是相同的一件事情，对于不同的人来说意义是不同的，也许在外向的人那里是补充精力的，但在内向的人那里则是消耗精力的，笔者觉得关键还是要学会让自己每天过得充实而快乐。</p>
<p>同时，需要<strong>将快乐和快感区分开</strong>，也体会过刷了一下午的手机后的那种空虚感，后来看到了
<a href="https://www.zhihu.com/people/ze.ran">ze ran</a>
写的一段话，才意识到那是下面说的快感，而不是快乐</p>
<blockquote>
<p>快乐和快感不同，快乐是要去争取的，是要付出努力的，是可以回味的；而快感是廉价的，是短暂的，是空虚的。不是说快感不好，而是在快感过去后，不用叹息快乐短暂，因为逝去的并不是快乐。努力拼搏，学习锻炼，也不用向别人诉说自己的辛苦，因为收获的是快乐</p>
</blockquote>
<h2 id="关于健康">关于健康</h2>
<p>今年体检各项指标也都还算正常，父母检查出了一些小毛病，但总体并无大碍</p>
<p>在运动上，刚刚看了下在内部健身房累积签到的次数，大概是 216 次，而
2021 年的大概是 80 次，大概 4~5 天一次</p>
<p><img src="https://wulc.me/imgs/gym2021.jpeg" height="20%" width="20%"></p>
<p>至于运动量，之前用的小米手环运动模式太少，比较难记录，所以双 11
换了荣耀的 GS PRO
手表，是真的好用，运动模式支持也比较多，所以也基本记录了 12
月份基本数据</p>
<p><img src="https://wulc.me/imgs/exercise2021.jpeg" height="50%" width="50%"></p>
<p>今年下半年开始有了减脂和增肌的计划，所以也学些了不少这方面的知识，经过饮食和训练，现在的总体的体脂也下降到
14%
左右，六块腹肌的轮廓已经隐隐欲现了，希望明年的总结能够放上八块腹肌的照片hhh</p>
<p><img src="https://wulc.me/imgs/fat202201.jpg" height="50%" width="50%"></p>
<p>这里也附上减脂过程中做的一些笔记，基本上知乎一搜一大堆,
这个回答比较全面，可以看一下 <a
href="https://www.zhihu.com/question/361928955/answer/1774167080">如何把体脂降到
15%?</a></p>
<p><img src="https://wulc.me/imgs/reduce_fat.jpg" height="50%" width="50%"></p>
<p>另外就是饮食和睡眠了，说实话这两点做得不够好，主要的问题是<strong>情绪性进食和报复性熬夜</strong>，前者往往出现在工作时比较繁忙时，总是忍不住会吃很多零食和正餐，后者则是因为工作、生活等压力等原因，工作日晚上容易熬夜无意义的刷手机等，当前已经意识到这个问题了，也有尝试小方法，希望明年总结的时候不会再被这两个问题困扰吧</p>
<h2 id="小结">小结</h2>
<p>如同去年的小结的短语一样，“写这篇总结文章的过程，是一个不断的自我剖析和自我反思的过程，剖析自我到底想成为一个什么样的人，反思自我还能不能做得更好”；而今年我觉得还能再加一句，这也是一个对自己诚实的过程，做的好与不好都需要暴露给自己，多问自己几个为什么；惟其如此，才能知道自己真正想要的是什么，下一步应该怎么走。</p>
<p>总体来说，去年的工作还算顺利、学习热情没有减退、生活能带来快乐、家人与自己身体还健康，感觉已经比较幸运了；至于技术/沟通/管理/投资等各种能力，在今年仍需慢慢培养，同时需要学会爱惜自己的身体。最后，也祝愿看到这里的你身体健康，心想事成。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>A Hybrid Bandit Model with Visual Priors for Creative Ranking in Display Advertising</title>
    <url>/2022/03/05/A%20Hybrid%20Bandit%20Model%20with%20Visual%20Priors%20for%20Creative%20Ranking%20in%20Display%20Advertising/</url>
    <content><![CDATA[<p>之前的文章 <a
href="https://wulc.me/2022/02/01/Dynamic%20Creative%20Optimization%20in%20Online%20Display%20Advertising/">Dynamic
Creative Optimization in Online Display
Advertising</a>中提到，广告创意往往可分为创意生成、创意优选和创意投放三大块，本文主要讲创意优选这部分的一些做法，这个过程一般会涉及到
E&amp;E 的过程。</p>
<p>本文的主要内容是选自阿里发表的一篇 paper：<a
href="https://arxiv.org/abs/2102.04033">A Hybrid Bandit Model with
Visual Priors for Creative Ranking in Display Advertising</a>，paper
通过 list-wise
的训练方式达到对同一计划下的候选创意进行排序(即优选)的目标；list-wise
可以算作 Exploitation 部分，paper 还通过了一个 bandit model 达到
Exploration
的目的，总体的做法比较合理，也在业界实际场景验证了有效性，值得一看。</p>
<span id="more"></span>
<p>paper 里提出的方法主要分为两大模块：VAM(visual-aware ranking model)
和 HBM(hybrid bandit model), 总体的模块图如下所示，VAM 即上面提到的基于
list-wise 优选做 exploitation 模块，HBM 则是基于 badnit model 做
exploration 模块，下面也主要从这两个模块进行介绍。</p>
<figure>
<img src="https://wulc.me/imgs/VAM_HBM.jpg" alt="architecture" />
<figcaption aria-hidden="true">architecture</figcaption>
</figure>
<h2 id="vam">VAM</h2>
<h3 id="list-wise-loss">list-wise loss</h3>
<p>list-wise 是 learning to rank 里一种建模方式，另外两种分别是
point-wise 和 pair-wise，常见的 ctr/cvr 预估都是采用 point-wise
的方式；</p>
<p>关于这几种建模方式可参考下面两篇 paper，两篇都是 Microsoft 发表的
paper，第一篇讲了 point-wise -&gt; pair-wise 的过程, 第二篇讲了
pair-wise 到 list-wise 的过程</p>
<ul>
<li><a
href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf">From
RankNet to LambdaRank to LambdaMART: An Overview</a></li>
<li><a
href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf">Learning
to Rank: From Pairwise Approach to Listwise Approach</a></li>
</ul>
<p>VAM 采用的 list-wise loss 即是第二篇 paper 中的提出的
loss，其流程如下图所示，更详细的推导可参考上面第二篇 paper</p>
<!-- ![listnet algorithm][6] -->
<p><img src="https://wulc.me/imgs/ListNetAlgorithm.jpg" height="50%" width="50%"></p>
<h3 id="vam-loss">VAM loss</h3>
<p>回到 VAM，上图的 query 相当于商品(product)，而 list 则是每个 product
对应的所有创意(一个 product 往往会有多个候选的创意)</p>
<p>因此，list 中的每个 item 的 prediction <span
class="math inline">\(p_{m}^{n}\)</span>和 ground truth <span
class="math inline">\(y_{rank}(C_m^n)\)</span> 表示如下,
每个符号含义可参考最上面的总体框架图右上角</p>
<p><span class="math display">\[p_{m}^{n} =
\frac{\exp(s_m^n)}{\sum_{i=1}^{M}\exp(s_i^n)}\]</span></p>
<p><span class="math display">\[y_{rank}(C_m^n) = \frac{\exp(CTR(C_m^n),
T) }{\sum_{i=1}^{M}\exp(\exp(CTR(C_i^n), T)}\]</span></p>
<p><span class="math inline">\(y_{rannk}(C_m^n)\)</span> 中的 <span
class="math inline">\(T\)</span> 的作用是
<code>adjust the scale of the value so that make the probability of top1 sample close to 1</code>，则对于第
<span class="math inline">\(n\)</span> 个 product, 其 list-wise loss
如下所示</p>
<p><span
class="math display">\[L_{rank}^{n}=-\sum_{m}y_{rank}(C_m^n)\log(p_{m}^{n})\]</span></p>
<p>除了常规的 list-wise loss, paper 里还添加了一项 point-wise 的
auxiliary regression loss，其含义也比较直观，就是让 VAM 的 prediction
尽可能接近其真实的 CTR 值，其表示如下</p>
<p><span class="math display">\[L_{reg}^{n}=\sum_{m} ||CTR(C_m^n) -
s_m^n||_{2}\]</span></p>
<p>根据原文的描述<strong><code>making the outputs close to the real CTRs will significantly stabilize the bandit learning procedure</code></strong>，其作用是让后续的
HBM 训练更加稳定，则第 <span class="math inline">\(n\)</span> 个 list
的总体 loss 如下所示（实验中 <span class="math inline">\(\gamma\)</span>
= 0.5）</p>
<p><span class="math display">\[L^{n} = L_{rank}^{n} + \gamma
L_{reg}^{n}\]</span></p>
<h3 id="noise-mitigation">noise mitigation</h3>
<p>这里的 noise mitigation 指的是部分创意的 impression
会比较少，统计的后验 CTR 波动性较大(极端的比如只曝光一次)，</p>
<p>一个粗暴的方法是对 impression 卡个阈值，小于阈值的 item
就不作为训练数据，但这样可能会导致训练的数据量过少，paper 里采用了如下 2
种方法</p>
<p>第一种方法是label smoothing, 也是这篇 paper 提出的方法 <a
href="http://www.cs.cmu.edu/~xuerui/papers/ctr.pdf">Click-Through Rate
Estimation for Rare Events in Online
Advertising</a>，其思想是基于贝叶斯学派给点击数 clicks 和 CTR
值整个先验分布，这样遇到极端值时也有分布约束，导致最终的值不会太离谱，</p>
<figure>
<img src="https://wulc.me/imgs/vam_label_smoothing.jpg"
alt="label smoothing" />
<figcaption aria-hidden="true">label smoothing</figcaption>
</figure>
<p>第二种方法是 weighted sampling，就是给点击数少的样本更小的权重，paper
的做法是对点击数取了个 log 变换作为这个样本的 weight。</p>
<h2 id="hbm">HBM</h2>
<p>HBM 本质上是一个 <a
href="https://en.wikipedia.org/wiki/Bayesian_linear_regression#:~:text=In%20statistics,%20Bayesian%20linear%20regression,the%20context%20of%20Bayesian%20inference.">Bayesian
Linear
Regression</a>，从名字大概就能猜测，这个是贝叶斯学派的方法，即认为模型参数是服从一个分布，通过从分布里采样达到
exploration 的目的，其推导过程如下</p>
<p>假设线上的数据按照如下方式产生, <span
class="math inline">\(y\)</span> 表示是否点击，<span
class="math inline">\(f^T\)</span> 表示通过 VAM 抽取出来的 visual
representation, <span class="math inline">\(\widetilde{w}\)</span> 和
<span class="math inline">\(\epsilon\)</span> 则是模型的参数</p>
<p><span class="math display">\[y = f^T\widetilde{w} +
\epsilon\]</span></p>
<p>paper 里将 <span class="math inline">\(\epsilon\)</span>
先验分布假设为一个正态分布即 <span class="math inline">\(\epsilon
\thicksim N(0, \sigma^2)\)</span>, 同样将 <span
class="math inline">\(\widetilde{w}|\sigma^2\)</span>
假设为一个正态分布，两者互为共轭</p>
<p><span class="math display">\[\sigma^2 \thicksim IG(a, b)\]</span></p>
<p><span class="math display">\[\widetilde{w}|\sigma^2 \thicksim N(\mu,
\epsilon^2 \Sigma^{-1}) \]</span></p>
<p>参考上面 wiki 的推导过程，总体模型的 training 和 serving
过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/HBM_training_serving.jpg"
alt="hbm_train_serving" />
<figcaption aria-hidden="true">hbm_train_serving</figcaption>
</figure>
<p>公式 18 可以认为是 training 过程(对于贝叶斯方法，有个特定的名字<a
href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian
inference</a>)，在贝叶斯的方法中，更新模型就是更新假定的 distribution
中的各个参数，本例中就是上面两个分布中的 <span
class="math inline">\(a\)</span>、<span
class="math inline">\(b\)</span>、<span
class="math inline">\(\mu\)</span>、<span
class="math inline">\(\Sigma^{-1}\)</span>,
这里使用的是解析法，但是很多问题解析法是无法解决的，因此常常会利用 Monte
Carlo sampling 一类方法，</p>
<p>而 serving 则是从 training 得到的分布中抽样得到 <span
class="math inline">\(w(t)\)</span>, 计算最终的 score，</p>
<p>上面的计算 score 的方法是第 <span class="math inline">\(n\)</span> 个
product 下所有 creative 共用一套参数 <span
class="math inline">\(w^n\)</span>, paper 还提出了针对每个 creative
也应该有一套参数，即针对第 <span class="math inline">\(n\)</span> 个
product 下的第 <span class="math inline">\(m\)</span> 个
creative，计算的 score 应该是</p>
<p><span class="math display">\[y_m^n = {f_m^n}^{T}w^n +
{f_m^n}^{T}w_m^n\]</span></p>
<p>paper 这样做的原因是</p>
<blockquote>
<p>This simple linear assumption works well for small datasets, but
becomes inferior when dealing with industrial data. For example, bright
and vivid colors will be more attractive for women’s top while concise
colors are more proper for 3C digital accessories. In addition to this
product-wise characteristic, a cre- ative may contain a unique designed
attribute that is not expressed by the shared weights. Hence, it is
helpful to have weights that have both shared and non-shared
components.</p>
</blockquote>
<p>所以 paper 根据曝光量算对 score 算了一个权重 <span
class="math inline">\(\lambda\)</span>, 其计算方法如下</p>
<p><span class="math display">\[\lambda =
(1+e^{\frac{-impression(I^n)+\theta_2}{\theta_1}})^{-1}\]</span></p>
<p>则最终的 socre 如下</p>
<p><span class="math display">\[y_m^n = (1-\lambda){f_m^n}^{T}w^n +
\lambda{f_m^n}^{T}w_m^n\]</span></p>
<p>这里的思想是在某个 product 的曝光量充足时，更加相信其 product-wise 的
score，反之则更相信 creative-wise 的 socre</p>
<p><strong>但是笔者对这里的做法存疑，笔者认为这个 <span
class="math inline">\(\lambda\)</span> 参数应该做在 creative 粒度，当
creative 粒度的数据充足时，应该更相信creative-wise 的 socre，反之更相信
product-wise 的 score。</strong></p>
<p><strong>因为如果每个 creative 都有足够的后验数据来进行训练，那做到
creative 粒度的个性化参数效果上应该会是最好的，但是问题是现实是很多
creative 的后验数据非常系数甚至是没有后验数据的，这个时候采用
product-wise 的 score 相当于是做了一个 clustering，笔者认为这样更加 make
sense</strong></p>
<p>因此，HBM 的算法流程如下图所示</p>
<!-- ![HBM_algo][13] -->
<p><img src="https://wulc.me/imgs/HybridBanditModel.jpg" height="50%" width="50%"></p>
<h2 id="实验">实验</h2>
<p>paper 里采用了 2 个评估指标：Simulated CTR(sCTR) 和 Cumulative
regret, 前者模拟 online learning 过程，后者则是评估 bandit model
，两者计算方法如下，但是好像这两个指标不是非常通用？</p>
<!-- ![sCTR][14] -->
<p><img src="https://wulc.me/imgs/VAM_HBM_sCTR.jpg" height="50%" width="50%"></p>
<!-- ![regret][15] -->
<p><img src="https://wulc.me/imgs/VAM_HBM_regret.jpg" height="50%" width="50%"></p>
<p>采用的评估数据集有 2
个，一个是自建的，另一个是公开数据集，效果上自然也是 paper
提出的效果最好，但是 paper 没有做在线的 ab
实验，逼近离线指标跟线上的效果还是有 diff 的</p>
<h2 id="小结">小结</h2>
<p>总的来说，这篇 paper 提出一种 creative selection 的方法，由 VAM + HBM
组成，笔者认为有以下几点值得学习</p>
<ol type="1">
<li>VAM 利用投后数据(ctr), 通过 list-wise 方法学习出 creative 的 visual
representation</li>
<li>HBM 利用 VAM 的 visual representation 通过 bandit model，来实现
exploration 部分，同时考虑了 product-wise 和 creative-wise 建模和预估
score 的融合</li>
</ol>
<p>但是也有以下几点笔者是存疑的</p>
<ol type="1">
<li>product-wise 和 creative-wise 的分数时，<span
class="math inline">\(\lambda\)</span>参数只考虑到 product-wise
的信息，没能很好体现 creative-wise的权重，具体原因上面说了</li>
<li>广告系统通常是召回+精排的环节，精排往往是 creative
粒度的，上面提出的系统未必能完整地融入现有的广告系统，倒是 VAM
训练得到的 visual representation 作为精排模型的一个 feature
是一种可能的方法</li>
<li>VAM 已经可以对候选创意做优选了，为什么还需要 HBM 来做
exploration？或者说 exploration 是为了拿什么收益?
根据笔者的经验，在广告系统中 exploration 意味着破坏原来系统 feedback
loop
所形成的分布，这往往会破坏系统由于马太效应形成的稳态，往往会造成收入的下降，相对应兑换的是一些生态指标或者信仰指标的提升。</li>
</ol>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>2022 小结</title>
    <url>/2023/01/01/2022%20%E5%B0%8F%E7%BB%93/</url>
    <content><![CDATA[<p>2022
的最后一个月，在全国“喜阳阳”的氛围中度过了，写这篇文章时，恢复了差不多一周多，基本也没什么症状了。但回想下今年发生的各种事情，真的是可以用魔幻来形容，这个魔幻不仅仅指防疫政策的
180
度大转弯，更是发生在身上的各种事情，这些事情基本都可以总计为计划赶不上变化，或者说未来无人知晓</p>
<p>一直都有写年度总结的习惯，而这么魔幻的一年，更值得写篇文章纪念下，正好也是元旦放假，趁着这几天把过去一年发生的事情梳理了一下~</p>
<span id="more"></span>
<h2 id="关于工作">关于工作</h2>
<p>现在回头看 2021
时的总结，发现当时写下的未来工作规划，跟后来实际的工作差异非常大；究其原因，还是总体业务和组织变化过于频繁</p>
<p>上半年主要在做一些广告创意上的工作，从平台和技术视角来看，笔者将这个方向主要分为如下三个子方向：生成、优选和投放；其中生成是指利用素材(标题、图片、视频、落地页等)生成候选创意(用户看到的广告)，优选是从计划的候选创意(一个计划下的候选往往有多个)中选择
topk 个用于投放，投放则是将优选出来的创意投放至线上</p>
<p>学界研究得比较多的往往是优选和投放，优选是个很典型的
E&amp;E(Exploration &amp; Exploitation) 问题,
研究的方法也很多，当时看到一篇比较有参考价值的是淘宝的一篇
paper，也针对这篇 paper 做了一些记录《<a
href="https://wulc.me/2022/03/05/A%20Hybrid%20Bandit%20Model%20with%20Visual%20Priors%20for%20Creative%20Ranking%20in%20Display%20Advertising/">A
Hybrid Bandit Model with Visual Priors for Creative Ranking in Display
Advertising</a>》,paper 里提出的方法主要由两大模块组成：VAM 和 HBM, VAM
是基于 list-wise 优选做 exploitation 模块，HBM 则是基于 badnit model 做
exploration 模块</p>
<p>投放则是一个更大的话题，往往涉及到成本、跑量、生态的问题，当时主要是针对生态问题做了一些研究和实践；这里的生态问题，往往是指复制问题和长尾问题，复制问题指的是投手利用系统的
variance
复制很多相同的创意，以达到跑量的目的，长尾问题指的是很多创意压根投不出去，或者投出去的量非常少</p>
<p>而从广告主的视角来看，素材制作是有成本的（如拍视频、修图等），且这个成本是在投放前就要花出去的，如果基于这些素材投放不起量，那这些成本就相当于打水漂了；而长尾也是导致复制问题的原因之一，毕竟就是投不出去，广告主才会去不断复制素材以达到跑量的目标；因此，通过技术手段缓解素材的长尾问题，对于整个系统的长期生态是有必要的</p>
<p>回到长尾问题，也是推荐/广告中很常见的一个问题，一般从策略或模型角度都有一些解决思路</p>
<ul>
<li>策略层面，根据系统和业务特性设计规则，比如说对长尾的 item
有特定的扶持，强行让这些 item 能触达到更多的用户</li>
<li>模型层面，核心思想就是让模型能更好地学习到 long tail item 的
representation，因为这个问题的根本原因就是 long tail item
的样本过少，进而导致模型学习的不好</li>
</ul>
<p>策略层面除了上面提到的一些强依赖业务的规则设计，也有一些通用的思路，比如说建模二部图，强行让创意的曝光量有
lowerbound 的保证，这其实也是冷启动比较常用的一个套路，这部分可参考这篇
paper 里提到的思路 《<a
href="https://wulc.me/2022/02/01/Dynamic%20Creative%20Optimization%20in%20Online%20Display%20Advertising/">Dynamic
Creative Optimization in Online Display Advertising</a>》</p>
<p>模型层面，当时研究下来，感觉比较靠谱的是 transfer learning 和
self-supervised learning 两个思路，当时也写了这部分的一个总结 《<a
href="https://wulc.me/2022/04/04/Long%20Tail%20Problem%20In%20Item%20Recommendation/">Long
Tail Problem In Item Recommendation</a>》</p>
<p>在广告系统中，优选和投放还算是比较常规的部分；素材生成则是近年业界在研究的一个方向，比如说巨量千川推出的产品：<a
href="https://mp.weixin.qq.com/s/fojF0LZKQcPVNKuEiGfrtg">高光快投</a>，也是笔者深度参的一个项目，这个产品的目标就是为直播广告主截取直播间的高光片段，然后加工成素材投放，节省广告主的素材制作成本（尤其是素材制作能力弱的中小商家）</p>
<p>从技术层面来说，这个难点在于“高光”在这里没有一个绝对的 ground
truth，而没有 ground truth 或者说 label
是无法通过模型进行截取，而基于人工打标的方式势必是不可长期持续的；当时针对这部分也做了一些调研，绝大部分的
paper 也都是基于人工打标的数据进行训练的，最后是 2019 年一篇 CVPR 的
paper 给了笔者不少启示，即实际业务中有很多投后的指标数据（ctr、cvr、roi
等），可以基于这些投后的数据来构建训练样本，即基于实际投放而不是人为的主观判断来决定一个视频是否属于高光，而在实际业务中，这也被证明是比较有效的；这部分的一些探索可参考《<a
href="https://wulc.me/2022/08/27/Highlight%20Detection%20In%20Video/">Highlight
Detection In Video</a>》</p>
<p>在高光快投这个项目中，基本上把创意的生成、优选和投放环节都涉猎了一遍，整个产品的消耗也在接手后涨了差不多
2 倍，但 7、8
月左右，因为整体组织架构有调整等原因，这个方向的优先级总体有变化；虽然上半年在做创意时已经有一些调整，但都不如这次的大，笔者总体还是能理解这些调整的，毕竟不同的老大判断的项目的优先级不同，而新老大一般上来都要重新
review 当前的项目，停一些认为不合理的项目，立一些新的项目</p>
<p>所以后面也去做了算力的相关工作，这部分工作挺有意思的，简单来说就是在机器资源有限的情况下，怎么提高机器的变现效率，从“算力
= 请求量 × 平均请求消耗资源”，可以从 2
方面进行优化，这部分业界也已经有一些尝试了，针对这部分也写了一些粗浅的理解
《<a
href="https://wulc.me/2022/10/30/%E6%B5%85%E8%B0%88%E7%AE%97%E5%8A%9B%E4%BC%98%E5%8C%96/">浅谈算力优化</a>》</p>
<p>上面提到的基本都是技术方面的工作，而在今年还有一些谈不上正式的管理经历，自己也在这个问题上做了一些调研，于是便对这部分做个总结
《<a
href="https://wulc.me/2022/09/25/%E8%81%8A%E8%81%8A%E7%AE%A1%E7%90%86/">聊聊管理</a>》。在这个过程中，也发现了身边那些优秀的管理者，使用管理的手段是多种多样的，共性更多是在人上，比如说他们的能力是出众的，态度是谦和的；围绕着事而不是人开展业务等。同时也意识到当上了管理者就能一劳永逸是个妄念；而随着业务的发展不断调整、进化自己，以更年轻和开放的心态去迎接当前的挑战，有管理工作委任时能够扛得起，没有也能做个能打的
IC，可能才是“一劳永逸”的答案；毕竟真正当上管理者的人是少的，而当上管理者可能也需要在合适的时机踩中合适的机会，有运气与努力成分；好好生活，快乐工作，才是每个普通人应该去努力追求的</p>
<h2 id="关于投资">关于投资</h2>
<p>今年上半年算是断断续续地学些了有知有行上的相关内容，并且按照笔者的理解划分为：认知与心态、概念与常识、买与卖三大模块。认知与形态主要是投资前的心理建设部分，概念与常识主要是介绍一些基本概念（如周期、投资标的、宏观常识等），买与卖则是一个比较成体系的投资系统（涉及到资产、仓位配置等）</p>
<ul>
<li><a
href="https://wulc.me/2022/05/04/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B%281%29-%E8%AE%A4%E7%9F%A5%E4%B8%8E%E5%BF%83%E6%80%81/">投资这件事(1)-认知与心态</a></li>
<li><a
href="https://wulc.me/2022/06/18/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B%282%29-%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%B8%B8%E8%AF%86/">投资这件事(2)-概念与常识</a></li>
<li><a
href="https://wulc.me/2022/07/02/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B%283%29-%E4%B9%B0%E4%B8%8E%E5%8D%96/">投资这件事(3)-买与卖</a></li>
</ul>
<p>写完上面的文章后，给笔者留下最深刻印象的是“<strong>盈亏同源</strong>”这个概念，顾名思义，就是盈利与亏损都是出自同一个源头，或者说都是同一个原因造成的；比如说，导致当下亏损的操作，如果换了一个平行时空，可能就是盈利的了。因为市场是不确定的，无法预测的，要放弃对所谓确定性的追求，同时摸索出适合自己的选择判断体系，基于当下的信息作出最好的判断，不要一直对过去的操作后悔或悔恨。仔细想想，生活不也是这样么？</p>
<p>而今年的整个投资市场非常魔幻，也是给笔者上了很好的一课，尤其是回想起比较疯狂的
2021
年初，大家疯狂买基金，连我妈啥都不懂都糊里糊涂地投了点钱进去，再看看今年惨淡，才更深刻地体会到教科书说的“闲钱投资、不加杠杆、不接飞刀、仓位配置”等是朴素却又正确的道理；也在各种媒体博眼球的报道中，体会到了“三根大阳线改变信仰”是怎么一回事</p>
<p>今年整个市场的回顾可以参考知行小酒馆的播客《<a
href="https://youzhiyouxing.cn/materials/1384">魔幻的 2022
年过去了，2023 年的市场会好吗？</a>》，给笔者印象最深刻的是 4
月份那次大下跌，上海封城，当时整个市场可以说是一遍哀嚎，有知有行的温度计也到了
0
度，现在回头看是个买入的好时机，但也只局限于现在回头看，因为在当时，大家剩下的都只有“<a
href="https://youzhiyouxing.cn/materials/1198">恐惧</a>”了</p>
<p>刚看了下账户，所有权益类资产今年总体回撤大概 5%
左右，而且是在边跌边买的，如果一开始就重仓，回撤会更大；主要是亏在了<strong>主动型基金和中概</strong>上，主动型基金是源于对基金经理过往历史业绩的信任，所以总体仓位不低，这里并不是说主动基金不好，而是要知道在主动基金获利，业绩较好时，需要清楚这个是
alpha 收益还是 beta
收益，是周期带来的收益还是基金经理择股带来的收益，同时主动型基金的仓位配比信息是有延迟的，你不清楚自己在各行业的配置如何，所以笔者也在逐渐减少主动型基金的配比，更多放到了宽基指数和行业指数上</p>
<p>中概则是过快地接了飞刀，在刚下跌的时候就开始加仓，导致后续越加仓越跌，当然，这里的“过快”其实也是站在当下来看而得到的结论，当时谁也不会觉得会跌到现在这样，是无法预测的；但交了中概这个学费后，笔者对安全边际的要求会更加严格，也更加敏感了。现在分析，当时这么快接飞刀，一是来源于不太懂，二是当时总体仓位还很轻，着急加仓</p>
<p>今年盈利的都是大 A 以外的指数, 主要是恒生和德国 DAX
指数，两者都是在比较低点时候进场的，其实也进一步验证了有知有行常说的“好资产+好价格”的理念，同时也说明了分散投资以及海外投资的必要性</p>
<p>另外，在今年做的比较多的一件事情，是经常看账户，看当前的盈亏；这听起来就是一个反面教材，因为根据一些研究，看账户越频繁，往往回撤会越大，因为恐惧割肉会比较多。但笔者在看账户的时候，更多在做的是<strong>观察自己面对上涨或下跌的情绪变化</strong>，算是自我情绪觉察的一个练习，然后根据当前情绪再来调整仓位。目标做到“涨跌都舒服”，因为这样才能拿得住</p>
<h2 id="关于生活">关于生活</h2>
<p>今年的生活也基本是两点一线，日常的状态也跟去年的差不多</p>
<blockquote>
<p>撸铁跑步带给我的满足感，并不亚于去探店吃到了心仪已久的美食；写完一篇文章、看到博客又记录了自己的变化所带来的的成就感，并不亚于去攀登了一座险峻的高峰；了解到一些表面现象背后的本质原因所带来的震撼，并不亚于看到了光怪陆离的自然风光；AC
一道题目所带来的快感，也不亚于通关一款制作精良的游戏。</p>
</blockquote>
<p>这种状态一直持续到 6~7
月，那会各大互联网公司在进行或开启裁员潮，内部业务在进行大调整，可以说是“内忧外患”，于是开始认真审视当前的这种生活的可持续性，同时心中也萦绕这很多没有答案的问题，那段时间可以用
2 个字来形容：焦虑</p>
<p>于是笔者开始去调研，尝试回答那些没有答案的问题，也是在那个时间段，将所有调研到的内容作了梳理，写成了这篇文章《<a
href="https://wulc.me/2022/07/31/%E4%BB%8E%E7%84%A6%E8%99%91%E8%B0%88%E8%B5%B7%EF%BC%8C%E8%81%8A%E8%81%8A%E7%94%9F%E6%B4%BB%E7%9A%84%E5%8F%AF%E8%83%BD%E6%80%A7%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%80%A7/">从焦虑谈起，聊聊生活的可能性与随机性</a>》，也算是给自己做的心理按摩。简单来说，就是生活和工作是存在很多可能性的，不止大厂这一种叙事方式，只要能对外提供社会需要的服务或者说
<a href="https://nav.al/productize-yourself">Productize
Yourself</a>，也是一种安身立命的途径，也是一种可能的生活方式</p>
<p>另外，焦虑在人生的每个阶段都是必然存在的，接受焦虑、接受生活的随机性，比起去对抗焦虑、精细规划未来、小心翼翼地迈出每一步，可能是一种更好的方式；毕竟随机性不可避免，而过分追求确定性可能会让我们瞻前顾后、步步惊心，还不如学着接受并享受生活的随机性；既然预定要飞向意大利的航班，最终有可能让你降落在荷兰，还不如好好享受荷兰的风光，对自己说一句：<a
href="https://zhuanlan.zhihu.com/p/435160088">欢迎来到荷兰</a></p>
<p>给自己做完了这个心理按摩后，心里的焦虑的确少了很多，或者说虽然日常也会焦虑，但是不再是之前的无头苍蝇的那种恐惧，更多的是对任务没有及时完成的那种着急，而不是无端生出的惶恐；因为认识到且认可了生活不止当前这一种叙事的方式，只要心态能够打开、积极拥抱变化，就不用过于恐惧所谓的
35
岁危机，毕竟未来的事情都是无人知晓的，而生活本身也是小马过河，其他人总结出来的经验未必适用你</p>
<p>另一个比较有意思的事情，是认识了 P；跟 P 认识的过程也很有趣， 我跟 P
不是一个序列的，但是都参与同一个业务，日常工作会有一些合作；最开始以为 P
是被我纯正的“广普”吸引的（毕竟多次调侃我的普通话），后来跟她聊天才发现，原来她在为她的闺蜜找对象，而我成了她“盲狙”的目标之一</p>
<p>对象当然没有谈成，因为还是比较享受一个人的状态~总体感觉就还是处于《<a
href="https://www.xiaoyuzhoufm.com/episode/5e74543a418a84a046c4e578">我（们）的孤老生活</a>》中的孤老第一阶段，至于是否会迈入第二阶段或者何时迈入，跟前面说的很多事情一样，无人知晓也无法预测</p>
<blockquote>
<p>孤老的两个阶段：（1）一个人的阶段，对个人成长非常重要（2）结束一个人的阶段，渴望有家庭甚至有陪伴
当你去探索生命的本源问题的时候，你会感到一种很极致的孤独。你会觉得人是没有办法被理解的。但这我觉得这是一个人心灵成熟的一个必要条件
而当孤独走到极致，或者说自立走到极致，会发现别人给不了我什么，或者不需要其他人给我什么，才真正明白了怎么去爱别人（付出的爱是<strong>溢出</strong>的，是允许）</p>
</blockquote>
<p>倒是在跟 P 的几次沟通下来，慢慢成为了兄弟（她是大哥 hhh）；P
是那种很早就知道自己想要什么的人，也一直有规划怎么去达成这些目标，跟她一块聊工作、聊生活、聊规划，探讨了很多困惑笔者比较久的问题，P
也给了我不少受用建议，同时也了解到了 P
比较神奇的经历，包括但不限于平静却又凡尔赛地更跟我说如何考上清华、工作不爽然后出国读了个书、面对外人看来的不幸经历却付之一笑...</p>
<p>后来在某天晚上心血来潮跟 P
去夜游了亮马河，算是我在北京为数不多出去看风景的经历；然后去吃火锅，压马路到凌晨
2
点，也算是一段难忘的经历了~（船在动+手机渣像素导致了这种图片，绝对不是个人没怎么拍过照、摄影技术差[狗头]）</p>
<p><img src="https://wulc.me/imgs/2022_liangmahe.jpeg" height="20%" width="20%"></p>
<p>可惜的是 P 马上就要到南方城市了，原本约定好的潮牛火锅，也在最后
11、12
月的居家中落空了；有人说职场中，我们在都在坐一趟时光的公交车，有些人中途上车了，和我们成了朋友，但也有些人下车后转到另一辆车了，希望跟
P 能在以后的公交中有再次重逢的机会吧~</p>
<h2 id="关于健康">关于健康</h2>
<p>记得去年测体脂的时候立了个 flag：希望今年体脂能降得更低，能放上 8
块腹肌的照片；可是这个计划随着 11、12 月的居家去不了健身房 +
居家时管不住嘴 +
康复后不敢做剧烈运动等等(为自己找的借口)，最终未能实现；现在的体脂得有
16% 了吧</p>
<p>今年 10
月的体检，总体无太大问题，但一些小毛病还是少不了，毕竟机器越用越坏；也买了一些保险，也当做是为未知的风险做一些对冲准备~</p>
<p>整年的运动基本都用运动手表记录下来了，回顾才发现居然耗时最长的是每天上下班的骑车部分，其次才是为了减脂做的力量训练，11、12
月基本是躺平状态了，因为都是居家办公+康复的状态</p>
<p><img src="https://wulc.me/imgs/2022_exercise.jpeg" height="20%" width="20%"></p>
<p>然后看了下几年去健身房的次数，最近一次就停留在 11
月初居家前，跟去年的数对比了下，大概今年去了 70 次左右，</p>
<p><img src="https://wulc.me/imgs/2022_gym.jpeg" height="20%" width="20%"></p>
<p>而去年提到的情绪性进食和报复性熬夜两个问题，今年也都有一些缓解，因为慢慢意识到，这两个行为本质上都是一样的，就是“<strong>把自己当做自己的泄欲工具</strong>”，而不在这么做的前提是“<strong>把自己当做一个真正的人</strong>”，这部分可以去听一下上面提到的播客《我（们）的孤老生活》。我们除了把自己当做自己的泄欲工具，也常常会把他人当做自己的泄欲工具，套用播客里的话是这么说的</p>
<blockquote>
<p>在一段关系里边，不管就是情侣关系，还是朋友之间的关系，还是家人等等。就是有的时候我们会简化对方或者理想化对方或者对扭曲化对方，都是因为对方我们<strong>没有把对方当成一个完整的人，是我们的欲望的投射</strong>，永远在衡量你有没有给到我我要那个东西，不允许对方成为他们的样子；但这里还有个前提：能允许别人是别人，首先要允许他自己是一个人，真正他把自己当成一个完整的人；只有先把自己当做一个人，才能把其他人当做一个人，才能不把自己当做一个泄欲的工具</p>
<p>允许自己是一个人：不再去做自我评判，接纳自己就是这样一个人（尽人事，听天命）</p>
</blockquote>
<h2 id="小结">小结</h2>
<p>去年真的是魔幻的一年，大到防疫政策的 180
度大转变、二级市场的此起彼伏、席卷而来的海内外裁员潮，小到个人工作的频繁变动；而这些事都在说明同一个事实：市场是无法预测的，未来是无人知晓的</p>
<p>去年虽然曲折，但家人与自己身体仍然健康，工作也还算顺利，也开始思考了生活更多的可能性；去年提到要培养的技术/沟通/管理/投资等各种能力，今年也都进行相应的学习和总结，也算是有所得</p>
<p>而今年最大的体会，就是生活存在非常多的随机性，正是这些随机性导致了前面提到的无法预测和无人知晓的未来，相比于面对随机性焦虑不安，小心翼翼走好每一步，更好的选择是享受这些随机性，基于当下境遇作出当下最好的选择，无须后悔或懊恼，毕竟“盈亏同源”，与君共勉</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>A Survey of Multi-Domain</title>
    <url>/2023/03/19/A%20Survey%20of%20Multi-Domain/</url>
    <content><![CDATA[<p>在实际的业务中，数据往往由多个 domain
组成，以广告为例，往往会存在多个转化目标，在 ctr、cvr
的预估时也要考虑不同转化目标的影响，因为在不同转化目标下，ctr、cvr
的分布(如均值、方差)往往是不一致的</p>
<p>解决这个问题最直观的思路是加 domain 相关特征或根据 domain
拆模型，前者属于隐式的方法，需要特征的区分性足够强、能被模型学到，但这个足够强没有一个量化的标准，基本只能看实验效果；后者则存在维护成本过高的问题，比如说有
n 个 domain 就要拆成 n 个模型</p>
<p>本文着重讲如何通过一个模型 serve 多个 domain
的方法，主要是在业界验证有收益且公开发表的工作，基本上可以分为 3 类</p>
<ol type="1">
<li>multi-head 结构</li>
<li>LHUC 机制</li>
<li>GRL 机制</li>
</ol>
<span id="more"></span>
<h2 id="mmoe">MMOE</h2>
<p>在一个模型中根据多个 domain 拆成多个 head（每个 head 代表一个
domain），通过每个 head 的参数学习特定 domain
的分布，是一种比较直观和常见的做法</p>
<p>这类方法的代表是 MMOE: <a
href="https://dl.acm.org/doi/pdf/10.1145/3219819.3220007">Modeling Task
Relationships in Multi-task Learning with Multi-gate
Mixture-of-Experts</a></p>
<p>下图直观展示了拆 head 的集中常见做法</p>
<p><img src="https://wulc.me/imgs/MultiDomainMMOE.jpg" height="50%" width="50%" alt="mmoe 结构对比"></p>
<p>MMOE 中的两个 M，第一个代表 multi-gate，第二个代表
multi-expert；multi-expert 比较好理解，从 ensemble 的角度来看，就是在做
bagging，而 gate 就是在控制每个 expert 的 weight，multi-gate 则是为每个
expert 分配一个 gate，本质上就是做到 domain-wise 的优化</p>
<p>而 gate 的具体实现，也是一个 mlp, 最终通过 softmax 得到每个 expert 的
weight，对于第 <span class="math inline">\(k\)</span>个
task，计算过程如下图所示</p>
<p><img src="https://wulc.me/imgs/MultiDomainMMOE_GATE.jpg" height="50%" width="50%" alt="mmoe gate 结构"></p>
<h2 id="star">STAR</h2>
<p>这是阿里的一篇 paper，应用场景就是比较典型的 CTR 业务，<a
href="https://arxiv.org/pdf/2101.11427.pdf">One Model to Serve All: Star
Topology Adaptive Recommender for Multi-Domain CTR Prediction</a></p>
<p>在模型结构上，也是为每个 domain
分配一部分自己的参数，从而达到在一个模型中 serve 多个 domain
的目的，这一点跟 MMOE 原理上是一样的，文章是这么说的</p>
<blockquote>
<p>Essentially, the network of each domain consists of two factorized
networks: one centered network shared by all domains and the
domain-specific network tailored for each domain</p>
</blockquote>
<p>STAR 基本结构如下图(b)所示，直观来看，有一个公共的 head，同时为每个
domain 分配了一个 head，最终每个 head 的参数是公共 head 参数与 domain
head 参数的 element-wise 结果</p>
<p><img src="https://wulc.me/imgs/MultiDomainSTAR.jpg" height="50%" width="50%" alt="mmoe star 结构"></p>
<ul>
<li>Partitioned Normalization(PN)</li>
</ul>
<p>在上面的结构中，有一个 Partitioned Normalization (PN)
的部分，目标是解决统一 batch normalization 在这 multi-domain
中不适用的问题</p>
<p>常规的 batch normalization 会计算 batch 内所有的样本的 mean 和
variance，然后做归一化，如下图所示；这里有个<strong>假设就是这批样本是独立同分布(i.i.d.)</strong>的，但
multi-domain 本身的要解决的问题就是不同 domain
的分布不一样，因此不能直接用原始的 batch normalization；关于 BN
为何有效，可参考这篇文章：<a
href="https://arxiv.org/pdf/2105.07576.pdf">Rethinking “Batch” in
BatchNorm</a></p>
<p><img src="https://wulc.me/imgs/MultiDomainSTAR_BN.jpg" height="40%" width="40%" alt="batch normalization"></p>
<p>而 PN 的做法是为原始 BN 中的参数 <span
class="math inline">\(\gamma\)</span> 和 <span
class="math inline">\(\beta\)</span> 生成额外的 domain-specify
参数，如下图所示</p>
<p><img src="https://wulc.me/imgs/MultiDomainSTAR_PN.jpg" height="40%" width="40%" alt="partitioned normalization"></p>
<ul>
<li>Auxiliary Network</li>
</ul>
<p>这是个小网络，输入是domain indicator(表示这个样本来自哪个
domain)，输出是一个预估值，最终输出的预估值会与上面的 STAR
的模型加和做最终预估; 作用等价于为每个 domain 增加了一个 bias 项</p>
<p><img src="https://wulc.me/imgs/MultiDomainSTAR_AT.jpg" height="40%" width="40%" alt="Auxiliary Network"></p>
<p>实验结果这里不展开，paper 效果显示比一些已有的 multi-domain
任务要好（参数量是否打平没提到）；也对 PN 的效果做了消融，结果显示 PN
的效果比直接用 BN 要好</p>
<h2 id="lhuc">LHUC</h2>
<p>前面的两篇文章基本思路都是为不同的 domain 分配多一个 head
的参数，然后通过不同 head 来描述不同 domain 的差异</p>
<p>提出 LHUC 这篇文章则没有显式地分 head ，而是通过在 hidden layer
上乘上一个 domain-aware embedding，来达到这样的效果：<a
href="https://arxiv.org/abs/1601.02828">Learning Hidden Unit
Contributions for Unsupervised Acoustic Model Adaptation</a></p>
<p>这篇 paper 最早是在 speech 领域提出的一个方法，基本的思路是为每个
speaker 单独调整 nn 中全连接层里部分的参数，从而达到每个 speaker
的个性化预估；总体思路比较直观，也很容易把方法迁移至推荐上</p>
<p>快手的提出的 PEPNet(<a
href="https://arxiv.org/pdf/2302.01115.pdf">Parameter and Embedding
Personalized Network for Infusing with Personalized Prior
Information</a>) 也是借鉴了 LHUC 的这个思想</p>
<p>整个模型结构如下图所示，LHUC 部分是最右边的 PPNet 部分，每个 GateNU
相当于为每个 hidden layer 生成一个 domain-aware 的 embedding，左边的
EPNet 则是相当于为 embedding 不用分生成类似的 embedding</p>
<p><img src="https://wulc.me/imgs/MultiDomainLHUC_PEPNet.jpg" height="50%" width="50%" alt="PEPNet 结构"></p>
<p>Gate NU 可以理解为一个简单两层的 nn
网络，输入是<strong>依靠先验知识挑选的能够区分不同 domain
的特征</strong>，输出则是一个 tensor（维度大小与 hidden layer 一样）</p>
<p><img src="https://wulc.me/imgs/MultiDomainLHUC_GateNU1.jpg" height="40%" width="40%"  alt="Gate NU">
<img src="https://wulc.me/imgs/MultiDomainLHUC_GateNU2.jpg" height="40%" width="40%" alt="Gate NU"></p>
<p>除了结构上的改进，这篇 paper
还做了较多的工程上的有优化，这里不详细展开</p>
<h2 id="grl">GRL</h2>
<p>这里主要想介绍 GRL（Gradient Reversal
Layer）这个机制，这个机制出自论文 <a
href="https://arxiv.org/pdf/1409.7495.pdf">Unsupervised Domain
Adaptation by Backpropagation</a></p>
<p>论文主要想解决的问题是 domain adaption，即在 source domain
有较多数据，target domain 较少数据，怎么能够较好地同时解决两个 domain
的问题，paper 里提到的方案是从特征层面去解决这个问题</p>
<blockquote>
<p>the approach promotes the emergence of “deep” features that are (i)
discriminative for the main learning task on the source domain and (ii)
invariant with respect to the shift between the domains.</p>
</blockquote>
<p>为了达到这个目标，论文提出的 GRL 机制如下图所示</p>
<p><img src="https://wulc.me/imgs/MultiDomainGRL.jpg" height="50%" width="50%" alt="GRL 机制"></p>
<p>从结构上来看，这也是个 multi-head 的结构，但蓝色的 head 是 source
domain 的原始 task，<strong>红色的 head（后面简称为 discriminator）
则是一个 domain classifier，即是用来区分样本是属于哪一个 domain
的</strong></p>
<p>两个 task 在做 bp 时，蓝色的 head 正常回传梯度，discriminator
则在梯度回传到 feature extractor 即图中色绿色部分时，乘上一个 negative
constant，这就是 GRL 的机制</p>
<p>那为什么要这么做呢？paper 给出的解释是这样的，</p>
<blockquote>
<p>we want to make the features <span class="math inline">\(f\)</span>
domain-invariant. That is, <strong>we want to make the distributions
<span class="math inline">\(S(f) = \lbrace G_f(x;\theta_f)|x∼S(x)
\rbrace\)</span> and <span class="math inline">\(T(f) = \lbrace
G_f(x;\theta_f)|x∼T(x) \rbrace\)</span> to be similar</strong>. Under
the covariate shift assumption, this would make the label prediction
accuracy on the target domain to be the same as on the source domain
(Shimodaira, 2000).</p>
</blockquote>
<p>即希望 feature extractor 抽取出来的特征是 domain-invariant、对 domain
不敏感的，或者说<strong>基于抽取出来的特征，discriminator
不能很好地区分样本来自哪个 domain</strong></p>
<p>而如果不加 GRL，正常的 bp 是会 discriminator 能够区分样本来自哪个
domain 的，加了 GRL 后，则能够达到上面提到的“discriminator
不能很好地区分样本来自哪个 domain”</p>
<p>那另一个问题来了，即为什么要在 feature extractor 这一层做，而不是在
<span class="math inline">\(L_d\)</span> 上就加一个负号？</p>
<p>因为<strong>如果直接在 <span class="math inline">\(L_d\)</span>
上加负号，相当于让 discriminator 把它分到错误的那个 domain，但一个好的
feature 应该是让 discriminator 分辨不出它来自哪个
domain，而不是把它分到错误的那个 domain</strong></p>
<p>因此，GRL 机制某种程度上也是一类 feature
engineering，用于提取出适用于多个 domain 的 feature</p>
<h2 id="小结">小结</h2>
<p>综上，本文主要介绍了三种解决 multi-domain 的思路，分别是 multi-head
结构，LHUC 机制和 GRL
机制；据笔者的了解，目前这几种方案在业界都有落地的案例，值得在相应业务中进行尝试~</p>
<p>multi-head 机制比较直观，为每个 domain 分配一个 head，分别学习不同
domain 的分布，MMOE 和 STAR 这一类模型属于这种；LHUC
机制则是根据先验选择一批有区分度的特征，通过一个小的 nn
学习一个隐变量作用到hidden-layer上（其实也能作用到 embedding 上，PEPNet
中没有介绍的 EPNet 就是这部分，原理基本一致）；GRL
则是通过训练方式使得模型抽取出来的 feature 是 domain-invariant
的，训练的思想跟 GAN 的对抗训练比较类似</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>A Tour of Go 摘记</title>
    <url>/2018/11/28/A%20Tour%20of%20Go%20%20%E6%91%98%E8%AE%B0/</url>
    <content><![CDATA[<p>最近在学习 <a href="https://golang.org/">golang</a>，本文主要是 <a
href="https://tour.golang.org/">A Tour of Go</a> 的一些摘记，涵盖了 go
的一些基本语法与数据类型、通过 struct 和 method 实现类的特性、以及 go
中重要的 concurrency 特性。</p>
<span id="more"></span>
<h2 id="basics">Basics</h2>
<h3 id="packages-variables-and-functions">packages, variables and
functions</h3>
<ul>
<li><p>程序的入口在 <code>main</code> 这个 package 中,
需要在文件头声明</p></li>
<li><p><code>import</code> 通过 <code>()</code> 引入多个 package
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;math/rand&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p></li>
<li><p>定义变量的几种形式（定义常量只能用第一种方法，且 var 改成 const)
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 方式 1</span></span><br><span class="line"><span class="keyword">var</span> i, j <span class="type">int</span></span><br><span class="line"><span class="keyword">var</span> i, j <span class="type">int</span> = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line"><span class="keyword">var</span> i, j <span class="type">int</span> = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方式 2</span></span><br><span class="line">i, j := <span class="number">1</span>, <span class="number">2</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>golang 中的变量类型 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span>  <span class="type">int8</span>  <span class="type">int16</span>  <span class="type">int32</span>  <span class="type">int64</span></span><br><span class="line"><span class="type">uint</span> <span class="type">uint8</span> <span class="type">uint16</span> <span class="type">uint32</span> <span class="type">uint64</span> <span class="type">uintptr</span></span><br><span class="line"></span><br><span class="line"><span class="type">byte</span> <span class="comment">// alias for uint8</span></span><br><span class="line"></span><br><span class="line"><span class="type">rune</span> <span class="comment">// alias for int32</span></span><br><span class="line">     <span class="comment">// represents a Unicode code point</span></span><br><span class="line"></span><br><span class="line"><span class="type">float32</span> <span class="type">float64</span></span><br><span class="line"></span><br><span class="line"><span class="type">complex64</span> <span class="type">complex128</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>函数声明时<strong>类型放在最后</strong>：参数类型放在参数后，返回类型放在函数名后;
且连续多个参数类型一样时可只为最后一个写类型，如下
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">add</span><span class="params">(x <span class="type">int</span>, y <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// same as above</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">add</span><span class="params">(x , y <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>函数可返回多个值,
且返回值可以被命名（此时的返回值相当函数里两个命名的变量）
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 多个返回值</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">swap</span><span class="params">(x, y <span class="type">string</span>)</span></span> (<span class="type">string</span>, <span class="type">string</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> y, x</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 具名返回值, 返回 x 和 y</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">split</span><span class="params">(sum <span class="type">int</span>)</span></span> (x, y <span class="type">int</span>) &#123;</span><br><span class="line">    x = sum * <span class="number">4</span> / <span class="number">9</span></span><br><span class="line">    y = sum - x</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>函数可作为参数传入其他函数，也可作为返回值, 如下
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;math&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">compute</span><span class="params">(fn <span class="keyword">func</span>(<span class="type">float64</span>, <span class="type">float64</span>)</span></span> <span class="type">float64</span>) <span class="type">float64</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    hypot := <span class="function"><span class="keyword">func</span><span class="params">(x, y <span class="type">float64</span>)</span></span> <span class="type">float64</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> math.Sqrt(x*x + y*y)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(hypot(<span class="number">5</span>, <span class="number">12</span>))</span><br><span class="line"></span><br><span class="line">    fmt.Println(compute(hypot))</span><br><span class="line">    fmt.Println(compute(math.Pow))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>闭包（一个函数访问并能更新在其函数域外的变量）一般会将函数作为返回值
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fibonacci</span><span class="params">()</span></span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">int</span> &#123;</span><br><span class="line">    a, b := <span class="number">-1</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">int</span> &#123;</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    f := fibonacci()</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">        fmt.Println(f())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="for-if-else-switch-and-defer">for, if else, switch and
defer</h3>
<ul>
<li><p>go 里面没有 while，for 相当于 while</p></li>
<li><p>包含 for 的三个元素的圆括号 <code>()</code> 是没有的(不仅是 for
语句，if else 等其他语句也没有)，且花括号 <code>&#123;&#125;</code>
总是必须的(哪怕只有一条语句) <figure class="highlight go"><table><tr><td class="code"><pre><span class="line">sum := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">    sum += i</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 三个元素的头尾元素可缺省</span></span><br><span class="line">sum := <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> ; sum &lt; <span class="number">1000</span>; &#123;</span><br><span class="line">    sum += sum</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>for 跟 range 结合可以遍历 slice 和 map, 每次返回两个值，对于 map
是 key:value，对于 slice 则是 index:value <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> pow = []<span class="type">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i, v := <span class="keyword">range</span> pow &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;2**%d = %d\n&quot;</span>, i, v)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 不要第一个元素</span></span><br><span class="line">    <span class="keyword">for</span> _, v := <span class="keyword">range</span> pow &#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 不要第二个元素</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="keyword">range</span> pow &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>if 语句的判断条件中可带有一个短的声明语句 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> v := math.Pow(<span class="number">3</span>, <span class="number">5</span>); v &lt; <span class="number">100</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> v</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>switch 语句不需要 break（实际上是go自动添加了）
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;runtime&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Print(<span class="string">&quot;Go runs on &quot;</span>)</span><br><span class="line">    <span class="keyword">switch</span> os := runtime.GOOS; os &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;darwin&quot;</span>:</span><br><span class="line">        fmt.Println(<span class="string">&quot;OS X.&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;linux&quot;</span>:</span><br><span class="line">        fmt.Println(<span class="string">&quot;Linux.&quot;</span>)</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">// freebsd, openbsd,</span></span><br><span class="line">        <span class="comment">// plan9, windows...</span></span><br><span class="line">        fmt.Printf(<span class="string">&quot;%s.&quot;</span>, os)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>defer 后面的语句直到其所在的函数返回才执行, 实际上 defer
后面的语句被 push 到了 stack 中，返回时就出栈 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 输出 hello world</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">defer</span> fmt.Println(<span class="string">&quot;world&quot;</span>)</span><br><span class="line">    fmt.Println(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 9 到 0 输出</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">defer</span> fmt.Println(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="pointer-struct-slice-and-map">pointer, struct, slice and
map</h3>
<ul>
<li><p>go 中的指针跟 C/C++ 中的类似 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    i, j := <span class="number">42</span>, <span class="number">2701</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> p1 *<span class="type">int</span>         </span><br><span class="line">    p1 = &amp;i</span><br><span class="line">    fmt.Println(*p1) <span class="comment">// read i through the pointer</span></span><br><span class="line">    *p1 = <span class="number">21</span>         <span class="comment">// set i through the pointer</span></span><br><span class="line">    fmt.Println(i)  <span class="comment">// see the new value of i</span></span><br><span class="line"></span><br><span class="line">    p2 := &amp;j         <span class="comment">// point to j</span></span><br><span class="line">    *p2 = *p2 / <span class="number">37</span>   <span class="comment">// divide j through the pointer</span></span><br><span class="line">    fmt.Println(j) <span class="comment">// see the new value of j</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>go 中的结构体也跟 C/C++ 的类似，只是声明方式不一样，多了 type
这个关键字，且类型 struct 放在最后 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Vertex <span class="keyword">struct</span> &#123;</span><br><span class="line">    X <span class="type">int</span></span><br><span class="line">    Y <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    v := Vertex&#123;<span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line">    fmt.Println(v.X)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>指向结构体的指针访问结构体的元素的方式跟 C/C++ 不一样，C/C++要用
<code>-&gt;</code>, go 中可直接使用 <code>.</code>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Vertex <span class="keyword">struct</span> &#123;</span><br><span class="line">    X <span class="type">int</span></span><br><span class="line">    Y <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    v := Vertex&#123;<span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line">    p := &amp;v</span><br><span class="line">    p.X = <span class="number">1e9</span></span><br><span class="line">    fmt.Println(v)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>array 与 slice 是两个不同的类型，<strong>区别在于 array
长度固定，slice 长度可变，声明时一个指定长度，一个不指定长度, 语法均是
[]type</strong> <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// array 声明方式一</span></span><br><span class="line">    <span class="keyword">var</span> a [<span class="number">2</span>]<span class="type">string</span></span><br><span class="line">    a[<span class="number">0</span>] = <span class="string">&quot;Hello&quot;</span></span><br><span class="line">    a[<span class="number">1</span>] = <span class="string">&quot;World&quot;</span></span><br><span class="line">    fmt.Println(a[<span class="number">0</span>], a[<span class="number">1</span>])</span><br><span class="line">    fmt.Println(a)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// array 声明方式二</span></span><br><span class="line">    primes := [<span class="number">6</span>]<span class="type">int</span>&#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>&#125;</span><br><span class="line">    fmt.Println(primes)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// slice 声明方式一</span></span><br><span class="line">    s := prime[:<span class="number">4</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// slice 声明方式二</span></span><br><span class="line">    <span class="keyword">var</span> s []<span class="type">int</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// slice 声明方式三</span></span><br><span class="line">    s := []<span class="type">int</span>&#123;<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// slice 声明方式四</span></span><br><span class="line">    s := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">5</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure></p></li>
<li><p>需要注意的是，<strong>每个 slice 都有一个 underlying array，
slice 就是这个 array 的 reference</strong> ，当 slice 被其他 array
的部分元素初始化时，修改 slice 就是在修改这个 array；slice
有两个方法：<code>len()</code> 和 <code>cap()</code>, <code>len()</code>
是 slice 的长度，<code>cap()</code> 则是 slice 对应的 underlying array
从 slice 的第一个元素开始计算的长度 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">printSlice</span><span class="params">(s []<span class="type">string</span>)</span></span> &#123;</span><br><span class="line">    fmt.Printf(<span class="string">&quot;len=%d cap=%d %v\n&quot;</span>, <span class="built_in">len</span>(s), <span class="built_in">cap</span>(s), s)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    names := [<span class="number">4</span>]<span class="type">string</span>&#123;</span><br><span class="line">        <span class="string">&quot;John&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Paul&quot;</span>,</span><br><span class="line">        <span class="string">&quot;George&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Ringo&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(names)</span><br><span class="line"></span><br><span class="line">    a := names[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">    b := names[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">    printSlice(a)</span><br><span class="line">    printSlice(b)</span><br><span class="line">    </span><br><span class="line">    b[<span class="number">0</span>] = <span class="string">&quot;XXX&quot;</span></span><br><span class="line">    fmt.Println(a, b)</span><br><span class="line">    fmt.Println(names)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出如下</span></span><br><span class="line">[John Paul George Ringo]</span><br><span class="line"><span class="built_in">len</span>=<span class="number">2</span> <span class="built_in">cap</span>=<span class="number">4</span> [John Paul]</span><br><span class="line"><span class="built_in">len</span>=<span class="number">2</span> <span class="built_in">cap</span>=<span class="number">3</span> [Paul George]</span><br><span class="line">[John XXX] [XXX George]</span><br><span class="line">[John XXX George Ringo]</span><br></pre></td></tr></table></figure></p></li>
<li><p>slice 是可变长的，通过 append 函数往 slice 末尾添加元素，如下
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> s []<span class="type">int</span></span><br><span class="line">    printSlice(s)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// The slice grows as needed.</span></span><br><span class="line">    s = <span class="built_in">append</span>(s, <span class="number">1</span>)</span><br><span class="line">    printSlice(s)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// We can add more than one element at a time.</span></span><br><span class="line">    s = <span class="built_in">append</span>(s, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">    printSlice(s)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>map 初始化方式有以下几种, map 声明的中括号里面是 key
的类型，外面是 value的类型，即 <code>map[key]value</code>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// method 1</span></span><br><span class="line">m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// method 2</span></span><br><span class="line"><span class="keyword">var</span> m = <span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span>&#123;<span class="number">1</span>:<span class="number">1</span>, <span class="number">2</span>:<span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>删除 map 中某个元素可直接使用
<code>delete (map, key)</code></p></li>
<li><p>测试某个 key 是否在 map 中可通过 <code>map[key]</code>
返回一个两元组实现，即<code>elem, ok := m[key]</code>, 如果 ok 为
true，则表示 key 里面</p></li>
</ul>
<h2 id="methods-and-interfaces">Methods and interfaces</h2>
<ul>
<li><p>go 没有提供类，但是可以通过为 struct 定义 method
来提供类相近的特性；method 就是在普通函数基础上定义一个 receiver
参数（定义在 <code>func</code> 和函数名之间），表明这个方法是属于某个
struct 的 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Vertex <span class="keyword">struct</span> &#123;</span><br><span class="line">    X, Y <span class="type">float64</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v1 Vertex)</span></span> Abs() <span class="type">float64</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> math.Sqrt(v1.X*v1.X + v1.Y*v1.Y)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    v := Vertex&#123;<span class="number">3</span>, <span class="number">4</span>&#125;</span><br><span class="line">    fmt.Println(v.Abs())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>reveiver 参数也可以是指针类型，这意味着通过 receiver
参数能够直接修改 struct
的值(函数的普通参数也是需要指针才能修改实参的值)， 同时也不用在调用
method 时创建新的内存来存储临时对象，因此指针类型的 receiver 也更加常用
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Vertex <span class="keyword">struct</span> &#123;</span><br><span class="line">    X, Y <span class="type">float64</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v Vertex)</span></span> Abs() <span class="type">float64</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> math.Sqrt(v.X*v.X + v.Y*v.Y)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(v *Vertex)</span></span> Scale(f <span class="type">float64</span>) &#123;</span><br><span class="line">    v.X = v.X * f</span><br><span class="line">    v.Y = v.Y * f</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    v := Vertex&#123;<span class="number">3</span>, <span class="number">4</span>&#125;</span><br><span class="line">    v.Scale(<span class="number">10</span>) <span class="comment">// equal to (&amp;v).Scale(10)</span></span><br><span class="line">    fmt.Println(v.Abs())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>go 中的接口（interface) 概念与
Java中的类似，声明一系列的方法，实现了这些方法就是实现了这个接口(无需显式声明）
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> I <span class="keyword">interface</span> &#123;</span><br><span class="line">    M()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> T <span class="keyword">struct</span> &#123;</span><br><span class="line">    S <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// This method means type T implements the interface I,</span></span><br><span class="line"><span class="comment">// but we don&#x27;t need to explicitly declare that it does so.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t T)</span></span> M() &#123;</span><br><span class="line">    fmt.Println(t.S)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> i I = T&#123;<span class="string">&quot;hello&quot;</span>&#125;</span><br><span class="line">    i.M()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>一个非常普遍的 interface 是 <code>Stringer</code>, 这是由
<code>fmt</code> 这个 package 中定义的，一旦实现过了这个接口里面的
<code>String() string</code> 方法, <code>fmt.Println()</code>
时就会调用这个方法 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Stringer <span class="keyword">interface</span> &#123;</span><br><span class="line">    String() <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">    Name <span class="type">string</span></span><br><span class="line">    Age  <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p Person)</span></span> String() <span class="type">string</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;%v (%v years)&quot;</span>, p.Name, p.Age)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    a := Person&#123;<span class="string">&quot;Arthur Dent&quot;</span>, <span class="number">42</span>&#125;</span><br><span class="line">    z := Person&#123;<span class="string">&quot;Zaphod Beeblebrox&quot;</span>, <span class="number">9001</span>&#125;</span><br><span class="line">    fmt.Println(a, z)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出</span></span><br><span class="line">Arthur Dent (<span class="number">42</span> years) Zaphod Beeblebrox (<span class="number">9001</span> years)</span><br></pre></td></tr></table></figure></p></li>
<li><p>类似于上面的接口 <code>fmt.Stringer</code>, <code>error</code>
也是一个常用的接口，实现该接口需要实现 <code>Error</code> 方法
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyError <span class="keyword">struct</span> &#123;</span><br><span class="line">    When time.Time</span><br><span class="line">    What <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *MyError)</span></span> Error() <span class="type">string</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;at %v, %s&quot;</span>,</span><br><span class="line">        e.When, e.What)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">run</span><span class="params">()</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;MyError&#123;</span><br><span class="line">        time.Now(),</span><br><span class="line">        <span class="string">&quot;it didn&#x27;t work&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err := run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>go 的很多标准库都实现了 <code>io.Reader</code>
这个接口，接口主要定义了这个方法
<code>func (T) Read(b []byte) (n int, err error)</code>,
如下是一个简单地用法，每次从 string 中读取 8 个 byte
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;io&quot;</span></span><br><span class="line">    <span class="string">&quot;strings&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    r := strings.NewReader(<span class="string">&quot;Hello, Reader!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    b := <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="number">8</span>)</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        n, err := r.Read(b)</span><br><span class="line">        fmt.Printf(<span class="string">&quot;n = %v err = %v b = %v\n&quot;</span>, n, err, b)</span><br><span class="line">        fmt.Printf(<span class="string">&quot;b[:n] = %q\n&quot;</span>, b[:n])</span><br><span class="line">        <span class="keyword">if</span> err == io.EOF &#123;</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="concurrency">Concurrency</h2>
<ul>
<li><p>goroutine 相当于是轻量级的线程，使用方法很简单
<code>go f()</code> 就启动了一个 goroutine 来执行函数
<code>f()</code></p></li>
<li><p>channel
类似于一个队列，但是出列时要等到所有入列的操作已完成则可进行，反之亦然，这就为
goroutine 提供了 synchronize 的功能 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>) <span class="comment">// create a channel of type int</span></span><br><span class="line">ch &lt;- v    <span class="comment">// Send v to channel ch.</span></span><br><span class="line">v := &lt;-ch  <span class="comment">// Receive from ch, and assign value to v.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// simple example</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sum</span><span class="params">(s []<span class="type">int</span>, c <span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    sum := <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> _, v := <span class="keyword">range</span> s &#123;</span><br><span class="line">        sum += v</span><br><span class="line">    &#125;</span><br><span class="line">    c &lt;- sum <span class="comment">// send sum to c</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    s := []<span class="type">int</span>&#123;<span class="number">7</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">-9</span>, <span class="number">4</span>, <span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line">    <span class="keyword">go</span> sum(s[:<span class="built_in">len</span>(s)/<span class="number">2</span>], c)</span><br><span class="line">    <span class="keyword">go</span> sum(s[<span class="built_in">len</span>(s)/<span class="number">2</span>:], c)</span><br><span class="line">    x, y := &lt;-c, &lt;-c <span class="comment">// receive from c</span></span><br><span class="line"></span><br><span class="line">    fmt.Println(x, y, x+y)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// output </span></span><br><span class="line"><span class="number">-5</span> <span class="number">17</span> <span class="number">12</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>Buffered channel：可以为 channel
指定长度(如<code>chan := make(chan int, 100)</code>)，这样当 channel
满了之后不能再往其中写数据（再写会报错），这种 channel 也被称为 buffered
channel；也可以 <code>close</code> 一个 channel，
这样也不能继续入列</p></li>
<li><p>通过 <code>range</code> 来遍历 channel 会自动判断 channel
是否已经为空，即 <code>for v := range channel</code>,
需要注意的是，<strong>用 for 来遍历一个 channel 时，该 channel 必须要先
<code>close</code>，否则会出现错误 fatal error: all goroutines are
asleep - deadlock!</strong></p></li>
<li><p><code>select</code> 包含的代码块中有多个 <code>case</code>
语句，当其中的任一条件被满足时才会执行，否则会阻塞（可以添加
<code>default</code> 选项使得 <code>select</code>
不会被阻塞），当有多个被满足时则随机选一个；通常 <code>select</code>
也被用来协调多个 goroutine 的通信, 如下 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fibonacci</span><span class="params">(c, quit <span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    x, y := <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> c &lt;- x:</span><br><span class="line">            x, y = y, x+y</span><br><span class="line">        <span class="keyword">case</span> &lt;-quit:</span><br><span class="line">            fmt.Println(<span class="string">&quot;quit&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line">    quit := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">            fmt.Println(&lt;-c)</span><br><span class="line">        &#125;</span><br><span class="line">        quit &lt;- <span class="number">0</span></span><br><span class="line">    &#125;()</span><br><span class="line">    fibonacci(c, quit)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>channel 是 goroutine 通信的一个有效工具，但是除了通信，多个
goroutine 往往还会存在着同时读写一个变量的情况，这时候就要加锁，os
中也将这样的锁机制成为互斥量（mutex），go 的 <code>sync.Mutex</code>
就是一个能够实现加锁和解锁的互斥量;如下是多个 goroutine 共享一个 Counter
的例子 <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;sync&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// SafeCounter is safe to use concurrently.</span></span><br><span class="line"><span class="keyword">type</span> SafeCounter <span class="keyword">struct</span> &#123;</span><br><span class="line">    v   <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span></span><br><span class="line">    mux sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Inc increments the counter for the given key.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *SafeCounter)</span></span> Inc(key <span class="type">string</span>) &#123;</span><br><span class="line">    c.mux.Lock()</span><br><span class="line">    <span class="comment">// Lock so only one goroutine at a time can access the map c.v.</span></span><br><span class="line">    c.v[key]++</span><br><span class="line">    c.mux.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Value returns the current value of the counter for the given key.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *SafeCounter)</span></span> Value(key <span class="type">string</span>) <span class="type">int</span> &#123;</span><br><span class="line">    c.mux.Lock()</span><br><span class="line">    <span class="comment">// Lock so only one goroutine at a time can access the map c.v.</span></span><br><span class="line">    <span class="keyword">defer</span> c.mux.Unlock()</span><br><span class="line">    <span class="keyword">return</span> c.v[key]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := SafeCounter&#123;v: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span>)&#125;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;</span><br><span class="line">        <span class="keyword">go</span> c.Inc(<span class="string">&quot;somekey&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    time.Sleep(time.Second)</span><br><span class="line">    fmt.Println(c.Value(<span class="string">&quot;somekey&quot;</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Adam那么棒，为什么还对SGD念念不忘</title>
    <url>/2019/03/18/Adam%E9%82%A3%E4%B9%88%E6%A3%92%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E5%AF%B9SGD%E5%BF%B5%E5%BF%B5%E4%B8%8D%E5%BF%98/</url>
    <content><![CDATA[<p>好久没更新了，最近在忙着写毕业论文，刚好写到与优化相关部分，想起了之前在知乎上收藏过的一篇很好的文章，重新看一遍还是觉得获益良多，特意转载。原文链接见<a
href="https://zhuanlan.zhihu.com/p/32230623">这里</a>，侵删。</p>
<span id="more"></span>
<p>机器学习界有一群炼丹师，他们每天的日常是：</p>
<p>拿来药材（数据），架起八卦炉（模型），点着六味真火（优化算法），就摇着蒲扇等着丹药出炉了。</p>
<p>不过，当过厨子的都知道，同样的食材，同样的菜谱，但火候不一样了，这出来的口味可是千差万别。火小了夹生，火大了易糊，火不匀则半生半糊。</p>
<p>机器学习也是一样，模型优化算法的选择直接关系到最终模型的性能。有时候效果不好，未必是特征的问题或者模型设计的问题，很可能就是优化算法的问题。(注：笔者有过亲身经历，曾经使用
Adam 一开局就陷入局部最优，检查了好多遍代码，最后近乎绝望地换了 SGD
，然后效果蹭蹭蹭上升)</p>
<p>说到优化算法，入门级必从 SGD
学起，老司机则会告诉你更好的还有AdaGrad/AdaDelta，或者直接无脑用
Adam。可是看看学术界的最新 paper，却发现一众大神还在用着入门级的
SGD，最多加个 Momentum 或者 Nesterov ，还经常会黑一下Adam。比如 UC
Berkeley的一篇论文就在Conclusion中写道(注：这篇论文是<a
href="https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning">The
Marginal Value of Adaptive Gradient Methods in Machine Learning</a>)</p>
<blockquote>
<p>Despite the fact that our experimental evidence demonstrates that
adaptive methods are not advantageous for machine learning, the Adam
algorithm remains incredibly popular. We are not sure exactly as to why
……</p>
</blockquote>
<p>无奈与酸楚之情溢于言表。</p>
<p>这是为什么呢？难道平平淡淡才是真？</p>
<h2 id="一个框架回顾优化算法">一个框架回顾优化算法</h2>
<p>首先我们来回顾一下各类优化算法。</p>
<p>深度学习优化算法经历了 <strong>SGD -&gt; SGDM -&gt; NAG -&gt;AdaGrad
-&gt; AdaDelta -&gt; Adam -&gt; Nadam</strong>
这样的发展历程。Google一下就可以看到很多的教程文章，详细告诉你这些算法是如何一步一步演变而来的。在这里，我们换一个思路，用一个框架来梳理所有的优化算法，做一个更加高屋建瓴的对比。</p>
<p>首先定义：待优化参数： <span class="math inline">\(w\)</span>
，目标函数： <span class="math inline">\(f(w)\)</span> ，初始学习率
<span class="math inline">\(\alpha\)</span></p>
<p>而后，开始进行迭代优化。在每个 epoch <span
class="math inline">\(t\)</span>, 执行如下操作：</p>
<ol type="1">
<li>计算目标函数关于当前参数的梯度： <span
class="math inline">\(g\_t=\nabla f(w\_t)\)</span></li>
<li>根据历史梯度计算一阶动量和二阶动量：<span class="math inline">\(m\_t
= \phi(g\_1, g\_2, \cdots, g\_t)\)</span>; <span
class="math inline">\(V\_t = \psi(g\_1, g\_2, \cdots,
g\_t)\)</span></li>
<li>计算当前时刻的下降梯度： <span class="math inline">\(\eta\_t =
\alpha \cdot m\_t / \sqrt{V\_t}\)</span></li>
<li>根据下降梯度进行更新： <span class="math inline">\(w\_{t+1} = w\_t -
\eta\_t\)</span></li>
</ol>
<p>掌握了这个框架，你可以轻轻松松设计自己的优化算法。</p>
<p>我们拿着这个框架，来照一照各种玄乎其玄的优化算法的真身。<strong>步骤3、4对于各个算法都是一致的，主要的差别就体现在1和2上。</strong></p>
<h3 id="sgd">SGD</h3>
<p>先来看SGD, SGD没有动量的概念，也就是说：</p>
<p><span class="math inline">\(m\_t = g\_t\)</span> <span
class="math inline">\(V\_t = I^2\)</span></p>
<p>代入步骤3，可以看到下降梯度就是最简单的</p>
<p><span class="math inline">\(\eta\_t = \alpha \cdot g\_t\)</span></p>
<p><strong>SGD最大的缺点是下降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点。</strong></p>
<h3 id="sgd-with-momentum">SGD with Momentum</h3>
<p>为了抑制 SGD 的震荡，SGDM
认为梯度下降过程可以加入惯性。下坡的时候，如果发现是陡坡，那就利用惯性跑的快一些。SGDM
全称是SGD with
momentum，<strong>在SGD基础上引入了一阶动量</strong>：</p>
<p><span class="math inline">\(m\_t = \beta\_1 \cdot m\_{t-1} +
(1-\beta\_1)\cdot g\_t\)</span></p>
<p>一阶动量是各个时刻梯度方向的<strong>指数移动平均值</strong>，约等于最近
<span class="math inline">\(1/(1-\beta\_1)\)</span>
个时刻的梯度向量和的平均值。</p>
<p>也就是说，t时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。
<strong><span class="math inline">\(\beta\_1\)</span>
的经验值为0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向。想象高速公路上汽车转弯，在高速向前的同时略微偏向，急转弯可是要出事的。</strong></p>
<h3 id="sgd-with-nesterov-acceleration">SGD with Nesterov
Acceleration</h3>
<p>SGD
还有一个问题是困在局部最优的沟壑里面震荡。想象一下你走到一个盆地，四周都是略高的小山，你觉得没有下坡的方向，那就只能待在这里了。可是如果你爬上高地，就会发现外面的世界还很广阔。因此，我们不能停留在当前位置去观察未来的方向，而要向前一步、多看一步、看远一些。</p>
<p>NAG 全称 Nesterov Accelerated Gradient，是在 SGD、SGD-M
的基础上的进一步改进，改进点在于步骤1。我们知道在时刻 t
的主要下降方向是由累积动量决定的，自己的梯度方向说了也不算，那与其看当前梯度方向，不如先看看如果跟着累积动量走了一步，那个时候再怎么走。因此，<strong>NAG在步骤
1，不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向</strong>：</p>
<p><span class="math inline">\(g\_t=\nabla f(w\_t-\alpha \cdot m\_{t-1}
/ \sqrt{V\_{t-1}})\)</span></p>
<p>然后用下一个点的梯度方向，与历史累积动量相结合，计算步骤2中当前时刻的累积动量。</p>
<h3 id="adagrad">AdaGrad</h3>
<p>此前我们都没有用到二阶动量。<strong>二阶动量的出现，才意味着“自适应学习率”优化算法时代的到来</strong>。SGD
及其变种以同样的学习率更新每个参数，但深度神经网络往往包含大量的参数，这些参数并不是总会用得到（想想大规模的embedding）。<strong>对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。</strong></p>
<p>怎么样去<strong>度量历史更新频率</strong>呢？那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：</p>
<p><span class="math inline">\(V\_t = \sum\_{\tau=1}^{t}
g\_\tau^2\)</span></p>
<p>我们再回顾一下步骤3中的下降梯度：</p>
<p><span class="math inline">\(\eta\_t = \alpha \cdot m\_t /
\sqrt{V\_t}\)</span></p>
<p>可以看出，此时实质上的学习率由 <span
class="math inline">\(\alpha\)</span> 变成了 <span
class="math inline">\(\alpha / \sqrt{V\_t}\)</span> 。
一般为了避免分母为0，会在分母上加一个小的平滑项。因此 <span
class="math inline">\(\sqrt{V\_t}\)</span>
是恒大于0的，而且<strong>参数更新越频繁，二阶动量越大，学习率就越小</strong>。</p>
<p>这一方法在<strong>稀疏数据场景下表现非常好</strong>。但也存在一些问题：因为
<span class="math inline">\(\sqrt{V\_t}\)</span>
是单调递增的，会使得学习率单调递减至0，可能会使得训练过程提前结束，即便后续还有数据也无法学到必要的知识。</p>
<h3 id="adadelta-rmsprop">AdaDelta / RMSProp</h3>
<p>由于 AdaGrad
单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：<strong>不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是
AdaDelta 名称中 Delta 的来历</strong>。</p>
<p>修改的思路很简单。前面我们讲到，<strong>指数移动平均值大约就是过去一段时间的平均值</strong>，因此我们用这一方法来计算二阶累积动量：</p>
<p><span class="math inline">\(V\_t = \beta\_2 * V\_{t-1} + (1-\beta\_2)
g\_t^2\)</span></p>
<p>这就避免了二阶动量持续累积、导致训练过程提前结束的问题了。</p>
<h3 id="adam">Adam</h3>
<p>谈到这里，Adam 和 Nadam
的出现就很自然而然了——它们是前述方法的集大成者。我们看到，SGD-M 在 SGD
基础上增加了一阶动量，AdaGrad 和 AdaDelta 在 SGD
基础上增加了二阶动量。<strong>把一阶动量和二阶动量都用起来，就是
Adam了——Adaptive + Momentum</strong>。</p>
<p>SGD的一阶动量：</p>
<p><span class="math inline">\(m\_t = \beta\_1 \cdot m\_{t-1} +
(1-\beta\_1)\cdot g\_t\)</span></p>
<p>加上AdaDelta的二阶动量：</p>
<p><span class="math inline">\(V\_t = \beta\_2 * V\_{t-1} + (1-\beta\_2)
g\_t^2\)</span></p>
<p>优化算法里最常见的两个超参数 <span
class="math inline">\(\beta\_1\)</span>, <span
class="math inline">\(\beta\_2\)</span>
就都在这里了，前者控制一阶动量，后者控制二阶动量。</p>
<h3 id="nadam">Nadam</h3>
<p>最后是Nadam。我们说Adam是集大成者，但它居然遗漏了Nesterov，这还能忍？必须给它加上，按照NAG的步骤1：</p>
<p><span class="math inline">\(g\_t=\nabla f(w\_t-\alpha \cdot m\_{t-1}
/ \sqrt{V\_t})\)</span></p>
<p>这就是Nesterov + Adam = Nadam了。</p>
<p>说到这里，大概可以理解为什么j经常有人说 Adam / Nadam
目前最主流、最好用的优化算法了。新手上路，先拿来一试，收敛速度嗖嗖滴，效果也是杠杠滴。</p>
<p>那为什么Adam还老招人黑，被学术界一顿鄙夷？难道只是为了发paper灌水吗？</p>
<h2 id="adam的两宗罪">Adam的两宗罪</h2>
<p>从理论上看，一代更比一代完善，Adam/Nadam
已经登峰造极了，为什么大家还是不忘初心SGD呢？</p>
<p>举个栗子。很多年以前，摄影离普罗大众非常遥远。十年前，傻瓜相机开始风靡，游客几乎人手一个。智能手机出现以后，摄影更是走进千家万户，手机随手一拍，前后两千万，照亮你的美（咦，这是什么乱七八糟的）。但是专业摄影师还是喜欢用单反，孜孜不倦地调光圈、快门、ISO、白平衡……一堆自拍党从不
care
的名词。技术的进步，使得傻瓜式操作就可以得到不错的效果，但是在特定的场景下，要拍出最好的效果，依然需要深入地理解光线、理解结构、理解器材。</p>
<p>优化算法大抵也如此。在上一篇中，我们用同一个框架让各类算法对号入座。可以看出，大家都是殊途同归，只是相当于在SGD基础上增加了各类学习率的主动控制。如果不想做精细的调优，那么Adam显然最便于直接拿来上手。</p>
<p>但这样的傻瓜式操作并不一定能够适应所有的场合。如果能够深入了解数据，研究员们可以更加自如地控制优化迭代的各类参数，实现更好的效果也并不奇怪。毕竟，精调的参数还比不过傻瓜式的Adam，无疑是在挑战顶级研究员们的炼丹经验！</p>
<h3 id="adam罪状一可能不收敛">Adam罪状一：可能不收敛</h3>
<p>这篇是正在深度学习领域顶级会议之一 ICLR 2018 匿名审稿中的 <a
href="https://openreview.net/forum?id=ryQu7f-RZ">On the Convergence of
Adam and
Beyond</a>，探讨了Adam算法的收敛性，通过反例证明了Adam在某些情况下可能会不收敛。(注:
这篇论文已经成了 2018 ICLR 最佳论文)</p>
<p>回忆一下上文提到的各大优化算法的学习率：</p>
<p><span class="math inline">\(\eta\_t = \alpha /
\sqrt{V\_t}\)</span></p>
<p>其中，SGD
没有用到二阶动量，因此学习率是恒定的（实际使用过程中会采用学习率衰减策略，因此学习率递减）。AdaGrad
的二阶动量不断累积，单调递增，因此学习率是单调递减的。因此，这两类算法会使得学习率不断递减，最终收敛到0，模型也得以收敛。</p>
<p>但 AdaDelta 和 Adam
则不然。二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得
<span class="math inline">\(V\_t\)</span>
可能会时大时小，不是单调变化。这就<strong>可能在训练后期引起学习率的震荡，导致模型无法收敛。</strong></p>
<p>这篇文章也给出了一个修正的方法。由于Adam中的学习率主要是由二阶动量控制的，为了保证算法的收敛，可以<strong>对二阶动量的变化进行控制，避免上下波动。</strong></p>
<p><span class="math inline">\(V\_t = max(\beta\_2 * V\_{t-1} +
(1-\beta\_2) g\_t^2, V\_{t-1})\)</span></p>
<p>通过这样修改，就保证了 <span class="math inline">\(||V\_t|| \geq
||V\_{t-1}||\)</span> ，从而使得<strong>学习率单调递减</strong>。</p>
<h3
id="adam罪状二可能错过全局最优解">Adam罪状二：可能错过全局最优解</h3>
<p>深度神经网络往往包含大量的参数，在这样一个维度极高的空间内，非凸的目标函数往往起起伏伏，拥有无数个高地和洼地。有的是高峰，通过引入动量可能很容易越过；但有些是高原，可能探索很多次都出不来，于是停止了训练。</p>
<p>近期Arxiv上的两篇文章谈到这个问题。</p>
<p>第一篇就是前文提到的吐槽 Adam 最狠的 The Marginal Value of Adaptive
Gradient Methods in Machine Learning
。文中说到，同样的一个优化问题，不同的优化算法可能会找到不同的答案，但自适应学习率的算法往往找到非常差的答案。他们通过一个特定的数据例子说明，<strong>自适应学习率算法可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果。</strong></p>
<p>另外一篇是 <a href="https://arxiv.org/abs/1712.07628">Improving
Generalization Performance by Switching from Adam to
SGD</a>，进行了实验验证。他们 CIFAR-10 数据集上进行测试，<strong>Adam
的收敛速度比 SGD
要快，但最终收敛的结果并没有SGD好。他们进一步实验发现，主要是后期 Adam
的学习率太低，影响了有效的收敛。他们试着对Adam的学习率的下界进行控制，发现效果好了很多。</strong></p>
<p>于是他们提出了一个用来改进Adam的方法：<strong>前期用Adam，享受Adam快速收敛的优势；后期切换到SGD，慢慢寻找最优解。</strong>这一方法以前也被研究者们用到，不过主要是根据经验来选择切换的时机和切换后的学习率。这篇文章把这一切换过程傻瓜化，给出了切换SGD的时机选择方法，以及学习率的计算方法，效果看起来也不错。</p>
<h3 id="到底该用adam还是sgd">到底该用Adam还是SGD？</h3>
<p>所以，谈到现在，到底Adam好还是SGD好？这可能是很难一句话说清楚的事情。去看学术会议中的各种paper，用SGD的很多，Adam的也不少，还有很多偏爱AdaGrad或者AdaDelta。可能研究员把每个算法都试了一遍，哪个出来的效果好就用哪个了。</p>
<p><strong>而从这几篇怒怼 Adam 的 paper
来看，多数都构造了一些比较极端的例子来演示了 Adam
失效的可能性。这些例子一般过于极端，实际情况中可能未必会这样，但这提醒了我们，理解数据对于设计算法的必要性。</strong>优化算法的演变历史，都是基于对数据的某种假设而进行的优化，那么某种算法是否有效，就要看你的数据是否符合该算法的胃口了。</p>
<p><strong>算法固然美好，数据才是根本。</strong></p>
<p>另一方面，Adam之流虽然说已经简化了调参，但是并没有一劳永逸地解决问题，默认参数虽然好，但也不是放之四海而皆准。因此，<strong>在充分理解数据的基础上，依然需要根据数据特性、算法特性进行充分的调参实验，找到自己炼丹的最优解。而这个时候，不论是Adam，还是SGD，于你都不重要了。</strong></p>
<p>少年，好好炼丹吧。</p>
<h2 id="优化算法的选择与使用策略">优化算法的选择与使用策略</h2>
<p>在前面两节中，我们用一个框架梳理了各大优化算法，并且指出了以Adam为代表的自适应学习率优化算法可能存在的问题。那么，在实践中我们应该如何选择呢？本文介绍Adam+SGD的组合策略，以及一些比较有用的tricks.</p>
<h3 id="不同优化算法的核心差异">不同优化算法的核心差异</h3>
<p>下降方向从第一篇的框架中我们看到，不同优化算法最核心的区别，就是第三步所执行的下降方向</p>
<p><span class="math inline">\(\eta\_t = (\alpha/ \sqrt{V\_t} ) \cdot
m\_t\)</span></p>
<p>这个式子中，前半部分是实际的学习率（也即下降步长），后半部分是实际的下降方向。<strong>SGD
算法的下降方向就是该位置的梯度方向的反方向，带一阶动量的SGD的下降方向则是该位置的一阶动量方向。自适应学习率类优化算法为每个参数设定了不同的学习率，在不同维度上设定不同步长，因此其下降方向是缩放过（scaled）的一阶动量方向。</strong></p>
<p><strong>由于下降方向的不同，可能导致不同算法到达完全不同的局部最优点。</strong>
<a href="https://arxiv.org/abs/1612.04010">An empirical analysis of the
optimization of deep network loss surfaces</a>
这篇论文中做了一个有趣的实验，他们把目标函数值和相应的参数形成的超平面映射到一个三维空间，这样我们可以直观地看到各个算法是如何寻找超平面上的最低点的。</p>
<figure>
<img src="https://wulc.me/imgs/optimizer_visulization.jpg"
alt="optimizer_compare" />
<figcaption aria-hidden="true">optimizer_compare</figcaption>
</figure>
<p>上图是论文的实验结果，横纵坐标表示降维后的特征空间，区域颜色则表示目标函数值的变化，红色是高原，蓝色是洼地。他们做的是配对儿实验，让两个算法从同一个初始化位置开始出发，然后对比优化的结果。可以看到，几乎任何两个算法都走到了不同的洼地，他们中间往往隔了一个很高的高原。这就说明，<strong>不同算法在高原的时候，选择了不同的下降方向。</strong></p>
<h3 id="adamsgd-组合策略">Adam+SGD 组合策略</h3>
<p>正是在每一个十字路口的选择，决定了你的归宿。如果上天能够给我一个再来一次的机会，我会对那个女孩子说：SGD！</p>
<p>不同优化算法的优劣依然是未有定论的争议话题。据我在paper和各类社区看到的反馈，主流的观点认为：<strong>Adam等自适应学习率算法对于稀疏数据具有优势，且收敛速度很快；但精调参数的SGD（+Momentum）往往能够取得更好的最终结果。</strong></p>
<p>那么我们就会想到，可不可以把这两者结合起来，先用Adam快速下降，再用SGD调优，一举两得？思路简单，但里面有两个技术问题：</p>
<ol type="1">
<li><strong>什么时候切换优化算法？</strong>——如果切换太晚，Adam可能已经跑到自己的盆地里去了，SGD再怎么好也跑不出来了。</li>
<li><strong>切换算法以后用什么样的学习率？</strong>——Adam用的是自适应学习率，依赖的是二阶动量的累积，SGD接着训练的话，用什么样的学习率？</li>
</ol>
<p>上一篇中提到的论文 Improving Generalization Performance by Switching
from Adam to SGD 提出了解决这两个问题的思路</p>
<p>首先来看第二个问题，切换之后用什么样的学习率。Adam的下降方向是</p>
<p><span class="math inline">\(\eta\_t^{Adam} = (\alpha/ \sqrt{V\_t} )
\cdot m\_t\)</span></p>
<p>而 SGD 的下降方向是</p>
<p><span class="math inline">\(\eta\_t^{SGD} = \alpha^{SGD} \cdot
g\_t\)</span></p>
<p><span class="math inline">\(\eta\_t^{SGD}\)</span> 必定可以分解为
<span class="math inline">\(\eta\_t^{Adam}\)</span>
所在方向及其正交方向上的两个方向之和，如下图所示，这里p为Adam下降方向，g为梯度方向，r为SGD的学习率。</p>
<figure>
<img src="https://wulc.me/imgs/adam_to_sgd_direction.jpg"
alt="adam_to_sgd_direction" />
<figcaption aria-hidden="true">adam_to_sgd_direction</figcaption>
</figure>
<p>那么其在 <span class="math inline">\(\eta\_t^{Adam}\)</span>
方向上的投影就意味着 SGD 在 Adam 算法决定的下降方向上前进的距离，而在
<span class="math inline">\(\eta\_t^{Adam}\)</span> 的正交方向上的投影是
SGD 在自己选择的修正方向上前进的距离。</p>
<p>如果SGD要走完Adam未走完的路，那就首先要接过Adam的大旗——沿着 <span
class="math inline">\(\eta\_t^{Adam}\)</span>
方向走一步，而后在沿着其正交方向走相应的一步。</p>
<p>这样我们就知道该如何确定SGD的步长（学习率）了——<strong>SGD在Adam下降方向上的正交投影，应该正好等于Adam的下降方向（含步长）</strong>。也即：</p>
<p><span class="math inline">\(proj\_{\eta\_t^{SGD}} =
\eta\_t^{Adam}\)</span></p>
<p>解这个方程，我们就可以得到接续进行SGD的学习率：</p>
<p><span class="math inline">\(\alpha\_t^{SGD} =
((\eta\_t^{Adam})^T\eta\_t^{Adam})/((\eta\_t^{Adam})^Tg\_t)\)</span></p>
<p>为了减少噪声影响，作者使用移动平均值来修正对学习率的估计：</p>
<p><span class="math inline">\(\lambda\_t^{SGD} = \beta\_2 \cdot
\lambda\_{t-1}^{SGD}+(1-\beta\_2) \cdot \alpha\_t^{SGD}\)</span></p>
<p><span
class="math inline">\(\tilde{\lambda}\_t^{SGD}=\lambda\_t^{SGD}/(1-\beta\_2^t)\)</span></p>
<p>这里直接复用了Adam的 <span class="math inline">\(\beta\_2\)</span>
参数。</p>
<p>然后来看第一个问题，<strong>何时进行算法的切换</strong>。</p>
<p>作者的回答也很简单，那就是<strong>当 SGD
的相应学习率的移动平均值基本不变的时候</strong>，即：</p>
<p><span class="math inline">\(|\tilde{\lambda}\_t^{SGD} -
\alpha\_t^{SGD}|&lt;\epsilon\)</span>.
每次迭代玩都计算一下SGD接班人的相应学习率，如果发现基本稳定了，那就 SGD
以 <span class="math inline">\(\tilde{\lambda}\_t^{SGD}\)</span>
为学习率接班前进。</p>
<h3 id="优化算法的常用tricks">优化算法的常用tricks</h3>
<p>最后，分享一些在优化算法的选择和使用方面的一些tricks。</p>
<ol type="1">
<li><p><strong>首先，各大算法孰优孰劣并无定论</strong>。如果是刚入门，<strong>优先考虑
SGD+Nesterov Momentum 或者 Adam</strong>.（<a
href="http://cs231n.github.io/neural-networks-3/">Standford 231n</a> :
The two recommended updates to use are either SGD+Nesterov Momentum or
Adam）</p></li>
<li><p><strong>选择你熟悉的算法</strong>——这样你可以更加熟练地利用你的经验进行调参</p></li>
<li><p><strong>充分了解你的数据</strong>——如果数据是非常稀疏的，那么优先考虑自适应学习率的算法。</p></li>
<li><p><strong>根据你的需求来选择</strong>——在模型设计实验过程中，要快速验证新模型的效果，可以先用Adam进行快速实验优化；在模型上线或者结果发布前，可以用精调的SGD进行模型的极致优化。</p></li>
<li><p><strong>先用小数据集进行实验</strong>。论文 <a
href="https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf">Stochastic
Gradient Descent Tricks</a>
指出，随机梯度下降算法的收敛速度和数据集的大小的关系不大。因此可以先用一个具有代表性的小数据集进行实验，测试一下最好的优化算法，并通过参数搜索来寻找最优的训练参数。</p></li>
<li><p><strong>考虑不同算法的组合</strong>。先用Adam进行快速下降，而后再换到
SGD 进行充分的调优。切换策略可以参考本文介绍的方法。</p></li>
<li><p><strong>数据集一定要充分的打散（shuffle）</strong>。这样在使用自适应学习率算法的时候，可以<strong>避免某些特征集中出现，而导致的有时学习过度、有时学习不足，使得下降方向出现偏差的问题</strong>。</p></li>
<li><p>训练过程中<strong>持续监控训练数据和验证数据</strong>上的目标函数值以及精度或者
AUC
等指标的变化情况。<strong>对训练数据的监控是要保证模型进行了充分的训练——下降方向正确，且学习率足够高；对验证数据的监控是为了避免出现过拟合</strong>。</p></li>
<li><p><strong>制定一个合适的学习率衰减策略</strong>。可以使用定期衰减策略，比如每过多少个
epoch 就衰减一次；或者利用精度或者 AUC
等性能指标来监控，<strong>当测试集上的指标不变或者下跌时，就降低学习率。</strong></p></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>An Overview Of An Ad System</title>
    <url>/2021/05/05/An%20Overview%20Of%20Ad%20System/</url>
    <content><![CDATA[<p>从实习到工作，接触过一些大大小小的广告系统，有麻雀虽小但五脏俱全的小
dsp，也有把 ssp、adx、dsp 都打包了的大媒体
，算是对业界的广告系统有了一个初步的了解。趁着五一放假这几天，简单地梳理一下当前了解到的广告系统知识，主要是想对零散的知识做个整理，由于广告系统这个概念非常的大，涉及到的部分非常的多，无法面面俱到，所以本文主要是从几个视角（技术、业务、产品）言简意赅的描述一下笔者比较关心的几个部分，中间内容可能不全，欢迎交流指正。</p>
<p>特意声明，本文内容与笔者雇主无关，主要是基于笔者当前的认知梳理的内容；在撰写过程中只会引用公开的内容，不会涉及到笔者雇主内部未公开的信息；如相关同学觉得有敏感内容，可联系删除。而其实在崇尚开源、paper
漫天飞、人员流动越来越快的如今，笔者觉得这些通用技术并不是最核心的地方，数据+对业务的理解+灵活组装这些通用的技术才是。</p>
<span id="more"></span>
<h2 id="技术视角">技术视角</h2>
<p>这里的技术视角主要是技术同学日常迭代较多的模块，总体的架构上可将其划分为
召回+精排，而在这个结构里的两个主要关注的地方是出价和模型。</p>
<h3 id="召回与精排">召回与精排</h3>
<p>基本有规模的的推荐或广告系统，每次请求中选出 topk 个候选的过程都是
“召回+精排”，中间还可能会插入一个粗排，其原因都是候选集过于庞大，需要在工程与效果的
trade-off，而如果候选不多，延迟允许的情况下，对全量候选直接做精排，效果上无疑是最好的。</p>
<p>关于召回和排序，这篇文章讲得比较全面，推荐读一下， <a
href="https://zhuanlan.zhihu.com/p/100019681">推荐系统技术演进趋势：从召回到排序再到重排</a></p>
<p>当前的召回基本都是采用多路召回的模式，每一路的召回都有其存在的业务意义和目标，且往往各路之间是互补关系，有点类似
ensemble 里的 bagging 的思想。且考虑到效率，当前采用的基本都是 ANN
召回，其基本思想就是先把全量的候选划分在 <span
class="math inline">\(m\)</span> 个子空间中，召回时通过特定方式选出
<span class="math inline">\(n\)</span> （<span class="math inline">\(m
\gt n\)</span>）子空间，然后将 query 与这 <span
class="math inline">\(n\)</span> 个子空间的候选的相似性最高的 topk
个候选进入精排。关于 ANN 召回可参考这篇文章 <a
href="https://yongyuan.name/blog/ann-search.html">图像检索：再叙ANN
Search</a>，其中的 IVF-PQ
是业界比较常用的一种召回方式。另外，FaceBook发表的 Embedding-based
Retrieval in Facebook Search
也值得一读，整篇文章读下来就像一个奋战在一线的工程师向你娓娓道来他们是怎么从
0 到 1 构建一个召回系统，笔者也针对这篇 paper 写了<a
href="http://wulc.me/2020/08/30/%E3%80%8AEmbedding-based%20Retrieval%20in%20Facebook%20Search%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">Embedding-based
Retrieval in Facebook Search 阅读笔记</a>，供参考。</p>
<p>召回的目标是尽可能快地选出较好的候选，往往采用的特征和模型都会比较简单；而精排相对于召回，在特征和模型上可以做得更为复杂，因为精排面临的候选相对于召回少了非常多，各种交叉特征、复杂的结构都可以精排中尝试，精排基本上就是在根据业务去挖特征，而这里面笔者认为比较值得学习的是
Airbnb 的这篇文章 Real-time Personalization using Embeddings for Search
Ranking at
Airbnb，里面没有涉及到比较玄学的模型结构、超参等；而是看到了作者对业务有较为深刻的理解，同时通过各种方式将这些理解融入到模型中，笔者也针对这篇
paper 写了 <a
href="http://wulc.me/2020/06/20/%E3%80%8AReal-time%20Personalization%20using%20Embeddings%20for%20Search%20Ranking%20at%20Airbnb%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">Real-time
Personalization using Embeddings for Search Ranking at Airbnb
阅读笔记</a>，供参考。</p>
<p>此外，这里需要注意的是，<strong>将一个排序的过程拆成了多个阶段来选择
topk
个候选，带来的问题是每个阶段的排序优化目标可能会有割裂</strong>，而这在上面的文章《推荐系统技术演进趋势：从召回到排序再到重排》中也有提出</p>
<blockquote>
<p>如果在召回阶段使用模型召回，理论上也应该同步采用和排序模型相同的优化目标，尤其是如果排序阶段采用多目标优化的情况下，召回模型也应该对应采取相同的多目标优化。同理，如果整个流程中包含粗排模块，粗排也应该采用和精排相同的多目标优化，几个环节优化目标应保持一致。因为召回和粗排是精排的前置环节，否则，<strong>如果优化目标不一致，很可能会出现高质量精排目标，在前置环节就被过滤掉的可能，影响整体效果</strong></p>
</blockquote>
<p>如果说上面的观点是<strong>召回应该去适配精排</strong>，则 FaceBook 在
Embedding-based Retrieval in Facebook Search
中提出的是让<strong>精排适配新的召回</strong>，paper 中指出新的 ANN
召回的结果可能并不会被精排认可，paper
中描述如下,也提出了一些解决方法</p>
<blockquote>
<p>since the current ranking stages are designed for existing retrieval
scenarios, this could result in new results returned from embedding
based retrieval to be ranked sub-optimally by the existing rankers</p>
</blockquote>
<h3 id="模型">模型</h3>
<p>模型的重要性无需强调了，往往离线指标的几个千分点的提升，就能带来线上比较显著的收益，而且几乎系统的规则约束的东西都可以被模型取代。这里主要讲一些笔者认为对模型效果比较重要的几部分：<strong>数据、训练、预估纠偏</strong>。</p>
<h4 id="数据">数据</h4>
<p>数据是可以说是对模型效果影响最大的因素，这里可将其分为<strong>数据流和特征工程</strong>两部分</p>
<p><strong>数据流比较核心的目标是及时且准确地获取各种事件(click,convert)的
ground
truth</strong>；“及时”指的是发生的事件需要尽可能快地喂给模型，“准确”指的是这些事件需要被正确打上label。</p>
<p>数据流与转化归因(conversion
attribution)这个领域密切相关，归因可以理解为 label 的获取与拼接,
当前最常见的是 last touch 方式的归因，也有一些其他的归因方式如
multi-touch 归因等,
通常涉及到广告主的上报和实际的拼接两部分，这里就不详细展开讲了，详细可参考这个
<a
href="https://github.com/wnzhang/rtb-papers#conversion-attribution">rtb-papers</a>
里相关的
paper。这里主要讲几个笔者认为比较值得关注的问题：<strong>delayed
feedback、bias、全渠道数据</strong>。</p>
<ul>
<li>delayed feedback</li>
</ul>
<p>在广告场景下，cvr
模型是这个问题的典型例子，因为转化是有延迟的，即在点击发生后过一段时间用户可能才会发生转化，且往往转化漏斗越深，延迟的时间越长</p>
<p>这时候有两种选择，一种是等待事件的 label
完全回流再进行训练，比如说事件的真实 label
能在一天内完全回流，做天级训练即可，但是这不符合上面提到的“及时”的原则；另一种则是实时把数据送入模型做
online training，但是这不符合上面提到的“准确”的原则，因为有些 label
可能还没回流。而实际上，实时性和准确性也是一个 trade-off 的关系。</p>
<p>这个问题也被归纳为一个 delayed feedback 的问题，这部分内容可以参考 <a
href="http://wulc.me/2020/12/05/Delay%20FeedBack%20In%20Computational%20Advertising/">Delayed
FeedBack In Computational Advertising</a>，里面介绍了一些paper
里的解决方法，基本都是解决在 online-training 模式下如何解决 label
回传不及时的问题，如利用 importance sampling
等方法对样本做加权，或者让样本多次进模型，然后从统计意义推导出新的概率表达，从而保证样本是无偏的。</p>
<ul>
<li>bias</li>
</ul>
<p>训练数据可能存在各种 bias，常见的有 exposure bias 和 position
bias</p>
<p>(1)exposure bias： 针对的问题是只有被曝光的样本才能进入训练集，导致
training 阶段能获取到的样本只是 serving 时很小的一部分 (2)position
bias： 针对的问题是位置越显眼的广告位被点击的概率越高</p>
<p>关于 exposure bias 可参考文章 <a
href="http://wulc.me/2021/04/03/Exposure%20Bias%20In%20Machine%20Learning/">Exposure
Bias In Machine Learning</a>，里面介绍了一些 paper
的解决方法，笔者将其总结为 Data Augmentation、IPS 和 Domain Adaption
三大类的方法</p>
<p>exposure bias
在召回上往往也会被简化成一个<strong>负例选择的问题</strong>，这篇文章 <a
href="https://zhuanlan.zhihu.com/p/358779957">SENet双塔模型：在推荐领域召回粗排的应用及其它</a>
最后一部分列了一些可能的负例选择方法，也具备一定的实践指导意义</p>
<blockquote>
<p>选择1:<strong>曝光未点击数据</strong></p>
<p>这就是上面说的导致 Sample Selection
Bias问题的原因。我们的经验是，这个数据还是需要的，只是要和其它类型的负例选择方法，按照一定比例进行混合，来缓解Sample
Selection
Bias问题。当然，有些结论貌似是不用这个数据，所以用还是不用，可能跟应用场景有关。</p>
<p>选择2:<strong>全局随机选择负例</strong></p>
<p>就是说在原始的全局物料库里，随机抽取做为召回或者粗排的负例。这也是一种做法，Youtube
DNN双塔模型就是这么做的。从道理上讲，这个肯定是完全符合输入数据的分布一致性的，但是，一般这么选择的负例，因为和正例差异太大，导致模型太好区分正例和负例，所以模型能学到多少知识是成问题的。</p>
<p>选择3:<strong>Batch内随机选择负例</strong></p>
<p>就是说只包含正例，训练的时候，在Batch内，选择除了正例之外的其它Item，做为负例。这个本质上是：给定用户，在所有其它用户的正例里进行随机选择，构造负例。它在一定程度上，也可以解决Sample
Selection Bias问题。比如Google的双塔召回模型，就是用的这种负例方法。</p>
<p>选择4:<strong>曝光数据随机选择负例</strong></p>
<p>就是说，在给所有用户曝光的数据里，随机选择做为负例。这个我们测试过，在某些场景下是有效的。</p>
<p>选择5:<strong>基于Popularity随机选择负例</strong></p>
<p>这种方法的做法是：全局随机选择，但是越是流行的Item，越大概率会被选择作为负例。目前不少研究证明了，负例采取Popularity-based方法，对于效果有明显的正面影响。它隐含的假设是：如果一个例子越流行，那么它没有被用户点过看过，说明更大概率，对当前的用户来说，它是一个真实的负例。同时，这种方法还会打压流行Item，增加模型个性化程度。</p>
<p>选择6:<strong>基于Hard选择负例</strong></p>
<p>它是选择那些比较难的例子，做为负例。因为难区分的例子，很明显给模型带来的loss和信息含量比价多，所以从道理上讲是很合理的。但是怎样算是难的例子，可能有不同的做法，有些还跟应用有关。比如Airbnb，还有不少工作，都是在想办法筛选Hard负例上。</p>
<p>以上是几种常见的在召回和粗排阶段选择负例的做法。我们在模型召回阶段的经验是：比如在19年年中左右，我们尝试过选择1+选择3的混合方法，就是一定比例的“曝光未点击”和一定比例的类似Batch内随机的方法构造负例，当时在FM召回取得了明显的效果提升。但是在后面做双塔模型的时候，貌似这种方法又未能做出明显效果。全局随机，则无论是FM召回还是后来的双塔，都没做出效果，有时甚至负向明显。但是你又能看到一些报道采用的是全局随机做为负例。所以，我目前的感觉，负例这块是个宝藏，值得深入探索下，包括不同方法的混合，但是到底哪种方法是有效的，貌似很难有统一的定论，带有一定艺术性。</p>
</blockquote>
<ul>
<li>全渠道数据</li>
</ul>
<p>除了自身的数据外，还需要关注如何利用全渠道的数据提升的效果，其核心是<strong>将被
cvr
被低估的用户通过全渠道数据捞回来</strong>。提到全渠道的数据的概念，不得不说一下广告的模式，传统的广告模式将广告的竞价划分为
ssp &lt;-&gt; adx &lt;-&gt; dsp
三大块，而当前的一些大媒体基本上都包含这三大模块，如微信、抖音等，自身是媒体(ssp)，也是拍卖平台(adx),
同时也承担着广告主投放的任务(dsp)。基本上面说的相关模型都数据媒体侧自身的
dsp 这一部分</p>
<p>媒体利用的数据往往只是用户在其自身产生的数据，如微信只能拿到用户在微信上的行为数据，拿不到用户在抖音上的相关数据；但广告主往往会在多个媒体上投放，可能用户在媒体
A 点击了某个广告，最终转化是在媒体 B 上，如果媒体 A
只用其自身的数据，会把 A 当做一个负例，cvr
会被低估，相当于放弃了这个转化高潜用户，而利用媒体 B
的数据则能让模型学习到这个用户真实的 cvr 情况；</p>
<p>怎么拿到这部分数据呢？一种是广告主将媒体 A 的数据归因后直接回传给媒体
B，另一种则是媒体之间相互合作，如笔者做过的联邦学习在广告的落地应用就是属于这部分。</p>
<p>拿到这部分数据后便可进行建模，最简单就是加到原来的模型中，除此之外，还可以独立建模，然后作用到出价或原始
cvr 上。</p>
<ul>
<li>特征工程</li>
</ul>
<p>如果说数据流决定用哪部分数据，特征工程则是决定了是否能够完全挖掘这部分数据的价值，即常说的“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”。</p>
<p>特征工程基本上做的就是根据业务特点去挖掘可能有用的特征，然后开 ab
实验验证效果；虽然说特征跟业务强相关，但是具体的挖掘也有一些套路，常用的有<strong>属性特征、计数特征、序列特征</strong>等</p>
<p>(1)属性特征：用户/广告本身的一些属性，如用户的年龄、性别；广告的类别、样式等
(2)计数特征：用户在特定时间范围(如过去 7d、 3d、 12h、1h
等)对当前广告的特定的维度(如特定类别、特定位置、特定广告主等)的广告进行了特定操作(如点击、浏览等)的次数；
(3)序列特征：即用户在一段时间内的行为序列，如最近 30
个点击过的广告/商品；典型的应用可参考阿里的 DIN</p>
<p>特征工程另一重要部分是特征筛选，特征筛选最简单的做法是删除指定特征，然后重新训练模型并评估，但是这种做法在训练时长较长时开销是比较大的；因此更合理的做法是<strong>在训练过程中便能得到每个特征的重要性</strong>，对于
logistics regression、tree-model
这种解释性较好的模型能够做到这点，但是在 embedding-based 的 dnn
中，每个特征都只能拿到一个
embedding，怎么能做较好的特征选择的？比较常见的方法有</p>
<ul>
<li>attention unit：为每个 feature 增加一个 attention unit（如 DIN 中的
activation unit），训练过程中通过这个 attention unit
输出的值来衡量每个特征重要性；其假设是对于重要特征，模型能够自动学习出其权重情况</li>
<li>embedding weight：根据每个 feature 对应的 embedding
的值大小来判断重要性， 常见的有基于 embedding 的 L1 norm，L2 norm
等；其假设是对于重要特征，其对应的 embedding 的值越大，类比 lr，其实 nn
可以近似认为是多个 lr 组成的</li>
</ul>
<p>上面的两种方法都存在着较强的假设，有没有更直接一点的方法呢？回到最开始的想法，即删除指定特征，然后重新训练模型并评估，能否在训练过程中便达到这一目的呢？其实是可以的，在训练过程中通过
mask 的方式近似将 embedding 全置为 0，近似当做 drop 掉这个特征，然后通过
multi-head 的方式计算这部分 auc 即可。</p>
<p>另外，在召回阶段，出于效率的考虑，线上往往只会抽取 user/ad
的单侧特征，一些交叉特征虽然效果好，但是无法直接在线上抽取，这时可以考虑一些其他方法，如蒸馏，可参考阿里的
Privileged Features Distillation for E-Commerce Recommendations 或 <a
href="http://wulc.me/2020/03/01/Distillation%20%E7%AE%80%E4%BB%8B/">Distillation
简介</a></p>
<h4 id="训练">训练</h4>
<p>在数据决定上限后，怎么通过模型逼近这个上限呢?
以下几部分或许值得关注一下：模型结构，初始化，优化器和损失函数；这里说的模型主要还是针对
DeepLearning 中的 NN 模型，在算力和数据量都达到一定标准后，NN
的确能够取得 sota 的效果，</p>
<ul>
<li>模型结构</li>
</ul>
<p>这里的模型结构针对是 NN 这一类模型，NN
里的各种结构可以说是百花齐放，如推荐领域的
Wide&amp;Deep、DeepFM、DIN、DCN等，CV 领域的
AlexNet、VGG、Inception、ResNet等，NLP 领域
transformer、Bert等；这些还是笔者读书那会就已经发表的paper
里的结构，如果算上近年发表的相关结构等，那就更多了</p>
<p>而由于深度学习的不可解释性，使得模型的构建这一过程基本没有什么理论基础，基本上只能尝试，然后根据效果推测有效的原因，所以也出现了
autoML
这种自动化去搜寻结构和参数的方法。但是抛开那些玄学的部分，在实际应用中模型结构还是有一些可以借鉴的经验，</p>
<ol type="1">
<li><a
href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension">VC
Dimension</a>: VC Dimension
本质上是在描述数据量大小和模型大小的关系，即模型参数量应该与数据量大小成正比关系，否则容易出现过拟合或欠拟合的问题</li>
<li>attention: attention
用最直白的话来说就是动态加权，而这也很符合直觉，如每个特征的重要性不一样，应该对重要性高的给予更高的权重；在
NN 模型中，attention 常用在两个地方: embedding 和 hidden unit；
embedding 的 attention 策略可参考这篇文章 <a
href="https://zhuanlan.zhihu.com/p/358779957">SENet双塔模型：在推荐领域召回粗排的应用及其它</a>；而针对
hidden unit 的 attention 则可参考这篇 paper，<a
href="https://arxiv.org/abs/1601.02828">Learning Hidden Unit
Contributions for Unsupervised Acoustic Model Adaptation</a></li>
<li>multitask: multitask 结构有两个常见的用处, 第一种认为多个 task
之间有关联，联合训练能增加数据量,同时提升效果;第二种则是对于预估值的准确性有要求的场景，如果广告的
ctr、cvr
的预估，往往数据流中混合了多个场景的数据，且每个场景对应的数据的后验不同的，为了保值预估值的准确性，需要将后验值不同的数据分到不同的
head 中</li>
</ol>
<ul>
<li>模型训练</li>
</ul>
<p>模型训练的过程，笔者认为可分为三大部分：初始化，优化器和损失函数</p>
<p>初始化对效果有影响，而这个问题可以从几个角度去理解，从最优化的角度理解，是因为
NN 的优化往往是一个 non-convex 的问题,
如果初始化不好，一开始可能就处于一个不好的位置；从 bp
的角度理解，初始化的值过小或过大，容易导致梯度消失会梯度爆炸，关于这部分，deeplearning.ai
上的 <a
href="https://www.deeplearning.ai/ai-notes/initialization/">Initializing
neural networks</a> 讲得比较好了，还辅以实践，推荐读一下。</p>
<p>训练过程本质上就是个优化问题，通过 bp 过程不断修正初始化的
parameter，从而达到损失函数最小的目标，更详细的描述可以参考 <a
href="https://www.deeplearning.ai/ai-notes/optimization/">Parameter
optimization in neural networks</a>；中间涉及到了各种超参数的选择：如
learning rate、batch size、optimizer 等；其中 optimizer
也有非常多的选择，其中 optimizer
的选择往往又是一个值得考量的地方，关于各类 optimizer
的区别可以参考这篇文章，<a
href="https://zhuanlan.zhihu.com/p/32230623">一个框架看懂优化算法之异同
SGD/AdaGrad/Adam</a></p>
<p>损失函数基本都是通过 <a
href="https://zhuanlan.zhihu.com/p/32480810">MLE 或 MAP</a>
推导出来的，其思想都是假设训练样本都是服从某些分布生成的，而训练的目标是让这些样本的联合概率最大；如
mse 的 assumption 是模型预估值与 ground truth 的误差服从正态分布，cross
entropy 的 assumption 是预估值服从伯努利分布；而这两个其实也能被统一到
GLM 这个框架下。</p>
<p>目前在业界更常见的做法是把问题转为分类问题，对应的 loss 即为 cross
entropy，而其实一些回归的 loss 也能通过 weighted logistics regression
转化为分类的问题，比较经典的就是 youtube 的 <a
href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf">Deep
Neural Networks for YouTube Recommendations</a> 中 Modeling Expected
Watch Time 部分；基于最原始 cross entropy 衍生出来的 loss
主要有两种形式</p>
<ol type="1">
<li>reweight, 即对样本进行各种加权,
包括但不限于根据物理含义直接加权(如观看时长)、通过 importance sampling
等方式推导出来的 loss，其最终形式也是 reweight 的模式</li>
<li>auxiliary/regularization, 即在原始的 task
上增加一些辅助任务或正则项，如 center loss等</li>
</ol>
<h4 id="预估纠偏">预估纠偏</h4>
<p>在推荐场景下，往往只要序准确就可以了，而总体高估或低估理论上不会影响总体的排序；但是广告场景下涉及到计费环节，需要保证计费时的准确性，因此在广告场景下还需要关注模型预估准确性的问题，假设模型高估了，相当于多收了广告主的钱，广告主吃亏，反之平台吃亏。</p>
<p>因此，在广告场景下，模型需要关注的指标不仅仅是
auc，还需要关注预估偏差；为了保证纠偏后不影响总体的排序即 auc
指标，预估纠偏往往采用的是保序回归，关于预估纠偏可参考这篇文章：<a
href="http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/12/21/classifier-calibration-with-isotonic-regression">使用
Isotonic Regression 校准分类器</a></p>
<p>另外，上面在 loss 中对样本进行 reweight
的方式，会影响正负样本的分布，导致统计意义上预估值的就是有偏的，应对的策略可以在训练阶段就进行纠偏，或者在预估值上直接做一个转换，这部分内容可参考这篇文章
<a
href="http://wulc.me/2020/12/05/Delay%20FeedBack%20In%20Computational%20Advertising/">Delayed
FeedBack In Computational Advertising</a> 的 Fake negative
calibration</p>
<h3 id="出价">出价</h3>
<p>上面的无论是召回+精排的架构，还是模型相关的部分，在推荐和广告基本都是通用的；而出价(bidding)这个领域,
则是笔者认为是广告相对于推荐的最大的不同；因为在广告场景中引入了广告主(advertiser)这一角色,
出价则是提供了一种方式供广告主表达其对付费诉求，即对一次曝光/点击/转化愿意付多少钱。</p>
<p>其次，广告平台往往需要提供多种产品形态来满足广告主的各种需求，如最常见的是保成本类产品、还有一些更追求跑量、品牌广告则是对保量有严格的要求；针对这些不同的产品形态，基本上最终的策略都落在了出价上。因为在基于
ecpm 排序的广告系统中，基本上能比较灵活地改动的就是 bid 这个因素了</p>
<p>而针对上面各种产品需求，其实都是可以通过相同的最优化建模的方式来解决的，阿里之前发表过一篇
paper
来描述这个问题，对于出价公式的推导和控制器的构建都有较好的指导意义；笔者针对这篇
paper 也写了一篇文章 <a
href="http://wulc.me/2020/07/19/%E3%80%8ABid%20Optimization%20by%20Multivariable%20Control%20in%20Display%20Advertising%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Bid
Optimization by Multivariable Control in Display
Advertising》阅读笔记</a>，供参考。</p>
<h2 id="业务视角">业务视角</h2>
<p>这里的业务视角，其实就是在实际迭代中直接面临的几个问题，也是会直接影响到客户体验与平台收入的几个问题；上面提到的技术可以说都是为了这些业务服务的。笔者将其总结为:
<strong>起量、成本、持续跑量和冷启动</strong>四大块。</p>
<h3 id="起量">起量</h3>
<p>起量可以说是投放面临的第一个难题，素材过审了、计划建好了、预算也准备好，计划是不是就能够如期地起量呢？答案肯定不是的</p>
<p><a
href="https://www.cnwebe.com/articles/187702.html">信息流广告起量真的要靠大量堆账户堆计划吗？</a>
和 <a
href="https://www.zhihu.com/question/438326415">广告投放不起量都是怎么解决的？</a>
就从优化师的角度，描述了为了让计划起量而想出的各种“奇技淫巧”，总的来说，有以下几个方向：优化素材、放开定向、提高出价&amp;预算、堆计划等。</p>
<p>那么从媒体/平台侧的角度来说，有什么手段去缓解广告主起量难的问题么？</p>
<p>一般来说，起量难的问题会随着广告候选变多而愈发严峻，而这也可以从
E&amp;E 的角度去解读，因为在 dau
基本稳定的情况下，媒体展示广告的次数是有限的，如果让更多的新计划得到展示机会，势必会挤压老计划，而且新计划起量后，后续能否持续跑量也是个问题，属于
explore 的部分。</p>
<p>因此，一个朴素的思想是固定一些 explore 的
quota，专门用于处于起量阶段的计划，相当于给这些起量阶段的计划开的绿色通道；有了绿色通道后，需要考虑的第二个问题是：哪些计划能通过这些绿色通道？每个计划都给同等的机会显然不是最优的，因为不同计划起量后的表现不一样，因此一种更合理的做法是建模判断这些计划在起量后的表现能力，然后根据表现能力决定计划是否能进绿色通道，同时还需要考虑那些堆计划的
case，避免对相同或只做了微小改动的计划重复进入绿色通道，给更多广告主以探索的机会。</p>
<h3 id="成本">成本</h3>
<p>大部分客户投放广告关注的是其
roi（品牌广告其实也可以认为追求的是长期的
roi），而近年各个媒体平台上也出现了各种 roi 类的产品，但是 roi
类的产品要求广告主把付费金额等敏感数据回传，因此大范围推广还需要时间；当前使用更多的是成本类产品，即认为广告主出价是
truthful bidding
的，可以将广告主的出价作为成本，投放过程中尽量让实际成本贴近广告主填的出价。</p>
<p>由于当前的广告系统都是基于 ecpm 排序和扣费的，因此构成 ecpm
的几个元素(bid, ctr,
cvr)的值必须要准确，才能保证成本不会过高(广告主亏)或过低(媒体亏)</p>
<p>首先需要重点关注的是 <strong>ctr、cvr
预估的准确性，而这个问题的难点在于能拿到的训练数据的 label 是
0和1(代表是否点击/转化)，但是实际中需要预估的是一个
rate，而这导致了没有一个绝对准确的 ground
truth，退化成只能通过训练来逼近训练样本中的正负样本的比例</strong>，这也是为什么改变了训练样本的分布需要在
loss function
或预估值上做纠偏。另外，从概率论出发，大数定律告诉我们：当样本数量越多，则其算术平均值就有越高的概率接近期望值，但问题是很多计划的的
click、convert
数量非常少，所以训练也没法很好的学习出各个计划的期望cvr。</p>
<p>因此，面对这么一个没有绝对 ground
truth，同时大数定律也不完全适用的而带来的预估偏差的问题，需要有额外的策略来应对，最常见的就是上面提到的保序回归，这个也是基于后验数据的统计对预估值做
calibration，因此也需要考虑纠偏粒度上的后验数据是否过少的问题。</p>
<p>另一个关键因素就是出价了，如果预估完全准确的情况下，按照广告主给定的出价来投放是最优的，但这显然是不太可能，因此，才有了控制器不断地调价来控制成本，满足保成本的诉求，可以认为出价是预估不准的兜底策略。</p>
<h3 id="冷启动">冷启动</h3>
<p>无论是在广告还是推荐，冷启动都是一个长期存在的问题，其原因是新用户/计划缺少历史数据，模型/策略对其学习不够充分，从而效果表现得很差；而在广告场景中，新计划比起新用户的冷启动往往是更常见且严峻的，因为对于成熟的媒体而言，dau/mau
等基本都是稳定的，但广告主会不断地新建计划。</p>
<p>冷启动往往会加剧上面提到的各类问题，如在模型上，预估值的准确性更难保证；在出价上，成本更难控制等；而针对冷启动的问题，往往也会从两个方面去优化，即模型和策略。</p>
<p>在模型上，有不少针对冷启动的paper，且基本都是针对 nn 这一类
embedding-based 的模型，其基本思路都是让冷启动 item 的 embedding 贴近
warm-up 阶段的状态，笔者将这类方法归纳成两类 (1)利用 meta-network
为冷启动的 item 生成一个 id embedding (2) 基于 MAML 的方法训练模型，让
embedding 更快收敛</p>
<p>第一种方法的基本思想是<strong>利用 item 的 meta 信息(即使冷启动 item
也有)通过一个小网络(即 mata-network)生成 embeddding，然后增加一些
auxiliary task 来训练这个小网络</strong>，这些 task
就有很多选择了，更多是对业务的理解，如可以让 meta-network 吐出来的
embedding 与item 在成熟期的 embedding
误差尽量小(针对已经步入成熟期的item 的样本)，也可以利用冷启动 item
对网络进行二次的训练等</p>
<p>这种方法的两篇比较典型的 paper 可参考</p>
<ul>
<li><a href="https://arxiv.org/pdf/1904.11547.pdf">Warm Up Cold-start
Advertisements: Improving CTR Predictions via Learning to Learn ID
Embeddings</a></li>
<li><a href="https://arxiv.org/pdf/2105.04790.pdf">Learning to Warm Up
Cold Item Embeddings for Cold-start Recommendation with Meta Scaling and
Shifting Networks</a></li>
</ul>
<p>第二中方法基本上就是基于 meta learning 的思想，让模型能够更好的 learn
to learn，即使对于样本量很少的 item 也能较快学习到，代表方法就是
MAML，可以参考下面两篇 paper，另外，关于 MAML 更通俗的介绍可参考知乎上<a
href="https://zhuanlan.zhihu.com/p/136975128">这篇文章</a></p>
<ul>
<li><a href="https://arxiv.org/pdf/1703.03400.pdf">Model-Agnostic
Meta-Learning for Fast Adaptation of Deep Networks</a></li>
<li><a href="https://arxiv.org/pdf/1908.00413.pdf">MeLU- Meta-Learned
User Preference Estimator for Cold-Start Recommendation</a></li>
</ul>
<p>上面的方法基本都是让冷启动 item 的 id embedding
能更快收敛，还有另一种方法是<strong>将冷启动的 item
的一些更泛化的特征直接加入到模型中，如图像、文本等描述性特征</strong>，通过一些
pretrained model (如 VGG、Bert 等)将其转为 embedding
的模型加入模型中，也是一种常见的套路。</p>
<p>除了模型，策略上往往也需要对冷启动的计划有额外的举措；如在冷启动阶段，可以给计划"绿色通道",
即一定 explore 的
quota，如同上面提到的起量问题一样(起量其实也可以算是一个冷启动问题)，而这也涉及到老生常谈的
E&amp;E 问题了，一个跟 deep learning
的玄学程度不相上下的领域，这部分内容介绍可参考 <a
href="http://wulc.me/2019/01/05/EE%28Exploitation%20Exploration%29%20%E9%97%AE%E9%A2%98%E6%A6%82%E8%BF%B0/">EE
问题概述</a>。同样地，这些 explore quota
也应该根据每个计划的预期表现给予个性化的分配；即需要识别计划未来的表现，毕竟往往个性化分别比起均分都是最优的。此外，这些
quota 必然会对成熟期的计划造成一定的积压，所以也需要考虑冷启动和成熟期的
trade-off。</p>
<p>除了额外的扶持，冷启动的出价方法也需要额外考虑，因为此时计划的后验数据基本是空的，那怎么才能获取出价调控需要的这些数据呢？这里也有一些思路，比如可不可以利用相似计划的后验数据？或者信任预估，直接对预估值取
sum？或者产品层面就不对冷启动计划做苛刻的成本要求？</p>
<p>同时，在实际产品中，往往也需要联合产品教育广告主，冷启动期间就是会存在不稳定性，更容易出现超成本等问题，而如果客户对平台粘性不高或者整个市场有其他更有竞争力的竞品，这些超成本所带来的损失往往也是需要有平台来承担。</p>
<h3 id="持续跑量">持续跑量</h3>
<p>持续跑量可以认为是计划渡过冷启动后，亦即计划进入了成熟期需要面临的问题，因为广告主在投放追求的往往是两个东西：<strong>成本和跑量</strong>，在成本能控住的前提下，跑量一般是越多越好的，但现状是在不少的媒体上，计划在进入成熟期不久就会掉量，而且往往是掉了之后就再也起不来了，也就是说计划的生命周期较短。</p>
<p>造成这个问题原因有很多，包括但不限于</p>
<ol type="1">
<li>广告主频繁地修改出价、定向、预算等有可能改变计划的稳态</li>
<li>模型预估的不准确、出价调控不够稳定，可能导致计划突然爆量或掉量</li>
<li>如果竞价环境比价激烈，那么对于有限的展示机会和不断增加的计划数，部分老计划掉量也是不可避免的</li>
<li>自然衰减，如计划圈定的人群基本都曝光了，或者创意的自然衰减</li>
</ol>
<p>这个问题会往往会导致<strong>广告主为了跑量而不断复制新建计划</strong>，进一步加剧起量、冷启动等问题，也直接导致竞争环境变得更激烈，系统的机器负载更大，因此，保证计划的持续跑量是所有广告系统都需要解决的重要问题。</p>
<p>抛开第三个比较难改变的因素，针对其他几个原因，有一些思路也许值得借鉴</p>
<ul>
<li>广告主要减少频繁修改计划的定向、出价等操作，这些需要平台教育广告主，至于频率多大算频繁，定向又应该放开到何种程度，需要平台同时实验等手段测试出来，最好能给广告主提供一个参考值</li>
<li>要尽量减少系统波动等因素对计划的影响，即要减少各中工程和算法的事故的影响，如尽量保证各种
infra 服务的高可用性，AB
实验要更加谨慎，因为这些操作都是有可能影响计划的稳态</li>
<li>对于要掉量的计划生效额外策略；这里面又可分为两个问题，如识别掉量计划以及对计划做何种策略，这个问题跟冷启动的扶持也很相似</li>
</ul>
<p>总的来说，从业务视角来看的几个问题：起量、冷启动、成本、持续跑量，都是广告主非常关心的几个问题，也是直接衡量平台给广告主带来的价值的几个方面，值得重点关注；而且这里面也不像第一部分那么偏技术导向了，需要更多地考虑产品形态、如何更好地服务客户等。</p>
<h2 id="产品视角">产品视角</h2>
<p>这里的产品视角也可以理解为广告主的视角，亦即平台披露给广告主的产品形态；一般可将其分为划分为品牌广告、效果广告两大类，而这两大类下面又有很多细分；这里就简单概述一下这两大类广告的一些基本知识。</p>
<h3 id="品牌广告">品牌广告</h3>
<p>品牌广告往往是一个广告系统发展初期的广告模式，基本流程是广告主先付钱，平台保证曝光，如
cpt，gd
就是典型的品牌广告，前者没什么好说的，固定的广告位在特定位置强出就好了；后者则一般会涉及到库存预估和库存分配两个问题</p>
<ul>
<li>库存预估：gd
承诺的是未来的曝光量，因此需要保证当前售卖的库存不能超过未来的曝光量；一般可以通过时序预估模型来进行预估</li>
<li>库存分配：将库存和 gd 计划作为 supply side 和 demand side
构造二部图，然后通过分配算法进行分配，常见的分配算法有 <a
href="https://zhuanlan.zhihu.com/p/123187987">HWM 和 SHALE</a></li>
</ul>
<p>上面的做法只是在解决 gd
广告的保量问题，但是随着优化的精细化，除了保量，还需要考虑一些其他问题，如</p>
<ul>
<li>gd
广告和效果广告往往存在竞争关系(因为曝光的机会是共享且数量是基本固定的),
需要联合效果广告建模使得利益最大化</li>
<li>gd
广告除了保量，往往客户也会提出效果的要求，否则平台可以把低质流量直接给到
gd 计划；因此，从建模上这成了一个多约束的优化问题</li>
</ul>
<p>如果额外考虑以上这两点，上面传统的分配算法就有点问题了，首先库存预估出来的量往往是总体的曝光量，gd
能占用其中多少的量需要拍一个数，或者根据 cpm
分配；其次，上面分配算法是直接把这个曝光给这个gd
广告的，不会判断质量的好坏，但我们实际是不希望把太差的量给广告主的，同时也不能对竞价有过多的挤压，因此需要判断流量对于
gd 计划的质量，需要为 gd 计划考虑一种更加灵活的拿量方法。</p>
<p>综上，gd
广告需要考虑保量、效果、溢价率以及对效果广告的挤压，因此建模时也需要把这些因素考虑进去。</p>
<h3 id="效果广告">效果广告</h3>
<p>效果广告占了广告市场的大部分的份额，因为绝大部分广告主关心的是投放的
roi；而上面提到的各种技术，很大一部分都是为效果广告服务的，如保成本、跑量等；这里就不赘述了。</p>
<h3 id="深度转化产品">深度转化产品</h3>
<p>随着优化的深入，常见的效果广告的优化目标已经不能满足所有广告主的需求了，比如部分行业广告主会希望直接优化到
roi 而不仅仅是成本，同时也能提供相应的数据</p>
<p>这个时候就需要考虑为这个广告主进行额外建模了，这里又有两种选择，一种是广告主直接把数据回传到平台进行常规的模型训练，另一种则是广告主不愿意把
label 直接回传到平台，这中情况下可以通过 Federated Learning
的方法对其进行优化，笔者在实际中对这部分也有一定实践经验，详细可参考 <a
href="https://mp.weixin.qq.com/s/mLLkLvO0MWBLYRmLMQquHA">字节跳动联邦学习平台Fedlearner：4个月落地开源，投放增效200%+</a></p>
<p>建模后往往会通过出价的方式应用模型，除非广告主能够提供直投深度目标的
bid；而这往往又是一个多目标约束的优化问题，具体的策略可以看上面出价部分</p>
<h2 id="小结">小结</h2>
<p>综上，本文主要从技术视角、业务视角和产品视角总结了一些笔者比较关注的计算广告领域的知识</p>
<ul>
<li>技术视角：基本是 “召回+精排”
的结构，里面两个值得关注的部分是模型和出价</li>
<li>业务视角：主要面临4个问题：起量、成本、持续跑量、冷启动</li>
<li>产品视角：主要可分为品牌广告、效果广告和深度转化广告三大类</li>
</ul>
<p>内容很多也很乱&gt;_&lt;,
但在整个广告系统下也只是冰山一角；同时因为保密性原因，很多具体方法没有在文中提及，但是相信提及的思想都是普适的，欢迎交流指导。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>Binary Indexed Trees 简介</title>
    <url>/2016/07/12/Binary%20Indexed%20Trees%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>Binary Indexed
Trees（中文名为树状数组，下文简称为BIT）是一种特殊的数据结构，可多用于高效计算数列的前缀和，
区间和。对于长度为n的数组，它可以以<span
class="math inline">\(O(logn)\)</span>的时间得到任意前缀和 $
{_{i=1}^{j}a[i],1&lt;=j&lt;=N}$，并同时支持在 $ O(log
n)$时间内支持动态单点值的修改。空间复杂度 <span
class="math inline">\(O(n)\)</span></p>
<span id="more"></span>
<p>虽然BIT名称中带有tree这个词，但是实际存储时是利用两个数组进行存储，记这两个数组为<code>nums</code>和
<code>BIT</code>。假设我们现在需要对原始数组 <code>arr</code>
进行前缀求和和区间求和，那么可以按照以下步骤进行。</p>
<p><strong>1.初始化</strong></p>
<p><span class="math inline">\(nums[i] = arr[i]\)</span> <span
class="math inline">\(BIT[i] = {\displaystyle \sum
_{k=i-lowestbit(i)+1}^{i}arr[k]}\)</span></p>
<p>上面的<code>lowestbit(i)</code>指将i转为二进制后,最后一个1的位置所代表的数值。如<code>lowestbit(1)=1、lowestbit(6)=2</code>，具体的实现可通过<code>(i&amp;-i)</code>获取。</p>
<p><strong>下图就是初始化后的情况，横轴为数组的下标(记为i)，纵轴为下标数值对应的lowestbit（i&amp;-i），长方形表示BIT[i]涵盖的求和的范围</strong></p>
<p>[][1]</p>
<p>可以看到每个数组下标的lowestbit（也就是图中描黑的部分）在形态上构成了一棵树的形状，这也是名称中<code>tree</code>的来源。并且对于每个下标的lowestbit表示成的tree
node有以下特性。</p>
<p><strong>(1)假如i是左子节点，那么其父节点下标为i+(lowestbit(i))
(2)假如i是右子节点，那么其父节点下标为i-(lowestbit(i))</strong></p>
<p>上面这两个特性非常重要，也是我们进行后文分析的重要基础。</p>
<p><strong>2. 更新一个数值</strong> 假如要修改原始数组 <code>arr</code>
中的下标为i的值，那么需要修改<code>nums</code>数组中对应下标的值。除此之外还需要修改<strong>BIT</strong>数组中涵盖了<code>arr[i]</code>的值。<strong>结合上图可以知道，BIT数组中涵盖了<code>arr[i]</code>的值为下标i及其所有父节点</strong>，伪代码如下
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> i &lt; n:</span><br><span class="line">    BIT[i] += new_value</span><br><span class="line">    i += (i&amp;-i)</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 区间求和</strong></p>
<p><strong>假如要求arr数组下标区间为[i,j]的数值之和，那么可以先求下标为[0,i-1]的数值之和，再求下标为[0,j]的数值之和，然后用后者减去前者即可。</strong></p>
<p>通过观察上面初始化后的图可以知道求[0, i]可以通过下面的方法：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> i&gt;<span class="number">0</span>:</span><br><span class="line">    count += BIT[i]</span><br><span class="line">    i -= (i&amp;-i)</span><br></pre></td></tr></table></figure></p>
<p>通过上面的操作，通过利用额外的两个数数组，将原来的区间求和的操作从时间复杂度<span
class="math inline">\(O(n)\)</span>变为了<span
class="math inline">\(O(logn)\)</span>,但是更新数组的值的操作的时间复杂度也从原来的<span
class="math inline">\(O(1)\)</span>变为了<span
class="math inline">\(O(logn)\)</span>,所以这种数据结构更适合用于区间求和频繁的应用场景。</p>
<p>下面是[LeetCode][2]上的一道利用了BIT的题目,有兴趣的读者可以尝试做一下，验证刚刚学的理论知识。
&gt;Given an integer array nums, find the sum of the elements between
indices i and j (i ≤ j), inclusive.</p>
<blockquote>
<p>The update(i, val) function modifies nums by updating the element at
index i to val.</p>
</blockquote>
<p>实现的python代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NumArray</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        initialize your data structure here.</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.nums = nums[:]</span><br><span class="line">        self.count = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(nums)+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(nums)):</span><br><span class="line">            self.initialize(i, nums[i])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">self, i, val</span>):</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(self.nums)+<span class="number">1</span>:</span><br><span class="line">            self.count[i] += val</span><br><span class="line">            i += (i &amp; -i)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, i, val</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type i: int</span></span><br><span class="line"><span class="string">        :type val: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        diff = val - self.nums[i]</span><br><span class="line">        self.nums[i] = val</span><br><span class="line">        self.initialize(i, diff)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">left_sum</span>(<span class="params">self, i</span>):</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i&gt;<span class="number">0</span>:</span><br><span class="line">            total += self.count[i]</span><br><span class="line">            i -= (i &amp; -i)</span><br><span class="line">        <span class="keyword">return</span> total</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumRange</span>(<span class="params">self, i, j</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        sum of elements nums[i..j], inclusive.</span></span><br><span class="line"><span class="string">        :type i: int</span></span><br><span class="line"><span class="string">        :type j: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.left_sum(j) - self.left_sum(i-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Your NumArray object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># numArray = NumArray(nums)</span></span><br><span class="line"><span class="comment"># numArray.sumRange(0, 1)</span></span><br><span class="line"><span class="comment"># numArray.update(1, 10)</span></span><br><span class="line"><span class="comment"># numArray.sumRange(1, 2)</span></span><br></pre></td></tr></table></figure> [1]:
https://wulc.me/imgs/fenwick_tree_binary_index_tree.jpg [2]:
https://leetcode.com/problems/range-sum-query-mutable/</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 编译初步</title>
    <url>/2018/11/24/C++%20%E7%BC%96%E8%AF%91%E5%88%9D%E6%AD%A5/</url>
    <content><![CDATA[<p>文章为转载，转载自 <a
href="http://wiki.ubuntu.org.cn/Compiling_Cpp">Compiling
Cpp</a>，主要涉及到 C++ 在linux 下通过 g++
编译的一些基础知识，包括编译单个源文件、多个源文件、创建并使用静态库等。</p>
<span id="more"></span>
<h2 id="关于程序的编译和链接">关于程序的编译和链接</h2>
<p>一般来说，无论是
C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下也就是
<code>.obj</code> 文件，UNIX下是 <code>.o</code> 文件，即 Object
File，这个动作叫做编译（compile）。然后再把大量的 Object
File合成执行文件，这个动作叫作链接（link）。</p>
<p><strong>编译时，编译器需要的是语法的正确，函数与变量的声明的正确。</strong>对于后者，通常需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件应该对应于一个中间目标文件。都如果函数未被声明，编译器会给出一个警告，但可以生成Object
File。但在链接程序时，链接器会在所有的 Object
File中找寻函数的实现，如果找不到，那到就会报链接错误码（Linker
Error）</p>
<p>链接时，主要是链接函数和全局变量，<strong>链接器并不管函数所在的源文件，只管函数的中间目标文件</strong>，在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要<strong>给中间目标文件打个包，在Windows下这种包叫“库文件”（Library
File)，也就是 <code>.lib</code> 文件，在UNIX下，是Archive File，也就是
<code>.a</code> 文件。</strong></p>
<h2 id="单个源文件生成可执行程序">单个源文件生成可执行程序</h2>
<p>下面是一个保存在文件 helloworld.cpp 中一个简单的 C++ 程序的代码：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* helloworld.cpp */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;hello, world&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>程序使用定义在头文件 iostream 中的
cout，向标准输出写入一个简单的字符串。该代码可用以下命令编译为可执行文件：</p>
<p><code>$ g++ helloworld.cpp</code></p>
<p>编译器 g++ 通过检查命令行中指定的文件的后缀名可识别其为 C++
源代码文件。<strong>编译器默认的动作：编译源代码文件生成对象文件(object
file)，链接对象文件和 libstdc++ 库中的函数得到可执行程序,
然后删除对象文件。</strong></p>
<p>由于命令行中未指定可执行程序的文件名，编译器采用默认的
a.out。程序可以这样来运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./a.out</span><br><span class="line">hello, world</span><br></pre></td></tr></table></figure>
<p>更普遍的做法是通过 <code>-o</code>
选项指定可执行程序的文件名。下面的命令将产生名为 helloworld
的可执行文件：</p>
<p><code>$ g++ helloworld.cpp -o helloworld</code></p>
<p>在命令行中输入程序名可使之运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./helloworld</span><br><span class="line">hello, world</span><br></pre></td></tr></table></figure>
<p><strong>程序 g++ 是将 gcc 默认语言设为 C++
的一个特殊的版本，链接时它自动使用 C++ 标准库而不用 C
标准库。</strong>通过遵循源码的命名规范并指定对应库的名字，用 gcc
来编译链接 C++ 程序是可行的，如下例所示：</p>
<p><code>$ gcc helloworld.cpp -l stdc++ -o helloworld</code></p>
<p><strong>选项 -l (ell) 通过添加前缀 lib 和后缀 .a
将跟随它的名字变换为库的名字
libstdc++.a。而后它在标准库路径中查找该库。gcc 的编译过程和输出文件与
g++ 是完全相同的。</strong></p>
<p>在大多数系统中，GCC 安装时会安装一名为 c++ 的程序。如果被安装，它和
g++ 是等同，如下例所示，用法也一致：</p>
<p><code>$ c++ helloworld.cpp -o helloworld</code></p>
<h2 id="多个源文件生成可执行程序">多个源文件生成可执行程序</h2>
<p>如果多于一个的源码文件在 g++
命令中指定，它们都将被编译并被链接成一个单一的可执行文件。下面是一个名为
speak.h 的头文件；它包含一个仅含有一个函数的类的定义：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* speak.h */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Speak</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">sayHello</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>下面列出的是文件 speak.cpp 的内容：包含 sayHello() 函数的函数体：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* speak.cpp */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;speak.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Speak::sayHello</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *str)</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Hello &quot;</span> &lt;&lt; str &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>文件 hellospeak.cpp 内是一个使用 Speak 类的程序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* hellospeak.cpp */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;speak.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Speak speak;</span><br><span class="line">    speak.<span class="built_in">sayHello</span>(<span class="string">&quot;world&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面这条命令将上述两个源码文件编译链接成一个单一的可执行程序：</p>
<p><code>$ g++ hellospeak.cpp speak.cpp -o hellospeak</code></p>
<p>PS：这里说一下为什么在命令中没有提到 <code>speak.h</code>
这个文件，原因是在 <code>speak.cpp</code> 中包含有
<code>#include"speak.h"</code>
这句代码，它的意思是<strong>搜索系统头文件目录之前将先在当前目录中搜索文件
<code>speak.h</code>,</strong>而 <code>speak.h</code>
正在该目录中，不用再在命令中指定了。</p>
<h2 id="源文件生成对象文件">源文件生成对象文件</h2>
<p><strong>选项 <code>-c</code>
用来告诉编译器编译源代码但不要执行链接，输出结果为对象文件</strong>。文件默认名与源码文件名相同，只是将其后缀变为
.o。例如，下面的命令将编译源码文件 hellospeak.cpp 并生成对象文件
hellospeak.o：</p>
<p><code>$ g++ -c hellospeak.cpp</code></p>
<p>命令 g++ 也能识别 .o
文件并将其作为输入文件传递给链接器。下列命令将编译源码文件为对象文件并将其链接成单一的可执行程序：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ g++ -c hellospeak.cpp </span><br><span class="line">$ g++ -c speak.cpp </span><br><span class="line">$ g++ hellospeak.o speak.o -o hellospeak</span><br></pre></td></tr></table></figure>
<p>选项 -o
不仅仅能用来命名可执行文件。它也用来命名编译器输出的其他文件。例如：除了中间的对象文件有不同的名字外，下列命令生将生成和上面完全相同的可执行文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ g++ -c hellospeak.cpp -o hspk1.o </span><br><span class="line">$ g++ -c speak.cpp -o hspk2.o </span><br><span class="line">$ g++ hspk1.o hspk2.o -o hellospeak</span><br></pre></td></tr></table></figure>
<h2 id="编译预处理">编译预处理</h2>
<p><strong>选项 <code>-E</code> 使 g++
将源代码用编译预处理器处理后不再执行其他动作</strong>。下面的命令预处理源码文件
helloworld.cpp 并将结果显示在标准输出中：</p>
<p><code>$ g++ -E helloworld.cpp</code></p>
<p>本文前面所列出的 helloworld.cpp
的源代码，仅仅有六行，而且该程序除了显示一行文字外什么都不做，但是，<strong>预处理后的版本将超过
1200 行。这主要是因为头文件 iostream
被包含进来，而且它又包含了其他的头文件，除此之外，还有若干个处理输入和输出的类的定义。</strong></p>
<p>预处理过的文件的 GCC 后缀为 <code>.ii</code>，它可以通过
<code>-o</code> 选项来生成，例如：</p>
<p><code>$ gcc -E helloworld.cpp -o helloworld.ii</code></p>
<h2 id="生成汇编代码">生成汇编代码</h2>
<p>选项 <code>-S</code>
指示编译器将程序编译成汇编语言，输出汇编语言代码而後结束。下面的命令将由
C++ 源码文件生成汇编语言文件 <code>helloworld.s</code>：</p>
<p><code>$ g++ -S helloworld.cpp</code></p>
<p><strong>生成的汇编语言依赖于编译器的目标平台</strong>。</p>
<h2 id="创建静态库">创建静态库</h2>
<p><strong>静态库是编译器生成的一系列对象文件的集合。链接一个程序时用库中的对象文件还是目录中的对象文件都是一样的。库中的成员包括普通函数，类定义，类的对象实例等等。静态库的另一个名字叫归档文件(archive)，管理这种归档文件的工具叫
ar 。</strong></p>
<p>在下面的例子中，我们先创建两个对象模块，然后用其生成静态库。</p>
<p>头文件 say.h 包含函数 sayHello() 的原型和类 Say 的定义：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* say.h */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sayhello</span><span class="params">(<span class="type">void</span>)</span></span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Say</span> &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">char</span> *string;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Say</span>(<span class="type">char</span> *str)&#123;</span><br><span class="line">    string = str;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">sayThis</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *str)</span></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; str &lt;&lt; <span class="string">&quot; from a static library\n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">sayString</span><span class="params">(<span class="type">void</span>)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>下面是文件 say.cpp
是我们要加入到静态库中的两个对象文件之一的源码。它包含 Say 类中
sayString() 函数的定义体；类 Say 的一个实例 librarysay
的声明也包含在内：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* say.cpp */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;say.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Say::sayString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; string &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Say <span class="title">librarysay</span><span class="params">(<span class="string">&quot;Library instance of Say&quot;</span>)</span></span>;</span><br></pre></td></tr></table></figure>
<p>源码文件 sayhello.cpp
是我们要加入到静态库中的第二个对象文件的源码。它包含函数 sayhello()
的定义：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* sayhello.cpp */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;say.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">sayhello</span><span class="params">()</span></span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;hello from a static library\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面的命令序列<strong>将源码文件编译成对象文件，命令 ar
将其存进库中</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">$ g++ -c sayhello.cpp</span><br><span class="line">$ g++ -c say.cpp</span><br><span class="line">$ ar -r libsay.a sayhello.o say.o</span><br></pre></td></tr></table></figure>
<p>程序 ar 配合参数 <code>-r</code> 创建一个新库 <code>libsay.a</code>
并将命令行中列出的对象文件插入。采用这种方法，如果库不存在的话，参数 -r
将创建一个新的库，而如果库存在的话，将用新的模块替换原来的模块。</p>
<p>下面是主程序 saymain.cpp，它调用库 libsay.a 中的代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* saymain.cpp */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;say.h&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span>&#123;</span><br><span class="line">  <span class="keyword">extern</span> Say librarysay; <span class="comment">// 使用库的对象</span></span><br><span class="line">  Say localsay = <span class="built_in">Say</span>(<span class="string">&quot;Local instance of Say&quot;</span>); <span class="comment">//使用库的类定义</span></span><br><span class="line">  <span class="built_in">sayhello</span>(); <span class="comment">// 使用库的普通该函数</span></span><br><span class="line">  librarysay.<span class="built_in">sayThis</span>(<span class="string">&quot;howdy&quot;</span>);</span><br><span class="line">  librarysay.<span class="built_in">sayString</span>();</span><br><span class="line">  localsay.<span class="built_in">sayString</span>();</span><br><span class="line">  <span class="keyword">return</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该程序可以下面的命令来编译和链接：</p>
<p><code>$ g++ saymain.cpp libsay.a -o saymain</code></p>
<p>程序运行时，产生以下输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hello from a static library</span><br><span class="line">howdy from a static library</span><br><span class="line">Library instance of Say</span><br><span class="line">Local instance of Say</span><br></pre></td></tr></table></figure>
<h2 id="小结">小结</h2>
<p>上面介绍了手动通过命令编译 C++
源文件，但是面对一些大工程，源码文件数量多且依赖关系复杂时，手动编译不太现实，这时候就要依赖
make 和 Makefile 对程序进行自动编译了，简单来说就是把编译规则写好在
Makefile 里，然后通过 make 进行自动编译，具体细节可参考这个教程 <a
href="http://wiki.ubuntu.org.cn/%E8%B7%9F%E6%88%91%E4%B8%80%E8%B5%B7%E5%86%99Makefile">跟我一起写Makefile</a>。</p>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 一些基本语法</title>
    <url>/2015/11/24/C++%E5%81%9AOJ%E6%97%B6%E5%B8%B8%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<p>本文主要涉及到 C++ 一些基本语法，在做 oj 时经常用到，特此记录。</p>
<span id="more"></span>
<h2 id="字符和字符串">字符和字符串</h2>
<ul>
<li>数字转字符串：std::to_string(int)</li>
<li>字符串转数字：std::stoi(string)</li>
</ul>
<p>上面两个函数均需要 <code>#include&lt;string&gt;</code></p>
<ul>
<li>字符串可以用数组方式来访问</li>
<li>字符串长度可用其length()函数获取</li>
<li>字符串可以通过substr(i，n)方法来提取子字符串,表示从第i个字符开始提取n个字符（包括i）</li>
<li>字符串大小写转换：利用STL中的transform函数，见下面的例子</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  string s = <span class="string">&quot;abcdEFg&quot;</span>;</span><br><span class="line">  <span class="built_in">transform</span>(s.<span class="built_in">begin</span>(), s.<span class="built_in">end</span>(), s.<span class="built_in">begin</span>(), ::toupper);</span><br><span class="line">  cout &lt;&lt; s&lt;&lt;endl;   <span class="comment">//输出ABCDEFG</span></span><br><span class="line">  <span class="built_in">transform</span>(s.<span class="built_in">begin</span>(), s.<span class="built_in">end</span>(), s.<span class="built_in">begin</span>(), ::tolower);</span><br><span class="line">  cout &lt;&lt; s &lt;&lt; endl; <span class="comment">//输出abcdefg</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>单个字符大小写转换
<ul>
<li>需要记住ASCII码中A-65，a-97</li>
<li>将char c从大写转为小写可以通过下面代码</li>
</ul></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(c&gt;=<span class="string">&#x27;A&#x27;</span> &amp;&amp; c&lt;=<span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line">     c=<span class="built_in">char</span>(c+<span class="number">32</span>);</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">- 数字从<span class="type">char</span>类型转为<span class="type">int</span>类型</span><br><span class="line">  - 需要记住<span class="number">0</span>对应的ASCII码为<span class="number">48</span></span><br><span class="line">  - 一个简单的例子如下</span><br><span class="line"></span><br><span class="line">```cpp</span><br><span class="line"><span class="type">char</span> c=<span class="string">&#x27;0&#x27;</span>;</span><br><span class="line"><span class="type">int</span> a=<span class="built_in">int</span>(c);</span><br><span class="line">cout&lt;&lt;a&lt;&lt;endl; <span class="comment">//输出48</span></span><br><span class="line"><span class="type">int</span> b=<span class="built_in">int</span>(c)<span class="number">-48</span>;</span><br><span class="line">cout&lt;&lt;b&lt;&lt;endl; <span class="comment">//输出0</span></span><br></pre></td></tr></table></figure>
<h2 id="数组">数组</h2>
<h3
id="初始化数组不初始化时为随机的地址值">初始化数组（不初始化时为随机的地址值）</h3>
<ul>
<li><p>方法一：直接用数值初始化，见下面代码 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a[<span class="number">3</span>]=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125; <span class="comment">//元素依次为1,2,3</span></span><br><span class="line"><span class="type">int</span> a[<span class="number">3</span>]=&#123;<span class="number">0</span>&#125;     <span class="comment">//元素依次为0,0,0</span></span><br><span class="line"><span class="type">int</span> a[<span class="number">3</span>]=&#123;<span class="number">1</span>&#125;     <span class="comment">//元素依次为1,0,0</span></span><br></pre></td></tr></table></figure>
采用这种方法初始化时如果{}里面的元素的个数小于数组长度，则不足长度的元素默认值为0</p></li>
<li><p>方法二：for循环 ### 动态分配数组长度方法(一维)</p>
<ul>
<li>方法一：通过vector实现，需要#include &lt; vector &gt;</li>
<li>方法二：通过malloc和free实现，如下面例子就初始化了一个长度为n的数组，且数组的值为从0到n-1（这个是继承了C分配内存的特性，C++可通过<code>new</code>和<code>delete</code>来实现，见方法三）</li>
</ul></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cin&gt;&gt;n;</span><br><span class="line"><span class="type">int</span> *a=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="built_in">sizof</span>(<span class="type">int</span>)*n);</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">  a[i]=i;</span><br><span class="line"><span class="built_in">free</span>(a);</span><br></pre></td></tr></table></figure>
<ul>
<li>方法三：通过<code>new</code>和<code>delete</code>来实现,见下面代码</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cin&gt;&gt;n;</span><br><span class="line"><span class="type">int</span> *a=<span class="keyword">new</span> <span class="type">int</span>[n];</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    a[i]=i;</span><br><span class="line"><span class="keyword">delete</span> []a;</span><br></pre></td></tr></table></figure>
<h2 id="容器">容器</h2>
<h3 id="vector">vector</h3>
<ul>
<li>需要 <code>#include &lt;vector&gt;</code></li>
<li>vector的方法：
<ul>
<li>vector中的元素可以以数组下标访问</li>
<li>push_back( ) 将一个元素放到vector中</li>
<li>vector.size( ) 获取vector的大小</li>
<li>查找元素t是否在vector中</li>
</ul></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">T t;</span><br><span class="line">vector&lt;T&gt;::iterator it=<span class="built_in">find</span>(vector.<span class="built_in">begin</span>( ),vector.<span class="built_in">end</span>( ),t);</span><br><span class="line"><span class="keyword">if</span>(it == vector.<span class="built_in">end</span>( ) )</span><br><span class="line"> cout&lt;&lt;<span class="string">&quot;not found&quot;</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>其他方法（需要 <code>#include &lt;algorithm&gt;</code>）：
<ul>
<li>sort(vector.begin( )，vector.end( ) )
//针对vector数据类型的排序</li>
<li>reverse(vector.begin( )，vector.begin( )+5 ) //针对vector数据类型的
反转 ,注意：reverse(vector.begin(),vector.begin()+5)
仅仅对5个元素进行reverse操作，不包括vector.begin()+5</li>
</ul></li>
</ul>
<h3 id="map">map</h3>
<ul>
<li>需要 <code>#include &lt;map&gt;</code></li>
<li>用数组下标的形式往map中添加元素和查找元素</li>
<li>当map的key为结构体类型时，可通过重载 &lt;
来判断该如何排序，见下面的代码</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;map&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">stu</span>&#123;</span><br><span class="line">	string name;</span><br><span class="line">	<span class="type">int</span> sco;</span><br><span class="line">    <span class="comment">/*重载运算符 &lt;,达到从大到小或从小到大的排序效果，下面的代码是从小到大，如改成 return a.sco &gt;b.sco 则是从大到小 */</span></span><br><span class="line">	<span class="keyword">friend</span> <span class="type">bool</span> <span class="keyword">operator</span> &lt; (<span class="type">const</span> stu &amp;a, <span class="type">const</span> stu &amp;b)&#123;</span><br><span class="line">		<span class="keyword">return</span> a.sco &lt; b.sco;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	map&lt;stu, <span class="type">int</span>&gt; score;</span><br><span class="line">	stu tmp;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">		tmp.name = <span class="built_in">to_string</span>(i);</span><br><span class="line">		tmp.sco = i;</span><br><span class="line">		score[tmp] = i+<span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">//获取顺序排列时的第一个元素，从大到小还是从小到大要看重载的&lt;</span></span><br><span class="line">	map&lt;stu, <span class="type">int</span>&gt;::iterator it = score.<span class="built_in">begin</span>();</span><br><span class="line">	cout &lt;&lt; it-&gt;first.name &lt;&lt; <span class="string">&#x27; &#x27;</span>&lt;&lt;it-&gt;second &lt;&lt; endl;</span><br><span class="line">	<span class="comment">//获取逆序排序的第一个元素，从大到小还是从小到大要看重载的&lt;</span></span><br><span class="line">	map&lt;stu,<span class="type">int</span>&gt;::reverse_iterator rit = score.<span class="built_in">rbegin</span>();</span><br><span class="line">	cout &lt;&lt; rit-&gt;first.name &lt;&lt; <span class="string">&#x27; &#x27;</span> &lt;&lt; rit-&gt;second &lt;&lt; endl;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>遍历map</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">map&lt;T,T&gt; m;</span><br><span class="line">map&lt;T,T&gt;::iterator it;</span><br><span class="line"><span class="keyword">for</span>(it=m.<span class="built_in">begin</span>();it!=m.<span class="built_in">end</span>();it++)</span><br><span class="line">    cout&lt;&lt;it-&gt;first&lt;&lt;<span class="string">&#x27;:&#x27;</span>&lt;&lt;it-&gt;second&lt;&lt;endl;</span><br></pre></td></tr></table></figure>
<hr />
<h2 id="输入输出">输入输出</h2>
<ul>
<li>printf函数格式化数字的输出</li>
<li>数字前补0到达指定位数:
<ul>
<li>如 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a=<span class="number">3</span>,b=<span class="number">4</span>;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%04d %05d  %d&quot;</span>,a,b,b) <span class="comment">//输出为 `0003 00004 4`</span></span><br></pre></td></tr></table></figure></li>
</ul></li>
<li>可通过scanf从输入的一定格式的字符串中提取数字如：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> year,month,day;</span><br><span class="line"><span class="built_in">scanf</span>(<span class="string">&quot;%d/%d/%d&quot;</span>,&amp;year,&amp;month,&amp;day);   <span class="comment">//输入2014/09/06时，year=2014，month=9,day=6</span></span><br></pre></td></tr></table></figure>
<ul>
<li>cin或cout的类型为string时需要include <string>
<ul>
<li>结构体的数据类型可以是别的结构体，也可以是自身结构体的指针</li>
<li>结构体内部也可以放函数，函数可用来初始化一个结构体</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>CPU缓存</title>
    <url>/2015/11/21/CPU%E7%BC%93%E5%AD%98/</url>
    <content><![CDATA[<p>下面是CPU缓存的一些概念，所用命令均是在Linux平台下</p>
<ul>
<li>可通过命令getconf -a| grep CACHE | grep size
查看CPU的各级缓存大小</li>
<li>也可以通过命令lscpu | grep ^L 查看</li>
<li>CPU缓存以行（line）单位，主内存以页（page）为单位，磁盘以块（block）为单位</li>
<li>CPU缓存一般分为指令缓存（I-Cache）和数据缓存（D-Cache），且两者一般都是分开的</li>
<li>缓存控制器（cache
controller）判断CPU要获取的指令和数据是否在CPU缓存中，从<strong>一级缓存往下找，直到主内存和磁盘，且从找到的那一级开始往上面所有级缓存</strong>,如下图所示：</li>
</ul>
<p><img src="https://wulc.me/imgs/Image.png" /></p>
<ul>
<li>评判软件优秀与否的一种标准：对cpu缓存的命中率</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>CTR 预估模型简介--非深度学习篇</title>
    <url>/2018/07/15/CTR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B--%E9%9D%9E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/</url>
    <content><![CDATA[<p>本文主要介绍 CTR 预估中常用的一些模型，主要是非深度学习模型，包括
LR、GBDT+LR、FM/FFM、MLR。每个模型会简单介绍其原理、论文出处以及其一些开源实现。</p>
<span id="more"></span>
<h2 id="lrlogistic-regerssion">LR(Logistic Regerssion)</h2>
<p><strong>LR + 海量人工特征</strong>
是业界流传已久的做法，这个方法由于简单、可解释性强，因此在工业界得到广泛应用，但是这种做法依赖于特征工程的有效性，也就是需要对具体的业务场景有深刻的认识才能提取出好的特征。</p>
<h3 id="原理"><strong>原理</strong></h3>
<p>LR 是一个很简单的线性模型，其输出的值可认为是事件发生(<span
class="math inline">\(y=1\)</span>)的概率，即输出值如下式所示</p>
<p><span class="math display">\[ h(x) = p(y=1|x) =
\sigma(w^Tx+b)\]</span></p>
<p>其中<span class="math inline">\(w\)</span> 为模型参数，<span
class="math inline">\(x\)</span> 为提取的样本特征，两者均为向量，<span
class="math inline">\(b\)</span> 是偏置项。<span
class="math inline">\(\sigma\)</span> 为 sigmoid 函数，即 <span
class="math inline">\(\sigma(x) = 1/(1+e^{-x})\)</span></p>
<p>有了事件发生的概率，则事件不发生的概率为 <span
class="math inline">\(p(y=0|x) =
1-h(x)\)</span>,将这两个概率通过如下一条公式表示为</p>
<p><span class="math display">\[p(y|x) =
h(x)^y(1-h(x))^{1-y}\]</span></p>
<p>有了这个概率值，则给定 <span class="math inline">\(n\)</span>
个样本，便可通过极大似然估计来估算模型参数，即目标函数为</p>
<p><span class="math display">\[\max
\prod\_{i=1}^np(y\_i|x\_i)\]</span></p>
<p>通常我们还会对概率取 log，同时添加负号将 max
改成min，则可将目标函数改写成如下的形式</p>
<p><span class="math display">\[\min -\sum\_{i=1}^ny\_i\log
h(x\_i)+(1-y\_i)\log (1-h(x\_i))\]</span></p>
<p>上面的损失函数也叫作 <strong>log loss</strong>，实际上多分类的
<strong>cross entropy</strong> 也同以通过极大似然估计推导出来。</p>
<p>有了损失函数，便可通过优化算法来求出最优的参数，由于这是个无约束的最优化问题，可选用的方法很多，最常用的就是
gradient
descent，除此之外，另外还有基于二阶导数的牛顿法系列，适用于分布式中的
ADMM，以及由 Google 在论文 <a
href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/41159.pdf">Ad
Click Prediction: a View from the Trenches</a> 中提出的 FTRL
算法，目前也是业界普遍采用的方法，该算法具有online learning
和稀疏性的良好特性，online learning 指的是其更新方式与 SGD(stochastic
gradient descent)
相似，稀疏性指的是该算法能够解决带非光滑的L1正则项的优化问题。由于这里这篇文章主要讲述各种
CTR 预估模型，因此这里不对优化算法做展开了。</p>
<p>上面提到了 L1 正则项，就是在原来的损失函数基础上加上了 <span
class="math inline">\(C\sum\_{i=1}^m |w\_i|\)</span> 这一项,
表示各个参数的绝对值的和乘上常数 <span
class="math inline">\(C\)</span>；加上这一项后能够使得最终的求解出来的参数中大部分的
<span class="math inline">\(|w\_i|\)</span>
为0，这也是稀疏性的名称来源。稀疏性使得模型的复杂度下降，缓解了过拟合的问题，同时具有有特征筛选的能力。因为
LR 模型可以理解为对各个特征进行加权求和，如果某些特征的权重即 <span
class="math inline">\(w\_i\)</span>
为0，则可认为这些特征的重要性不高。在CTR预估中输入的是海量人工特征，因此添加
L1 正则化就更有必要了。</p>
<p>由于 L1 正则项不再是处处光滑可导的函数，因此在优化损失函数时。原来的
gradient descent 不能够直接使用，而是要通过 <a
href="https://en.wikipedia.org/wiki/Subgradient_method">subgradient</a>
的方法或前面提到的 FTRL 算法进行优化。</p>
<p>上面涵盖了 LR 模型的基本原理。而<strong>在 CTR 预估中，应用 LR
模型的重点在于特征工程。LR 模型适用于高维稀疏特征</strong>。对于
categorical 特征，可以通过 one-hot 编码使其变得高纬且稀疏。而对于
continious 特征，可以先通过区间划分为 categorical 特征再进行 one-hot
编码。同时还需要进行特征的组合/交叉，以获取更有效的特征。</p>
<h3 id="一些问题"><strong>一些问题</strong></h3>
<p>上面介绍过程中有一些结论我们直接就使用了，下面对于上面提到的某些结论做出一些解释</p>
<p><strong>1. LR 的输出为什么可以被当做是概率值？</strong></p>
<p>这部分涉及到广义线性模型(GLM，<a
href="https://en.wikipedia.org/wiki/Generalized_linear_model">Generalized
linear model</a>) 的知识，这里略过复杂的推导，直接给出结论。简单来说，LR
实际上是一个广义线性模型，其假设是二分类中 <span
class="math inline">\((y|x,\theta)\)</span>
服从伯努利分布(二项分布)，即给定输入样本 <span
class="math inline">\(x\)</span> 和模型参数 <span
class="math inline">\(\theta\)</span>,
事件是否发生服从伯努利分布。假设伯努利分布的参数 <span
class="math inline">\(\phi\)</span> ，则 <span
class="math inline">\(\phi\)</span> 可作为点击率。通过
广义线性模型的推导，能够推出 <span class="math inline">\(\phi\)</span>
的表示形式如下</p>
<p><span class="math display">\[\phi = 1/(1+e^{-\eta})\]</span></p>
<p>从上面的式子可知，<strong>LR 中的 sigmoid
函数并不是凭空来的</strong>，而式子中的 <span
class="math inline">\(\eta\)</span> 也被称为连接函数（Link function),
是确定一个 GLM 的重要部分，在 LR 中为简单的线性加权。</p>
<p>另外，如果将输出值与真实值的误差的分布假设为高斯分布，那么从 GLM
可推导出 Linear Regression，关于 GLM 详细的推导可参考这篇文章 <a
href="https://www.cnblogs.com/dreamvibe/p/4259460.html">广义线性模型（GLM）</a>。</p>
<p><strong>2. 为什么 L1 正则项能够带来稀疏性？</strong></p>
<p>这里有个很直观的回答，<a
href="https://www.zhihu.com/question/37096933/answer/70426653">l1 相比于
l2
为什么容易获得稀疏解？</a>，简单来说，就是<strong>当不带正则项的损失函数对于某个参数
<span class="math inline">\(w\_i\)</span> 的导数的绝对值小于 l1
正则项中的常数 <span class="math inline">\(C\)</span> 时，这个参数 <span
class="math inline">\(w\_i\)</span> 的最优解就是0</strong>。</p>
<p>因为求解某个参数 <span class="math inline">\(w\_i\)</span>
使得损失函数取极小值时可分两种情况讨论(下面的 <span
class="math inline">\(L\)</span> 为不带正则项的损失函数) 1）<span
class="math inline">\(w\_i&lt;0\)</span> 时, <span
class="math inline">\(L+C|w\_i|\)</span> 的导数为 <span
class="math inline">\(L&#39;- C\)</span> 2) <span
class="math inline">\(w\_i&gt;0\)</span>时, <span
class="math inline">\(L+C|w\_i|\)</span> 的导数为 <span
class="math inline">\(L&#39;+C\)</span></p>
<p>当 <span class="math inline">\(w\_i&lt;0\)</span> 时，令 <span
class="math inline">\(L&#39;- C &lt; 0\)</span>, 函数在递减；而当<span
class="math inline">\(w\_i&gt;0\)</span>时, 令 <span
class="math inline">\(L&#39;+C &gt; 0\)</span>, 函数在递增，则 <span
class="math inline">\(w\_i=0\)</span>
便是使得损失函数最小的最优解，且结合 <span class="math inline">\(L&#39;-
C &lt; 0\)</span> 和 <span class="math inline">\(L&#39;+C &gt;
0\)</span>，可得 <span class="math inline">\(C &gt;
|L&#39;|\)</span>。这便是我们上面得到的结论，上面是针对某一个参数，实际上也可以推广到所有参数上。事实上，通过
subgradient descent 求解这个问题时也能够得到相同的结论。</p>
<p><strong>3.连续特征为什么需要离散化？</strong></p>
<p>参考这个问题：<a
href="https://www.zhihu.com/question/31989952/answer/54184582">连续特征的离散化：在什么情况下将连续的特征离散化之后可以获得更好的效果？</a></p>
<p>离散化后有以下几个好处：</p>
<ol type="1">
<li>稀疏向量内积乘法运算速度快，计算结果方便存储</li>
<li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，<strong>可以通过
one-hot
编码为每个变量设置单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合</strong>；</li>
<li>离散化后可以进行<strong>特征交叉</strong>，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；</li>
<li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间要取决于具体的场景</li>
</ol>
<p><strong>4.1 为什么要对 categorical 特征做 One-hot 编码后再输入
LR？</strong></p>
<p>参考这篇文章 <a
href="http://www.jiehuozhe.com/article/3">One-Hot编码与哑变量</a>，简单来说，就是LR建模时，要求特征具有线性关系，而实际应用中很少有满足这个假设关系的，因此LR模型效果很难达到应用要求。但是通过对离散特征进行
one-hot 编码，LR
可以为某个特征中所有可能的值设置一个权重，这样就能够更准确的建模，也就能够获得更精准的模型。而
one-hot 编码后特征实际上也是做了一个 min-max
归一化，能够克服不同特征的量纲差异，同时使模型收敛更快。</p>
<h3 id="开源实现"><strong>开源实现</strong></h3>
<p>由于 LR 模型的广泛性，基本上每个机器学习库或者框架都有相关实现，如
sklearn 提供了<a
href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">单机版的实现</a>，spark
提供了<a
href="https://spark.apache.org/docs/2.3.0/mllib-linear-methods.html">分布式版本的实现</a>，腾讯开源的
Parameter Server <a href="https://github.com/Tencent/angel">Angel</a>
中也提供了 <a
href="https://github.com/Tencent/angel/blob/master/docs/algo/sona/sparselr_ftrl.md">LR+FTRL</a>
的实现，Angel 支持 Spark，目前也还在开发中 。除此之外，Github
上也有很多个人开源的实现，这里不再列举。</p>
<h2 id="ls-plmlarge-scale-piece-wise-linear-model">LS-PLM(Large Scale
Piece-wise Linear Model)</h2>
<p>LS-PLM(也叫作 MLR, Mixture of Logistics Regression)是阿里妈妈在 2017
年在论文 <a href="https://arxiv.org/abs/1704.05194">Learning Piece-wise
Linear Models from Large Scale Data for Ad Click Prediction</a>
中公开的，但是模型早在 2012 年就在阿里妈妈内部使用。这个模型在 LR
基础上进行了拓展，目的是为了解决单个 LR 无法进行非线性分割的问题。</p>
<h3 id="原理-1"><strong>原理</strong></h3>
<p>LR
是一个线性模型，模型会在数据空间中生成一个线性分割平面，但是对于非线性可分的数据，这一个线性分割面显然无法正确分割这些数据。以下图为例（摘自上面的论文），A）为一组非线性训练数据的正负样本分布；对于该问题，LR会生成
B）中的分割平面，C) 图展示的 LS-PLM 模型 则取得了较好的效果。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdhkuov7q2413hf3n14ecse0c.png"
alt="LS-PIC" />
<figcaption aria-hidden="true">LS-PIC</figcaption>
</figure>
<p>在CTR问题中，<strong>划分场景分别建模</strong>是一种常见的手法。例如，同一产品的PC/APP端，其用户的使用时间和习惯差异可能很大；比如PC可能更多是办公时间在看，而手机则是通勤时间或者临睡前使用更多。假设有hour作为特征，那么“hour=23”对于APP端更加有信息量，而对于PC可能意义不大。因此，区分PC/APP端分别建模可能提升效果。</p>
<p>LS-PLM
也是采用这个思想的，不够这里不是划分场景，而是划分数据，通过将数据划分不同的region、然后每个region分别建立
LR。</p>
<p>这里需要注意的是这里一个样本并不是被唯一分到了一个region，而是按权重分到了不同的region。其思想有点像
LDA(Latent Dirichlet allocation) 中一个单词会按照概率分到多个 topic
上。</p>
<p>论文中的公式如下</p>
<p><span class="math display">\[p(y=1|x) = g ( \sum\_{j=1}^m
\sigma(\mu\_j^T x)\eta(w\_j^Tx))\]</span></p>
<p>公式中的符号定义如下：</p>
<p>参数定义如下：</p>
<ul>
<li><span class="math inline">\(m\)</span> : region
的个数(超参数：一般是10~100)</li>
<li><span class="math inline">\(\Theta=\{\mu\_1,\dots,\mu\_m,
w\_1,\dots,w\_m \}\)</span>: 表示模型的参数，需要训练</li>
<li><span
class="math inline">\(g(\cdot)\)</span>：为了让模型符合概率定义(概率和为1)的函数</li>
<li><span class="math inline">\(\sigma(\cdot)\)</span>：将样本分到
region 的函数</li>
<li><span class="math inline">\(\eta(\cdot)\)</span>：在 region
中划分样本的函数</li>
</ul>
<p>前面提出的公式更像个框架，在论文中，只讨论了 <span
class="math inline">\(g(x) = x\)</span>, <span
class="math inline">\(\sigma\)</span> = softmax ，<span
class="math inline">\(\eta\)</span> = sigmoid
的情形，而且因此，上面的公式可写成如下的形式</p>
<p><span class="math display">\[p(y=1|x) = \sum\_{i=1}^m
\frac{e^{\mu\_i^Tx}}{\sum\_{j=1}^m
e^{\mu\_j^Tx}}\frac{1}{1+e^{-w\_i^Tx}}\]</span></p>
<p>这个公式其实已经变成了通过多个 LR 模型进行加权求和的 bagging
模式，只是这里每个模型的权重是学习出来而不是事先确定的。</p>
<p>写出了概率函数, 后面的推导跟前面的 LR
其实是一样的，也是先通过极大似然估计得到 <span
class="math inline">\(\max\)</span> 问题，添加负号后转为损失函数求 <span
class="math inline">\(\min\)</span> 问题。这里不做详细的推导了。</p>
<p>在 LS-PLM 中也是需要添加正则项的，除了在 LR 中提到的 L1
正则化，论文还提出了 <span class="math inline">\(L\_{2,1}\)</span>
正则项，表示如下</p>
<p><span class="math display">\[||\Theta||\_{2,1} = \sum\_{i=1}^d \sqrt
{\sum\_{j=1}^m(\mu\_{ij}^2+w\_{ij}^2)}\]</span></p>
<p>上式中的 <span class="math inline">\(d\)</span> 表示特征的维数，其中
<span class="math inline">\(\sqrt
{\sum\_{j=1}^m(\mu\_{ij}^2+w\_{ij}^2)}\)</span>
表示对某一维特征的所有参数进行 L2 正则化，而外侧的 <span
class="math inline">\(\sum\_{i=1}^d\)</span> 表示对所有的 feature 进行
L1 正则化，由于开方后的值必为正，因此这里也不用添加绝对值了。由于结合了
L1 和 L2 正则项，所以论文也将这个叫做<span
class="math inline">\(L\_{2,1}\)</span> 正则项。</p>
<p>由于损失函数和正则项都是光滑可导的，因此优化方面比带 L1 正则的 LR
更加简单，可选的优化方法也更多。</p>
<p>MLR 适用的场景跟 LR 一样，也是适用于高纬稀疏特征作为输入。</p>
<h3 id="开源实现-1"><strong>开源实现</strong></h3>
<p>前面提到的腾讯的 PS Angel 实现了这个算法，具体可参考<a
href="https://github.com/Tencent/angel/blob/master/docs/algo/mlr_on_angel.md">这里</a>；Angel
是用 Scala 开发的。也有一些个人开源的版本如 <a
href="https://github.com/CastellanZhang/alphaPLM">alphaPLM</a>，这个版本是用
C++ 写的，如果需要实现可以参考以上资料。</p>
<h2
id="gbdtlrgradient-boost-decision-tree-logistic-regression">GBDT+LR(Gradient
Boost Decision Tree + Logistic Regression)</h2>
<p>GBDT + LR 是 FaceBook 在这篇论文 <a
href="http://quinonero.net/Publications/predicting-clicks-facebook.pdf">Practical
Lessons from Predicting Clicks on Ads at Facebook</a>
中提出的，其思想是借助 GBDT 帮我们做部分特征工程，然后将 GBDT 的
输出作为 LR 的输入。</p>
<h3 id="原理-2"><strong>原理</strong></h3>
<p>我们前面提到的无论 LR 还是
MLR，都避免不了要做大量的特征工程。比如说构思可能的特征，将连续特征离散化，并对离散化的特征进行
One-Hot
编码，最后对特征进行二阶或者三阶的特征组合/交叉，这样做的目的是为了得到非线性的特征。但是特征工程存在几个难题：</p>
<ol type="1">
<li>连续变量切分点如何选取？</li>
<li>离散化为多少份合理？</li>
<li>选择哪些特征交叉？</li>
<li>多少阶交叉，二阶，三阶或更多？</li>
</ol>
<p>而 GBDT + LR 这个模型中，GBDT 担任了特征工程的工作，下面首先介绍一下
GBDT。</p>
<p>GBDT 最早在这篇论文 <a
href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf">Greedy Function
Approximation：A Gradient Boosting Machine</a> 中提出； GBDT
中主要有两个概念：GB(<a
href="https://en.wikipedia.org/wiki/Gradient_boosting">Gradient
Boosting</a>)和DT(Decision Tree)，Gradient Boosting 是集成学习中
boosting 的一种形式，Decision Tree
则是机器学习中的一类模型，这里不对这两者展开，只讲述在 GBDT
中用到的内容。关于决策树的介绍可参考这篇文章 <a
href="http://www.cnblogs.com/wxquare/p/5379970.html">决策树模型
ID3/C4.5/CART算法比较</a>。</p>
<p>在 GBDT 中采用的决策树是CART (Classification And Regression
Tree)，将其当做回归树使用，这里的回归树是一棵在每个树节点进行分裂的时候，给节点设定其在某个特征的的值，若样本对应的特征的值大于这个给定的值的属于一个子树，小于这个给定的值的属于另一个子树。</p>
<p>那么，构建 CART 回归树是
的关键问题就在于选择具体的特征还有这个特征上具体的值了。选择的指标是<strong>平方误差最小化准则</strong>。对于任意一个切分，其平方误差计算方式如下</p>
<ol type="1">
<li>假设切分后左子树有 <span class="math inline">\(m\)</span>
个样本，右子树有 <span class="math inline">\(n\)</span> 个</li>
<li>计算左子树样本的目标值的均值为 <span class="math inline">\(y\_m =
\frac{1}{m}\sum\_{i=1}^{m}y\_i\)</span>,
同样计算右子树样本的目标值的均值为 <span class="math inline">\(y\_n =
\frac{1}{n}\sum\_{j=1}^{n}y\_j\)</span></li>
<li>平方误差和为 <span class="math inline">\(L = \sum\_{i=1}^m(y\_i -
y\_m)^2 + \sum\_{j=1}^n(y\_j - y\_n)^2\)</span></li>
<li>对于每一个可能的切分值，我们都可计算其平方误差和 <span
class="math inline">\(L\)</span>，选择使得 <span
class="math inline">\(L\)</span> 最小的切分点即可。</li>
</ol>
<p>上面便是 GBDT 中的 “DT”
部分，用于解决一个回归问题，也就是给定一组样本，我们可以通过上面的方式来构建出一棵
CART 来拟合这组样本。下面我们来讲一下 GBDT 中的 “GB” 部分。</p>
<p>简单来说，<strong>gradient boosting
就是将若干个模型的输出进行叠加作为最终模型的输出。</strong>如下图是一个简单的例子(图片来源于提出
xgb 的论文：<a href="https://arxiv.org/pdf/1603.02754.pdf">XGBoost: A
Scalable Tree Boosting System</a>)</p>
<figure>
<img src="https://wulc.me/imgs/gbdt.png" alt="xgboost" />
<figcaption aria-hidden="true">xgboost</figcaption>
</figure>
<p>下式就是叠加了 <span class="math inline">\(T\)</span> 个 <span
class="math inline">\(f\_t(x)\)</span> 模型作为最终的模型，<span
class="math inline">\(f\_t(x)\)</span> 在 GBDT 中就是一棵 CART，当然
<span class="math inline">\(f\_t(x)\)</span> 不限于树模型。</p>
<p><span class="math display">\[F(x) = \sum\_{t=1}^Tf\_t(x)\]</span></p>
<p>在构建每棵树的时候，输入的样本不同的地方在于每个样本的目标值 <span
class="math inline">\(y\)</span>；如构建第 <span
class="math inline">\(k\)</span> 棵树，对于原始样本 <span
class="math inline">\((x\_i, y\_i)\)</span>, 其目标值变为</p>
<p><span class="math display">\[y\_{ik} = y\_i -
\sum\_{t=1}^{k-1}f\_t(x\_i)\]</span></p>
<p>即输入第 <span class="math inline">\(k\)</span> 棵树的样本变为 <span
class="math inline">\((x\_i, y\_{ik})\)</span>，所以在<strong>构建第
<span class="math inline">\(k\)</span> 棵树的时候，实际上是在拟合前
<span class="math inline">\(k-1\)</span>
棵树的输出值的和与样本真实值的残差。</strong></p>
<p>回到我们的 GBDT + LR 模型，首先通过前面提到的 GBDT
训练出一批树模型，然后样本输入每棵树后最终都会落到一个具体的叶子节点上，那我们就将这个节点标为
1，其他叶子节点标为 0，<strong>这样每棵树输出的就相当于是一个 one-hot
编码的特征</strong>。如下图是摘自 FaceBook
原始论文的图，里面有两棵树，假如输入 <span
class="math inline">\(x\)</span>
在第一棵树中落入第一个叶子节点，在第二棵树种落入第二个叶子节点，那么输入
LR 的特征为 [1, 0, 0, 0, 1].</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdjf062nsovu4v1d3bbsn1rk49.png"
alt="GBDT + LR" />
<figcaption aria-hidden="true">GBDT + LR</figcaption>
</figure>
<p>GBDT+LR
方案中每棵决策树从根节点到叶节点的路径，会经过不同的特征，此路径就是特征组合，而且包含了二阶，三阶甚至更多，因此输出的
one-hot
特征是原始特征进行交叉后的结果。而且每一维的特征其实还是可以追溯出其含义的，因为从根节点到叶子节点的路径是唯一的，因此落入到某个叶子节点表示这个特征满足了这个路径中所有节点判断条件。</p>
<p><strong>GBDT 适用的问题刚好与 LR 相反，GBDT
不适用于高纬稀疏特征，因为这样很容易导致训练出来的树的数量和深度都比较大从而导致过拟合。因此一般输入GBDT
的特征都是连续特征。</strong></p>
<p>在 CTR 预估中，会存在大量的 id 特征，对于这种离散特征，一般有两种做法
1) <strong>离散特征不直接输入到 GBDT 中进行编码</strong>，而是做 one-hot
编码后直接输入到 LR 中即可；对于连续特征，先通过 GBDT
进行离散化和特征组合输出 one-hot 编码的特征，最后结合这两种 one-hot
特征直接输入到 LR。大致框架如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdk1jok51p5u13mgv2d1p6d1hll4c.png"
alt="Real GBDT" />
<figcaption aria-hidden="true">Real GBDT</figcaption>
</figure>
<ol start="2" type="1">
<li><strong>将离散的特征也输入 GBDT
进行编码</strong>，但是只保留那些出现频率高的离散特征，这样输入 GBDT
中的 one-hot 特征的维度会遍地，同时通过 GBDT 也对原始的 one-hot
特征进行了组合和交叉。</li>
</ol>
<h3 id="一些问题-1"><strong>一些问题</strong></h3>
<p><strong>1. GBDT 中的 gradient 在哪里体现了？</strong></p>
<p>推导到现在，好像也没有提及到
gradient，其实前面<strong>拟合残差时已经用到了 gradient
的信息</strong>。</p>
<p>首先，我们要转换一下思维，我们一般在优化中使用的 gradient descent
都是对某个参数进行的，或者说是在参数空间中进行的，但是除了参数空间，还可以在函数空间中进行。如下图所示对比了两种方式(下面两张图均摘自<a
href="http://wepon.me/files/gbdt.pdf">GBDT算法原理与系统设计简介</a>)</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdjtahckkop2e81umc1l651lgi32.png"
alt="gredient descent v.s. gradient boosting" />
<figcaption aria-hidden="true">gredient descent v.s. gradient
boosting</figcaption>
</figure>
<p>在函数空间中，是对函数直接进行求导的，因此 GBDT 算法的流程如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdkhqh8gpjrb9n1mi11o6b16tj56.png"
alt="GBDT" />
<figcaption aria-hidden="true">GBDT</figcaption>
</figure>
<p>上图中的 <span class="math inline">\(\tilde{y\_i}\)</span>
就是我们前面说的第 <span class="math inline">\(i\)</span>
个样本的残差，当损失函数为平方损失即 <span
class="math display">\[L(y,F(x)) = \frac{1}{2}(y-F(x))^2\]</span></p>
<p>对 <span class="math inline">\(F(x)\)</span> 求导得出的残差为</p>
<p><span class="math display">\[\tilde{y\_i} = y\_i -
F(x\_i)\]</span></p>
<p>这正是我们前面说的样本的真实值与前面建的树的输出和的差。<strong>如果损失函数改变，这个残差值也会进行相应的改变。</strong></p>
<p><strong>2. GBDT 怎么处理分类问题？</strong></p>
<p>上面我们讲的 GBDT 是处理回归问题的，但是对于 CTR
预估这一类问题，从大分类上其实还是一个分类问题。那 GBDT
是怎么处理这个问题？</p>
<p>在回归问题中，GBDT每一轮迭代都构建了一棵树，实质是构建了一个函数
<span class="math inline">\(f\)</span>，当输入为x时，树的输出为 <span
class="math inline">\(f(x)\)</span>。</p>
<p>在多分类问题中，假设有 <span class="math inline">\(k\)</span>
个类别，那么每一轮迭代实质是构建了 <span
class="math inline">\(k\)</span> 棵树，对某个样本 <span
class="math inline">\(x\)</span> 的预测值为 <span
class="math inline">\(f\_{1}(x), f\_{2}(x), ..., f\_{k}(x)\)</span>,</p>
<p>在这里我们仿照多分类的逻辑回归，使用
softmax来产生概率，则属于某个类别 <span class="math inline">\(j\)</span>
的概率为</p>
<p><span class="math display">\[p\_{c} = \frac{\exp(f\_{j}(x))}{
\sum\_{i=1}^{k}{exp(f\_{k}(x))}}\]</span></p>
<p>通过上面的概率值，可以分别计算出样本在各个分类下的 log loss，根据上面
GBDT 在函数空间的求导，对 <span class="math inline">\(f\_1\)</span> 到
<span class="math inline">\(f\_k\)</span>
都可以算出一个梯度，也就是当前轮的残差，供下一轮迭代学习。也就是每一轮的迭代会同时产生
k 棵树。</p>
<p>最终做预测时，输入的 <span class="math inline">\(x\)</span> 会得到
<span class="math inline">\(k\)</span>
个输出值，然后通过softmax获得其属于各类别的概率即可。</p>
<p>更详细的推导可参考这篇文章：<a
href="https://zhuanlan.zhihu.com/p/25257856">当我们在谈论GBDT：Gradient
Boosting 用于分类与回归</a></p>
<h3 id="开源实现-2"><strong>开源实现</strong></h3>
<p>直接实现 GBDT + LR
的开源方案不多，但是由于两者的耦合关系并不强，因此可以先训练
GBDT，然后将原始特征通过 GBDT 转换后送入到 LR 中，GBDT
有多个高效的实现，如 <a
href="https://github.com/dmlc/xgboost">xgboost</a>，<a
href="https://github.com/Microsoft/LightGBM">LightGBM</a>。</p>
<h2 id="fmfactorization-machine">FM(Factorization Machine)</h2>
<p>FM（Factorization Machine）是于2010年在论文 <a
href="http://www.algo.uni-konstanz.de/members/rendle/pdf/Rendle2010FM.pdf">Factorization
Machines</a>
中提出，旨在解决稀疏数据下的特征组合问题。其思想是对组合特征的参数所构成的参数矩阵进行矩阵分解，从而得到每个原始特征的隐向量表示，更新特征的隐向量对数据的稀疏性具有鲁棒性。关于
FM 和 FFM ，美团点评这篇文章：<a
href="https://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html">深入FFM原理与实践</a>
其实已经写得很详细了，本文主要参考该文章进行修改。</p>
<h3 id="原理-3"><strong>原理</strong></h3>
<p>FM 可以认为是在 LR
的基础上加入特征的二阶组合，即最多有两个特征相乘，则模型可表示成如下形式</p>
<p><span class="math display">\[y(\mathbf{x}) = w\_0+ \sum\_{i=1}^n w\_i
x\_i + \sum\_{i=1}^n \sum\_{j=i+1}^n w\_{ij} x\_i x\_j \]</span></p>
<p>从模型也可以看出，其实 FM 是在 LR 基础上增加了最后的二阶交叉项。</p>
<p>从上面的公式可以看出，组合特征的参数一共有 <span
class="math inline">\(\frac{n(n−1)}{2}\)</span>
个，任意两个参数都是独立的。然而，在数据稀疏性普遍存在的实际应用场景中，<strong>二次项参数的训练是很困难的,原因是每个参数
<span class="math inline">\(w\_{ij}\)</span> 的训练需要大量 <span
class="math inline">\(x\_i\)</span> 和 <span
class="math inline">\(x\_j\)</span>
都非零的样本</strong>；由于样本数据本来就比较稀疏，满足 <span
class="math inline">\(x\_i\)</span> 和 <span
class="math inline">\(x\_j\)</span>
都非零的样本将会非常少。训练样本的不足，则会导致参数 <span
class="math inline">\(w\_{ij}\)</span>
不准确，最终将严重影响模型的性能。</p>
<p>如何解决这个问题？FM 中借鉴了矩阵分解的思想，在推荐系统中，会对
user-item 矩阵进行矩阵分解，从而每个 user 和每个 item
都会得到一个隐向量。如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdkb5qkk2ie1njv17ekj5s131k4p.png"
alt="matrix" />
<figcaption aria-hidden="true">matrix</figcaption>
</figure>
<p>类似地，所有二次项参数 <span class="math inline">\(w\_{ij}\)</span>
可以组成一个对称阵 <span
class="math inline">\(W\)</span>，那么这个矩阵就可以分解为 <span
class="math inline">\(W=V^TV\)</span>，<span
class="math inline">\(V\)</span> 的第 <span
class="math inline">\(j\)</span> 列便是第 <span
class="math inline">\(j\)</span>
维特征的隐向量。换句话说，每个参数可表示成两个隐向量的内积的形式。即
<span class="math inline">\(w\_{ij}=&lt;v\_i,v\_j&gt;\)</span>，<span
class="math inline">\(v\_i\)</span> 表示第 <span
class="math inline">\(i\)</span>
维特征的隐向量，这就是FM模型的核心思想。因此，可以将上面的方程改写成如下形式</p>
<p><span class="math display">\[y(\mathbf{x}) = w\_0+ \sum\_{i=1}^n w\_i
x\_i + \sum\_{i=1}^n \sum\_{j=i+1}^n
&lt;v\_i, v\_j&gt;x\_i x\_j \]</span></p>
<p>假设隐向量的长度为 <span
class="math inline">\(k(k&lt;&lt;n)\)</span>，二次项的参数数量减少为
<span
class="math inline">\(kn\)</span>个，远少于多项式模型的参数数量。另外，参数因子化使得
<span class="math inline">\(x\_hx\_i\)</span> 的参数和 <span
class="math inline">\(x\_ix\_j\)</span>
的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计FM的二次项参数。</p>
<p>具体来说，<span class="math inline">\(x\_hx\_i\)</span> 和 <span
class="math inline">\(x\_ix\_j\)</span> 的系数分别为 <span
class="math inline">\(&lt;v\_h,v\_i&gt;\)</span> 和 <span
class="math inline">\(&lt;v\_i,v\_j&gt;\)</span>，它们之间有共同项 <span
class="math inline">\(v\_i\)</span>。也就是说，<strong>所有包含 <span
class="math inline">\(x\_i\)</span> 的非零组合特征（即存在某个<span
class="math inline">\(j≠i\)</span>，使得 <span
class="math inline">\(x\_ix\_j≠0\)</span>）的样本都可以用来学习隐向量
<span
class="math inline">\(v\_i\)</span>，这很大程度上避免了数据稀疏性造成的影响</strong>。而在多项式模型中，<span
class="math inline">\(w\_{hi}\)</span> 和 <span
class="math inline">\(w\_{ij}\)</span> 是相互独立的。</p>
<p>另外，原始论文还对特征交叉项计算的时间复杂度做了优化，具体见如下公式</p>
<p><span class="math display">\[\sum\_{i=1}^n \sum\_{j=i+1}^n \langle
\mathbf{v}\_i, \mathbf{v}\_j \rangle x\_i x\_j = \frac{1}{2}
\sum\_{f=1}^k \left(\left( \sum\_{i=1}^n v\_{i, f} x\_i \right)^2 -
\sum\_{i=1}^n v\_{i, f}^2 x\_i^2 \right)\]</span></p>
<p>从公式可知，原来的计算复杂度为 <span
class="math inline">\(O(kn^2)\)</span>，而改进后的时间复杂度为 <span
class="math inline">\(O(kn)\)</span></p>
<p>在 CTR 预估中，对 FM 的输出进行 sigmoid 变换后与 Logistics Regression
是一致的，因此损失函数的求解方法以及优化算法都基本一致，这里不再详细展开。</p>
<p>由于 FM 可以看做是 LR
基础上加上二阶特征组合的模型，同时模型本身对稀疏性有较好的鲁棒性，因此
FM
适用范围跟LR一样，都<strong>适用于输入的特征是高纬度稀疏特征</strong>。</p>
<h3 id="开源实现-3"><strong>开源实现</strong></h3>
<p>FM 在 github 上有单机版本的开源实现 <a
href="http://ibayer.github.io/fastFM/">fastFM</a>和<a
href="https://github.com/coreylynch/pyFM">pyFM</a>， fastFM
是一个学术项目，发表了相关论文 <a
href="https://arxiv.org/abs/1505.00641">fastFM: A Library for
Factorization Machines</a>, 对 FM 进行了拓展；同时我们前面提到的腾讯的PS
Angel 中也实现了这个算法，可参考<a
href="https://github.com/Tencent/angel/blob/master/docs/algo/fm_on_angel.md">这里</a>。</p>
<h2 id="ffmfield-aware-factorization-machine">FFM(Field-aware
Factorization Machine)</h2>
<p>FFM 发表于论文 <a
href="https://www.csie.ntu.edu.tw/~cjlin//papers/ffm.pdf">Field-aware
Factorization Machines for CTR Prediction</a>， 是台大的学生在参加 2012
KDD Cup 时提出的，这个论文借鉴了论文 <a
href="https://kaggle2.blob.core.windows.net/competitions/kddcup2012/2748/media/Opera.pdf">Ensemble
of Collaborative Filtering and Feature Engineered Models for Click
Through Rate Prediction</a> 中的 field 的 概念，从而提出了 FM
的升级版模型 FFM。</p>
<h3 id="原理-4"><strong>原理</strong></h3>
<p><strong>通过引入field的概念，FFM把相同性质的特征归于同一个field。简单来说，同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field</strong>，包括用户性别、职业、品类偏好等。</p>
<p>在FFM中，每一维特征 <span
class="math inline">\(x\_i\)</span>，针对其它特征的每一种 field <span
class="math inline">\(f\_j\)</span>，都会学习一个隐向量 <span
class="math inline">\(v\_{i,f\_j}\)</span>。因此，<strong>隐向量不仅与特征相关，也与field相关。也就是说，假设有
<span class="math inline">\(f\)</span> 个 field，那么每个特征就有 <span
class="math inline">\(f\)</span> 个隐向量，与不同的 field
的特征组合时使用不同的隐向量</strong>，而原来的 FM
中每个特征只有一个隐向量。</p>
<p>实际上，FM 可以看作 FFM 的特例，是把所有特征都归属到一个 field
时的FFM模型。根据FFM的field敏感特性，同样可以导出其模型方程如下</p>
<p><span class="math display">\[y(\mathbf{x}) = w\_0 + \sum\_{i=1}^n
w\_i x\_i + \sum\_{i=1}^n \sum\_{j=i+1}^n \langle \mathbf{v}\_{i, f\_j},
\mathbf{v}\_{j, f\_i} \rangle x\_i x\_j \]</span></p>
<p>其中，<span class="math inline">\(f\_j\)</span> 是第 <span
class="math inline">\(j\)</span> 个特征所属的 field。如果隐向量的长度为
<span class="math inline">\(k\)</span>，那么FFM的二次参数有 <span
class="math inline">\(nfk\)</span> 个，远多于FM模型的 <span
class="math inline">\(nk\)</span> 个。此外，由于隐向量与 field
相关，FFM二次项并不能够化简，其预测复杂度是 <span
class="math inline">\(O(kn^2)\)</span>。</p>
<p>其实，FFM 是在 FM
的基础上进行了更细致的分类，增加了参数的个数使得模型更复杂，能够拟合更复杂的数据分布。但是损失函数的推导以及优化的算法跟前面的
FM 还有 LR 都是一样的，因此这里不再赘述。</p>
<p>FFM 适用的场景跟 FM 和 LR
一样，<strong>适用于输入的特征是高维稀疏特征</strong>。</p>
<h3 id="开源实现-4"><strong>开源实现</strong></h3>
<p>FFM 最早的开源实现是台大提供的 <a
href="https://github.com/guestwalk/libffm">libffm</a>，去年开源的 <a
href="https://github.com/aksnzhy/xlearn">xlearn</a>
中也提供了该算法的实现，提供的 api 比 libffm 更加友好。</p>
<p>另外，由于 FM/FFM 可以看做是 LR
加了特征交叉的增强版本，对输入的特征的特点要求一致，因此上面的 GBDT+LR
也可以直接套到 GBDT+FM/FFM 上，值得一提的是，还是台大的学生，在 2014 由
Criteo 举办的比赛上，通过 GBDT+FFM 的方案夺冠，其实现细节可参考 <a
href="https://github.com/guestwalk/kaggle-2014-criteo">kaggle-2014-criteo</a>。</p>
<h2 id="小结">小结</h2>
<p>在非深度学习中，可以看到主流的几个模型基本都是基于 LR 进行的拓展或将
LR 与其他模型结合。原因是 LR
模型简单，具有良好的理论基础，可解释性强，能够获取各个特征的重要性，且能够直接输出概率值。但是应用
LR 过程中无法避免且最为重要的一点就是人工特征工程，特征决定了上限，虽然
FM/FMM 和 GBDT+LR
在一定程度上起到了自动特征工程的作用，但是需要人工特征还是占主要部分。</p>
<p>后面要讲的深度学习的方法在一定程度上能够缓解这个问题，因为深度学习能够通过模型自动学习出有效特征，因此，深度学习也被归类为表示学习(
Representation
Learning)的一种;但是，没有免费午餐的，特征工程的便利性带来的是特征的不可解释性，所以怎么选取还是要根据具体的需求和业务场景。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>CTR 预估模型简介--深度学习篇</title>
    <url>/2018/07/16/CTR%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/</url>
    <content><![CDATA[<p>本文主要介绍 CTR 预估中一些深度学习模型，包括
FNN、Wide&amp;Deep、PNN、DIN、
Deep&amp;Cross等。每个模型会简单介绍其原理、论文出处以及其一些开源实现。</p>
<span id="more"></span>
<h2
id="fnnfactorization-machine-supported-neural-network">FNN(Factorization-machine
supported Neural Network)</h2>
<h3 id="模型结构"><strong>模型结构</strong></h3>
<p>FNN 是伦敦大学于 2016 在一篇论文中发表的，模型的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1chv050jnp9ada415od111t1ae39.png"
alt="FNN" />
<figcaption aria-hidden="true">FNN</figcaption>
</figure>
<p>FNN 假设输入数据的格式是离散的类别特征(表示为 one-hot
编码)，且每个特征属于一个 field，通过 embedding
层将高纬稀疏特征映射成低维稠密特征后，再作为多层感知机(MLP)的输入。</p>
<p>一般来说，embedding 层的参数可以随机初始化，但是在 FNN 中，初始化
embedding 是采用通过 FM
预训练得到的每个特征的隐向量，<strong>这样初始化的好处是将预训练的向量作为初始化参数时，能够让模型的参数在初始化的时候就处于较优的位置(训练的目的其实就是为了得到最优的模型参数)，能够加快收敛的过程</strong>，至于效果方面，则不一定会优于随机初始化的情况，因为随机初始化经过多轮的迭代也可能会收敛同样的效果。</p>
<h3 id="相关论文"><strong>相关论文</strong></h3>
<p>提出 FNN 的论文 <a href="https://arxiv.org/abs/1601.02376">Deep
Learning over Multi-field Categorical Data: A Case Study on User
Response Prediction</a>是<a
href="http://wnzhang.net/">张伟楠</a>博士在伦敦大学时发表的，张伟楠博士还有很多与
RTB 相关的论文，具体可参看其主页。</p>
<h3 id="开源实现"><strong>开源实现</strong></h3>
<p>论文作者在 github 上的 <a
href="https://github.com/wnzhang/deep-ctr">deep-ctr</a> 这个仓库中提供了
FNN 的代码，但是是 Theano 实现的；后来作者又将代码更新为 Tensorflow
框架实现的，详见 <a
href="https://github.com/Atomu2014/product-nets">product-nets</a>，这个仓库也包含了后面要介绍的
PNN 的实现代码。</p>
<h2 id="widedeep">Wide&amp;Deep</h2>
<h3 id="模型结构-1"><strong>模型结构</strong></h3>
<p>Wide &amp; Deep 是 Google
在2016年6月中发布的。模型结合了传统的特征工程与深度模型：既有 Wide 的 LR
模型，也有 Deep 的 NN 模型。</p>
<p>其结构如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1ce0lvnsf1pdvp3r3gfg0n1ltv33.png"
alt="model structure" />
<figcaption aria-hidden="true">model structure</figcaption>
</figure>
<p>wide 部分其实就是 LR，deep部分其实就是 FNN，只是 deep 部分中的
embedding 层不用 FM 训练得到的隐向量初始化。根据论文的描述，wide
部分主要负责memorization， deep 部分主要负责
generalization；memorization
主要指的是记住出现过的样本，可以理解为拟合训练数据的能力，generalization
则是泛化能力。</p>
<p>根据论文的实验，wide &amp; deep 比起单纯的 wide 或 deep
都要好，但是根据我后面的实验以及网上的一些文章，wide
部分仍然需要人工设计特征，在特征设计不够好的情况下，wide&amp;deep
整个模型的效果并不如单个的 deep 模型。</p>
<p>Wide&amp;Deep 中还允许输入连续的特征，这点与 FNN
不同，连续特征可以直接作为 Wide 部分或 Deep 部分的输入而无需 embedding
的映射，具体如下图所示。</p>
<figure>
<img src="https://wulc.me/imgs/image_1ce0lpmmdcus1aa7upklnatjg9.png"
alt="input feature" />
<figcaption aria-hidden="true">input feature</figcaption>
</figure>
<h3 id="相关论文-1"><strong>相关论文</strong></h3>
<p>Wide&amp;Deep 是 Google 在论文 <a
href="https://arxiv.org/abs/1606.07792">Wide &amp; Deep Learning for
Recommender Systems</a> 中提出的，论文原来是用于 Google Play
的推荐中，但是推荐和CTR实际上是同一类的问题：排序问题，所以也可以迁移到CTR预估的领域。</p>
<h3 id="开源实现-1"><strong>开源实现</strong></h3>
<p>由于 Wide&amp;Deep 是 google 提出的，因此在自家的框架 Tensorflow
中提供了 Wide&amp;Deep API，具体的使用方法可参考官方的文档 <a
href="https://www.tensorflow.org/tutorials/wide_and_deep">TensorFlow
Wide &amp; Deep Learning Tutorial</a>。</p>
<h2 id="pnnproduct-based-neural-networks">PNN(Product-based Neural
Networks)</h2>
<h3 id="模型结构-2"><strong>模型结构</strong></h3>
<p>PNN 是上海交大在2016年发表的，FNN 是在 PNN
的基础上进行了改进，就是增加了特征的二阶交叉项。因此，FNN 和 PNN
的关系，类似于 LR 和 FM 的关系，只是 FNN 和 PNN 均是对原始特征进行了
embedding 映射。PNN 模型的结构如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1chv5blf02te19u2qo0a1721i19.png"
alt="PNN" />
<figcaption aria-hidden="true">PNN</figcaption>
</figure>
<p>特征经过 embedding
层映射后，有两种乘积的操作，第一种是跟1做外积，实际上就是将映射后的特征进行拼接,
得到了上图中的 z
向量部分；第二种是与其他特征分别两两进行内积，得到了上图中的 p
向量部分，这个操作其实就相当于进行了特征交叉，只是这种交叉是在 embedding
映射后。再后面的结构其实又是一个多层感知机了。</p>
<h3 id="相关论文-2"><strong>相关论文</strong></h3>
<p>PNN 是在上海交大于2016年在这篇论文 <a
href="https://arxiv.org/abs/1611.00144">Product-based Neural Networks
for User Response Prediction</a> 中提出。</p>
<h3 id="开源实现-2"><strong>开源实现</strong></h3>
<p>PNN 的作者在 github 上的 <a
href="https://github.com/Atomu2014/product-nets">product-nets</a>
上开源了其代码，通过 Tensorflow 实现，代码里面也包含了 FNN，DeepFM
等一些其他模型的实现。</p>
<h2 id="deepfm">DeepFM</h2>
<h3 id="模型结构-3"><strong>模型结构</strong></h3>
<p>DeepFM 是华为诺亚方舟实验室在 2017 提出的用于 CTR 预估的模型，DeepFM
其实就是模仿 Wide&amp;Deep，只是将 Wide 部分替换成了
FM，所以创新性并不算大。其结构如下所示，</p>
<figure>
<img src="https://wulc.me/imgs/image_1ceiplk5lcfkbn9cia1p5j12pc2m.png"
alt="DeepFM" />
<figcaption aria-hidden="true">DeepFM</figcaption>
</figure>
<h3 id="相关论文-3"><strong>相关论文</strong></h3>
<p>DeepFM 是在这篇论文中提出的 <a
href="https://arxiv.org/abs/1703.04247">DeepFM: A Factorization-Machine
based Neural Network for CTR Prediction</a></p>
<h3 id="开源实现-3"><strong>开源实现</strong></h3>
<p>作者没有公开源码，上面提到的 <a
href="https://github.com/Atomu2014/product-nets">product-nets</a>
提供了这个模型的实现代码，同时 <a
href="https://github.com/ChenglongChen/tensorflow-DeepFM">tensorflow-DeepFM</a>
也提供了一个 tensorflow 实现的版本，star 数是 github 上较高的了。</p>
<h2 id="dindeep-interest-network">DIN(Deep Interest Network)</h2>
<h3 id="模型结构-4"><strong>模型结构</strong></h3>
<p>从之前提到的几个模型可知，CTR预估中的深度学习模型的基本思路是将原始的高维稀疏特征映射到一个低维空间中，也即对原始特征做了embedding操作，之后一起通过一个全连接网络学习到特征间的交互信息和最终与CTR之间的非线性关系。这里值得注意的一点是，在对用户历史行为数据进行处理时，每个用户的历史点击个数是不相等的，我们需要把它们编码成一个固定长的向量。以往的做法是，对每次历史点击做相同的embedding操作之后，将它们做一个求和或者求最大值的操作，类似经过了一个pooling层操作。提出
DIN 的论文认为这个操作损失了大量的信息，于是引入了 attention
机制(其实就是一种加权求和)。</p>
<p>DIN 是阿里妈妈在 2017 年提出的，其模型的结构如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1ci11abueoek1so1rhpeo2a3639.png"
alt="Deep Interest Network" />
<figcaption aria-hidden="true">Deep Interest Network</figcaption>
</figure>
<p>Activation Unit 的结构如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1ci11cdgs9ol13jn1iv113icqpc3m.png"
alt="Activation Unit" />
<figcaption aria-hidden="true">Activation Unit</figcaption>
</figure>
<p>DIN模型在对用户的表示计算上引入了attention network
(也即图中的Activation Unit)
。DIN把用户特征、用户历史行为特征进行embedding操作，视为对用户兴趣的表示，之后通过attention
network，对每个兴趣表示赋予不同的权值。<strong>这个权值是由用户的兴趣和待估算的广告进行匹配计算得到的</strong>，如此模型结构符合了之前的两个观察——用户兴趣的多样性以及部分对应。attention
network 的计算公式如下， <span class="math inline">\(V_u\)</span>
代表用户表示向量， <span class="math inline">\(V_i\)</span>
代表用户兴趣表示向量， <span class="math inline">\(V_a\)</span>
代表广告表示向量，<span class="math inline">\(w_i\)</span>
表示各个用户兴趣表示向量的权重，<span class="math inline">\(g\)</span>
是 Activation Unit 的逻辑，论文中提出了一种如上图的 Activation Unit
所示，当然也可自行设计新的 Activation 方法。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cfp1c0l61j781euse3uul14mh13.png"
alt="DIN" />
<figcaption aria-hidden="true">DIN</figcaption>
</figure>
<h3 id="相关论文-4"><strong>相关论文</strong></h3>
<p>DIN 是在论文 <a href="https://arxiv.org/abs/1706.06978">Deep Interest
Network for Click-Through Rate Prediction</a> 中提出的。</p>
<h3 id="开源实现-4"><strong>开源实现</strong></h3>
<p>论文作者在 github 上的仓库 <a
href="https://github.com/zhougr1993/DeepInterestNetwork">DeepInterestNetwork</a>
开源了其代码，通过 Tensorflow 实现。</p>
<h2 id="deepcross">Deep&amp;Cross</h2>
<h3 id="模型结构-5"><strong>模型结构</strong></h3>
<p>PNN
进行了特征的二阶交叉，目前是为了获得信息量更多的特征，除了二阶，三阶四阶甚至更高阶的特征会更加有区分度；Deep&amp;Cross
就是一个能够进行任意高阶交叉的神经网络。</p>
<p>Deep&amp;Cross 是 StandFord 和 Google 与 2017年 提出的，类似于
Wide&amp;Deep，模型也是由两部分组成，分别是 Deep network 和 Cross
network，该模型结构如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1cdm0f6me1dn61p6l2i511kqerd9.png"
alt="Deep &amp; Cross" />
<figcaption aria-hidden="true">Deep &amp; Cross</figcaption>
</figure>
<p><span class="math inline">\(x_i\)</span> 表示可由如下公式确定</p>
<figure>
<img src="https://wulc.me/imgs/image_1ci130kk62821o3t1r4t7d6ojc43.png"
alt="x0" />
<figcaption aria-hidden="true">x0</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1ci1318p11e2v15q8agn12c1po24g.png"
alt="xl" />
<figcaption aria-hidden="true">xl</figcaption>
</figure>
<p>从上面两条公式可知，Cross network 中的第 <span
class="math inline">\(l+1\)</span> 层的神经元由最原始的输入和第 <span
class="math inline">\(l\)</span> 层的神经元共同决定，因此第 <span
class="math inline">\(l\)</span> 层相当于对原始特征进行了 <span
class="math inline">\(l\)</span> 阶交叉。</p>
<h3 id="相关论文-5">相关论文</h3>
<p>Deep&amp;Cross 是在这篇论文 <a
href="https://arxiv.org/abs/1708.05123">Deep &amp; Cross Network for Ad
Click Predictions</a> 中提出的。</p>
<h3 id="开源实现-5">开源实现</h3>
<p>论文没有公开代码，<a
href="https://github.com/shenweichen/DeepCTR">DeepCTR</a> 中提供了
Deep&amp;Cross 的 tensorflow 实现，可供参考。</p>
<h2 id="总结">总结</h2>
<p>在CTR预估中，模型适用传统方法还是深度学习方法，其实是一个<strong>海量离散特征+简单模型</strong>
和 <strong>少量连续特征+复杂模型</strong>
的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。特征与模型往往是对偶的，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS下安装python的sklearn模块</title>
    <url>/2015/10/23/CentOS%E4%B8%8B%E5%AE%89%E8%A3%85python%E7%9A%84sklearn%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<p>sklearn是python的一个机器学习库，封装了很多常用的机器学习算法，在数据挖掘中经常会用到这个库。在MacOS上安装只需要一条命令，可以说是最简单的。在windows下也可以直接安装封装好这些模块的程序如winpython等。但是我在CentOS下的安装可谓痛苦，用pip安装会有各种依赖，用yum解决依赖又会因为支持sklearn的库（如numpy，scipy）版本不够新而导致sklearn无法安装。</p>
<span id="more"></span>
<p>最后还是在<a
href="http://scikit-learn.org/stable/install.html">官方的安装指南</a>中找到了解决方法，所以官方文档真的是非常有参考价值，而且权威性也是很好的。下面说说具体的解决方法。</p>
<p>解决方法实际上是安装一个类似于Windows下winpython的程序，在Linux中就是<a
href="https://www.continuum.io/why-anaconda">Anaconda</a>,可以认为Anaconda是封装了python和sklearn等第三方库的一个程序。下面讲一下安装步骤以及注意事项。</p>
<p>安装非常简单：</p>
<p>1.下载安装文件
安装可以选择32位或者64位以及python的版本（提供2.7和3.5），下面下载的是64位的python
2.7
版本的andconda，若要下载其他版本的请移步到https://www.continuum.io/downloads</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wget https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.5.0-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<p>2.运行安装文件<br />
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bash Anaconda2-2.5.0-Linux-x86_64.sh</span><br></pre></td></tr></table></figure></p>
<p>在安装过程中会询问安装的目录，默认是当前目录下创建anaconda2目录，也可以自己在询问时输入指定目录。安装到最后还会问是否要在~/.bashrc中添加环境变量，添加环境变量的作用是为了方便某些命令的输入如python、conda等。连配置环境变量的功夫都省去了。</p>
<p>3.安装第三方模块 因为Anaconda采用了<a
href="http://conda.pydata.org/">conda</a>作为包管理程序，所以更新或卸载已安装的模块、安装其他模块都可以用conda命令。
如<code>conda update scikit-learn</code>可以更新已经安装了的sklearn，<code>conda remove scikit-learn</code>可以卸载已安装的sklearn。<code>conda install</code>可以安装新的第三方模块。简直就是一个加强版的python
shell。</p>
<p>到这里安装就结束了，比起之前折腾的一个一个包来安装的要方便得多。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos下安装python2.7</title>
    <url>/2015/03/23/Centos%E4%B8%8B%E5%AE%89%E8%A3%85python2-7/</url>
    <content><![CDATA[<p>Centos是一个Linux
发行版，因为稳定性得到了比较广泛的应用，但是存在着软件版本不够新的问题。比如说python版本为2.6，但是python
2.7对第三方模块的支持往往更好，下面就说一下怎么在Centos下安装python2.7。</p>
<span id="more"></span>
<h2 id="简介">简介</h2>
<p>需要注意的是，系统内部的一些命令依赖python环境运行（比如说yum），所以假如卸载系统自带的python环境会导致这些程序不能运行，所以建议<strong>不要动原来系统自带的python
而在另外一个路径安装python
2.7，调用python命令时调用这个安装路径的python路径即可</strong>。</p>
<p>安装利用了<a
href="http://conda.pydata.org/miniconda.html">miniconda</a>,里面集成了python
和 <a href="http://conda.pydata.org/docs/">conda</a>，conda
可以简单认为是一个包管理系统，允许在同一台机器上安装同一软件的多个版本。</p>
<h2 id="安装步骤">安装步骤</h2>
<h3 id="下载安装脚本">下载安装脚本</h3>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<h3 id="运行安装脚本">运行安装脚本</h3>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sh Miniconda-latest-Linux-x86_64.sh -b -p /usr/local/miniconda</span><br></pre></td></tr></table></figure>
<p><code>-p</code> 参数会指定安装的目录,可以根据自己的修改</p>
<h3 id="修改环境变量">修改环境变量</h3>
<p>因为系统自带的 python 2.6 命令路径为
<code>/usr/bin/python</code>,而<code>/usr/bin</code>本来就存在系统的环境变量PATH中，所以<strong>假如输入python的时候希望进入python
2.7，那么python2.7
的环境变量就必须添加在PATH前，因为系统是从前往后读PATH变量的。</strong></p>
<p>修改<code>~/.bashrc</code> 或
<code>/etc/profile</code>（前者针对的是当前用户，后者针对的是全部用户，可参考<a
href="http://wulc.me/2015/11/21/Linux%E4%B8%8B%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/">这篇文章</a>）
, 在文件末尾添加环境变量如下:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/miniconda:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<p><code>/usr/local/miniconda</code>是你安装python的目录，一定要添加在<code>$PATH</code>前，否则输入python还是会跑回原来2.6版本的python。</p>
<p>然后输入<code>source ~/.bashrc</code>或<code>source /etc/profile</code>让配置生效。</p>
<p>这时输入python应该就能看到 python 2.7 了。</p>
<h3 id="安装第三方模块">安装第三方模块</h3>
<p>因为上面安装的miniconda中除了python还安装了conda，而conda提供了包管理机制，所以可以通过conda安装第三方模块。</p>
<p>如<code>conda install numpy</code>就安装了numpy模块。更详细内容参考<a
href="http://conda.pydata.org/docs/">conda官方文档</a>。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Code Complete 阅读笔记-创建高质量的代码(1)</title>
    <url>/2018/10/18/Code%20Complete%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%88%9B%E5%BB%BA%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E4%BB%A3%E7%A0%81(1)/</url>
    <content><![CDATA[<p>最近在看<a
href="https://github.com/WuLC/resources/blob/master/code-complete-2nd-edition.pdf">Code
Complete</a>（中文译作代码大全），一本关于代码构建的书。虽然研究生阶段做的东西与算法结合比较紧密，找工作的岗位也叫算法工程师，但是始终觉得算法工程师首先也得是个工程师，而不应该仅仅是调参师，因此一些基本的工程能力还是不可或缺的。本文主要是创建高质量的代码部分的的两章笔记：第
6 章（可以工作的类）、第 7
章（高质量的子程序），主要给出了在构建类和子程序过程中的一些建议。</p>
<span id="more"></span>
<h2 id="可以工作的类working-class">可以工作的类（Working class）</h2>
<h3 id="良好的类接口">良好的类接口</h3>
<p>创建高质量的类，第一步也可能是最重要的一步就是创建一个良好的接口，而这又涉及到两部分：<strong>抽象和封装</strong></p>
<p>对于抽象，有以下建议</p>
<ol type="1">
<li><strong>类的接口应该展示一致的抽象层次</strong>,
也就是说如果某个类实现了不止一个 ADT(abstract data
type)，那么就应该把这个类重新组织为一个或多个定义更加明确的
ADT，如下所示的 cpp 代码中混合了不同层次抽象的类接口</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EmployeeCensus</span>: <span class="keyword">public</span> ListContainer &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// The abstraction of these routines is at the “employee” level.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddEmployee</span><span class="params">( Employee employee )</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RemoveEmployee</span><span class="params">( Employee employee )</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//The abstraction of these routines is at the “list” level.</span></span><br><span class="line">  <span class="function">Employee <span class="title">NextItemInList</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">Employee <span class="title">FirstItem</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">Employee <span class="title">LastItem</span><span class="params">()</span></span>;</span><br><span class="line">  ...</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这个类展现了两个 ADT： Employee 和
ListContainer，原因是使用容器类或其他类库来实现内部逻辑，但是却<strong>没有把使用容器类或其他类库这一事实隐藏起来</strong>，如下是修改过有着一直抽象层次的类接口</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EmployeeCensus</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// The abstraction of all these routines is now at the “employee” level.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddEmployee</span><span class="params">( Employee employee )</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RemoveEmployee</span><span class="params">( Employee employee )</span></span>;</span><br><span class="line">  <span class="function">Employee <span class="title">NextEmployee</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">Employee <span class="title">FirstEmployee</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">Employee <span class="title">LastEmployee</span><span class="params">()</span></span>;</span><br><span class="line">  ...</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// That the class uses the ListContainer library is now hidden.</span></span><br><span class="line">  ListContainer m_EmployeeList;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>没有采取 EmployeeCensus 继承 ListContainer 的方式，是因为
<strong>EmployeeCensus 与 ListContainer 不是 “is a” 的关系</strong>,
因为 EmployeeCensus 中可能还会有排序、统计等 ListContainer
不支持的操作。</p>
<ol start="2" type="1">
<li><p><strong>提供成对的服务</strong>。大多数操作都有与其相对应、相等以及相反的操作，如上面的第一个和最后一个，添加和删除等。所以在设计一个类的时候，要检查每一个公共子程序，决定是否需要另一个与其互补的操作，但是也不要盲目地创建</p></li>
<li><p><strong>把不相关的信息转移到其他类</strong>。如果某个类中一半子程序使用着该类的一半数据，而另一半子程序则使用另一半的数据，这时其实已经把两个类混在一起使用了，需要拆开。</p></li>
</ol>
<p><strong>抽象通过提供一个可以让你忽略实现细节的模型来管理复杂度，而封装则强制阻止你看到细节</strong>。两个概念比较相似，关于封装，有以下建议</p>
<ol type="1">
<li><p><strong>尽可能限制类和成员的可访问性</strong>。当犹豫着子程序的可访问性应设为
public、protected、private
中哪一种时，经验之举是采用最严格且可行的访问级别。</p></li>
<li><p><strong>不要公开暴露成员数据</strong>。即不要直接访问成员数据，而是通过
<code>Get</code> 、 <code>Set</code> 子程序进行访问和修改。</p></li>
<li><p><strong>留意过于紧密的耦合关系</strong>。耦合指的是两个类之间关联的紧密程度，这种关联通常是约松越好，因此可以有以下一些指导建议</p></li>
</ol>
<ul>
<li>尽可能限制类和成员的可访问性</li>
<li>避免友元类/友元函数</li>
<li>避免在公开接口中暴露成员数据</li>
</ul>
<h3 id="设计和实现问题">设计和实现问题</h3>
<h4 id="包含has-a与继承is-a">包含(has a)与继承(is a)</h4>
<p>从英文上便可区分两者，包含指的是将某个对象作为类的成员，而继承则是在原来的对象之上进行拓展。</p>
<p>关于包含，需要<strong>警惕有超过约 7
个数据成员的类</strong>，因为某些研究表明人们在做事情时能记住的离散项目的个数是
7 ± 2，如果一个类包含超过约 7
个数据成员，可考虑将其分解为几个更小的类。</p>
<p>关于继承，其目的是通过<strong>定义能为两个或更多的派生类提供共有元素的基类从而写出更精炼的代码</strong>，在使用继承时，需要考虑</p>
<p>（1）成员函数是否应对派生类可见？是否应该有默认实现？默认实现能够被覆盖？
（2）继承需要遵循 Liskov 替换原则(Liskov Substitution Principle，LSP),
简单来说就是<strong>对于基类中定义的所有子程序，用在它的任何一个派生类中时的含义都应该是相同的</strong>，而不应该存在着不同派生类在使用同一个基类方法时需要区分其返回的值的单位等细节。
（3) 派生类中的成员函数不要与基类中不可覆盖的成员函数重名
（4）使用多态来避免类型检查, 对于下面的代码，应该用基类的 shape.Draw()
的方法来替代 <code>shape.DrawCircle()</code> 和
<code>shape.DrawSquare()</code>，从而避免这些类型检查。 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span> ( shape.type ) &#123;</span><br><span class="line">  <span class="keyword">case</span> Shape_Circle:</span><br><span class="line">    shape.<span class="built_in">DrawCircle</span>();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> Shape_Square:</span><br><span class="line">    shape.<span class="built_in">DrawSquare</span>();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
（5）避免让继承体系过深，建议继承的层次在 2-3 层，派生类的个数在 7±2
（6）<strong>让所有数据都是
private</strong>，如果派生类需要访问基类的属性，应该提供 protected 的
accessor function。</p>
<p>那么，<strong>何时使用包含，何时使用继承</strong>？</p>
<ol type="1">
<li>如果多个类共享数据而非行为，应该创建这些类可以包含的共用对象</li>
<li>如果多个类共享行为而非数据，应该让它们从共同的基类继承而来，并在基类里面定义公用的子程序</li>
<li>如果过多个类既共享数据也共享行为，应该让它们从一个共同过的基类继承，并在基类里面定义共用的数据和子程序</li>
</ol>
<h4 id="成员函数数据成员构造函数">成员函数、数据成员、构造函数</h4>
<p>关于成员函数和数据成员有以下建议</p>
<p>（1) 让类中的子程序的数量尽可能少 （2)
减少类调用的不同子程序的数量（也叫扇入/fan
in，因为类用到其他类的数量越高，其出错率也越高 （3)
对其他类的子程序的间接调用要尽可能少，比图说 A 对象中创建了 B
对象，应该避免 A 对象直接调用 B 对象中的方法，即
<code>A.B().b_action()</code> （4)
减少类和类之间的互相合作的范围，应尽量让下面这些数字尽可能小，包括实例化的对象的种类、实例化对象上直接调用的不同的子程序的数量、调用由其他对象返回的对象的子程序的数量。</p>
<p>关于构造函数有以下建议</p>
<p>（1）应该尽可能在构造函数中初始化所有的数据成员 （2）<strong>用
private
构造函数来强制实现单例模式</strong>。单例模式指的是一个类只有一个对象，实现的具体方法是把类的所有构造函数都隐藏起来，然后对外提供一个static
的 <code>GetInstance()</code> 子程序，如下所示（Java 示例）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java Example of Enforcing a Singleton with a Private Constructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MaxId</span> &#123;</span><br><span class="line">  <span class="comment">// Private Constructor</span></span><br><span class="line">  <span class="keyword">private</span> <span class="title function_">MaxId</span><span class="params">()</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> MaxId <span class="title function_">GetInstance</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> m_instance;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Here is the single instance. </span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">MaxId</span> <span class="variable">m_instance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MaxId</span>();</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）优先使用 deep copies，除非论证可行，才采用 shallow copies。因为
deep copies 在开发和维护方面都比 shallow copies 简单，shallow copies
需要增加很多代码用于引用计数、确保安全地复制对象、安全地比较对象以及安全地删除对象等。而这些代码是很容易出错的，除非有充分的理由，否则就应该避免它们。</p>
<h2
id="高质量的子程序high-quality-routines">高质量的子程序（High-Quality
Routines）</h2>
<p>创建子程序的必要性不言而喻：能够重用代码、提高可移植性、良好子程序命名甚至能够达到自我注解的作用等等。</p>
<h3 id="内聚性">内聚性</h3>
<p>对子程序而言，<strong>内聚性指的是子程序中各种操作之间联系的紧密程度</strong>。像
Cosine()
（余弦函数）这样的函数就是内聚性很强的，因为整个程序只完成了一项功能；而CosinAndTan()
(余弦与正切)
这个函数的内聚性就比较弱，因为它完成了多余一项的操作。我们的目标<strong>是让每一个子程序只把一件事做好，不再做其他事情</strong>，这也是功能上的内聚性，虽然也有一些其他的内聚性，但是功能上的内聚性是最佳的一种内聚性。</p>
<h3 id="命名">命名</h3>
<p>好的子程序命名非常重要，命名应该遵循以下原则</p>
<p>（1）描述子程序所做的事情，一般采用<strong>动宾结构</strong>；除了面向对象语言中的类可以忽略宾语，因为对象本身已经包含在调用语句总了，如
<code>document.Print(), orderInfo.Check()</code> 等。
（2）<strong>避免使用无意义、模糊或表达不清的动词</strong>。有些动词的含义非常灵活，可以延伸到涵盖几乎任何含义。像<code>HandleCalculation(), PerformServices(), OutputUser(), ProcessInput(), DealWithOutput()</code>
这些子程序名称根本不能说明子程序是做什么的。这时候要采用更具体的词语，比如说将<code>HandleOutput</code>
改成 <code>FormatAndPrintOutput</code>
就会清晰很多；假如是子程序本身的设计问题而导致了无法采用更具体的词，那么就需要重新组织这个子程序了。
（3）<strong>给函数命名时要对返回值有所描述</strong>。这里的有所描述并不是显式地描述返回值类型，而是通过函数名体现，如
<code>customerID.next(),printer.isReady()</code> 等都较好地体现了返回值
（4）<strong>准确适用对仗词</strong>。命名时遵循对仗词的命名规则有助于保持一致性，从而也提高可读性。下面是一些通用的对仗词。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cqimiqmf9d918cn2dcn2t84v1c.png"
alt="对仗词" />
<figcaption aria-hidden="true">对仗词</figcaption>
</figure>
<p>（5）给常用的操作建立命名规则。如下是作者列举的某个例子，这些方法是某个工程里面获取对象
id
的所有方法，其作用一致，但是到了后来，没人能记住哪个对象应该用哪些子程序了。所以应该一开始就应该统一获取
id 的子程序名称，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">employee.id.Get()</span><br><span class="line">dependent.GetId()</span><br><span class="line">supervisor()</span><br><span class="line">candidata.id()</span><br></pre></td></tr></table></figure>
<h3 id="参数与返回值">参数与返回值</h3>
<p>关于参数和返回值有以下建议</p>
<p>（1）<strong>按照输入-修改-输出的顺序排列参数</strong>。而不是按照字母顺序排列，还可以考虑采用某种表示输入、修改、输出的命名规则，如可以给这些参数名字加上
<code>i_, m_, o_</code> 前缀。
（2）如果几个子程序都用了类似的一些参数，应该让这些参数的排列顺序保持一致。这样可以产生一定的记忆效应
（3）把状态变量或错误变量放到最后。就是将那些表明发生了错误的变量放到函数的最后，这些参数只是附属于主程序的主要功能，而且是仅用于输出的参数。
（4）不要把子程序的参数用于工作变量。如下的代码中 <code>inputVal</code>
就不应该被这么用, 在 C++ 中可以用 <code>const</code>
参数来做这一限制。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">Sample</span><span class="params">( <span class="type">int</span> inputVal )</span> &#123;</span><br><span class="line">  inputVal = inputVal * CurrentMultiplier( inputVal );</span><br><span class="line">  inputVal = inputVal + CurrentAdder( inputVal );</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> inputVal;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="5" type="1">
<li>关于返回值，要检查所有可能的返回路径。也就是要确保在所有可能的情况下该函数都会返回值。<strong>在函数开头用一个默认值来初始化返回值</strong>是一个很好的做法，这种方法能够在未正确地设置返回值时提供一张保险网。</li>
</ol>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Delayed FeedBack In Computational Advertising</title>
    <url>/2020/12/05/Delay%20FeedBack%20In%20Computational%20Advertising/</url>
    <content><![CDATA[<p>转化是有延迟的，即在点击发生后过一段时间用户可能才会发生转化，且往往转化漏斗越深，延迟的时间越长；在计算广告中，delayed
feedback 主要影响下面两个场景</p>
<ol type="1">
<li>CVR 模型的训练</li>
<li>基于后验的调价策略</li>
</ol>
<p>对于场景1，影响体现在（1）过早把样本送入模型，把最终会转化但是还没回传
label
的事件当做负例，导致模型低估（2）过晚把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，导致模型没能及时更新</p>
<p>对于场景2，影响体现控制器控制 cost/value=target
时，分母会小于实际值，导致控制的不稳定</p>
<p>本文主要介绍三篇 paper 针对这个问题在场景 1
的一些解决思路，其中涉及到的一些方法也能应用到场景 2 中（而如果问题 1
能被较好地解决，也能基于预估值而不是后验数据进行调价）</p>
<span id="more"></span>
<p>第一篇 paper
是较早提出的一个解决方法，引入了一个隐变量辅助建模，同时对延迟时间单独建模，总体建模思路比较值得学习
第二篇 paper 是对第一篇 paper 的拓展，第一篇 paper
是通过指数分布建模回传延迟的时间的，而这篇 paper 则借鉴了 KDE(Kernel
density estimation) 来学习任意分布去建模回传延迟时间 第三篇 paper
则是比较了几种方法在离线数据和在线实验的效果，改动主要是在 loss function
上；其中就包括了第一篇 paper 的方法，以及其他一些利用了
positive-unlabeled learning/importance sampling 等方法推导出来出新的
loss。</p>
<h2 id="modeling-delayed-feedback-in-display-advertising2014">Modeling
Delayed Feedback in Display Advertising(2014)</h2>
<p>这篇 paper 是 criteo 在 2014 年发表的一篇对 delayed feedback 建模的
paper，建模思路比较值得学习。针对这篇 paper 可参考之前写过的一篇文章</p>
<p><a
href="http://wulc.me/2020/05/17/Modeling%20Delayed%20Feedback%20in%20Display%20Advertising%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Modeling
Delayed Feedback in Display Advertising》 阅读笔记</a></p>
<h2
id="a-nonparametric-delayed-feedback-model-for-conversion-rate-prediction2018">A
Nonparametric Delayed Feedback Model for Conversion Rate
Prediction(2018)</h2>
<p>这篇 paper 是在第一篇 paper
基础上对回传延迟函数做了改进，第一篇回传延迟使用了指数分布来建模，这里则借助了
KDE（<a
href="https://en.wikipedia.org/wiki/Kernel_density_estimation">Kernel
density estimation</a>） 的思想用任意分布来代替第一篇 paper
的指数分布，而这正是 paper 名字中 <a
href="https://en.wikipedia.org/wiki/Nonparametric_statistics">nonparametric</a>
意思的含义。</p>
<p>基本符号定义跟第一篇 paper 差不多</p>
<figure>
<img src="https://wulc.me/imgs/SurvivalAnalytics.jpg" alt="notion" />
<figcaption aria-hidden="true">notion</figcaption>
</figure>
<p>Paper 中主要通过 <a
href="https://en.wikipedia.org/wiki/Survival_analysis">Survival
analysis</a> 的方法来推导, 简单来说，survival analysis
主要研究如下领域</p>
<blockquote>
<p>Survival analysis is a branch of statistics for analyzing the
expected duration of time until one or more events happen, such as death
in biological organisms and failure in mechanical systems.</p>
</blockquote>
<p>Paper 中使用到的 survival analysis 概念和推论如下</p>
<figure>
<img src="https://wulc.me/imgs/SA_assumption.jpg" alt="assumption" />
<figcaption aria-hidden="true">assumption</figcaption>
</figure>
<p>第一篇 paper 其实也用了上面的推论，<span
class="math inline">\(f(t)\)</span> 是指数分布的 pdf，<span
class="math inline">\(s(t)\)</span> 是指数分布的 cdf，而 <span
class="math inline">\(h(t)\)</span> 则是第一篇 paper 中的 <span
class="math inline">\(\lambda(x)\)</span></p>
<p>而从上面的表达可知，求解出 <span class="math inline">\(s(t)\)</span>
的关键是求出 hazard function <span class="math inline">\(h(x)\)</span>,
hazard function 的含义是当前时刻第一次发生事件的 event rate;
相比于第一篇直接令 <span class="math inline">\(h(x) = \lambda(x) =
w\\_dx\)</span>, 这里借鉴了 Kernel density estimation 的思想将 hazard
function 写成如下形式（<span
class="math inline">\(L\)</span>是一个超参，表示时间轴上的 <span
class="math inline">\(L\)</span>个 pseudo-points）</p>
<p><span class="math display">\[h(d\_i; x\_i, V) =
\sum\_{l=1}^{L}\alpha\_l(x\_i;V)k(t\_l, d\_i)\]</span></p>
<p>下图更直观地描述了这种形式是如何拟合任意分布的</p>
<figure>
<img src="https://wulc.me/imgs/SAKDE.jpg" alt="KDE" />
<figcaption aria-hidden="true">KDE</figcaption>
</figure>
<p>上面中的 <span class="math inline">\(\alpha\_l,
k\)</span>定义如下，直观来看，<span
class="math inline">\(\alpha\_l\)</span> 表示当前的 pseudo-point
对总体的 hazard function 的贡献，<span class="math inline">\(k(t\_l,
\tau)\)</span> 表示离当前的 pseudo-point <span
class="math inline">\(t\_l\)</span>越近的训练样本，对当前的 pseudo-point
<span class="math inline">\(t\_l\)</span>的参数 <span
class="math inline">\(V\_l\)</span> 的影响越大（想象 bp 时各个 <span
class="math inline">\(V\_l\)</span>的 gradient）</p>
<p><span class="math display">\[\alpha\_l(x\_i; V) =
(1+\exp(-V\_{l}^{T}x\_i))^{-1}\]</span></p>
<p><span class="math display">\[k(t\_l, \tau) =
\exp(-\frac{(t\_l-\tau)^2}{2h^2})\]</span></p>
<p>写出了 hazard function 后，根据公式（2）有</p>
<figure>
<img src="https://wulc.me/imgs/survivalFunction.jpg"
alt="survival function" />
<figcaption aria-hidden="true">survival function</figcaption>
</figure>
<p>则 paper1 的的回传延迟概率可写成如下形式</p>
<p><span class="math display">\[p(d\_i|x\_i, c\_i = 1) = s(d\_i; x\_i, V
)h(d\_i; x\_i, V)\]</span></p>
<figure>
<img src="https://wulc.me/imgs/nonparametricf2.jpg" alt="probability" />
<figcaption aria-hidden="true">probability</figcaption>
</figure>
<p>训练的算法就跟 paper1 中的 EM 算法一样</p>
<figure>
<img src="https://wulc.me/imgs/nonparametric_EM.jpg" alt="EM" />
<figcaption aria-hidden="true">EM</figcaption>
</figure>
<p>上面这种形式是借鉴了 KDE 的思想，KDE 可以理解为一种可写出任意分布的
pdf 的方法，关于这部分的推导这里有一个直观的回答：<a
href="https://www.zhihu.com/question/27301358/answer/105267357">什么是核密度估计？如何感性认识？</a></p>
<h2
id="addressing-delayed-feedback-for-continuous-training-with-neural-networks-in-ctr-prediction2019">Addressing
Delayed Feedback for Continuous Training with Neural Networks in CTR
prediction(2019)</h2>
<p>这是 Twitter 发的一篇 paper，主要对比了几种方法在 delayed feedback
问题上的效果</p>
<h3 id="faked-nagative-weighted">Faked nagative weighted</h3>
<p>Delay feedback 的问题也可以从另一个角度去理解，观察到的样本的分布是
biased distribution <span
class="math inline">\(b\)</span>,但是需要求解真实的样本的分布 <span
class="math inline">\(p\)</span>的期望；而 <a
href="https://en.wikipedia.org/wiki/Importance_sampling">importance
sampling</a> 是解决这个问题的一个方法，这个方法在 Wikipedia
上的简单介绍如下</p>
<blockquote>
<p>In statistics, importance sampling is a general technique for
estimating properties of a particular distribution, while only having
samples generated from a different distribution than the distribution of
interest</p>
</blockquote>
<p>zhihu 上一个更通俗的解释见 <a
href="https://zhuanlan.zhihu.com/p/41217212">重要性采样（Importance
Sampling</a>），则 paper 中的可将真实分布的期望写成如下形式</p>
<p><span class="math display">\[E\_p[\log f\_{\theta}(y|x)] =
E\_b[\frac{p(x,y)}{b(x,y)} f\_{\theta}(y|x)]\]</span></p>
<p>即在观察到的 biased distribution <span
class="math inline">\(b\)</span> 上对样本进行加权 <span
class="math inline">\(w(x,y) = \frac{p(x,y)}{b(x,y)}\)</span>，则 loss
function 可写成如下形式</p>
<figure>
<img src="https://wulc.me/imgs/FakeNegativeWeightedLoss.jpg"
alt="loss func" />
<figcaption aria-hidden="true">loss func</figcaption>
</figure>
<p>这个方法会将所有的样本在一开始都当做负样本，然后在正样本回传时多传一个正样本，假设
<span class="math inline">\(N\)</span>是全部样本，<span
class="math inline">\(M\)</span>是其中的正样本，则有</p>
<p><span class="math display">\[b(y=1|x) = \frac{M}{M+N} =
\frac{\frac{M}{N}}{1+\frac{M}{N}} =
\frac{p(y=1|x)}{1+p(y=1|x)}\]</span></p>
<p><span class="math display">\[b(y=0|x) = 1- b(y=1|x)=
\frac{1}{1+p(y=1|x)}\]</span></p>
<p>即上面公式(7)可被写成下面公式(10), 即需要给分布 <span
class="math inline">\(b\)</span> 中的正样本加的权重为<span
class="math inline">\(1+p(y=1|x)\)</span>, 负样本的权重为 <span
class="math inline">\(p(y=0|x)(1+p(y=1|x))\)</span></p>
<figure>
<img src="https://wulc.me/imgs/FakeNegativeWeightedLoss1.jpg"
alt="loss func1" />
<figcaption aria-hidden="true">loss func1</figcaption>
</figure>
<p>但是这里的 <span class="math inline">\(p\)</span> 是未知的，因此
paper 中利用了模型的预估值 <span
class="math inline">\(f\_{\theta}\)</span> 来近似</p>
<p>此外，importance sampling 也被应用在强化学习中的 off-policy
策略中，简单来说就是通过行为策略(behavior strategy) <span
class="math inline">\(b\)</span> 产生的序列分布来优化目标策略(target
strategy) <span class="math inline">\(π\)</span> 价值函数，关于
on-policy 与 off-policy 的区别可参考这个回答 <a
href="https://www.zhihu.com/question/57159315/answer/465865135">强化学习中on-policy
与off-policy有什么区别？</a> ）</p>
<h3 id="fake-negative-calibration">Fake negative calibration</h3>
<p>这个方法直接让模型学习 biased distribution <span
class="math inline">\(b\)</span>,然后基于上面 Faked nagative weighted
中推导出来的公式反推出 <span
class="math inline">\(p(y=1|x)\)</span>的概率，即由</p>
<p><span class="math display">\[b(y=1|x) = \frac{M}{M+N} =
\frac{\frac{M}{N}}{1+\frac{M}{N}} = \frac{p(y=1|x)}{1+p(y=1|x)}
\]</span></p>
<p>可推出</p>
<p><span class="math display">\[p(y=1|x) = \frac{b(y=1|x)}{1-b(y=1|x)}
\]</span></p>
<p>这种方法可以认为是一种 post
calibration，除此之外，也有一种方法是在训练的时候就做了纠正的，也叫做
prior correction，基本思路就是在训练的时候对预估的 logit
做一层转换，简单推导如下</p>
<p>假设真实的分布下, 正样本的数量是 <span
class="math inline">\(P\)</span>，负样本的数量是 <span
class="math inline">\(N\)</span>，</p>
<p>则 serving 是输出的概率值应该是</p>
<p><span class="math display">\[\frac{P}{P+N} =
\frac{1}{1+e^{-x}}\]</span></p>
<p>但是在 training
时，由于上面的机制使得每条样本都会以负样本的形式出现一次，
同时假设会对负样本采样，采样率为 <span class="math inline">\(r\)</span>,
则有</p>
<p><span class="math display">\[\frac{P}{r*(P+N)+P} =
\frac{1}{1+e^{-x^{*}}}\]</span></p>
<p>通过对上面的变换有</p>
<p><span class="math display">\[\frac{P}{r*(P+N)+P}
=  \frac{P/(P+N)}{r+P/(P+N)} =  \frac{1/(1+e^{-x})}{r +
1/(1+e^{-x})}\]</span></p>
<p>则令</p>
<p><span class="math display">\[\frac{1/(1+e^{-x})}{r +
1/(1+e^{-x})}=\frac{1}{1+e^{-x^{*}}}\]</span></p>
<p>可推导出</p>
<p><span class="math display">\[x^{*} = -(\ln r+
\ln(1+e^{-x}))\]</span></p>
<p>即在训练时计算 logit，不使用 <span
class="math inline">\(\frac{1}{1+e^{-x}}\)</span> 而是使用 <span
class="math inline">\(\frac{1}{1+e^{-x^{*}}}\)</span></p>
<h3 id="positive-unlabeled-learning">Positive-Unlabeled Learning</h3>
<p>paper 关于里面基本没有推导，详细的推导可参考 <a
href="http://cseweb.ucsd.edu/~elkan/posonly.pdf">Learning Classifiers
from Only Positive and Unlabeled Data</a>,
基本思路跟第一篇比较像，这里就不详细展开了，主要引用了里面一些关键的推导步骤</p>
<blockquote>
<p>A key assumption about the training data is that they are drawn
randomly from <span class="math inline">\(p(x,y,s)\)</span>, and for
each tuple <span class="math inline">\(&lt; x,y,s &gt;\)</span> that is
drawn, only <span class="math inline">\(&lt; x,s &gt;\)</span> is
recorded. Here <span class="math inline">\(s\)</span> is the observed
label and <span class="math inline">\(y\)</span> is the actual label,
which might not have occurred yet. Along with this, it is assumed that
labeled positive examples are chosen completely randomly from all
positive examples, i.e. <span class="math inline">\(p(s = 1|x, y = 1) =
p(s = 1|y = 1)\)</span></p>
</blockquote>
<p>基于上面的 assumption 有</p>
<figure>
<img src="https://wulc.me/imgs/PUAsumption.jpg" alt="assumption" />
<figcaption aria-hidden="true">assumption</figcaption>
</figure>
<blockquote>
<p>The value of the constant <span class="math inline">\(c = p(s = 1|y =
1)\)</span> can be estimated using a trained classifier <span
class="math inline">\(g\)</span> and a validation set of examples. Let
<span class="math inline">\(V\)</span> be such a validation set that is
drawn from the overall distribution <span class="math inline">\(p(x, y,
s)\)</span> in the same manner as the nontraditional training set. Let
<span class="math inline">\(P\)</span> be the subset of examples in
<span class="math inline">\(V\)</span> that are labeled (and hence
positive). The estimator of <span class="math inline">\(p(s = 1|y =
1)\)</span> is the average value of <span
class="math inline">\(g(x)\)</span> for <span
class="math inline">\(x\)</span> in <span
class="math inline">\(P\)</span>. That is <span
class="math inline">\(\frac{1}{n}\sum\_{x \in P}g(x)\)</span></p>
</blockquote>
<p>求解环节，所有样本的 期望/likelihook 可写成如下形式</p>
<figure>
<img src="https://wulc.me/imgs/PUMLE.jpg" alt="MLE" />
<figcaption aria-hidden="true">MLE</figcaption>
</figure>
<p>则最终的 loss 函数形式如下</p>
<figure>
<img src="https://wulc.me/imgs/PU_finalloss.jpg" alt="pu-loss" />
<figcaption aria-hidden="true">pu-loss</figcaption>
</figure>
<h2 id="总结">总结</h2>
<p>本文主要介绍了对 delay feedback 问题的几种解决方法，其中第一篇 paper
引入了一个隐变量，同时对转化延迟和转化分别建模，建模思路比较值得学习；第二篇
paper 则是对第一篇 paper
的转化延迟模型做了改进；第三篇则介绍了几种在一开始将所有样本都当做负样本，并在正样本回传的时候再进一次模型，但是这样会导致
training 和 serving 不一致（正负样本比例不一致），对此 paper
也提出了几种解决方法。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Code Complete 阅读笔记-创建高质量的代码(2)</title>
    <url>/2018/10/31/Code%20Complete%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%88%9B%E5%BB%BA%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E4%BB%A3%E7%A0%81(2)/</url>
    <content><![CDATA[<p>本文主要是 Code Complete 中创建高质量的代码部分的的两章笔记：第 8
章（防范式编程）、第 9
章（伪代码编码过程），介绍了如何进行防范式编程（defensive
programming），即<strong>保护程序免遭非法输入数据的破坏</strong>，目的其实就是增强程序的鲁棒性；同时介绍了如何通过伪代码编码方法来创建类和子程序。</p>
<span id="more"></span>
<h2 id="防御式编程defensive-programming">防御式编程（defensive
programming）</h2>
<p>这里的防御式编程的主要思想是：<strong>子程序不应该因为传入错误的数据而被破坏，哪怕是由其他子程序产生的错误数据</strong>。下面主要就是讲述一些方法来处理这类问题</p>
<h3 id="断言assertion">断言（assertion）</h3>
<p>assert 关键字在多门语言中均有出现，如 Python， Java，c++
等；其目的就是非常肯定某个条件表达式是成立的，否则就是出错了，如确保分母不为
0 等。而应用在防范式编程中，可以用来检查如下条件</p>
<ul>
<li>输入参数和输出参数的取值处于预期的范围内</li>
<li>子程序开始（或结束）执行时，文件或流是打开（或关闭）的状态</li>
<li>子程序开始（或结束）执行时，文件或流的读写位置处于开头（或结尾）的状态</li>
<li>子程序开始（或结束）执行时，某个容器是空的（满的）</li>
<li>文件或流已用只读、只写或可读可写的方式打开</li>
<li>仅用于输入的变量的值没有被子程序修改</li>
<li>指针非空</li>
<li>传入子程序的数组或其他容器的 size 能容纳设定的数据元素个数</li>
<li>........</li>
</ul>
<p>需要注意的是，断言只是在开发阶段被编译到目标代码中，而在生成产品代码是并不编译进去，以降低系统的性能。</p>
<p>关于使用断言，有如下的建议</p>
<ul>
<li><strong>用错误处理代码来处理预期会发生的情况，而用断言来处理绝对不应该发生的状况</strong></li>
<li><strong>避免把执行代码放到断言中</strong>，因为这样会导致关闭断言时，编译器很可能就把这些代码排除在外,正确的做法是先将执行代码的结果在断言外用变量存起来，如下所示
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// bad</span><br><span class="line">assert PerformAction() == True</span><br><span class="line"></span><br><span class="line">//good</span><br><span class="line">result = PerformAction() </span><br><span class="line">assert result == True</span><br></pre></td></tr></table></figure></li>
<li><strong>用断言来注解并验证前条件（precondition）和后条件（postcondition）</strong>。简单来说，前条件就是在执行函数前需要为函数准备好的条件，后条件则是在函数执行后要完成的任务。</li>
</ul>
<h3 id="错误处理技术">错误处理技术</h3>
<p>上面提到用断言来处理绝对不应该发生的状况，而用错误处理代码来处理预期会发生的情况，如网络阻塞等。那么该怎么处理那些可能发生的错误呢？本章给出了如下可行的方法</p>
<ul>
<li><strong>返回中立值</strong>。如数值计算结果返回0，字符串可以返回空字符，指针操作可以返回一个空指针等。</li>
<li><strong>返回下一个正确的数据</strong>。如在处理数据流的时候，如果发现某一条记录已经损坏，可以继续读下去知道又找到一条正确记录为止，比如说以每秒
100 次的速度读取体温计的数据，那么如果某一次得到的数据有误，只需再等上
1/100 秒然后继续读取即可。</li>
<li><strong>返回与前一次相同的数据</strong>。同样是上面的体温计的例子，如果在某次读取中没有获得数据，可以简单地返回前一次的读取结果，这是根据实际的应用情况决定的，在某些变化较大的场景下不能这么使用。</li>
<li><strong>使用最接近的合法值</strong>。比如说汽车的速度盘，倒车时无法显示负值的速度，因此简单地显示0，即最接近的合法值。</li>
<li><strong>把警告信息记录到日志文件中，然后继续执行</strong>。</li>
<li><strong>返回一个错误码</strong>。即只让系统的某些部分处理错误，其他部分不在本地处理错区，而是简单地报告说有错误发生。</li>
<li><strong>调用错误处理子程序或对象</strong>。把错误处理都集中在一个全局的错误处理子程序或对象中。</li>
<li>....</li>
</ul>
<h3 id="异常">异常</h3>
<p>异常是把代码中的错误或异常事件传递给调用代码的一种特殊手段。异常的基本结构是：子程序使用
<code>throw</code> 跑出一个异常对象，再被调用链上层其他子程序的
<code>try-catch</code> 语句捕获。</p>
<p>使用异常时有以下建议</p>
<ul>
<li><strong>只有在真正例外的情况下才抛出异常</strong>。也就是说<strong>假如子程序局部能够处理这个错误就不要抛出异常</strong>；因为异常虽然能够增加程序的鲁棒性，但是会使程序的复杂性增加。调用子程序的代码需要了解呗调用的代码中可能会抛出的异常，因此异常弱化了封装性。</li>
<li><strong>避免在构造函数和析构函数中抛出异常</strong>。比如在C++里只有当对象完全构造后才可能调用析构函数，也就是说，如果在构造函数的代码里抛出异常，就不会调用析构函数，从而造成潜在的资源泄露问题。</li>
<li><strong>在合适的抽象层次抛出异常</strong>。即抛出的异常应该与子程序接口的抽象层次一致的。如下所示，第一个例子中
<code>GetTaxId()</code> 将更底层的 <code>EOFException</code>
返回给调用方,
这样破坏了封装性。与之相反的是第二个例子，<code>GetTaxId()</code>
里的异常处理代码可能只要把一个 <code>io_disk_not_ready</code> 异常映射为
<code>EmployeeDataNotAvailable</code> 异常就好了。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 抛出抽象层次不一致的异常的类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Employee</span> &#123;</span><br><span class="line">    ....</span><br><span class="line">    <span class="keyword">public</span> TaxId <span class="title function_">GetTacId</span><span class="params">()</span> <span class="keyword">throws</span> EOFException &#123;</span><br><span class="line">        ....</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个在一致的抽象层次上抛出的异常的类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Employee</span> &#123;</span><br><span class="line">    ....</span><br><span class="line">    <span class="keyword">public</span> TaxId <span class="title function_">GetTacId</span><span class="params">()</span> <span class="keyword">throws</span> EmployeeDataNotAvailable &#123;</span><br><span class="line">        ....</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>把项目中对异常的使用标准化</strong>。为了保持异常处理尽可能便于管理，可以用以下几种途径把对异常的使用标准化
<ul>
<li>某些语言允许抛出的类型多种多样，如C++ 就可以抛出对象、数据以及指针，
因此应该为可以抛出哪些种类的异常建立一个标准；可以考虑只抛出从
<code>std::exception</code> 基类派生出来的对象</li>
<li>考虑创建项目的特定异常类，用作项目所有可能抛出的异常的基类</li>
<li>规定在何种场合先允许代码使用 <code>throw-catch</code>
语句在局部对错误进行处理</li>
<li>规定在何种场合允许代码抛出不在局部进行处理的异常</li>
</ul></li>
</ul>
<h3 id="隔离程序">隔离程序</h3>
<p>隔栏（barricade）是一种容损策略，与防火墙类似，当火灾发生时，防火墙能阻止火势从建筑物的一个部位向其他部位蔓延。而以防御式编程为目的而进行隔离的一种方法，就是<strong>把某些接口选定为
“安全”
区域的边界。对穿越安全区域边界的数据进行合法性校验，并当数据非法时做出对策</strong>，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1cr7k9der10aa1s21qbdoqj1pif9.png"
alt="隔离程序" />
<figcaption aria-hidden="true">隔离程序</figcaption>
</figure>
<p>同样的可以在类的层次中使用这种方法，<strong>类的公用方法可以假设数据是不安全了，需要负责检查数据并进行清理。一旦类的公用
方法接受了数据，那么类的私有方法就可以假定数据都是安全的了</strong>。</p>
<p>隔栏的使用使断言和错误处理有了清晰的区分，<strong>隔栏外部的程序应使用错误处理技术</strong>，在哪里对数据做任何假定都是不安全的；而在<strong>隔栏的内部的程序就应该使用断言技术</strong>，因为传进来的数据应该已在通过隔栏时被清理过了。</p>
<h3 id="小结">小结</h3>
<p>防御式编程能够让错误更容易发现和修改，并减少错误对产品代码的破坏，增加程序的鲁棒性，但是过度的使用也会引起问题。如果在每一个能够想到的提防用一种能想到的方法检查从参数传入的数据，那么程序将会变得臃肿而缓慢，而且引入了额外的代码增加了软件的复杂度。因此需要考虑好在那些重要的地方进行防御，然后因地制宜地调整进行防御式编程的优先级。</p>
<h2 id="伪代码编码过程">伪代码编码过程</h2>
<p>这一章主要关注创建类及其子程序的一种方式：伪代码编码。伪代码编程过程是一种通过书写伪代码而更加高效的创建程序代码的专门方法。</p>
<h3 id="伪代码">伪代码</h3>
<p>关于使用伪代码有以下指导原则</p>
<ul>
<li>用类似英语的语言来精确描述特定操作</li>
<li>避免使用目标编程语言中的语法元素，而应该在一个比代码本身略高的层次上进行设计</li>
<li>在意图层面上编写伪代码，即用伪代码去描述解决问题的方法的意图，而不是写如何在目标语言中实现这个方法</li>
</ul>
<p>如下是一段违背了上面的指导原则的伪代码，这段代码的意图不明确，而且包含了
C 语言的具体语法以及编码细节（返回1表示null）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">increment resource number by 1</span><br><span class="line">allocate a dlg struct using malloc</span><br><span class="line">if malloc() returns NULL then return 1</span><br><span class="line">invoke OSrsrc_init to initialize a resource for the operating system</span><br><span class="line">*hRsrcPtr = resource number</span><br><span class="line">return 0</span><br></pre></td></tr></table></figure>
<p>下面是针对同样功能所写的伪代码，比起上面的就要好很多了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Keep track of current number of resources in use</span><br><span class="line">    If another resource is available</span><br><span class="line">        Allocate a dialog box structure</span><br><span class="line">        If a dialog box structure could be allocated</span><br><span class="line">            Note that one more resource is in use</span><br><span class="line">            Initialize the resource</span><br><span class="line">            Store the resource number at the location provided by the caller</span><br><span class="line">        Endif</span><br><span class="line">    Endif</span><br><span class="line">Return true if a new resource was created; else return false</span><br></pre></td></tr></table></figure>
<p>使用这种风格的伪代码能够带来以下好处</p>
<ul>
<li>伪代码使得评审更加容易。无须检查源代码就可以评审细节设计</li>
<li>伪代码支持反复迭代精化的思想。从高层设计开始，将其精化为伪代码，然后再把伪代码精化为源代码。这样持续不断的小步精化，可以在推向更低的细节层次的同时，不断检查已形成的设计；及时修复各个层次的错误</li>
<li>伪代码使变更更加容易。这跟<strong>在产品最具可塑性的阶段进行变动</strong>的原则是相同的</li>
<li>伪代码比其他形式的设计文档更加容易维护。使用其他方法时，设计和代码是分离的，当其中之一变动时，两者就不再一致，而使用伪代码编程时，伪代码中的语句将会变为代码中的注释。</li>
</ul>
<h3 id="通过伪代码创建子程序">通过伪代码创建子程序</h3>
<p>通过伪代码创建子程序主要包括以下步骤</p>
<ol type="1">
<li>设计子程序</li>
<li>编写子程序的代码</li>
<li>检查代码</li>
<li>收尾工作</li>
<li>按照需要重复上述步骤</li>
</ol>
<h4 id="设计子程序">设计子程序</h4>
<p>设计子程序可以从以下角度出发</p>
<p>（1）检查先决条件。即检查子程序与整体设计是否匹配，是否是真正必需的，至少是间接需要的
（2）定义子程序要解决的问题。应该详细说明如下问题</p>
<ul>
<li>子程序将要隐藏的信息</li>
<li>传给这个子程序的各项输入</li>
<li>从该子程序得到的输出</li>
<li>调用程序前确保有关的前条件成立</li>
<li>在子程序将控制权交回给调用方之前，确保其后条件的成立</li>
</ul>
<p>（3）为子程序命名，这一部分在<a
href="http://wulc.me/2018/10/18/Code%20Complete%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%88%9B%E5%BB%BA%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84%E4%BB%A3%E7%A0%81%281%29/">上一篇笔记</a>有提及
（4）决定如何测试子程序
（5）在标准库中搜寻可用的功能。即如果在标准库中已经有该子程序特定的功能的实现，可以直接使用而不重复造轮子
（6）研究算法和数据类型
（7）编写伪代码。首先为子程序编写一般性注释，然后为子程序编写高层次的伪代码。如下所示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 一般性注释</span><br><span class="line">This routine outputs an error message based on an error code</span><br><span class="line">supplied by the calling routine. The way it outputs the message</span><br><span class="line">depends on the current processing state, which it retrieves</span><br><span class="line">on its own. It returns a value indicating success or failure.</span><br><span class="line">// 伪代码</span><br><span class="line">set the default status to &quot;fail&quot;</span><br><span class="line">look up the message based on the error code</span><br><span class="line">if the error code is valid</span><br><span class="line">if doing interactive processing, display the error message</span><br><span class="line">interactively and declare success</span><br><span class="line">if doing command line processing, log the error message to the</span><br><span class="line">command line and declare success</span><br><span class="line">if the error code isn&#x27;t valid, notify the user that an internal error</span><br><span class="line">has been detected</span><br><span class="line">return status information</span><br></pre></td></tr></table></figure>
<h4 id="编写子程序代码">编写子程序代码</h4>
<p>主要过程就是<strong>在伪代码的每一句话下填入代码</strong>。如下所示</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* This routine outputs an error message based on an error code</span></span><br><span class="line"><span class="comment">supplied by the calling routine. The way it outputs the message</span></span><br><span class="line"><span class="comment">depends on the current processing state, which it retrieves</span></span><br><span class="line"><span class="comment">on its own. It returns a value indicating success or failure.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">Status <span class="title">ReportErrorMessage</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    ErrorCode errorToReport</span></span></span><br><span class="line"><span class="params"><span class="function">    )</span> </span>&#123;</span><br><span class="line">    <span class="comment">// set the default status to &quot;fail&quot;</span></span><br><span class="line">    Status errorMessageStatus = Status_Failure;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// look up the message based on the error code</span></span><br><span class="line">    Message errorMessage = <span class="built_in">LookupErrorMessage</span>( errorToReport );</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if the error code is valid</span></span><br><span class="line">    <span class="keyword">if</span> ( errorMessage.<span class="built_in">ValidCode</span>() ) &#123;</span><br><span class="line">        <span class="comment">// determine the processing method</span></span><br><span class="line">        ProcessingMethod errorProcessingMethod = <span class="built_in">CurrentProcessingMethod</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// if doing interactive processing, display the error message</span></span><br><span class="line">        <span class="comment">// interactively and declare success</span></span><br><span class="line">        <span class="keyword">if</span> ( errorProcessingMethod == ProcessingMethod_Interactive ) &#123;</span><br><span class="line">            <span class="built_in">DisplayInteractiveMessage</span>( errorMessage.<span class="built_in">Text</span>() );</span><br><span class="line">            errorMessageStatus = Status_Success;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// if doing command line processing, log the error message to the</span></span><br><span class="line">        <span class="comment">// command line and declare success</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ( errorProcessingMethod == ProcessingMethod_CommandLine ) &#123;</span><br><span class="line">            CommandLine messageLog;</span><br><span class="line">            <span class="keyword">if</span> ( messageLog.<span class="built_in">Status</span>() == CommandLineStatus_Ok ) &#123;</span><br><span class="line">                messageLog.<span class="built_in">AddToMessageQueue</span>( errorMessage.<span class="built_in">Text</span>() );</span><br><span class="line">                messageLog.<span class="built_in">FlushMessageQueue</span>();</span><br><span class="line">                errorMessageStatus = Status_Success;</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// can&#x27;t do anything because the routine is already error processing</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// can&#x27;t do anything because the routine is already error processing</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// if the error code isn&#x27;t valid, notify the user that an</span></span><br><span class="line">    <span class="comment">// internal error has been detected</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">DisplayInteractiveMessage</span>(</span><br><span class="line">            <span class="string">&quot;Internal Error: Invalid error code in ReportErrorMessage()&quot;</span></span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// return status information</span></span><br><span class="line">    <span class="keyword">return</span> errorMessageStatus;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="检查代码">检查代码</h4>
<p>主要包含以下几个步骤</p>
<p>1.人肉运行代码
2.编译子程序。把编译器的告警级别调到最高；消除产生错误消息和警告的所有根源
3.在调试器中逐行执行代码 4.测试代码，编写测试用例来测试代码
5.消除程序中的错误</p>
<h4 id="收尾工作">收尾工作</h4>
<p>收尾工作就是重新审视整个子程序代码来确保子程序的质量合乎标准</p>
<ul>
<li>检查子程序的接口。确保所有的输入、输出数据都参与了计算，且所有的参数也都用到了</li>
<li>检查整体的设计质量。确认子程序只干一件事；子程序之间的耦合是松散的；子程序采用了防御式编程；</li>
<li>检查子程序中的变量。检查是否存在不准确的变量名称、未被用到的对象、未经声明的变量、未经初始化的对象等</li>
<li>检查子程序的布局。确保正确地使用了空白来明确子程序、表达式及参数列表的逻辑结构</li>
<li>检查子程序的文档，确认有伪代码转化而来的注释仍是准确无误的。</li>
<li>出去冗余的注释</li>
<li>。。。</li>
</ul>
<h3 id="小结-1">小结</h3>
<p>伪代码编码是创建类和子程序的一个有效途径，在编写时需要使用易懂的英语，避免使用特定编程语言中才有的特性，同时要在意图层面上写伪代码，即描述该做什么，而不是怎么去做。</p>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Distillation 简介</title>
    <url>/2020/03/01/Distillation%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>本文简单了描述机器学习中的蒸馏（distillation）技术的原理，distillation
可简单分为 model distillation 和 feature
distillation。顾名思义，蒸馏是对原来的模型/特征进行了压缩，其原因可能是为了减少模型的大小（model
distillation）、或者某些特征只能在 training 时获取，serving
无法获取(feature
distillation)；在实际业务中可根据具体场景灵活地应用这两类技术。</p>
<span id="more"></span>
<h2 id="基本原理">基本原理</h2>
<p>Distillation 可分为 Model Distillation 和 Feature
Distillation，其思想都是在训练时同时训练两个模型：teacher 模型和 student
模型，而在 serving 时只用 student 模型。这里的假设是：<strong>teacher
模型比起 student 模型，在模型结构上更复杂(Model Distillation)
，或在特征集上更为丰富(Feature Distillation) ；因此其准确率也会比
student 模型要好。</strong></p>
<p>如下图所示是 Model Distillation和Feature Distillation示例
（下面的图和公式基本摘自 <a
href="https://arxiv.org/pdf/1907.05171.pdf">Privileged Features
Distillation for E-Commerce Recommendations</a>）</p>
<figure>
<img
src="https://wulc.me/imgs/ModelDistillationVSFeatureDistillation.png"
alt="MD vs FD" />
<figcaption aria-hidden="true">MD vs FD</figcaption>
</figure>
<p>那如何利用 teacher 模型指导 student
模型学得更好？<strong>基本的做法是将 teacher 模型的输出作为 soft
label(相对于作为 ground truth 的 hard label）, 为 student 模型添加额外的
loss 项</strong>；如下公式 (1) 所示</p>
<p><span class="math display">\[\min\_{W\_s} (1-\lambda)L\_s(y,
f\_s(X;W\_s))+\lambda*L\_d(f\_t(X;W\_t),f\_s(X;W\_s))
\tag{1}\]</span></p>
<p>上式中各项符号含义如下</p>
<ul>
<li><span class="math inline">\(f\_s(X; W\_s)\)</span> ：student
模型的预估值</li>
<li><span class="math inline">\(f\_t(X;W\_t)\)</span> ： teacher
模型的预估值</li>
<li><span class="math inline">\(L\_s\)</span> ：student 模型原始的
loss</li>
<li><span class="math inline">\(L\_d\)</span> ：利用 teacher
模型预估值输出作为 soft label 计算的 distillation loss;</li>
<li><span class="math inline">\(\lambda\)</span>：平衡 <span
class="math inline">\(L\_s\)</span> 和 <span
class="math inline">\(L\_d\)</span> 的超参</li>
</ul>
<p>上面公式（1）是 Model Distillation 的典型做法，可以看到输入 teacher
模型和 student 模型的特征都是相同的即 <span
class="math inline">\(X\)</span> ；而公式(2)描述的 Feature Distillation
则认为 teacher 模型的特征（<span class="math inline">\(X^*\)</span>）比
student 模型的特征(<span class="math inline">\(X\)</span>)
更为丰富，</p>
<p><span class="math display">\[\min\_{W\_s} (1-\lambda)L\_s(y,
f\_s(X;W\_s))+\lambda\*L\_d(f\_t(X^\*;W\_t),f\_s(X;W\_s))
\tag{2}\]</span></p>
<p>上面两条公式是 Distillation
的核心思想了，且在使用<strong>理论上应该首先训练好 teacher 网络，再训练
student 网络；但是在实际训练的时候，为了加快训练速度，会令 teacher
模型和 student
模型同时进行训练</strong>；因此最终的损失函数变为了如下公式(3)
形式，其中 <span class="math inline">\(L\_s\)</span> 和 <span
class="math inline">\(L\_t\)</span> 是 logloss， 而 <span
class="math inline">\(L\_d\)</span> 是 cross entropy loss</p>
<p><span class="math display">\[\min\_{W\_s, W\_t} (1-\lambda)L\_s(y,
f\_s(X;W\_s)) +  \lambda\*L\_d(f\_t(X^\*;W\_t),f\_s(X;W\_s)) + L\_t(y,
f\_t(X^\*;W\_t))\tag{3}\]</span></p>
<p>综上，在 training 和 serving 时的模型结构分别如下所示</p>
<figure>
<img src="https://wulc.me/imgs/DistillationTrainingAndServing.png"
alt="trainingAndServing" />
<figcaption aria-hidden="true">trainingAndServing</figcaption>
</figure>
<h2 id="训练注意事项">训练注意事项</h2>
<p>上面提到，distillation 需要训练 teacher 和 student
两个网络，因此也有两种训练模式：</p>
<p>（1）先训练 teacher 网络，再训练 student 网络，也被称为 asynchronous
training （2）同时训练 teacher 网络和 student 网络，也被称为 synchronous
training</p>
<p>理论上应该采用方式(1),
但是由于需要<strong>串行训练两个模型，会导致训练的时间过长</strong>,
因此才提出了方式（2）的方法；而方式 (2) 会带来训练效果不稳定的问题,
其原因是在 teacher 在训练初期，其效果往往还不好，而将其输出结果作为
label 很容易导致 student 网络学飞了</p>
<p>因此更常用的做法在这两个之间做个权衡，<strong>基本做法就是在训练的初期，将公式(3)
中的 <span class="math inline">\(\lambda\)</span>
设为0，然后后面逐渐增大 <span class="math inline">\(\lambda\)</span>
这个值</strong></p>
<p>上面提到的paper在这点上提出了一个更简单策略，就是在 <span
class="math inline">\(k\)</span> 个 step 后才让 teacher 网络的输出作为
loss 影响 student 网络，<span class="math inline">\(k\)</span>
是一个拍定的超参，因此其详细训练方式如下</p>
<figure>
<img src="https://wulc.me/imgs/SynchronousTraining.png"
alt="synchronous training" />
<figcaption aria-hidden="true">synchronous training</figcaption>
</figure>
<h2 id="实现">实现</h2>
<p>tensorflow 提供的一个distillation 的实现 <a
href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/distillation.py">distillation.py</a>，使用见
stack-overflow 上的 <a
href="https://stackoverflow.com/questions/53291939/how-do-i-use-tensor2tensors-distillation-py-to-distill-the-knowledge-from-a-tea?answertab=active#tab-top">这个回答</a></p>
<p>核心代码如下所示，注释写得已经非常清晰了，下面默认的模式是先训练好了
Teacher 网络，再训练 Student 网络，也就是上面提到的 asynchronous
training 模式；但是也可以比较容易将下面的逻辑改成 synchronous training
的。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">### Teacher Network</span></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;teacher&quot;</span>):</span><br><span class="line">  teacher_outputs = self.teacher_model.body(features)</span><br><span class="line">  tf.logging.info(<span class="string">&quot;teacher output shape: %s&quot;</span> % teacher_outputs.get_shape())</span><br><span class="line">  teacher_outputs = tf.reduce_mean(teacher_outputs, axis=[<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">  teacher_logits = tf.layers.dense(teacher_outputs, hp.num_classes)</span><br><span class="line"></span><br><span class="line">  teacher_task_xent = tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">      labels=one_hot_targets, logits=teacher_logits)</span><br><span class="line">  outputs = teacher_logits</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> is_distill:</span><br><span class="line">  <span class="comment"># Load teacher weights</span></span><br><span class="line">  tf.train.init_from_checkpoint(hp.teacher_dir, &#123;<span class="string">&quot;teacher/&quot;</span>: <span class="string">&quot;teacher/&quot;</span>&#125;)</span><br><span class="line">  <span class="comment"># Do not train the teacher</span></span><br><span class="line">  trainable_vars = tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)</span><br><span class="line">  <span class="keyword">del</span> trainable_vars[:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### Student Network</span></span><br><span class="line"><span class="keyword">if</span> is_distill:</span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;student&quot;</span>):</span><br><span class="line">    student_outputs = self.student_model.body(features)</span><br><span class="line">    tf.logging.info(</span><br><span class="line">        <span class="string">&quot;student output shape: %s&quot;</span> % student_outputs.get_shape())</span><br><span class="line">    student_outputs = tf.reduce_mean(student_outputs, axis=[<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">    student_logits = tf.layers.dense(student_outputs, hp.num_classes)</span><br><span class="line"></span><br><span class="line">    student_task_xent = tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">        labels=one_hot_targets, logits=student_logits)</span><br><span class="line">    teacher_targets = tf.nn.softmax(teacher_logits / hp.distill_temperature)</span><br><span class="line">    student_distill_xent = tf.nn.softmax_cross_entropy_with_logits_v2(</span><br><span class="line">        labels=tf.stop_gradient(teacher_targets),</span><br><span class="line">        logits=student_logits / hp.distill_temperature)</span><br><span class="line">    <span class="comment"># scale soft target obj. to match hard target obj. scale</span></span><br><span class="line">    student_distill_xent *= hp.distill_temperature**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">    outputs = student_logits</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Summaries</span></span><br><span class="line">    tf.summary.scalar(<span class="string">&quot;distill_xent&quot;</span>, student_distill_xent)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> is_distill:</span><br><span class="line">  phase_loss = teacher_task_xent</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  phase_loss = hp.task_balance * student_task_xent</span><br><span class="line">  phase_loss += (<span class="number">1</span> - hp.task_balance) * student_distill_xent</span><br><span class="line"></span><br><span class="line">losses = &#123;<span class="string">&quot;training&quot;</span>: phase_loss&#125;</span><br><span class="line">outputs = tf.reshape(outputs, [-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, outputs.shape[<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> outputs, losses</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Dynamic Creative Optimization in Online Display Advertising</title>
    <url>/2022/02/01/Dynamic%20Creative%20Optimization%20in%20Online%20Display%20Advertising/</url>
    <content><![CDATA[<p>最近在研究广告创意相关内容,
笔者根据当前的调研，将这个领域划分为<strong>创意生成、创意优选和创意投放</strong>三大块，每一块的具体职责如下</p>
<ul>
<li>创意生成：利用素材(标题、图片、视频、落地页等)生成候选创意(用户看到的广告)</li>
<li>创意优选：从计划的候选创意(一个计划下的候选往往有多个)中选择 topk
个用于投放</li>
<li>创意投放：将优选出来的创意投放至线上</li>
</ul>
<p>严格来说，这三部分其实也并非泾渭分明，比如前两部分可以统一理解为创意生成(从最原始的素材生成最终要投放的创意)，后两部分可以统一理解为创意投放过程(从候选中选出来并投放至线上)。</p>
<p>本文主要侧重讲述与创意投放相关的一篇 paper,
而且偏向于上面提到第三块内容(没有基于 E&amp;E 的优选过程)，paper
的标题是 <a
href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3863663">Dynamic
Creative Optimization in Online Display Advertising</a>，这篇 paper
将素材在线投放问题建模成一个二部图匹配问题，并提供了严格求解的方法和在线的近似求解方法。更重要的是，这种建模的方法不局限于创意领域，能应用到更多投放场景下。</p>
<span id="more"></span>
<h2 id="问题建模">问题建模</h2>
<p>online advertising 的绝大多数方法，如targeting、ranking、bidding
等，本质上都是在解决在线分配问题，即让合适的广告分发给合适用户，从而使得收入最大化（同时需要考虑生态、用户体验等），因此也可以从分配的角度去构造出一个如下简单二部图的形式，左边是
user，右边则是具体的广告(在这里为创意),
连接的边表示这个用户访问了这个广告/创意，边的权重可根据具体的业务目标决定</p>
<figure>
<img src="https://wulc.me/imgs/dco_graph.jpg" alt="dco_graph" />
<figcaption aria-hidden="true">dco_graph</figcaption>
</figure>
<p>基于上图的二部图，paper 里将问题建模成如下的最优化问题</p>
<figure>
<img src="https://wulc.me/imgs/modelling_dco.jpg" alt="modelling" />
<figcaption aria-hidden="true">modelling</figcaption>
</figure>
<p>符号含义如下</p>
<ul>
<li><span class="math inline">\(u\)</span>: user 的 index</li>
<li><span class="math inline">\(i\)</span>: item 的 index, 这里的 item
指的是创意(creative)</li>
<li><span class="math inline">\(r_{iu}\)</span>: 第 <span
class="math inline">\(u\)</span> 个 user 访问了第 <span
class="math inline">\(i\)</span> 个 item 的
revenue，比如消耗/点击等，即上图中的边权</li>
<li><span class="math inline">\(T_u\)</span>: 第 <span
class="math inline">\(u\)</span> 个 user 的总访问次数</li>
<li><span class="math inline">\(x_{iu}\)</span>: 第 <span
class="math inline">\(u\)</span> 个 user 访问了第 <span
class="math inline">\(i\)</span> 个 item 的次数</li>
<li><span class="math inline">\(\underline{k_{iu}}\)</span>: 第 <span
class="math inline">\(u\)</span> 个 user 访问了第 <span
class="math inline">\(i\)</span> 个 item 的次数的下限</li>
<li><span class="math inline">\(\overline{k_{iu}}\)</span>: 第 <span
class="math inline">\(u\)</span> 个 user 访问了第 <span
class="math inline">\(i\)</span> 个 item 的次数的上限</li>
<li><span class="math inline">\(y_{iu}\)</span>: 第 <span
class="math inline">\(u\)</span> 个 user 是否访问了第 <span
class="math inline">\(i\)</span> 个 item</li>
<li><span class="math inline">\(l_i\)</span>: 第 <span
class="math inline">\(i\)</span> 个 item
触达的不同用户数的下限(防止只给一个用户出广告)</li>
</ul>
<p>上面的最优化问题中，(1b)到(1d) 中的三个约束，对应的是如下三个约束</p>
<blockquote>
<p>(1b) <strong>ad fatigue constraint</strong>, which aims to help in
avoiding customers becoming fatigued by seeing a product too many times.
This constraint says that a particular item <span
class="math inline">\(i\)</span> can be shown at most <span
class="math inline">\(\overline{k_{iu}}\)</span> times to user <span
class="math inline">\(u\)</span>. To calibrate ad fatigue, <strong>this
parameter can be set using historical data showing when customers stop
engaging with ads</strong>. (1c) <strong>ad retargeting
constraint</strong>, which focuses on showing products to customers that
have seen or searched for them before. In this constraint, we say that a
particular item <span class="math inline">\(i\)</span> has to be shown
at least <span class="math inline">\(\underline{k_{iu}}\)</span> times
to user <span class="math inline">\(u\)</span>. To retarget an ad,
<strong>this parameter can be set postive for items that the user saw
just before the ad campaign is planned</strong>. (1d) <strong>user
diversity constraint</strong>, which addresses the requirement that
advertisers want to increase reach and purchasing by showing their
products to many different customers. This constraints says that at
least <span class="math inline">\(l_i\)</span> users have to see a
particular item <span class="math inline">\(i\)</span>. These parameters
are specifically set by the advertiser.</p>
</blockquote>
<h2 id="问题求解">问题求解</h2>
<p>这里问题的求解分为了离线和在线两部分，区别是离线时是以上帝视角看这个问题，即能够获取
用户的访问次数 <span
class="math inline">\(T_u\)</span>，但是在线时则是不知道的。因此，离线可采用严格的求解方法，在线则只能采用近似的求解方法。</p>
<h3 id="离线求解">离线求解</h3>
<p>假如能够获取 <span
class="math inline">\(T_u\)</span>（即用户当天的访问次数），就能够采用来求解上面的最优化问题，这类问题通常会被变换成一个<a
href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E6%B5%81">网络流</a>问题来求解，关于网络流更详细的介绍可以参考
<a href="https://zhuanlan.zhihu.com/p/122375531">算法学习笔记(28):
网络流</a></p>
<p>而上面建模出来的问题，可以被转变成网络流中的最小费用最大流问题(<a
href="https://en.wikipedia.org/wiki/Minimum-cost_flow_problem">minimum-cost
flow problem</a>), 这部分更详细的描述也可参考 <a
href="https://zhuanlan.zhihu.com/p/127046673">算法学习笔记(31):
最小费用最大流</a></p>
<p>因此，基于最小费用最大流的概念，可以构造出如下的网络流</p>
<figure>
<img src="https://wulc.me/imgs/dco_flow_problem.jpg" alt="dco graph" />
<figcaption aria-hidden="true">dco graph</figcaption>
</figure>
<p>上面的网络流中有 2 个 user 和 2 个
item，理解以下几点就能够理解上图的含义了</p>
<ul>
<li>每条边的三个参数的含义分别是 <strong>(流量上限, 流量下限,
费用)</strong></li>
<li>从 source 出发到第 <span class="math inline">\(u\)</span> 个 user
的流量上限为 <span
class="math inline">\(T_u\)</span>(即用户当前访问的次数)</li>
<li>每个 user 访问每个 item 的次数的上限（<strong>ad fatigue
constraint</strong>）和下限（<strong>ad retargeting
constraint</strong>）的约束体现在
<code>users-&gt;item-copies</code>的边上</li>
<li><code>item-copies-&gt;items</code>
的连边是为了满足上面的<strong>user diversity
constraint</strong>，即保证访问第 <span class="math inline">\(i\)</span>
个 item 的不同用户的数量不小于 <span
class="math inline">\(l_i\)</span></li>
<li><code>item-&gt;sink</code> 中，流量上限为 <span
class="math inline">\(m\)</span>, 即访问第 <span
class="math inline">\(i\)</span> 个 item
的不同用户数的上限是总用户数</li>
</ul>
<p>此外，在构图中还需要考虑如下几个问题，paper
里没有给明确的答案，也算比较 open
的问题，需要针对不同的业务场景设计对应的技术方案了</p>
<p><strong>(1)边的权值(即上面说的费用的负值)的物理含义是什么？缺失的边的权值怎么计算？</strong>
<strong>(2)采用 id
粒度过小可能导致整个图可能过大，进而导致图的求解比较困难，如果做
clustering 要怎么做？</strong> <strong>(3)新 uid/item-id
如何处理？</strong></p>
<h3 id="在线求解">在线求解</h3>
<p>上面的解法是离线解法，即能够拿到了用户当天的访问次数 <span
class="math inline">\(T_u\)</span>,
然后用严格的方法求解最优化问题，这个模式往往可以用来大致摸底方法的收益天花板（通过回放历史精排日志），但是在实际投放中，并不知道用户当天的访问次数
<span
class="math inline">\(T_u\)</span>(笔者附：如果用历史平均来近似，误差会有多大？)，因此在线需要提供一种近似最优的求解方法</p>
<h4 id="deterministic-algorithm">deterministic algorithm</h4>
<p>paper 指出了 <a
href="https://en.wikipedia.org/wiki/Deterministic_algorithm">deterministic
algorithm</a>（简单来说就是不会有 random
操作，反例是启发式算法）对于在线问题表现效果很差，至于有多差，paper
给了一些证明，这里略过过程，只给出其中一些核心概念和结论</p>
<p>paper 在这个过程中使用了 <a
href="https://en.wikipedia.org/wiki/Competitive_analysis_%28online_algorithm%29">competitive
ratio</a>来衡量 deterministic
算法的效果，这个指标主要用来描述极端情况下，online algorithm
的效果相比于 offline 的有多差，引用这个<a
href="http://theory.stanford.edu/~trevisan/cs261/lecture17.pdf">讲义</a>里的定义如下</p>
<blockquote>
<p>The competitive ratio of an online algorithm for an optimization
problem is simply the approximation ratio achieved by the algorithm,
that is, the worst-case ratio between the cost of the solution found by
the algorithm and the cost of an optimal solution.</p>
</blockquote>
<p>有了 competitive ratio 的概念，paper 针对 deterministic algorithm
给出了如下结论（证明的详细过程可以参考 paper 中的 4.1 小节)，即
deterministic algorithm 的效果很差，哪怕给 reward 加了 bound</p>
<blockquote>
<p>Proposition 1. The competitive ratio of any deterministic algorithm
for the online DCO problem is arbitrarily small</p>
<p>Proposition 2. Suppose that the revenue associated to all item and
user pairs are bounded, that is, there exists an <span
class="math inline">\(r\)</span> such that <span
class="math inline">\(\underline{r} ≤ r_{iu} ≤ 1\)</span> for all items
<span class="math inline">\(i\)</span> and users <span
class="math inline">\(u\)</span>. In this case, the competitive ratio of
any deterministic algorithm for the online DCO problem is <span
class="math inline">\(\underline{r}\)</span></p>
</blockquote>
<h4 id="deterministic-algorithm-with-assumption">deterministic algorithm
with assumption</h4>
<p>上面给出的结果中，没有任何的假设，因此在这个方法中加入了一个
assumption：即用户 <span class="math inline">\(u\)</span> 每天至少有
<span class="math inline">\(c_u\)</span> 次访问，paper 中引用了 IAB(<a
href="https://en.wikipedia.org/wiki/Interactive_Advertising_Bureau">Interactive
Advertising Bureau</a> )
的一个结论，认为这个数据是比较容易能得到的，paper 描述如下，</p>
<blockquote>
<p>Using historical data, advertisers can make accurate estimates about
the minimum number of times they expect a user to visit the platform
during the advertising period (Interactive Advertising Bureau 2020).</p>
</blockquote>
<p>但是 paper 中给出了这一结论的<a
href="https://www.iab.com/wp-content/uploads/2020/05/Consumer-Media-Usage-2019-through-April-2020.pdf">参考资料</a>中似乎只是一些统计数据的罗列，并未提及上面这个结论的推导过程。。。而从逻辑上讲，笔者猜测虽然用户
<span class="math inline">\(u\)</span> 准确的访问次数 <span
class="math inline">\(T_u\)</span> 比较难预测，但是这个访问次数的 lower
bound <span class="math inline">\(c_u\)</span>
的难度也许会比较容易获得</p>
<p>在 <span class="math inline">\(c_u\)</span> 比较容易获得的 assumption
下，paper 里给出了第一种在线算方法，总体算法流程如下</p>
<figure>
<img src="https://wulc.me/imgs/dco_online_algo1.jpg" alt="algo1" />
<figcaption aria-hidden="true">algo1</figcaption>
</figure>
<p>其实跟 offline 的区别不大，就是用了 <span
class="math inline">\(c_u\)</span> 替换了 <span
class="math inline">\(T_u\)</span>,
在线分配时优先满足约束，而满足了约束后，就可以在 ad fatigue 的约束下去拿
highest revenue 的边</p>
<p>paper 里绕了一大圈才给出了上面的算法流程，给出了各种符号、
lemma、proposition，但是跟最终的结论的关系又不是非常大，有点凑字数的感觉；而且比较核心的部分即
<span class="math inline">\(c_u\)</span>
是如何获取的则是基本没怎么提。。。</p>
<p>paper 里还给出了这个算法的 competitive ratio 的 lower bound
是（证明过程可参考 paper，这里略过）</p>
<p><span class="math display">\[1-\frac{(\overline{r} -
\underline{r})n_1}{\underline{r}(n_1+n_2)}\]</span></p>
<p>各个符号含义如下</p>
<ul>
<li><span class="math inline">\(n_1=\sum_{u=1}^{m} c_u\)</span>:
即所有用户的最少访问次数之和</li>
<li><span class="math inline">\(n_2= T- n_1\)</span>: <span
class="math inline">\(T\)</span> 是所有用户的实际访问次数之和</li>
<li><span class="math inline">\(\underline{r}=\min_{i=1 \dots n, u=1
\dots m}r_{iu}\)</span>: 即所有 pair 的 revenue 的最小值</li>
<li><span class="math inline">\(\overline{r}=\max_{i=1 \dots n, u=1
\dots m}r_{iu}\)</span>: 即所有 pair 的 revenue 的最大值</li>
</ul>
<h4 id="greedy-algorithm">greedy algorithm</h4>
<p>paper 里还提到到了另一种贪心的算法，其 assumption 是每个 item/user
都有一个reserved revenue, 第 <span class="math inline">\(i\)</span> 个
item 的 reserved revenue 记为 $ _i$, 第 <span
class="math inline">\(u\)</span> 个 user 的 reserved revenue 记为 <span
class="math inline">\(\beta_u\)</span>, 则有</p>
<p><span class="math display">\[r_{iu} = \alpha_i + \beta_u\]</span></p>
<p>基于这个假设，paper 里给了如下的 online algorithm，并且证明了这里的
competitive ratio 能跟最优的一致</p>
<figure>
<img src="https://wulc.me/imgs/dco_online_algo2.jpg" alt="algo2" />
<figcaption aria-hidden="true">algo2</figcaption>
</figure>
<p>但是笔者觉得这里的 assumption 有很大的问题，即假设了每个 item 对所有
user 的 revenue 是一样的，这样显然不合理，因为正是每个 user
的兴趣不同，才需要进行个性化的推荐，也是当前推荐/广告里各种算法和策略有效的原因，所以这里的算法笔者觉得可以看一下数学的原理，但是在实际应用并不现实</p>
<h2 id="小结">小结</h2>
<p>总的来说，这篇 paper
将在线广告的分配建模成一个经典的二部图问题，提供了离线和在线的解法，并给出了一些理论证明，笔者觉得可以学习一下其中的思想，但是如果照搬
paper 的方法在实际应用的话比较难</p>
<p>第一个 online algorithm 的问题在于 <span
class="math inline">\(c_u\)</span> 的获取并没有给出具体的方法，第二个
online algorithm 的问题在于本来的 assumption 就不合理</p>
<p>笔者认为利用用户 <span class="math inline">\(u\)</span>
过去一段时间的访问次数来近似（或者通过预估的方式）作为其未来的访问次数
<span class="math inline">\(T_u\)</span>
是一种可行的方法，但是这个方法还需要解决如下的问题</p>
<p><strong>（1）如果求解出来某个 item 需要分配给某个 user，paper
里说了是直接展示，但是在实际的系统中往往是“召回+精排”的结构，需要如何保证这个
item 一定能被 user
看到？或者说，实际中的系统往往已经有一套召回和精排的策略，怎么让这套新策略融入现有的系统中</strong></p>
<p><strong>（2）user-item
边的权值的物理含义是什么？缺失的边的权值怎么计算？</strong></p>
<p><strong>（3）采用 id
粒度过小可能导致整个图可能过大，进而导致图的求解比较困难，可以怎么做，如果做
clustering 怎么保证两次聚类的结果差异性不大？</strong></p>
<p><strong>（4）新 uid/item-id 如何处理？</strong></p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>EE 问题概述</title>
    <url>/2019/01/05/EE(Exploitation%20Exploration)%20%E9%97%AE%E9%A2%98%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>EE(Exploitation &amp; Exploration)
问题在计算广告/推荐系统中非常常见，甚至在更广义的范围上，任意决策问题都会牵涉到
EE
问题。简单来说，这个问题就是要解决的是<strong>在决策时到底是根据已有经验选择最优的策略(Exploitation)，还是去探索一些新的策略来提升未来的收益(Exploration)</strong>。本文主要介绍解决这个问题的三种比较常见的方法：随机方法，UCB
方法，Thompson sampling 方法，侧重于方法的具体流程和基本思想。</p>
<span id="more"></span>
<h2 id="mab-建模">MAB 建模</h2>
<p>EE 问题一般会通过 MAB(Multi-Armed Bandit) 进行建模, 如下所示，所有
arm 就是每次决策中可作出的选择，拉下某个 arm 表示作出了相应的选择。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cvujraje37f8ne6ej1l25o9e9.png"
alt="MAB" />
<figcaption aria-hidden="true">MAB</figcaption>
</figure>
<p>MAB 符号化表述如下</p>
<ol type="1">
<li>MAB 可表示为一个二元组 &lt;<span class="math inline">\(A,
R\)</span>&gt;</li>
<li><span class="math inline">\(A\)</span> 表示为一系列可能的动作, <span
class="math inline">\(R(r|a)\)</span>
则表示给定动作下的奖赏的分布，</li>
<li>每一时刻根据给定策略从 <span class="math inline">\(A\)</span>
选择动作 <span class="math inline">\(a\_t\)</span>, 同时环境根据分布
<span class="math inline">\(R(r|a)\)</span> 生成奖赏 <span
class="math inline">\(r\_t\)</span></li>
<li>目标是最大化奖赏之和 <span class="math inline">\(\sum\_{t=1}^T
r\_t\)</span></li>
</ol>
<p>上面的第 3 步的策略就是下面要介绍的 EE
问题的解决方法，除去随机方法，<strong>UCB 方法和 Thompson sampling
方法的思想均是通过定义每个 arm 的收益的期望，然后选择收益期望最大的
arm</strong>。UCB 是<strong>频率学派</strong>的思想，认为每个 arm
的收益期望是固定的，通过试验记录得到其历史收益状况，然后加上一个 bound
构成了收益期望；Thompson sampling
则是<strong>贝叶斯学派</strong>的思想，认为 arm
的收益期望服从一个特定的概率分布，通过试验记录更新分布的参数，然后从每个
arm 的分布中产生收益期望。</p>
<p>而<strong>根据一个 arm
的历史试验记录判断其优劣又有两种方法，因而也衍生了两类 bandit
问题：Bernoulli Bandit 和 Contextual Bandit</strong>。在 Bernoulli
Bandit 中，认为每个 arm
的优劣（即当前试验是否产生收益）是服从伯努利分布的，而分布的参数可以通过历史收益状况求解；而在
Contextual Bandit中，没有直接定义出一个概率分布来描述每个 arm 的优劣,
而是假设了 arm 的优劣和描述 arm 的特征组成的向量 <span
class="math inline">\(x\)</span> 存在一个线性关系：<span
class="math inline">\(x^T \theta\)</span>，参数 <span
class="math inline">\(\theta\)</span> 可通过历史样本求解和更新。</p>
<p>UCB 方法和 Thompson sampling 方法均可解决这两类问题，UCB 解决
Bernoulli Bandit 的方法有 UCB1，UCB2 等，解决 Contextual Bandit 的方法有
LinUCB 等；而 Thomson Sampling 解决 Bernoulli Bandit 时采用了 Bernoulli
分布和 Beta 分布，解决 Contextual Bandit
时采用了两个正态分布。后面会详细介绍这些方法。</p>
<h2 id="随机方法">随机方法</h2>
<h3 id="epsilon-greedy"><span
class="math inline">\(\epsilon\)</span>-greedy</h3>
<p><span class="math inline">\(\epsilon\)</span>-greedy
是一种最简单的随机方法，原理很简单：每次决策时，以 1 - <span
class="math inline">\(\epsilon\)</span> 的概率选择最优的策略，以 <span
class="math inline">\(\epsilon\)</span> 的概率随机选择任意一个策略;
并且在每次做出决策获取到真实的 reward
后更新每个决策的收益情况（用于选择最优策略）。伪代码实现可参考 <a
href="https://zhuanlan.zhihu.com/p/32335683">Multi-Armed Bandit:
epsilon-greedy</a></p>
<p><span class="math inline">\(\epsilon\)</span>-greedy
存在着以下几个比较显著的问题</p>
<ol type="1">
<li><span class="math inline">\(\epsilon\)</span>
是个超参数，设置过大会导致决策随机性过大，设置过小则会导致探索性不足</li>
<li><span class="math inline">\(\epsilon\)</span>-greedy
策略运行一段时间后，对各个 arm
的收益情况有所了解，但没有利用这些信息，仍然不做任何区分地随机
exploration（会选择到明显较差的item）</li>
<li><span class="math inline">\(\epsilon\)</span>-greedy
策略运行一段时间后，但仍然花费固定的精力去
exploration，浪费了本应该更多进行 exploitation 机会</li>
</ol>
<p>针对第 2 个问题，可以在 <span
class="math inline">\(\epsilon\)</span>-greedy
策略运行一段时间后，选择出收益最高的前 <span
class="math inline">\(n\)</span> 个 arm，然后 exploration 时从这 <span
class="math inline">\(n\)</span> 个 arm 中随机选择。</p>
<p>针对第 3 个问题，可以设置进行 exploration 的概率 <span
class="math inline">\(\epsilon\)</span>
随着策略进行的次数而逐渐下降，比如说可以取如下的对数形式, <span
class="math inline">\(m\)</span> 表示目前进行了 <span
class="math inline">\(m\)</span> 次的决策</p>
<p><span class="math display">\[\epsilon = \frac{1}{1 +
\log(m+1)}\]</span></p>
<h3 id="softmax">Softmax</h3>
<p>通过 Softmax 进行的 Exploration 也称为 Boltzmann
Exploration，这个方法通过一个温度参数来控制 exploration 和 exploitation
的比例，假设各个 arm 的历史收益为 <span
class="math inline">\(\mu\_0\)</span>, <span
class="math inline">\(\mu\_1\)</span>, ......, <span
class="math inline">\(\mu\_n\)</span>, 温度参数记为 <span
class="math inline">\(T\)</span>，则选择某个 arm 时参考的指标为</p>
<p><span class="math display">\[p\_i =
\frac{e^{\mu\_i/T}}{\sum\_{j=0}^{n} e^{\mu\_j/T}}(i=0, 1,....,
n)\]</span></p>
<p>当温度参数 <span class="math inline">\(T=1\)</span>,
上面的方法就是纯粹的 exploitation；而当 <span class="math inline">\(T
\to \infty\)</span> 时，上面的方法就是纯粹的 exploration，因此，可以控制
<span class="math inline">\(T\)</span> 的范围来控制 exploration 和
exploitation 的比例。某些文献也会将 <span
class="math inline">\(1/T\)</span> 称为学习率。一个很直观的想法就是让
<span class="math inline">\(T\)</span>
随着策略运行次数的增加而下降，这样便可让策略从偏向 exploration 转为偏向
exploitation。</p>
<p>但是，这篇 paper <a
href="https://arxiv.org/pdf/1705.10257.pdf">Boltzmann Exploration Done
Right</a> 证明了单调的学习率（即<span
class="math inline">\(1/T\)</span>）会导致收敛到局部最优，并提出了一种针对不同的
arm 采用不同的学习率的方法，但是形式已经不是上面的 softmax
形式了。文章涉及的证明和公式符号较多，这里不再展开阐述，感兴趣读者可自行参考。</p>
<h2 id="ucb-方法">UCB 方法</h2>
<p>假如能够对每个 arm
都进行足够多次的试验，根据大数定律，次数越多，这些试验结果统计得到的收益便会约接近各个
arm 真实的收益。然而在实际中，只能对各个 arm
进行有限次的试验，因此这会导致根据统计得到的收益跟真实的收益存在一个误差，<strong>UCB
的核心就在于如果预估这个误差(也就是 UCB 中的 B(bound))，然后将 arm
统计的收益加上其通过 UCB 方法计算出来的 bound
进行排序，选择最高的那个。</strong></p>
<h3 id="ucb1">UCB1</h3>
<p>UCB1 方法的理论基础是 <a
href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoeffding's
inequality</a>，该不等式的定义如下</p>
<blockquote>
<p>假设 <span class="math inline">\(X\_1, X\_2...X\_n\)</span>
是同一个分布产生的 <span class="math inline">\(n\)</span>
个独立变量，其均值为 <span class="math inline">\(\overline{X} =
\frac{1}{n}\sum\_{i=1}^n X\_i\)</span>, 则如下公式成立 <span
class="math display">\[p(|E[X] - \overline{X}| \le \delta) \ge 1 -
2e^{-2n\delta^2}\]</span></p>
</blockquote>
<p>更直观地说，该不等式表明了 <strong><span
class="math inline">\(n\)</span>
个独立同分布的变量的均值与该变量的真实期望的误差小于某个预设的阈值 <span
class="math inline">\(u\)</span> 会以概率 <span class="math inline">\(1
- e^{-2nu^2}\)</span> 恒成立</strong>。</p>
<p>回到我们的问题，可以将 <span class="math inline">\(X\_1,
X\_2...X\_n\)</span> 看做某个 arm 在 <span
class="math inline">\(n\)</span>
次试验中获得的收益，则通过上面的式子可以设定一个 <span
class="math inline">\(\delta\)</span> 使得公式成立, 然后用<span
class="math inline">\(\overline{X} + \delta\)</span> 来近似真实的收益
<span class="math inline">\(E(X)\)</span>；理论上也可用 <span
class="math inline">\(\overline{X} - \delta\)</span>，但是 UCB
方法会用上界，这也是 UCB 中 U(upper) 的含义。<strong>那么现在的问题便是
<span class="math inline">\(\delta\)</span> 该选多大了？</strong></p>
<p>UCB1 方法中将 <span class="math inline">\(\delta\)</span>
设为如下公式，公式中的 <span class="math inline">\(N\)</span>
表示目前所有 arm 试验的总次数，<span class="math inline">\(n\)</span>
表示某个 arm 的实验次数</p>
<p><span class="math display">\[ \delta =
\sqrt{\frac{2\ln{N}}{n}}\]</span></p>
<p>直观地看上面定义的 <span class="math inline">\(\delta\)</span>,
分子的 <span class="math inline">\(N\)</span> 对所有的 arm
是相同的，分母的 <span class="math inline">\(n\)</span> 则表示某个 arm
目前为止试验的次数，如果这个值越小，那么 <span
class="math inline">\(\delta\)</span> 便越大，相当于
exploration；而当各个 arm 的 <span class="math inline">\(n\)</span>
相同时，实际上就是在比较各个 arm 的历史收益情况了。</p>
<p>UCB1 方法的流程如下，该图摘自 <a
href="https://jeremykun.com/2013/10/28/optimism-in-the-face-of-uncertainty-the-ucb1-algorithm/">Optimism
in the Face of Uncertainty: the UCB1 Algorithm</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1d06kc0hg38a172e1hs85rg1q8416.png"
alt="UCB1" />
<figcaption aria-hidden="true">UCB1</figcaption>
</figure>
<p>可以看到 UCB1 的 bound 完全是由 Hoeffding's inequality
推导出来的，而除了 Hoeffding's inequality，其他的一些 inequality
也能够推导出相应的 bound，<a
href="http://home.deib.polimi.it/restelli/MyWebSite/pdf/rl5.pdf">Reinforcement
Learning: Exploration vs Exploitation</a> 中就提到了一些其他的
inequality</p>
<ul>
<li>Bernstein’s inequality</li>
<li>Empirical Bernstein’s inequality</li>
<li>Chernoff inequality</li>
<li>Azuma’s inequality</li>
<li>.......</li>
</ul>
<h3 id="ucb2">UCB2</h3>
<p>从名字上基本就可以猜出 UCB2 是 UCB1 的改进，改进的地方是降低了 UCB1
的 regret 的上界，regret
指的是每次能获得的最大的收益与实际获得的收益的差距，这部分涉及到较多的数学证明，这里略去这部分，详细可参考
<a
href="https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf">Finite-time
Analysis of the Multiarmed Bandit Problem</a>。UCB2
算法的流程如下，图片同样摘自 <a
href="https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf">Finite-time
Analysis of the Multiarmed Bandit Problem</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1d0bpj8ghom61ki0e8q1no31urc9.png"
alt="UCB2" />
<figcaption aria-hidden="true">UCB2</figcaption>
</figure>
<p>从流程图上可知，UCB2 与 UCB1 相似，也是为每个 arm 计算一个
bound，然后根据 arm 的历史收益和 bound 选出 arm ，只是对这个 arm
不止试验一次，而是试验 <span class="math inline">\(\tau(r\_j+1) -
\tau(r\_j)\)</span> 次。上面的 <span class="math inline">\(a\_{n,
r\_j}\)</span> 和 <span class="math inline">\(\tau(r)\)</span>
定义如下，由于 <span class="math inline">\(\tau(r)\)</span>
要为整数，因此取了上界</p>
<p><span class="math display">\[a\_{n,r} =
\sqrt{\frac{(1+\alpha)\ln(ne/\tau(r))}{2\tau(r)}}\]</span></p>
<p><span class="math display">\[\tau(r) = \lceil
(1+\alpha)^r\rceil\]</span></p>
<p>上面式子中的 <span class="math inline">\(\alpha\)</span>
是个超参数，根据上面给出的论文中的实验结果(如下图所示)，这个值不能取得太大，论文建议值是
0.0001</p>
<figure>
<img src="https://wulc.me/imgs/image_1d0c0s8c31qaqi6v12g51g1iprj2m.png"
alt="alpha" />
<figcaption aria-hidden="true">alpha</figcaption>
</figure>
<h3 id="linucb">LinUCB</h3>
<p>上面的 UCB1 和 UCB2 算法都是解决 Bernoulli Bandit
问题的，也就是假设每个 arm
的优劣是服从伯努利分布，而根据历史记录计算出的 <span
class="math inline">\(\overline
{x}\_j\)</span>（获得收益的试验次数和总试验次数的比值）其实就是伯努利分布的参数。</p>
<p>这样基于统计的方法很简单，但是问题也比较显著，因为 arm
的收益会跟多个因素有关（比如说某个 arm
在早上选择时没有收益，但是晚上就有了），利用这些信息可以预估得更准确；而基于统计的方法则忽略了这一点。</p>
<p>区别于 Bernoulli Bandit，这类利用了上下文信息的问题就是上面提到的
Contextual Bandit 问题，而 LinUCB 就是要解决这个问题的。 LinUCB
中没有直接定义出一个概率分布来描述每个 arm 的历史收益状况, 而是假设了
arm 的优劣和描述 arm 的特征的向量 <span class="math inline">\(x\)</span>
存在一个线性关系： <span class="math inline">\(x^T \theta\)</span></p>
<p>实际上这是一个经典的 Linear Regression(收益不在局限于 0 和 1)
问题，<span class="math inline">\(x\)</span> 是 arm
的特征组成的向量(需要根据具体的问题选择特征), <span
class="math inline">\(\theta\)</span>
则是模型的参数，每一次的试验就是一条样本，label 为具体的收益。</p>
<p>通过历史样本可以求解出 <span class="math inline">\(\theta\)</span>,
则在每次选择选择 arm 时，LinUCB 会用 <span class="math inline">\(x^T
\theta\)</span> 来替换掉 UCB1或UCB2 中的 <span
class="math inline">\(\overline {x}\_j\)</span>，但是这还不是 LinUCB
的全部，作为 UCB 类方法，LinUCB 中还是有个 bound
的，因为毕竟从历史记录只能对 arm
进行有限次的试验，预估出来的收益情况与真实的还是存在差距的。</p>
<p>UCB1 中推到出 bound 的 Hoeffding's inequality 不能直接应用到 LinUCB
中，而关于 linear regression 的 bound 最早是在这篇论文 <a
href="https://arxiv.org/ftp/arxiv/papers/1205/1205.2606.pdf">Exploring
compact reinforcement-learning representations with linear
regression</a> 中提出的，这里不详细展开具体的证明过程了。提出 LinUCB
的论文 <a href="http://rob.schapire.net/papers/www10.pdf">A
Contextual-Bandit Approach to Personalized News Article
Recommendation</a> 直接采用了这一结论，其表达形式，如下所示</p>
<blockquote>
<p><span class="math display">\[p(|x\_j^T\theta\_j - E(r|x\_j)| \le
\alpha \sqrt{x\_j^T(D\_j^TD\_j+I)^{-1}x\_j}) \ge 1- \delta\]</span></p>
</blockquote>
<p>即对于某个 arm <span class="math inline">\(j\)</span>, 计算出来的
<span class="math inline">\(x\_j^T\theta\_j\)</span>
与实际的期望相差小于 $ $ 的概率要大于 <span class="math inline">\(1-
\delta\)</span>, 其中 <span class="math inline">\(D\_j\)</span> 是 arm
<span class="math inline">\(j\)</span>
前面每次被观察到的特征组成的矩阵，比如说 arm <span
class="math inline">\(j\)</span> 前面被观察了 <span
class="math inline">\(m\)</span> 次，且特征组合成的向量的维度为 <span
class="math inline">\(d\)</span>, 则 <span
class="math inline">\(D\_j\)</span> 的大小为 <span
class="math inline">\(m\)</span> X <span
class="math inline">\(d\)</span>, <span class="math inline">\(I\)</span>
为单位向量，而 <span class="math inline">\(\alpha = 1 +
\sqrt{\ln(2/\delta)/2}\)</span> ,因此<strong>，只要根据概率选定 <span
class="math inline">\(\delta\)</span>，则各个arm 的 bound 便可通过 <span
class="math inline">\(\alpha
\sqrt{x\_j^T(D\_j^TD\_j+I)^{-1}x\_j}\)</span> 求出</strong>。</p>
<p>因此 LinUCB 算法流程如下，算法同时包含了选择 arm 的方式和更新 linear
regress 模型。</p>
<figure>
<img src="https://wulc.me/imgs/image_1d0c9tmfu1jf9187016761golc433.png"
alt="LinUCB1" />
<figcaption aria-hidden="true">LinUCB1</figcaption>
</figure>
<p>上面的每个 arm 的 linear model
的参数都是独立的，论文针对这对点设计了这些 model
共享的一些参数，即将原来某个 arm <span class="math inline">\(j\)</span>
计算出来的 <span class="math inline">\(x\_j^T\theta\_j\)</span> 换成了
<span class="math inline">\(x\_j^T\theta\_j + z\_j^T \beta\)</span>,
<span class="math inline">\(\beta\)</span> 是各个模型共享的的参数，<span
class="math inline">\(z\_j^T\)</span>
则是这些参数对应的特征。对应这种情况，也有了论文的第二种算法</p>
<figure>
<img src="https://wulc.me/imgs/image_1d0cb0gnb11ifqtmc971pj3p3t3t.png"
alt="LinUCB2" />
<figcaption aria-hidden="true">LinUCB2</figcaption>
</figure>
<h2 id="thompson-sampling-方法">Thompson sampling 方法</h2>
<p>前面的 UCB 方法采用的都是频率学派的思想，即认为评判某个 arm
的优劣的指标是个定值，如果有无限次的试验，便可准确地计算出这个值，但是由于现实中只能进行有限次的试验，因此预估出来的值是有偏差的，需要通过另外计算一个
bound 来衡量这个误差。</p>
<p>而下面要介绍的 Thompson sampling
方法采用的则是贝叶斯学派的思想，即认为评判某个 arm
的优劣的指标不再是个定值，而是服从着某种假定的分布(先验)，通过观察到的历史记录去更新这个分布的参数(似然)，得到了新的分布参数(后验),
然后不断重复这个过程。当需要进行比较时，从分布中随机产生一个样本即可。</p>
<h3 id="bernoulli-bandit">Bernoulli Bandit</h3>
<p>前面提到，Bernoulli Bandit 假设某个 arm
的优劣服从伯努利分布，即每次是否获得收益的服从参数为 <span
class="math inline">\(\theta\)</span> 的伯努利分布</p>
<p>$p(reward | ) Bernoulli() $</p>
<p>UCB 方法中的 UCB1 和 UCB2 都是通过简单的历史统计得到 <span
class="math inline">\(\overline {x}\_j\)</span> 来表示 <span
class="math inline">\(\theta\)</span> 的，但是贝叶斯学派则认为 <span
class="math inline">\(\theta\)</span>
服从着一个特定的分布，根据贝叶斯公式有</p>
<p><span class="math display">\[p(\theta|reward) =
\frac{p(reward|\theta) p{(\theta)}}{p(reward)} \propto p(reward|\theta)
p{(\theta)} ＝Bernoulli(\theta) p(\theta)\]</span></p>
<p><span class="math inline">\(p(\theta|reward)\)</span>
表示根据观察到的实验收益情况更新的后验概率，且由于似然 <span
class="math inline">\(p(reward|\theta)\)</span>
为伯努利分布，为了保持共轭便于计算；先验分布 <span
class="math inline">\(p(\theta)\)</span> 选择为了 Beta 分布，即 <span
class="math inline">\(Beta(\alpha, \beta)\)</span>，而两个分布相乘 <span
class="math inline">\(Bernoulli(\theta)*Beta(\alpha, \beta)\)</span>
会得到一个新的 Beta 分布, 简单来说，就是</p>
<ul>
<li>当 <span class="math inline">\(Bernoulli(\theta)\)</span>
的结果为1，则会得到 <span class="math inline">\(Beta(\alpha + 1,
\beta)\)</span></li>
<li>当 <span class="math inline">\(Bernoulli(\theta)\)</span>
的结果为0，则会得到 <span class="math inline">\(Beta(\alpha, \beta +
1)\)</span></li>
</ul>
<p>因此，Bernoulli Bandit 中的 Thompson Sampling 步骤如下, 图片摘自 <a
href="https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf">A Tutorial on
Thompson Sampling</a></p>
<figure>
<img
src="https://wulc.me/imgs/image_1d0e3h5bo11oc15e5191q1n4d1hhi4a.png"
alt="Thompson Sampling for Bernoulli Bandit" />
<figcaption aria-hidden="true">Thompson Sampling for Bernoulli
Bandit</figcaption>
</figure>
<h3 id="contextual-bandit">Contextual Bandit</h3>
<p>在 Bernoulli Bandit 中，我们假设 arm
是否获得收益是服从伯努利分布的，即 <span class="math inline">\(p(reward
| \theta) \sim Bernoulli(\theta)\)</span></p>
<p>而在 Contextual Bandit
中，我们假设获得的收益和特征向量存在一个线性关系, 即$reward = x^T
$，因此无法像前面一样直接通过似然 <span class="math inline">\(p(reward |
\theta) \sim Bernoulli(\theta)\)</span> 来更新 <span
class="math inline">\(\theta\)</span></p>
<p>但是根据前面解决 Bernoulli Bandit 的思路，<strong>只要定义 <span
class="math inline">\(p(reward|\theta)\)</span> 和 <span
class="math inline">\(p(\theta)\)</span>
为合适的共轭分布，那么就可以使用Thompson Sampling来解决Contextual
Bandit</strong>, 因为根据贝叶斯公式有如下的公式</p>
<p><span class="math display">\[p(\theta|reward) \propto
p(reward|\theta) p{(\theta)}\]</span></p>
<p>理论上，只要 <span class="math inline">\(p(reward|\theta)\)</span> 和
<span class="math inline">\(p(\theta)\)</span>
为共轭即可，但是考虑到假设的分布的合理性，参考这篇论文 <a
href="https://arxiv.org/pdf/1209.3352.pdf">Thompson Sampling for
Contextual Bandits with Linear
Payoffs</a>，分别对这两个分布都采用正态分布的形式,
论文给出了较多的数学证明，这里略去证明，直接给出最终结论</p>
<p>对于 <span class="math inline">\(p(reward|\theta)\)</span> ，由于估计
reward 为 <span class="math inline">\(x^T\theta\)</span>
，因此假设真实的 reward 服从以 <span
class="math inline">\(x^T\theta\)</span> 为中心、 <span
class="math inline">\(v^2\)</span> 为标准差的正态分布，即 <span
class="math inline">\(p(reward|\theta) \sim \mathcal{N}(x^T\theta,
v^2)\)</span>, <span class="math inline">\(v\)</span>
的具体含义后面会给出</p>
<p>为了运算上的便利性， <span class="math inline">\(p(\theta)\)</span>
一般会选择与 <span class="math inline">\(p(reward|\theta)\)</span>
共轭的形式; 由于 <span class="math inline">\(p(reward|\theta)\)</span>
是正态分布，那么 <span class="math inline">\(p(\theta)\)</span>
也应该是正态分布（正态分布的共轭还是正态分布）</p>
<p>为了便于给出后验概率的形式，论文首先定义了如下的等式</p>
<p><span class="math display">\[B(t) = I\_d + X^TX\]</span></p>
<p><span class="math display">\[\mu(t) = B(t)^{-1}(\sum\_{\tau =
1}^{t-1} x\_{\tau}^Tr\_{\tau})\]</span></p>
<p>上面的 <span class="math inline">\(t\)</span> 表示某个 arm 第 <span
class="math inline">\(t\)</span> 次的试验，<span
class="math inline">\(d\)</span> 表示特征的维度，<span
class="math inline">\(X\)</span> 的含义与 LinUCB 中介绍的一致，即是这个
arm 前 <span class="math inline">\(t-1\)</span>
次的特征组成的矩阵，在这个例子中其维度大小为 (<span
class="math inline">\(t-1\)</span>) X <span
class="math inline">\(d\)</span>, <span
class="math inline">\(r\_{\tau}\)</span> 则表示前面 <span
class="math inline">\(t-1\)</span> 次试验中第 <span
class="math inline">\(\tau\)</span> 次获得的 reward。</p>
<p>则 <span class="math inline">\(p(\theta)\)</span> 在 <span
class="math inline">\(t\)</span> 时刻服从正态分布 <span
class="math inline">\(\mathcal{N}(\mu(t), v^2B(t)^{-1})\)</span>, 而
<span class="math inline">\(p(\theta)\)</span> 与 <span
class="math inline">\(p(reward|\theta)\)</span> 相乘计算出来的后验概率
<span class="math inline">\(p(\theta|reward) \sim \mathcal{N}(\mu(t+1),
v^2B(t+1)^{-1})\)</span></p>
<p>前面提到的 <span class="math inline">\(v\)</span> 的定义为 <span
class="math inline">\(v =
R\sqrt{9d\ln(\frac{t}{\delta})}\)</span>，该式子中的 <span
class="math inline">\(t\)</span> 和 <span
class="math inline">\(d\)</span> 的含义与上面的相同，而 <span
class="math inline">\(R\)</span> 和 <span
class="math inline">\(\delta\)</span>
是需要自定义的两个常数，均是用在两个不等式中约束 regret bound的，其中
<span class="math inline">\(R \ge 0\)</span> ,<span
class="math inline">\(0 \le \delta \lt 1\)</span>,
具体的等式可参考原始论文，这里不再展开。</p>
<p>当 <span class="math inline">\(t = 1\)</span>
也就是在最开始一次试验都没有的时候， <span
class="math inline">\(p(\theta)\)</span> 会被初始化为 <span
class="math inline">\(\mathcal{N}(0, v^2I\_d)\)</span>,</p>
<p>而每次选择 arm 的策略跟上面的 Bernoulli Bandit 类似: 每个 arm 的
<span class="math inline">\(p(reward|\theta)\)</span> 分布分别产生一个
<span class="math inline">\(\theta\)</span>, 然后选择 <span
class="math inline">\(x^t\theta\)</span> 最大的那个 arm 进行试验。</p>
<h2 id="小结">小结</h2>
<p>本文主要介绍了几种针对 EE 问题的策略，除了最简单的随机方法，UCB 和
Thompson Sampling 是这个问题两种比较典型的方法，两个方法的思想均是为每个
arm 计算出一个收益值，然后根据这个值进行 ranking 然后选择值最大的
arm。</p>
<p>UCB 采用的是频率学派的思想，计算的收益值是历史收益加上一个
bound，可以认为历史收益是 Exploitation，而 bound 则是 Exploration；而
Thompson Sampling 方法中每个 arm 的收益值会从一个分布中产生，没有明显的
Exploitation 和 Exploration，但也可以认为从分布中较大概率产生的值是
Exploitation ，而较小概率产生的值是
Exploration。另外，文中重点是介绍这些方法的具体做法，更多关于这些方法的理论基础和数学推导可参考下面这些文献。</p>
<hr />
<p>参考：</p>
<ul>
<li><a
href="https://zhuanlan.zhihu.com/p/32311522">开栏：智能决策系列</a></li>
<li><a
href="https://x-algo.cn/index.php/2016/12/15/ee-problem-and-bandit-algorithm-for-recommender-systems/#">推荐系统的EE问题及Bandit算法</a></li>
<li><a
href="http://home.deib.polimi.it/restelli/MyWebSite/pdf/rl5.pdf">Reinforcement
Learning: Exploration vs Exploitation</a></li>
<li><a
href="https://www.cs.cornell.edu/courses/cs6840/2017sp/lecnotes/6840sp17R_Kleinberg.pdf">Multi-Armed
Bandits and the Gittins Index</a></li>
<li><a href="https://arxiv.org/pdf/1705.10257.pdf">Boltzmann Exploration
Done Right</a></li>
<li><a
href="https://jeremykun.com/2013/10/28/optimism-in-the-face-of-uncertainty-the-ucb1-algorithm/">Optimism
in the Face of Uncertainty: the UCB1 Algorithm</a></li>
<li><a
href="https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf">Finite-time
Analysis of the Multiarmed Bandit Problem</a></li>
<li><a
href="https://arxiv.org/ftp/arxiv/papers/1205/1205.2606.pdf">Exploring
compact reinforcement-learning representations with linear
regression</a></li>
<li><a href="https://web.stanford.edu/~bvr/pubs/TS_Tutorial.pdf">A
Tutorial on Thompson Sampling</a></li>
<li><a href="http://rob.schapire.net/papers/www10.pdf">A Contextual-Ba
ndit Approach to Personalized News Article Recommendation</a></li>
</ul>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Effective Go 摘记</title>
    <url>/2019/02/18/Effective%20Go%20%E6%91%98%E8%AE%B0/</url>
    <content><![CDATA[<p>本文是 <a href="https://golang.org/doc/effective_go.html">Effective
Go</a> 中的一些摘记，主要涉及 golang
中的语法、技巧、风格等。为了尽可能保持原文意思，会通过英文记录相关的知识点。</p>
<span id="more"></span>
<h2 id="formatting">Formatting</h2>
<ul>
<li>The gofmt program (also available as <code>go fmt</code>, which
operates at the package level rather than source file level) reads a Go
program and emits the source in a standard style of indentation and
vertical alignment, retaining and if necessary reformatting
comments.</li>
</ul>
<h2 id="commentary">Commentary</h2>
<ul>
<li><p><strong>Every package should have a package comment, a block
comment preceding the package clause.</strong> For multi-file packages,
the package comment only needs to be present in one file, and any one
will do. The package comment should introduce the package and provide
information relevant to the package as a whole, for example
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">Package regexp implements a simple library for regular expressions.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">The syntax of the regular expressions accepted is:</span></span><br><span class="line"><span class="comment">    .......</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">package</span> regexp</span><br></pre></td></tr></table></figure></p></li>
<li><p>Doc comments work best as complete sentences, which allow a wide
variety of automated presentations. <strong>The first sentence should be
a one-sentence summary that starts with the name being
declared</strong>. <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Compile parses a regular expression and returns, if successful,</span></span><br><span class="line"><span class="comment">// a Regexp that can be used to match against text.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Compile</span><span class="params">(str <span class="type">string</span>)</span></span> (*Regexp, <span class="type">error</span>) &#123;</span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>Grouping variables</strong> can indicate relationships
between items, such as the fact that a set of variables is protected by
a mutex. <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    countLock   sync.Mutex</span><br><span class="line">    inputCount  <span class="type">uint32</span></span><br><span class="line">    outputCount <span class="type">uint32</span></span><br><span class="line">    errorCount  <span class="type">uint32</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="names">Names</h2>
<ul>
<li><p>By convention, <strong>packages are given lower case, single-word
names, no need for underscores or mixedCaps</strong></p></li>
<li><p>Another convention is that <strong>the package name is the base
name of its source directory</strong>; the package in
"src/encoding/base64" is imported as "encoding/base64" but has name
base64, not encoding_base64 and not encodingBase64</p></li>
<li><p>By convention, <strong>one-method interfaces are named by the
method name plus an -er suffix</strong> or similar modification to
construct an agent noun: Reader, Writer, Formatter,
CloseNotifier</p></li>
<li><p>the convention in Go is to <strong>use <code>MixedCaps</code> or
<code>mixedCaps</code> rather than underscores to write multiword
names</strong></p></li>
</ul>
<h2 id="control-structures">Control structures</h2>
<ul>
<li><p><code>if</code> and <code>switch</code> accept an
<strong>optional initialization statement</strong> like that of
<code>for</code> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> err := file.Chmod(<span class="number">0664</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Print(err)</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>In a <code>:=</code> declaration a variable v may appear even if
it has already been declared, providing that <strong>there is at least
one other variable in the declaration that is being declared
anew</strong>, otherwise an error
<code>no new variables on left side of :=</code> will occur
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// legal for err</span></span><br><span class="line">f, err := os.Open(name)</span><br><span class="line">d, err := f.Stat()</span><br><span class="line"></span><br><span class="line"><span class="comment">// not legal for a</span></span><br><span class="line">a := <span class="number">1</span></span><br><span class="line">a := <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// not legal for a and b</span></span><br><span class="line">a, b := <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">a, b := <span class="number">2</span>, <span class="number">2</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>For strings, the <code>range</code> breaks out individual
Unicode code points</strong> by parsing the UTF-8. Erroneous encodings
consume one byte and produce the replacement rune U+FFFD, <strong>rune
is Go terminology for a single Unicode code point</strong>, similar to
char in other languages <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> pos, char := <span class="keyword">range</span> <span class="string">&quot;日本\x80語&quot;</span> &#123; <span class="comment">// \x80 is an illegal UTF-8 encoding</span></span><br><span class="line">    fmt.Printf(<span class="string">&quot;character %#U starts at byte position %d\n&quot;</span>, char, pos)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* output</span></span><br><span class="line"><span class="comment">character U+65E5 &#x27;日&#x27; starts at byte position 0</span></span><br><span class="line"><span class="comment">character U+672C &#x27;本&#x27; starts at byte position 3</span></span><br><span class="line"><span class="comment">character U+FFFD &#x27;�&#x27; starts at byte position 6</span></span><br><span class="line"><span class="comment">character U+8A9E &#x27;語&#x27; starts at byte position 7</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>if the <code>switch</code>has no expression it switches on true.
It's therefore possible—and idiomatic—to <strong>write an
if-else-if-else chain as a switch</strong>. <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">unhex</span><span class="params">(c <span class="type">byte</span>)</span></span> <span class="type">byte</span> &#123;</span><br><span class="line">    <span class="keyword">switch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;0&#x27;</span> &lt;= c &amp;&amp; c &lt;= <span class="string">&#x27;9&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> c - <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;a&#x27;</span> &lt;= c &amp;&amp; c &lt;= <span class="string">&#x27;f&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> c - <span class="string">&#x27;a&#x27;</span> + <span class="number">10</span></span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;A&#x27;</span> &lt;= c &amp;&amp; c &lt;= <span class="string">&#x27;F&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> c - <span class="string">&#x27;A&#x27;</span> + <span class="number">10</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="functions">Functions</h2>
<ul>
<li><p>Deferred functions are executed in <strong>LIFO order(imagine it
like a stack)</strong>, so the following code will cause 4 3 2 1 0 to be
printed when the function returns. <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">defer</span> fmt.Printf(<span class="string">&quot;%d &quot;</span>, i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>The <strong>arguments to deferred functions are evaluated when
the defer executes</strong>, not when the function executes
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">trace</span><span class="params">(s <span class="type">string</span>)</span></span> <span class="type">string</span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;entering:&quot;</span>, s)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">un</span><span class="params">(s <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;leaving:&quot;</span>, s)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">a</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">defer</span> un(trace(<span class="string">&quot;a&quot;</span>))</span><br><span class="line">    fmt.Println(<span class="string">&quot;in a&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">b</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">defer</span> un(trace(<span class="string">&quot;b&quot;</span>))</span><br><span class="line">    fmt.Println(<span class="string">&quot;in b&quot;</span>)</span><br><span class="line">    a()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    b()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*output</span></span><br><span class="line"><span class="comment">entering: b</span></span><br><span class="line"><span class="comment">in b</span></span><br><span class="line"><span class="comment">entering: a</span></span><br><span class="line"><span class="comment">in a</span></span><br><span class="line"><span class="comment">leaving: a</span></span><br><span class="line"><span class="comment">leaving: b</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="data">Data</h2>
<h3 id="new-v.s-make">new v.s make</h3>
<ul>
<li><p>Go has two allocation primitives, the built-in functions
<strong><code>new</code> and <code>make</code></strong></p></li>
<li><p><code>New</code> does not initialize the memory,
<strong><code>new(T)</code> allocates zeroed storage for a new item of
type T and returns its address,</strong> that is a pointer to a newly
allocated zero value of type T, it's helpful to arrange when designing
your data structures that the zero value of each type can be used
without further initialization</p></li>
<li><p>Sometimes <strong>the zero value isn't good enough and an
initializing constructor is necessary</strong>, as in this example
derived from package os <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewFile</span><span class="params">(fd <span class="type">int</span>, name <span class="type">string</span>)</span></span> *File &#123;</span><br><span class="line">    <span class="keyword">if</span> fd &lt; <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">    f := <span class="built_in">new</span>(File)</span><br><span class="line">    f.fd = fd</span><br><span class="line">    f.name = name</span><br><span class="line">    f.dirinfo = <span class="literal">nil</span></span><br><span class="line">    f.nepipe = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> f</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>We can simplify it using a <strong>composite literal</strong>,
which is an expression that creates a new instance each time it is
evaluated(<code>File&#123;fd, name, nil, 0&#125;</code> in the following code). If
a composite literal contains no fields at all, it creates a zero value
for the type. <strong>The expressions <code>new(File)</code> and
<code>&amp;File&#123;&#125;</code> are equivalent</strong>.
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewFile</span><span class="params">(fd <span class="type">int</span>, name <span class="type">string</span>)</span></span> *File &#123;</span><br><span class="line">    <span class="keyword">if</span> fd &lt; <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">    f := File&#123;fd, name, <span class="literal">nil</span>, <span class="number">0</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> &amp;f</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>Note that <strong>unlike in C, it's perfectly OK to return the
address of a local variable</strong>, the storage associated with the
variable survives after the function returns</p></li>
<li><p><code>make(T, args)</code> serves a purpose different from
new(T), it **creates slices, maps, and channels only, and it returns an
initialized (not zeroed) value of type T (not *T)**</p></li>
<li><p>The reason for the distinction is that these three types(slices,
maps, and channels) represent, under the covers, references to
<strong>data structures that must be initialized before
use</strong></p></li>
</ul>
<h3 id="array-v.s-slice">array v.s slice</h3>
<ul>
<li><p>There are major differences between the ways arrays work in Go
and C. In Go,</p>
<ul>
<li>Arrays are values. <strong>Assigning one array to another copies all
the elements</strong>.</li>
<li>In particular, if you <strong>pass an array to a function, it will
receive a copy of the array, not a pointer to it</strong>.</li>
<li>The size of an array is part of its type. <strong>The types [10]int
and [20]int are distinct</strong></li>
</ul></li>
<li><p>The value property can be useful but also expensive; <strong>if
you want C-like behavior and efficiency, you can pass a pointer to the
array</strong></p></li>
<li><p>A slice does not store any data, it just describes a section of
an underlying array, so <strong>if you assign one slice to another, both
refer to the same array</strong> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">names := [<span class="number">4</span>]<span class="type">string</span>&#123;</span><br><span class="line">	<span class="string">&quot;John&quot;</span>,</span><br><span class="line">	<span class="string">&quot;Paul&quot;</span>,</span><br><span class="line">	<span class="string">&quot;George&quot;</span>,</span><br><span class="line">	<span class="string">&quot;Ringo&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">a := names[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">b := names[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">b[<span class="number">0</span>] = <span class="string">&quot;XXX&quot;</span></span><br><span class="line">fmt.Println(a, b)</span><br><span class="line">fmt.Println(names)</span><br><span class="line"><span class="comment">// output</span></span><br><span class="line"><span class="comment">// [John XXX] [XXX George]</span></span><br><span class="line"><span class="comment">// [John XXX George Ringo]</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>If a function takes a slice argument, <strong>modification of
elements of the slice will be visible to the caller, but append elements
won't</strong>, if you want to append elements to slice in function,
pass the address instead</p></li>
<li><p>slices are variable-length, for a two-dimensional slice, it is
possible to <strong>have each inner slice be a different length</strong>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">text := LinesOfText&#123;</span><br><span class="line">	[]<span class="type">byte</span>(<span class="string">&quot;Now is the time&quot;</span>),</span><br><span class="line">	[]<span class="type">byte</span>(<span class="string">&quot;for all good gophers&quot;</span>),</span><br><span class="line">	[]<span class="type">byte</span>(<span class="string">&quot;to bring some fun to the party.&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="map">map</h3>
<ul>
<li><p>For a map in golang like <code>map[KeyType]ValueType</code>,
<strong>KeyType may be any type that is <a
href="https://golang.org/ref/spec#Comparison_operators">comparable</a></strong>
,such as integers, floating point and complex numbers, strings,
pointers, interfaces (as long as the dynamic type supports
equality).Slices cannot be used as map keys, because equality is not
defined on them, and <strong>ValueType may be any type at all, including
another map!</strong> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">hits := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">int</span>)</span><br><span class="line">n := hits[<span class="string">&quot;/doc/&quot;</span>][<span class="string">&quot;au&quot;</span>]</span><br></pre></td></tr></table></figure></p></li>
<li><p>Like slices, maps hold references to an underlying data
structure. <strong>If you pass a map to a function that changes the
contents of the map, the changes will be visible in the
caller.</strong></p></li>
<li><p>An attempt to fetch a map value with <strong>a key that is not
present in the map will return the zero value for the type of the
entries in the map</strong>.The zero value is:</p>
<ul>
<li>0 for numeric types,</li>
<li>false for the boolean type</li>
<li>"" (the empty string) for strings.</li>
</ul></li>
<li><p>If you need to judge whether a key in map, you can do this
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> val, ok := dict[<span class="string">&quot;foo&quot;</span>]; ok &#123;</span><br><span class="line">    <span class="comment">//do something here</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="methods">Methods</h2>
<ul>
<li><p>Methods can be defined for any named type (except a pointer or an
interface); <strong>the receiver does not have to be a struct.</strong>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> ByteSlice []<span class="type">byte</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(slice ByteSlice)</span></span> Append(data []<span class="type">byte</span>) []<span class="type">byte</span> &#123;</span><br><span class="line">    <span class="comment">// Body exactly the same as the Append function defined above.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>The rule about pointers vs. values for receivers is that
<strong>value methods can be invoked on pointers and values, but pointer
methods can only be invoked on pointers</strong>.</p></li>
</ul>
<h2 id="interfaces-and-other-types">Interfaces and other types</h2>
<h3 id="interfaces">Interfaces</h3>
<ul>
<li><p>An interface is defined as <strong>a set of method
signatures</strong>, and a type implements an interface by implementing
its methods. <strong>A type can implement multiple interfaces</strong>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Sequence []<span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Methods required by sort.Interface.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Sequence)</span></span> Len() <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(s)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Sequence)</span></span> Less(i, j <span class="type">int</span>) <span class="type">bool</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> s[i] &lt; s[j]</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s Sequence)</span></span> Swap(i, j <span class="type">int</span>) &#123;</span><br><span class="line">    s[i], s[j] = s[j], s[i]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>You can define your own interface and <strong>a value of
interface type can hold any value that implements those
methods</strong>. <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Abser <span class="keyword">interface</span> &#123;</span><br><span class="line">	Abs() <span class="type">float64</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyFloat <span class="type">float64</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f MyFloat)</span></span> Abs() <span class="type">float64</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> f &lt; <span class="number">0</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="type">float64</span>(-f)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="type">float64</span>(f)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> a Abser</span><br><span class="line">	f := MyFloat(-math.Sqrt2)</span><br><span class="line">	a = f  <span class="comment">// a MyFloat implements Abser</span></span><br><span class="line">	fmt.Println(a.Abs())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="concurrency">Concurrency</h2>
<h3 id="share-by-communicating">Share by communicating</h3>
<ul>
<li><p>Concurrent programming in many environments is made difficult by
the subtleties required to implement correct access to shared
variables.</p></li>
<li><p>Go encourages a different approach in which <strong>shared values
are passed around on channels and, in fact, never actively shared by
separate threads of execution，only one goroutine has access to the
value at any given time</strong>.</p></li>
<li><p>For example，Reference counts may be best done by putting a mutex
around an integer variable. But as a high-level approach, using channels
to control access makes it easier to write clear, correct
programs.</p></li>
</ul>
<h3 id="goroutines">Goroutines</h3>
<ul>
<li><p>A goroutine has a simple model: it is a function executing
concurrently with other goroutines in the <strong>same address
space</strong>.</p></li>
<li><p>Prefix a function or method call with the <code>go</code> keyword
to run the call in a new goroutine. When the call completes, <strong>the
goroutine exits silently</strong>，don't wait for it.</p></li>
</ul>
<h3 id="channels">Channels</h3>
<ul>
<li><p>Like maps, channels are allocated with <code>make</code>, and the
resulting value acts as a <strong>reference to an underlying data
structure</strong></p></li>
<li><p>There are lots of nice idioms using channels. For example, if we
launched a sort in the background and do sth else while waiting for the
goroutine to finish. A channel allows us to do so
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)  <span class="comment">// Allocate a channel.</span></span><br><span class="line"><span class="comment">// Start the sort in a goroutine; when it completes, signal on the channel.</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    list.Sort()</span><br><span class="line">    c &lt;- <span class="number">1</span>  <span class="comment">// Send a signal; value does not matter.</span></span><br><span class="line">&#125;()</span><br><span class="line">doSomethingForAWhile()</span><br><span class="line">&lt;-c   <span class="comment">// Wait for sort to finish; discard sent value.</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>The above code works becase <strong>receivers always block until
there is data to receive</strong>. As for the sender, if the channel is
unbuffered, the sender blocks until the receiver has received the value.
If the channel has a buffer, the sender blocks only until the value has
been copied to the buffer; if the buffer is full, this means waiting
until some receiver has retrieved a value.</p></li>
<li><p><strong>A buffered channel can be used like a semaphore</strong>,
for instance to limit throughput. In the following example, incoming
requests are passed to handle, which sends a value into the channel,
processes the request, and then receives a value from the channel to
ready the “semaphore” for the next consumer. <strong>The capacity of the
channel buffer limits the number of simultaneous calls to
process.</strong> <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> sem = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, MaxOutstanding)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(r *Request)</span></span> &#123;</span><br><span class="line">    sem &lt;- <span class="number">1</span>    <span class="comment">// Wait for active queue to drain.</span></span><br><span class="line">    process(r)  <span class="comment">// May take a long time.</span></span><br><span class="line">    &lt;-sem       <span class="comment">// Done; enable next request to run.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(queue <span class="keyword">chan</span> *Request)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        req := &lt;-queue</span><br><span class="line">        <span class="keyword">go</span> handle(req)  <span class="comment">// Don&#x27;t wait for handle to finish.</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>The above design has a problem: Serve creates a new goroutine for
every incoming request, even though only MaxOutstanding of them can run
at any moment. As a result, <strong>the program can consume unlimited
resources if the requests come in too fast</strong>. We can address that
deficiency by changing Serve to gate the creation of the goroutines.
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(queue <span class="keyword">chan</span> *Request)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> req := <span class="keyword">range</span> queue &#123;</span><br><span class="line">        sem &lt;- <span class="number">1</span></span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            process(req) <span class="comment">// Buggy; see explanation below.</span></span><br><span class="line">            &lt;-sem</span><br><span class="line">        &#125;()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>The bug in the above code is that <strong>in a Go
<code>for</code> loop, the loop variable is reused for each iteration,
so the req variable is shared across all goroutines</strong>. But we
need to make sure that req is unique for each goroutine. Here's one way
to do that, <strong>passing the value of req as an argument to the
closure in the goroutine</strong>: <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(queue <span class="keyword">chan</span> *Request)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> req := <span class="keyword">range</span> queue &#123;</span><br><span class="line">        sem &lt;- <span class="number">1</span></span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(req *Request)</span></span> &#123;</span><br><span class="line">            process(req)</span><br><span class="line">            &lt;-sem</span><br><span class="line">        &#125;(req)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>Another solution is just to create a new variable with the same
name, like the following code, <code>req := req</code> may seem odd, but
it's legal and idiomatic in Go to do this. You get a fresh version of
the variable with the same name <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(queue <span class="keyword">chan</span> *Request)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> req := <span class="keyword">range</span> queue &#123;</span><br><span class="line">        req := req <span class="comment">// Create new instance of req for the goroutine.</span></span><br><span class="line">        sem &lt;- <span class="number">1</span></span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            process(req)</span><br><span class="line">            &lt;-sem</span><br><span class="line">        &#125;()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>Another approach that manages resources well is to <strong>start
a fixed number of handle goroutines all reading from the request
channel</strong>. The number of goroutines limits the number of
simultaneous calls to process. <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(queue <span class="keyword">chan</span> *Request)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> r := <span class="keyword">range</span> queue &#123;</span><br><span class="line">        process(r)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(clientRequests <span class="keyword">chan</span> *Request, quit <span class="keyword">chan</span> <span class="type">bool</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// Start handlers</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; MaxOutstanding; i++ &#123;</span><br><span class="line">        <span class="keyword">go</span> handle(clientRequests)</span><br><span class="line">    &#125;</span><br><span class="line">    &lt;-quit  <span class="comment">// Wait to be told to exit.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h3 id="channels-of-channels">Channels of channels</h3>
<ul>
<li><p>In the example in the previous section, handle was an idealized
handler for a request but we didn't define the type it was handling.
<strong>If that type includes a channel on which to reply, each client
can provide its own path for the answer</strong>.
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Request <span class="keyword">struct</span> &#123;</span><br><span class="line">    args        []<span class="type">int</span></span><br><span class="line">    f           <span class="function"><span class="keyword">func</span><span class="params">([]<span class="type">int</span>)</span></span> <span class="type">int</span></span><br><span class="line">    resultChan  <span class="keyword">chan</span> <span class="type">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>The client provides a function and its arguments, as well as a
channel inside the request object on which to receive the answer.
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sum</span><span class="params">(a []<span class="type">int</span>)</span></span> (s <span class="type">int</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> _, v := <span class="keyword">range</span> a &#123;</span><br><span class="line">        s += v</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request := &amp;Request&#123;[]<span class="type">int</span>&#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;, sum, <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)&#125;</span><br><span class="line"><span class="comment">// Send request</span></span><br><span class="line">clientRequests &lt;- request</span><br></pre></td></tr></table></figure></p></li>
<li><p>On the server side, the handler function is the only thing that
changes. <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(queue <span class="keyword">chan</span> *Request)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> req := <span class="keyword">range</span> queue &#123;</span><br><span class="line">        req.resultChan &lt;- req.f(req.args)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="errors">Errors</h2>
<ul>
<li><p>Library routines must often return some sort of error indication
to the caller, it is easy to return a detailed error description
alongside the normal return value with Go's multivalue return
feature</p></li>
<li><p>Type <code>error</code> is a simple built-in interface, and
library writer is free to implement this interface with a richer model
under the covers, making it possible not only to see the error but also
to provide some context <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// built-in error interface</span></span><br><span class="line"><span class="keyword">type</span> <span class="type">error</span> <span class="keyword">interface</span> &#123;</span><br><span class="line">    Error() <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// custom error</span></span><br><span class="line"><span class="comment">// PathError records an error and the operation and</span></span><br><span class="line"><span class="comment">// file path that caused it.</span></span><br><span class="line"><span class="keyword">type</span> PathError <span class="keyword">struct</span> &#123;</span><br><span class="line">    Op <span class="type">string</span>    <span class="comment">// &quot;open&quot;, &quot;unlink&quot;, etc.</span></span><br><span class="line">    Path <span class="type">string</span>  <span class="comment">// The associated file.</span></span><br><span class="line">    Err <span class="type">error</span>    <span class="comment">// Returned by the system call.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *PathError)</span></span> Error() <span class="type">string</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> e.Op + <span class="string">&quot; &quot;</span> + e.Path + <span class="string">&quot;: &quot;</span> + e.Err.Error()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PathError&#x27;s Error will generate a string like this:</span></span><br><span class="line"><span class="comment">// open /etc/passwx: no such file or directory</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>The usual way to report an error to a caller is to return an
error as an extra return value, but sometimes <strong>the error is
unrecoverable</strong>, the program simply cannot continue. We can use
the built-in function <code>panic</code> in this case</p></li>
<li><p><strong><code>panic</code> function takes a single argument of
arbitrary type—often a string—to be printed as the program
dies</strong>. It's also a way to indicate that something impossible has
happened, for example,it is reasonable to use <code>panic</code> with
the failure of initialization, <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = os.Getenv(<span class="string">&quot;USER&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> user == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(<span class="string">&quot;no value for $USER&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>When <code>panic</code> is called, including implicitly for
run-time errors such as indexing a slice out of bounds or failing a type
assertion, it immediately <strong>stops execution of the current
function and begins unwinding the stack of the goroutine, running any
deferred functions along the way.</strong> If that unwinding reaches the
top of the goroutine's stack, the program dies. But it is possible to
<strong>use the built-in function <code>recover</code> to regain control
of the goroutine and resume normal execution.</strong></p></li>
<li><p>A call to <code>recover</code> stops the unwinding and returns
the argument passed to <code>panic</code>. Because the only code that
runs while unwinding is inside deferred functions,
<strong><code>recover</code> is only useful inside deferred
functions.</strong></p></li>
<li><p><strong>One application of <code>recover</code> is to shut down a
failing goroutine inside a server without killing the other executing
goroutines.</strong> In this example, if <code>do(work)</code> panics,
the result will be logged and the goroutine will exit cleanly without
disturbing the others <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">server</span><span class="params">(workChan &lt;-<span class="keyword">chan</span> *Work)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> work := <span class="keyword">range</span> workChan &#123;</span><br><span class="line">        <span class="keyword">go</span> safelyDo(work)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">safelyDo</span><span class="params">(work *Work)</span></span> &#123;</span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> err := <span class="built_in">recover</span>(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">            log.Println(<span class="string">&quot;work failed:&quot;</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    do(work)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="some-syntax">Some Syntax</h2>
<ul>
<li><p><code>int(math.Pow(float64(x), float64(count)))</code></p></li>
<li><p><code>Atoi</code> (string to int) and <code>Itoa</code> (int to
string). <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">i, err := strconv.Atoi(<span class="string">&quot;-42&quot;</span>)</span><br><span class="line">s := strconv.Itoa(<span class="number">-42</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>concate string <code>s1</code> and <code>s2</code>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line">buffer := bytes.NewBufferString(s1)</span><br><span class="line">buffer.WriteString(s2)</span><br><span class="line">buffer.String()</span><br></pre></td></tr></table></figure></p></li>
<li><p><code>append</code> function <figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="comment">// append multiple elements</span></span><br><span class="line">x := []<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">x = <span class="built_in">append</span>(x, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// append a slice </span></span><br><span class="line">x := []<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">y := []<span class="type">int</span>&#123;<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>&#125;</span><br><span class="line">x = <span class="built_in">append</span>(x, y...)</span><br></pre></td></tr></table></figure></p></li>
</ul>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Exposure Bias In Machine Learning</title>
    <url>/2021/04/03/Exposure%20Bias%20In%20Machine%20Learning/</url>
    <content><![CDATA[<p>机器学习本质上是在学习数据的分布, 其有效性的假设是模型 training 和
serving 时的数据是独立同分布(Independent and Identically Distributed,
IID) 的，但是在实际应用中，由于采样有偏、具体场景等约束， training
的样本与 serving 时的样本并不是 IID 的。在广告场景下，最典型的就是训练
cvr 模型时，训练样本都是 post clicked 的，但是 serving 时，cvr
模型面临的是所有被召回的样本；这类问题也被称为 exposure bias 或 sample
selection bias，除了 exposure bias，position bias 等也是常见的
bias。</p>
<p>本文首先会简单介绍一些机器学习中的常见 bias，并着重介绍上面提到的
exposure bias(也叫 sample selection bias) 的在当前的一些解决思路,
笔者将其总结为 Data Augmentation、IPS 和 Domain Adaption
三大类方法。</p>
<span id="more"></span>
<h2 id="bias-in-recommender-system">Bias In Recommender System</h2>
<p>除了本文要重点介绍的 exposure bias，这篇综述 <a
href="https://arxiv.org/abs/2010.03240">Bias and Debias in Recommender
System: A Survey and Future Directions</a>
描述了当前的推荐系统中存在的若干种 bias，paper 将当前的推荐系统划分为
User、Data、Model 三个大模块，并将各个模块的 iteraction 导致的 7 种 bias
归纳成下图</p>
<figure>
<img src="https://wulc.me/imgs/BiasInML.jpg" alt="Bias in ML" />
<figcaption aria-hidden="true">Bias in ML</figcaption>
</figure>
<ul>
<li>User-&gt;Data: 产生训练数据的过程，也是 Bias 的最主要来源
<ul>
<li>Position Bias(implicit)：用户更倾向于和位置靠前的物品进行交互</li>
<li>Exposure/Observation
Bias(implicit)：带标签的数据都是曝光过的，未曝光的数据无法确定其标签</li>
<li>Selection
Bias(explicit)：用户倾向于给自己喜欢或者不喜欢的物品进行打分(导致
exposure bias 的一个重要原因，不少 paper 将这个 bias 也当做 exposure
bias)</li>
<li>Conformity
Bias(explicit)：用户打分的分数倾向于和群体观点保持一致</li>
</ul></li>
<li>Data-&gt;Model: 利用数据训练出模型的过程
<ul>
<li><a href="https://en.wikipedia.org/wiki/Inductive_bias">Inductive
Bias</a>: 指的是模型为了泛化性而做出的一些 assumption，如 Occam's
razor，SVM 假设线性可分的 assumption 等，这个 bias
没有带来显示的缺陷</li>
</ul></li>
<li>Model-&gt;User Interaction: 指的是模型预估的过程
<ul>
<li>Popularity
Bias：指的是长尾效应，热门物品会得到更高的曝光概率，因为模型会更倾向于推荐这些物品（unbalanced
training data 引起）</li>
<li>Unfairness: 一些预估结果带有性别歧视、种族歧视等（unbalanced
training data 引起</li>
</ul></li>
</ul>
<p>上面的各种 bias 的起因、影响以及一些解决思路可归纳为下表</p>
<figure>
<img src="https://wulc.me/imgs/BiasTableInML.jpg"
alt="Bias details Table" />
<figcaption aria-hidden="true">Bias details Table</figcaption>
</figure>
<p>可以看到，上面这些 bias 并不是孤立的，而是相互影响和恶化的，其中
position bias 和 exposure bias
又是最为常见且相关研究较多的一个领域，下面主要详细描述一些应对 exposure
bias 的方法，值得注意的是，这里的 selection bias 跟 exposure bias
面临的问题是一致的，因此这里的方法也会一并归纳； bias
相应的方法可以参考上面的 paper。</p>
<h2 id="solutions-to-exposure-bias">Solutions to Exposure Bias</h2>
<p>exposure bias 也被称为 Sample Selection Bias(SSB), 本质上是一个
<strong>training 和 serving
不一致的问题</strong>。这个问题往往是由于具体业务场景的限制，导致
training data 中的样本只是其 serving
时的很小一部分，因为其他的样本没被曝光/点击，导致了无法得到其
label。</p>
<p>如文章开头提到的 cvr
模型，对于那些不被点击的样本是无法得知其是否被转化的；同样地，在 ctr
模型中，那些没有曝光机会的样本是无法得知其是否被点击的了；但是在 serving
阶段，ctr/cvr
模型面对的是所有的样本，而其中有很多是从未曝光过的，因此便导致了一个
training 与 serving 不一致的问题。</p>
<p>针对这个问题，当前有以下几种解决思路(不限于上面综述的 paper)</p>
<ol type="1">
<li><strong>Data
Augmentation</strong>：这个是最朴素的想法，就是尽可能将那些没进入训练数据集的样本利用上，因此不少研究也是给
unobserved/unclicked 的样本打上一个<strong>相对准确的
label</strong>；而这里面也主要分为下面三类方法</li>
</ol>
<ul>
<li>最粗暴的是把所有未曝光的样本当做 negative
sample，然后基于不同策略给这些样本不同的权重</li>
<li>训练一个 imputation model，然后通过 imputation model
来预估未曝光样本的 label</li>
<li>通过 multitask 的方式建模，训练使用前一转化目标的全量样本(ESMM)</li>
</ul>
<ol start="2" type="1">
<li><p><strong>IPS(Inverse Propensity Score)</strong>:
这个方法的假设是样本被<strong>曝光或点击服一个伯努利分布</strong>，然后从概率论推导出：只要给每个曝光的样本加权(权重即为
inverse propensity
score)，最终在曝光的样本上求得的期望等于在全量样本上的期望；实际上，这个方法的思想就是
<a href="https://en.wikipedia.org/wiki/Importance_sampling">importance
sampling</a></p></li>
<li><p><strong>Domain Adaption</strong>: 类似 transfer learning
的思想，将曝光/点击的样本视为 source domain，全部样本视为 target
domain；通过 domain adaption 的一些方法去进行 debias</p></li>
</ol>
<h3 id="data-augmentation">Data Augmentation</h3>
<p>上面提到了，最朴素的想法是将那些未被观测到的样本利用上，而这里面又可分为三大类方法：all
nagative with confidence、imputation model 和 multitask learning</p>
<h4 id="all-nagative-with-confidence">all nagative with confidence</h4>
<p>第一类方法是将所有未被观测到的样本都当做负样本，而这里的核心是如何给每个样本一个合理的
confidence，其实就是样本的加权，上面提到的综述中介绍了三种方法，分别是
<strong>Heuristic、Sampling、Exposure-based model</strong></p>
<ul>
<li><p>Heuristic 尝试将 user activity level、user preference、item
popularity、user-item feature similarity 等作为 (user, item) pair 的
confidence,
其思想都是认为用户活跃度越高、商品越热门、用户-商品匹配度越高，该样本的可信度(confidence)
越高；但是这种方法往往可行性不够高，因为这个 confidence
实际的值是比较难获取的，其量纲以及需要对庞大的数据集都生成这个
confidence，难度是很大的。</p></li>
<li><p>Sampling：TODO</p></li>
<li><p>Exposure-based mode：TODO</p></li>
</ul>
<h4 id="imputation-model">imputation model</h4>
<p>第二种方法也很直观，就是训练一个 imputation model
为那些未曝光/点击的样本打上标签，然后基于这些 imputed label
来训练模型；而 imputation model 可单独训练，也与目标的模型做 joint
training；这个方法的弊端也很明显，就是生成的 imputed label 缺少绝对的
ground truth 来衡量其效果，实际上，这个是所有直接为样本生成 label
的方法的弊端。</p>
<h4 id="multitask-learning">multitask learning</h4>
<p>第三种方法是基于 multitask
的方法，主要思想就是<strong>同时建模当前的任务及其更浅一层的任务，进而间接利用那些没被曝光/点击的数据</strong>；其中为人熟知的是阿里在
2018 年发表的 ESMM, <a
href="https://arxiv.org/pdf/1804.07931.pdf">Entire Space Multi-Task
Model: An Eﬀective Approach for Estimating Post-Click Conversion
Rate</a>，这篇 paper 主要针对的是 cvr 模型中缺少未点击的样本带来的
bias，增加了两个 auxiliary task(CTR 和 CTCVR)
来缓解这个问题，总体的模型结构如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/ESMM_Model.jpg" alt="ESMM" />
<figcaption aria-hidden="true">ESMM</figcaption>
</figure>
<p>训练的 loss function 如下所示(<span class="math inline">\(y\)</span>
表示点击事件，<span class="math inline">\(z\)</span> 表示转化事件)</p>
<p><span class="math display">\[\begin{align}
L(\theta_{ctr},\theta_{cvr}) &amp;=
\sum_{i=1}^{N}l(y_i,f(x_i;\theta_{ctr})) \notag \\\
&amp;+\sum_{i=1}^{N}l(y_i\&amp;
z_i,f(x_i;\theta_{ctr})×f(x_i;\theta_{cvr})) \notag
\end{align}\]</span></p>
<p>可以将模型利用的样本视为 (show, click, convert) pair 对，则相比传统
cvr 模型，ESMM
能够利用那些曝光未点击的样本(即下表中最后一列，0/1表示对应的中间链路事件是否发生)</p>
<table>
<thead>
<tr class="header">
<th>show</th>
<th>click</th>
<th>convert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>在预估时，通过如下条件概率公式，能够从统计意义上保证 cvr
的值是无偏的</p>
<p><span class="math display">\[p(z=1|y=1,x) =
\frac{p(y=1,z=1|x)}{p(y=1|x)}\]</span></p>
<p>实验效果如下，各种方法的具体含义如下</p>
<figure>
<img src="https://wulc.me/imgs/ESMM_EXP.jpg" alt="ESMM 效果对比" />
<figcaption aria-hidden="true">ESMM 效果对比</figcaption>
</figure>
<ul>
<li>BASE: 普通建模 CVR 模型</li>
<li>AMAN: 对负样本做 negative sampling</li>
<li>OVERSAMPLING: 对正样本做 over sampling</li>
<li>UNBIAS: 参考 <a href="http://wnzhang.net/papers/unbias-kdd.pdf">这篇
paper</a> 将 pCTR 当做 rejection probability</li>
<li>DIVISION: 分别建模 pCTR 和 pCTCVR，然后利用上面的公式计算 pCVR</li>
<li>ESMM-NS: 不 share bottom 的 ESMM</li>
<li>ESMM: share bottom 的 ESMM</li>
</ul>
<h3 id="ipsinverse-propensity-score">IPS(Inverse Propensity Score)</h3>
<p>Inverse Propensity Score 的做法是为每个有 label 的样本预估一个
propensity score(倾向性得分)，其含义直观来说就是样本进入训练集(被标记
label)的概率，如对于 CTR 模型，propensity 就是曝光的概率，对于 CVR
模型，propensity 就是点击的概率</p>
<p>IPS 实际上借鉴了 Importance Sampling
的思想，通过给每个样本一个概率值作为权重，从统计学上证明了基于观测到的数据求得的期望与全量数据的期望是一致，其推导过程可简单描述为如下方式</p>
<p>记 <span class="math inline">\(L\)</span> 是观测到 label
的样本数，<span class="math inline">\(L&#39;\)</span>
则是同时包含了那些没被观测到的样本(<span class="math inline">\(L&#39;
\gg L\)</span>);则无偏的优化目标应该是 (<span
class="math inline">\(y_i\)</span>、<span
class="math inline">\(p_i\)</span> 分别表示 label 与预估值)</p>
<p><span class="math display">\[\min \sum_{i=1}^{L&#39;} l(y_i, p_i)
\tag{1}\]</span></p>
<p>现在令第 <span class="math inline">\(i\)</span>
个样本的是否被观测到记为 <span class="math inline">\(O_i \in \lbrace 0,
1 \rbrace\)</span>，则可假设 <span class="math inline">\(O_i\)</span>
服从一个伯努利分布即 <span class="math inline">\(O_i \sim
Bern(z_i)\)</span>, 这里的 <span class="math inline">\(z_i\)</span>
是样本 <span class="math inline">\(i\)</span>
被观测到的概率，则上面的优化问题可写成如下形式</p>
<p><span class="math display">\[
\begin{align}
Loss &amp;= \sum_{i=1}^{L&#39;} l(y_i, p_i)\notag \\\
&amp;= \sum_{i=1}^{L&#39;} \frac{l(y_i, p_i)}{z_i} E_{O}(O_i)\notag \\\
&amp;= E_{O}(\sum_{i=1}^{L&#39;} \frac{l(y_i, p_i)}{z_i} O_i)\notag \\\
&amp;= \sum_{i=1}^{L} \frac{l(y_i, p_i)}{z_i}\notag
\end{align}
\]</span></p>
<p>则上面问题 (1) 可被写成如下形式,
即可通过观测到的数据进行模型的训练，而 <span
class="math inline">\(z_i\)</span> 可利用label
为是否被观测到的数据进行训练，训练方式可以是单独训练或与这个 task 做
joint training。</p>
<p><span class="math display">\[\min \sum_{i=1}^{L} \frac{l(y_i,
p_i)}{z_i} \tag{2}\]</span></p>
<p>而如果套用 <a href="https://zhuanlan.zhihu.com/p/41217212">importance
sampling</a> 的方法，其实也能得到上面问题(2)的形式，在观测到的样本中,
样本 <span class="math inline">\(i\)</span> 被采样的概率是 <span
class="math inline">\(z_i\)</span>,
而在全部样本中，由于每个样本都会被采样到，因此其采样概率是
1，即加权的系数是 <span class="math inline">\(\frac{1}{z_i}\)</span></p>
<p>此外，也有方法同时融合了第一类方法中的 imputation model 和这里的 IPS
方法，被称为 <strong>Doubly Robust
Method</strong>，则其损失函数可写成如下形式（<span
class="math inline">\(\sigma_i\)</span> 是通过 imputation model 得到的
label）</p>
<p><span class="math display">\[\min \sum_{i=1}^{L} (\frac{l(y_i,
p_i)}{z_i} - l(\sigma_i, p_i)) + \sum_{i=1}^{L&#39;} l(\sigma_i,
p_i)\]</span></p>
<p>上述方法在 <a
href="https://www.csie.ntu.edu.tw/~cjlin/papers/occtr/ctr_oc.pdf">Improving
Ad Click Prediction by Considering Non-displayed Events</a>
有较为详细的描述，可以参考一下</p>
<h3 id="domain-adaption">Domain Adaption</h3>
<p><a href="https://en.wikipedia.org/wiki/Domain_adaptation">Domain
Adatption</a> 可以认为是 transfer learning 的一个子领域，根据 wiki
的说法其目标是</p>
<blockquote>
<p>aim at learning from a source data distribution a well performing
model on a different (but related) target data distribution.</p>
</blockquote>
<p>这个说法比较宽泛，实际中用到的方法可分为下面四大类(from <a
href="https://en.wikipedia.org/wiki/Domain_adaptation#Four_algorithmic_principles">wiki</a>)，实际上跟我们上面提到的方法的思想都比较相似</p>
<ol type="1">
<li><strong>Reweighting algorithms</strong>: reweight the source labeled
sample such that it "looks like" the target sample (in terms of the
error measure considered).</li>
<li><strong>Iterative algorithms</strong>：iteratively "auto-labeling"
the target examples</li>
<li><strong>Search of a common representation space</strong>：construct
a common representation space for the two domains</li>
<li><strong>Hierarchical Bayesian Model</strong>：build a factorization
model to derive domain-dependent latent representations allowing both
domain-specific and globally shared latent factors</li>
</ol>
<p>而在 Exposure Bias 场景下，观测到的数据被当做 source
domain，全量数据被当做 target domain，利用 domain adaption 解决 exposure
bias 比较有代表性的 paper 是阿里在 2020 发表的 ESAM，<a
href="https://arxiv.org/pdf/2005.10545.pdf">ESAM: Discriminative gDomain
Adaptation with Non-Displayed Items to Improve Long-Tail
Performance</a></p>
<p>ESAM(Entire Space Adaption Modelling) 跟上面提到的 ESMM(Entire Space
Multi-Task Model) 名字很相似，要解决的问题也很相似，但是前者是召回场景,
后者是 cvr 场景；</p>
<p>ESAM
总体如下所示，各符号含义如下（基本上就是向量化召回的涉及到的概念）</p>
<ul>
<li><span class="math inline">\(q\)</span>: query</li>
<li><span class="math inline">\(d^s\)</span>: 有曝光的 item</li>
<li><span class="math inline">\(d^t\)</span>: 没有曝光的 item</li>
<li><span class="math inline">\(f_q\)</span>, <span
class="math inline">\(f_d\)</span>: 将 query 和 item 映射成 embedding
的函数</li>
<li><span class="math inline">\(v_{q}\)</span>, <span
class="math inline">\(v_{d}\)</span>: query 和 item 被 <span
class="math inline">\(f_q\)</span>, <span
class="math inline">\(f_d\)</span> 映射出来的 embedding</li>
<li><span class="math inline">\(f_s\)</span>: 计算 <span
class="math inline">\(v_{q}\)</span>, <span
class="math inline">\(v_{d}\)</span> 相似性的函数，常见的是內积</li>
<li><span class="math inline">\(L_s\)</span>: 基于 <span
class="math inline">\(f_s\)</span> 吐出的预估值 <span
class="math inline">\(S_{c_{q,d^s}}\)</span> 计算的损失函数，常见的有
point-wise、pair-wise、list-wise 三大类</li>
<li><span class="math inline">\(L_{DA}\)</span>、<span
class="math inline">\(L_{DC}^{c}\)</span>、<span
class="math inline">\(L_{DC}^{p}\)</span>: paper 中提出的缓解 exposure
bias 的三种途径，以 loss 形式叠加在原始的 <span
class="math inline">\(L_s\)</span> 上，也是下文要重点展开描述的部分</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/ESAMOverview.jpg" alt="ESAMOverview" />
<figcaption aria-hidden="true">ESAMOverview</figcaption>
</figure>
<p>ESAM 的核心在于叠加在原始损失函数 <span
class="math inline">\(L_s\)</span> 上的三项：<span
class="math inline">\(L_{DA}\)</span>、<span
class="math inline">\(L_{DC}^{c}\)</span>、<span
class="math inline">\(L_{DC}^{p}\)</span>，下面会分别描述这三项的含义和计算方式</p>
<h4
id="l_dadomain-adaptation-with-attribute-correlation-alignment"><span
class="math inline">\(L_{DA}\)</span>：Domain Adaptation with Attribute
Correlation Alignment</h4>
<p>这个 loss 项的出发点是两个特征在 source domain 和 target domain
中的相关性是保持一致的，如下图所示，左边的图认为 price 跟 brand
是具有强相关的、brand 跟 material 中度相关、price 跟 material 弱相关，而
<span class="math inline">\(L_{DA}\)</span>
这个损失项是基于下面两个假设产生的</p>
<ol type="1">
<li>相关性在 source domain 和 target domain 都是一致的</li>
<li>原始的特征(即 price、brand、material)会被映射到 embedding
中某一维或几维</li>
</ol>
<figure>
<img src="https://wulc.me/imgs/ESAM_L_DA.jpg" alt="L_DA" />
<figcaption aria-hidden="true">L_DA</figcaption>
</figure>
<p>因此，可以设计 loss 项<strong>令两个特征的相关性在 source domain 和
target domain 尽可能保持一致</strong>, 而这里的相关性可采用协方差</p>
<p>因此，<span class="math inline">\(L_DA\)</span> 项计算方式如下，令
<span class="math inline">\(D^{s} = \lbrack v_{d_1^s};v_{d_2^s};\dots
v_{d_n^s} \rbrack \in \mathbb{R}^{n×L}\)</span> 为 n 个 source domain
样本映射出来的 embedding matrix，而 <span class="math inline">\(D^{s} =
\lbrack v_{d_1^t};v_{d_2^t};\dots v_{d_n^t} \rbrack \in
\mathbb{R}^{n×L}\)</span> 则是 n 个 target domain 样本映射出来的
embedding matrix, 每个 <span class="math inline">\(v\)</span>
是一个长度为 <span class="math inline">\(L\)</span> 的向量</p>
<p>如果将每个 embedding 相同的维度提取出来作为一个 vector <span
class="math inline">\(h\)</span>，则 <span
class="math inline">\(D^{s}\)</span> 和 <span
class="math inline">\(D^{t}\)</span> 也可写成如下形式，每个 <span
class="math inline">\(h\)</span> 是一个长度为 <span
class="math inline">\(n\)</span> 的向量</p>
<p><span class="math inline">\(D^{s}=\lbrack h_{1}^{s},h_{2}^{s};\dots
h_{L}^{s} \rbrack \in \mathbb{R}^{n×L}\)</span> <span
class="math inline">\(D^{t}=\lbrack h_{1}^{t},h_{2}^{t};\dots h_{L}^{t}
\rbrack \in \mathbb{R}^{n×L}\)</span></p>
<p>则 <span class="math inline">\(L_{DA}\)</span> 计算方式如下</p>
<p><span class="math display">\[\begin{align}
L_{DA} &amp;= \frac{1}{L^2}\sum_{(j,k)}({h_j^s}^T{h_k^s} -
{h_j^t}^T{h_k^t})^2 \notag  \\\
&amp;= \frac{1}{L^2} ||Cov(D^s) - Cov(D^t)||_F^2 \notag
\end{align}\]</span></p>
<p>上式中的 <span class="math inline">\(Cov(D^s) \in
\mathbb{R}^{L×L}\)</span> 和 <span class="math inline">\(Cov(D^t) \in
\mathbb{R}^{L×L}\)</span> 分别代表 source domain 和 target domain 的
covariance matrix，此外，笔者认为上面的公式其实表达不完全准确，因为 <a
href="https://en.wikipedia.org/wiki/Covariance">covariance</a>
计算还需要减去均值的，上面并没有这么做</p>
<p>加上改了这一项后，可以认为 source domain 和 target domain
在向量空间中的分布变化如下</p>
<figure>
<img src="https://wulc.me/imgs/ESAM_Loss1.jpg" alt="ESAM_L1" />
<figcaption aria-hidden="true">ESAM_L1</figcaption>
</figure>
<h4 id="l_dcccenter-wise-clustering-for-source-clustering."><span
class="math inline">\(L_{DC}^{c}\)</span>：Center-Wise Clustering for
Source Clustering.</h4>
<p>第二项 loss <span class="math inline">\(L_{DC}^{c}\)</span> <span
class="math inline">\(L_{DC}^{c}\)</span>跟人脸识别中最早提出的 <a
href="https://link.springer.com/chapter/10.1007/978-3-319-46478-7_31">center
loss</a>
很相似，就是让相同类型的样本在向量空间中尽可能接近，在广告的场景下这个类型可以是
click、non-click、purchase等；此外，还会令不同类型的样本在向量空间中的距离尽可能远；这个思想比较好理解</p>
<p>而为了定义出距离，会为每一个类型定义出一个聚类中心，聚类中心会被参数化；具体计算方式如下</p>
<p><span class="math display">\[\begin{align}
L_{DC}^{c} &amp;= \sum_{j=1}^{n} \max(0,
||\frac{v_{d_j^s}}{||v_{d_j^s}||} - c_{q}^{y_j^s}||_{2}^{2} -
m_1)  \notag \\\
&amp;+ \sum_{k=1}^{n_y} \sum_{u=k+1}^{n_y} \max(0, m2 - ||c_{q}^{k} -
c_{q}^{u}||_{2}^{2})\notag
\end{align}\]</span></p>
<p>上面的公式中 <span class="math inline">\(m_1\)</span> 和 <span
class="math inline">\(m_2\)</span> 分别是两个
margin，表示样本距离其类簇距离小于 <span
class="math inline">\(m_1\)</span> 和 类簇之间的距离大于 <span
class="math inline">\(m_2\)</span> 的情况下无需优化；同时假设所有样本有
<span class="math inline">\(n_y\)</span> 种类型, 第 <span
class="math inline">\(k\)</span> 种类型(即样本 label 为 <span
class="math inline">\(Y_k\)</span>)样本的 center 是 <span
class="math inline">\(c_{q}^{k}\)</span>，其定义为当前训练样本中类型为
<span class="math inline">\(k\)</span>
的样本的向量的中心，表示如下(<span
class="math inline">\(\delta(cond)\)</span> 函数的值为 1(cond=true) 或
0(cond=false))</p>
<p><span class="math display">\[c_q^k = \frac{\sum_{j=1}^{n}
\delta(y_j^s = Y_k)\frac{v_{d_j^s}}{||v_{d_j^s}||}}{\sum_{j=1}^{n}
\delta(y_j^s = Y_k)}\]</span></p>
<p>则加入 <span class="math inline">\(L_{DC}^{c}\)</span>
这一项后，source domain 和 target domain
在向量空间中的分布变化如下，可以看到，<strong>虽然 target domain
中的样本具有高内聚性，但是其聚类的簇可能是错误，其原因是对于 target
domain 中的样本，目前为止都没有加入 label 信息</strong>，而这便是下一项
loss <span class="math inline">\(L_{DC}^{p}\)</span> 要解决的问题</p>
<figure>
<img src="https://wulc.me/imgs/ESAM_Loss2.jpg" alt="ESAM_Loss2" />
<figcaption aria-hidden="true">ESAM_Loss2</figcaption>
</figure>
<h4 id="l_dcpself-training-for-target-clustering."><span
class="math inline">\(L_{DC}^{p}\)</span>：Self-Training for Target
Clustering.</h4>
<p>从这项 loss 的描述中的 <strong>self
training</strong>，可以猜测其做法是为 target domain 中 unlabeled
的样本打上标签用于训练模型，这是 semi supervised learning 中常见做法，而
paper 中并<strong>没有直接为 unlabeled 的样本打上标签，而是通过 loss
<span class="math inline">\(L_{DC}^{p}\)</span>
较为巧妙地实现了这一点</strong>，其表达如下</p>
<p><span class="math display">\[L_{DC}^{p} = -\frac{\sum_{j=1}^{n}
\delta(S_{c_{q,d^t}} &lt; p_1 | S_{c_{q,d^t}} &gt; p_2)S_{c_{q,d^t}}
\log S_{c_{q,d^t}}} {\sum_{j=1}^{n} \delta(S_{c_{q,d^t}} &lt; p_1 |
S_{c_{q,d^t}} &gt; p_2)}\]</span></p>
<p>其中 <span class="math inline">\(p_1\)</span> 和 <span
class="math inline">\(p_2\)</span>
是两个阈值，表示含义是样本的<strong>置信度达到一定程度才认为其是负样本/正样本，则这个
loss 的目标会让预估值小于 <span class="math inline">\(p_1\)</span>
的样本预估值更接近 0，预估值大于 <span
class="math inline">\(p_2\)</span> 的样本的预估值更接近
1</strong>，原因见可以看下面画出的 <span class="math inline">\(-p(x)
\log p(x)\)</span> 的函数，直接令这一项最小即可达到 self-training
的目标</p>
<figure>
<img src="https://wulc.me/imgs/EntropyRegularization.jpg"
alt="Entropy regularization" />
<figcaption aria-hidden="true">Entropy regularization</figcaption>
</figure>
<p>加入 <span class="math inline">\(L_{DC}^{p}\)</span> 这一项后，source
domain 和 target domain 在向量空间中的分布变化如下, 也是 ESAM
的最终形态</p>
<figure>
<img src="https://wulc.me/imgs/ESAM_loss3.jpg" alt="ESAM_Loss3" />
<figcaption aria-hidden="true">ESAM_Loss3</figcaption>
</figure>
<p>则最终的 loss 为下式所示，其中 <span
class="math inline">\(\lambda_1\)</span>, <span
class="math inline">\(\lambda_2\)</span>, <span
class="math inline">\(\lambda_3\)</span> 是三个超参, 通过 gradient
descent 即可求解</p>
<p><span class="math display">\[L_{all} = L_s + \lambda_1 L_{DA} +
\lambda_2 L_{DC}^{c} + \lambda_3 L_{DC}^{p}\]</span></p>
<h2 id="summary">Summary</h2>
<p>综上，本文主要针对 exposure bias 介绍了三大类方法，分别是 Data
Augmentation、IPS 和 Domain Adaption，三类方法主要思想如下</p>
<ol type="1">
<li>Data Augmentation: 即利用那些 unlabeled
的样本，方法较多，如将所有样本都当做负样本、训练一个 imputation model
来给 unlabeled 的样本打上标签、通过 multitask 方式利用等</li>
<li>IPS：只利用曝光的样本，从概率论推导出给曝光样本进行合适的加权后，基于曝光的样本求的期望是无偏的</li>
<li>Domain Adaption：利用了 unlabeled 的样本，主要分析了 ESAM 这篇
paper, 同时通过在 loss 上添加了三项，能够令曝光和未曝光的 item
训练得到的向量空间尽可能保持一致，这三项的 loss
背后的思想也值得参考</li>
</ol>
<p>此外，上面的一些方法虽然从理论上看起来比较
fancy，但是根据笔者当前的工作经验，实际中应用这些方法，还需要考虑到模型的迭代效率、、理论的假设是否符合实际等等；比如说
data augmentation/ESAM
方法会导致数据量增加不止一个量级，而这会势必会导致训练时长增加，即使这个方法有效果，也要考虑带来的收益以及牺牲的迭代效率和机器资源等兑换是否划算,
或者考虑如何改进采样策略尽可能打平样本量。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Google C++ Style Guide 阅读笔记</title>
    <url>/2018/10/02/Google%20C++%20Style%20Guide%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>统一规范的代码风格在团队协作中非常重要，在若干的风格标准中，Google
C++ Style 又是较为被认可的，本文是阅读了 <a
href="https://github.com/WuLC/resources/blob/master/Google%20C++%20Style%20Guide%20%28%E4%B8%AD%E6%96%87%E7%89%88%29.pdf">Google
C++ Style Guide</a>
中第六(命名约定)、七(注释)、八(格式)章后的一些笔记，主要涉及代码的一些基本规范。需要注意的是，各种规范之间并没有绝对的好坏之分，只要团队保持一致即可。</p>
<span id="more"></span>
<h2 id="命名约定">命名约定</h2>
<h3 id="一般性命名规则">一般性命名规则</h3>
<ul>
<li>给出描述性的名称(某些为人熟知的词可用缩写如 DNS)</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 使用</span></span><br><span class="line"><span class="type">int</span> num_errors; <span class="comment">// Good.</span></span><br><span class="line"><span class="type">int</span> num_completed_connections; <span class="comment">// Good.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 不使用</span></span><br><span class="line"><span class="type">int</span> nerr; <span class="comment">// Bad - ambiguous abbreviation.</span></span><br><span class="line"><span class="type">int</span> n_comp_conns; <span class="comment">// Bad - ambiguous abbreviation.</span></span><br></pre></td></tr></table></figure>
<ul>
<li>变量一般是名词(如上）， 函数名一般是指令性的（如
<code>open_file()、 set_num_errors()</code>)</li>
</ul>
<h3 id="文件命名">文件命名</h3>
<ul>
<li><p>文件名要<strong>全部小写</strong>，可以**包含下划线（_）** ,
C++文件以 <code>.cc</code> 结尾，头文件以 <code>.h</code> 结尾</p></li>
<li><p>尽量让文件名更加明确， 如 <code>http_server_logs.h</code> 比
<code>logs.h</code> 要好</p></li>
<li><p>定义类时文件名一般成对出现，如 <code>foo_bar.h</code> 和
<code>foo_bar.cc</code>，对应类 <code>FooBar</code></p></li>
</ul>
<h3 id="类型命名">类型命名</h3>
<p>所有类型命名，包括<strong>类、结构体、类型定义（typedef）、枚举</strong>，均使用相同约定：<strong>每个单词以大写字母开头，不包含下划线</strong>，其实就是驼峰法,
如下</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// classes and structs</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UrlTable</span> &#123; ...</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UrlTableTester</span> &#123; ...</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">UrlTableProperties</span> &#123; ...</span><br><span class="line"><span class="comment">// typedefs</span></span><br><span class="line"><span class="keyword">typedef</span> hash_map&lt;UrlTableProperties *, string&gt; PropertiesMap;</span><br><span class="line"><span class="comment">// enums</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">UrlTableErrors</span> &#123; ...</span><br></pre></td></tr></table></figure>
<h3 id="变量命名">变量命名</h3>
<ul>
<li>变量名一律<strong>小写</strong>，单词间以下划线相连，<strong>类的成员变量以下划线结尾</strong>，结构体的数据成员可以和普通变量一样，不用像类那样接下划线，如</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string table_name; <span class="comment">// OK - uses underscore.</span></span><br><span class="line">string tableName; <span class="comment">// Bad - mixed case</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UrlTableProperties</span> &#123;</span><br><span class="line">  string name_;</span><br><span class="line">  <span class="type">int</span> num_entries_;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">UrlTableProperties</span> &#123;</span><br><span class="line">  string name;</span><br><span class="line">  <span class="type">int</span> num_entries;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>对全局变量没有特别要求，少用就好，可以以 <code>g_</code>
或其他易与局部变量区分的标志为前缀</li>
</ul>
<h3 id="常量命名">常量命名</h3>
<ul>
<li>在名称前加 k, 且 k 后接大写字母开头的单词, 如
<code>kDaysInAWeek</code></li>
</ul>
<h3 id="函数命名">函数命名</h3>
<p>函数这里做了两种分类：普通函数(regular functions)和存取函数(accessors
and mutators)</p>
<ol type="1">
<li>普通函数: <strong>每个单词首字母大写，没有下划线</strong>, 如
<code>MyExcitingMethod()</code></li>
<li>存取函数: <strong>与变量名匹配</strong>：如
<code>set_my_exciting_member_variable()</code></li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span> &#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    ...</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">num_entries</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> num_entries_; &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">set_num_entries</span><span class="params">(<span class="type">int</span> num_entries)</span> </span>&#123; num_entries_ = num_entries; &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">   <span class="type">int</span> num_entries_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="枚举命名">枚举命名</h3>
<ul>
<li>枚举值应全部大写，单词间以下划线相连(宏的命名也与其保持一致)：
<code>MY_EXCITING_ENUM_VALUE</code></li>
<li>枚举名称属于类型，因此大小写混合, 即
<code>UrlTableErrors</code>。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">UrlTableErrors</span> &#123;</span><br><span class="line">    OK = <span class="number">0</span>,</span><br><span class="line">    ERROR_OUT_OF_MEMORY,</span><br><span class="line">    ERROR_MALFORMED_INPUT,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="小结">小结</h3>
<ol type="1">
<li><p>总体规则：<strong>不要随意缩写</strong>，如果说 ChangeLocalValue
写作 ChgLocVal 还有情可原的话，把 ModifyPlayerName 写作 MdfPlyNm
就太过分了，<strong>除函数名可适当为动词外，其他命名尽量使用清晰易懂的名词</strong></p></li>
<li><p><strong>宏、枚举</strong>等使用全部<strong>大写+下划线</strong>；</p></li>
<li><p><strong>变量（含类、结构体成员变量）、文件、命名空间、存取函数</strong>等使用全部<strong>小写+下划线</strong>
，类成员变量以下划线结尾，全局变量以 g_开头；</p></li>
<li><p><strong>普通函数、类型（含类与结构体、枚举类型）、常量</strong>等使用大小写混合，不含下划线；</p></li>
</ol>
<h2 id="注释">注释</h2>
<p>注释对保证代码可读性至为重要，当然也要记住，注释的确很重要，但<strong>最好的代码本身就是文档（
self-documenting），类型和变量命名意义明确要比通过注释解释模糊的命名好得多</strong>。</p>
<p>下面的规则描述了应该注释什么、注释在哪儿。比通过注释解释模糊的命名好得多</p>
<h3 id="文件注释">文件注释</h3>
<p><strong>在每一个文件开头加入版权公告，然后是文件内容描述。</strong></p>
<p><strong>1. 版权公告</strong></p>
<p>每一文件包含以下项，依次是： 1) <strong>版权</strong>（copyright
statement） ：如 Copyright 2008 Google Inc.； 2)
<strong>许可版本</strong>（license boilerplate）
：为项目选择合适的许可证版本，如 Apache 2.0、BSD、 LGPL、 GPL； 3)
<strong>作者</strong>（author line） ：标识文件的原始作者</p>
<p>如果你对其他人创建的文件做了重大修改，将你的信息添加到作者信息里，这样当其他人对该文件有疑问时可以知道该联系谁。</p>
<p><strong>2. 文件内容</strong></p>
<p>每一个文件版权许可及作者信息后，都要对文件内容进行注释说明。</p>
<p>1）<code>.h</code>
文件要对所声明的类的功能和用法作<strong>简单说明</strong> 2)
<code>.cc</code>
文件包含了更多的<strong>实现细节或算法讨论</strong>，如果你感觉这些实现细节或算法讨论对于阅读有帮助，可以把
<code>.cc</code> 中的注释放到 <code>.h</code> 中，并在 <code>.cc</code>
中指出文档在 <code>.h</code> 中。</p>
<p>不要单纯在 <code>.h</code> 和 <code>.cc</code>
间复制注释，复制的注释偏离了实际意义。</p>
<h3 id="类注释">类注释</h3>
<p>每个类的定义要附着描述<strong>类的功能和用法</strong>的注释, 如</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Iterates over the contents of a GargantuanTable. Sample usage:</span></span><br><span class="line"><span class="comment">// GargantuanTable_Iterator* iter = table-&gt;NewIterator();</span></span><br><span class="line"><span class="comment">// for (iter-&gt;Seek(&quot;foo&quot;); !iter-&gt;done(); iter-&gt;Next()) &#123;</span></span><br><span class="line"><span class="comment">// process(iter-&gt;key(), iter-&gt;value());</span></span><br><span class="line"><span class="comment">// &#125;</span></span><br><span class="line"><span class="comment">// delete iter;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GargantuanTableIterator</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="函数注释">函数注释</h3>
<p>注释于<strong>声明之前</strong>，描述函数<strong>功能及用法</strong>，注释使用描述式（"opens
the file"）而非指令式（"open the
file"）；注释只是为了<strong>描述函数而不是告诉函数做什么</strong>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Returns an iterator for this table. It is the client&#x27;s</span></span><br><span class="line"><span class="comment">// responsibility to delete the iterator when it is done with it,</span></span><br><span class="line"><span class="comment">// and it must not use the iterator once the GargantuanTable object</span></span><br><span class="line"><span class="comment">// on which the iterator was created has been deleted.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The iterator is initially positioned at the beginning of the table.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// This method is equivalent to:</span></span><br><span class="line"><span class="comment">// Iterator* iter = table-&gt;NewIterator();</span></span><br><span class="line"><span class="comment">// iter-&gt;Seek(&quot;&quot;);</span></span><br><span class="line"><span class="comment">// return iter;// If you are going to immediately seek to another place in the</span></span><br><span class="line"><span class="comment">// returned iterator, it will be faster to use NewIterator()</span></span><br><span class="line"><span class="comment">// and avoid the extra seek.</span></span><br><span class="line"><span class="function">Iterator* <span class="title">GetIterator</span><span class="params">()</span> <span class="type">const</span></span>;</span><br></pre></td></tr></table></figure>
<p><strong>函数定义</strong>处注释的内容:</p>
<p>每个函数定义时要以注释说明<strong>函数功能和实现要点</strong>，如使用的漂亮代码、实现的简要步骤、如此实现的理由、为什么前半部分要加锁而后半部分不需要。</p>
<p><strong>简要说明函数功能是可以的，重点要放在如何实现上。</strong></p>
<h3 id="变量注释">变量注释</h3>
<p><strong>通常变量名本身足以很好说明变量用途，特定情况下，需要额外注释说明</strong></p>
<p><strong>类数据成员</strong>
每个类数据成员（也叫实例变量或成员变量）应注释说明用途，如果变量可以接受
NULL 或-1等警戒值（ sentinel values） ，须说明之，如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Keeps track of the total number of entries in the table.</span></span><br><span class="line">  <span class="comment">// Used to ensure we do not go over the limit. -1 means</span></span><br><span class="line">  <span class="comment">// that we don&#x27;t yet know how many entries the table has.</span></span><br><span class="line">  <span class="type">int</span> num_total_entries_;</span><br></pre></td></tr></table></figure>
<p><strong>全局变量（常量）</strong></p>
<p>和数据成员相似，所有全局变量（常量）也应注释说明含义及用途，如：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// The total number of tests cases that we run through in this regression test.</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> kNumTestCases = <span class="number">6</span></span><br></pre></td></tr></table></figure></p>
<h3 id="todo-注释">TODO 注释</h3>
<p><strong>对那些临时的、短期的解决方案，或已经够好但并不完美的代码使用
TODO 注释。</strong></p>
<p>这样的注释要使用全大写的字符串 TODO，后面括号里加上你的大名、邮
件地址等，还可以加上冒号目的是可以根据统一的 TODO 格式进行查找：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// TODO(kl@gmail.com): Use a &quot;*&quot; here for concatenation operator.</span></span><br><span class="line"><span class="comment">// TODO(Zeke) change this to use relations.</span></span><br></pre></td></tr></table></figure>
<p>如果加上是为了在“将来某一天做某事”，可以加上一个特定的时间（"Fix by
November 2005"）或事件（ "Remove this code when all clients can handle
XML responses."）。</p>
<h2 id="格式">格式</h2>
<p>代码风格和格式确实比较随意，但一个项目中所有人遵循同一风格是非常容易的，作为个人未必同意下述格式规则的每一处，但整个项目服从统一的编程风格是很重要的，这样做才能让所有人在阅读和理解代码时更加容易。</p>
<h3 id="空格还是制表位">空格还是制表位</h3>
<p><strong>只使用空格，每次缩进 2 个空格</strong>。</p>
<p>使用空格进行缩进，不要在代码中使用 tabs，设定编辑器将 tab
转为空格。</p>
<h3 id="函数声明与定义">函数声明与定义</h3>
<p>返回类型和函数名在同一行，合适的话，参数也放在同一行。
函数看上去像这样：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">ReturnType <span class="title">ClassName::FunctionName</span><span class="params">(Type par_name1, Type par_name2)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DoSomething</span>();</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果同一行文本较多，容不下所有参数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">ReturnType <span class="title">ClassName::ReallyLongFunctionName</span><span class="params">(Type par_name1,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             Type par_name2,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             Type par_name3)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DoSomething</span>();</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>甚至连第一个参数都放不下</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">ReturnType <span class="title">LongClassName::ReallyReallyReallyLongFunctionName</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    Type par_name1, <span class="comment">// 4 space indent</span></span></span></span><br><span class="line"><span class="params"><span class="function">    Type par_name2,</span></span></span><br><span class="line"><span class="params"><span class="function">    Type par_name3)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DoSomething</span>(); <span class="comment">// 2 space indent</span></span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意以下几点 1) 返回值总是和函数名在同一行； 2) 左圆括号（ open
parenthesis） 总是和函数名在同一行； 3)
<strong>函数名和左圆括号间没有空格</strong>； 4)
<strong>圆括号与参数间没有空格</strong>； 5)
左大括号总在最后一个参数同一行的末尾处； 6)
右大括号总是单独位于函数最后一行； 7)
<strong>右圆括号和左大括号间总是有一个空格</strong>； 8)
<strong>函数声明和实现处的所有形参名称必须保持一致</strong>； 9)
所有形参应尽可能对齐； 10) <strong>缺省缩进为 2 个空格</strong>； 11)
独立封装的参数保持 4 个空格的缩进。</p>
<p>如果函数为 const 的，关键字 const 应与最后一个参数位于同一行。
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Everything in this function signature fits on a single line</span></span><br><span class="line"><span class="function">ReturnType <span class="title">FunctionName</span><span class="params">(Type par)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// This function signature requires multiple lines, but</span></span><br><span class="line"><span class="comment">// the const keyword is on the line with the last parameter.</span></span><br><span class="line"><span class="function">ReturnType <span class="title">ReallyLongFunctionName</span><span class="params">(Type par1,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  Type par2)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>函数调用</strong> 的风格跟定义一样</p>
<h3 id="条件语句">条件语句</h3>
<p>有些条件语句写在同一行以增强可读性，只有当语句简单并且没有使用 else
子句时使用：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (x == kFoo) <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Foo</span>();</span><br><span class="line"><span class="keyword">if</span> (x == kBar) <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Bar</span>();</span><br></pre></td></tr></table></figure>
<p><strong>如果语句有 else 分支是不允许</strong>的： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Not allowed - IF statement on one line when there is an ELSE clause</span></span><br><span class="line"><span class="keyword">if</span> (x) <span class="built_in">DoThis</span>();</span><br><span class="line"><span class="keyword">else</span> <span class="built_in">DoThat</span>();</span><br></pre></td></tr></table></figure></p>
<p>通常，单行语句不需要使用大括号，如果你喜欢也无可厚非，也有人要求 if
必须使用大括 号： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (condition)</span><br><span class="line">  <span class="built_in">DoSomething</span>(); <span class="comment">// 2 space indent.</span></span><br><span class="line"><span class="keyword">if</span> (condition) &#123;</span><br><span class="line">  <span class="built_in">DoSomething</span>(); <span class="comment">// 2 space indent.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>如果语句中哪一分支使用了大括号的话，其他部分也必须使用</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Not allowed - curly on IF but not ELSE</span></span><br><span class="line"><span class="keyword">if</span> (condition) &#123;</span><br><span class="line">  foo;</span><br><span class="line">&#125; <span class="keyword">else</span></span><br><span class="line">  bar;</span><br><span class="line">  </span><br><span class="line"><span class="comment">// Not allowed - curly on ELSE but not IF</span></span><br><span class="line"><span class="keyword">if</span> (condition)</span><br><span class="line">  foo;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">  bar;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Curly braces around both IF and ELSE required because</span></span><br><span class="line"><span class="comment">// one of the clauses used braces.</span></span><br><span class="line"><span class="keyword">if</span> (condition) &#123;</span><br><span class="line">  foo;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  bar;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="循环和开关选择语句">循环和开关选择语句</h3>
<p>switch 语句可以使用大括号分块；<strong>空循环体应使用{}或
continue</strong></p>
<p>switch 语句中的 case
块可以使用大括号也可以不用，取决于你的喜好，使用时要依下文所述。</p>
<p>如果有不满足 case 枚举条件的值，要总是包含一个
default（如果有输入值没有 case 去处理，编译器将报警）。如果 default
永不会执行，可以简单的使用 assert：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// switch 语句</span></span><br><span class="line"><span class="keyword">switch</span> (var) &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="number">0</span>: &#123; <span class="comment">// 2 space indent</span></span><br><span class="line">      ... <span class="comment">// 4 space indent</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">case</span> <span class="number">1</span>: &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">default</span>: &#123;</span><br><span class="line">      <span class="built_in">assert</span>(<span class="literal">false</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 空循环体</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; kSomeNumber; ++i) &#123;&#125; <span class="comment">// Good - empty body.</span></span><br><span class="line"><span class="keyword">while</span> (condition) <span class="keyword">continue</span>; <span class="comment">// Good - continue indicates no logic.</span></span><br><span class="line"><span class="keyword">while</span> (condition); <span class="comment">// Bad - looks like part of do/while loop.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="指针和引用表达式">指针和引用表达式</h3>
<p>句点（<code>.</code>）或箭头（<code>-&gt;</code>）<strong>前后不要有空格</strong>，指针/地址操作符（<code>*</code>、<code>&amp;</code>）后不要有空格</p>
<p>下面是指针和引用表达式的正确范例：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">x = *p;</span><br><span class="line">p = &amp;x;</span><br><span class="line">x = r.y;</span><br><span class="line">x = r-&gt;y;</span><br></pre></td></tr></table></figure>
<p><strong>在声明指针变量或参数时，星号与类型或变量名紧挨都可以</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// These are fine, space preceding.</span></span><br><span class="line"><span class="type">char</span> *c;</span><br><span class="line"><span class="type">const</span> string &amp;str;</span><br><span class="line"><span class="comment">// These are fine, space following.</span></span><br><span class="line"><span class="type">char</span>* c; <span class="comment">// but remember to do &quot;char* c, *d, *e, ...;&quot;!</span></span><br><span class="line"><span class="type">const</span> string&amp; str;</span><br><span class="line"><span class="type">char</span> * c; <span class="comment">// Bad - spaces on both sides of *</span></span><br><span class="line"><span class="type">const</span> string &amp; str; <span class="comment">// Bad - spaces on both sides of &amp;</span></span><br></pre></td></tr></table></figure>
<h3 id="布尔表达式">布尔表达式</h3>
<p>如果一个布尔表达式超过标准行宽（80 字符），如果断行要统一一下。
下例中，逻辑与（<code>&amp;&amp;</code>）操作符总位于行尾(可也考虑放在行首)：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (this_one_thing &gt; this_other_thing &amp;&amp;</span><br><span class="line">    a_third_thing == a_fourth_thing &amp;&amp;</span><br><span class="line">    yet_another &amp; last_one) &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="变量及数组初始化">变量及数组初始化</h3>
<p>选择 <code>=</code> 或 <code>()</code>, 下面的形式都是正确的：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x = <span class="number">3</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">x</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line"><span class="function">string <span class="title">name</span><span class="params">(<span class="string">&quot;Some Name&quot;</span>)</span></span>;</span><br><span class="line">string name = <span class="string">&quot;Some Name&quot;</span>;</span><br></pre></td></tr></table></figure></p>
<h3 id="预处理指令">预处理指令</h3>
<p>预处理指令<strong>不要缩进，从行首开始</strong></p>
<p>即使预处理指令位于缩进代码块中，指令也应从行首开始。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Good - directives at beginning of line</span></span><br><span class="line">  <span class="keyword">if</span> (lopsided_score) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> DISASTER_PENDING <span class="comment">// Correct -- Starts at beginning of line</span></span></span><br><span class="line">    <span class="built_in">DropEverything</span>();</span><br><span class="line">#<span class="built_in">endifBackToNormal</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"> </span><br><span class="line"><span class="comment">// Bad - indented directives</span></span><br><span class="line">  <span class="keyword">if</span> (lopsided_score) &#123;</span><br><span class="line">    <span class="meta">#<span class="keyword">if</span> DISASTER_PENDING <span class="comment">// Wrong! The &quot;#if&quot; should be at beginning of line</span></span></span><br><span class="line">      <span class="built_in">DropEverything</span>();</span><br><span class="line">    <span class="meta">#<span class="keyword">endif</span> <span class="comment">// Wrong! Do not indent &quot;#endif&quot;</span></span></span><br><span class="line">      <span class="built_in">BackToNormal</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="类格式">类格式</h3>
<p>声明属性依次序是 <code>public:、 protected:、 private:</code>,
每次缩进 1 个空格; 除第一个关键词（一般是
public）外，其他关键词前空一行，关键词后不要空行；</p>
<p>每一块中，<strong>声明次序</strong>一般如下：</p>
<p><strong>1) typedefs 和 enums； 2) 常量； 3) 构造函数； 4) 析构函数；
5) 成员函数，含静态成员函数； 6) 数据成员，含静态数据成员。</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span> : <span class="keyword">public</span> OtherClass &#123;</span><br><span class="line"> <span class="keyword">public</span>: <span class="comment">// Note the 1 space indent!</span></span><br><span class="line">   <span class="built_in">MyClass</span>(); <span class="comment">// Regular 2 space indent.</span></span><br><span class="line">   <span class="function"><span class="keyword">explicit</span> <span class="title">MyClass</span><span class="params">(<span class="type">int</span> var)</span></span>;</span><br><span class="line">   ~<span class="built_in">MyClass</span>() &#123;&#125;</span><br><span class="line">   </span><br><span class="line">   <span class="function"><span class="type">void</span> <span class="title">SomeFunction</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="function"><span class="type">void</span> <span class="title">SomeFunctionThatDoesNothing</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="function"><span class="type">void</span> <span class="title">set_some_var</span><span class="params">(<span class="type">int</span> var)</span> </span>&#123; some_var_ = var; &#125;</span><br><span class="line">   <span class="function"><span class="type">int</span> <span class="title">some_var</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> some_var_; &#125;</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">   <span class="function"><span class="type">bool</span> <span class="title">SomeInternalFunction</span><span class="params">()</span></span>;</span><br><span class="line">   <span class="type">int</span> some_var_;</span><br><span class="line">   <span class="type">int</span> some_other_var_;</span><br><span class="line">   <span class="built_in">DISALLOW_COPY_AND_ASSIGN</span>(MyClass);</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure>
<h3 id="命名空间格式化">命名空间格式化</h3>
<p>命名空间不添加额外缩进层次，例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123; <span class="comment">// Correct. No extra indentation within namespace.</span></span><br><span class="line">...</span><br><span class="line">&#125; </span><br><span class="line">&#125; <span class="comment">// namespace</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line">  <span class="comment">// Wrong. Indented when  it should not be.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="comment">// namespace</span></span><br></pre></td></tr></table></figure>
<h3 id="水平留白">水平留白</h3>
<p>添加冗余的留白会给其他人编辑时造成额外负担，因此，不要加入多余的空格。如果确定一
行代码已经修改完毕，将多余的空格去掉；或者在专门清理空格时去掉（确信没有其他人在
使用）</p>
<p><strong>一般情况</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">(<span class="type">bool</span> b)</span> </span>&#123; <span class="comment">// 大括号前需要有空格...</span></span><br><span class="line"><span class="type">int</span> i = <span class="number">0</span>; <span class="comment">// 分号前一般没空格</span></span><br><span class="line"><span class="type">int</span> x[] = &#123;<span class="number">0</span>&#125;; <span class="comment">// 初始化数组的分号的空格可选</span></span><br><span class="line"><span class="type">int</span> x[] = &#123; <span class="number">0</span> &#125;; <span class="comment">// 要使用的话，两边都加上</span></span><br></pre></td></tr></table></figure>
<p><strong>循环和条件语句</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (b) &#123; <span class="comment">// Space after the keyword in conditions and loops.</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123; <span class="comment">// Spaces around else.</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span> (test) &#123;&#125; <span class="comment">// There is usually no space inside parentheses.</span></span><br><span class="line"><span class="keyword">switch</span> (i) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i) &#123;</span><br></pre></td></tr></table></figure>
<p><strong>操作符</strong></p>
<p>赋值符号和二元操作符一般左右都带上空格，一元操作符则不用, 如下</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">x = <span class="number">0</span>; <span class="comment">// Assignment operators always have spaces around them.</span></span><br><span class="line">v = w*x + y/z; <span class="comment">// but it&#x27;s okay to remove spaces around factors.</span></span><br><span class="line">v = w * (x + z); <span class="comment">// Parentheses should have no spaces inside them</span></span><br><span class="line">x = <span class="number">-5</span>; <span class="comment">// No spaces separating unary operators and their</span></span><br><span class="line">++x; <span class="comment">// arguments.</span></span><br></pre></td></tr></table></figure>
<h3 id="垂直留白">垂直留白</h3>
<p><strong>垂直留白越少越好</strong>。这不仅仅是规则而是原则问题了：不是非常有必要的话就不要使用空行。尤其是：</p>
<p>1）<strong>不要在两个函数定义之间空超过 2 行</strong>
2）函数体头、尾不要有空行，函数体中也不要随意添加空行。
3）基本原则是：同一屏可以显示越多的代码，程序的控制流就越容易理解。当然，过于密集的
代码块和过于疏松的代码块同样难看，取决于你的判断，但通常是越少越好。</p>
<p>函数头、尾不要有空行，如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Function</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Unnecessary blank lines before and after</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码块头、尾不要有空行, 如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (condition) &#123;</span><br><span class="line">  <span class="comment">// Unnecessary blank line after</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (condition) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Unnecessary blank line before</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，有人根据这些规则总结了一张图，比较直观归纳了上面提到的各种规则风格，图片出自<a
href="https://blog.csdn.net/voidccc/article/details/37599203">这里</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1cqho6ing2pb1ejv1nt48u61g4q9.png"
alt="style image" />
<figcaption aria-hidden="true">style image</figcaption>
</figure>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Google 图片爬虫</title>
    <url>/2017/09/23/Google%20%E5%9B%BE%E7%89%87%E7%88%AC%E8%99%AB/</url>
    <content><![CDATA[<p>这里的 Google 图片爬虫指的是爬取在 Google
上通过关键词搜索得到的图片，由于最近需要一些特定领域的图片，而且现有的数据库满足不了要求，因此就想通过
Google
搜索筛选出这些特定领域的图片，然后下载下来后再进行人工筛选。这里采用了两种方法，区别在于是否需要解析网页端的
JS 代码。该项目的代码已经放到了 Github 上，详细代码参见<a
href="https://github.com/WuLC/GoogleImagesDownloader">这里</a>。</p>
<span id="more"></span>
<p>整体的思路就是先获取 Google 搜索结果页面的 html
代码，然后从中提取出图片的真实 URL，因为实际上 Google
也是通过爬虫来爬取这些图片的地址以及根据描述归类，所以图片并不存储在
Google 的服务器中。</p>
<p>这个过程中的一个关键点就是通过关键词 <code>search_query</code>
搜索得到的页面可直接通过下面这个 url 访问</p>
<p><code>https://www.google.com/search?q=search_query&amp;source=lnms&amp;tbm=isch</code></p>
<p>将 <code>search_query</code> 换成需要搜索的关键词即可。</p>
<p>这样便可以直接获取这个页面的源码，然后通过正则表达式解析出所有的图片的链接，这个方法只需要
python 的 urllib 库即可，对应的源码文件为 <a
href="https://github.com/WuLC/GoogleImagesDownloader/blob/master/download_with_urllib.py">download_with_urllib.py</a></p>
<p>上面是第一种方法，这种方法比较简单，当时有一个问题就是每个关键词最多只能下载
100 张图片，原因是 访问上面的链接返回的 HTTP Response
中限制了最多只有前100张图片的URL，如果需要显示更多，则需要在解析页面中相应的
JS 代码，这就是接下来要介绍的第二种方法。</p>
<p>所谓解析 JS
代码，其实就是浏览器的滚动条向下滚动时，浏览器引擎解析了页面的 JS
代码，从而向 Google
的服务器发出新的请求，从而返回更多的图片，当向下滚动时到底时，会出现一个显示为
<code>Show more results</code>需要点击的按钮，只有点击后才能加载更多的图片，这些操作要通过浏览器完成，而
python 提供了一个 <code>selenium</code>
库，这个库通过相应的浏览器驱动来启动浏览器（不同的浏览器对应于不同的驱动），并在代码中制定具体的浏览器操作。</p>
<p>这里采用的是 FireFox 浏览器，对应的驱动为 <a
href="https://github.com/mozilla/geckodriver/releases">geckodriver</a>，具体的安装步骤就是先安装
FireFox 浏览器，然后<a
href="https://github.com/mozilla/geckodriver/releases">在这里</a>下载与浏览器版本相应的
geckodriver，并且在环境变量 <code>PATH</code> 中添加 geckodriver
的路径。</p>
<p>第二种方法对应的源码文件为 <a
href="https://github.com/WuLC/GoogleImagesDownloader/blob/master/download_with_selenium.py">download_with_selenium.py</a></p>
<p>第二种方法的源码中主要有两个方法:
<code>get_image_links</code>和，，第一个方法是获取所有图片链接并写入到文件中，第二个方法则是下载第一个方法获取的文件中的图片；在测试时，第二个方法常常会卡住，原因可能是网络的不稳定，也可能是图片服务器那边的反爬虫机制，代码中没有捕获到
<code>Exception</code>,
因此后面对第二个方法进行了改进，并将新的方法写到文件 <a
href="https://github.com/WuLC/GoogleImagesDownloader/blob/master/download_images_with_time_limit.py">download_images_with_time_limit.py</a></p>
<p>新的方法主要是限制 HTTP
请求的最大耗时，超过这个时间就会抛出异常，实现是通过系统的 <a
href="https://docs.python.org/2/library/signal.html">signal</a>
来中断进程的，并且用了 <code>SIGALRM</code> 这个信号，而这个信号只在
unix-like 系统中，因此 Windows 无法运行这个脚本。</p>
<p>而 <code>SIGALRM</code> 在 python 中的用法如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> signal, os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handler</span>(<span class="params">signum, frame</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Signal handler called with signal&#x27;</span>, signum</span><br><span class="line">    <span class="keyword">raise</span> IOError(<span class="string">&quot;Couldn&#x27;t open device!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># Set the signal handler and a 5-second alarm</span></span><br><span class="line">    signal.signal(signal.SIGALRM, handler)</span><br><span class="line">    signal.alarm(<span class="number">5</span>)</span><br><span class="line">exception IOERROR:</span><br><span class="line">    <span class="comment"># This open() may hang indefinitely</span></span><br><span class="line">    fd = os.<span class="built_in">open</span>(<span class="string">&#x27;/dev/ttyS0&#x27;</span>, os.O_RDWR)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    signal.alarm(<span class="number">0</span>)          <span class="comment"># Disable the alarm</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP协议简介</title>
    <url>/2016/06/10/HTTP%E5%8D%8F%E8%AE%AE%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>HTTP协议采用了非常简单的请求-响应模式。由浏览器向网站发出请求（称为http
request），网站根据请求将相关的资源返回给浏览器（称为http
response）。这样周而复始就形成了网络通信。</p>
<span id="more"></span>
<p>HTTP协议是无状态的，也就是说<strong>同一个客户端的这次请求和上次请求是独立的，对http服务器来说，它并不知道这两个请求来自同一个客户端。</strong>为了解决这个问题，在HTTP中通过Session和Cookie机制来维护状态。</p>
<h2 id="http-请求http-request">HTTP 请求（http request）</h2>
<h3 id="消息的结构">消息的结构</h3>
<p>HTTP消息可分为三部分，第一部分叫<code>request line</code>（请求行），
第二部分叫<code>http header</code>,
第三部分是<code>body</code>。下面通过一个例子解释</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 第一部分：request line</span><br><span class="line">GET http://www.google.com/ HTTP/1.1  </span><br><span class="line"># 第二部分：http header</span><br><span class="line">Host: www.google.com</span><br><span class="line">Proxy-Connection: keep-alive</span><br><span class="line">Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</span><br><span class="line">Upgrade-Insecure-Requests: 1</span><br><span class="line">User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36</span><br><span class="line">...</span><br><span class="line"># 第三部分：body（由于请求方法为get，所以body为空）</span><br></pre></td></tr></table></figure>
<p>从上面的例子可以看到： <strong>request line</strong>
可分为三部分，分别是<code>请求方法 请求资源 使用的协议</code>，上面的例子中，请求的方法是GET，请求的资源是<code>http://www.google.com/</code>，使用的HTTP协议是1.1版本的，也有1.0版本的HTTP协议，主要区别在于<strong>1.1版本允许多个HTTP请求复用一个TCP连接，以加快传输速度</strong>。</p>
<p><strong>http header</strong>
是格式为<code>key:value</code>的一系列kv对，这些kv对主要作用是告知服务器关于浏览器的一些基本信息，如请求的host、使用的终端类型、页面缓存情况等。具体作用要根据具体的kv对分析</p>
<p><strong>body</strong> 是发送给服务器的query信息 当使用的是"GET"
方法的时候，body是为空的（GET只能读取服务器上的信息，post能写入)</p>
<p>上面提到的三部分通过换行符<code>\r\n</code>，其中<code>request line</code>永远都是占第一行，接下来每个header一行一个，换行符是<code>\r\n</code>，当遇到<strong>连续两个</strong><code>\r\n</code>时，Header部分结束，后面的数据全部是Body</p>
<h3 id="请求的方法">请求的方法</h3>
<p>上面提到的request
line的最后一个部分为请求的方法，在HTTP中请求的方法最基本的有4种，分别是<code>GET,POST,PUT,DELETE</code>。
<strong>一个URL地址用于描述一个网络上的资源，而HTTP中的GET, POST, PUT,
DELETE 就对应着对这个资源的查，改，增，删4个操作。</strong></p>
<p>我们最常见的就是GET和POST了。GET一般用于获取/查询资源信息，而POST一般用于更新资源信息.
GET方法和POST方法的区别如下：</p>
<ul>
<li><p>GET
提交的数据会放在URL之后，以<code>?</code>分割URL和传输数据，参数之间以<code>&amp;</code>相连，如<code>EditPosts.aspx?name=test1&amp;id=123456</code>。POST
方法是把提交的数据放在HTTP包的Body中。</p></li>
<li><p>GET
提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制.</p></li>
<li><p>GET
方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码.</p></li>
</ul>
<h2 id="http-响应http-response">HTTP 响应（http response）</h2>
<h3 id="消息的结构-1">消息的结构</h3>
<p>HTTP也分为三部分，第一部分叫<code>response line</code>,
第二部分叫<code>response header</code>，第三部分是<code>body</code>。下面是对应着上面的请求的一个响应</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 第一部分：response line</span><br><span class="line">HTTP/1.1 302 Found </span><br><span class="line"># 第二部分：response header</span><br><span class="line">Location: http://www.google.com.hk/url?sa=p&amp;hl=zh-CN&amp;pref=hkredirect&amp;pval=yes&amp;q=http://www.google.com.hk/%3Fgws_rd%3Dcr&amp;ust=1465567219496491&amp;usg=AFQjCNGmfj-b-0AJ0D2coSy_40k76XajIw</span><br><span class="line">Cache-Control: private</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line">Date: Fri, 10 Jun 2016 13:59:49 GMT</span><br><span class="line">Server: gws</span><br><span class="line">Content-Length: 390</span><br><span class="line">Proxy-Connection: keep-alive</span><br><span class="line"></span><br><span class="line"># 第三部分：body</span><br><span class="line">....</span><br></pre></td></tr></table></figure>
<p>从上面的例子可以看到： <strong>response
line</strong>可以分为两部分，分别是使用的HTTP协议，状态码及其含义。在上面的例子中使用的协议版本为1.1，状态码为302，表示重定向，也就是会向response中的location表示的url发出新的请求。</p>
<p><strong>response
header</strong>也是格式为<code>key:value</code>的一系列kv对，表示服务器的状态和返回的内容的一些信息：如<code>Content-Type</code>表明返回的内容的类型，该类型也决定了body的内容，如果是网页，Body就是文本，如果是图片，Body就是图片的二进制数据；<code>Content-Length</code>表明返回的内容的类型；<code>Content-Encoding</code>表示，Body数据是被压缩的，最常见的压缩方式是gzip，如<code>content-Encoding: gzip</code>，压缩的目的在于减少Body的大小，加快网络传输。</p>
<p><strong>body</strong>
则是返回给浏览器的实际内容，由content决定其类型。如上面的例子中返回的类型是<code>text\html</code>,则body的内容是该网页的html代码。如果该html代码中还有其他的资源如图片等，浏览器会发送一个新的http请求来获取这个资源。</p>
<h3 id="状态码">状态码</h3>
<p>response
line中的状态码表示对浏览器的请求的回应状况，状态码由三位数字组成，第一个数字定义了响应的类别其中</p>
<ul>
<li>1XX 提示信息 - 表示请求已被成功接收，继续处理</li>
<li>2XX 成功 - 表示请求已被成功接收，理解，接受</li>
<li>3XX 重定向 - 要完成请求必须进行更进一步的处理</li>
<li>4XX 客户端错误 - 请求有语法错误或请求无法实现</li>
<li>5XX 服务器端错误 - 服务器未能实现合法的请求</li>
</ul>
<p>一些常见的状态码及其含义如下所示：</p>
<ul>
<li>200 OK 请求被成功地完成，所请求的资源发送回客户端</li>
<li>302 Found
重定向，新的URL会在response中的Location中返回，浏览器将会使用新的URL发出新的Request</li>
<li>304 Not Modified 文档已经被缓存，直接从缓存调用</li>
<li>400 Bad Request 客户端请求与语法错误，不能被服务器所理解</li>
<li>403 Forbidden 服务器收到请求，但是拒绝提供服务</li>
<li>404 Not Found 请求资源不存在</li>
<li>500 Internal Server Error 服务器发生了不可预期的错误</li>
<li>503 Server Unavailable
服务器当前不能处理客户端的请求，一段时间后可能恢复正常</li>
</ul>
<p>更多状态码详细解释见http://tool.oschina.net/commons?type=5</p>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop2.6.0安装注意事项</title>
    <url>/2016/02/20/Hadoop2-6-0%E5%AE%89%E8%A3%85%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
    <content><![CDATA[<p>本文为在centos上安装hadoop 2.6.0
的一些需要注意的地方。过程不会很详细，如需详细配置过程，可看后面的参考链接。</p>
<span id="more"></span>
<h2 id="基本注意事项">基本注意事项</h2>
<h3 id="改主机名">改主机名</h3>
<p><strong>修改/etc/hosts文件</strong>。每台机器都要，目的是为了每台机器都能够通过主机名访问其他机器</p>
<h3 id="java环境">java环境</h3>
<p>每台机器都要。**为了方便可直接安装open-jdk(1.7.0及以上)，要安装下面两个包。</p>
<pre><code>java-1.8.0-openjdk   
java-1.8.0-openjdk-devel  # 运行 jps 命令需要的</code></pre>
<p>同时添加 <code>JAVA_HOME</code>
环境变量，如果是yum直接安装，<code>JAVA_HOME</code>
的值应该是<code>/usr/lib/jvm/java-1.8.0</code></p>
<h3 id="ssh环境">ssh环境</h3>
<p>要求无需密码登录。如果是伪分布式,要求能够无密码登录本机。如果是完全分布式，<strong>要求master能够无密码登录所有的slaves</strong>。</p>
<h3
id="下载hadoop编译好的文件解压并做软链接到usrlocalhadoop">下载hadoop编译好的文件，解压并做软链接到<code>/usr/local/hadoop</code></h3>
<p>添加hadoop相关的环境变量 <figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$HADOOP_HOME</span>/bin</span><br></pre></td></tr></table></figure></p>
<h2 id="伪分布式安装的配置">伪分布式安装的配置</h2>
<p>需要修改<code>core-site.xml</code>和<code>hdfs-site.xml</code>两个文件,<code>core-site.xml</code>中的localhost可改为本机主机名，但是hosts文件要有对应关系
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">#core-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#hdfs-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>初次启动需要将namenode格式化。</p>
<pre><code>hadf namenode -format</code></pre>
<p>启动map-reduce</p>
<pre><code>start-dfs.sh</code></pre>
<p><strong>注意：</strong>若出现提示 “WARN util.NativeCodeLoader: Unable
to load native-hadoop library for your platform… using builtin-java
classes where # applicable”，该 WARN 提示可以忽略，不会影响 Hadoop
正常运行
原因:http://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning</p>
<p>此时可访问 <code>http://localhost:50070</code>，查看 NameNode 和
Datanode 信息，还可以在线查看 HDFS 中的文件。</p>
<p>启动YARN（伪分布式下可选）。Yarn是从 MapReduce
中分离出来的，负责资源管理与任务调度。YARN 运行于
MapReduce之上，提供了高可用性、高扩展性，</p>
<p>需要修改配置文件 <code>mapred-site.xml</code> 和
<code>yarn-site.xml</code> 。修改配置文件 mapred-site.xml，需要将
<code>mapred-site.xml.template</code>重命名为mapred-site.xml，不用yarn时做相反操作，因为
mapred-site.xml 存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying
connect to server: 0.0.0.0/0.0.0.0:8032” 的错误， <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">#mapred-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">#yarn-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<strong>启动yarn,先要start-dfs.sh,然后执行下面命令</strong></p>
<pre><code>./sbin/start-yarn.sh      # 启动YARN
./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况</code></pre>
<p>访问localhoost:8088便可以看到启动yarn后开启的界面。</p>
<p><strong>YARN
主要是为集群提供更好的资源管理与任务调度，然而这在单机上体现不出价值，反而会使程序跑得稍慢些。因此在单机上是否开启
YARN 就看实际情况了。</strong></p>
<h2 id="完全分布式配置">完全分布式配置</h2>
<p>master和所有的slave的时间要同步，可通过ntp实现</p>
<pre><code>yum -y install ntp &amp;&amp; ntpdate time.nist.gov</code></pre>
<p>可选的时间服务器： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">time.nist.gov</span><br><span class="line">time.nuri.net</span><br><span class="line">0.asia.pool.ntp.org</span><br><span class="line">1.asia.pool.ntp.org</span><br><span class="line">2.asia.pool.ntp.org</span><br><span class="line">3.asia.pool.ntp.org</span><br></pre></td></tr></table></figure></p>
<p>master上修改五个配置文件:salves、core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">#slaves #datanodes的主机名，一行一个</span><br><span class="line"></span><br><span class="line">#core-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master主机名:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">#hdfs-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  #datanode的数量</span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#mapred.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master主机名:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master主机名:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">#yarn-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>将master的hadoop文件夹复制到salve（也是/usr/local/hadoop目录），然后在master启动即可：</p>
<pre><code>start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver</code></pre>
]]></content>
      <categories>
        <category>Hadoop</category>
        <category>安装配置</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop中MapReduce快速入门</title>
    <url>/2015/12/14/Hadoop%E4%B8%ADMapReduce%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>因为研究生的方向是数据挖掘，所以免不了要接触到Hadoop,Hadoop是一个用Java语言实现开源软件框架，通过大量计算机组成的集群对海量数据进行分布式计算。</p>
<span id="more"></span>
<p>Hadoop中两个重要组成部分为HDFS和MapReduce。其中HDFS用于存储海量的数据，MapRudece则负责处理这些数据，从中获取所需的信息。</p>
<h2 id="hdfs简单介绍">HDFS简单介绍</h2>
<p>HDFS（Hadoop Distributed File System）翻译过来就是"Hadoop
分布式文件系统"，用于存储海量的数据。从“分布式文件系统”的名字可以知道这个文件系统运行在集群上。对于一个文件，Hadoop会将其先分成若干个block（每个block的大小默认为64M,当然也可以自己指定block的大小），然后再将block存储到集群上。为了保证数据的冗余性，HDFS会为每个block创建2个副本，然后将这三个相同的block分别存储在不同的机器上。</p>
<p>例如下图就是将data1分成了1、2、3共三个block，为每个block创建副本后再存储在不同的机器上；同理将data2分成了4、5共两个block</p>
<p><img src="https://wulc.me/imgs/Image.png" /></p>
<h2 id="mapreduce介绍">MapReduce介绍</h2>
<p>有了数据就可以对其进行处理，从中提取出我们所需的信息。在Hadoop中是通过MapReduce来实现的。</p>
<p>MapReduce任务过程被分为两个阶段：<strong>Map阶段和Reduce阶段。每个阶段都用key/value作为输入和输出</strong>；每个阶段都需要定义函数，也就是map函数和reduce函数；可以简单认为map函数是对原始数据提出出有用的部分，而reduce函数则是对提取出来的数据进行处理。</p>
<p>所以实际编写程序时<strong>需要编写三个函数：Map函数，Reduce函数和调用他们执行任务的主函数，在编写程序时必须要有这个整体的概念</strong>。</p>
<p>下面会以Hadoop官方文档中的WordCount任务为例阐述MapReduce，WordCount的任务很简单，就是计算出一个文本中每个单词出现了多少次。下面分别来分析这几个函数：</p>
<p>需要注意的而是在编写这三个函数时均需要用到Hadoop本身提供的jar包
下面的实例是Hadoop 1.2.1 版本提供的jar包</p>
<h3 id="map函数">Map函数</h3>
<p>在本例中map函数的主要作用就是以k-v形式记录所有出现过的词，代码如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*WordCount的map程序</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.lc.hadoop;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="comment">//引入Hadoop本身提供的jar包</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*继承Mapper类，&lt;Object,Text,Text,IntWritable&gt;表示输入输出的key-value 类型*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object,Text,Text,IntWritable&gt; &#123;</span><br><span class="line">	IntWritable one=<span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">	Text text=<span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key,Text value,Context context)</span><span class="keyword">throws</span> IOException,InterruptedException&#123;</span><br><span class="line"><span class="comment">/*key为输入的key，value为输入的value，因为用不上输入的key的类型，所以直接定义为Object类型，而Context是定义在Mapper类内部的，用于存储key-value键值对*/</span></span><br><span class="line">		StringTokenizer tokenizer=<span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">		<span class="keyword">while</span>(tokenizer.hasMoreTokens())&#123;</span><br><span class="line">			text.set(tokenizer.nextToken());</span><br><span class="line">			context.write(text,one);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于程序的几点解释：</p>
<ul>
<li>StringTokenizer类的作用是根据某一分隔符将String分隔开，默认是采用空格。</li>
<li>IntWritable
类表示的是一个整数，是一个以类表示的<strong>可序列化的整数</strong></li>
<li>Text 类代表的是<strong>可序列化的String类型</strong></li>
<li>Mapper 类将输入键值对映射到输出键值对，也就是 MapReduce 里的 Map
过程</li>
</ul>
<p>经过map过程后，文章被分割成大量的k-v对，k为实际的单词，v均为1，下一步就是要将相同的单词合并在一起。</p>
<h3 id="reduce函数">Reduce函数</h3>
<p>Reduce函数的作用就是将相同的单词出现的次数合并在一起，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*WordCount的reduce程序</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.lc.hadoop;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text ,IntWritable,Text,IntWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">	IntWritable result=<span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key,Iterable&lt;IntWritable&gt; values,Context context)</span><span class="keyword">throws</span> IOException,InterruptedException&#123;</span><br><span class="line">		<span class="type">int</span> sum=<span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span>(IntWritable iw : values)&#123;</span><br><span class="line">			sum+=iw.get();</span><br><span class="line">		&#125;</span><br><span class="line">		result.set(sum);</span><br><span class="line">		context.write(key,result);</span><br><span class="line">	&#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>Reduce与Map函数有很多地方比较相似，均是继承了hadoop提供的jar包中的类，只是map函数继承了Mapper类，而reduce函数继承了Reducer类，输入输出的类型均是k-v键值对。而且reduce函数的输入就是map函数的输出。</p>
<h3 id="主函数">主函数</h3>
<p>主函数的任务就是要创建一个任务，并且把map和reduce类都引进来，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*WordCount的主程序</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.lc.hadoop;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">		Configuration conf=<span class="keyword">new</span> <span class="title class_">Configuration</span>();<span class="comment">//从hadoop配置文件中读取参数</span></span><br><span class="line">		<span class="comment">//从命令行读取参数</span></span><br><span class="line">		String[] otherArgs=<span class="keyword">new</span> <span class="title class_">GenericOptionsParser</span>(conf,args).getRemainingArgs();</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span>(otherArgs.length!=<span class="number">2</span>)&#123;</span><br><span class="line">			System.out.println(<span class="string">&quot;Usage:wordcount &lt;in&gt; &lt;out&gt;&quot;</span>);</span><br><span class="line">			System.exit(<span class="number">2</span>);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		Job job=<span class="keyword">new</span> <span class="title class_">Job</span>(conf,<span class="string">&quot;WordCount&quot;</span>);</span><br><span class="line">		job.setJarByClass(WordCount.class);</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(IntWritable.class);</span><br><span class="line">		job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">		job.setReducerClass(CountReducer.class);</span><br><span class="line">		FileInputFormat.addInputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">1</span>]));</span><br><span class="line">		System.exit( (job.waitForCompletion(<span class="literal">true</span>)?<span class="number">0</span>:<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于程序有几点需要注意的地方：</p>
<ul>
<li>Configuration 类用于读写和保存各种配置资源</li>
<li>Path 类保存文件或者目录的路径字符串</li>
<li>Job 类：在hadoop中<strong>每个需要执行的任务是一个
Job</strong>，这个 Job 负责很多事情，包括参数配置，设置 MapReduce
细节，提交到 Hadoop 集群，执行控制，查询执行状态，等等</li>
<li>FileInputFormat和FileOutputFormat用于处理文件的输入和输入（针对MapReduce而言）</li>
<li>GenericOptionsParser 类负责解析 hadoop 的命令行参数</li>
</ul>
<h3 id="执行任务">执行任务</h3>
<p>编写好源程序后，需要在hadoop上执行我们在源程序中写好的代码，大致的过程如下：<code>编译-&gt;打包-&gt;执行</code>，下面分别介绍。为了程序的规范性，首先建立一个wordcount的文件夹，下面再建两个子文件夹src和classes，分别放置源程序文件和编译好后的class文件。且默认是在Linux上执行这些操作的。</p>
<h4 id="编译">编译</h4>
<p>首先将上面写好的三个源文件放到wordcount的src目录下，同时拷贝安装hadoop后提供的两个jar包hadoop-core-1.2.1.jar和commons-cli-1.2.jar。进入wordcount目录，采用下面命令进行编译</p>
<p><code>javac -classpath hadoop-core-1.2.1.jar:commons-cli-1.2.jar -d ./classes  ./src/*</code></p>
<p>这条命令的作用是<strong>将src目录下的所有文件进行编译，生成的class文件放到classes目录下，编译过程中需要引入的hadoop-core-1.2.1.jar和commons-cli-1.2.jar两个包，里面包含了上面源文件中导入的hadoop的类。</strong>
编译完成后，可以在classes目录下发现以下子目录的结构<code>classes-&gt;com-&gt;lc-&gt;hadoop</code>,最后在目录hadoop下会有三个class文件，分别对应上面的的三个源文件。</p>
<h4 id="打包">打包</h4>
<p>打包需要用到 jar 命令，jar 命令是 JDK 的打包命令行工具，跟 tar
非常像。</p>
<p>先切换到WordCount目录，再执行下面的命令：</p>
<p><code>jar -cvf  WordCount.jar -C ./classes/*  .</code></p>
<p>在命令里，-C 是指需要打包的class文件的路径，。打包结果是
wordcount.jar 文件，放在当前目录下。</p>
<h4 id="执行">执行</h4>
<p>执行hadoop任务需要在HDFS上进行，所以文件的输入输出路径也就是在HDFS上的路径</p>
<p>首先需要将待处理的文件放入到HDFS中，可以按顺序输入以下命令：
<code>hadoop fs -mkdir in</code> //在HDFS中创建一个名为in的文件夹</p>
<p><code>hadoop fs -put Readme.txt readme.txt</code>
//将Linux当前目录下的Readme.txt文件放置到HDFS中的in目录</p>
<p><code>hadoop jar WordCount.jar com.lc.hadoop WordCount in/readme.txt out</code>//执行Linux当前目录下的WordCount
jar包里面的WordCount类，输入文件是HDFS中in目录下的readme.txt文件，输出文件放到HDFS中的out目录</p>
<p><code>hadoop fs -cat out/part-r-0000</code> //查看得到的结果</p>
<p>需要注意的是HDFS中的文件路径不能够在Linux下直接通过<code>cd</code>或<code>ls</code>进行切换或查看，而必须要通过<code>hadoop fs</code>进行操作。</p>
<p>以上就是Hadoop中MapReduce的流程，针对不同的应用会有不同的变化，但是总体上的流程是一致的，就是先编写好三个函数（map函数，reduce函数和主函数），然后要经历<code>编译-&gt;打包-&gt;执行</code>的流程。再查看得到的结果即可。</p>
<p>参考资料：最短路径系列之一从零开始学习Hadoop</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>分布式</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Highlight Detection In Video</title>
    <url>/2022/08/27/Highlight%20Detection%20In%20Video/</url>
    <content><![CDATA[<p>Highlight
Detection，直译过来就是高光检测，一般应用在图像或视频里，本文主要关注视频场景，其任务就是从一段长视频里找到某个“高光”的片段。这里的“高光”是一个非常宽泛的定义，不像
ctr/cvr
有明确的含义，不同场景下对“高光”的定义不一样：比如说对于带货直播，高光片段也许是
gmv
最高的时间段；对于非带货直播，高光的片段也许是观看人数或者刷礼物最多的时间段。</p>
<p>Highlight Detection
在实际的应用场景较为广泛：一些视频网站(如爱奇艺、哔哩哔哩)里鼠标停留在视频上时会自动播放一些片段，这些片段可认为是高光片段；主流的直播平台基本都提供了直播回放工具，其中往往也会提供高光片段的候选，除了提供给用户侧，广告主/商家侧也会提供类似产品，如<a
href="https://mp.weixin.qq.com/s/fojF0LZKQcPVNKuEiGfrtg">巨量千川</a>、<a
href="https://partner.e.kuaishou.com/detail/2628">磁力金牛</a>等平台的产品</p>
<p><a
href="https://paperswithcode.com/task/highlight-detection">Highlight
Detection</a>
在学术界也是一个研究方向，但是学界基本研究局限在几个人工标注的数据集上，一般无法直接应用到实际的生产环境中，原因就是上面说的，不同场景下对高光的定义不一样，需要的数据集也不一样。Highlight
Detection 相关 paper 不少，本文主要讲2 篇更贴近业界的
paper，可以重点关注<strong>高光的监督信号的定义，损失函数的设计以及数据集的获取</strong></p>
<span id="more"></span>
<h2 id="taohighlight">TaoHighlight</h2>
<p>这个方法来自 <a
href="https://ieeexplore.ieee.org/document/9447925">TaoHighlight:
Commodity-Aware Multi-Modal Video Highlight Detection in
E-Commerce</a></p>
<p>这是淘宝在 2021
提出的一个方法，总体的模型结构图如下图所示，模型不复杂，左边是抽取多模态特征部分，右边则是基于抽取出来的特征和
score，通过 GCN 做 finetune，损失函数由两部分组成，即
<code>Loss_reg</code> 和 <code>Loss_ag</code></p>
<p><img src="https://wulc.me/imgs/TaoHighlight_CAM.jpg" height="70%" width="70%"></p>
<p>特征工程部分，visual information 通过 I3D+BiGRU 提取，比较常规；text
information 提出了一个 QFGA(Query-Focus Graph Aggregation), 一个基于
graph 抽取特征的模块</p>
<p><strong>Co-Attention
Module</strong>，这个模块主要作用是融合多模态特征（即 visual information
和 text information），基本的原理是参考了 trasformer 的 self-attention
机制, 对于下面左边的 block，<span class="math inline">\(v\)</span>
相当于 query, <span class="math inline">\(s\)</span> 相当于 key 和
value</p>
<p><img src="https://wulc.me/imgs/TaoHighlight_coattention.jpg" height="50%" width="50%"></p>
<p>其计算逻辑如下图所示</p>
<p><img src="https://wulc.me/imgs/TaoHighlight_Coattention_compute.jpg" height="50%" width="50%"></p>
<p><strong>Graph-based Fine-tuning</strong>:
这部分主要是为了减少抽取出来的特征里的 noise；paper 里是这么说的:
<code>Due to the presence of visual and text noises in multi-modal video highlight detection, we propose a graph based fine-tuning module to improve the accuracy of our model.</code>，但是也没进一步说明原因</p>
<p>具体的做法就是给每帧打一个分，然后选取按 score 排序 topk 的 frame
构造一个 graph，基于 graph 做 GCN 的计算，关于 GCN
的详细解释可参考这篇文章：<a
href="https://distill.pub/2021/understanding-gnns/">Understanding
Convolutions on Graphs</a>，</p>
<p>而最终的损失函数由 2 部分组成，<span
class="math inline">\(L_{reg}\)</span> 和 <span
class="math inline">\(L_{ag}\)</span>, 两部分的含义如下</p>
<p><span class="math inline">\(L_{reg}\)</span>
，计算预估的开始/结束时间和真正的开始/结束时间的的差异，计算方式如下</p>
<p><span class="math display">\[L_{reg} = \frac{1}{N}
\sum_{i=1}^{N}[R(\hat{s_i}, s_i) + R(\hat{e_i}, e_i)]\]</span></p>
<p>各符号含义如下</p>
<ul>
<li><span class="math inline">\(s_i\)</span>, <span
class="math inline">\(e_i\)</span>:
预估的高光片段的开始和结束时间点</li>
<li><span class="math inline">\(\hat{s_i}\)</span>, <span
class="math inline">\(\hat{e_i}\)</span>: 高光开始和结束时间的 ground
truth</li>
<li><span class="math inline">\(R\)</span>: L1 函数</li>
</ul>
<p><span class="math inline">\(L_{ag}\)</span> 计算方式如下,
主要用来计算两段视频的相关性，<span class="math inline">\(k\)</span>
表示将每段视频切成 <span class="math inline">\(k\)</span> 段
clips，主要由三项组成</p>
<p><span class="math display">\[L_{ag} = - \sum_{i=1}^{k}e(v_i,
\hat{v})\]</span></p>
<p><span class="math display">\[e(v_i, v_j) = \theta_{r} \cdot r(v_i,
v_j)+\theta_{d} \cdot d(v_i, v_j)+\theta_{s} \cdot \cos(v_i,
v_j)\]</span></p>
<p>各符号含义如下</p>
<ul>
<li><span class="math inline">\(v_i\)</span>, <span
class="math inline">\(\hat{v_i}\)</span>: 预估的高光片段和 ground
truth</li>
<li><span class="math inline">\(r(v_i, v_j) = \frac{I(v_i, v_j)}{U(v_i,
v_j)}\)</span>, 就是 <a
href="https://medium.com/analytics-vidhya/iou-intersection-over-union-705a39e7acef">IoU</a>
指标，表示重合面积占比</li>
<li><span class="math inline">\(d(v_i, v_j) = \frac{ |c_i - c_j|}{U(v_i,
v_j)}\)</span>, <span class="math inline">\(c_i\)</span> 和 <span
class="math inline">\(c_j\)</span> 表示两个 video 的中心位置</li>
<li><span class="math inline">\(cos\)</span>: 两个片段的 cos 相似性</li>
</ul>
<p>预估时实际是一个多分类模型(softmax)，会对最后构造的 graph
做一个预估，并选择概率最大的一帧作为起始帧，然后取其后的 128
frame作为固定的高光片段</p>
<p>实验评估的效果指标就是看各种 IoU 的占比，数据集是 taobao 提供的包含 5
个大分类的数据，整个 dataset 的信息如下</p>
<p><img src="https://wulc.me/imgs/TaoHighlight_dataset.jpg" height="60%" width="60%"></p>
<p>paper 做了消融实验，结果如下图所示</p>
<p><img src="https://wulc.me/imgs/TaoHighlight_ablation.jpg" height="50%" width="50%"></p>
<p>各符号含义如下，可以看到文本特征，Graph-based Fine-tuning
以及损失函数中的 <span class="math inline">\(L_{ag}\)</span>
项作用还是不小的</p>
<ul>
<li>w/o.ti. 去掉文本特征</li>
<li>w/o.ci. 文本特征只包含 video title（去掉了商品 titile
和商品属性）</li>
<li>w/o.st. 去掉了 Graph-based Fine-tuning</li>
<li>w/o.ag. 去掉了损失函数中的 <span
class="math inline">\(L_{ag}\)</span> 项</li>
</ul>
<h2 id="unsupervised-solution">“unsupervised” solution</h2>
<p>上面的 TaoHighlight
方法使用的是人工标注的数据集，其缺陷是比较明显的，即人工标注导致了成本较高，可维护性太差；一是高光的定义因人而异，标注时主观性会比较强，二是成本和标注的难度决定了数据更新频率不会很高，这在业界基本是无法接受的</p>
<p>那很自然就会想到，能否利用一些无须标注的信号来规避掉需要人工打标这个环节呢？这篇
paper 就提供了一个思路 <a href="https://arxiv.org/abs/1903.00859">Less
is More: Learning Highlight Detection from Video Duration</a></p>
<p>peper 认为 <strong>Less is More</strong>,
即越短的视频的信息量就越高，所以切分出来的片段都可以认为是高光片段，反之越长的视频的信息量约低，切出来的都不是高光片段，因此，paper
将训练样本 <span class="math inline">\(D\)</span>
分为分为三部分，即<span class="math inline">\(D= \lbrace D_S, D_L, D_R
\rbrace\)</span>，<span class="math inline">\(D_S\)</span>
表示短视频的集合，<span class="math inline">\(D_L\)</span>
表示长视频的集合，paper 将短于 15s 定义为短视频，长于 45s
的定义为长视频</p>
<p>每个视频都会被切成等成的 segment，记为 <span
class="math inline">\(s\)</span>, <span
class="math inline">\(v(s)\)</span> 表示 segment 对应的视频</p>
<p>paper 采用了 pair-wise 的方法来构造样本，即从 <span
class="math inline">\(D_S\)</span> 和 <span
class="math inline">\(D_L\)</span> 切好的 segment
中分别取出一个，来构成一对 pair <span class="math inline">\((s_i,
s_j)\)</span>，然后基于下面的 <a
href="https://gombru.github.io/2019/04/03/ranking_loss/">ranking
loss</a> 计算两部分的差异，这里的 ranking loss
其实是一类损失函数，常见的 triplet loss、magrin loss、hinge loss
其实都可以算做 ranking loss</p>
<p>损失函数的表达如下</p>
<p><span class="math display">\[L(D) = \sum_{(s_i, s_j) \in \mathcal{P}}
\max(0, 1 - f(x_i) + f(x_j))\]</span></p>
<p>但这种认为短视频切出来的都是高光，长视频切出来都不是高光的方法显然是比较武断的，或者说存在
noise，所以需要计算每对 pair 的置信度，因此引入了一个 binary latent
variable <span class="math inline">\(w_{ij}\)</span>，表示每对 pair
的置信度, 因此上面的损失函数变成了如下形式</p>
<p><span class="math display">\[
\begin{align\*}
&amp;L(D) = \sum_{(s_i, s_j) \in \mathcal{P}} w_{ij} \max(0, 1 - f(x_i)
+ f(x_j)) \\\
&amp;\begin{array} \\\
s.t.&amp; \sum_{(s_i, s_j) \in \mathcal{P}} w_{ij} = p|\mathcal{P}|,
w_{ij} \in [0,1] \\\
&amp;w_{ij} = h(x_i, x_j)
\end{array}
\end{align\*}
\]</span></p>
<p>上面的 <span class="math inline">\(p\)</span> 表示训练样本里有效的
pair 的比例，<span class="math inline">\(h\)</span> 则是计算 <span
class="math inline">\(w_{ij}\)</span> 这个 variable
的网络，在训练时会跟原来的网络做 joint training，实际实现时，会通过分
batch + softmax 生效</p>
<p>虽然这里通过 <span class="math inline">\(w_{ij}\)</span>
做到了在<strong>统计意义上只有部分样本有效</strong>，但是未必就能把
noise 完全干掉，因为缺少人工先验的信息，可能最终训练出来，在真正有效的
pair 上，<span class="math inline">\(w_{ij}\)</span> 可能会更小</p>
<p>总体的模型和流程如下图所示，<span
class="math inline">\(\mathcal{P_1}\)</span> 到 <span
class="math inline">\(\mathcal{P_t}\)</span> 可认为是 <span
class="math inline">\(t\)</span> 个 batch，每个 batch 有 n 个 pair</p>
<p><img src="https://wulc.me/imgs/HighlightDetection_LessIsMore.jpg" height="50%" width="50%"></p>
<p>上面也提到，<span
class="math inline">\(w_{ij}\)</span>实际的生效是通过分 batch +
softmax，即上面的损失函数最终会改成如下形式，<span
class="math inline">\(\sigma\)</span> 是个 softmax 函数，生效在 <span
class="math inline">\(\mathcal{P_g}\)</span> 中，相当于 <span
class="math inline">\(p=\frac{1}{n}\)</span></p>
<p><span class="math display">\[
\begin{align\*}
&amp;L(D) = \sum_{g=1}^{m} \sum_{(s_i, s_j) \in \mathcal{P_g}} w_{ij}
\max(0, 1 - f(x_i) + f(x_j)) \\\
&amp;\begin{array}\\\
s.t.&amp; \sum_{(s_i, s_j) \in \mathcal{P_g}} w_{ij} = \sum_{(s_i, s_j)
\in \mathcal{P_g}} \sigma(h(x_i, x_j)) = 1 \\\
&amp;w_{ij} \in [0,1]
\end{array}
\end{align\*}
\]</span></p>
<p>实验采用的指标是 mAP(mean average precision)，在 object detection
中比较常见的指标，可以简单理解为多个类别物体检测中，每一个类别都可以根据recall和precision绘制一条曲线，AP
就是该曲线下的面积，mAP是多个类别AP的平均值</p>
<p>mAP 的定义跟 AUC 有点像，只是这里采用了 PR 曲线，AUC 采用的是 ROC
曲线，两者的区别可参考 <a
href="https://wulc.me/2018/06/16/ROC%20%E6%9B%B2%E7%BA%BF%E4%B8%8E%20PR%20%E6%9B%B2%E7%BA%BF/">ROC
曲线与 PR 曲线</a></p>
<p>实验主要在两个公开数据集上做，数据集为 YouTube Highlights 和
TVSum，数据集里对视频做了分类(domain)，因此也尝试了总体建模（下图的
Ours-A）和分 domain 建模（下图的
Ours-S），效果还是挺不错的，也超过了一些 supervised 的方法</p>
<p><img src="https://wulc.me/imgs/HighlightDetection_LessIsMore_result1.jpg" height="50%" width="50%"></p>
<p><img src="https://wulc.me/imgs/HighlightDetection_LessIsMore_result2.jpg" height="50%" width="50%"></p>
<p>文章也做了消融实验，主要是 2 部分</p>
<p>（1）针对上面的binary latent variable <span
class="math inline">\(w_{ij}\)</span>，对比了去掉 <span
class="math inline">\(w_{ij}\)</span> （下图中的Ranking-D）和通过 EM
来更新 <span class="math inline">\(w_{ij}\)</span> （下图中的
Ranking-EM）的效果，效果是 joint training &gt; EM &gt; 去掉 <span
class="math inline">\(w_{ij}\)</span></p>
<p><img src="https://wulc.me/imgs/HighlightDetection_LessIsMore_ablation1.jpg" height="50%" width="50%"></p>
<p>（2）对比了数据集大小的影响，随着数据集增大，准确率逐渐上升并减缓，比较常规的结论</p>
<p><img src="https://wulc.me/imgs/HighlightDetection_LessIsMore_ablation2.jpg" height="50%" width="50%"></p>
<h2 id="小结">小结</h2>
<p>关于 highlight detection 的 paper
不少，这里主要挑选了两篇有针对性的，两篇 paper 的一些核心点如下</p>
<p>第一篇 paper，TaoHighlight: Commodity-Aware Multi-Modal Video
Highlight Detection in E-Commerce</p>
<ul>
<li>特征工程: video 和 text 特征的提取，通过 co-attention
机制融合这两部分特征</li>
<li>损失函数的设计，<span class="math inline">\(L_{reg}\)</span> + <span
class="math inline">\(L_{ag}\)</span></li>
<li>减少noise: graph-based fine-tunning 模块，对一些 topk 的候选做
fine-tuning</li>
</ul>
<p>第二篇 paper，Less is More: Learning Highlight Detection from Video
Duration</p>
<ul>
<li>数据集，根据 video 的长短来判断视频的是否属于高光，无需人工打标</li>
<li>损失函数的设计，pair-wise 的 ranking loss</li>
<li>减少noise: 通过一个可训练的 binary latent variable
来标识样本的置信度</li>
</ul>
<p>第二篇的 paper
的模式感觉是更适合实际的生产环境的，主要是人工标注的可维护性和持续性都不好，而在第二篇基础上，真正落地时可能还有几个问题需要思考</p>
<ol type="1">
<li>video duration
是一个比较粗糙的信号，<strong>实际的业务中，会有很多的指标(比如说
ctr、cvr、roi等)，这些指标作为高光的定义也许是一个更好的选择，同时需要权衡选择的信号的深度和数据稀疏的
trade-off</strong></li>
<li>除了以上的 ranking loss，<strong>LTR(pair-wise, list-wise)
建模也是一个不错的选择，实际业务中需要考虑 pair 或 list
怎么构建</strong></li>
<li>如果是直播的场景下，需要实时做高光的检测，无法拿到整个视频，需要考虑一种<strong>流式的检测方法</strong></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《ImageNet Classification with Deep Convolutional Neural Networks》阅读笔记</title>
    <url>/2017/05/15/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a
href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet
Classification with Deep Convolutional Neural Networks</a>
这篇论文可以说是多层CNN用在图像领域的首次尝试（此前的LeNet也将CNN用在手写数字的识别上，但是没有用到连续多层CNN）。文中提出的网络模型
AlexNet(设计者的名字叫 Alex) 在 ImageNet 2010、2012
年的比赛上取得的效果远远地优于传统方法，这篇文献最重要的工作是设计并验证了这样一个有多层卷积层的网络的有效性，对学术界和工业界的影响都很大。</p>
<p>本文主要介绍这篇文章中提出的网络模型
AlexNet，以及其他涉及到的一些知识，主要的介绍的内容有：CNN的基础知识，AlexNet
的设计，训练和效果，以及对网络泛化（generalization）性能的一些探讨。</p>
<span id="more"></span>
<h2 id="cnn-简介">CNN 简介</h2>
<p><a
href="https://en.wikipedia.org/wiki/Convolutional_neural_network">CNN</a>
全称是 Convolutional Neural
Network，翻译做卷积神经网络，类似于我们常见的神经网络，CNN
也是一层一层连接起来的。顺便一提，这种 layer by layer 的网络叫做
feed-forward network，特点是无环，以区别于贝叶斯网络这种有环的网络</p>
<p>但是与传统的多层神经网络不同点在于,组成 CNN
的各个网络层不是常见的神经网络的里的网络层，而是由以下四种特殊的网络层组成</p>
<ol type="1">
<li>卷积层(convolutional layer)</li>
<li>池化层(pooling layer)</li>
<li>ReLU层(ReLU layer)</li>
<li>全连接层(fully connected layer)</li>
</ol>
<p>下面分别介绍各个层的具体结构与作用</p>
<h3 id="卷积层convolutional-layer">卷积层(Convolutional layer)</h3>
<p>卷积层是 CNN 中最重要的层，也是 CNN
名称的来源，卷积层里面有几个重要概念：核（kernel/filter)、卷积（convolution）、输出（activation
map）。对照下图可以比较清晰的理解</p>
<figure>
<img src="https://wulc.me/imgs/single%20channel.gif"
alt="convolutional layer" />
<figcaption aria-hidden="true">convolutional layer</figcaption>
</figure>
<p>核（kernel/filter): 移动的橙色正方形 卷积（convolution）：kernel 和
image 相应区域的点积 输出（activation
map）：卷积的输出，图中的粉色区域（convolved feature）</p>
<p>卷积层的作用可以理解为特征抽取，这种设计来源于人脑里面的机制，但是我们也能够直观地理解这类操作的意义，假设说我们现在要观察一幅图像，往往是从左到右，从上到下来观察的，而相邻的区域往往具有相似性，对于小面积区域（也就是
kernel 覆盖的区域）可以用更少的数据来概括这部分的特征。</p>
<p>上面的图像只用了一个
kernel，我们将其看做是一个人观察这张图片得到的信息，那假如有更多的人观察这张图片，并将所有人观察到的信息综合起来，得到的信息是否会更加完备呢?答案是肯定的，这就涉及到了多个kernel的情况，具体如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/multiple_kernel.jpg"
alt="multiple_kernel.jpg-16.2kB" />
<figcaption aria-hidden="true">multiple_kernel.jpg-16.2kB</figcaption>
</figure>
<p>除了多个 kernel，图片也会有多个channel，上图显示的 input image
只有一个channel，但是实际中用于分类的图片往往是 RGB
图片，有3个channel，分别是red， blue，green，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglhhknu1e7jni414k7g2v1ip11d.png"
alt="RGB channels" />
<figcaption aria-hidden="true">RGB channels</figcaption>
</figure>
<p>因此当输入的图片有多个channel，并且用多个 kernel
去进行卷积的时候，过程会如下图所示（<a
href="http://cs231n.github.io/convolutional-networks/#conv">来源</a>）</p>
<figure>
<img src="https://wulc.me/imgs/multiple%20channel.gif"
alt="convolutional network" />
<figcaption aria-hidden="true">convolutional network</figcaption>
</figure>
<p>上图的左边是 input image 的三个 channel，中间是两个
kernel，右边是输出的两个 activation map。对于有多个 channel 的情况，每个
kernel 就不再是二维的，而是三维，除去表示 kernel
大小的两个维度，剩下的一个维度也叫深度，大小就是输入的 channel
的大小。将从各个 channel 得到的值加起来，就得到了对应的 activation map
相应位置的输出。这里需要注意的的是，无论输入有多少个 channel，每个
kernel 最终只产生一个 activation map。</p>
<h3 id="池化层pooling-layer">池化层(pooling layer)</h3>
<p>池化类似于一种下采样（down sampling),
目的是要较少参数数量和计算量，如下所示是一个 max polling
的例子，其步长（stride）为2，kernel 为 2 X 2。</p>
<figure>
<img src="https://wulc.me/imgs/max_pooling.gif" alt="max pooling" />
<figcaption aria-hidden="true">max pooling</figcaption>
</figure>
<p>max pooling 指的是每次取 kernel 中的最大值最为输出，除了 max
pooling，还有 average pooling
等其他方式。除了上面提到的减少参数数量和计算量，池化还可以避免过拟合。</p>
<p>当上面的步长改为1后，kernel 移动过的区域会有重叠，我们称之为
overlapping pooling，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglieks0s4d1r5kklrdf7qg426.png"
alt="overlapping pooling" />
<figcaption aria-hidden="true">overlapping pooling</figcaption>
</figure>
<h3 id="relu-层relu-layer">ReLU 层(ReLU layer)</h3>
<p>ReLU 的全称是 Rectified Linear Units，从严格意义上来讲，ReLU
只是一个激活函数，而不能称之为一个层。其函数表达式为 <span
class="math inline">\(f(x) = max(0, x)\)</span>，其图像如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglikg561ica1iq811mf1aduhd2j.png"
alt="ReLU" />
<figcaption aria-hidden="true">ReLU</figcaption>
</figure>
<p>ReLU的主要作用是提升整个网络的非线性判别能力。关于选择 ReLU
作为激活函数而不是 sigmoid 或 tanh，后面会有详细说明。</p>
<h3 id="全连接层fully-connected-layer">全连接层(fully connected
layer)</h3>
<p>全连接层就是我们常见的神经网络中的网络层，每个神经元都与前面或后面的各个神经元有连接，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglj2kqt1mluolk8vjhfv7f430.png"
alt="fully connected layer" />
<figcaption aria-hidden="true">fully connected layer</figcaption>
</figure>
<p>由于全连接层的参数过多，在 CNN
中全连接层往往是作为最后几层用于输出。</p>
<h2 id="网络的设计">网络的设计</h2>
<p>上面介绍的四类 layer 是构成这篇论文中的 CNN 网络四种
layer，下面介绍论文中的 CNN 网络的结构及其特点。</p>
<h3 id="网络结构总览">网络结构总览</h3>
<p>文中提出的 CNN 网络结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgljihpe1q911dbdib71phbop3d.png"
alt="Alexnet" />
<figcaption aria-hidden="true">Alexnet</figcaption>
</figure>
<p>上图有以下几个特点</p>
<ol type="1">
<li>由5层卷积层+3层全连接层构成，并且整个网络在两个GPU上训练</li>
<li>在第 1、2、5 层卷积层后添加了最大池化的操作</li>
<li>在每层卷积层和全连接层后都有 ReLU 激活函数</li>
</ol>
<p>上图中网络就是
AlexNet，网络结构可以这样理解，首先上下两部分表示网络在两个GPU上训练，前五层表示5层卷积层，后三层表示3层全连接层；而立方体（最左边的是输入的图像，这里不算入）表示每层卷积层的输出，立方体里面的小立方体表示kernel的大小。</p>
<p>第一层卷积层采用了 48+48 共96个 kernel，输入的图像有三个
channel，但是前面提到无论有多少个channel，一个 kernel 只会产生一个
activation map，所以图中的第一个立方体 48 表示输出的 48 个 activation
map，而这48个 activation map 作为第二层卷积层的输入又成为了 48 个 input
channels，依次类推，第二层卷积层采用了 128+128 共 256 个kernel。</p>
<h3 id="网络的特点">网络的特点</h3>
<p>这个网络有三个特点并没有在上图中并不是非常显式地展示出来：分别是 ReLU
Nonlinearity、Local Response Normalization 和 Overlapping Pooling。</p>
<p><strong>ReLU Nonlinearity</strong></p>
<p>ReLU 在前面已经简单地进行了介绍，这里要讨论的是为什么采用了 ReLu
作为激活函数而不是 其他的如 sigmoid 或 tanh。主要原因是 ReLU
能够更快地收敛，因为其能够在一定程度上避免梯度消失（vanishing gradient
）的现象。</p>
<p>要解释这个原因首先需要看看这三个函数的图像（ReLU
的图像上面已经给出）</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglkiiou130110g4ola16hkni3q.png"
alt="tanh 和 sigmoid" />
<figcaption aria-hidden="true">tanh 和 sigmoid</figcaption>
</figure>
<p>这两个激活函数的图像非常相似，均是两边平，中间陡。当通过反向传播（backpropgation）训练时，需要通过链式法则求出总的梯度，而当激活值很大或很小的时候，也就是对应到上面图像两边平缓的地方是，对这两个激活函数的求导结果几乎为0，
从而导致相乘得到的总的梯度也几乎为0，错误不能有效地传播到前面的层，修正前面层的参数。这种现象就称为梯度消失。</p>
<p>而对于 ReLU
函数，当激活值小于0的时候，也存在着相同问题，而且这时候导数完全是0；但是大于0的时候
ReLU
的导数总是1，因此大于0的时候不存在梯度消失的现象。也有人说当激活值小于0的时候会带来稀疏性的好处。</p>
<p><strong>Local Response Normalization</strong></p>
<p>Local Response Normalization 指的是对网络中经过 ReLU
层输出的结果进行正规化， 其正规化的公式如下所示：</p>
<p><span class="math display">\[b\_{x,y}^i = a\_{x,y}^i/(k + \alpha
\sum\_{j=\max(0, i-n/2)}^{\min(N-1,
i+n/2)}(a\_{x,y}^j)^2)^{\beta}\]</span></p>
<p>上式中的 <span class="math inline">\(a\_{x,y}^i\)</span> 表示第 <span
class="math inline">\(i\)</span> 个kernel 在位置 <span
class="math inline">\((x,y)\)</span> 的原始输出，而 <span
class="math inline">\(b\_{x,y}^i\)</span>表示正规化后的输出，<span
class="math inline">\(N\)</span> 表示所有 kernel 的数目。上式表明对某个
kernel 在某个位置的输出的正规化利用了与这个 kernel 相邻的 <span
class="math inline">\(n\)</span> 个 kernel 在相同位置的值进行。</p>
<p>而其他参数 <span class="math inline">\(k, n, \alpha, \beta\)</span>
则是通过 cross-validataion 获得的参数，Local Response Normalization
分别被应用到第一层和第二层卷积层，文章里说这种方法分别将 top-1 error 和
top-5 error 降低了 1.4% 和1.2%。</p>
<p><strong>Overlapping Pooling</strong></p>
<p>这个机制我们在前面谈到池化层的时候已经提到，文章里说这种方法分别将
top-1 error 和 top-5 error 降低了 0.4% 和 0.3%。</p>
<h2 id="网络的训练">网络的训练</h2>
<h3 id="目标函数">目标函数</h3>
<p>文章中的问题是一个图像多分类的问题，多分类问题有若干种方法，在神经网络中最常用的就是
<a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a></p>
<p>单纯从数学的角度来讲，softmax
只是一种向量变换方式，假设现在有一个长度为 <span
class="math inline">\(k\)</span> 的向量 <span class="math inline">\(z =
(z\_1,...z\_k)\)</span>,对其进行 softmax 变换后得到向量 <span
class="math inline">\(\sigma(z)\)</span>, 其变换公式如下</p>
<p><span class="math display">\[\sigma(z)\_j =
\frac{e^{z\_j}}{\sum\_{l=1}^k e^{z\_l}}~~~(j=1,...k)\]</span></p>
<p>变换后的向量 <span class="math inline">\(\sigma(z)\)</span>
有一个重要特征，就是所有元素之和加起来为
1；从概率论的角度来考虑，很自然地可以将这个向量作为属于各个分类的一个概率分布，选择值最大的那个项对应的分类作为其分类。</p>
<p>这种“自然”也是有数学支撑的，实际上，softmax 的这个特性可以从 <a
href="https://en.wikipedia.org/wiki/Generalized_linear_model">Generalized
Linear Model</a> 中推导出来。这里就不详细展开论述了。</p>
<p>有了概率分布，很自然地一个想法就是做极大似然估计，如下是一个 <span
class="math inline">\(k\)</span> 分类问题中，最大化 <span
class="math inline">\(m\)</span> 个sample 的联合概率分布，其中 <span
class="math inline">\(1 \lbrace . \rbrace\)</span> 的含义为 <span
class="math inline">\(1 \lbrace True \rbrace = 1, 1 \lbrace False
\rbrace = 0\)</span>，如<span class="math inline">\(1 \lbrace 2=2
\rbrace = 1, 1 \lbrace 2=3 \rbrace = 0\)</span></p>
<p><span class="math display">\[\max \sum\_{i=1}^{m} \sum\_{j=1}^{k} 1
\lbrace y^{(i)} = j \rbrace \log \frac{e^{z\_j}}{\sum\_{l=1}^k
e^{z\_l}}\]</span></p>
<p>在其前面添加一个负号和一个常数 <span
class="math inline">\(\frac{1}{m}\)</span>
可以将其转为如下的极小化问题</p>
<p><span class="math display">\[\min -\frac{1}{m} \sum\_{i=1}^{m}
\sum\_{j=1}^{k} 1 \lbrace y^{(i)} = j \rbrace \log
\frac{e^{z\_j}}{\sum\_{l=1}^k e^{z\_l}}\]</span></p>
<p>实际上，上面要最小化的目标函数是交叉熵损失（cross-entropy
error），这个目标函数也可以通过交叉熵的定义推导出来。</p>
<h3 id="训练算法">训练算法</h3>
<p>上面得到的最后是一个无约束的最优化问题，对于这类最优化问题有多种方法可用，其中最常用的是随机梯度下降（Stochastic
Gradient Descent），但是这里没有用原始的SGD， 而是采用了带有 momentum,
weight decay 和 mini-batch 的SGD。</p>
<p>momentum, weight decay 和 mini-batch
是三个非常重要的概念，这里简单说明他们的作用</p>
<p><a
href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum">momentum</a>
指的是每次更新参数的梯度除了用当前迭代得到的梯度，还要加上前一次迭代得到的梯度，起作用是为了加快收敛，避免局部最优（如果问题非凸的话）</p>
<p><a
href="https://metacademy.org/graphs/concepts/weight_decay_neural_networks">weight
decay</a> 实际上是 L2 regularization
微分后得到的项，其目的是为了防止过拟合。</p>
<p><a
href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">mini-batch</a>
则是指每个更新时不仅采用一个样本，而是采用多个样本，这种方法介于 BGD 和
SGD 之间。</p>
<p>其更新的规则如下所示,参数 ，<span class="math inline">\(v\_i\)</span>
被称作 momentum variable， $- 0.0005 w_i $ 是 weight decay 项，<span
class="math inline">\(&lt;\frac{\partial L}{\partial
w}|\_{w\_i}&gt;\_{D\_i}\)</span> 则是从 mini-batch 为 <span
class="math inline">\(D\_i\)</span> 中得到的gradient， <span
class="math inline">\(\epsilon\)</span> 为步长。</p>
<p><span class="math display">\[\begin{align\*}
&amp;v\_{i+1} = 0.9v\_i - 0.0005 \epsilon w\_i - \epsilon
&lt;\frac{\partial L}{\partial w}|\_{w\_i}&gt;\_{D\_i}\\\
&amp;w\_{i+1} = w\_i + v\_{i+1}
\end{align\*}\]</span></p>
<h3 id="多gpu训练">多GPU训练</h3>
<p>前面已经提到了整个网络在两个 GPU 上训练， 原因是 GPU
能够并行的处理数据，训练速度较快，而同时一个 GPU
限制了模型的大小，因此用到了两个，两个 GPU
是并行的训练网络的，除了在第三层的卷积层两个 GPU 交换了数据用于cross
validation。与一个GPU训练的模型相比，两个GPU训练的模型分别将 top-1 error
和 top-5 error 降低了 1.7% 和 1.2%。</p>
<h3 id="防止过拟合">防止过拟合</h3>
<p>为了防止过拟合，文章采用了两种方法，data augmentation 和
dropout。</p>
<p><strong>data augmentation</strong></p>
<p>data augmentation
指的是如何从提供的数据集中得到更多的数据，文中也采用了两种途径，其中一种是从原始图像（大小为
256 × 256）中抽出多个大小为 224 × 224
的块作为图像，因此一幅原始图像能够生成多个图像；另外一种途径就是在原始图像的像素上加上通过PCA从图像中抽取出来的信息，从而生成新的图像。这两种方法将
top-1 error 降低了1%。</p>
<p><strong>dropout</strong></p>
<p>droupout 指的是每个神经元每次传递值时只有 50%
的概率工作，如下图所示，灰色的神经元指的是该神经元并没有工作。</p>
<figure>
<img src="https://wulc.me/imgs/dropout.gif" alt="dropout" />
<figcaption aria-hidden="true">dropout</figcaption>
</figure>
<p>这种方法的好处是降低了神经元间的依赖性，使得每个神经元更加
robust。droupout 被添加在第一和第二层全连接层中。</p>
<h2 id="网络的效果">网络的效果</h2>
<p>文中采用的数据集是 <a
href="http://www.image-net.org/">ImageNet</a>，这是一个有着约 14 million
张 labeled image 的图片集，每一年通过这个数据集会举办一次名为 ImageNet
Large-Scale Visual Recognition Challenge(ILSVRC)
的比赛，就是一个图片多分类比赛，文中展示了上面提到的 cnn 网络在 2010
年和2012年比赛中的表现结果，结果如下所示</p>
<p>2010年</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglq20231k02ek11q8lesb7i850.png"
alt="2010" />
<figcaption aria-hidden="true">2010</figcaption>
</figure>
<p>2012年 <img
src="https://wulc.me/imgs/image_1bglq28egel61eidsd6r4k11aa5d.png"
alt="2012" /></p>
<p>其中 2012 年的表格中 5 CNNs 表示用了 5 个CNN做投票 ensemble
后的效果，CNN*
表示在原来的5层卷积层的基础上再增加一层卷积层。可以看到CNN所得到的结果要远远优于第二名的，而这也是当年这篇文章震惊了学术界和工业界的原因。</p>
<h2 id="网络泛化能力的探讨">网络泛化能力的探讨</h2>
<p>从上面的论述中可知，我们将多个卷积层和全连接层连在一起，然后加上pooling，dropout等操作，就构建了一个取得非常好效果的网络，很自然我们会问，这个网络为什么能够取得这么好的效果？或者说这个网络的泛化能力为什么会这么好，是不是有什么保证了其泛化误差不会过大？</p>
<p>在统计机器学习中，有一个叫 <a
href="https://en.wikipedia.org/wiki/VC_dimension">VC dimension</a>
的概念，用于描述模型的复杂度，这个概念中的 VC bound
为泛化误差约束了一个bound，但是这个概念需要很复杂的数学推导，这里我们略去这些推导。只说一个
VC dimension
给我们揭示的一个很直观的概念：<strong>要取得较好的泛化能力，用于训练模型的样本数目应该至少是参数数目的10倍。</strong></p>
<p>这个理论在统计机器学习的svm等模型中都得到了较好的验证，但是文中提出的网络有
60 million的参数和1.25 million
的样本，因此这个条件远远没得到满足。但是网路却取得了很好的效果，这样看来，VC
dimension这个理论并适用于这个网络，实际上，不仅仅是这个网络，VC
dimension 在深度学习中多个网络中也不适用。</p>
<p>而这一点，也被 <a
href="http://www.iclr.cc/doku.php?id=ICLR2017:main&amp;redirect=1">2017
ICLR</a> 的最佳论文 <a
href="https://arxiv.org/abs/1611.03530">Understanding deep learning
requires rethinking generalization</a>指出，下图是从这篇论文的
presentation 中抽取的一张图片。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bglsl8l91sjp1k7bide1f5bbhc9.png"
alt="4 networks" />
<figcaption aria-hidden="true">4 networks</figcaption>
</figure>
<p>图中四个宠物小精灵代表了四个著名的网络，随着 p/n 值越来越大，也就是
“样本/参数” 的比值越来越小，越不满足 VC dimension
提出的条件，但是泛化的误差却越来越小。</p>
<p>这篇最佳论文还做了很多其他实验，这里就不详细展开，但是从这篇文章并没有从理论上说明了这个网络泛化误差小的理论依据，也就是没有提出在深度学习领域适用的
“VC
dimension”，而这一工作将会是未来深度学习发展中非常重要和有意义的工作。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 面向对象的几个概念</title>
    <url>/2016/07/01/Java%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%87%A0%E4%B8%AA%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<p>本文主要记录Java面向对象中几个容易混淆的概念。主要包括重写(override)与重载(overload)，多态，抽象类与接口。</p>
<span id="more"></span>
<h2 id="继承">继承</h2>
<p>在Java中，类的继承是单一继承，<strong>一个子类只能拥有一个父类</strong>。通过<code>extends</code>关键字实现类的继承。所有Java的类均是由<code>java.lang.Object</code>类继承而来的，所以Object是所有类的祖先类，而除了Object外，所有类必须有一个父类。</p>
<p>通过<code>instanceof</code>关键字可以判断一个对象是不是一个类的实例。见下面的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//A.java</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//B.java</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">B</span> <span class="keyword">extends</span> <span class="title class_">A</span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">  <span class="type">A</span> <span class="variable">a</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">A</span>();</span><br><span class="line">  <span class="type">B</span> <span class="variable">b</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">B</span>();</span><br><span class="line">  System.out.println(a <span class="keyword">instanceof</span> A);</span><br><span class="line">  System.out.println(b <span class="keyword">instanceof</span> B);</span><br><span class="line">  System.out.println(a <span class="keyword">instanceof</span> B);</span><br><span class="line">  System.out.println(b <span class="keyword">instanceof</span> A);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码的输出为 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">true</span><br><span class="line">true</span><br><span class="line">false</span><br><span class="line">true</span><br></pre></td></tr></table></figure>
也就是说子类的对象也是父类的一个实例。</p>
<h2 id="重写override与重载overload">重写(override)与重载(overload)</h2>
<h3 id="重写override">重写(override)</h3>
<p>重写(override)是子类对父类的允许访问的方法的实现过程进行重新编写,<strong>返回值和形参都不能改变。</strong></p>
<p>重写有以下几点规则</p>
<ul>
<li><strong>参数列表和返回类型</strong>必须完全与被重写方法相同；</li>
<li>访问权限不能比父类中被重写的方法的访问权限更低。例如：如果父类的一个方法被声明为public，那么在子类中重写该方法就不能声明为protected。</li>
<li>子类只能重写有访问权限的父类方法，在此基础上声明为final的方法不能被重写。</li>
<li>重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常。但是，重写的方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常，反之则可以</li>
<li>构造方法不能被重写。 如果不能继承一个方法，则不能重写这个方法</li>
</ul>
<p>详见下面的例子： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">move</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;动物可以移动&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span> <span class="keyword">extends</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">move</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;狗可以跑和走&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestDog</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span>&#123;</span><br><span class="line">      <span class="type">Animal</span> <span class="variable">a</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Animal</span>(); <span class="comment">// Animal 对象</span></span><br><span class="line">      <span class="type">Animal</span> <span class="variable">b</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Dog</span>(); <span class="comment">// Dog 对象</span></span><br><span class="line">      a.move();<span class="comment">// 执行 Animal 类的方法</span></span><br><span class="line">      b.move();<span class="comment">//执行 Dog 类的方法</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
在上面的例子中可以看到，尽管b属于Animal类型，但是它运行的是Dog类的move方法。
这是由于在<strong>编译阶段，只是检查参数的引用类型</strong>。
然而在<strong>运行时，Java虚拟机(JVM)指定对象的类型并且运行该对象的方法</strong>。
因此在上面的例子中，<strong>之所以能编译成功，是因为Animal类中存在move方法，然而运行时，运行的是特定对象的方法。</strong>而这就是一个典型的多态例子。</p>
<p>再看看下面的例子能更好地理解上面的话 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">move</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;动物可以移动&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span> <span class="keyword">extends</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">move</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;狗可以跑和走&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bark</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;狗可以吠叫&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestDog</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span>&#123;</span><br><span class="line">      <span class="type">Animal</span> <span class="variable">a</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Animal</span>(); <span class="comment">// Animal 对象</span></span><br><span class="line">      <span class="type">Animal</span> <span class="variable">b</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Dog</span>(); <span class="comment">// Dog 对象</span></span><br><span class="line">      a.move();<span class="comment">// 执行 Animal 类的方法</span></span><br><span class="line">      b.move();<span class="comment">//执行 Dog 类的方法</span></span><br><span class="line">      b.bark();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
以上实例编译运行结果如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TestDog.java:30: cannot find symbol</span><br><span class="line">symbol  : method bark()</span><br><span class="line">location: class Animal</span><br><span class="line">                b.bark();</span><br><span class="line">                 ^</span><br></pre></td></tr></table></figure>
该程序将抛出一个编译错误，因为<strong>b的引用类型Animal没有bark方法</strong>。</p>
<p>当需要<strong>在子类中调用父类的被重写方法时</strong>，要使用super关键字。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">move</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;动物可以移动&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span> <span class="keyword">extends</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">move</span><span class="params">()</span>&#123;</span><br><span class="line">      <span class="built_in">super</span>.move(); <span class="comment">// 应用super类的方法</span></span><br><span class="line">      System.out.println(<span class="string">&quot;狗可以跑和走&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestDog</span>&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span>&#123;</span><br><span class="line">      <span class="type">Animal</span> <span class="variable">b</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Dog</span>(); <span class="comment">// Dog 对象</span></span><br><span class="line">      b.move(); <span class="comment">//执行 Dog类的方法</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上实例编译运行结果如下： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">动物可以移动</span><br><span class="line">狗可以跑和走</span><br></pre></td></tr></table></figure></p>
<h3 id="重载overload">重载(overload)</h3>
<p>重载(overloading)
是在<strong>一个类里面，方法名字相同，而参数不同，返回类型可以相同也可以不同。</strong></p>
<p>重载有以下几点规则</p>
<ul>
<li>被重载的方法<strong>必须改变参数列表</strong>；</li>
<li>被重载的方法可以改变返回类型；</li>
<li>被重载的方法可以改变访问修饰符，没有限制权限只能变大或变小的限制</li>
<li>方法能够在同一个类中或者在一个子类中被重载。</li>
</ul>
<p>见下面的例子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Overloading</span> &#123;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;test1&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">(<span class="type">int</span> a)</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;test2&quot;</span>);</span><br><span class="line">	&#125;	</span><br><span class="line"> </span><br><span class="line">	<span class="comment">//以下两个参数类型顺序不同</span></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">test</span><span class="params">(<span class="type">int</span> a,String s)</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;test3&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;returntest3&quot;</span>;</span><br><span class="line">	&#125;	</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">test</span><span class="params">(String s,<span class="type">int</span> a)</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;test4&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;returntest4&quot;</span>;</span><br><span class="line">	&#125;	</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">		<span class="type">Overloading</span> <span class="variable">o</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Overloading</span>();</span><br><span class="line">		System.out.println(o.test());</span><br><span class="line">		o.test(<span class="number">1</span>);</span><br><span class="line">		System.out.println(o.test(<span class="number">1</span>,<span class="string">&quot;test3&quot;</span>));</span><br><span class="line">		System.out.println(o.test(<span class="string">&quot;test4&quot;</span>,<span class="number">1</span>));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3
id="重写override与重载overload的区别">重写(override)与重载(overload)的区别</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">区别点</th>
<th style="text-align: center;">重写(override)</th>
<th style="text-align: center;">重载(overload)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">参数列表</td>
<td style="text-align: center;">不能改变</td>
<td style="text-align: center;">必须改变</td>
</tr>
<tr class="even">
<td style="text-align: center;">返回类型</td>
<td style="text-align: center;">不能改变</td>
<td style="text-align: center;">可以改变</td>
</tr>
<tr class="odd">
<td style="text-align: center;">范围</td>
<td style="text-align: center;">只能在子类中重写</td>
<td style="text-align: center;">可以在当前类或子类中重载</td>
</tr>
<tr class="even">
<td style="text-align: center;">权限</td>
<td style="text-align: center;">重写的方法的访问权限只能变大</td>
<td style="text-align: center;">重载方法的访问权限无变化限制</td>
</tr>
<tr class="odd">
<td style="text-align: center;">异常</td>
<td
style="text-align: center;">可以减少或删除，不能抛出新的或者更广的异常</td>
<td style="text-align: center;">无添加减少的限制</td>
</tr>
</tbody>
</table>
<h2 id="多态">多态</h2>
<p>从字面上的意思解释，多态是<strong>同一个行为具有多个不同表现形态</strong>的能力。反映在Java面向对象中指的是<strong>同一方法（参数列表和返回类型都相同）有具有多种实现方式</strong>。</p>
<p>因此，结合上面说到的内容，多态存在有以下三个必要条件:</p>
<ul>
<li>继承</li>
<li>重写</li>
<li>父类引用指向子类对象</li>
</ul>
<p>当使用多态方式调用方法时，<strong>首先检查父类中是否有该方法，如果没有，则编译错误；如果有，再去调用子类的同名方法。</strong></p>
<p>上面的重写所提到的例子就是一个典型的多态例子。</p>
<h2 id="抽象类与接口">抽象类与接口</h2>
<h3 id="抽象类">抽象类</h3>
<p>抽象类<strong>不能实例化对象</strong>，抽象类的用途在于声明了一系列需要被继承并实现的抽象方法，然后被其他类继承并实现。也是因为这个原因，通常在设计阶段决定要不要设计抽象类。</p>
<p>抽象类通过<code>abstract class</code>来定义，同时需要注意<strong>如果一个类包含抽象方法，那么该类一定要声明为抽象类；但是抽象类可以不包含抽象方法，也可以同时包含抽象方法和非抽象方法</strong>。</p>
<p>见下面的例子 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Employee.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Employee</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">private</span> String name;</span><br><span class="line">   <span class="keyword">private</span> String address;</span><br><span class="line">   <span class="keyword">private</span> <span class="type">int</span> number;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="type">double</span> <span class="title function_">computePay</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// seller.java</span></span><br><span class="line"><span class="keyword">public</span>  <span class="keyword">class</span> <span class="title class_">seller</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">double</span> computePay</span><br><span class="line">     &#123;</span><br><span class="line">     </span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>继承抽象类后需要注意下面两点：</p>
<ul>
<li>如果一个类包含抽象方法，那么该类必须是抽象类。</li>
<li>任何子类必须重写父类<strong>所有的抽象方法</strong>，否则需要声明自身为抽象类。</li>
</ul>
<h3 id="接口interface">接口（interface）</h3>
<p>接口（英文：Interface），在JAVA中是<strong>抽象方法的集合</strong>，接口通常以
<code>interface</code>
来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法。</p>
<p>接口并不是类，编写接口的方式和类很相似，但是它们属于不同的概念。类描述对象的属性和方法。接口则包含类要实现的方法。</p>
<p>接口有以下特性：</p>
<ul>
<li>接口是隐式抽象的，当声明一个接口的时候，不必使用abstract关键字。</li>
<li>接口中每一个方法也是隐式抽象的，声明时同样不需要abstract关键子。</li>
<li>接口中的方法都是公有的。</li>
</ul>
<p>如下面就声明了一个接口： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Animal</span> &#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">eat</span><span class="params">()</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">travel</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>当类实现接口的时候，类要实现接口中所有的方法。否则，类必须声明为抽象的类。</strong>
类使用<code>implements</code>关键字实现接口,且<strong>一个类可以实现多个接口</strong>。</p>
<p>下面是实现上面的接口的一个例子： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MammalInt</span> <span class="keyword">implements</span> <span class="title class_">Animal</span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">eat</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Mammal eats&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">travel</span><span class="params">()</span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;Mammal travels&quot;</span>);</span><br><span class="line">   &#125; </span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">noOfLegs</span><span class="params">()</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span>&#123;</span><br><span class="line">      <span class="type">MammalInt</span> <span class="variable">m</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MammalInt</span>();</span><br><span class="line">      m.eat();</span><br><span class="line">      m.travel();</span><br><span class="line">   &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></p>
<p>一个接口能继承另一个接口，和类之间的继承方式比较相似。接口的继承使用<code>extends</code>关键字，见下面的例子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Sports.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sports</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setHomeTeam</span><span class="params">(String name)</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setVisitingTeam</span><span class="params">(String name)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Football.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Football</span> <span class="keyword">extends</span> <span class="title class_">Sports</span></span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">homeTeamScored</span><span class="params">(<span class="type">int</span> points)</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">visitingTeamScored</span><span class="params">(<span class="type">int</span> points)</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">endOfQuarter</span><span class="params">(<span class="type">int</span> quarter)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>除此之外，接口还允许多继承，但是 Java
中是不允许类的多继承的。如下面的接口就继承了上面的两个接口
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Socer</span> <span class="keyword">extends</span> <span class="title class_">Sports</span>, Football</span><br><span class="line">&#123;</span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接口与抽象类非常相似，两者的区别入下：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">区别</th>
<th style="text-align: center;">接口</th>
<th style="text-align: center;">抽象类</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">继承(实现)的个数</td>
<td style="text-align: center;">一个类可实现多个接口</td>
<td style="text-align: center;">一个类仅能继承一个抽象类</td>
</tr>
<tr class="even">
<td style="text-align: center;">内部是否可以含有实现的方法</td>
<td style="text-align: center;">没有实现的方法</td>
<td style="text-align: center;">可以有实现的方法</td>
</tr>
</tbody>
</table>
<hr />
<p>参考：http://www.runoob.com/java</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 中的修饰符</title>
    <url>/2016/06/20/Java%20%E4%B8%AD%E7%9A%84%E4%BF%AE%E9%A5%B0%E7%AC%A6/</url>
    <content><![CDATA[<p>Java的修饰符主要分为两种</p>
<ul>
<li>访问修饰符</li>
<li>非访问修饰符</li>
</ul>
<span id="more"></span>
<h2 id="访问修饰符">访问修饰符</h2>
<p><strong>访问修饰符用于控制对类、方法、变量的访问权限</strong>，使用中有private、default、protected、public四个修饰符，其访问权限从小到大。其中default不是一个保留字，而是当任何修饰符都不加的时候的默认权限。</p>
<p>四种修饰符的区别如下所示</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">修饰符</th>
<th style="text-align: center;">属性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">private</td>
<td style="text-align: center;">仅对同一个类（class）内部可见</td>
</tr>
<tr class="even">
<td style="text-align: center;">default</td>
<td style="text-align: center;">对同一个包（package）内的所有类可见</td>
</tr>
<tr class="odd">
<td style="text-align: center;">protected</td>
<td
style="text-align: center;">对同一个包内的所有类及其子类可见（即使子类在另外一个包）</td>
</tr>
<tr class="even">
<td style="text-align: center;">public</td>
<td style="text-align: center;">对所有包的所有类均可见</td>
</tr>
</tbody>
</table>
<p>访问权限的继承的一个原则就是<strong>子类从父类继承过来的方法和变量的访问权限只能变大，private除外</strong>，因此就有了以下几条原则</p>
<ul>
<li>父类中声明为public的方法在子类中也必须为public。</li>
<li>父类中声明为protected的方法在子类中要么声明为protected，要么声明为public。不能声明为private。</li>
<li>父类中声明为private的方法，不能够被继承。</li>
</ul>
<h2 id="非访问修饰符">非访问修饰符</h2>
<p>非访问修饰符指的是一些实现其他功能的修饰符，为了与控制访问权限的访问修饰符区别，就命名为了非访问修饰符。</p>
<p>非访问修饰符主要包含static，final， abstract，
synchronized和volatile。其主要区别如下：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">修饰符</th>
<th style="text-align: center;">属性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">static</td>
<td style="text-align: center;">声明方法或变量属于整个类而不是变量</td>
</tr>
<tr class="even">
<td style="text-align: center;">final</td>
<td style="text-align: center;">声明方法或变量不可被修改</td>
</tr>
<tr class="odd">
<td style="text-align: center;">abstract</td>
<td
style="text-align: center;">仅仅声明了类或方法的名称而让子类对抽象类进行拓展和修改</td>
</tr>
<tr class="even">
<td style="text-align: center;">synchronized和volatile</td>
<td style="text-align: center;">用于线程的同步</td>
</tr>
</tbody>
</table>
<p>关于上面的几个修饰符有以下几点需要注意：</p>
<h3 id="static">static</h3>
<ul>
<li>静态（static）方法不能使用类的非静态变量</li>
<li>静态变量或方法可通过类直接调用：如<code>class.staticVariable</code>或<code>class.staticMethod</code></li>
</ul>
<h3 id="final">final</h3>
<ul>
<li>final变量需要<strong>在声明的时候显式初始化并且只能初始化一次</strong></li>
<li>final方法可以被子类继承，但是不能被子类修改，或者说重写(override)</li>
<li>final类不能被继承，没有类能够继承final类的任何特性</li>
<li>final修饰符通常和static修饰符一起使用来创建类常量</li>
</ul>
<h3 id="abstract">abstract</h3>
<ul>
<li>抽象（abstract）方法是一种<strong>没有任何实现的方法（没有花括号）</strong>，该方法的的具体实现由子类提供</li>
<li>抽象方法的声明以分号结尾，且例如：<code>public abstract sample();</code></li>
<li>任何继承抽象类的子类必须实现父类的所有抽象方法，除非该子类也是抽象类。</li>
<li>如果<strong>一个类包含抽象方法，那么该类一定要声明为抽象类</strong>；但是抽象类可以不包含抽象方法，也可以同时包含抽象方法和非抽象方法</li>
</ul>
<p>一个抽象类的定义 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Caravan</span>&#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="type">double</span> price;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">goFast</span><span class="params">()</span>; <span class="comment">//抽象方法</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">changeColor</span><span class="params">()</span></span><br><span class="line">   &#123;</span><br><span class="line">    <span class="comment">// 抽象类中可以包含实现了的方法</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>抽象方法: <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">SuperClass</span>&#123;</span><br><span class="line">    <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">m</span><span class="params">()</span>; <span class="comment">//抽象方法</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SubClass</span> <span class="keyword">extends</span> <span class="title class_">SuperClass</span>&#123;</span><br><span class="line">     <span class="comment">//实现抽象方法</span></span><br><span class="line">      <span class="keyword">void</span> <span class="title function_">m</span><span class="params">()</span>&#123;</span><br><span class="line">          .........</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里顺便穿插抽象类和接口（interface）的一些差异：</p>
<p>接口（interface）就是给出一些没有内容的方法，封装到一起，到某个类需要使用的时候，再根据具体情况将这些方法写出。</p>
<p>与抽象类不同的是<strong>抽象类中的方法可以有主体（也就是实现了该方法）；而接口中的所有方法都不可以有主体（也就是所有方法都不可以实现）</strong></p>
<p>除此之外，<strong>一个类可以实现多个接口，实现了类似于多继承的特性；但是一个类不能继承多个类</strong>，并且一个类在实现一个接口的同时也可以继承一个类，如：<code>class son extends father implements interface&#123;&#125;</code></p>
<h3 id="synchronized和volatile">synchronized和volatile</h3>
<ul>
<li>synchronized关键字声明的方法同一时间只能被一个线程访问，通过synchronized修饰符可以实现线程锁的功能</li>
<li>volatile
修饰的成员变量在每次被线程访问时，都强制从共享内存中重新读取该成员变量的值。而且，当成员变量发生变化时，会强制线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值</li>
</ul>
<p>关于violate的一个列子如下所示 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyRunnable</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">boolean</span> active;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        active = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">while</span> (active) <span class="comment">// 第一行</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 代码</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stop</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        active = <span class="literal">false</span>; <span class="comment">// 第二行</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>通常情况下，在一个线程调用 run() 方法（在 Runnable
开启的线程），在另一个线程调用 stop() 方法。 <strong>如果 第一行
中缓冲区的 active 值被使用，那么在 第二行 的 active 值为 false
时循环不会停止。</strong>但是以上代码中我们使用了 volatile 修饰
active，所以该循环会停止。</p>
<p>在对变量和方法使用修饰符时，访问修饰符和非访问修饰符可以混用，且对访问修饰符只能选择其中一个，而非访问修饰符则没有这个限制。因此以下修饰符都是合法的
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">()</span> <span class="comment">// 执行类的入口--main 方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">final</span> <span class="variable">pi</span> <span class="operator">=</span> <span class="number">3.14</span> <span class="comment">//不可修改的变量π</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">Test</span> <span class="comment">// 不能被继承的类</span></span><br><span class="line">.............</span><br></pre></td></tr></table></figure></p>
<hr />
<p>Referer</p>
<ul>
<li>http://www.runoob.com/java/java-modifier-types.html</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中Hashtable与HashMap的区别</title>
    <url>/2016/04/03/Java%E4%B8%ADHashtable%E4%B8%8EHashMap%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>据说这是面试中被问频率非常高的一个问题，下面做简单的记录：
<span id="more"></span></p>
<h2 id="相同点">相同点</h2>
<ul>
<li>父类都是Map类</li>
<li>都是用来存储kv对的</li>
<li>存取kv的方法名一样（前提是均使用iterator来遍历）</li>
</ul>
<h2 id="不同点">不同点</h2>
<h3 id="线程安全">线程安全</h3>
<p><strong>Hashtable是线程安全的，HashMap不是线程安全的。</strong>什么是线程安全？简单就是在<strong>多线程的情况下变量的值能否正确地被每个线程修改</strong>。因为多线程同时修改的时候有可能发生冲突，如同时修改一个变量等操作。</p>
<p>所以在多线程的情况下，要使用Hashtable。</p>
<h3 id="效率">效率</h3>
<p><strong>Hashtable的效率比HashMap的效率要低</strong>。表现为相同的数据下HashMap比Hashtable使用的内存更多而且更慢。这个可以算是线程安全所付出的代价，因为要保证线程间的同步，需要额外的维护变量不能同时被修改。</p>
<p>所以单线程的时候，建议使用HashMap，效率较高</p>
<h3 id="遍历的方法">遍历的方法</h3>
<p>两者均可通过<code>java.util.Iterator</code>来遍历，除此之外Hashtable还可以通过<code>java.util.Enumeration</code>来遍历。关于两者的区别可以看<a
href="http://wulc.me/2016/04/03/Java%E4%B8%ADIterator%E5%92%8CEnumeration%E7%9A%84%E5%8C%BA%E5%88%AB/">这篇文章</a></p>
<h3 id="空键值">空键值</h3>
<p><strong>Hashtable不允许null的键值，HashMap则允许一个 null
键和若干null的value。</strong></p>
<h2 id="使用建议">使用建议</h2>
<p>单线程的情况下使用HashMap，效率较高，多线程的情况下使用Hashtable保证线程间的同步。</p>
<p>此外，<code>Vector</code>和<code>ArrayList</code>的一个重要区别也是上面提到的线程安全问题，其中<code>Vector</code>是线程安全的，而<code>ArrayList</code>不是线程安全的。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中Iterator和Enumeration的区别</title>
    <url>/2016/04/03/Java%E4%B8%ADIterator%E5%92%8CEnumeration%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>Java中的<code>java.util.Iterator</code>和<code>java.util.Enumeration</code>均可用来遍历Java中的集合框架（list,map,set等）。
<span id="more"></span> 但是两者也有一些区别，主要表现为:</p>
<ul>
<li><p>并非所有的collection都支持<code>Enumeration</code>的遍历，但是都支持<code>Iterator</code>的遍历。如Hashtable支持但是HashMap不支持。但是两者都支持<code>Iterator</code>的遍历。</p></li>
<li><p><code>Iterator</code>
提供了<code>remove()</code>方法可以在<strong>遍历的同时删除集合中的元素</strong>，但是<code>Enumeration</code>没有这个方法，对集合中的元素只读</p></li>
<li><p>两者的方法名不同，具体见下面的代码</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * compare Iterator with Enumeration</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashTableAndHashMap</span> </span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span></span><br><span class="line">	&#123;</span><br><span class="line">	    <span class="comment">//init the map</span></span><br><span class="line">	    Hashtable&lt;String,String&gt;  ht = <span class="keyword">new</span> <span class="title class_">Hashtable</span>&lt;String,String&gt;();</span><br><span class="line">	    Map&lt;String,String&gt;  hm = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String,String&gt;();</span><br><span class="line">	    </span><br><span class="line">	    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++)</span><br><span class="line">	    &#123;</span><br><span class="line">	    	ht.put(Integer.toString(i), Integer.toString(i));</span><br><span class="line">	    	hm.put(Integer.toString(i), Integer.toString(i));</span><br><span class="line">	    &#125;</span><br><span class="line">	    </span><br><span class="line">	    <span class="comment">//different ways of iterating the values</span></span><br><span class="line">	    Iterator&lt;Map.Entry&lt;String, String&gt;&gt; it = hm.entrySet().iterator();    </span><br><span class="line">	    System.out.println(<span class="string">&quot;traverse hashmap&quot;</span>);</span><br><span class="line">	    <span class="keyword">while</span> (it.hasNext())</span><br><span class="line">	    &#123;   </span><br><span class="line">	    	<span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> it.next().getKey();</span><br><span class="line">	        <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> hm.get(key);</span><br><span class="line">	        <span class="keyword">if</span> (key.equals(<span class="string">&quot;2&quot;</span>))</span><br><span class="line">	        &#123;</span><br><span class="line">	        	it.remove();</span><br><span class="line">	        	System.out.println(key+<span class="string">&quot; is removed&quot;</span>);</span><br><span class="line">	        	<span class="keyword">continue</span>;</span><br><span class="line">	        &#125;</span><br><span class="line">	    	System.out.println(key+<span class="string">&quot;:&quot;</span>+value);</span><br><span class="line">	    &#125;</span><br><span class="line">	    System.out.println(<span class="string">&quot;hashmap final size:&quot;</span>+hm.size()+<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">	    </span><br><span class="line">	    </span><br><span class="line">	    System.out.println(<span class="string">&quot;traverse hashtable&quot;</span>);</span><br><span class="line">	    Enumeration&lt;String&gt; em = ht.keys();</span><br><span class="line">	    <span class="keyword">while</span>(em.hasMoreElements())</span><br><span class="line">	    &#123;</span><br><span class="line">	    	<span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> em.nextElement();</span><br><span class="line">	    	<span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> ht.get(key);</span><br><span class="line">	    	<span class="keyword">if</span> (key.equals(<span class="string">&quot;2&quot;</span>))</span><br><span class="line">	        &#123;</span><br><span class="line">	        	<span class="comment">//em不提供remove的方法，但是可以通过ht.remove(key)删除</span></span><br><span class="line">	        	System.out.println(key+<span class="string">&quot; is removed&quot;</span>);</span><br><span class="line">	        	<span class="keyword">continue</span>;</span><br><span class="line">	        &#125;</span><br><span class="line">	    	System.out.println(key+<span class="string">&quot;:&quot;</span>+value);</span><br><span class="line">	    &#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的代码可以看到，两者遍历的方法名不同：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">名称</th>
<th style="text-align: center;">是否还有元素</th>
<th style="text-align: center;">找到下一元素</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Iterator</td>
<td style="text-align: center;">hasNext()</td>
<td style="text-align: center;">next()</td>
</tr>
<tr class="even">
<td style="text-align: center;">Enumeration</td>
<td style="text-align: center;">hasMoreElements()</td>
<td style="text-align: center;">nextElement()</td>
</tr>
</tbody>
</table>
<p>而且虽然em遍历的时候不可以通过自己删除某个元素，但是可以通过collection自身删除，见上面的<code>ht.remove()</code>,而通过Iterator遍历的时候不可以通过collection自身删除，如上面假如用了<code>hm.remove()</code>会抛出<code>ConcurrentModificationException</code>。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中String和byte[]的转换</title>
    <url>/2016/01/13/Java%E4%B8%ADString%E5%92%8Cbyte%5B%5D%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<p>在Java的网络编程中，通过socket发送和接收到的数据是byte[
]类型的，而我们希望发送的消息一般是用String类型表示的，所以在Java的网络编程中，发送端需要将String类型转换为byte[
]类型，接收端需要将byte[ ]类型转换为String类型。</p>
<span id="more"></span>
<h2 id="string类型转换为byte-类型">String类型转换为byte[ ]类型</h2>
<p>代码如下： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String sendString=<span class="string">&quot;hello&quot;</span>;</span><br><span class="line"><span class="type">byte</span>[] sendByte=sendString.getBytes(<span class="string">&quot;UTF8&quot;</span>);</span><br></pre></td></tr></table></figure>
除了UTF8编码方式外，还可以采用"GBK","IOS-8859-1"等编码方式，这几种编码方式的差别在于表示同一个字符采用的字节数不同，而且为了中文显示不乱码，一般采用UTF8的编码方式。</p>
<h2 id="byte-类型转换为string类型">byte[ ]类型转换为String类型</h2>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String receiveString=<span class="keyword">new</span> <span class="title class_">String</span>(receiveBytes,<span class="string">&quot;UTF8&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>receiveBytes为需要转为String的字节数组，"UTF8"的作用也是为了指定转换采用的编码方式，省略时会采用系统默认的编码方式。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中String的比较方式（== 和 equals）</title>
    <url>/2016/05/18/Java%E4%B8%ADString%E7%9A%84%E6%AF%94%E8%BE%83%E6%96%B9%E5%BC%8F%EF%BC%88==%20%E5%92%8C%20equals%EF%BC%89/</url>
    <content><![CDATA[<h2 id="基本概念">基本概念</h2>
<p>在Java中，<strong>String既可以作为一个对象来使用，又可以作为一个基本类型来使用</strong>。
<span id="more"></span>
这里指的作为一个基本类型来使用只是指使用方法上的，比如<code>String s = "hello"</code>，它的使用方法如同基本类型int一样，比如int
i =
1;，而作为一个对象来使用，则是指<strong>通过new关键字来创建一个新对象</strong>，比如<code>String s = new String("Hello")</code></p>
<p>Java中String比较的方法有两种：
1）<strong>用"=="来比较</strong>。这种比较是比较两个String类型变量的<strong>引用</strong>是否相同(即是否指相同的内存地址)
2）<strong>用Object对象的<code>equals()</code>方法来比较</strong>。String对象继承自Object，并且对equals()方法进行了重写。两个String对象通过equals()方法来进行比较时，也就是对String对象的实际内容进行比较。</p>
<h2 id="实际例子">实际例子</h2>
<h3 id="string-作为对象时的比较">String 作为对象时的比较</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(s1 == s2);</span><br><span class="line">System.out.println(s1.equals(s2));</span><br><span class="line"></span><br><span class="line"><span class="comment">/*output*/</span></span><br><span class="line"><span class="literal">false</span></span><br><span class="line"><span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>两个String对象都是通过<code>new</code>创建出来的，而<code>new</code>关键字为创建的每个对象分配一块新的、独立的内存堆，因此当通过"=="来比较它们的引用是否相同时，将返回false；而通过<code>equals()</code>方法来比较时，则返回true，因为这两个对象所封装的字符串内容是完全相同的。</p>
<h3 id="string作为基本类型时的比较">String作为基本类型时的比较</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line"></span><br><span class="line">System.out.println(s1 == s2);</span><br><span class="line">System.out.println(s1.equals(s2));</span><br><span class="line"></span><br><span class="line"><span class="comment">/*output*/</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>由于这两个String对象都是作为一个基本类型来使用的，而<strong>不是通过new关键字来创建的，因此虚拟机不会为这两个String对象分配新的内存堆</strong>，而是到<strong>String缓冲池</strong>中来寻找。</p>
<p>什么是String缓冲池？在Java中，由于String（final）是不可改变的，为了提高效率，不重复创建新的字符创，Java引用了String缓冲池的概念。</p>
<p>首先为s1寻找String缓冲池内是否有与"Hello"相同值的String对象存在，此时String缓冲没有相同值的String对象存在，所以<strong>虚拟机会在String缓冲池内创建此String对象，其动作就是new
String("Hello");。然后把此String对象的引用赋值给s1</strong>。</p>
<p>接着为s2寻找String缓冲池内是否有与"Hello"相同值的String对象存在，此时虚拟机找到了一个与其相同值的String对象，这个String对象其实就是为s1所创建的String对象。既然找到了一个相同值的对象，那么虚拟机就不在为此创建一个新的String对象，而是直接把存在的String对象的引用赋值给s2。</p>
<p>这里既然s1和s2所引用的是同一个String对象，即自己等于自己，所以以上两种比较方法都返回ture。
。</p>
<h3 id="对象与基本类型的比较">对象与基本类型的比较</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(s1 == s2);</span><br><span class="line">System.out.println(s1.equals(s2));</span><br><span class="line"></span><br><span class="line"><span class="comment">/*output*/</span></span><br><span class="line"><span class="literal">false</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>由于<strong><code>new</code>关键字会申请新的内存空间，创建新的对象</strong>，因此不会去查找缓存池，即使缓存池中有"Hello"，因此两者的内存地址不是一样的，所以第一个输出为false，而两者的内容是一样的，输出为true。</p>
<p>将上面的代码稍作修改</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line">s2 = s2.intern();</span><br><span class="line"></span><br><span class="line">System.out.println(s1 == s2);</span><br><span class="line">System.out.println(s1.equals(s2));</span><br><span class="line"></span><br><span class="line"><span class="comment">/*output*/</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="literal">true</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面的代码增加了一行<code>s2 = s2.intern();</code><strong>其作用是从String缓冲池内取出一个与其值相同的String对象的引用赋值给s（假如有的话）</strong>。</p>
<p>这样做的原因是如果频繁地创建相同内容的对象，虚拟机分配许多新的内存堆，虽然它们的内容是完全相同的。<strong>由于String是final类，因此String对象在创建后不能改变</strong>。所以为了节省内存，可以使用String缓冲池，因为String缓冲池内不会存在相同内容的String对象。而<code>intern()</code>方法就是使用这种机制的途径。</p>
<p>在一个已实例化的String对象s上调用<code>intern()</code>方法后，虚拟机会在String缓冲池内寻找与此s对象存储内容相同的String对象，如果能找到，则返回对象在缓冲池中的地址，如果找不到，那么虚拟机在缓冲池中以s的内容新建一个对象并返回这个对象的地址。<strong>注意需要将s指向返回的缓冲池对象的地址，这样才能通过垃圾回收器回将原先那个通过new关键字所创建出的String对象回收。</strong></p>
<p>因此可以解释上面的<code>s1==s2</code>返回结果为什么是true了，因为此时，两者的引用相同，均指向缓冲池的对象。</p>
<h3 id="拼接字符串后的比较">拼接字符串后的比较</h3>
<p>上面提到由于String是final类，因此String对象在创建后不能改变，那么像拼接字符串的操作如<code>String s1=s2+s3;</code>（s2、s3是已赋值的String）应该会产生一个新的对象，用新的地址空间存储。但是这句话也不完全对，详见下面的例子</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;a&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="string">&quot;b&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s3</span> <span class="operator">=</span> <span class="string">&quot;ab&quot;</span>;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s4</span> <span class="operator">=</span> <span class="string">&quot;a&quot;</span>+<span class="string">&quot;b&quot;</span>;  </span><br><span class="line">System.out.println(<span class="string">&quot;s3==s4? &quot;</span>+ (s3==s4));  </span><br><span class="line">  </span><br><span class="line"><span class="type">String</span> <span class="variable">s5</span> <span class="operator">=</span> s1+s2;  </span><br><span class="line">System.out.println(<span class="string">&quot;s3==s5? &quot;</span>+ (s3==s5));  </span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="type">String</span> <span class="variable">s6</span> <span class="operator">=</span> <span class="string">&quot;a&quot;</span> ;   </span><br><span class="line"><span class="keyword">final</span> <span class="type">String</span> <span class="variable">s7</span> <span class="operator">=</span> <span class="string">&quot;b&quot;</span> ;  </span><br><span class="line"><span class="type">String</span> <span class="variable">s8</span> <span class="operator">=</span> s6 + s7;  </span><br><span class="line">System.out.println(<span class="string">&quot;s3==s8? &quot;</span>+ (s3==s8));  </span><br></pre></td></tr></table></figure>
<p>输出如下： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">s3==s4? <span class="literal">true</span></span><br><span class="line">s3==s5? <span class="literal">false</span></span><br><span class="line">s3==s8? <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<p>s4由"a"、"b"两个常量拼接而成，本来按照上面的说法应该会生成新的内存空间，但是<strong>因为"a"、"b"为两个为常量，不可变</strong>，在编译期间编译器会把s5="a"+"b"优化为s5="ab"。</p>
<p>s5由s1和s2拼接而成，由于两个变量的相加所以编译器无法优化，
在运行时，会有新的String地址空间的分配，而不是指向缓冲池中的“ab”。所以结果false。</p>
<p>s6虽让也是由两个变量拼接而成，但是这两个变量已经声明为final不可变的了，所以类似于s4，在编译期间编译器也进行了优化确定了s8的值。</p>
<hr />
<p>参考： http://blog.csdn.net/wangdong20/article/details/8566217
http://www.itxxz.com/a/tea/2014/0814/208.html
http://renxiangzyq.iteye.com/blog/549554</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java内置的数据类型</title>
    <url>/2016/05/15/Java%E5%86%85%E7%BD%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<p>Java可分为两大数据类型:</p>
<ul>
<li>内置数据类型（Primitive）</li>
<li>引用数据类型（Reference） <span id="more"></span>
两者的分类及区别如下所示：</li>
</ul>
<p><img src="https://wulc.me/imgs/DataType_All.png" /></p>
<p>从上图可知，内置数据类型有八种基本类型。六种数字类型（四个整数型，两个浮点型），一种字符类型，还有一种布尔型。上图直接将字符类型char归入到整数类型中，原因是两者可以进行相互的转换。</p>
<h2 id="整数类型">整数类型</h2>
<h3 id="byte">byte</h3>
<ul>
<li>byte数据类型是<strong>8位、有符号</strong>的，以二进制补码表示的整数；</li>
<li>最小值是-128（-2^7）；</li>
<li>最大值是127（2^7-1）；</li>
<li>默认值是0；</li>
<li>byte类型用在大型数组中节约空间，主要代替整数，因为byte变量占用的空间只有int类型的四分之一；</li>
<li>例子：byte a = 100，byte b = -50。</li>
</ul>
<h3 id="short">short</h3>
<ul>
<li>short数据类型是<strong>16位、有符号</strong>的以二进制补码表示的整数</li>
<li>最小值是-32768（-2^15）；</li>
<li>最大值是32767（2^15 - 1）；</li>
<li>short数据类型也可以像byte那样节省空间。一个short变量是int型变量所占空间的二分之一；</li>
<li>默认值是0；</li>
<li>例子：short s = 1000，short r = -20000。</li>
</ul>
<h3 id="int">int</h3>
<ul>
<li>int数据类型是<strong>32位、有符号</strong>的以二进制补码表示的整数；</li>
<li>最小值是-2,147,483,648（-2^31）；</li>
<li>最大值是2,147,485,647（2^31 - 1）；</li>
<li>一般地整型变量默认为int类型；</li>
<li>默认值是0；</li>
<li>例子：int a = 100000, int b = -200000。</li>
</ul>
<h3 id="long">long</h3>
<ul>
<li>long数据类型<strong>是64位、有符号</strong>的以二进制补码表示的整数；</li>
<li>最小值是-9,223,372,036,854,775,808（-2^63）；</li>
<li>最大值是9,223,372,036,854,775,807（2^63 -1）；</li>
<li>这种类型主要使用在需要比较大整数的系统上；</li>
<li>默认值是0L；</li>
<li>例子： long a = 100000L，int b = -200000L。</li>
</ul>
<h3 id="小结">小结</h3>
<p>可见整数类型的最大区别在于其<strong>表示范围和占用的内存大小不同</strong>。在使用时根据实际的使用场景选择合适的数据类型。</p>
<p>可将表示范围小的数值复制给表示范围大的数，但是反过来不行，因为大数的值可能会超出小的数的表示范围。如下所示
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line"><span class="type">short</span> <span class="variable">b</span> <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">byte</span> <span class="variable">c</span> <span class="operator">=</span> a; <span class="comment">// 错误</span></span><br><span class="line"><span class="type">long</span> <span class="variable">d</span> <span class="operator">=</span> b; <span class="comment">// 正确</span></span><br></pre></td></tr></table></figure></p>
<h2 id="浮点数">浮点数</h2>
<h3 id="float">float</h3>
<ul>
<li>float数据类型是<strong>单精度（single-precision）、32位（4字节）</strong>、符合IEEE
754标准的浮点数；</li>
<li>float在储存大型浮点数组的时候可节省内存空间；</li>
<li>默认值是0.0f；</li>
<li>浮点数不能用来表示精确的值，如货币；</li>
<li>例子：float f1 = 234.5f。</li>
</ul>
<h3 id="double">double</h3>
<ul>
<li><p>double数据类型是<strong>双精度（double-precision）、64位（8字节）</strong>、符合IEEE
754标准的浮点数；</p></li>
<li><p><strong>浮点数的默认类型为double类型</strong>，见下面的例子
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*下面的表达式会导致编译器会报错，因为默认0.1是double类型，而a是一个float类型，这样赋值会导致精度的损失*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">float</span> a=<span class="number">0.1</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">//有两种方法，一是将float改为double，二是将0.1改成0.1f</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>double类型同样不能表示精确的值，如货币；</p></li>
<li><p>默认值是0.0f；</p></li>
<li><p>例子：double d1 = 123.4。</p></li>
</ul>
<h3 id="小结-1">小结</h3>
<p>float是单精度数字，而double是双精度数字。两者的主要区别如下：</p>
<ul>
<li>存储</li>
</ul>
<p>float由32 bit存储，其中1位符号位，8位指数位，23位尾数位。 double由64
bit存储，其中1位符号位，11位指数位，52位尾数位。</p>
<ul>
<li>数值范围</li>
</ul>
<p>float的指数范围为-128<sub>+127，而double的指数范围为-1024</sub>+1023，并且指数位是按补码的形式来划分的。</p>
<p>其中负指数决定了浮点数所能表达的绝对值最小的非零数；而正指数决定了浮点数所能表达的绝对值最大的数，也即决定了浮点数的取值范围。</p>
<p>float的范围为-2^128 ~ +2^127，也即-3.40E+38 ~
+3.40E+38；double的范围为-2^1024 ~ +2^1023，也即-1.79E+308 ~
+1.79E+308。</p>
<ul>
<li>精度</li>
</ul>
<p>float和double的精度是由尾数的位数来决定的。浮点数在内存中是按科学计数法来存储的，其整数部分始终是一个隐含着的“1”，由于它是不变的，故不能对精度造成影响。</p>
<p>float：2^23 =
8388608，一共七位，由于最左为1的一位省略了，这意味着最多能表示8位数：
2*8388608 =
16777216。有8位有效数字，但绝对能保证的为7位，也即<strong>float的精度为7~8位有效数字</strong></p>
<p>double：2^52 =
4503599627370496，一共16位，同理，<strong>double的精度为16~17位</strong>。</p>
<p>之所以<strong>不能用f1==f2来判断两个数相等，是因为虽然f1和f2在可能是两个不同的数字，但是受到浮点数表示精度的限制，有可能会错误的判断两个数相等</strong>！</p>
<h2 id="boolean">boolean</h2>
<ul>
<li>boolean数据类型表示一位的信息，<strong>大小不确定</strong></li>
<li>只有两个取值：true和false；</li>
<li>这种类型只作为一种标志来记录true/false情况；</li>
<li>默认值是false；</li>
<li>例子：boolean one = true。</li>
</ul>
<h2 id="char">char</h2>
<ul>
<li>char类型是一个单一的16位（2字节）Unicode字符；</li>
<li>最小值是’000’（即为0）；</li>
<li>最大值是’’（即为65,535）；</li>
<li>char数据类型可以储存<strong>任何字符，包括汉字</strong>；</li>
<li>例子：char letter =
'A'。(<strong>只能用单引号，不能用双引号</strong>)</li>
</ul>
<p>参考：
https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html
http://www.runoob.com/java/java-basic-datatypes.html
http://blog.csdn.net/zq602316498/article/details/41148063
http://blog.csdn.net/abing37/article/details/5332798</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java通过socket获取mysql中的记录遇到的问题</title>
    <url>/2016/01/12/Java%E9%80%9A%E8%BF%87socket%E8%8E%B7%E5%8F%96mysql%E4%B8%AD%E7%9A%84%E8%AE%B0%E5%BD%95%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>在实际应用中，经常会遇到这种需求，客户端发送关键字到服务器端，服务器端根据关键字查找数据库中的内容并发送给客户端。<strong>本文主要阐述根据传输过来的关键字在查找数据库时查找不到（实际上是数据库中是有数据的）的问题，以及解决方法。</strong>
<span id="more"></span></p>
<p>先看Java与mysql交互的代码:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="type">String</span> <span class="variable">driver</span> <span class="operator">=</span> <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>; <span class="comment">// 驱动程序名</span></span><br><span class="line"> <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> <span class="string">&quot;mysql的地址&quot;</span>; <span class="comment">// URL指向要访问的数据库</span></span><br><span class="line"> <span class="type">String</span> <span class="variable">user</span> <span class="operator">=</span> <span class="string">&quot;用户名&quot;</span>;  <span class="comment">// MySQL配置时的用户名</span></span><br><span class="line"> <span class="type">String</span> <span class="variable">password</span> <span class="operator">=</span> <span class="string">&quot;你的密码&quot;</span>; <span class="comment">// MySQL配置时的密码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Class.forName(driver);<span class="comment">// 加载驱动程序</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(url, user, password);<span class="comment">// 连接数据库</span></span><br><span class="line"><span class="keyword">if</span>(!conn.isClosed())</span><br><span class="line">    System.out.println(<span class="string">&quot;成功连接到数据库!&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="type">PreparedStatement</span> <span class="variable">prepstmt</span> <span class="operator">=</span> <span class="literal">null</span>; <span class="comment">//用预编译对象执行sql语句并返回结果</span></span><br><span class="line"><span class="type">String</span> <span class="variable">sql</span> <span class="operator">=</span> <span class="string">&quot;select admoment,url1,url2  from captiontest where filmname=? order by admoment&quot;</span>;<span class="comment">//要执行的SQL语句,按时间查找广告出现的数据记录</span></span><br><span class="line">prepstmt=conn.prepareStatement(sql);</span><br><span class="line">prepstmt.setString(<span class="number">1</span>,name); <span class="comment">// 由于filmnam是String类所以这里是setString，其他同理为setxxx（xxx为类型）</span></span><br><span class="line">ResultSet rs=prepstmt.executeQuery(); <span class="comment">//结果集</span></span><br></pre></td></tr></table></figure>
<p>其中程序中的 <code>name</code> 为 <code>String</code>
类型，也就是客户端传过来的关键字，但是测试时的问题<strong>是即使数据库中存在相关的关键字信息，也不会输出相关信息。</strong>。</p>
<p>这个时候首先要做的就是将执行的SQL语句打印出来，因为很多时候得不到预期的结果都是因为是实际执行的SQL语句跟自己预期会执行的SQL语句不同。通过下面语句可以得出执行的SQL语句:
<code>System.out.println(prepstmt.toString());</code>。</p>
<p>结果如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select admoment,url1,url2  from captiontest where filmname=&#x27;爱情公寓4\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\&#x27; order by admoment</span><br></pre></td></tr></table></figure>
<p>怪不得找不到，sql语句都变成这个模样了，那中间的 <code>\0</code>
是从哪里来的？在网上查了后得出的原因如下：<strong>在 <code>socket</code>
传输自己流时，默认会有一段固定长度的 <code>bufferstream</code>
来接受传输的字节流，这段固定长度的默认值就是 <code>\0</code> , 而那些
<code>\0</code> 就是 <code>bufferstream</code>
中没被传输过来的字节流覆盖的单元，解决方法也很简单，就是在服务器接受到客户端传输过来的字节流时，根据字节流有效长度来创建String</strong></p>
<p>原来我的<code>name</code>是这样产生的，is是socket的输入流：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">String name=<span class="keyword">new</span> <span class="title class_">String</span>(b,<span class="string">&quot;UTF-8&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>没有指定长度，改为下面的产生方式就好了</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">String name=<span class="keyword">new</span> <span class="title class_">String</span>(b,<span class="number">0</span>,n);<span class="comment">//0和n是指定产生String用到的字节流的开头和结尾</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java解释XML的四种方法</title>
    <url>/2015/12/21/Java%E8%A7%A3%E9%87%8AXML%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>最近毕设需要用Java解释XML文件，在网上搜到了Java解释XML的一篇比较详细的文章，<a
href="http://www.cnblogs.com/lanxuezaipiao/archive/2013/05/17/3082949.html">原文链接</a>,下面为原文
众所周知，现在解析XML的方法越来越多，但主流的方法也就四种，即：DOM、SAX、JDOM和DOM4J</p>
<span id="more"></span>
<p>下面首先给出这四种方法的jar包下载地址</p>
<p>DOM：在现在的Java JDK里都自带了，在xml-apis.jar包里</p>
<p>SAX：http://sourceforge.net/projects/sax/</p>
<p>JDOM：http://jdom.org/downloads/index.html</p>
<p>DOM4J：http://sourceforge.net/projects/dom4j/</p>
<h1 id="介绍及优缺点分析">介绍及优缺点分析</h1>
<h2 id="domdocument-object-model">DOM（Document Object Model)</h2>
<p>DOM是用与平台和语言无关的方式表示XML文档的官方W3C标准。DOM是以层次结构组织的节点或信息片断的集合。这个层次结构允许开发人员在树中寻找特定信息。分析该结构通常需要加载整个文档和构造层次结构，然后才能做任何工作。由于它是基于信息层次的，因而DOM被认为是基于树或基于对象的。</p>
<p>【优点】 ①允许应用程序对数据和结构做出更改。
②访问是双向的，可以在任何时候在树中上下导航，获取和操作任意部分的数据。
【缺点】 ①通常需要加载整个XML文档来构造层次结构，消耗资源大。</p>
<h2 id="saxsimple-api-for-xml">SAX（Simple API for XML)</h2>
<p>SAX处理的优点非常类似于流媒体的优点。分析能够立即开始，而不是等待所有的数据被处理。而且，由于应用程序只是在读取数据时检查数据，因此不需要将数据存储在内存中。这对于大型文档来说是个巨大的优点。事实上，应用程序甚至不必解析整个文档；它可以在某个条件得到满足时停止解析。一般来说，SAX还比它的替代者DOM快许多。</p>
<p>选择DOM还是选择SAX？
对于需要自己编写代码来处理XML文档的开发人员来说，
选择DOM还是SAX解析模型是一个非常重要的设计决策。
DOM采用建立树形结构的方式访问XML文档，而SAX采用的是事件模型。</p>
<p>DOM解析器把XML文档转化为一个包含其内容的树，并可以对树进行遍历。用DOM解析模型的优点是编程容易，开发人员只需要调用建树的指令，然后利用navigation
APIs访问所需的树节点来完成任务。可以很容易的添加和修改树中的元素。然而由于使用DOM解析器的时候需要处理整个XML文档，所以对性能和内存的要求比较高，尤其是遇到很大的XML文件的时候。由于它的遍历能力，DOM解析器常用于XML文档需要频繁的改变的服务中。</p>
<p>SAX解析器采用了基于事件的模型，它在解析XML文档的时候可以触发一系列的事件，当发现给定的tag的时候，它可以激活一个回调方法，告诉该方法制定的标签已经找到。SAX对内存的要求通常会比较低，因为它让开发人员自己来决定所要处理的tag.特别是当开发人员只需要处理文档中所包含的部分数据时，SAX这种扩展能力得到了更好的体现。但用SAX解析器的时候编码工作会比较困难，而且很难同时访问同一个文档中的多处不同数据。</p>
<p>【优势】 ①不需要等待所有数据都被处理，分析就能立即开始。
②只在读取数据时检查数据，不需要保存在内存中。
③可以在某个条件得到满足时停止解析，不必解析整个文档。
④效率和性能较高，能解析大于系统内存的文档。</p>
<p>【缺点】
①需要应用程序自己负责TAG的处理逻辑（例如维护父/子关系等），文档越复杂程序就越复杂。
②单向导航，无法定位文档层次，很难同时访问同一文档的不同部分数据，不支持XPath。</p>
<h2 id="jdomjava-based-document-object-model">JDOM(Java-based Document
Object Model)</h2>
<p>JDOM的目的是成为Java特定文档模型，它简化与XML的交互并且比使用DOM实现更快。由于是第一个Java特定模型，JDOM一直得到大力推广和促进。正在考虑通过“Java规范请求JSR-102”将它最终用作“Java标准扩展”。从2000年初就已经开始了JDOM开发。</p>
<p>JDOM与DOM主要有两方面不同。首先，JDOM仅使用具体类而不使用接口。这在某些方面简化了API，但是也限制了灵活性。第二，API大量使用了Collections类，简化了那些已经熟悉这些类的Java开发者的使用。</p>
<p>JDOM文档声明其目的是“使用20%（或更少）的精力解决80%（或更多）Java/XML问题”（根据学习曲线假定为20%）。JDOM对于大多数Java/XML应用程序来说当然是有用的，并且大多数开发者发现API比DOM容易理解得多。JDOM还包括对程序行为的相当广泛检查以防止用户做任何在XML中无意义的事。然而，它仍需要您充分理解XML以便做一些超出基本的工作（或者甚至理解某些情况下的错误）。这也许是比学习DOM或JDOM接口都更有意义的工作。</p>
<p>JDOM自身不包含解析器。它通常使用SAX2解析器来解析和验证输入XML文档（尽管它还可以将以前构造的DOM表示作为输入）。它包含一些转换器以将JDOM表示输出成SAX2事件流、DOM模型或XML文本文档。JDOM是在Apache许可证变体下发布的开放源码。</p>
<p>【优点】 ①使用具体类而不是接口，简化了DOM的API。
②大量使用了Java集合类，方便了Java开发人员。</p>
<p>【缺点】 ①没有较好的灵活性。 ②性能较差。</p>
<h2 id="dom4jdocument-object-model-for-java">DOM4J(Document Object Model
for Java)</h2>
<p>虽然DOM4J代表了完全独立的开发结果，但最初，它是JDOM的一种智能分支。它合并了许多超出基本XML文档表示的功能，包括集成的XPath支持、XML
Schema支持以及用于大文档或流化文档的基于事件的处理。它还提供了构建文档表示的选项，它通过DOM4J
API和标准DOM接口具有并行访问功能。从2000下半年开始，它就一直处于开发之中。</p>
<p>为支持所有这些功能，DOM4J使用接口和抽象基本类方法。DOM4J大量使用了API中的Collections类，但是在许多情况下，它还提供一些替代方法以允许更好的性能或更直接的编码方法。直接好处是，虽然DOM4J付出了更复杂的API的代价，但是它提供了比JDOM大得多的灵活性。</p>
<p>在添加灵活性、XPath集成和对大文档处理的目标时，DOM4J的目标与JDOM是一样的：针对Java开发者的易用性和直观操作。它还致力于成为比JDOM更完整的解决方案，实现在本质上处理所有Java/XML问题的目标。在完成该目标时，它比JDOM更少强调防止不正确的应用程序行为。</p>
<p>DOM4J是一个非常非常优秀的Java XML
API，具有性能优异、功能强大和极端易用使用的特点，同时它也是一个开放源代码的软件。如今你可以看到越来越多的Java软件都在使用DOM4J来读写XML，特别值得一提的是连Sun的JAXM也在用DOM4J.</p>
<p>【优点】
①大量使用了Java集合类，方便Java开发人员，同时提供一些提高性能的替代方法。
②支持XPath。 ③有很好的性能。</p>
<p>【缺点】 ①大量使用了接口，API较为复杂。</p>
<h1 id="比较">比较</h1>
<ol type="1">
<li><p>DOM4J性能最好，连Sun的JAXM也在用DOM4J。目前许多开源项目中大量采用DOM4J，例如大名鼎鼎的Hibernate也用DOM4J来读取XML配置文件。如果不考虑可移植性，那就采用DOM4J.</p></li>
<li><p>JDOM和DOM在性能测试时表现不佳，在测试10M文档时内存溢出，但可移植。在小文档情况下还值得考虑使用DOM和JDOM.虽然JDOM的开发者已经说明他们期望在正式发行版前专注性能问题，但是从性能观点来看，它确实没有值得推荐之处。另外，DOM仍是一个非常好的选择。DOM实现广泛应用于多种编程语言。它还是许多其它与XML相关的标准的基础，因为它正式获得W3C推荐（与基于非标准的Java模型相对），所以在某些类型的项目中可能也需要它（如在JavaScript中使用DOM）。</p></li>
<li><p>SAX表现较好，这要依赖于它特定的解析方式－事件驱动。一个SAX检测即将到来的XML流，但并没有载入到内存（当然当XML流被读入时，会有部分文档暂时隐藏在内存中）。</p></li>
</ol>
<p>我的看法：如果XML文档较大且不考虑移植性问题建议采用DOM4J；如果XML文档较小则建议采用JDOM；如果需要及时处理而不需要保存数据则考虑SAX。但无论如何，还是那句话：适合自己的才是最好的，如果时间允许，建议大家讲这四种方法都尝试一遍然后选择一种适合自己的即可。</p>
<h1 id="示例">示例</h1>
<p>为了节约篇幅，这里暂时不给出这四种建立XML文档的方法与差异，仅给出解析XML文档的代码，如果需要完整工程（建立XML文档+解析XML+测试比较），可去我的CSDN下载。</p>
<p>这里以下面的XML内容为例进行解析： <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">users</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user</span> <span class="attr">id</span>=<span class="string">&quot;0&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Alexia<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">age</span>&gt;</span>23<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">sex</span>&gt;</span>Female<span class="tag">&lt;/<span class="name">sex</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user</span> <span class="attr">id</span>=<span class="string">&quot;1&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Edward<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">age</span>&gt;</span>24<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">sex</span>&gt;</span>Male<span class="tag">&lt;/<span class="name">sex</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user</span> <span class="attr">id</span>=<span class="string">&quot;2&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>wjm<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">age</span>&gt;</span>23<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">sex</span>&gt;</span>Female<span class="tag">&lt;/<span class="name">sex</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user</span> <span class="attr">id</span>=<span class="string">&quot;3&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>wh<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">age</span>&gt;</span>24<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">sex</span>&gt;</span>Male<span class="tag">&lt;/<span class="name">sex</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">users</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>首先定义XML文档解析的接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Alexia</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 定义XML文档解析的接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">XmlDocument</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析XML文档</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     *            文件全路径名称</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">parserXml</span><span class="params">(String fileName)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="dom示例">DOM示例</h2>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xml;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.PrintWriter;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.DocumentBuilder;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.DocumentBuilderFactory;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.ParserConfigurationException;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.OutputKeys;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.Transformer;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.TransformerConfigurationException;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.TransformerException;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.TransformerFactory;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.dom.DOMSource;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.stream.StreamResult;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.Document;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.Element;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.Node;</span><br><span class="line"><span class="keyword">import</span> org.w3c.dom.NodeList;</span><br><span class="line"><span class="keyword">import</span> org.xml.sax.SAXException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Alexia</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * DOM 解析XML文档</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DomDemo</span> <span class="keyword">implements</span> <span class="title class_">XmlDocument</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Document document;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">parserXml</span><span class="params">(String fileName)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">DocumentBuilderFactory</span> <span class="variable">dbf</span> <span class="operator">=</span> DocumentBuilderFactory.newInstance();</span><br><span class="line">            <span class="type">DocumentBuilder</span> <span class="variable">db</span> <span class="operator">=</span> dbf.newDocumentBuilder();</span><br><span class="line">            <span class="type">Document</span> <span class="variable">document</span> <span class="operator">=</span> db.parse(fileName);</span><br><span class="line">            <span class="type">NodeList</span> <span class="variable">users</span> <span class="operator">=</span> document.getChildNodes();</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; users.getLength(); i++) &#123;</span><br><span class="line">                <span class="type">Node</span> <span class="variable">user</span> <span class="operator">=</span> users.item(i);</span><br><span class="line">                <span class="type">NodeList</span> <span class="variable">userInfo</span> <span class="operator">=</span> user.getChildNodes();</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; userInfo.getLength(); j++) &#123;</span><br><span class="line">                    <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> userInfo.item(j);</span><br><span class="line">                    <span class="type">NodeList</span> <span class="variable">userMeta</span> <span class="operator">=</span> node.getChildNodes();</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> <span class="number">0</span>; k &lt; userMeta.getLength(); k++) &#123;</span><br><span class="line">                        <span class="keyword">if</span>(userMeta.item(k).getNodeName() != <span class="string">&quot;#text&quot;</span>)</span><br><span class="line">                            System.out.println(userMeta.item(k).getNodeName()</span><br><span class="line">                                    + <span class="string">&quot;:&quot;</span> + userMeta.item(k).getTextContent());</span><br><span class="line">                    &#125;</span><br><span class="line">                    </span><br><span class="line">                    System.out.println();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ParserConfigurationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SAXException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="sax示例">SAX示例</h2>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xml;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.OutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.StringWriter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.ParserConfigurationException;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.SAXParser;</span><br><span class="line"><span class="keyword">import</span> javax.xml.parsers.SAXParserFactory;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.OutputKeys;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.Result;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.Transformer;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.TransformerConfigurationException;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.sax.SAXTransformerFactory;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.sax.TransformerHandler;</span><br><span class="line"><span class="keyword">import</span> javax.xml.transform.stream.StreamResult;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.xml.sax.Attributes;</span><br><span class="line"><span class="keyword">import</span> org.xml.sax.SAXException;</span><br><span class="line"><span class="keyword">import</span> org.xml.sax.helpers.AttributesImpl;</span><br><span class="line"><span class="keyword">import</span> org.xml.sax.helpers.DefaultHandler;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Alexia</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * SAX 解析XML文档</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SaxDemo</span> <span class="keyword">implements</span> <span class="title class_">XmlDocument</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">parserXml</span><span class="params">(String fileName)</span> &#123;</span><br><span class="line">        <span class="type">SAXParserFactory</span> <span class="variable">saxfac</span> <span class="operator">=</span> SAXParserFactory.newInstance();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">SAXParser</span> <span class="variable">saxparser</span> <span class="operator">=</span> saxfac.newSAXParser();</span><br><span class="line">            <span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(fileName);</span><br><span class="line">            saxparser.parse(is, <span class="keyword">new</span> <span class="title class_">MySAXHandler</span>());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ParserConfigurationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (SAXException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MySAXHandler</span> <span class="keyword">extends</span> <span class="title class_">DefaultHandler</span> &#123;</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">hasAttribute</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="type">Attributes</span> <span class="variable">attributes</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startDocument</span><span class="params">()</span> <span class="keyword">throws</span> SAXException &#123;</span><br><span class="line">        <span class="comment">// System.out.println(&quot;文档开始打印了&quot;);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">endDocument</span><span class="params">()</span> <span class="keyword">throws</span> SAXException &#123;</span><br><span class="line">        <span class="comment">// System.out.println(&quot;文档打印结束了&quot;);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startElement</span><span class="params">(String uri, String localName, String qName,</span></span><br><span class="line"><span class="params">            Attributes attributes)</span> <span class="keyword">throws</span> SAXException &#123;</span><br><span class="line">        <span class="keyword">if</span> (qName.equals(<span class="string">&quot;users&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (qName.equals(<span class="string">&quot;user&quot;</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (attributes.getLength() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">this</span>.attributes = attributes;</span><br><span class="line">            <span class="built_in">this</span>.hasAttribute = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">endElement</span><span class="params">(String uri, String localName, String qName)</span></span><br><span class="line">            <span class="keyword">throws</span> SAXException &#123;</span><br><span class="line">        <span class="keyword">if</span> (hasAttribute &amp;&amp; (attributes != <span class="literal">null</span>)) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; attributes.getLength(); i++) &#123;</span><br><span class="line">                System.out.print(attributes.getQName(<span class="number">0</span>) + <span class="string">&quot;:&quot;</span></span><br><span class="line">                        + attributes.getValue(<span class="number">0</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">characters</span><span class="params">(<span class="type">char</span>[] ch, <span class="type">int</span> start, <span class="type">int</span> length)</span></span><br><span class="line">            <span class="keyword">throws</span> SAXException &#123;</span><br><span class="line">        System.out.print(<span class="keyword">new</span> <span class="title class_">String</span>(ch, start, length));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="jdom-示例">JDOM 示例</h2>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xml;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.jdom2.Document;</span><br><span class="line"><span class="keyword">import</span> org.jdom2.Element;</span><br><span class="line"><span class="keyword">import</span> org.jdom2.JDOMException;</span><br><span class="line"><span class="keyword">import</span> org.jdom2.input.SAXBuilder;</span><br><span class="line"><span class="keyword">import</span> org.jdom2.output.XMLOutputter;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Alexia</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * JDOM 解析XML文档</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JDomDemo</span> <span class="keyword">implements</span> <span class="title class_">XmlDocument</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">parserXml</span><span class="params">(String fileName)</span> &#123;</span><br><span class="line">        <span class="type">SAXBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SAXBuilder</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">Document</span> <span class="variable">document</span> <span class="operator">=</span> builder.build(fileName);</span><br><span class="line">            <span class="type">Element</span> <span class="variable">users</span> <span class="operator">=</span> document.getRootElement();</span><br><span class="line">            <span class="type">List</span> <span class="variable">userList</span> <span class="operator">=</span> users.getChildren(<span class="string">&quot;user&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; userList.size(); i++) &#123;</span><br><span class="line">                <span class="type">Element</span> <span class="variable">user</span> <span class="operator">=</span> (Element) userList.get(i);</span><br><span class="line">                <span class="type">List</span> <span class="variable">userInfo</span> <span class="operator">=</span> user.getChildren();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; userInfo.size(); j++) &#123;</span><br><span class="line">                    System.out.println(((Element) userInfo.get(j)).getName()</span><br><span class="line">                            + <span class="string">&quot;:&quot;</span> + ((Element) userInfo.get(j)).getValue());</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (JDOMException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="dom4j示例">DOM4J示例</h2>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xml;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileWriter;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.Writer;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.dom4j.Document;</span><br><span class="line"><span class="keyword">import</span> org.dom4j.DocumentException;</span><br><span class="line"><span class="keyword">import</span> org.dom4j.DocumentHelper;</span><br><span class="line"><span class="keyword">import</span> org.dom4j.Element;</span><br><span class="line"><span class="keyword">import</span> org.dom4j.io.SAXReader;</span><br><span class="line"><span class="keyword">import</span> org.dom4j.io.XMLWriter;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Alexia</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * Dom4j 解析XML文档</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Dom4jDemo</span> <span class="keyword">implements</span> <span class="title class_">XmlDocument</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">parserXml</span><span class="params">(String fileName)</span> &#123;</span><br><span class="line">        <span class="type">File</span> <span class="variable">inputXml</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(fileName);</span><br><span class="line">        <span class="type">SAXReader</span> <span class="variable">saxReader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SAXReader</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">Document</span> <span class="variable">document</span> <span class="operator">=</span> saxReader.read(inputXml);</span><br><span class="line">            <span class="type">Element</span> <span class="variable">users</span> <span class="operator">=</span> document.getRootElement();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">Iterator</span> <span class="variable">i</span> <span class="operator">=</span> users.elementIterator(); i.hasNext();) &#123;</span><br><span class="line">                <span class="type">Element</span> <span class="variable">user</span> <span class="operator">=</span> (Element) i.next();</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">Iterator</span> <span class="variable">j</span> <span class="operator">=</span> user.elementIterator(); j.hasNext();) &#123;</span><br><span class="line">                    <span class="type">Element</span> <span class="variable">node</span> <span class="operator">=</span> (Element) j.next();</span><br><span class="line">                    System.out.println(node.getName() + <span class="string">&quot;:&quot;</span> + node.getText());</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (DocumentException e) &#123;</span><br><span class="line">            System.out.println(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(167, 1, 15, 16, 18)--双指针解决ksum问题</title>
    <url>/2016/03/08/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(167,%201,%2015,%2016,%2018)--%E5%8F%8C%E6%8C%87%E9%92%88%E8%A7%A3%E5%86%B3ksum%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>ksum 问题是一类问题,
要求从给定的数字中找到k个数，使得这k个数的和等于特定值。题目不难，直观的方法的时间复杂度为
<span class="math inline">\(O(n^k)\)</span>, <span
class="math inline">\(n\)</span> 为给定的数字的个数，
关键在于时间复杂度的控制,
本文主要讲述通过双指针将这类问题的时间复杂度降为 <span
class="math inline">\(O(n^{k-1})\)</span>。</p>
<span id="more"></span>
<p>下面将以 LeetCode 上的几道题目为例讲述这类问题： <a
href="https://leetcode.com/problems/two-sum-ii-input-array-is-sorted/">167.
Two Sum II - Input array is sorted</a> <a
href="https://leetcode.com/problems/two-sum/">1. Two Sum</a> <a
href="https://leetcode.com/problems/3/leetcode.com/problems/two-sum/">15.
3Sum</a> <a href="https://leetcode.com/problems/3sum-closest/">16. 3Sum
Closest</a> <a href="https://leetcode.com/problems/4sum/">18.
4Sum</a></p>
<p>之所以从 <a
href="https://leetcode.com/problems/two-sum-ii-input-array-is-sorted/">167.
Two Sum II - Input array is sorted</a>
开始讲述,是因为解决这个题目的思路就是解决这类问题的核心思想。</p>
<p><a
href="https://leetcode.com/problems/two-sum-ii-input-array-is-sorted/">167.
Two Sum II - Input array is sorted</a> 这道题目的解决思路如下：
<strong>1）初始化双指针，left指针在最左端，right指针在最右端
2）计算left指针和right指针指向的两个数的和，如果大于目标和，右指针往左移动一步；如果小于目标和，左指针往右移动一步；如果等于目标和则返回
3) 重复 2）的操作直到两个指针相遇</strong></p>
<p><strong>上面的方法需要的前提条件是数字列表是有序的</strong>。</p>
<p>实现的python代码如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, numbers, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type numbers: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(numbers) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            tmp = numbers[left] + numbers[right]</span><br><span class="line">            <span class="keyword">if</span> tmp &gt; target:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> tmp &lt; target:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> [left+<span class="number">1</span>, right+<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>通过上面的方法的思想可以解决这一类问题。</p>
<p>对于题目 <a href="https://leetcode.com/problems/two-sum/">1. Two
Sum</a>
，因为原来的数组数无序的，因此需要对数组先排序，而且由于要求返回的是下标而不是数字，因此也需要一个
<code>HashTable</code> 来存储原来数字的下标。时间复杂度为<span
class="math inline">\((nlgn)\)</span></p>
<p>AC的python代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># O(nlgn) time, O(n) space, AC</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        inx = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(nums)):</span><br><span class="line">            inx.setdefault(nums[i], [])</span><br><span class="line">            inx[nums[i]].append(i)</span><br><span class="line">            </span><br><span class="line">        nums.sort()</span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            tmp = nums[left] + nums[right]</span><br><span class="line">            <span class="keyword">if</span> tmp &gt; target:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> tmp &lt; target:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">sorted</span>([inx[nums[left]].pop(), inx[nums[right]].pop()])</span><br></pre></td></tr></table></figure></p>
<p>对于题目 <a
href="https://leetcode.com/problems/3/leetcode.com/problems/two-sum/">15.
3Sum</a>
,也是需要先要对无序的数组进行排序，然后固定第一个数的下标，再用上面的双指针方法找到另外两个数；由于需要返回的是数字而不是下标，因此不需要一个
<code>HashTable</code> 来存储这些数字的下标。时间复杂度为<span
class="math inline">\(O(n^2+nlgn)\)</span>,也就是<span
class="math inline">\(O(n^2)\)</span>。</p>
<p>AC的python代码如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">threeSum</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        result = []</span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(nums)-<span class="number">2</span>:</span><br><span class="line">            <span class="keyword">if</span> nums[i]&gt;<span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j = i+<span class="number">1</span></span><br><span class="line">                k = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span> j &lt; k:</span><br><span class="line">                    <span class="keyword">if</span> nums[i]+nums[j]+nums[k]&gt;<span class="number">0</span>:</span><br><span class="line">                        k-=<span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> nums[i]+nums[j]+nums[k]&lt;<span class="number">0</span>:</span><br><span class="line">                        j+=<span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        tmp = [nums[i],nums[j],nums[k]]</span><br><span class="line">                        <span class="keyword">if</span> tmp <span class="keyword">not</span> <span class="keyword">in</span> result:</span><br><span class="line">                            result.append(tmp)</span><br><span class="line">                        j+=<span class="number">1</span></span><br><span class="line">                        k-=<span class="number">1</span></span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>题目 <a href="https://leetcode.com/problems/3sum-closest/">16. 3Sum
Closest</a> 与 <a
href="https://leetcode.com/problems/3/leetcode.com/problems/two-sum/">15.
3Sum</a> 思路一致，只是要找到与目标和最接近的和。时间复杂度也是 <span
class="math inline">\(O(n^2)\)</span></p>
<p>AC的python代码如下所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">threeSumClosest</span>(<span class="params">self, nums, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="built_in">min</span> = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">2</span>):</span><br><span class="line">            j = i+<span class="number">1</span></span><br><span class="line">            k = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> j&lt;k:</span><br><span class="line">                <span class="built_in">sum</span> = nums[i]+nums[j]+nums[k]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">sum</span> &gt; target:</span><br><span class="line">                    gap = <span class="built_in">abs</span>(<span class="built_in">sum</span> -target)</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">min</span> == <span class="literal">None</span> <span class="keyword">or</span> <span class="built_in">min</span> &gt; gap:</span><br><span class="line">                        <span class="built_in">min</span> = gap</span><br><span class="line">                        result = <span class="built_in">sum</span></span><br><span class="line">                    k-=<span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">sum</span> &lt; target:</span><br><span class="line">                    gap = <span class="built_in">abs</span>(target - <span class="built_in">sum</span>)</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">min</span>==<span class="literal">None</span> <span class="keyword">or</span> <span class="built_in">min</span> &gt; gap:</span><br><span class="line">                        <span class="built_in">min</span> = gap</span><br><span class="line">                        result = <span class="built_in">sum</span></span><br><span class="line">                    j+=<span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    result = <span class="built_in">sum</span></span><br><span class="line">                    <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<p>题目 <a href="https://leetcode.com/problems/4sum/">18. 4Sum</a>
的思路与上面的<a
href="https://leetcode.com/problems/3/leetcode.com/problems/two-sum/">15.
3Sum</a>，
只是一开始需要固定前两个数，然后通过双指针找到另外两个数，时间复杂度是<span
class="math inline">\(O(n^3)\)</span>。推广到 <code>ksum</code>
问题就是开始需要固定 <code>k-2</code>
两个数，然后通过双指针找到剩下的两个数。时间复杂度是<span
class="math inline">\(O(n^{k-1})\)</span></p>
<p>AC的 python 代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fourSum</span>(<span class="params">self, nums, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result =[]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        </span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">3</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,<span class="built_in">len</span>(nums)-<span class="number">2</span>):</span><br><span class="line">                m = j +<span class="number">1</span></span><br><span class="line">                n = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span> m &lt; n:</span><br><span class="line">                    <span class="built_in">sum</span> = nums[i] + nums[j] + nums[m] + nums[n]</span><br><span class="line">                    <span class="keyword">if</span>  <span class="built_in">sum</span>&gt;target:</span><br><span class="line">                        n-=<span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">sum</span>&lt;target:</span><br><span class="line">                        m+=<span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        tmp = [nums[i],nums[j],nums[m],nums[n]]</span><br><span class="line">                        <span class="keyword">if</span> tmp <span class="keyword">not</span> <span class="keyword">in</span> result:</span><br><span class="line">                            result.append(tmp)</span><br><span class="line">                        m+=<span class="number">1</span></span><br><span class="line">                        n-=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(207,210)--拓扑排序(Topological Sort)</title>
    <url>/2016/07/27/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(207,210)--%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<p>拓扑排序是有向图中一种较常用的排序方法，本文主要以LeetCode上的两道题目
<a href="https://leetcode.com/problems/course-schedule/">207. Course
Schedule</a> 和 <a
href="https://leetcode.com/problems/course-schedule-ii/">210. Course
Schedule II</a> 讲述如何拓扑排序的概念与使用方法。</p>
<span id="more"></span>
<p>LeetCode 上的两道题目是关于拓扑排序（Topological
Sort）比较经典的两道题目，大意就是有0~(n-1)的n门课程需要修，但是有部分课程需要先修了别的课程才能修，问是否能修完所有课程。从题意可知，将这些课程及依赖关系表示成一个有向图，那么当图中存在闭环时是不可能修完所有课程的，因为形成闭环的几门课程相互依赖，无法选择第一门开始修的课程。</p>
<p>因此题目就是要求<strong>判断一个有向图中是否存在闭环</strong>。</p>
<p>最直观的思路就是通过深度优先搜索以每个点为起点遍历，判断每次的遍历中是否存在闭环，若存在则无法修完，反之则可以。</p>
<p>针对<a href="https://leetcode.com/problems/course-schedule/">207.
Course Schedule</a>，利用上面的思路实现的代码如下所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canFinish</span>(<span class="params">self, numCourses, prerequisites</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type numCourses: int</span></span><br><span class="line"><span class="string">        :type prerequisites: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        course = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(numCourses)] <span class="keyword">for</span> j <span class="keyword">in</span> xrange(numCourses)]</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> prerequisites:</span><br><span class="line">            course[s[<span class="number">0</span>]][s[<span class="number">1</span>]] = <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        visited = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(numCourses)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(numCourses):</span><br><span class="line">            <span class="keyword">if</span> self.dfs(course, i, visited)==<span class="literal">False</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">self, course, num, visited</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(course[num])):</span><br><span class="line">            <span class="keyword">if</span> course[num][i] == <span class="number">1</span>:</span><br><span class="line">                visited[num] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> visited[i] == <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> self.dfs(course, i, visited) == <span class="literal">False</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    visited[num] = <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>这个方法的时间复杂度是<span
class="math inline">\(O(n^2)\)</span>,n是图中所有点的数目。在提交时会提示TLE。</p>
<p>其实解决这种问题还有更好的方法，就是下面要介绍的拓扑排序，拓扑排序实际上返回的结果是有向图中所有点依据有向边指向顺序的排列而成的点。下面是拓扑排序的两个例子，第一个是合法的拓扑排序的结果，第二个是非法的拓扑排序结果。</p>
<p><img
src="https://wulc.me/imgs/image_1aoot4m511enm1ingj7tuka1fn79.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1aoot6dd87n98il1o71u3juu6m.png" /></p>
<p>那么该如何获得一个有向图的拓扑排序的结果？</p>
<p>最直观的方法步骤如下 （1）
找到图中入度（indegree）为0的点，然后记录这个点并删除这个点的所有出度（outdegree），也就是连接了这个点的其他点的入度
（2） 检查图中是否有入度为0的点，如果有重复步骤（1）</p>
<p>重复步骤（1）-（2）直至无法找到入度为0的点，此时如果记录的点的数目与所有点的数目相同，那么说明图中不存在闭合的环，反之则存在。</p>
<p>上面这种方法虽然比较直观，但是每次找到入度为0的点的时间复杂度是<span
class="math inline">\(O(n)\)</span>,因此总的时间复杂度是<span
class="math inline">\(O(n^2)\)</span>，n为图中所有点的数目。下面介绍一种利用队列将时间复杂度降为<span
class="math inline">\(O(n+e)\)</span>,e为图中所有边的数目。</p>
<p>这种方法特殊的地方在于<strong>利用了一个队列存储当前入度为0的点，每次队首元素出列时，将队首元素出度相连的所有点的入度减去1</strong>。因此还需要一个额外的空间存储每个点出度连接的所有点。整体的数据结构如下：</p>
<p><img
src="https://wulc.me/imgs/image_1aoov0c3j1tollp313bh2nl1mhf13.png" /></p>
<p>图中的<code>In-Degree array</code>就是存储每个点的入度数的队列，而<code>Adjacency list</code>则是存储每个点通过出度连接的所有点的数据结构。</p>
<p><strong>这个算法的具体流程如下：
(1)遍历有向图中所有的边可以构造出上面提到的两个数据结构，时间复杂度为<span
class="math inline">\(O(e)\)</span>
(2)从<code>In-Degree array</code>中找所有点中入度数为0的点，构成初始队列，时间复杂度<span
class="math inline">\(O(n)\)</span>
(3)通过队首出列，调整与队首元素出度相连的所有点的入度数，并检查这些点的入度数是否为0，若是则入队列
(4)重复步骤(3)直至队列为空，此时若从队列中出列的所有点的数目为原来有向图中所有点的数目，则图中不存在闭合的环，且出列的顺序是一种可行的遍历方法</strong>。步骤(3)(4)的时间复杂度为<span
class="math inline">\(O(n+e)\)</span></p>
<p>因此这个方法的时间复杂度为<span
class="math inline">\(O(n+e)\)</span>,除了能够判断有向图中是否有闭合的环，也能够给出一种合理的遍历方法，因此能解决上面提到的<a
href="https://leetcode.com/problems/course-schedule/">207. Course
Schedule</a> 和 <a
href="https://leetcode.com/problems/course-schedule-ii/">210. Course
Schedule II</a>两个问题。</p>
<p>下面是<a href="https://leetcode.com/problems/course-schedule/">207.
Course Schedule</a> 的解决方法 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canFinish</span>(<span class="params">self, numCourses, prerequisites</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type numCourses: int</span></span><br><span class="line"><span class="string">        :type prerequisites: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        indegree = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(numCourses)] </span><br><span class="line">        connection = &#123;i:[] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(numCourses)&#125;</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> prerequisites:</span><br><span class="line">            connection[link[<span class="number">1</span>]].append(link[<span class="number">0</span>])</span><br><span class="line">            indegree[link[<span class="number">0</span>]] += <span class="number">1</span></span><br><span class="line">        zero_indegree = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(numCourses):</span><br><span class="line">            <span class="keyword">if</span> indegree[i] == <span class="number">0</span>:</span><br><span class="line">                zero_indegree.append(i)</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(zero_indegree):</span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> connection[zero_indegree[i]]:</span><br><span class="line">                indegree[node] -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span>  indegree[node] == <span class="number">0</span>:</span><br><span class="line">                    zero_indegree.append(node)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(zero_indegree) == numCourses:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure> <a
href="https://leetcode.com/problems/course-schedule-ii/">210. Course
Schedule
II</a>的解决方法跟上面一样，只需要将<code>return True</code>改为<code>return zero_indegree</code>即可。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(19)--从后往前删除链表第n个元素</title>
    <url>/2016/03/10/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(19)--%E4%BB%8E%E5%90%8E%E5%BE%80%E5%89%8D%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%AC%ACn%E4%B8%AA%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/remove-nth-node-from-end-of-list/">原题</a>如下：
&gt;Given a linked list, remove the nth node from the end of list and
return its head.</p>
<blockquote>
<p>For example,</p>
</blockquote>
<pre><code>Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.
After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5.</code></pre>
<blockquote>
<p>Note: Given n will always be valid. Try to do this in one pass.
<span id="more"></span></p>
</blockquote>
<p>题目比较容易理解，就是删除从后往前数的第n个节点。一开始想到的方法就是先找出链表元素总数num，再删除第num-n+1个元素即可.实现方法如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeNthFromEnd</span>(<span class="params">self, head, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        nextNode = head.<span class="built_in">next</span></span><br><span class="line">        num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> nextNode == <span class="literal">None</span>:</span><br><span class="line">            num +=<span class="number">1</span></span><br><span class="line">            nextNode = nextNode.<span class="built_in">next</span></span><br><span class="line">        </span><br><span class="line">        delete = num-n+<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> delete == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> head.<span class="built_in">next</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            currNode = head</span><br><span class="line">            i = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> i&lt;delete-<span class="number">1</span>:</span><br><span class="line">                currNode = currNode.<span class="built_in">next</span></span><br><span class="line">                i+=<span class="number">1</span>    </span><br><span class="line">            currNode.<span class="built_in">next</span> = currNode.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure></p>
<p>这种方法虽然能AC，但是题目提示了<code>Try to do this in one pass</code>,也就是这道题目存在<strong>只需遍历一遍</strong>的解法。在网上查找后发现可以先让一个指针p1从head向后移动n个node，然后另外一个指针p2此时从head出发和p1一起移动，当p1移动到最后一个节点时，p2后面的一个元素即为需要删除的元素。实现的代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeNthFromEnd</span>(<span class="params">self, head, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        p1=head</span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i&lt;=n:</span><br><span class="line">            p1 = p1.<span class="built_in">next</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        p2 = head</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> p1.<span class="built_in">next</span>==<span class="literal">None</span>:</span><br><span class="line">            p1 = p1.<span class="built_in">next</span></span><br><span class="line">            p2 = p2.<span class="built_in">next</span></span><br><span class="line">        p2.<span class="built_in">next</span> =p2.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure></p>
<p>但是在提交时出错，排查后发现上述代码<strong>删除的node刚好是head时会出错</strong>，因为是从1开始往后n步，当删除的node是head是，n是所有节点的数目，而此时会导致p1为None，然后p1.next自然会报错。</p>
<p>解决方法是增加一个无意义的node指向head，从这个node开始遍历即可。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeNthFromEnd</span>(<span class="params">self, head, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        dummy=ListNode(<span class="number">0</span>) </span><br><span class="line">        dummy.<span class="built_in">next</span>=head</span><br><span class="line">        p1=p2=dummy</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): </span><br><span class="line">            p1=p1.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">while</span> p1.<span class="built_in">next</span>:</span><br><span class="line">            p1=p1.<span class="built_in">next</span></span><br><span class="line">            p2=p2.<span class="built_in">next</span></span><br><span class="line">        p2.<span class="built_in">next</span>=p2.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></p>
<p>除了上面的解决方法，一开始还想过通过将链表反转再删除第n个node即可，但是题目意思是删除这个node不能改变其他node原来的排序。虽然不符合题意，但是这里一并附上代码记录链表反转的一种方法：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeNthFromEnd</span>(<span class="params">self, head, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        preNode  = head</span><br><span class="line">        nextNode = head.<span class="built_in">next</span></span><br><span class="line">        tmp = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> nextNode == <span class="literal">None</span>:</span><br><span class="line">            preNode.<span class="built_in">next</span> = tmp</span><br><span class="line">            tmp = preNode</span><br><span class="line">            preNode = nextNode</span><br><span class="line">            nextNode = nextNode.<span class="built_in">next</span></span><br><span class="line">        preNode.<span class="built_in">next</span> = tmp</span><br><span class="line">        head = preNode</span><br><span class="line">        <span class="keyword">if</span> n==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> head.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">else</span>:    </span><br><span class="line">            i = <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> i &lt; n-<span class="number">1</span>:</span><br><span class="line">                nextNode = nextNode.<span class="built_in">next</span></span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            nextNode.<span class="built_in">next</span> = nextNode.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(22)--生成所有合法的嵌套括号</title>
    <url>/2016/03/29/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(22)--%E7%94%9F%E6%88%90%E6%89%80%E6%9C%89%E5%90%88%E6%B3%95%E7%9A%84%E5%B5%8C%E5%A5%97%E6%8B%AC%E5%8F%B7/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/generate-parentheses/">原题</a>如下：
&gt;Given n pairs of parentheses, write a function to generate all
combinations of well-formed parentheses. <span id="more"></span> &gt;For example,
given n = 3, a solution set is: "((()))", "(()())", "(())()", "()(())",
"()()()"</p>
<!--more-->
<p>题目要求生成给定数量的所有合法嵌套括号，最直观的想法是通过穷举得到所有的组合结果，再判断每个是否合法，但是这样的时间复杂度太大，会导致TLE。</p>
<p>既然上面的方法会导致TLE,
那么能不能在构造的过程中判断目前所构造的嵌套括号是否合法？</p>
<p>答案是可以的，只需要遵循以下的两条规则即可:
<strong>1.只要"("的数量没有超过n，都可以插入"("。
2.而可以插入")"的前提则是当前的"("数量必须要多余当前的")"数量。</strong></p>
<p>通过回溯法能够实现这个判断并构造出所有合法的嵌套括号，实现代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generateParenthesis</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        res = []</span><br><span class="line">        self.helper(n,n,<span class="string">&#x27;&#x27;</span>,res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span>  <span class="title function_">helper</span>(<span class="params">self,left,right,item,res</span>):</span><br><span class="line">        <span class="keyword">if</span> left==<span class="number">0</span> <span class="keyword">and</span> right==<span class="number">0</span>:</span><br><span class="line">            res.append(item)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> left&gt;<span class="number">0</span>:</span><br><span class="line">            self.helper(left-<span class="number">1</span>,right,item+<span class="string">&#x27;(&#x27;</span>,res)</span><br><span class="line">        <span class="keyword">if</span> right&gt;left:</span><br><span class="line">            self.helper(left,right-<span class="number">1</span>,item+<span class="string">&#x27;)&#x27;</span>,res)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(402,316,321)--删除字符串k个字符使剩余字符串取最值</title>
    <url>/2016/09/25/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(402,316,321)--%E5%88%A0%E9%99%A4%E5%AD%97%E7%AC%A6%E4%B8%B2k%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%BD%BF%E5%89%A9%E4%BD%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8F%96%E6%9C%80%E5%80%BC/</url>
    <content><![CDATA[<p>本文主要讲述如何解决这一类问题：<strong>给定一个含有数字或英文字母的字符串，从中删除k个字符，使得剩下的字符取得最小值或最大值</strong>。数字的大小的比较容易理解，而字母的大小则是按照其ASCII码来排列，如'abc'&gt;'abd'。</p>
<span id="more"></span>
<p>下面以 LeetCode 上的几道题目为例进行讲解： <a
href="https://leetcode.com/problems/remove-k-digits/">402. Remove K
Digits</a> <a
href="https://leetcode.com/problems/remove-duplicate-letters/">316.
Remove Duplicate Letters</a> <a
href="https://leetcode.com/problems/create-maximum-number/">321. Create
Maximum Number</a></p>
<p>解决这类题目的关键点是<strong>借助栈这种数据结构，遍历给出的字符串，将当前元素与栈顶元素比较大小，从而决定是否要将当前元素出栈，最后栈内剩余元素就是所需结果。</strong>这只是大致的过程，具体的步骤需要根据题目的具体要求。下面以上面的题目为例讲解</p>
<p><a href="https://leetcode.com/problems/remove-k-digits/">402. Remove
K Digits</a> 这个题目要求去掉给定字符串（全是数字）中的 k
个字符，使得剩余的字符串表示的数字最小。根据我们上面说到的大致流程，这道题目的解决步骤如下：</p>
<p>1.创建一个栈，以及记录当前已经删除的字符数量的计数器
2.对于字符串中的每个字符，记为当前字符，先将其与栈顶元素比较（假如栈不为空），若当前字符小于栈顶元素，则将栈顶元素出栈，将计数器加一，重复该操作直到<strong>栈为空</strong>或<strong>栈顶元素小于当前元素</strong>或<strong>计数器等于k</strong>，然后将当前元素入栈</p>
<p>具体的 python 代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeKdigits</span>(<span class="params">self, num, k</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type num: str</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        stack = []</span><br><span class="line">        remain = <span class="built_in">len</span>(num) - k</span><br><span class="line">        <span class="keyword">for</span> dig <span class="keyword">in</span> num:</span><br><span class="line">            <span class="keyword">while</span> k <span class="keyword">and</span> stack <span class="keyword">and</span> stack[-<span class="number">1</span>] &gt; dig:</span><br><span class="line">                stack.pop()</span><br><span class="line">                k -= <span class="number">1</span></span><br><span class="line">            stack.append(dig)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(stack[:remain]).lstrip(<span class="string">&#x27;0&#x27;</span>) <span class="keyword">or</span> <span class="string">&#x27;0&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>最后<code>return</code>语句之所以要选取前<code>len(num) - k</code>个字符是因为
result
中可能会有多余这个数目的字符，如对于从小到大排列的字符串就会出现这种情况，另外还需要处理掉前缀0以及当结果为空的时候返回
'0'</p>
<p><a
href="https://leetcode.com/problems/remove-duplicate-letters/">316.
Remove Duplicate Letters</a> 的要求跟 <a
href="https://leetcode.com/problems/remove-k-digits/">402. Remove K
Digits</a>
类似，只是这次要求删除的是字母，而且<strong>每个字符要求出现一次且只能出现一次</strong>。</p>
<p>解决的思路跟上面的一样，只是因为要求每个字符出现且只出现一次，在入栈和出栈的时候需要特殊的限制条件。具体步骤入下</p>
<p>1.创建一个栈，记录每个字符在字符串中出现的次数的table
2.对于字符串中的每个字符，先判断其是否已在栈内，若已在栈内，将table中对应该字符的计数减去1，然后跳到字符串的下一字符；若不在栈内，<strong>栈顶元素大于当前字符且table内剩余的栈顶元素的个数大于1时，将栈顶元素出栈</strong>，重复该操作直到<strong>栈为空</strong>或<strong>栈顶元素小于当前元素</strong>，然后将当前字符入栈</p>
<p>实现的 python 代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeDuplicateLetters</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result, stored, count = [], <span class="built_in">set</span>(), &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> s:</span><br><span class="line">             count.setdefault(char, <span class="number">0</span>)</span><br><span class="line">             count[char] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> char <span class="keyword">in</span> stored:</span><br><span class="line">                count[char] -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">while</span> result <span class="keyword">and</span> result[-<span class="number">1</span>] &gt; char <span class="keyword">and</span> count[result[-<span class="number">1</span>]] &gt; <span class="number">1</span>:</span><br><span class="line">                    count[result[-<span class="number">1</span>]] -= <span class="number">1</span></span><br><span class="line">                    stored.remove(result.pop())</span><br><span class="line">                stored.add(char)</span><br><span class="line">                result.append(char)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(result)</span><br></pre></td></tr></table></figure></p>
<p><a href="https://leetcode.com/problems/create-maximum-number/">321.
Create Maximum Number</a>
题目要求与上面两题相比不是相似性不高，但是也是利用这种思想的，题目要求从两个数组
<code>nums1</code> 和 <code>nums2</code>
中共选出k个数字，从而使得这k个数字组成的数最大。</p>
<p>解决方法就是先从 <code>nums1</code> 中选出 i 个数（0 &lt;= i &lt;=
k）使得这i个数组成的数字最大，然后从 <code>nums2</code> 中选出 k-i
个数，同样使得这 k-i
个数组成的数字最大，最后将从两个数组中抽出的最大数字合并起来。</p>
<p>实现的代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxNumber</span>(<span class="params">self, nums1, nums2, k</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums1: List[int]</span></span><br><span class="line"><span class="string">        :type nums2: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(self.merge(self.single_max(nums1, i), self.single_max(nums2, k-i)) <span class="keyword">for</span> i <span class="keyword">in</span> xrange(k+<span class="number">1</span>) <span class="keyword">if</span> i &lt;= <span class="built_in">len</span>(nums1) <span class="keyword">and</span> (k-i) &lt;= <span class="built_in">len</span>(nums2))</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">single_max</span>(<span class="params">self, nums, k</span>):</span><br><span class="line">        drop = <span class="built_in">len</span>(nums) - k</span><br><span class="line">        stack = []</span><br><span class="line">        <span class="keyword">for</span> digit <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">while</span> drop <span class="keyword">and</span> stack <span class="keyword">and</span> stack[-<span class="number">1</span>] &lt; digit:</span><br><span class="line">                stack.pop()</span><br><span class="line">                drop -= <span class="number">1</span></span><br><span class="line">            stack.append(digit)</span><br><span class="line">        <span class="keyword">return</span> stack[:k]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">merge</span>(<span class="params">self, nums1, nums2</span>):</span><br><span class="line">        <span class="keyword">return</span> [<span class="built_in">max</span>(nums1,nums2).pop(<span class="number">0</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> xrange(<span class="built_in">len</span>(nums1)+<span class="built_in">len</span>(nums2))]</span><br></pre></td></tr></table></figure></p>
<p>上面的代码中 <code>max(num1, num2)</code>中的 <code>nums1</code> 和
<code>nums2</code>是两个数组，比较的时候回比较两个数组的第一个元素，然后返回第一个元素较大的数组，若第一个元素相等，则比较第二个元素，依此类推；pop(0)则是删除并返回下标为0的元素，也就是第一个元素。通过这些语法可以简化代码</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(684,685,721)-并查集介绍及应用</title>
    <url>/2017/10/12/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(684,685,721)-%E5%B9%B6%E6%9F%A5%E9%9B%86%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<p>本文主要以LeetCode上的几道题目： <a
href="https://leetcode.com/problems/redundant-connection/description/">684.
Redundant Connection</a> 、 <a
href="https://leetcode.com/problems/redundant-connection-ii/description/">685.
Redundant Connection II</a> 和 <a
href="https://leetcode.com/problems/accounts-merge/description/">721.
Accounts Merge</a> 为例讲解并查集（<a
href="https://en.wikipedia.org/wiki/Disjoint-set_data_structure">merge–find
set</a>）这种数据结构的应用。</p>
<span id="more"></span>
<p>说到并查集，不得不提的是最小生成树，因为并查集的最经典的应用地方便是解决最小生成树的
Kruskal 算法。</p>
<h2 id="最小生成树">最小生成树</h2>
<p>有两个经典的算法可用来解决 <a
href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91">最小生成树</a>
问题： <a
href="https://en.wikipedia.org/wiki/Kruskal%27s_algorithm">Kruskal
算法</a> 和 <a
href="https://en.wikipedia.org/wiki/Prim%27s_algorithm">Prim
算法</a>。其中 Kruskal
算法中便应用了并查集这种数据结构，该算法的步骤如下</p>
<ol type="1">
<li>新建图G，G中拥有原图中相同的节点，但没有边</li>
<li>将原图中所有的边按权值从小到大排序</li>
<li>从权值最小的边开始，如果这条边连接的两个节点于图G中不在同一个连通分量中，则添加这条边到图G中</li>
<li>重复3，直至图G中所有的节点都在同一个连通分量中</li>
</ol>
<p>该算法的动图显示如下(摘自维基百科)</p>
<figure>
<img src="https://wulc.me/imgs/KruskalDemo.gif"
alt="KruskalDemo.gif-415.5kB" />
<figcaption aria-hidden="true">KruskalDemo.gif-415.5kB</figcaption>
</figure>
<p>Kruskal 算法很简单，实际上 Kruskal
算法是一种贪心算法，并且已被证明最终能够收敛到最好结果。而在实现 Kruskal
算法时，则需要用到并查集这种数据结构来减小算法的时间复杂度。下面将详细介绍这种数据结构。</p>
<p>在介绍并查集前，顺便介绍一下 Prime 算法，Prime
算法也是一种贪心算法，而且也被证明了最终能够得到最好的结果，只是两者的侧重点不同，
Kruskal 算法维护的是一个边的集合，而 Prime
算法则同时维护了一个边的集合和一个点的集合，Prim 算法的过程如下</p>
<ol type="1">
<li>输入：一个加权连通图，其中顶点集合为V，边集合为E；</li>
<li>初始化：Vnew = {x}，其中x为集合V中的任一节点（起始点），Enew =
{}；</li>
<li>重复下列操作，直到Vnew = V：
<ol type="1">
<li>在集合E中选取权值最小的边（u, v），其中<strong>u为集合 Vnew
中的元素</strong>，而v则是V中没有加入Vnew的顶点（如果存在有多条满足前述条件即具有相同权值的边，则可任意选取其中之一）；</li>
<li>将v加入集合Vnew中，将（u, v）加入集合Enew中；</li>
</ol></li>
<li>输出：使用集合Vnew和Enew来描述所得到的最小生成树。</li>
</ol>
<p>其动图描述如下(摘自维基百科)</p>
<figure>
<img src="https://wulc.me/imgs/PrimAlgDemo.gif"
alt="PrimAlgDemo.gif-51.1kB" />
<figcaption aria-hidden="true">PrimAlgDemo.gif-51.1kB</figcaption>
</figure>
<h2 id="并查集">并查集</h2>
<p>在上面描述的 Kruskal 算法中，第三步是</p>
<blockquote>
<ol start="3" type="1">
<li>从权值最小的边开始，如果这条边连接的两个节点于图G中不在同一个连通分量中，则添加这条边到图G中</li>
</ol>
</blockquote>
<p><strong>而判断这条边连接的两个节点是否在同一个连通分量中，
实际上就是判断加入了这条边后，是否会与原来已经添加的边形成环路</strong>，并查集正是高效的实现了这个功能。</p>
<p>并查集主要有三种操作：MakeSet，Find 和 Union。</p>
<ul>
<li><strong>MakeSet</strong> 是初始化操作，即为每个 node
创建一个连通分量，且这个 node
为这个连通分量的代表，这里连通分量的代表指的是当连通分量中有多个点时，需要从这些点中选出一个点来代表这个连通分量，而这个点也往往被称为这个连通分量的
parent（意思即指这个点是其他点的 parent）</li>
<li><strong>Find</strong> 是指找到这个点所属的连通分量的 parent</li>
<li><strong>Union</strong>
是指将两个连通分量合并成一个连通分量，并选出代表这个连通分量的新的
parent</li>
</ul>
<p><strong>那么怎么通过上面这几种操作判断某条边是否会与原来的边形成环路呢？</strong>具体操作如下</p>
<ol type="1">
<li>给定一条边，为这条边的两个顶点执行 Find 操作，假如两个顶点的 parent
一样，那么说明这两个点已经在同一个连通分量中，再添加就会导致闭环</li>
<li>当两个点的 parent 不同，即两个点在不同的连通分量时，需要通过 Union
操作将这两个连通分量连起来</li>
<li>重复 1、2 步操作直到所有边遍历完</li>
</ol>
<p>在具体实现，往往并不需要集合这种数据结构，而是仅仅通过数组即可，比如说有
n 个点，那么就创建一个长度为 n
的数组，每个下标代表一个点，而下标对应的值则代表这个点的 parent。</p>
<p>并查集还有两个重要的概念 path compression 和 union by
rank，目的均是降低时间复杂度，下面会详细说明。</p>
<p>现在通过具体的题目来讲解上面提到若干概念</p>
<h2 id="redundant-connection">Redundant Connection</h2>
<p><a
href="https://leetcode.com/problems/redundant-connection/description/">684.
Redundant Connection</a>
这道题目实际上就是要找到一个无向图中形成环路的最后那条边(输入保证了所有边会形成回路)。首先，看一种最简单的解决方法</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findRedundantConnection</span>(<span class="params">self, edges</span>):</span><br><span class="line">        parents = <span class="built_in">range</span>(<span class="number">1001</span>)</span><br><span class="line">        <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">            v1, v2 = edge[<span class="number">0</span>], edge[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> parents[v1] == parents[v2]:</span><br><span class="line">                <span class="keyword">return</span> edge</span><br><span class="line">            tmp = parents[v2]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(parents)):</span><br><span class="line">                <span class="keyword">if</span> parents[i] == tmp:</span><br><span class="line">                    parents[i] = parents[v1]</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p>这种方法中每次 Find 的时间复杂度为 <span
class="math inline">\(O(1)\)</span>（即 parents[v1] 操作）, 每次 Union
则需要遍历所有的点，时间复杂度是 <span
class="math inline">\(O(n)\)</span>，总体时间复杂度是 <span
class="math inline">\(O(mn)\)</span>, <span
class="math inline">\(m\)</span> 为边的数目，而 <span
class="math inline">\(n\)</span> 为点的数目。</p>
<p>而我们也可以改变思路，就是进行 Union
操作时不再将某个连通分量中所有点的 parent 改为另一个连通分量的
parent，而是只改变那个连通分量的代表；这样进行 Find
操作的时候只需要递归的查找即可，下面为这种思路对应的代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFindSet</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.parents = <span class="built_in">range</span>(<span class="number">1001</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, val</span>):</span><br><span class="line">        <span class="keyword">if</span> self.parents[val] != val:</span><br><span class="line">            <span class="keyword">return</span> self.find(self.parents[val])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.parents[val]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, v1, v2</span>):</span><br><span class="line">        p1, p2 = self.find(v1), self.find(v2)</span><br><span class="line">        <span class="keyword">if</span> p1 == p2:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.parents[p1] = p2</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findRedundantConnection</span>(<span class="params">self, edges</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type edges: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ufs = UnionFindSet()</span><br><span class="line">        <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">            <span class="keyword">if</span> ufs.union(edge[<span class="number">0</span>], edge[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">return</span> edge</span><br></pre></td></tr></table></figure>
<p>这个方法每次 Union 的时间复杂度为 <span
class="math inline">\(O(1)\)</span>, 但是每次 Find 的时间复杂度是 <span
class="math inline">\(O(n)\)</span>，所以总体时间复杂度还是 <span
class="math inline">\(O(mn)\)</span>,
那么有没有一种改进总体时间复杂度的方法呢？</p>
<p>答案就是上面提到的 path compression 和 union by rank。</p>
<p>path compression 指的是在上面的递归的 Find
操作中，将最终得到的结果赋给递归过程中经过的所有点，从而降低连通分量的高度，实际上<strong>可以将一个连通分量当做一颗树，树的每个节点都连着其
parent</strong>，而 path compression
则相当于将搜寻路径中的所有点直接连到最终的那个 parent
上，因此能够降低树的高度。</p>
<p>降低树的高度有什么好处？那就是能够降低查找的时间复杂度，从 <span
class="math inline">\(O(n)\)</span> 降为了 <span
class="math inline">\(O(logn)\)</span>,
因为原来的递归搜索实际上是在一颗每个节点只有一个子节点的树上进行搜索，树的高度即为点的个数，而通过
path compression 则能够有效降低树的高度。</p>
<p>另外一个问题就是进行 Union
操作时，需要将高度低的树连接到高度较高的树上，目的是为了减少 Union
后的整棵树的高度，这就是 union by rank, rank 代表的就是树的高度。</p>
<p>采用 path compression 和 union by rank 后，Find 的时间复杂度变为了
<span class="math inline">\(O(logn)\)</span>, Union 的时间复杂度为 <span
class="math inline">\(O(1)\)</span>, 因此总体时间复杂度是 <span
class="math inline">\(O(mlogn)\)</span>, <span
class="math inline">\(m\)</span> 为边的数目，而 <span
class="math inline">\(n\)</span> 为点的数目。改进后的代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFindSet</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.parents = <span class="built_in">range</span>(<span class="number">1001</span>)</span><br><span class="line">        self.rank = [<span class="number">0</span>] * <span class="number">1001</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, val</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;find with path compression&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.parents[val] != val:</span><br><span class="line">            self.parents[val] = self.find(self.parents[val])</span><br><span class="line">        <span class="keyword">return</span> self.parents[val]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, v1, v2</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;union by rank, check whether union two vertics will lead to a cycle&quot;&quot;&quot;</span></span><br><span class="line">        p1, p2 = self.find(v1), self.find(v2)</span><br><span class="line">        <span class="keyword">if</span> p1 == p2:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> self.rank[p1] &gt; self.rank[p2]:</span><br><span class="line">            self.parents[p2] = p1</span><br><span class="line">        <span class="keyword">elif</span> self.rank[p1] &lt; self.rank[p2]:</span><br><span class="line">            self.parents[p1] = p2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.rank[p2] += <span class="number">1</span></span><br><span class="line">            self.parents[p1] = p2</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findRedundantConnection</span>(<span class="params">self, edges</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type edges: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ufs = UnionFindSet()</span><br><span class="line">        <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">            <span class="keyword">if</span> ufs.union(edge[<span class="number">0</span>], edge[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">return</span> edge</span><br></pre></td></tr></table></figure>
<h2 id="redundant-connection-ii">Redundant Connection II</h2>
<p><a
href="https://leetcode.com/problems/redundant-connection-ii/description/">685.
Redundant Connection II</a>
从前面的无向图升级到了有向图，对应的要求从原来的仅要求不形成环路升级到在不形成环路的基础上，拓扑必须要是一棵合法树，也就是每个点只能有一个父节点，例如
<code>[[2,1],[3,1]]</code> 这两条边虽然没有形成环路，但是 1
有两个父亲节点（2和3），因此不是一棵合法的树。</p>
<p>由于题目说明了输入只有一条不合法的边，因此<strong>首先可以统计一下这些边中是否存在某个点有两个父亲节点，假如有，则需要移除的边必定为连着这个点的两条边中的一条</strong>，通过上面
Union-find
的方法，可以判断出假如移除掉连着这个点的第一条边时，是否会形成回路。如果会，则说明需要移除第二条边，否则直接移除第一条边。</p>
<p>如果统计的结果中没有点含有两个父亲节点，那么可以直接通过第一题的方法直接找到形成回路的最后那条边。AC的代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFindSet</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.parents = <span class="built_in">range</span>(<span class="number">1001</span>)</span><br><span class="line">        self.rank = [<span class="number">0</span>] * <span class="number">1001</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, val</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;find with path compression&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.parents[val] != val:</span><br><span class="line">            self.parents[val] = self.find(self.parents[val])</span><br><span class="line">        <span class="keyword">return</span> self.parents[val]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, v1, v2</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;union by rank, check whether union two vertics will lead to a cycle&quot;&quot;&quot;</span></span><br><span class="line">        p1, p2 = self.find(v1), self.find(v2)</span><br><span class="line">        <span class="keyword">if</span> p1 == p2:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> self.rank[p1] &gt; self.rank[p2]:</span><br><span class="line">            self.parents[p2] = p1</span><br><span class="line">        <span class="keyword">elif</span> self.rank[p1] &lt; self.rank[p2]:</span><br><span class="line">            self.parents[p1] = p2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.rank[p2] += <span class="number">1</span></span><br><span class="line">            self.parents[p1] = p2</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findRedundantDirectedConnection</span>(<span class="params">self, edges</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type edges: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        redundant_edges = <span class="literal">None</span></span><br><span class="line">        count = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> edges:</span><br><span class="line">            <span class="keyword">if</span> e[<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> count:</span><br><span class="line">                count[e[<span class="number">1</span>]] = []</span><br><span class="line">            count[e[<span class="number">1</span>]].append(e)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(count[e[<span class="number">1</span>]]) == <span class="number">2</span>:</span><br><span class="line">                redundant_edges = count[e[<span class="number">1</span>]]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> redundant_edges:</span><br><span class="line">            ufs = UnionFindSet()</span><br><span class="line">            <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">                <span class="keyword">if</span> edge == redundant_edges[<span class="number">1</span>]:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> ufs.union(edge[<span class="number">0</span>], edge[<span class="number">1</span>]):</span><br><span class="line">                    <span class="keyword">return</span> redundant_edges[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">return</span> redundant_edges[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            ufs = UnionFindSet()</span><br><span class="line">            <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">                <span class="keyword">if</span> ufs.union(edge[<span class="number">0</span>], edge[<span class="number">1</span>]):</span><br><span class="line">                    <span class="keyword">return</span> edge</span><br></pre></td></tr></table></figure>
<h2 id="accounts-merge">Accounts Merge</h2>
<p>这道题目虽然也用到了并查集的数据结构，但是与前面的两道题目又有点不同，主要体现在两个方面</p>
<ol type="1">
<li>节点不再以数字标识，因此标识 parents 的数据结构要从 array 变为
map</li>
<li>不需要判断是否形成闭环，而要返回最终各个集合内的元素；在这个操作中需要注意的是不能直接利用存储各个节点的
parent 的 map 直接为每个节点找到其 parent， 因为并非各个节点都进行了
path compression。对应有两种方法 (1)借助 find 方法找到各个节点的parent
(2) 对存储各个节点的 parent 的 map 再进行一次 path compression,
然后直接在 map 中找到各个节点的 parent 对应的方法入下</li>
</ol>
<p>方法(1)</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accountsMerge</span>(<span class="params">self, accounts</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type accounts: List[List[str]]</span></span><br><span class="line"><span class="string">        :rtype: List[List[str]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        owners, parents = &#123;&#125;, &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> accounts:</span><br><span class="line">            owners[account[<span class="number">1</span>]] = account[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="built_in">len</span>(account)):</span><br><span class="line">                parents[account[i]] = account[i]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> accounts:</span><br><span class="line">            p = self.find(account[<span class="number">1</span>], parents)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="built_in">len</span>(account)):</span><br><span class="line">                parents[self.find(account[i], parents)] = p</span><br><span class="line">        </span><br><span class="line">        unions = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> accounts:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="built_in">len</span>(account)):</span><br><span class="line">                p = self.find(account[i], parents)</span><br><span class="line">                unions.setdefault(p, <span class="built_in">set</span>())</span><br><span class="line">                unions[p].add(account[i])</span><br><span class="line">        </span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> unions.items():</span><br><span class="line">            result.append([owners[k]] + <span class="built_in">sorted</span>(v))</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, email, parents</span>):</span><br><span class="line">        <span class="keyword">if</span> parents[email] !=  email:</span><br><span class="line">            parents[email] = self.find(parents[email], parents)</span><br><span class="line">        <span class="keyword">return</span> parents[email]</span><br></pre></td></tr></table></figure>
<p>方法(2)</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accountsMerge</span>(<span class="params">self, accounts</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type accounts: List[List[str]]</span></span><br><span class="line"><span class="string">        :rtype: List[List[str]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        owners, parents = &#123;&#125;, &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> accounts:</span><br><span class="line">            owners[account[<span class="number">1</span>]] = account[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="built_in">len</span>(account)):</span><br><span class="line">                parents[account[i]] = account[i]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> account <span class="keyword">in</span> accounts:</span><br><span class="line">            p = self.find(account[<span class="number">1</span>], parents)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>, <span class="built_in">len</span>(account)):</span><br><span class="line">                parents[self.find(account[i], parents)] = p</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># not all paths are compressed currently</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> parents.items():</span><br><span class="line">            <span class="keyword">if</span> k!=v:</span><br><span class="line">                parents[k] = self.find(parents[v], parents)</span><br><span class="line">            </span><br><span class="line">        unions = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> parents.items():</span><br><span class="line">            <span class="keyword">if</span> v  <span class="keyword">not</span> <span class="keyword">in</span> unions:</span><br><span class="line">                unions[v] = <span class="built_in">set</span>()</span><br><span class="line">            unions[v].add(k)</span><br><span class="line">        </span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> unions.items():</span><br><span class="line">            result.append([owners[k]] + <span class="built_in">sorted</span>(v))</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, email, parents</span>):</span><br><span class="line">        <span class="keyword">if</span> parents[email] !=  email:</span><br><span class="line">            parents[email] = self.find(parents[email], parents)</span><br><span class="line">        <span class="keyword">return</span> parents[email]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>树</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(51)--回溯法解决N皇后问题</title>
    <url>/2016/05/16/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(51)--%E5%9B%9E%E6%BA%AF%E6%B3%95%E8%A7%A3%E5%86%B3N%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p><a href="https://leetcode.com/problems/n-queens/">原题</a>如下：
&gt;The n-queens puzzle is the problem of placing n queens on an n×n
chessboard such that no two queens attack each other. <span id="more"></span> <img
src="https://wulc.me/imgs/8-queens.png" /></p>
<blockquote>
<p>Given an integer n, return all distinct solutions to the n-queens
puzzle.</p>
</blockquote>
<blockquote>
<p>Each solution contains a distinct board configuration of the
n-queens' placement, where 'Q' and '.' both indicate a queen and an
empty space respectively.</p>
</blockquote>
<blockquote>
<p>For example, There exist two distinct solutions to the 4-queens
puzzle: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line"> [&quot;.Q..&quot;,  // Solution 1</span><br><span class="line">  &quot;...Q&quot;,</span><br><span class="line">  &quot;Q...&quot;,</span><br><span class="line">  &quot;..Q.&quot;],</span><br><span class="line"></span><br><span class="line"> [&quot;..Q.&quot;,  // Solution 2</span><br><span class="line">  &quot;Q...&quot;,</span><br><span class="line">  &quot;...Q&quot;,</span><br><span class="line">  &quot;.Q..&quot;]</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>经典的n皇后问题，通过回溯法解决。</p>
<p>关键的地方有以下几点：
1）由于题目本身的特点，每一行只能放置一个皇后，因此<strong>每行只要找到第一个合适的位置</strong>便可跳到下一行找下一个皇后的合适位置。
2）由于遍历的顺序是从坐到又从上到下的，因此判断当前位置能否放置皇后时只需要判断当前位置上方的列、左上斜边、右上斜边是否有皇后即可。</p>
<p>实现的代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">solveNQueens</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[str]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        solutions = []</span><br><span class="line">        board = [[<span class="string">&#x27;.&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment">#生成n*n的原始矩阵</span></span><br><span class="line">        self.helper(board, solutions,<span class="number">0</span> )</span><br><span class="line">        <span class="keyword">return</span> solutions</span><br><span class="line">        </span><br><span class="line">                </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self,board,solutions, row</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(board)</span><br><span class="line">        <span class="keyword">if</span> row==n:</span><br><span class="line">            tmp=[]          </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> board:</span><br><span class="line">                tmp.append(reduce(<span class="keyword">lambda</span> x,y:x+y,i)) <span class="comment"># reduce函数的作用是将[&#x27;Q&#x27;,&#x27;.&#x27;,&#x27;.&#x27;,&#x27;.&#x27;]转为&#x27;Q...&#x27;</span></span><br><span class="line">            solutions.append(tmp)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> self.is_valid(board,row,i):</span><br><span class="line">                board[row][i] = <span class="string">&#x27;Q&#x27;</span></span><br><span class="line">                self.helper(board,solutions,row+<span class="number">1</span>)</span><br><span class="line">                board[row][i] = <span class="string">&#x27;.&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_valid</span>(<span class="params">self,board,i,j</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(board)</span><br><span class="line">        <span class="comment"># check column</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> xrange(n):</span><br><span class="line">            <span class="keyword">if</span> board[k][j] == <span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># check diagonal，只需要检查上面的两条边</span></span><br><span class="line">        ri = i</span><br><span class="line">        rj = j</span><br><span class="line">        <span class="keyword">while</span> <span class="number">0</span>&lt;=i&lt;=n-<span class="number">1</span> <span class="keyword">and</span> <span class="number">0</span>&lt;=j&lt;=n-<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> board[i][j]==<span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            i-=<span class="number">1</span></span><br><span class="line">            j-=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        i = ri</span><br><span class="line">        j = rj</span><br><span class="line">        <span class="keyword">while</span> <span class="number">0</span>&lt;=i&lt;=n-<span class="number">1</span> <span class="keyword">and</span> <span class="number">0</span>&lt;=j&lt;=n-<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">if</span> board[i][j]==<span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            i-=<span class="number">1</span></span><br><span class="line">            j+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
上面的代码虽然结果正确，但是判断当前位置能否放置皇后的方法效率较低，判断的一次的平均时间复杂度为O(n)，n为棋盘的边的大小，下面主要介绍一种判断当前位置能否放置皇后的时间复杂度为O(1)的方法。</p>
<p>通过观察可发现，在<strong>同一条左斜边上的每个点的行值加上列值的结果相等，而在同一条右斜边上的每个点的行值减去列值的结果相等</strong>。如下图所示就是左斜线每个点的行值加上列值的情况：</p>
<p><img src="https://wulc.me/imgs/Nqueen.png" /></p>
<p>右斜线每个点的行值减去列值的情况同理。</p>
<p>由于这些结果大小是连续的，因此我们可以使用数组的下标代表某一斜边，用该下标的对应的数组值（0或1）表示该斜边上是否有皇后。设棋盘的大小为n*n。则左斜边的范围为[0,2n-2],长度为2n+1；右斜边的范围为[-n+1,n-1],由于数组的下标不能为负，所以每个下标加上n-1，将范围变为[0,2n-2],长度同样为2n-1。</p>
<p>实现的代码如下所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">solveNQueens</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[str]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        solutions = []</span><br><span class="line">        board = [[<span class="string">&#x27;.&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment">#生成n*n的原始矩阵</span></span><br><span class="line">        col = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        left_dia =  [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>*n-<span class="number">1</span>)]</span><br><span class="line">        right_dia = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>*n-<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        self.helper(board, solutions,<span class="number">0</span>, col,left_dia,right_dia)</span><br><span class="line">        <span class="keyword">return</span> solutions</span><br><span class="line">        </span><br><span class="line">                </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self,board,solutions,row,col,left_dia,right_dia</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(board)</span><br><span class="line">        <span class="keyword">if</span> row==n:</span><br><span class="line">            tmp=[]          </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> board:</span><br><span class="line">                tmp.append(reduce(<span class="keyword">lambda</span> x,y:x+y,i)) <span class="comment"># reduce函数的作用是将[&#x27;Q&#x27;,&#x27;.&#x27;,&#x27;.&#x27;,&#x27;.&#x27;]转为&#x27;Q...&#x27;</span></span><br><span class="line">            solutions.append(tmp)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> col[i]==<span class="number">0</span> <span class="keyword">and</span> left_dia[row+i]==<span class="number">0</span> <span class="keyword">and</span> right_dia[i-row+n-<span class="number">1</span>]==<span class="number">0</span>:</span><br><span class="line">                board[row][i] = <span class="string">&#x27;Q&#x27;</span></span><br><span class="line">                col[i],left_dia[row+i],right_dia[i-row+n-<span class="number">1</span>]=<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span></span><br><span class="line">                self.helper(board,solutions,row+<span class="number">1</span>,col,left_dia,right_dia)</span><br><span class="line">                board[row][i] = <span class="string">&#x27;.&#x27;</span></span><br><span class="line">                col[i],left_dia[row+i],right_dia[i-row+n-<span class="number">1</span>]=<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(739,901,907)-线性时间寻找数组中各个元素作为最值的最大范围</title>
    <url>/2018/12/28/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(739,901,907)-%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E5%AF%BB%E6%89%BE%E6%95%B0%E7%BB%84%E4%B8%AD%E5%90%84%E4%B8%AA%E5%85%83%E7%B4%A0%E4%BD%9C%E4%B8%BA%E6%9C%80%E5%80%BC%E7%9A%84%E6%9C%80%E5%A4%A7%E8%8C%83%E5%9B%B4/</url>
    <content><![CDATA[<p>题目有点拗口，其实就是给定一个数组，要求给出某个元素作为最小值或最小值的那些
continous subarrays 中最长的长度，如对于数组 <code>[1, 2, 5, 6]</code>,
元素 5 作为最大值的 continous subarrays 有三个：
<code>[5], [2, 5], [1, 2, 5]</code>，长度最长的是
3。遍历的解法找出一个元素要 <span class="math inline">\(O(n)\)</span>
的时间复杂度，找出所有元素则需要 <span
class="math inline">\(O(n^2)\)</span>
的时间复杂度，而<strong>通过栈能够在 <span
class="math inline">\(O(n)\)</span>
的时间复杂度内解决这个问题</strong>。</p>
<span id="more"></span>
<p>下面这两个题目都直接用到了这种解法</p>
<p><a
href="https://leetcode.com/problems/daily-temperatures/description/">739.
Daily Temperatures</a> <a
href="https://leetcode.com/problems/online-stock-span/description/">901.
Online Stock Span</a></p>
<p>以 901. Online Stock Span
为例，如下所示，其实题目就要找出某个元素作为最大值时 subarray
的最大长度，且这个 subarray 是有方向的，即只能从当前元素往左延伸</p>
<blockquote>
<p>Write a class StockSpanner which collects daily price quotes for some
stock, and returns the span of that stock's price for the current
day.</p>
<p>The span of the stock's price today is defined as the maximum number
of consecutive days (starting from today and going backwards) for which
the price of the stock was less than or equal to today's price.</p>
<p>For example, if the price of a stock over the next 7 days were [100,
80, 60, 70, 60, 75, 85], then the stock spans would be [1, 1, 1, 2, 1,
4, 6].</p>
</blockquote>
<p>暴力的遍历需要 <span class="math inline">\(O(n^2)\)</span>
的时间复杂度，那通过栈如何在 <span class="math inline">\(O(n)\)</span>
的时间复杂度解决这个问题呢？</p>
<p><strong>首先创建一个空栈用于存储每个元素的下标，从左到右遍历数组中的元素，对于当前元素，假如栈为空或栈顶元素大于当前元素，则将当前元素入栈，否则一直出栈直到栈为空或栈顶元素大于当前元素</strong>，这样做将左边比当前元素小的元素都出栈，最后栈顶元素（如果有）和当前元素之间的距离就是要求的距离，如果栈为空，则当前元素是当前遍历的所有元素中最大的，其
下标+1 便是要求的距离。</p>
<p>由于每个元素最多会被入栈一次和出栈一次，因此其时间复杂度便是 <span
class="math inline">\(O(n)\)</span>,
其<strong>减小时间复杂度的原理其实就是通过出栈减少了元素比较的次数</strong>，比如说对于当前元素
e，出栈了 k 个元素，那后面如果有个元素比 e 大，肯定也比出栈的 k
个元素要大，因此无需进行比较，而这 k 个元素已经出栈了，因此减少了这 k
次的比较。</p>
<p>另外，需要注意的是，由于要求的是距离，因此<strong>栈存储的是元素的下标</strong>，比较元素大小是通过原数组加下标即可。</p>
<p>因此 901 题目的 python 代码如下, 也有 <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/C++/901.%20Online%20Stock%20Span.cc">c++版本</a>
和 <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/Go/901.%20Online%20Stock%20Span.go">go版本</a>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">StockSpanner</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.nums = []</span><br><span class="line">        self.stack = []</span><br><span class="line">        self.idx = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self, price</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type price: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">while</span> self.stack <span class="keyword">and</span> self.nums[self.stack[-<span class="number">1</span>]-<span class="number">1</span>] &lt;= price:</span><br><span class="line">            self.stack.pop()</span><br><span class="line">        self.nums.append(price)</span><br><span class="line">        span = self.idx-self.stack[-<span class="number">1</span>] <span class="keyword">if</span> self.stack <span class="keyword">else</span> self.idx</span><br><span class="line">        self.stack.append(self.idx)</span><br><span class="line">        self.idx += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> span</span><br></pre></td></tr></table></figure></p>
<p>739.Daily Temperatures
的题目原理是一样的，只是要求的是最小元素往右的最长
subarray，解法同上，只是此时需要从后往前遍历数组了，具体的代码可见: <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/Python/739.%20Daily%20Temperatures.py">python版本</a>，<a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/C++/739.%20Daily%20Temperatures.cc">c++版本</a>，<a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/Go/739.%20Daily%20Temperatures.go">go版本</a></p>
<h2 id="拓展">拓展</h2>
<p>上面两个题目是比较明确要求出各个元素作为最小值或最大值时的最长
subarray 的长度，但是有些问题不会直接要求这么求解。比如说题目 <a
href="https://leetcode.com/problems/sum-of-subarray-minimums/description/">907.
Sum of Subarray Minimums</a>, 题目要求的是求出所有 subarray
中最小元素的和，下面是一个简单的例子</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Input: [3,1,2,4]</span><br><span class="line">Output: 17</span><br><span class="line">Explanation: Subarrays are [3], [1], [2], [4], [3,1], [1,2], [2,4], [3,1,2], [1,2,4], [3,1,2,4]. </span><br><span class="line">Minimums are 3, 1, 2, 4, 1, 1, 2, 1, 1, 1.  Sum is 17.</span><br></pre></td></tr></table></figure>
<p>通过穷举法求解的时间复杂度显然太高了，但是我们可以换一个角度来求解这个问题，就是<strong>只要求出某个元素作为最小值的
subarray 个数，那么该元素乘上 subarray
个数便是这个元素对最终的结果的贡献值</strong>，比如说比如说对于某个长度为
n 的数组 A, 其各个元素作为最小值的 subarray 个数分别是
<code>f[0], f[1].....f[n-1]</code>, 则最终结果为</p>
<p><span class="math display">\[\sum_{i=0}^{n-1} A[i]f[i]\]</span></p>
<p>那么现在的问题就是要求出各个元素作为最小值的 subarray
个数，这就要用到了我们前面提到的通过栈求解的方法了，而且要分别往左和往右求出
subarray 的长度。</p>
<p><strong>对于当前元素 <code>A[i]</code>,
将当前值作为最小值，分别往左和往右求出的 subarray 长度记为 left 和
right，则包含 <code>A[i]</code> 作为最小值的 subarray 个数为：
<code>f[i] = left * right</code></strong></p>
<p>实现的 python 代码如下，也可参考 <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/C++/907.%20Sum%20of%20Subarray%20Minimums.cc">c++版本</a>
和 <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/Go/907.%20Sum%20of%20Subarray%20Minimums.go">go版本</a></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumSubarrayMins</span>(<span class="params">self, A</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type A: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = <span class="built_in">len</span>(A)</span><br><span class="line">        s, left = [], []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n):</span><br><span class="line">            <span class="keyword">while</span> s <span class="keyword">and</span> A[s[-<span class="number">1</span>]] &gt;= A[i]:</span><br><span class="line">                s.pop()</span><br><span class="line">            left.append(i - s[-<span class="number">1</span>] <span class="keyword">if</span> s <span class="keyword">else</span> i + <span class="number">1</span>)</span><br><span class="line">            s.append(i)</span><br><span class="line">        </span><br><span class="line">        s, right = [], []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">while</span> s <span class="keyword">and</span> A[s[-<span class="number">1</span>]] &gt; A[i]:</span><br><span class="line">                s.pop()</span><br><span class="line">            right.append(s[-<span class="number">1</span>] - i <span class="keyword">if</span> s <span class="keyword">else</span> n - i)</span><br><span class="line">            s.append(i)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(A[i] * left[i] * right[n-i-<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)) % (<span class="number">10</span>**<span class="number">9</span> + <span class="number">7</span>) </span><br></pre></td></tr></table></figure>
<p>上面的思路就是分别从左到右和从右到左获取 left 和 right 这两个表示
subarray 数量的数组，需要注意的是，获取 left 数组是用的比较条件是
<code>A[s[-1]] &gt;= A[i]</code>, 但是获取 right 数组时用的是
<code>A[s[-1]] &gt; A[i]</code>;这里以一个例子简介会比较方便，假如说对于数组
<code>[71,55,82,55]</code>, 如果两个比较条件都采用
<code>&gt;=</code>，那么 <code>[55,82,55]</code> 这个 subarray
会被重复计算两次， 如果都采用 &gt;, <code>[55,82,55]</code>
则不会被计算, 因此一定要有一个采用 <code>&gt;=</code>, 而另一个采用
<code>&gt;</code>。</p>
<p><strong>这里其实也引出另外一个非常重要的思想，就是分别求出每个元素对最终结果的贡献，然后累加起来便是最终的结果</strong>，在上面的问题即是求出某个元素作为最小值的
subarray 个数，那么该元素乘上 subarray
个数便是这个元素对最终的结果的贡献值。且这一类问题一般都跟
<code>subarray</code>、 <code>subsequence</code> 相关，比如说 <a
href="https://leetcode.com/problems/unique-letter-string/description/">828.
Unique Letter String</a> 和 <a
href="https://leetcode.com/problems/sum-of-subsequence-widths/description/">891.
Sum of Subsequence Widths</a> 都是通过这种思想来解决的</p>
<p>首先看问题 828. Unique Letter String，题目要求出所有的 subarray 中的
unique characters 的数量，遍历的时间复杂度是 <span
class="math inline">\(O(n^3)\)</span>,
但是采用上面提到的思想，可以分别求出每个元素作为 unique character 时的
subarray 的数量，然后累加起来即可，这样的时间复杂度变为了 <span
class="math inline">\(O(n^2)\)</span>, AC 的 python 代码如下,
另外也可参考 <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/C++/828.%20Unique%20Letter%20String.cc">c++版本</a>
和 <a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/Go/828.%20Unique%20Letter%20String.go">go版本</a></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">uniqueLetterString</span>(<span class="params">self, S</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type S: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        MOD = <span class="number">1000000007</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(S)):</span><br><span class="line">            left, right = i - <span class="number">1</span>, i + <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left &gt;=<span class="number">0</span> <span class="keyword">and</span> S[left] != S[i]:</span><br><span class="line">                left -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> right &lt; <span class="built_in">len</span>(S) <span class="keyword">and</span> S[right] != S[i]:</span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            result += ((i - left) * (right - i)) % MOD</span><br><span class="line">            result %= MOD</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>问题 891. Sum of Subsequence Widths 与前面的不同，前面的都是连续的
subarray， 而这里是可以<strong>不连续的
subsequence</strong>，题目要求出每个 subsequence
中最大值和最小值的差，然后求和得到最终的结果。同样采用上面的思想，求出某个元素
<code>A[i]</code> 作为最小值的 subsequence 的数量 n1, 作为最大值的
subsequence 的数量 n2, 则 <code>A[i]</code> 对最终结果的贡献是
<code>n2 * A[i] - n1 * A[i]</code>。但是 n1、n2
不能像之前一样分别往左往右延伸获取了，这里有一个很重要但是很容易被忽略的事实：<strong>数组的顺序不影响最终的结果</strong>。因此可以将数组进行排序，n1
就是当前元素左边元素的一个组合数量了，n2 同理。AC 的 python 代码如下,
在实现中计算 <span class="math inline">\(2^i\)</span> 使用位移操作即
<code>1&lt;&lt;i</code> 而不是直接计算，否则会导致超时</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumSubseqWidths</span>(<span class="params">self, A</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type A: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        MOD = <span class="number">1000000007</span></span><br><span class="line">        n = <span class="built_in">len</span>(A)</span><br><span class="line">        A.sort()</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>((((<span class="number">1</span> &lt;&lt; i) - (<span class="number">1</span> &lt;&lt; (n-i-<span class="number">1</span>))) * A[i]) % MOD <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)) % MOD</span><br></pre></td></tr></table></figure>
<h2 id="小结">小结</h2>
<p>本文主要介绍了两个重要的思想，其中一个是<strong>通过栈在线性时间内求解数组中某个元素作为最小值（或最大值）的最长
subarray</strong>，代表性的题目有 <a
href="https://leetcode.com/problems/daily-temperatures/description/">739.
Daily Temperatures</a>、<a
href="https://leetcode.com/problems/online-stock-span/description/">901.
Online Stock Span</a> 和 <a
href="https://leetcode.com/problems/sum-of-subarray-minimums/description/">907.
Sum of Subarray
Minimums</a>；另外一个重要的思想是<strong>分别求出每个元素对最终结果的贡献，然后累加起来便是最终的结果</strong>，代表性的题目有
<a
href="https://leetcode.com/problems/unique-letter-string/description/">828.
Unique Letter String</a>、<a
href="https://leetcode.com/problems/sum-of-subsequence-widths/description/">891.
Sum of Subsequence Widths</a> 和 <a
href="https://leetcode.com/problems/sum-of-subarray-minimums/description/">907.
Sum of Subarray Minimums</a>。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(10, 44)--正则表达式的匹配与通配符的匹配</title>
    <url>/2016/10/23/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(10,%2044)--%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%8C%B9%E9%85%8D%E4%B8%8E%E9%80%9A%E9%85%8D%E7%AC%A6%E7%9A%84%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<p>正则表达式和通配符均是用来匹配字符串的，但是两者使用的范围不一样，通配符一般用在
Linux
命令行shell中，而正则表达式使用则更加广泛，在各种编程语言和工具中均有支持。下面主要讲述如何实现正则表达式和通配符的简单匹配。</p>
<span id="more"></span>
<p>题目选自 LeetCode 的 <a
href="https://leetcode.com/problems/regular-expression-matching/">10.
Regular Expression Matching</a> 和 <a
href="https://leetcode.com/problems/wildcard-matching/">44. Wildcard
Matching</a>，之所以说是简单匹配，是因为两者的实现的只是两个符号的功能。正则匹配要求实现
<code>*</code>和
<code>.</code>的匹配功能，而通配符匹配要求实现<code>?</code>和
<code>*</code>的匹配。</p>
<p><strong>解决这种两个字符串的比较问题一般可考虑动态规划。以两个字符串的长度分别作为长和宽建立一个二维矩阵，通过二维动态规划解决。</strong></p>
<h2 id="正则表达式">正则表达式</h2>
<p>在正则表达式中,<code>.</code>表示任意一个单一字符，<code>*</code>表示0个或若干个前一个字符（表示为0个的时候前一字符也失效，也就是
<code>a*</code> 可以匹配出空字符串）。</p>
<p>首先我们建立了一个 m*n 的dp矩阵，其中m表示匹配模式字符串 p
的长度，n表示待匹配字符串 s 的长度。则 <code>dp[i][j]</code>
表示子字符串 <code>p[:i]</code> 和 <code>s[:j]</code>
(均包含i和j)是否匹配(true/false)。假设目前已知 <code>dp[i][j-1]</code>
及其前面的所有情况的匹配关系，那么要求<code>dp[i][j]</code>通过动态规划的递推关系如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 假如 p[i] == &#x27;.&#x27;，则dp[i][j] = dp[i-1][j-1]</span><br><span class="line">2. 假如 p[i] == letter(a-zA-Z)，则dp[i][j] = dp[i-1][j-1] &amp;&amp; (p[i]==s[j])</span><br><span class="line">3. 假如 p[i] == &#x27;*&#x27;,则 dp[i][j] = dp[i-2][j] || </span><br><span class="line">                                  dp[i-1][j] || </span><br><span class="line">                                  (dp[i][j-1] &amp;&amp; (p[i-1] == s[j]))</span><br></pre></td></tr></table></figure>
<p>上面的1,2 均比较好理解，关键是出现 <code>*</code>
时要分三种情况讨论，分别是 <code>*</code> 匹配了0个，1
个，和若干个前一字符。假如匹配了0个前一字符，那么当前位置的匹配结果与<code>dp[i-2][j]</code>相同；匹配了1个前一字符，则当前位置的匹配结果与
<code>dp[i-1][j]</code>
相同；关键是假如匹配了多个前一字符，该如何判断，此时我们无法知道到底匹配了多少个前一字符，但是换个角度去想这个问题，<strong>假如匹配了多个前一字符，那么前一字符要与当前的
<code>s[j]</code> 匹配（p[i-1]==s[j] 或
p[i-1]='.'），此时要想匹配成功(<code>dp[i][j]</code>为true)，则当前的匹配串(p[:i])必须能够匹配<code>s[:j-1]</code>,也就是<code>dp[i][j-1]</code>为true。</strong>对于这三种情况出现任意一种均可认为匹配，因此取或操作。</p>
<p>在具体实现中还要注意数组越界的问题，可以看到上面出现了
i-1，j-1，i-2的下标，那么在实现的时候要在原二维矩阵中各增加一行和一列，表示第0个字符也就是空字符从而避免了i-1的越界；同时只有在遇到<code>*</code>时才会出现i-2的下标，且这种情况下只有当<code>*</code>出现在匹配串第一个的时候才会越界，而当*出现在匹配串的第一个字符的时候表示为空字符串，除了待匹配字符串为空时一律为false。具体实现的Java代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isMatch</span><span class="params">(String s, String p)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> p.length()+<span class="number">1</span>, n = s.length()+<span class="number">1</span>;</span><br><span class="line">        <span class="type">boolean</span>[][] dp = <span class="keyword">new</span> <span class="title class_">boolean</span>[m][n];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;m; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j=<span class="number">0</span>;j&lt;n; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(j==<span class="number">0</span>) dp[i][j] = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j] = <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(j==<span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(p.charAt(i-<span class="number">1</span>)!=<span class="string">&#x27;*&#x27;</span>) dp[i][j] = <span class="literal">false</span>;</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j] = dp[i-<span class="number">1</span>][j] || dp[i-<span class="number">2</span>][j];</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span> (p.charAt(i-<span class="number">1</span>)==<span class="string">&#x27;.&#x27;</span>) dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (p.charAt(i-<span class="number">1</span>) == <span class="string">&#x27;*&#x27;</span>) </span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="keyword">if</span> (i==<span class="number">1</span>) dp[i][j] = <span class="literal">false</span>;</span><br><span class="line">                        <span class="keyword">else</span> dp[i][j] = dp[i-<span class="number">2</span>][j] || </span><br><span class="line">                                        dp[i-<span class="number">1</span>][j] || </span><br><span class="line">                                        ((p.charAt(i-<span class="number">2</span>)== <span class="string">&#x27;.&#x27;</span> || p.charAt(i-<span class="number">2</span>)==s.charAt(j-<span class="number">1</span>)) &amp;&amp; dp[i][j-<span class="number">1</span>]);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j] = (s.charAt(j-<span class="number">1</span>)==p.charAt(i-<span class="number">1</span>)) &amp;&amp; dp[i-<span class="number">1</span>][j-<span class="number">1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="通配符">通配符</h2>
<p>在通配符中 <code>？</code> 表示一个字符，而 <code>*</code>
与正则表示式中的含义不一样，在这里 <code>*</code>
表示任意字符串（包括空字符串）。</p>
<p>采用上面的符号(dp,s,p)的定义，在求
<code>dp[i][j]</code>,有以下的递推关系</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 假如 p[i] == &#x27;?&#x27;，则dp[i][j] = dp[i-1][j-1]</span><br><span class="line">2. 假如 p[i] == letter(a-zA-Z)，则dp[i][j] = dp[i-1][j-1] &amp;&amp; (p[i]==s[j])</span><br><span class="line">3. 假如 p[i] == &#x27;*&#x27;,则 dp[i][j] = dp[i-1][j] || dp[i][j-1]</span><br></pre></td></tr></table></figure>
<p>前面的两种情况都比较好理解，这里的关键点是当遇到 <code>*</code>
时，需要讨论两种情况，第一种是<code>*</code>表示空字符，这时候匹配结果与<code>dp[i-1][j]</code>相同；第二种是<code>*</code>表示任意字符串，这时候假如
<code>dp[i-1][0]</code> 到 <code>dp[i-1][j-1]</code>
有一个为真，则<code>dp[i][j]</code>为真,但是这样遍历的话遇到
<code>*</code>
时会导致时间复杂度变得很大，这时候用到了一个技巧，就是<code>dp[i-1][0]</code>
到 <code>dp[i-1][j-1]</code>的结果已经包含在<code>dp[i-1][j]</code>
中了（根据递推式可知道），所以此时只需要或上<code>dp[i-1][j]</code>即可。</p>
<p>实现时也需要注意越界问题，解决方法同上面提到的添加空字符，具体实现的Java代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isMatch</span><span class="params">(String s, String p)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">m</span> <span class="operator">=</span> p.length()+<span class="number">1</span>, n = s.length()+<span class="number">1</span>;</span><br><span class="line">        <span class="type">boolean</span>[][] dp = <span class="keyword">new</span> <span class="title class_">boolean</span>[m][n];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;m; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j=<span class="number">0</span>; j&lt;n; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(j==<span class="number">0</span>) dp[i][j] = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j] = <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(j==<span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(p.charAt(i-<span class="number">1</span>)==<span class="string">&#x27;*&#x27;</span>) dp[i][j] = dp[i-<span class="number">1</span>][j];</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j] = <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span> (p.charAt(i-<span class="number">1</span>)==<span class="string">&#x27;?&#x27;</span>) dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(p.charAt(i-<span class="number">1</span>)==<span class="string">&#x27;*&#x27;</span>) dp[i][j] = dp[i-<span class="number">1</span>][j] || dp[i][j-<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">else</span> dp[i][j] = (s.charAt(j-<span class="number">1</span>)==p.charAt(i-<span class="number">1</span>)) &amp;&amp; dp[i-<span class="number">1</span>][j-<span class="number">1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>动态规划</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(105. 106)--树的重构</title>
    <url>/2016/07/20/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(105.%20106)--%E6%A0%91%E7%9A%84%E9%87%8D%E6%9E%84/</url>
    <content><![CDATA[<p>本文主要从LeetCode两道题出发讲解如何从树的周游结果来重构树。这两道题分别是<a
href="https://leetcode.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/">105.
Construct Binary Tree from Preorder and Inorder Traversal</a>和 <a
href="https://leetcode.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/">106.
Construct Binary Tree from Inorder and Postorder Traversal</a></p>
<span id="more"></span>
<p><a
href="https://leetcode.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/">105.
Construct Binary Tree from Preorder and Inorder
Traversal</a>要求从树的前序周游和中序周游的结果重构树。由两种周游的遍历顺序可知，两种周游方式得到的结果的结构如下</p>
<p><img
src="https://wulc.me/imgs/image_1aog9uofj196u1tu21t941e0esv39.png" /></p>
<p>其中<code>left_tree</code>是<code>root</code>的左子树，
<code>right_tree</code>是<code>root</code>的右子树。</p>
<p>因此<strong>通过树的根节点root以及左子树的最后一个节点，可以从两个周游结果中分别找到左子树的两种周游结果和右子树的两种周游结果。然后将问题转化为原问题的子问题，通过递归解决即可。</strong></p>
<p>python实现的代码如下所示,需要注意的是下面的代码通过下标指出子树的范围，而不是通过slice，也就是preorder[i:j]的方式来将子树范围切出来，因为slice会在内存开辟新的空间，递归时会开辟大量空间而导致MLE错误：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">buildTree</span>(<span class="params">self, preorder, inorder</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type preorder: List[int]</span></span><br><span class="line"><span class="string">        :type inorder: List[int]</span></span><br><span class="line"><span class="string">        :rtype: TreeNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.helper(preorder, <span class="number">0</span>, <span class="built_in">len</span>(preorder)-<span class="number">1</span>, inorder, <span class="number">0</span>, <span class="built_in">len</span>(inorder)-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self, preorder, pleft, pright, inorder, ileft, iright</span>):</span><br><span class="line">        <span class="keyword">if</span> pleft &gt; pright:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> pleft == pright:</span><br><span class="line">            <span class="keyword">return</span> TreeNode(preorder[pleft])</span><br><span class="line">        inx = inorder.index(preorder[pleft])</span><br><span class="line">        left_len = inx - ileft</span><br><span class="line">        root = TreeNode(preorder[pleft])</span><br><span class="line">        root.left = self.helper(preorder, pleft + <span class="number">1</span>, pleft + left_len, inorder, ileft, inx-<span class="number">1</span>)</span><br><span class="line">        root.right = self.helper(preorder, pleft + left_len + <span class="number">1</span>, pright, inorder, inx+<span class="number">1</span>, right)</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<p><a
href="https://leetcode.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/">106.
Construct Binary Tree from Inorder and Postorder
Traversal</a>的结题思路与上面一致。两种周游结果的结构如下：</p>
<p><img
src="https://wulc.me/imgs/image_1aogafogj1n5c1rpgqe21co539m.png" /></p>
<p>同样可以通过树的根节点root以及左子树的最后一个节点，分别找到两棵子树的两种周游结果，进而将问题转化为原来问题的子问题，通过递归解决。</p>
<p>python实现代码如下所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">buildTree</span>(<span class="params">self, inorder, postorder</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type inorder: List[int]</span></span><br><span class="line"><span class="string">        :type postorder: List[int]</span></span><br><span class="line"><span class="string">        :rtype: TreeNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.helper(inorder, <span class="number">0</span>, <span class="built_in">len</span>(inorder)-<span class="number">1</span>, postorder, <span class="number">0</span>, <span class="built_in">len</span>(postorder)-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self, inorder, ileft, iright, postorder, pleft, pright</span>):</span><br><span class="line">        <span class="keyword">if</span> ileft &gt; iright: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> ileft == iright: <span class="keyword">return</span> TreeNode(inorder[ileft])</span><br><span class="line">        inx = inorder.index(postorder[pright])</span><br><span class="line">        left_len = inx - ileft</span><br><span class="line">        root = TreeNode(postorder[pright])</span><br><span class="line">        root.left = self.helper(inorder, ileft, inx-<span class="number">1</span>, postorder, pleft, pleft+left_len-<span class="number">1</span>) </span><br><span class="line">        root.right = self.helper(inorder, inx+<span class="number">1</span>, iright, postorder, pleft+left_len, pright-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>树</tag>
        <tag>分治法</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 解题报告(343, 377)-动态规划求解数字的组合方案</title>
    <url>/2017/06/28/LeetCode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(343,%20377)-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%B1%82%E8%A7%A3%E6%95%B0%E5%AD%97%E7%9A%84%E7%BB%84%E5%90%88%E6%96%B9%E6%A1%88/</url>
    <content><![CDATA[<p>LeetCode 上的这两道题 <a
href="https://leetcode.com/problems/integer-break/#/description">343.
Integer Break</a> 和 <a
href="https://leetcode.com/problems/combination-sum-iv/#/description">377.
Combination Sum IV</a>
从名字上来看没有什么联系，但是实际上两个题目都是通过动态规划来降低了求解时间复杂度，并且面对这种题目一开始往往难以往动态规划方向去想，特此记录。</p>
<span id="more"></span>
<p>对我而言，之所以不会一开始就想到动态规划，原因是这两个题目要求解的问题均是以某种方式构造某个数字时，总共的方案有几种或者最优的方案是哪种。一开始往往就是往数学或者
dfs 方向去想，而不会想到通过动态规划建立一个从 1
到目标数字的数组来记录各个状态的答案。</p>
<p>对于问题 <a
href="https://leetcode.com/problems/integer-break/#/description">343.
Integer Break</a>,
该问题属于求解组成某个数字的最优方案的问题，首先需要注意的是<strong>只把数字分为两部分</strong>，这样能够简化问题，然后对于这两部分都取最优时，则这两部分的乘积就是这种分法的最优解。那对于这两部分，可以很自然地想到均通过递归去求解最优，但是这种方法或导致很多重复的计算，比如说将
8 分为 6 和 2 时，需要计算 6 和 2 的最优解，但是进一步将 6 分为 4 和 2
时，还要计算 2 的最优解，这样显然会导致 多次计算 2 的最优解。</p>
<p>解决这个问题就是通过动态规划建立的数组记录数字 2
的最优解，需要求解时直接从数组中取即可，这时候动态规划的数组就有点类似
cache 的作用，实现的 java 代码如下,其中 <code>dp[i]</code> 表示数字 i
的最优解（即分解的数字的乘积最大）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">integerBreak</span><span class="params">(<span class="type">int</span> n)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span>[] dp = <span class="keyword">new</span> <span class="title class_">int</span>[n+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">2</span>; i &lt;= n; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">max</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt;= (i &gt;&gt; <span class="number">1</span>); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                max = Math.max( Math.max(dp[j], j) * Math.max(i - j, dp[i-j]), max);</span><br><span class="line">            &#125;</span><br><span class="line">            dp[i] = max;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>针对 LeetCode
的评测方法（建立一个对象，输入多组评测数据），上面的代码还能该继续优化，就是为这个对象建立一个全局的数组记录各个数字的最优解，供多组评测数据使用，当评测数字在数组中已经有答案了就不必再求解，反之递增数组。实现的
Java 代码如下，代码中的 <code>cache</code> list 与上面方法中的
<code>dp</code> 数组的作用相同</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;Integer&gt; cache = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;Integer&gt;();</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">integerBreak</span><span class="params">(<span class="type">int</span> n)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> cache.size(); i &lt;= n; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">max</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">1</span>; j &lt;= (i &gt;&gt; <span class="number">1</span>); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                max = Math.max( Math.max(cache.get(j), j) * Math.max(i - j, cache.get(i-j)), max);</span><br><span class="line">            &#125;</span><br><span class="line">            cache.add(max);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cache.get(n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>针对问题 <a
href="https://leetcode.com/problems/combination-sum-iv/#/description">377.
Combination Sum IV</a>，一开始想的是通过 dfs
来求解，但是题目中允许重复的数字，并且不同的顺序被认为是不同的组合方案，这样就使得如果通过
dfs 求解，时间复杂度会非常大。</p>
<p>通过动态规划求解，通过 <code>dp</code> 数组中的 <code>dp[i]</code>
表示数字 i
的组合方式的数目，可以同时解决上面提到的重复数字和数字的顺序问题。</p>
<p>则 <code>dp[i+1]</code> 可以考虑所有数字与已有的
<code>dp[j] (j=0，1，...i)</code> 的组合，实现的 Java 代码如下</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">combinationSum4</span><span class="params">(<span class="type">int</span>[] nums, <span class="type">int</span> target)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span>[] dp = <span class="keyword">new</span> <span class="title class_">int</span>[target+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        <span class="type">int</span> count;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= target; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            count = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; nums.length; j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span> (nums[j] &gt; i) <span class="keyword">break</span>;</span><br><span class="line">                count += dp[i - nums[j]];</span><br><span class="line">            &#125;</span><br><span class="line">            dp[i] = count;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[target];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>往往会听到说动态规划的难点在构造递推关系，这没错，但是还有一个难点就是想到题目可以通过动态规划去求解，其实只要能往动态规划方向去想，递推关系往往也不难得到。因此，本文的主要作用还是要提醒<strong>面对这种求解目标数字的最优构造方案或者构造方案数目的时候，可以往动态规划方向去想，建立一个从1到目标数字的数组记录各个数字的结果，而不是仅仅拘泥于目标数字。</strong></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(11)--双指针找最大储水容器</title>
    <url>/2016/02/05/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(11)--%E5%8F%8C%E6%8C%87%E9%92%88%E6%89%BE%E6%9C%80%E5%A4%A7%E5%82%A8%E6%B0%B4%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<p>原题如下： &gt;Given n non-negative integers a1, a2, ..., an, where
each represents a point at coordinate (i, ai). n vertical lines are
drawn such that the two endpoints of line i is at (i, ai) and (i, 0).
Find two lines, which together with x-axis forms a container, such that
the container contains the most water.</p>
<span id="more"></span>
<p>这道题的不难理解，但是对时间复杂度有要求。简单地通过两个for循环寻找最大的蓄水量的时间复杂度为O(n^2),提交时提示超时。</p>
<p>蓄水量由container
的底（也就是两个下标之差）乘上其两端的边的最小值。假如left
为第一条竖直边的下标，right
为最后一条竖直边的下标，i,j为其中的两条边（设i &lt; j），那么：</p>
<p><strong>要使任何S(i&gt;=left, j&lt;=right) &gt;=
S(left,right)，由于j-i &lt;=
right-left，必然要有min(ai,aj)&gt;=min(a(left),a(right))才行</strong></p>
<p>因此可以从两边同时开始往中间逼近，每次只移动一步（左边的边或右边的边），而且两条边中最短的边进行移动。时间复杂度为O(n)，实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxArea</span>(<span class="params">self, height</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type height: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="built_in">len</span>(height) - <span class="number">1</span></span><br><span class="line">        <span class="built_in">max</span> = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            current = (right - left)* <span class="built_in">min</span>(height[left],height[right])</span><br><span class="line">            <span class="keyword">if</span> current &gt;<span class="built_in">max</span>:</span><br><span class="line">                <span class="built_in">max</span> = current</span><br><span class="line">            <span class="keyword">if</span> height[left] &gt; height[right]:</span><br><span class="line">                right-=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(17)--电话数字组合成的不同字符串</title>
    <url>/2016/03/06/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(17)--%E7%94%B5%E8%AF%9D%E6%95%B0%E5%AD%97%E7%BB%84%E5%90%88%E6%88%90%E7%9A%84%E4%B8%8D%E5%90%8C%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/letter-combinations-of-a-phone-number/">原题</a>如下:
&gt;Given a digit string, return all possible letter combinations that
the number could represent. <span id="more"></span> &gt;A mapping of digit to
letters (just like on the telephone buttons) is given below.</p>
<p><img
src="https://wulc.me/imgs/200px-Telephone-keypad2.svg.png" /></p>
<p>Input:Digit string "23" Output: ["ad", "ae", "af", "bd", "be", "bf",
"cd", "ce", "cf"].</p>
<p>题目很好理解，就是组合出所有可能结果即可。每个数字写一个for循环即可，但是在程序运行前我们无法知道到底输入有几个数字,下面给出两个方法解决这个问题。</p>
<p>方法一是回溯法，每次选择当前数字的一个字符，然后将下一个数字作为当前数字，直到所有的数字都遍历完即可。实现的代码如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    numDict =&#123;<span class="string">&#x27;2&#x27;</span>:[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>],<span class="string">&#x27;3&#x27;</span>:[<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;f&#x27;</span>],<span class="string">&#x27;4&#x27;</span>:[<span class="string">&#x27;g&#x27;</span>,<span class="string">&#x27;h&#x27;</span>,<span class="string">&#x27;i&#x27;</span>],<span class="string">&#x27;5&#x27;</span>:[<span class="string">&#x27;j&#x27;</span>,<span class="string">&#x27;k&#x27;</span>,<span class="string">&#x27;l&#x27;</span>],<span class="string">&#x27;6&#x27;</span>:[<span class="string">&#x27;m&#x27;</span>,<span class="string">&#x27;n&#x27;</span>,<span class="string">&#x27;o&#x27;</span>],<span class="string">&#x27;7&#x27;</span>:[<span class="string">&#x27;p&#x27;</span>,<span class="string">&#x27;q&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;s&#x27;</span>],<span class="string">&#x27;8&#x27;</span>:[<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;u&#x27;</span>,<span class="string">&#x27;v&#x27;</span>],<span class="string">&#x27;9&#x27;</span>:[<span class="string">&#x27;w&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>,<span class="string">&#x27;z&#x27;</span>]&#125;</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">letterCombinations</span>(<span class="params">self, digits</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type digits: str</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = []</span><br><span class="line">        self.helper(<span class="number">0</span>, digits, <span class="string">&#x27;&#x27;</span>, result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self, index, digits, tmp, result</span>):</span><br><span class="line">        <span class="keyword">if</span> index == <span class="built_in">len</span>(digits):</span><br><span class="line">            <span class="keyword">if</span> tmp: <span class="comment"># empty string</span></span><br><span class="line">                result.append(tmp)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> Solution.numDict[digits[index]]:</span><br><span class="line">            self.helper(index+<span class="number">1</span>, digits, tmp+char, result)</span><br></pre></td></tr></table></figure>
<p>除了回溯法，还可以通过顺序的合并，考虑<strong>每次对两个string
list进行合并，合并后作为一个string list，再和后面的一个数字表示的string
list合并，就这样一直循环下去直到最后一个数字</strong></p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">letterCombinations</span>(<span class="params">self, digits</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type digits: str</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        numDict =&#123;<span class="string">&#x27;2&#x27;</span>:[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>],<span class="string">&#x27;3&#x27;</span>:[<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;f&#x27;</span>],<span class="string">&#x27;4&#x27;</span>:[<span class="string">&#x27;g&#x27;</span>,<span class="string">&#x27;h&#x27;</span>,<span class="string">&#x27;i&#x27;</span>],<span class="string">&#x27;5&#x27;</span>:[<span class="string">&#x27;j&#x27;</span>,<span class="string">&#x27;k&#x27;</span>,<span class="string">&#x27;l&#x27;</span>],<span class="string">&#x27;6&#x27;</span>:[<span class="string">&#x27;m&#x27;</span>,<span class="string">&#x27;n&#x27;</span>,<span class="string">&#x27;o&#x27;</span>],<span class="string">&#x27;7&#x27;</span>:[<span class="string">&#x27;p&#x27;</span>,<span class="string">&#x27;q&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;s&#x27;</span>],<span class="string">&#x27;8&#x27;</span>:[<span class="string">&#x27;t&#x27;</span>,<span class="string">&#x27;u&#x27;</span>,<span class="string">&#x27;v&#x27;</span>],<span class="string">&#x27;9&#x27;</span>:[<span class="string">&#x27;w&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>,<span class="string">&#x27;z&#x27;</span>]&#125;</span><br><span class="line">        </span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(digits)==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="comment"># 先将第一位对应的字符复制给result，防止调用函数combine2StrList时一开始result为空</span></span><br><span class="line">        result = numDict[digits[<span class="number">0</span>]]   </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(digits)):</span><br><span class="line">            result = self.combine2StrList(result,numDict[digits[i]])</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">            </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combine2StrList</span>(<span class="params">self,s1,s2</span>):</span><br><span class="line">        mix =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s1)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s2)):</span><br><span class="line">               mix.append(s1[i]+s2[j])</span><br><span class="line">        <span class="keyword">return</span> mix</span><br></pre></td></tr></table></figure></p>
<p>如有更好的解法，欢迎交流</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(200,130)--图的孤立子图</title>
    <url>/2016/07/17/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(200,130)--%E5%9B%BE%E7%9A%84%E5%AD%A4%E7%AB%8B%E5%AD%90%E5%9B%BE/</url>
    <content><![CDATA[<p><a href="https://leetcode.com/problems/number-of-islands/">200.
Number of Islands</a>题目描述如下： &gt;Given a 2d grid map of '1's
(land) and '0's (water), count the number of islands. An island is
surrounded by water and is formed by connecting adjacent lands
horizontally or vertically. You may assume all four edges of the grid
are all surrounded by water. <span id="more"></span> &gt;Example 1:</p>
<blockquote>
<p>11110 11010 11000 00000</p>
</blockquote>
<blockquote>
<p>Answer: 1</p>
</blockquote>
<p>上面的问题是一个经典的图论问题，需要求孤立的岛屿的个数，而岛屿仅可通过上下左右来连接，这种问题可以<strong>通过深度优先搜索(DFS)或广度优先搜索(BFS)来解决，每次遇到一个没访问过的岛屿就对当前岛屿进行DFS或DFS，并记录这个过程中访问过的岛屿，直至最终所有岛屿都被访问</strong></p>
<p>采用DFS的的python代码如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numIslands</span>(<span class="params">self, grid</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type grid: List[List[str]]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(grid) == <span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        m, n, result = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>]), <span class="number">0</span></span><br><span class="line">        visited = [[<span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n)] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(m)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n):</span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="string">&#x27;1&#x27;</span> <span class="keyword">and</span> visited[i][j] == <span class="number">0</span>:</span><br><span class="line">                    self.dfs(grid, visited, i, j)</span><br><span class="line">                    result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">self, grid, visited, i, j</span>):</span><br><span class="line">        visited[i][j] = <span class="number">1</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span>&lt;= i-<span class="number">1</span> &lt;m <span class="keyword">and</span> grid[i-<span class="number">1</span>][j] == <span class="string">&#x27;1&#x27;</span> <span class="keyword">and</span> visited[i-<span class="number">1</span>][j] == <span class="number">0</span>:</span><br><span class="line">            self.dfs(grid, visited, i-<span class="number">1</span>, j)</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span>&lt;= i+<span class="number">1</span> &lt;m <span class="keyword">and</span> grid[i+<span class="number">1</span>][j] == <span class="string">&#x27;1&#x27;</span> <span class="keyword">and</span> visited[i+<span class="number">1</span>][j] == <span class="number">0</span>:</span><br><span class="line">            self.dfs(grid, visited, i+<span class="number">1</span>, j)</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span>&lt;= j-<span class="number">1</span> &lt;n <span class="keyword">and</span> grid[i][j-<span class="number">1</span>] == <span class="string">&#x27;1&#x27;</span> <span class="keyword">and</span> visited[i][j-<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            self.dfs(grid, visited, i, j-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span>&lt;= j+<span class="number">1</span> &lt;n <span class="keyword">and</span> grid[i][j+<span class="number">1</span>] == <span class="string">&#x27;1&#x27;</span> <span class="keyword">and</span> visited[i][j+<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            self.dfs(grid, visited, i, j+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>假如将上面的题目改为一个岛屿邻接的岛屿除了上下左右，还有左上、左下、右上、右下，也就是有八个可能连接的地方，那么答案该如何修改？</p>
<p>实际上方法也很简单，对上面代码中的<code>dfs</code>方法增加检查左上、左下、右上、右下这四个点的代码即可。</p>
<p>上面的DFS中利用了<code>visited</code>数组检查某个点是否已经被访问过，空间复杂度为<code>O(m*n)</code>。实际上在原来的<code>grid</code>可修改的情况下,可以通过修改grid中的值为'1','0'以外的值，从而使得空间复杂度为O(1)。下面的BFS方法利用了这点</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numIslands</span>(<span class="params">self, grid</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type grid: List[List[str]]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        m = <span class="built_in">len</span>(grid)</span><br><span class="line">        <span class="keyword">if</span> m == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        n = <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n):</span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                    self.bfs(i, j, grid)</span><br><span class="line">                    count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">bfs</span>(<span class="params">self, row, col, grid</span>):</span><br><span class="line">        m, n = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        que = deque()</span><br><span class="line">        que.append((row, col))</span><br><span class="line">        grid[row][col] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">        <span class="keyword">while</span> que:</span><br><span class="line">            row, col = que.popleft()</span><br><span class="line">            <span class="keyword">if</span> row&gt;<span class="number">0</span> <span class="keyword">and</span> grid[row-<span class="number">1</span>][col]==<span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                que.append((row-<span class="number">1</span>, col))</span><br><span class="line">                grid[row-<span class="number">1</span>][col] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> row&lt;m-<span class="number">1</span> <span class="keyword">and</span> grid[row+<span class="number">1</span>][col] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                que.append((row+<span class="number">1</span>, col))</span><br><span class="line">                grid[row+<span class="number">1</span>][col] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> col&gt;<span class="number">0</span> <span class="keyword">and</span> grid[row][col-<span class="number">1</span>]==<span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                que.append((row, col-<span class="number">1</span>))</span><br><span class="line">                grid[row][col-<span class="number">1</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> col&lt;n-<span class="number">1</span> <span class="keyword">and</span> grid[row][col+<span class="number">1</span>] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">                que.append((row, col+<span class="number">1</span>))</span><br><span class="line">                grid[row][col+<span class="number">1</span>] = <span class="string">&#x27;2&#x27;</span></span><br></pre></td></tr></table></figure>
<p>此外，<a
href="https://leetcode.com/problems/surrounded-regions/">130. Surrounded
Regions</a>跟上面的题目也类似，只是需要对边上的点进行BFS或DFS，具体代码见<a
href="https://github.com/WuLC/LeetCode/blob/master/Algorithm/Python/130.%20Surrounded%20Regions.py">这里</a></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>图</tag>
        <tag>深度优先搜索</tag>
        <tag>广度优先搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(23)--合并k个有序数组</title>
    <url>/2016/03/29/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(23)--%E5%90%88%E5%B9%B6k%E4%B8%AA%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<p>原题如下： &gt;Merge k sorted linked lists and return it as one
sorted list. Analyze and describe its complexity.</p>
<span id="more"></span>
<p>题目不难理解，就是将k个排好序的链表合并成一个，可以说是merge two
sorted
lists的升级版。一开始想的方法超时，后来参考了网上的两种方法并通过python实现后能够AC，下面分别讲述这三种方法。</p>
<h2 id="方法一线性合并tle">方法一：线性合并（TLE）</h2>
<p>一开始想到的方法就是基于<code>merge two sorted lists</code>逐个合并list，就是先将两个list合成一个，然后将这个合并好的list再和一个未合并的list进行merge操作，这样<strong>总共会合并k-1</strong>次，时间复杂度为<span
class="math inline">\(O(2n+3n+....+kn) =
O(nk^2)\)</span>（设n为链表的平均长度）。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeKLists</span>(<span class="params">self, lists</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type lists: List[ListNode]</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        k = <span class="built_in">len</span>(lists)</span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        mergedList = lists[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,k):</span><br><span class="line">            mergedList = self.mergeTwoLists(mergedList,lists[i])</span><br><span class="line">        <span class="keyword">return</span> mergedList</span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeTwoLists</span>(<span class="params">self, l1, l2</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type l1: ListNode</span></span><br><span class="line"><span class="string">        :type l2: ListNode</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> l1 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> l2</span><br><span class="line">        <span class="keyword">if</span> l2 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> l1</span><br><span class="line">        </span><br><span class="line">        dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        nextNode = dummy</span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">and</span> l2:</span><br><span class="line">            <span class="keyword">if</span> l1.val &gt; l2.val:</span><br><span class="line">                nextNode.<span class="built_in">next</span> = l2</span><br><span class="line">                nextNode = nextNode.<span class="built_in">next</span></span><br><span class="line">                l2 = l2.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                nextNode.<span class="built_in">next</span> = l1</span><br><span class="line">                nextNode = nextNode.<span class="built_in">next</span></span><br><span class="line">                l1 = l1.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">if</span> l1:</span><br><span class="line">            nextNode.<span class="built_in">next</span> = l1</span><br><span class="line">        <span class="keyword">if</span> l2:</span><br><span class="line">            nextNode.<span class="built_in">next</span> = l2</span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></p>
<h2 id="方法二归并合并ac">方法二：归并合并（AC）</h2>
<p>这种方法类似于归并排序，先将当前需要排序的list对半分，重复这个步骤直到对半分出的list的数量为1，在进行merge，这时实际进行的是merge
two sorted list。</p>
<p>这种方法采用的思想跟第一种一样，都是<strong>分治法</strong>，先处理好局部，再合并成一个整体。但是<strong>与第一种方法在于这种方法在给出的lists的数量很大时需要进行merge的操作小于方法一。</strong></p>
<p>这里有两个需要注意是当<strong>lists的数量很大（也就是k很大）</strong>是merge的操作才会比方法一要少。方法一无论k的大小merge的次数为k-1，而方法二merge的次数为</p>
<p><span class="math display">\[\sum_{i=0}^m 2^i
(m=log_2k-1)\]</span></p>
<p>可以通过下面的程序验证当k很大时，这两种方法merge的次数不同
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">k = <span class="number">100000</span></span><br><span class="line">m = <span class="built_in">int</span>(math.log(k,<span class="number">2</span>))</span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">    <span class="built_in">sum</span>+=math.<span class="built_in">pow</span>(<span class="number">2</span>,i)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;merge times for method 1 when k=%s: %s&#x27;</span>%(k,k-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;merge times for method 2 when k=%s: %s&#x27;</span>%(k,<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure></p>
<p>根据主定理分析，这种方法的时间复杂度是<strong>O(nklog(nk))</strong>,下面是方法二实现的具体代码
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeKLists</span>(<span class="params">self, lists</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type lists: List[ListNode]</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        k = <span class="built_in">len</span>(lists)</span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.helper(lists,<span class="number">0</span>,<span class="built_in">len</span>(lists)-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self,lists,l,r</span>):</span><br><span class="line">        <span class="keyword">if</span> l&lt;r:</span><br><span class="line">            m = (r-l)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">return</span> self.mergeTwoLists(self.helper(lists,l,l+m),self.helper(lists,l+m+<span class="number">1</span>,r))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> lists[l]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeTwoLists</span>(<span class="params">self,l1,l2</span>):</span><br><span class="line">        <span class="keyword">if</span> l1 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> l2</span><br><span class="line">        <span class="keyword">if</span> l2 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> l1</span><br><span class="line"></span><br><span class="line">        dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        curr = dummy</span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">and</span> l2:</span><br><span class="line">            <span class="keyword">if</span> l1.val &lt; l2.val:</span><br><span class="line">                curr.<span class="built_in">next</span> = l1</span><br><span class="line">                curr = curr.<span class="built_in">next</span></span><br><span class="line">                l1 = l1.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                curr.<span class="built_in">next</span> = l2</span><br><span class="line">                curr = curr.<span class="built_in">next</span></span><br><span class="line">                l2 = l2.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">if</span> l1:</span><br><span class="line">            curr.<span class="built_in">next</span> = l1</span><br><span class="line">        <span class="keyword">if</span> l2:</span><br><span class="line">            curr.<span class="built_in">next</span> = l2</span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></p>
<h2 id="方法三基于堆排序的归并ac">方法三：基于堆排序的归并（AC）</h2>
<p>第三种方法非常巧妙，先建立一个大小为k的堆（k就是链表数量），
<strong>堆中的一个元素代表一个链表当前的最小元素，每次取堆顶的最小元素放到结果中，然后读取该元素的下一个元素放入堆中，重新维护好。</strong></p>
<p>因为每个链表是有序的，每次又是去当前k个元素中最小的，所以当所有链表都读完时结束，这个时候所有元素按从小到大放在结果链表中。
时间复杂度是O(nklogk)。</p>
<p>实现代码如下,建堆的方法有两种，下面一并给出： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeKLists</span>(<span class="params">self, lists</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type lists: List[ListNode]</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        k = <span class="built_in">len</span>(lists)</span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        listsHeap = []</span><br><span class="line">        listsHeap.append(<span class="number">0</span>) <span class="comment"># 使堆中的元素从1开始</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="keyword">if</span> lists[i] == <span class="literal">None</span>: <span class="comment"># avoid empty list</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            listsHeap.append(lists[i])</span><br><span class="line">        </span><br><span class="line">        dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        curr = dummy</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化堆有两种方法</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;方法一</span></span><br><span class="line"><span class="string">        j = len(listsHeap) - 1 </span></span><br><span class="line"><span class="string">        while j &gt; 1:</span></span><br><span class="line"><span class="string">            if listsHeap[j].val&lt;listsHeap[j/2].val:</span></span><br><span class="line"><span class="string">                listsHeap[j],listsHeap[j/2] = listsHeap[j/2],listsHeap[j]</span></span><br><span class="line"><span class="string">                self.siftDown(listsHeap,j)  #必须，否则初始建的堆会有问题</span></span><br><span class="line"><span class="string">            j-=1</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 方法二</span></span><br><span class="line">        leafParent = (<span class="built_in">len</span>(listsHeap)-<span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(leafParent,<span class="number">0</span>,-<span class="number">1</span>):</span><br><span class="line">            siftDown(listsHeap,i)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 取堆顶元素并调整堆</span></span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(listsHeap) &gt; <span class="number">1</span>:</span><br><span class="line">            curr.<span class="built_in">next</span> = listsHeap[<span class="number">1</span>]</span><br><span class="line">            curr = curr.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> listsHeap[<span class="number">1</span>].<span class="built_in">next</span> == <span class="literal">None</span>:  <span class="comment"># 将空的列表移到最后并删除</span></span><br><span class="line">                listsHeap[<span class="number">1</span>] = listsHeap[<span class="built_in">len</span>(listsHeap)-<span class="number">1</span>] </span><br><span class="line">                <span class="keyword">del</span>(listsHeap[<span class="built_in">len</span>(listsHeap)-<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                listsHeap[<span class="number">1</span>] = listsHeap[<span class="number">1</span>].<span class="built_in">next</span></span><br><span class="line">            self.siftDown(listsHeap,<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">siftDown</span>(<span class="params">self,listsHeap,i</span>):</span><br><span class="line">        <span class="keyword">while</span> i*<span class="number">2</span>+<span class="number">1</span> &lt;= <span class="built_in">len</span>(listsHeap):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">2</span>+<span class="number">1</span> &lt; <span class="built_in">len</span>(listsHeap):</span><br><span class="line">                <span class="keyword">if</span> listsHeap[i].val &gt; <span class="built_in">min</span>(listsHeap[i*<span class="number">2</span>].val,listsHeap[i*<span class="number">2</span>+<span class="number">1</span>].val):</span><br><span class="line">                    <span class="keyword">if</span> listsHeap[i*<span class="number">2</span>].val &lt; listsHeap[i*<span class="number">2</span>+<span class="number">1</span>].val:</span><br><span class="line">                        listsHeap[i],listsHeap[i*<span class="number">2</span>] = listsHeap[i*<span class="number">2</span>],listsHeap[i]</span><br><span class="line">                        i = i*<span class="number">2</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        listsHeap[i],listsHeap[i*<span class="number">2</span>+<span class="number">1</span>] = listsHeap[i*<span class="number">2</span>+<span class="number">1</span>],listsHeap[i]</span><br><span class="line">                        i = i*<span class="number">2</span>+<span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> </span><br><span class="line">            <span class="keyword">elif</span> i*<span class="number">2</span>+<span class="number">1</span> == <span class="built_in">len</span>(listsHeap):</span><br><span class="line">                <span class="keyword">if</span> listsHeap[i*<span class="number">2</span>].val &lt; listsHeap[i].val:</span><br><span class="line">                    listsHeap[i],listsHeap[i*<span class="number">2</span>] = listsHeap[i*<span class="number">2</span>],listsHeap[i]</span><br><span class="line">                i = i*<span class="number">2</span> </span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure></p>
<hr />
<p>参考：http://blog.csdn.net/linhuanmars/article/details/19899259</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(26)--消除有序数组中重复值(常数空间)</title>
    <url>/2016/03/31/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(26)--%E6%B6%88%E9%99%A4%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E9%87%8D%E5%A4%8D%E5%80%BC(%E5%B8%B8%E6%95%B0%E7%A9%BA%E9%97%B4)/</url>
    <content><![CDATA[<p>原题如下： &gt;Given a sorted array, remove the duplicates in place
such that each element appear only once and return the new length. Do
not allocate extra space for another array, you must do this in place
with constant memory. <span id="more"></span> &gt;For example, Given input array
nums = [1,1,2],</p>
<blockquote>
<p>Your function should return length = 2, with the first two elements
of nums being 1 and 2 respectively. It doesn't matter what you leave
beyond the new length.</p>
</blockquote>
<p>题目不难理解，但是要注意的是除了返回length以外，对原来数组的元素也要处理，因为LeetCode的评测是根据你给出的length去读取原来数组的前length个元素。</p>
<p>注意题目要求的空间复杂度是常数，这意味着不能新建一个数组来存放不重复元素。</p>
<p>实现思路是<strong>双指针，就是先用一个整数count来维护已经选出的不重复的元素的个数，同时count也作为数组下标。然后另外一个指针遍历数组，找到与当前数组下标为count的元素不重复的元素，交换两者即可</strong>。</p>
<p>因为数组已经排列了，所以后面的元素肯定会比前面的要大。所以假如给出的数组是无序的同时要实现这个功能，那么可以先排序再使用上面的方法。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeDuplicates</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br><span class="line">        </span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> nums[i] == nums[count]:</span><br><span class="line">                count+=<span class="number">1</span></span><br><span class="line">                nums[count]=nums[i]</span><br><span class="line">        <span class="keyword">return</span> count+<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(27)--双指针找数组所有特定元素</title>
    <url>/2016/03/31/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(27)--%E5%8F%8C%E6%8C%87%E9%92%88%E6%89%BE%E6%95%B0%E7%BB%84%E6%89%80%E6%9C%89%E7%89%B9%E5%AE%9A%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<p>原题如下： &gt;Given an array and a value, remove all instances of
that value in place and return the new length.</p>
<blockquote>
<p>Do not allocate extra space for another array, you must do this in
place with constant memory. <span id="more"></span> The order of elements can be
changed. It doesn't matter what you leave beyond the new length.</p>
</blockquote>
<blockquote>
<p>Example: Given input array nums = [3,2,2,3], val = 3</p>
</blockquote>
<blockquote>
<p>Your function should return length = 2, with the first two elements
of nums being 2.</p>
</blockquote>
<p>实现思路：<strong>双指针遍历，指针1从前往后遍历，指针2从后往前遍历。</strong>指针2先往前找到<strong>与val值不同</strong>的元素，然后停止；接着指针1开始往后找到<strong>与val相同</strong>的元素，然后指针1和指针2的元素交换，这样便把与val值相同的元素全部扔到了数组末尾。</p>
<p>需要注意的是，虽然该数组提供了删除元素的操作，但是删除一个元素的平均时间复杂度是<span
class="math inline">\(O(n)\)</span>,总的时间复杂度为<span
class="math inline">\(O(n^2)\)</span></p>
<p>还需要注意的是一个溢出的问题，对于一般的编译型语言如Java、C++等int是4个字节的，所以int的范围是<span
class="math inline">\(-2^{31}\)</span> ~ <span
class="math inline">\(2^{31}-1\)</span>,但是在python中int在32位系统上占四个字节，在64为系统上占8个字节，可通过<code>sys.maxint</code>查看，而在本题中默认就是4个字节，如果溢出时输出<code>sys.maxint</code>会报错。</p>
<p>实现代码如下: <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeElement</span>(<span class="params">self, nums, val</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type val: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        l = <span class="number">0</span></span><br><span class="line">        r = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l&lt;r:</span><br><span class="line">            <span class="keyword">if</span> nums[r] == val:</span><br><span class="line">                r-=<span class="number">1</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> nums[l] == val:</span><br><span class="line">                nums[l],nums[r] = nums[r],nums[l]</span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">                r -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> l == r: <span class="comment"># 有可能l&gt;r</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> nums[l] == val:</span><br><span class="line">                l+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> l</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(3)--双指针找最长不重复子串</title>
    <url>/2016/01/08/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(3)--%E5%8F%8C%E6%8C%87%E9%92%88%E6%89%BE%E6%9C%80%E9%95%BF%E4%B8%8D%E9%87%8D%E5%A4%8D%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/longest-substring-without-repeating-characters/">原题</a>如下</p>
<blockquote>
<p>Given a string, find the length of the longest substring without
repeating characters. For example, the longest substring without
repeating letters for "abcabcbb" is "abc", which the length is 3. For
"bbbbb" the longest substring is "b", with the length of 1.</p>
</blockquote>
<span id="more"></span>
<p>这道题是典型的找最长子字符串问题，就是要找出没有重复的最长子字符串。本文讲述了两种方法，一种时间复杂度为<span
class="math inline">\(O(n^2)\)</span>，另一种的时间复杂度为<span
class="math inline">\(O(n)\)</span></p>
<p>最容易想到的方法就是遍历整个字符串，找出以每个字符开头的最长子字符串，再从中找出最长的子字符串。这样的时间复杂度是<span
class="math inline">\(O(n^2)\)</span>，实现代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">max</span>=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span>  i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">           tmp=[]</span><br><span class="line">           tmp.append(s[i])</span><br><span class="line">           <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,<span class="built_in">len</span>(s)):</span><br><span class="line">               <span class="keyword">if</span> s[j] <span class="keyword">not</span> <span class="keyword">in</span> tmp:</span><br><span class="line">                   tmp.append(s[j])</span><br><span class="line">               <span class="keyword">else</span>:</span><br><span class="line">                   <span class="keyword">if</span> <span class="built_in">len</span>(tmp)&gt;<span class="built_in">max</span>:</span><br><span class="line">                       <span class="built_in">max</span>=<span class="built_in">len</span>(tmp)</span><br><span class="line">                       <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span></span><br></pre></td></tr></table></figure>
<p>这种方法虽然易于理解，但是由于时间复杂度问题，运行超时。</p>
<p>现在再分析一下题目，<strong>是否有必要计算以每个字符开头的最长子字符串</strong>？</p>
<p>答案是不必要的。比如说对于字符串<code>abcdedfghi</code>,从a开始往后进行判断，则遇到第二个d的时候会发现与前面的d重复了，判断停止，那么以a开头的最长子字符串为<code>abcde</code>，然后以一个新的字母开头找最长的子字符串。按照上面的方法，接下来会以b为开头找其最长子字符串。但是你会发现找到的最长子字符串肯定比以a开头的最长子字符串要短，原因是后面重复的元素位置没有变，而从b或c开始相当于把不重复的部分截断了。所以<strong>如果要找到可能更长的子字符串，必须要从与当前字符重复的字符往后的一个字符位置开始找</strong>，在本例中就是要从e开始找，才有可能找得到比以a开头的最长子字符串更长的子字符串。</p>
<p>这样，便可以通过找与当前字符重复的前一字符的位置来避免第二层的for循环，将时间复杂度缩短为<span
class="math inline">\(O(n)\)</span></p>
<p>通过双指针能够实现上面的功能，左右指针共同维护一个没有重复字符的子字符串，每当没有重复字符时，右指针一直往右移动；有重复字符时左指针往右移动直到左右指针之间没有重复字符。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        left, right, n = <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(s)</span><br><span class="line">        visited, result = <span class="built_in">set</span>(), <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> right &lt; n:</span><br><span class="line">            <span class="keyword">if</span> s[right] <span class="keyword">in</span> visited:</span><br><span class="line">                <span class="keyword">while</span> s[right] <span class="keyword">in</span> visited:</span><br><span class="line">                    visited.remove(s[left])</span><br><span class="line">                    left += <span class="number">1</span></span><br><span class="line">                visited.add(s[right])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                visited.add(s[right])</span><br><span class="line">                result = <span class="built_in">max</span>(right-left+<span class="number">1</span>, result)</span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<p>上面的方法虽然能够AC,但是每次遇到重复元素时左指针往右一步一步地移动并删除元素的操作会比较慢，因此可以
<strong>通过 <code>HashTable</code>
存储每个元素的最大下标，遇到重复元素的时候判断前一重复元素位置的下标是否大于当前左指针位置，若是则更新左指针，否则不更新；同时更新<code>HashTable</code>
当前重复元素的下标</strong>。下面是实现的代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        left, right,result= <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        indices = &#123;&#125;</span><br><span class="line">        <span class="keyword">while</span> right &lt; <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="keyword">if</span> s[right] <span class="keyword">in</span> indices <span class="keyword">and</span> indices[s[right]] &gt;= left:</span><br><span class="line">                result = <span class="built_in">max</span>(result, right - left)</span><br><span class="line">                left = indices[s[right]] + <span class="number">1</span></span><br><span class="line">            indices[s[right]] = right</span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(result, right - left)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(29)--通过加法完成除法</title>
    <url>/2016/04/01/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(29)--%E9%80%9A%E8%BF%87%E5%8A%A0%E6%B3%95%E5%AE%8C%E6%88%90%E9%99%A4%E6%B3%95/</url>
    <content><![CDATA[<p>原题如下： &gt;Divide two integers without using multiplication,
division and mod operator.</p>
<blockquote>
<p>If it is overflow, return MAX_INT.</p>
</blockquote>
<span id="more"></span>
<p>题目要求返回一个数除以另外一个数的结果，并且要求不能用乘除或取模，意思就是只能用加减，用加减也不难，先初始化sum=0，每次sum加上除数的大小并与被除数比较，直到sum大于等于被除数即可。但是这样的时间复杂度是<span
class="math inline">\(\Theta(n)\)</span>，提交时会超时。</p>
<p>解决思路是采用<strong>二分搜索</strong>，或者说变形的二分搜索。思路类似于上面所说的，但是<strong>sum每次加上自己的大小</strong>，也相当于sum=sum*2,这样的时间复杂度是<span
class="math inline">\(\Theta(log_2n)\)</span>,提交时能够AC</p>
<p>实现的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">divide</span>(<span class="params">self, dividend, divisor</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type dividend: int</span></span><br><span class="line"><span class="string">        :type divisor: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        MAX_INT = <span class="built_in">pow</span>(<span class="number">2</span>,<span class="number">31</span>)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> divisor == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> MAX_INT</span><br><span class="line">    </span><br><span class="line">        flag = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> (dividend &gt; <span class="number">0</span> <span class="keyword">and</span> divisor&lt;<span class="number">0</span> ) <span class="keyword">or</span> (dividend&lt;<span class="number">0</span> <span class="keyword">and</span> divisor &gt;<span class="number">0</span>):</span><br><span class="line">            flag = -<span class="number">1</span></span><br><span class="line">        a = <span class="built_in">abs</span>(dividend)</span><br><span class="line">        b = <span class="built_in">abs</span>(divisor)</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> a &gt;= b :</span><br><span class="line">            <span class="built_in">sum</span> = b</span><br><span class="line">            count =<span class="number">1</span> </span><br><span class="line">            <span class="keyword">while</span> a &gt;= <span class="built_in">sum</span>+<span class="built_in">sum</span>:</span><br><span class="line">                <span class="built_in">sum</span> += <span class="built_in">sum</span></span><br><span class="line">                count += count</span><br><span class="line">            a-=<span class="built_in">sum</span></span><br><span class="line">            res+=count</span><br><span class="line">        <span class="keyword">if</span> res*flag &gt; MAX_INT:</span><br><span class="line">            <span class="keyword">return</span> MAX_INT</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> res*flag</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(31)--数字排列的下一项</title>
    <url>/2016/04/04/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(31)--%E6%95%B0%E5%AD%97%E6%8E%92%E5%88%97%E7%9A%84%E4%B8%8B%E4%B8%80%E9%A1%B9/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/next-permutation/">原题</a>如下：
&gt;Implement next permutation, which rearranges numbers into the
lexicographically next greater permutation of numbers. <span id="more"></span>
&gt;If such arrangement is not possible, it must rearrange it as the
lowest possible order (ie, sorted in ascending order).</p>
<blockquote>
<p>The replacement must be in-place, do not allocate extra memory.</p>
</blockquote>
<blockquote>
<p>Here are some examples. Inputs are in the left-hand column and its
corresponding outputs are in the right-hand column. 1,2,3 → 1,3,2 3,2,1
→ 1,2,3 1,1,5 → 1,5,1</p>
</blockquote>
<p>题目的意思就是对给出的数字list进行排列组合并从小到大排序，找出给出的list组成的数字的下一个数。</p>
<p>实现的时候当然不会弄得像上面说的这么复杂，只需要对给出的list从后往前遍历，找到第一个当前数字(记为i)比前一数字(记为j)大的那个数字，然后从这个位置往后的数字中找到一个<code>&gt;j&amp;&amp;&lt;=i</code>的最小的数字，交换两者后再对i后面的数字排序即可，说起来比较拗口。下面举个简单的例子。</p>
<p>假如给出的list是<code>[1,2,5,4,3]</code>,找到的i=5，j=2,然后将i后面大于j且小于等于i的最小数字与j交换，这里是3，也就是交换后的list是<code>[1,3,5,4,2]</code>,然后对i后面的数字进行排序，排序后为<code>[1,3,2,4,5]</code>，也是我们得到的结果。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nextPermutation</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: void Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>  </span><br><span class="line">        i = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        flag = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> nums[i] &gt; nums[i-<span class="number">1</span>]:</span><br><span class="line">                <span class="comment"># 往后找大于nums[i-1]且小于nums[i]的数与nums[i-1]交换</span></span><br><span class="line">                j = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span> j&gt;i:</span><br><span class="line">                    <span class="keyword">if</span> nums[i-<span class="number">1</span>]&lt;nums[j]&lt;nums[i]:</span><br><span class="line">                        nums[j],nums[i-<span class="number">1</span>] = nums[i-<span class="number">1</span>],nums[j]</span><br><span class="line">                        flag = <span class="number">1</span></span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    j-=<span class="number">1</span></span><br><span class="line">                        </span><br><span class="line">                <span class="comment"># 找不到这样的数</span></span><br><span class="line">                <span class="keyword">if</span> flag == <span class="number">0</span>:</span><br><span class="line">                    nums[i],nums[i-<span class="number">1</span>] = nums[i-<span class="number">1</span>],nums[i]</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 交换后对i后面的元素进行排序</span></span><br><span class="line">                nums[i:] = <span class="built_in">sorted</span>(nums[i:])</span><br><span class="line">                <span class="keyword">return</span>                 </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i-=<span class="number">1</span></span><br><span class="line">        nums.sort()  <span class="comment"># 重新从小到大排序</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(30)--双指针找拼接子字符串</title>
    <url>/2016/04/04/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(30)--%E5%8F%8C%E6%8C%87%E9%92%88%E6%89%BE%E6%8B%BC%E6%8E%A5%E5%AD%90%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/substring-with-concatenation-of-all-words/">原题</a>如下：
&gt;You are given a string, s, and a list of words, words, that are all
of the same length. Find all starting indices of substring(s) in s that
is a concatenation of each word in words exactly once and without any
intervening characters. <span id="more"></span> &gt;For example, given: s:
"barfoothefoobarman" words: ["foo", "bar"]</p>
<blockquote>
<p>You should return the indices: [0,9]. (order does not matter).</p>
</blockquote>
<p>题目不难理解，实现也不难，关键是<strong>时间复杂度的控制</strong>。下面会讲述两种方法，第一种方法时间复杂度<span
class="math inline">\(O((n-k)*k)\)</span>,其中n为s的长度，k为所有的words拼接起来后的长度，这种方法提交时在TLE和AC间徘徊（即偶尔AC，偶尔TLE）。第二种方法时间复杂度为O(n)，提交的时候能够AC。</p>
<h2 id="方法一">方法一</h2>
<h3 id="思路">思路</h3>
<p>设wordLen为给出的words列表中每个词的长度，wordNum为给出的words列表的长度，n为给出的s的长度。</p>
<p>那么可以<strong>从头开始遍历s直到n-wordLen*wordNum+1，每次遍历用一个字典存储遍历中遇到的属于words的词语，并检查两者对应的词语的数量关系。遇到不属于words的词语或者字典中的某一词语的数量大于words中该词语的数量则跳出执行下一次的遍历</strong></p>
<p>这种方法的时间复杂度<span
class="math inline">\(O((n-k)*k)\)</span>，n为s的长度。提交时偶尔TLE，偶尔AC，AC时显示的时间是876ms。
### 实现代码： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findSubstring</span>(<span class="params">self, s, words</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :type words: List[str]</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 注意words中的词可能会重复</span></span><br><span class="line">        wordDict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> wordDict:</span><br><span class="line">                wordDict[word] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                wordDict[word] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        wordLen = <span class="built_in">len</span>(words[<span class="number">0</span>])</span><br><span class="line">        result = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)-wordLen*wordNum+<span class="number">1</span>):</span><br><span class="line">            tmp = s[i:i+wordLen]</span><br><span class="line">            tmpDict = &#123;&#125; <span class="comment"># 存储words的临时list</span></span><br><span class="line">            <span class="keyword">if</span> tmp <span class="keyword">in</span> words:                </span><br><span class="line">                head = i</span><br><span class="line">                <span class="keyword">while</span> tmp <span class="keyword">in</span> words <span class="keyword">and</span> i &lt; <span class="built_in">len</span>(s)-wordLen+<span class="number">1</span>:            </span><br><span class="line">                    <span class="keyword">if</span> tmp <span class="keyword">in</span> tmpDict:</span><br><span class="line">                        tmpDict[tmp] += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        tmpDict[tmp] = <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> tmpDict[tmp] &gt; wordDict[tmp]:</span><br><span class="line">                        tmpDict[tmp] -= <span class="number">1</span></span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                    i += wordLen</span><br><span class="line">                    tmp = s[i:i+wordLen]</span><br><span class="line">                <span class="keyword">if</span> tmpDict == wordDict:</span><br><span class="line">                    result.append(head)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">continue</span>         </span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<h2 id="方法二">方法二</h2>
<h3 id="思路-1">思路</h3>
<p>这种方法参考了<a
href="https://leetcode.com/discuss/20151/an-o-n-solution-with-detailed-explanation.html">这里</a>,主要思想是<strong>利用了双指针围着当前符合words（包括数量和种类）中的连续子字符串，同时计算围着的子字符串中word的数量。</strong></p>
<p>巧妙的地方在于双指针当前包围的子字符串中如果含有某个word的数量大于words中这个word的数量时，移动左指针直到把这个word的数量减少。</p>
<p>这种方法的时间复杂度为O(n),提交时AC的时间约100ms</p>
<h3 id="实现代码">实现代码</h3>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findSubstring</span>(<span class="params">self, s, words</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :type words: List[str]</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 注意words中的词可能会重复</span></span><br><span class="line">        wordDict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> wordDict:</span><br><span class="line">                wordDict[word] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                wordDict[word] = <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        wordLen = <span class="built_in">len</span>(words[<span class="number">0</span>])</span><br><span class="line">        wordNum = <span class="built_in">len</span>(words)</span><br><span class="line">        wordSet = <span class="built_in">set</span>(words)</span><br><span class="line">        sLen = <span class="built_in">len</span>(s)</span><br><span class="line">        result = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(wordLen): </span><br><span class="line">            left = i</span><br><span class="line">            tmpDict = &#123;&#125;</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            j=i</span><br><span class="line">            <span class="keyword">while</span> j &lt; sLen-wordLen+<span class="number">1</span>: </span><br><span class="line">                tmp = s[j:j+wordLen]</span><br><span class="line">                j += wordLen</span><br><span class="line">                <span class="keyword">if</span> tmp <span class="keyword">in</span> wordSet:</span><br><span class="line">                    <span class="keyword">if</span> tmp <span class="keyword">in</span> tmpDict:</span><br><span class="line">                        tmpDict[tmp]+=<span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        tmpDict[tmp]=<span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> tmpDict[tmp]&lt;=wordDict[tmp]:</span><br><span class="line">                        count+=<span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># 某个词的数量比wordDict中规定的要多了，往右移动左指针</span></span><br><span class="line">                        <span class="keyword">while</span> tmpDict[tmp] &gt; wordDict[tmp]:</span><br><span class="line">                            t = s[left:left+wordLen]</span><br><span class="line">                            left += wordLen</span><br><span class="line">                            tmpDict[t] -= <span class="number">1</span></span><br><span class="line">                            <span class="keyword">if</span> tmpDict[t] &lt; wordDict[t]:</span><br><span class="line">                                count -= <span class="number">1</span></span><br><span class="line">                    <span class="comment"># 仅去掉最左边的一个word，再往右找</span></span><br><span class="line">                    <span class="keyword">if</span> count == wordNum:</span><br><span class="line">                        result.append(left)</span><br><span class="line">                        t = s[left:left+wordLen]</span><br><span class="line">                        tmpDict[t] -= <span class="number">1</span></span><br><span class="line">                        left += wordLen</span><br><span class="line">                        count -= <span class="number">1</span>  </span><br><span class="line">                <span class="comment"># 当前的词不在wordDict                        </span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    tmpDict = &#123;&#125;</span><br><span class="line">                    count = <span class="number">0</span> </span><br><span class="line">                    left = j</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(32)--最长合法的子括号串</title>
    <url>/2016/04/06/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(32)--%E6%9C%80%E9%95%BF%E5%90%88%E6%B3%95%E7%9A%84%E5%AD%90%E6%8B%AC%E5%8F%B7%E4%B8%B2/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/longest-valid-parentheses/">原题</a>如下：
&gt;Given a string containing just the characters '(' and ')', find the
length of the longest valid (well-formed) parentheses substring.
<span id="more"></span> &gt;For "(()", the longest valid parentheses substring is
"()", which has length = 2.</p>
<blockquote>
<p>Another example is ")()())", where the longest valid parentheses
substring is "()()", which has length = 4.</p>
</blockquote>
<p>题目的要求从给出的包含括号的string中找到最长的合法string。</p>
<p>最暴力的方法就是从长到短遍历string中的所有可能的subString，再判断subString是否合法，这种方法的时间复杂度是<span
class="math inline">\(O(n^3)\)</span>，提交时TLE。</p>
<p><strong>两种比较巧妙的方法的方法的时间复杂度都是O(n)，一种是动态规划，一种是利用栈存储不合法的括号的位置。</strong></p>
<p>下面分别列出这三种方法</p>
<h2 id="方法一暴力枚举时间复杂度on3">方法一，暴力枚举，时间复杂度<span
class="math inline">\(O(n^3)\)</span></h2>
<p>虽然容易理解，答案也正确，但是提交超时 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestValidParentheses</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s)&lt;<span class="number">2</span>:</span><br><span class="line">           <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                left+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> s[i] == <span class="string">&#x27;)&#x27;</span>:</span><br><span class="line">                right+=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        m = <span class="built_in">min</span>(left,right)</span><br><span class="line">        </span><br><span class="line">        cut = <span class="built_in">len</span>(s)-<span class="number">2</span>*m <span class="comment"># 从长到短遍历</span></span><br><span class="line">        <span class="keyword">while</span> cut&lt;=<span class="built_in">len</span>(s)-<span class="number">2</span>:</span><br><span class="line">            subLen = <span class="built_in">len</span>(s) - cut</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cut+<span class="number">1</span>):</span><br><span class="line">                subStr = s[i:i+subLen]</span><br><span class="line">                <span class="keyword">if</span> subStr[<span class="number">0</span>] == <span class="string">&#x27;)&#x27;</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> self.isValid(subStr):</span><br><span class="line">                    <span class="keyword">return</span> subLen</span><br><span class="line">            cut +=<span class="number">2</span>        </span><br><span class="line">    <span class="comment"># 判断子字符串是否有效        </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isValid</span>(<span class="params">self,s</span>):</span><br><span class="line">        stack = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                stack.append(<span class="string">&#x27;(&#x27;</span>)</span><br><span class="line">            <span class="keyword">elif</span> s[i] == <span class="string">&#x27;)&#x27;</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(stack)&gt;<span class="number">0</span>:</span><br><span class="line">                    stack.pop(<span class="built_in">len</span>(stack)-<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(stack)==<span class="number">0</span> <span class="keyword">and</span> i==<span class="built_in">len</span>(s)-<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<h2 id="方法二动态规划时间复杂度on">方法二，动态规划，时间复杂度<span
class="math inline">\(O(n)\)</span></h2>
<p>DP会先建立一个longest列表，其中<strong>longest[i] 代表以 s[i]
结尾的最长合法串的长度</strong>。这样便有了以下判断条件：</p>
<ul>
<li>假如 <code>s[i]=(</code> ，那么longest[i]=0</li>
<li>假如 <code>s[i]=) &amp;&amp; s[i-1]=(</code> ,
那么longest[i]=longest[i-2]+2</li>
<li>假如
<code>s[i]=) &amp;&amp; s[i-1]=) &amp;&amp; s[i-longest[i-1]-1]==(</code>
,那么longest[i]=longest[i-longest[i-1]-2]+longest[i-1]+2</li>
<li>假如上面情况都不符合那么，longest[i] = 0</li>
</ul>
<p>实现代码如下,提交时能够AC： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestValidParentheses</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        longest = []</span><br><span class="line">        longest.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                longest.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> i-<span class="number">1</span>&gt;=<span class="number">0</span> <span class="keyword">and</span> s[i-<span class="number">1</span>]==<span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                    longest.append(longest[i-<span class="number">2</span>]+<span class="number">2</span>)</span><br><span class="line">                <span class="keyword">elif</span> i-<span class="number">1</span>&gt;=<span class="number">0</span> <span class="keyword">and</span> s[i-<span class="number">1</span>]==<span class="string">&#x27;)&#x27;</span> <span class="keyword">and</span> i-longest[i-<span class="number">1</span>]-<span class="number">1</span> &gt;=<span class="number">0</span> <span class="keyword">and</span> s[i-longest[i-<span class="number">1</span>]-<span class="number">1</span>]==<span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                    tmp = longest[i-longest[i-<span class="number">1</span>]-<span class="number">2</span>] <span class="keyword">if</span> i-longest[i-<span class="number">1</span>]-<span class="number">2</span>&gt;=<span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">                    longest.append(longest[i-<span class="number">1</span>]+<span class="number">2</span>+tmp)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    longest.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(longest)</span><br><span class="line"> </span><br></pre></td></tr></table></figure></p>
<h2
id="方法三通过栈存储不合法的括号位置时间复杂度on">方法三，通过栈存储不合法的括号位置，时间复杂度<span
class="math inline">\(O(n)\)</span></h2>
<p>这种方法通过栈来存储不合法的括号的<strong>位置</strong>。</p>
<p>具体流程是先遍历字符串s，遇到左括号就将位置其入栈，遇到右括号就检查栈顶是否有左括号号，有的话就弹出这个左括号，否则将右括号的位置入栈。最后得到的栈中的元素就是原来str中不合法的括号的位置，那么栈中相邻位置的元素的差值就是一个合法的括号串的长度，找到其中最大值即可。</p>
<p>需要注意的是最后遍历栈找最长合法串时需要在最左边和最右边分别加上<code>-1</code>和<code>len(s)</code>(s就是原字符串的长度)，目的是为了当原字符串最左边或最右边的括号均为合法时能够被计算长度。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestValidParentheses</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        maxLen = <span class="number">0</span></span><br><span class="line">        stack=[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">&#x27;)&#x27;</span> <span class="keyword">and</span> <span class="built_in">len</span>(stack)&gt;<span class="number">0</span> <span class="keyword">and</span> s[stack[-<span class="number">1</span>]]==<span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                stack.pop(<span class="built_in">len</span>(stack)-<span class="number">1</span>)</span><br><span class="line">                maxLen = <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                stack.append(i)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 全匹配        </span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(stack) == <span class="number">0</span>: </span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(s)</span><br><span class="line">        <span class="comment"># 不在不匹配的要在头尾插入元素来计算头或尾匹配的括号</span></span><br><span class="line">        stack.append(<span class="built_in">len</span>(s))</span><br><span class="line">        stack.insert(<span class="number">0</span>,-<span class="number">1</span>)</span><br><span class="line">        j = <span class="built_in">len</span>(stack)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> j&gt;<span class="number">0</span>:</span><br><span class="line">            maxLen = <span class="built_in">max</span>(maxLen,stack[j]-stack[j-<span class="number">1</span>]-<span class="number">1</span>)</span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> maxLen</span><br></pre></td></tr></table></figure></p>
<p>参考：
【1】https://leetcode.com/discuss/7609/my-o-n-solution-using-a-stack
【2】https://leetcode.com/discuss/8092/my-dp-o-n-solution-without-using-stack</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>栈</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(33,81,153,154)--二分搜索找旋转数组特定值</title>
    <url>/2016/04/08/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(33)--%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%89%BE%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%E7%89%B9%E5%AE%9A%E5%80%BC/</url>
    <content><![CDATA[<p>本文主要讲述如何在一个<code>Rotated Sorted Array</code>中找到特定的值，<code>Rotated Sorted Array</code>指旋转了的数组，如<code>4 5 6 7 0 1 2</code>就是<code>0 1 2 4 5 6 7</code>的一个旋转数组。正常情况下遍历一遍即可，但是这样的时间复杂度为<span
class="math inline">\(O(n)\)</span>,但是本文主要讲述通过二分查找将时间复杂度降到<span
class="math inline">\(O(log_2n)\)</span>。</p>
<span id="more"></span>
<p>本文主要以LeetCode上的四道题目为例讲解,分别是</p>
<p><a
href="https://leetcode.com/problems/search-in-rotated-sorted-array/">33.
Search in Rotated Sorted Array</a> <a
href="https://leetcode.com/problems/search-in-rotated-sorted-array-ii/">81.
Search in Rotated Sorted Array II</a> <a
href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/">153.
Find Minimum in Rotated Sorted Array</a> <a
href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array-ii/">154.
Find Minimum in Rotated Sorted Array II</a></p>
<p>其中33、81是在<code>Rotated Sorted Array</code>找出给定的值，不同的地方在于33中没有重复元素，而81中有重复的元素；153、154则是在<code>Rotated Sorted Array</code>中找到最小值，区别也是一个有重复元素而另一个没有。</p>
<h2 id="search-in-rotated-sorted-array1"><a
href="https://leetcode.com/problems/search-in-rotated-sorted-array/">33.
Search in Rotated Sorted Array</a></h2>
<p>对于一个<code>Rotated Sorted Array</code>，每次的binary
search查找的中间元素都会将原来的list分为两个lists,<strong>其中的一个list肯定是有序</strong>的，可以判断目标元素是否在这个有序的list中，如果在这个list则在这个list内进行二分查找，否则在另外一个list内找。</p>
<p>这种方法时间复杂度为<span
class="math inline">\(O(log_2n)\)</span>。实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, nums, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        left = <span class="number">0</span> </span><br><span class="line">        right = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left + right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                <span class="keyword">return</span> mid</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">if</span> nums[left] &lt;= nums[mid]:</span><br><span class="line">                <span class="keyword">if</span> nums[left]&lt;=target&lt;=nums[mid]:</span><br><span class="line">                    right = mid - <span class="number">1</span>   <span class="comment"># mid要减去1，否则两个元素的时候会导致死循环</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    left = mid+<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> nums[mid] &lt;= nums[right]:</span><br><span class="line">                <span class="keyword">if</span> nums[mid]&lt;=target&lt;=nums[right]:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    right = mid - <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> nums[left] == target:</span><br><span class="line">            <span class="keyword">return</span> left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="search-in-rotated-sorted-array-ii2"><a
href="https://leetcode.com/problems/search-in-rotated-sorted-array-ii/">81.
Search in Rotated Sorted Array II</a></h2>
<p>这个问题的解决思路同上面的类似，但是因为有可能存在重复的元素，所以每次
binary search 后分成的两个lists中不一定存在一个有序的 list，
这时候就需要两个list都遍历了，所以这种方法最差情况下的时间复杂度为<code>O(n)</code>。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, nums, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> self.helper(nums, <span class="number">0</span>, n-<span class="number">1</span>,target):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self,nums,left,right,target</span>):</span><br><span class="line">        <span class="keyword">if</span> left &gt; right:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> left == right:</span><br><span class="line">            <span class="keyword">return</span> nums[left] == target</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mid = (left+right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span>  nums[left]&lt;=target&lt;nums[mid]:</span><br><span class="line">                <span class="keyword">return</span> self.helper(nums,left,mid-<span class="number">1</span>,target)</span><br><span class="line">            <span class="keyword">elif</span> nums[mid]&lt;target&lt;=nums[right]:</span><br><span class="line">                <span class="keyword">return</span> self.helper(nums,mid+<span class="number">1</span>,right,target)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self.helper(nums,mid+<span class="number">1</span>,right,target) <span class="keyword">or</span> self.helper(nums,left,mid-<span class="number">1</span>,target)</span><br></pre></td></tr></table></figure></p>
<h2 id="find-minimum-in-rotated-sorted-array3"><a
href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/">153.
Find Minimum in Rotated Sorted Array</a></h2>
<p>本题需要求
<code>Rotated Sorted Array</code>中最小的元素，且<code>Rotated Sorted Array</code>中没有重复元素。关键点在于每次将<code>nums[(left+right)/2]</code>与<code>nums[right]</code>比较，假如<code>nums[(left+right)/2]&gt;nums[right]</code>,则最小值在<code>nums[(left+right)/2:right]</code>中，反之在另一半元素中。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMin</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left+right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[right] &lt; nums[mid]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = mid</span><br><span class="line">        <span class="keyword">return</span> nums[left]</span><br></pre></td></tr></table></figure></p>
<p>通过找到最小元素，也可以解决上面提到的问题<a
href="https://leetcode.com/problems/search-in-rotated-sorted-array/">33.
Search in Rotated Sorted
Array</a>，就是<strong>先用二分搜索找到最小元素的下标，最小元素的下标会将原来的list分为两个sorted
list，判断target在哪个sorted list然后对这个sorted
list进行二分查找即可</strong>。</p>
<p>这种方法对array进行了两次二分查找</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, nums, target</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type target: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        left = <span class="number">0</span> </span><br><span class="line">        right = <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left&lt;right:</span><br><span class="line">            mid = (left+ right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid]&gt;nums[right]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = mid</span><br><span class="line">        minIndex = left</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> minIndex == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> nums[minIndex]&lt;=target&lt;= nums[<span class="built_in">len</span>(nums)-<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> self.binarySearch(minIndex,<span class="built_in">len</span>(nums)-<span class="number">1</span>,nums,target)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> nums[<span class="number">0</span>]&lt;= target&lt;=nums[minIndex-<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> self.binarySearch(<span class="number">0</span>,minIndex-<span class="number">1</span>,nums,target)</span><br><span class="line">            <span class="keyword">elif</span> nums[minIndex]&lt;= target&lt;=nums[<span class="built_in">len</span>(nums)-<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> self.binarySearch(minIndex,<span class="built_in">len</span>(nums)-<span class="number">1</span>,nums,target)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对一个sorted list的经典二分查找</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">binarySearch</span>(<span class="params">self,left,right,nums,target</span>):</span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left + right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == target:</span><br><span class="line">                <span class="keyword">return</span> mid</span><br><span class="line">            <span class="keyword">elif</span> nums[mid]&gt;target:</span><br><span class="line">                right = mid -<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = mid+<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> nums[left] == target:</span><br><span class="line">            <span class="keyword">return</span> left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2 id="find-minimum-in-rotated-sorted-array-ii4"><a
href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array-ii/">154.
Find Minimum in Rotated Sorted Array II</a></h2>
<p>这个问题跟<a
href="https://leetcode.com/problems/find-minimum-in-rotated-sorted-array/">153.
Find Minimum in Rotated Sorted
Array</a>不同的地方是<code>Rotated Sorted Array</code>中可能存在重复的元素，虽然也可以通过二分搜索解决，但是最差的情况下的时间复杂度也是<code>O(n)</code>,最差的情况下就是<code>nums[left]=nums[mid]=nums[right]</code>,这是无法确定最小元素在那一边，因此两边都要搜索。下面给出两种实现方法：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># method 1</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMin</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left+right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[right] &lt; nums[mid]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums[right] &gt; nums[mid]:</span><br><span class="line">                right = mid</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> nums[mid] == nums[left]:</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">sum</span>(nums[left:mid+<span class="number">1</span>]) == nums[mid] * (mid-left+<span class="number">1</span>):</span><br><span class="line">                        left = mid + <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        right = mid</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    right = mid</span><br><span class="line">        <span class="keyword">return</span> nums[left]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMin</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left+right)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[right] &lt; nums[mid]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums[right] &gt; nums[mid]:</span><br><span class="line">                right = mid</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> nums[left]       </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>二分搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(37)--回溯法解决数独问题</title>
    <url>/2016/04/15/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(37)--%E5%9B%9E%E6%BA%AF%E6%B3%95%E8%A7%A3%E5%86%B3%E6%95%B0%E7%8B%AC/</url>
    <content><![CDATA[<p><a href="https://leetcode.com/problems/sudoku-solver/">原题</a>如下：
&gt;Write a program to solve a Sudoku puzzle by filling the empty
cells.</p>
<blockquote>
<p>Empty cells are indicated by the character '.'. <span id="more"></span> You may
assume that there will be only one unique solution.</p>
</blockquote>
<blockquote>
<p><img
src="https://wulc.me/imgs/250px-Sudoku-by-L2G-20050714.svg.png" /></p>
</blockquote>
<blockquote>
<p>A sudoku puzzle...</p>
</blockquote>
<blockquote>
<p><img
src="https://wulc.me/imgs/250px-Sudoku-by-L2G-20050714_solution.svg.png" /></p>
</blockquote>
<p>题目要求解决一个给定的数独，且每个数独的答案唯一。</p>
<p><strong>解题思路如下</strong>：采用<strong>回溯法</strong>，每插入一个数之前检查插入这个数之后是否有效。假如有效就插入并且保留当前插入了这个数的状态。以保证后面插入的数无效的时候能够回溯到当前这个状态，修改当前状态插入的数。实现这种状态的保存与回溯可以通过递归实现。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">solveSudoku</span>(<span class="params">self, board</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type board: List[List[str]]</span></span><br><span class="line"><span class="string">        :rtype: void Do not return anything, modify board in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.helper(board)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self, board</span>):</span><br><span class="line">        num = <span class="built_in">len</span>(board)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">                <span class="keyword">if</span> board[i][j] == <span class="string">&#x27;.&#x27;</span>:</span><br><span class="line">                    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>):</span><br><span class="line">                        c = <span class="built_in">str</span>(t)</span><br><span class="line">                        <span class="keyword">if</span> self.is_valid(board, c, i, j):</span><br><span class="line">                            board[i][j] = c</span><br><span class="line">                            <span class="keyword">if</span> self.helper(board):</span><br><span class="line">                                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                            <span class="keyword">else</span>:</span><br><span class="line">                                board[i][j] = <span class="string">&#x27;.&#x27;</span> </span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span>  <span class="comment"># 当前插入1~9均无效，回溯到前一状态</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span>  <span class="comment"># 插入最后一个数成功时需要返回True,从而将前面的状态确定下来</span></span><br><span class="line">               </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_valid</span>(<span class="params">self, board, c, row , col</span>):</span><br><span class="line">        num = <span class="built_in">len</span>(board)</span><br><span class="line">        <span class="comment"># check row </span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">            <span class="keyword">if</span> board[row][m] == c:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                </span><br><span class="line">        <span class="comment"># check column </span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">            <span class="keyword">if</span> board[n][col] == c:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">               </span><br><span class="line">        <span class="comment"># check block </span></span><br><span class="line">        row_start = (row/<span class="number">3</span>)*<span class="number">3</span></span><br><span class="line">        column_start = (col/<span class="number">3</span>)*<span class="number">3</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(row_start,row_start+<span class="number">3</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(column_start,column_start+<span class="number">3</span>):</span><br><span class="line">                <span class="keyword">if</span> board[i][j] == c:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(382, 398)--随机采样算法 Reservoir Sampling</title>
    <url>/2017/05/28/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(382,%20398)--%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7%E7%AE%97%E6%B3%95%20Reservoir%20Sampling/</url>
    <content><![CDATA[<p><a href="https://en.wikipedia.org/wiki/Reservoir_sampling">Reservoir
sampling</a> 是一个随机采样算法，简单来说就是从 <span
class="math inline">\(n\)</span> 个 items 中随机选择 <span
class="math inline">\(k\)</span> 个items，并且每个 item
被选择的概率应该都一样。<strong>这个算法的优点在于时空复杂度都不高，其中时间复杂度为
<span class="math inline">\(O(n)\)</span>, 空间复杂度为 <span
class="math inline">\(O(1)\)</span>。</strong>下面介绍该算法的过程，并且以
leetcode 上的两道题目为例讲解。</p>
<span id="more"></span>
<p>假设现在要从 <span class="math inline">\(n\)</span>
个数里面随机选择一个数，那么通过 Reservoir sampling 选择的流程如下</p>
<ol type="1">
<li>记最终选择的数为 result</li>
<li>遍历数组，对于数组第 i 个数，以 <span
class="math inline">\(1/i\)</span>
的概率将其赋给result（i从1开始，所以第一个数肯定会赋给result）</li>
<li>遍历完数组后得到的 result 即为产生的随机数</li>
</ol>
<p>假设现在有数组 [1, 2, 3], 随机产生一个数，那么按照上面的流程有 1.
遍历第一个数时，result = 1 2. 遍历第二个数时，result = 2 的概率为 1/2,
即 result = 1 的概率也是 1/2 3. 遍历第三个数时，result = 3 的概率为 1/3,
result = 1 的概率为 (1 - 1/3) * 1/2 = 1/3, 同理 result = 2 的概率也是
1/3</p>
<p>上面的 (1 - 1/3) * 1/2 指的是这一次没有选择第三个数且之前 result
的值为1的概率，通过数学归纳法可以很容易的证明遍历完整个数组后每个数被选择的概率是
1/n (n 为数组的长度)</p>
<p>而假如要从 <span class="math inline">\(n\)</span> 个数里面随机选择
<span class="math inline">\(k\)</span> 个数时，Reservoir sampling
的过程类似上面的</p>
<ol type="1">
<li>选择前 <span class="math inline">\(k\)</span> 个数作为 result</li>
<li>从第 <span class="math inline">\(k+1\)</span>
个数开始遍历数组，对于数组第 <span class="math inline">\(k+i （i =
1,2,.....）\)</span>个数，以 <span
class="math inline">\(\frac{k}{k+i}\)</span>
的概率选择这个数加入result并替换掉 result 中的任意一个数</li>
<li>遍历完数组后得到的 result 即为产生的 <span
class="math inline">\(k\)</span> 个随机样本</li>
</ol>
<p>下面通过数学归纳法证明通过上面的算法过程最终每个数被选择的概率为
<span class="math inline">\(k/n\)</span></p>
<ol type="1">
<li><span class="math inline">\(i = 1\)</span> 时，选择第 <span
class="math inline">\(k+1\)</span> 个数的概率为 <span
class="math inline">\(\frac{k}{k+1}\)</span>，而在 result 中 <span
class="math inline">\(k\)</span> 个数里面的一个(记为 <span
class="math inline">\(x\)</span>) 能够保留下来的概率为是 <strong><span
class="math inline">\(x\)</span> 原来在
result中且这一次没有被替换的概率</strong>，而这一次没有被替换掉又可分为两种情况，一种是根本没有选择到第
<span class="math inline">\(k+i\)</span> 个数，一种是选择了第 <span
class="math inline">\(k+i\)</span> 个数，但是替换 <span
class="math inline">\(k\)</span> 个数中的一个时没有替换掉 <span
class="math inline">\(x\)</span>。公式表示为</li>
</ol>
<p><span class="math display">\[p( x 上一次在 result 中) \* p( x
没有被替换掉) = 1 \*（\frac{k}{k+1} \* (1-\frac{1}{k}) + (1 -
\frac{k}{k+1})）= \frac{k}{k+1}\]</span></p>
<p>即每个数被选择的概率为 <span
class="math inline">\(\frac{k}{k+1}\)</span></p>
<ol start="2" type="1">
<li><p>因此当 <span class="math inline">\(i = m\)</span>
时，每个数被选择的概率为 <span
class="math inline">\(k/(k+m)\)</span></p></li>
<li><p>则当 <span class="math inline">\(i = m+1\)</span> 时，选择第
<span class="math inline">\(k+m+1\)</span> 个数的概率为 <span
class="math inline">\(\frac{k}{k+m+1}\)</span>, 在 result 中 <span
class="math inline">\(k\)</span> 个数里面的一个(记为 <span
class="math inline">\(x\)</span>) 能够保留下来的概率为:</p></li>
</ol>
<p><span class="math display">\[p( x 上一次在 result 中) \* p( x
没有被替换掉) = \frac{k}{k+m} \*（\frac{k}{k+m+1} \* (1- \frac{1}{k}) +
(1 - \frac{k}{k+m+1})）= \frac{k}{k+m+1}\]</span></p>
<p>从上可知，遍历到第 <span class="math inline">\(i\)</span>
个数的时候，前 <span class="math inline">\(k+i\)</span>
每个数被选择的概率为 <span
class="math inline">\(k/(k+i)\)</span>,则遍历完 <span
class="math inline">\(n\)</span> 个数后，每个数被选择的概率为 <span
class="math inline">\(k/n\)</span></p>
<p>LeetCode 上的题目 <a
href="https://leetcode.com/problems/linked-list-random-node/#/descriptionn.wikipedia.org/wiki/Reservoir_sampling">382.
Linked List Random Node</a> 和 <a
href="https://leetcode.com/problems/random-pick-index/#/description">398.
Random Pick Index</a> 均用到了 Reservoir Sampling
的技巧，上面的依概率选择可以通过产生随机数并与概率值比较来实现，下面分别是
解决 382. Linked List Random Node 和 398. Random Pick Index 的 Java
代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 382. Linked List Random Node</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">ListNode</span> <span class="variable">dummy</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ListNode</span>(<span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Solution</span><span class="params">(ListNode head)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        dummy.next = head;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getRandom</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">ListNode</span> <span class="variable">curr</span> <span class="operator">=</span> dummy.next;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>, result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (curr != <span class="literal">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            count ++;</span><br><span class="line">            <span class="keyword">if</span> (Math.random() &lt; <span class="number">1.0</span>/count) result = curr.val;</span><br><span class="line">            curr = curr.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 398. Random Pick Index</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Solution</span> </span><br><span class="line">&#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span>[] numbers;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Solution</span><span class="params">(<span class="type">int</span>[] nums)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        numbers = nums;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">pick</span><span class="params">(<span class="type">int</span> target)</span> </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> <span class="number">0</span>, count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; numbers.length; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (numbers[i] == target)</span><br><span class="line">            &#123;</span><br><span class="line">                count++;</span><br><span class="line">                <span class="keyword">if</span>(Math.random() &lt; <span class="number">1.0</span>/count) index = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Reservoir Sampling</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(39,40)--数字集合中找特定和</title>
    <url>/2016/04/16/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(39,40)--%E6%95%B0%E5%AD%97%E9%9B%86%E5%90%88%E4%B8%AD%E6%89%BE%E7%89%B9%E5%AE%9A%E5%92%8C/</url>
    <content><![CDATA[<p>这两道题目<a
href="https://leetcode.com/problems/combination-sum/">39. Combination
Sum</a>和<a href="https://leetcode.com/problems/combination-sum-ii/">40.
Combination Sum
II</a>均要求从给定的一个数字集合中找出若干个数字的和等于某个给定的数。解决方法有两种，第一种是回溯法，第二种是动态规划。下面分别讲述。</p>
<span id="more"></span>
<h2 id="combination-sum">39. Combination Sum</h2>
<p><a
href="https://leetcode.com/problems/combination-sum/">原题</a>如下：</p>
<blockquote>
<p>Given a set of candidate numbers (C) and a target number (T), find
all unique combinations in C where the candidate numbers sums to T.
<!--more--> The same repeated number may be chosen from C unlimited
number of times.</p>
</blockquote>
<blockquote>
<p>Note: All numbers (including target) will be positive integers.
Elements in a combination (a1, a2, … , ak) must be in non-descending
order. (ie, a1 ≤ a2 ≤ … ≤ ak). The solution set must not contain
duplicate combinations. For example, given candidate set 2,3,6,7 and
target 7, A solution set is: [7] [2, 2, 3]</p>
</blockquote>
<h3 id="回溯法">回溯法</h3>
<p>回溯法的的过程如下：先对数组从小到大排序。然后从第一个数字开始往后加，<strong>每加上一个数字就保留当前的状态</strong>，再加上下一个数字的时候假如和超过了给定的数字，就回到上一状态，上一个状态就跳过这个数字继续往后加。注意当前数字可以重复使用。</p>
<p>实现方法如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum</span>(<span class="params">self, candidates, target</span>):</span><br><span class="line">        res = []</span><br><span class="line">        candidates.sort()</span><br><span class="line">        self.dfs(candidates, target, <span class="number">0</span>, [], res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">self, nums, target, index, path, res</span>):</span><br><span class="line">        <span class="keyword">if</span> target == <span class="number">0</span>:</span><br><span class="line">            res.append(path)</span><br><span class="line">            <span class="keyword">return</span> </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(index, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> target-nums[i] &lt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span>  <span class="comment"># backtracking</span></span><br><span class="line">            self.dfs(nums, target-nums[i], i, path+[nums[i]], res)</span><br></pre></td></tr></table></figure></p>
<h3 id="动态规划法">动态规划法</h3>
<p>动态规划利用一个list存储每个数字可能的组合，dp[i]表示和为i的数字的可能的组合，那么下一个dp[i+1]=dp[i]+dp[1]=dp[i-1]+dp<a
href="https://leetcode.com/problems/combination-sum-ii/">2</a>......上面的加号表示对这两个可能的数字的组合进行组合。实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum</span>(<span class="params">self, candidates, target</span>):</span><br><span class="line">        dp = &#123;&#125;</span><br><span class="line">        dp[<span class="number">0</span>] = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>,target+<span class="number">1</span>):</span><br><span class="line">            dp [i] = []</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> candidates:</span><br><span class="line">                dp[i].append([i])</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">1</span>,i/<span class="number">2</span>+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(dp[j]) ==<span class="number">0</span> <span class="keyword">or</span> <span class="built_in">len</span>(dp[i-j])==<span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">for</span> m <span class="keyword">in</span> dp[j]:</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> dp[i-j]:</span><br><span class="line">                        tmp = m+k</span><br><span class="line">                        tmp.sort()</span><br><span class="line">                        <span class="keyword">if</span> tmp <span class="keyword">not</span> <span class="keyword">in</span> dp[i]:</span><br><span class="line">                            dp[i].append(tmp)</span><br><span class="line">        <span class="keyword">return</span> dp[target]</span><br></pre></td></tr></table></figure>
<h2 id="combination-sum-ii">40. Combination Sum II</h2>
<p><a
href="https://leetcode.com/problems/combination-sum-ii/">原题</a>如下：
&gt;Given a collection of candidate numbers (C) and a target number (T),
find all unique combinations in C where the candidate numbers sums to T.
<!--more--> &gt;Each number in C may only be used once in the
combination.</p>
<blockquote>
<p>Note: All numbers (including target) will be positive integers.
Elements in a combination (a1, a2, … , ak) must be in non-descending
order. (ie, a1 ≤ a2 ≤ … ≤ ak). The solution set must not contain
duplicate combinations. For example, given candidate set 10,1,2,7,6,1,5
and target 8, A solution set is: [1, 7] [1, 2, 5] [2, 6] [1, 1, 6]</p>
</blockquote>
<p>本题与前一题Combination
Sum非常相似，只是附加了<strong>每个数字只能使用一次</strong>的要求。需要注意给出的candidate
numbers中会有重复的数字。</p>
<p>解决方法与前一题Combination
Sum也类似，只是在这个过程中元素不能被重复使用。</p>
<h3 id="回溯法-1">回溯法</h3>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum2</span>(<span class="params">self, candidates, target</span>):</span><br><span class="line">        candidates.sort()</span><br><span class="line">        result = []</span><br><span class="line">        self.dfs(candidates,target,<span class="number">0</span> ,[],result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">self, nums, tar, index, tmp, res</span>):</span><br><span class="line">        <span class="keyword">if</span> tar == <span class="number">0</span> :</span><br><span class="line">            <span class="keyword">if</span> tmp <span class="keyword">not</span> <span class="keyword">in</span> res:</span><br><span class="line">                res.append(tmp)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(index,<span class="built_in">len</span>(nums)):</span><br><span class="line">                <span class="keyword">if</span> tar-nums[i]&lt;<span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                self.dfs(nums, tar-nums[i], i+<span class="number">1</span>, tmp+[nums[i]], res)</span><br></pre></td></tr></table></figure></p>
<h3 id="动态规划法-1">动态规划法</h3>
<p>需要先获取原来的candidates中各个数字的个数，然后每次遇到和等于目标数字的list时都要判断这个list中的各个数字个数是否超过给定的candidates中的标准。
实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum2</span>(<span class="params">self, candidates, target</span>):</span><br><span class="line">        can_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">            <span class="keyword">if</span> candidate <span class="keyword">not</span> <span class="keyword">in</span> can_dict: </span><br><span class="line">                can_dict[candidate] = <span class="number">0</span></span><br><span class="line">            can_dict[candidate] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        dp = &#123;&#125;</span><br><span class="line">        dp[<span class="number">0</span>] = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>,target+<span class="number">1</span>):</span><br><span class="line">            dp[i] = []</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> candidates:</span><br><span class="line">                dp[i].append([i])</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">1</span>,i/<span class="number">2</span>+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(dp[j])==<span class="number">0</span> <span class="keyword">or</span> <span class="built_in">len</span>(dp[i-j])==<span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">for</span> m <span class="keyword">in</span> dp[j]:</span><br><span class="line">                    <span class="keyword">for</span> n <span class="keyword">in</span> dp[i-j]:</span><br><span class="line">                        tmp_dict = &#123;&#125;</span><br><span class="line">                        flag = <span class="number">0</span>               </span><br><span class="line">                        tmp = m+n</span><br><span class="line">                        <span class="keyword">for</span> t <span class="keyword">in</span> tmp:</span><br><span class="line">                            <span class="keyword">if</span> t <span class="keyword">not</span> <span class="keyword">in</span> tmp_dict: </span><br><span class="line">                                tmp_dict[t] = <span class="number">0</span></span><br><span class="line">                            tmp_dict[t] += <span class="number">1</span></span><br><span class="line">                       </span><br><span class="line">                        <span class="keyword">for</span> te <span class="keyword">in</span> tmp_dict:</span><br><span class="line">                            <span class="keyword">if</span> tmp_dict[te] &gt; can_dict[te]: </span><br><span class="line">                                flag = <span class="number">1</span></span><br><span class="line">                                <span class="keyword">break</span></span><br><span class="line">                        <span class="keyword">if</span> flag == <span class="number">0</span>:</span><br><span class="line">                            tmp.sort()                         </span><br><span class="line">                            <span class="keyword">if</span> tmp <span class="keyword">not</span> <span class="keyword">in</span> dp[i]:</span><br><span class="line">                                dp[i].append(tmp)</span><br><span class="line">        <span class="keyword">return</span> dp[target]</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>回溯法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(4)--二分法查找两个有序数组的中位数</title>
    <url>/2016/01/10/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(4)--%E4%BA%8C%E5%88%86%E6%B3%95%E6%9F%A5%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/median-of-two-sorted-arrays/">原题</a>如下：</p>
<blockquote>
<p>There are two sorted arrays nums1 and nums2 of size m and n
respectively. Find the median of the two sorted arrays. The overall run
time complexity should be O(log (m+n)).</p>
</blockquote>
<span id="more"></span>
<p>大意就是找出两个排好序的数组中所有数的中位数。</p>
<p>最直观的做法是先将两个数组按从大到小合并成一个数组，再找出中位数。这样相当于遍历了两个数组，其时间复杂度是O(m+n)。实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMedianSortedArrays</span>(<span class="params">self, nums1, nums2</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums1: List[int]</span></span><br><span class="line"><span class="string">        :type nums2: List[int]</span></span><br><span class="line"><span class="string">        :rtype: float</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        index1=<span class="number">0</span></span><br><span class="line">        index2=<span class="number">0</span></span><br><span class="line">        mergedArr=[]</span><br><span class="line">        <span class="keyword">while</span> index1&lt;<span class="built_in">len</span>(nums1) <span class="keyword">and</span> index2&lt;<span class="built_in">len</span>(nums2):</span><br><span class="line">            <span class="keyword">if</span> nums1[index1] &gt; nums2[index2]:</span><br><span class="line">                mergedArr.append(nums2[index2])</span><br><span class="line">                index2+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums1[index1] &lt; nums2[index2]:</span><br><span class="line">                mergedArr.append(nums1[index1])</span><br><span class="line">                index1+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>: <span class="comment">#equal</span></span><br><span class="line">                mergedArr.append(nums1[index1])</span><br><span class="line">                mergedArr.append(nums2[index2])</span><br><span class="line">                index1+=<span class="number">1</span></span><br><span class="line">                index2+=<span class="number">1</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> index1!=<span class="built_in">len</span>(nums1):</span><br><span class="line">            <span class="keyword">while</span> index1&lt;<span class="built_in">len</span>(nums1):</span><br><span class="line">                mergedArr.append(nums1[index1])</span><br><span class="line">                index1+=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> index2!=<span class="built_in">len</span>(nums2):</span><br><span class="line">            <span class="keyword">while</span> index2&lt;<span class="built_in">len</span>(nums2):</span><br><span class="line">                mergedArr.append(nums2[index2])</span><br><span class="line">                index2+=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        mergedLen=<span class="built_in">len</span>(mergedArr)</span><br><span class="line">        <span class="keyword">if</span> mergedLen %<span class="number">2</span> == <span class="number">0</span>: <span class="comment">#even length</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">float</span>(mergedArr[mergedLen/<span class="number">2</span>]+mergedArr[mergedLen/<span class="number">2</span>-<span class="number">1</span>])/<span class="number">2</span> </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">float</span> (mergedArr[(mergedLen-<span class="number">1</span>)/<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>尽管上面的时间复杂度是O(m+n)，但是实际的提交时也能AC。</p>
<p>虽然上面的方法也能够AC，但是<strong>根据题目的提示的O(log(m+n))时间复杂度，显然还有更好的解法。下面就来讨论一种时间复杂度为O(log(m+n))的算法。</strong></p>
<p>提到时间复杂度为O(log(m+n))的算法，很容易想到的就是<strong>二分查找</strong>，所以<strong>现在要做的就是在两个排序数组中进行二分查找</strong>。</p>
<p>具体思路如下，可以将问题转化为在两个数组中找第K个大的数，先在两个数组中分别找出第k/2大的数，再比较这两个第k/2大的数，这里假设两个数组为A,B。那么比较结果会有下面几种情况：</p>
<ul>
<li>A[k/2]=B[k/2],那么第k大的数就是A[k/2]</li>
<li>A[k/2]&gt;B[k/2],那么第k大的数肯定在A[0:k/2+1]和B[k/2:]中，这样就将原来的所有数的总和减少到一半了，再在这个范围里面找第k/2大的数即可，这样也达到了二分查找的区别了。</li>
<li>A[k/2] &lt;
B[k/2]，那么第k大的数肯定在B[0:k/2+1]和A[k/2:]中,同理在这个范围找第k/2大的数就可以了。</li>
</ul>
<p>上面思路的实现代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMedianSortedArrays</span>(<span class="params">self, A, B</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(A) + <span class="built_in">len</span>(B)</span><br><span class="line">        <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> self.findKth(A, B, n / <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smaller = self.findKth(A, B, n / <span class="number">2</span>)</span><br><span class="line">            bigger = self.findKth(A, B, n / <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> (smaller + bigger) / <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findKth</span>(<span class="params">self, A, B, k</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(A) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> B[k - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(B) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> A[k - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">min</span>(A[<span class="number">0</span>], B[<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        a = A[k / <span class="number">2</span> - <span class="number">1</span>] <span class="keyword">if</span> <span class="built_in">len</span>(A) &gt;= k / <span class="number">2</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        b = B[k / <span class="number">2</span> - <span class="number">1</span>] <span class="keyword">if</span> <span class="built_in">len</span>(B) &gt;= k / <span class="number">2</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> b <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> (a <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> a &lt; b):</span><br><span class="line">            <span class="keyword">return</span> self.findKth(A[k / <span class="number">2</span>:], B[<span class="number">0</span>:k/<span class="number">2</span>+<span class="number">1</span>], k - k / <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> self.findKth(A[<span class="number">0</span>:k/<span class="number">2</span>+<span class="number">1</span>], B[k / <span class="number">2</span>:], k - k / <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>二分搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(42)--柱状图的储水量</title>
    <url>/2016/05/01/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(42)--%E6%9F%B1%E7%8A%B6%E5%9B%BE%E7%9A%84%E5%82%A8%E6%B0%B4%E9%87%8F/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/trapping-rain-water/">原题</a>如下
&gt;Given n non-negative integers representing an elevation map where
the width of each bar is 1, compute how much water it is able to trap
after raining. <span id="more"></span> For example, Given [0,1,0,2,1,0,1,3,2,1,2,1],
return 6. <img src="https://wulc.me/imgs/rainwatertrap.png" /> The above
elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this
case, 6 units of rain water (blue section) are being trapped. Thanks
Marcos for contributing this image!</p>
<p>从题目给出的图可以比较清楚知道，题目给出的数组中的每个数字代表一根柱子的高度，将数组中的数字全部表示为特定高度的柱子后，求这些柱子组成的容器能够容纳的水量。</p>
<p>解题思路：可以分别求出每根柱子的储水量，然后将每根柱子的储水量加起来即为总的储水量。而<strong>每根柱子的储水量可以通过下面方法求：找到这根柱子左边所有柱子中最高的那根，记为A；找到这根柱子右边所有柱子中最高的那根，记为B；min(A,B)-r即为这根柱子的储水量，r为这根柱子的高度。</strong></p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">trap</span>(<span class="params">self, height</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type height: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(height)==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        leftMax = []</span><br><span class="line">        <span class="comment"># leftMax Array</span></span><br><span class="line">        <span class="built_in">max</span> = height[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(height)):</span><br><span class="line">            <span class="keyword">if</span> height[i] &gt; <span class="built_in">max</span> :</span><br><span class="line">                <span class="built_in">max</span> = height[i]</span><br><span class="line">            leftMax.append(<span class="built_in">max</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">        rightMax = height[<span class="built_in">len</span>(height)-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(height)-<span class="number">1</span>)):</span><br><span class="line">            miniHeight = <span class="built_in">min</span>(leftMax[i-<span class="number">1</span>],rightMax)</span><br><span class="line">            <span class="keyword">if</span> miniHeight &gt; height[i]:</span><br><span class="line">                <span class="built_in">sum</span> += miniHeight - height[i]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> height[i] &gt; rightMax:</span><br><span class="line">                rightMax = height[i]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span> </span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(41)--第一个缺失的正整数</title>
    <url>/2016/04/20/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(41)--%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%BC%BA%E5%A4%B1%E7%9A%84%E6%AD%A3%E6%95%B4%E6%95%B0/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/first-missing-positive/">原题</a>如下：</p>
<blockquote>
<p>Given an unsorted integer array, find the first missing positive
integer. <span id="more"></span> For example, Given [1,2,0] return 3, and [3,4,-1,1]
return 2.</p>
</blockquote>
<blockquote>
<p>Your algorithm should run in O(n) time and uses constant space.</p>
</blockquote>
<p>题目要求找出第一个缺失的正整数，难点在于时间复杂度要控制在O(n)，也就是说不能对数组排序，空间复杂度要控制在O(1)，也就是说不能开一个新的数组去存储这些数字。</p>
<p>但是这道题目也有它的特点，<strong>假如给定的数组的长度为n，那么缺失的第一个正数肯定在[1,n+1]内</strong>，根据这个特点，可以将范围为[1,n]的数字移动到与其数值相等的下标的位置，对所有的数这样操作后从头遍历一遍数组，找出的第一个
<code>i+1 != a[i]</code>的i,那么i+1就是第一个缺失的正整数。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">firstMissingPositive</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n):</span><br><span class="line">            <span class="keyword">while</span> <span class="number">0</span>&lt;nums[i]&lt;=n <span class="keyword">and</span> (<span class="keyword">not</span> nums[nums[i]-<span class="number">1</span>]==nums[i]):</span><br><span class="line">                    tmp = nums[i]</span><br><span class="line">                    nums[i] = nums[tmp-<span class="number">1</span>]</span><br><span class="line">                    nums[tmp-<span class="number">1</span>] = tmp</span><br><span class="line">                    <span class="comment"># nums[i],nums[nums[i]-1] = nums[nums[i]-1],nums[i]错误</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == i+<span class="number">1</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> i+<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> n+<span class="number">1</span> <span class="comment"># all match</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(46，47)--排列</title>
    <url>/2016/05/06/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(46%EF%BC%8C47)--%E6%8E%92%E5%88%97/</url>
    <content><![CDATA[<h2 id="permutations">46. Permutations</h2>
<p><a
href="https://leetcode.com/problems/permutations/">原题</a>如下：</p>
<p>Given a collection of distinct numbers, return all possible
permutations. <span id="more"></span> For example, [1,2,3] have the following
permutations: [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], and
[3,2,1].</p>
<p>题目要求列出给定的不重复数字的所有排列结果。解题方法有两种。下面分别讲述。</p>
<h3 id="方法一">方法一</h3>
<p>第一种方法每次取一个数字，将数字插入现有的排列中形成新的排列，然后重复上面的过程直到所有数字都被取完。</p>
<p>实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permute</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = [[]]</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            new_result = []</span><br><span class="line">            <span class="keyword">for</span> seq <span class="keyword">in</span> result:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(seq)+<span class="number">1</span>):</span><br><span class="line">                    new_result.append(seq[:i]+[num]+seq[i:])</span><br><span class="line">            result = new_result</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h3 id="方法二">方法二</h3>
<p>第二种方法采用回溯法。将当前数字与后面的数字逐一交换，当与某一数字交换后，然后移动到下一个数字重复上面的操作。实现具体代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permute</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = []</span><br><span class="line">        self.helper(nums,<span class="number">0</span>,result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self, nums, begin, result</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> begin == n:</span><br><span class="line">            tmp = nums[:]</span><br><span class="line">            result.append(tmp)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(begin,n):</span><br><span class="line">            nums[begin],nums[i] = nums[i], nums[begin]</span><br><span class="line">            self.helper(nums,begin+<span class="number">1</span>,result)</span><br><span class="line">            nums[begin],nums[i] = nums[i], nums[begin]</span><br></pre></td></tr></table></figure>
<h2 id="permutations-ii">47. Permutations II</h2>
<p><a
href="https://leetcode.com/problems/permutations-ii/">原题</a>如下：</p>
<p>Given a collection of numbers that might contain duplicates, return
all possible unique permutations.</p>
<p>For example, [1,1,2] have the following unique permutations: [1,1,2],
[1,2,1], and [2,1,1].</p>
<p>这道题目的要求与上一道一样，只是在上面的基础上添加了存在重复数字的约束条件。
上面提到回溯法在这里不适用了（即使判定交换的元素是否相等），比如说对于[1,2,3,3]就不正确了。</p>
<p>采用方法一的直接插入法，从后往前插，遇到与当前要插入数字相同的数字时就终止当前排列的插入，进行下一个排列的插入。实现的具体代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permuteUnique</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = [[]]</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            new_result = []</span><br><span class="line">            <span class="keyword">for</span> seq <span class="keyword">in</span> result:</span><br><span class="line">                n = <span class="built_in">len</span>(seq)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> i &lt; n <span class="keyword">and</span> seq[i] == num:</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    new_result.append(seq[:i]+[num]+seq[i:])</span><br><span class="line">            result = new_result</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(5)--最长回文子字符串</title>
    <url>/2016/01/24/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(5)--%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<p><a
href="https://leetcode.com/problems/longest-palindromic-substring/">原题</a>如下：</p>
<blockquote>
<p>Given a string S, find the longest palindromic substring in S. You
may assume that the maximum length of S is 1000, and there exists one
unique longest palindromic substring.</p>
</blockquote>
<p>就是要从给定的字符串中找出最大的回文子字符串。 <span id="more"></span></p>
<p>下面介绍两种时间复杂度为 <span class="math inline">\(O(n^2)\)</span>
的方法，第一种是以每个字符为中心向两边拓展从而得到尽可能长的回文字符串，第二种是利用动态规划。</p>
<p>第一种方法的关键点是<strong>以每个字符为中心向两边拓展从而得到尽可能长的回文字符串</strong>。这里要注意的是回文字符串的长度可以是奇数也可以是偶数，所以要分两种情况讨论。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        r=s[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">1</span>,<span class="built_in">len</span>(s)):</span><br><span class="line">                <span class="comment"># oddResult</span></span><br><span class="line">                begin=i </span><br><span class="line">                end=i</span><br><span class="line">                oddResult=self.getPalindoreStr(s,begin,end)</span><br><span class="line">                <span class="keyword">if</span> oddResult != <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">len</span>(oddResult)&gt; <span class="built_in">len</span>(r):</span><br><span class="line">                    r=oddResult</span><br><span class="line"></span><br><span class="line">                <span class="comment"># enevResult</span></span><br><span class="line">                begin=i-<span class="number">1</span></span><br><span class="line">                end=i</span><br><span class="line">                evenResult=self.getPalindoreStr(s,begin,end)</span><br><span class="line">                <span class="keyword">if</span> evenResult != <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">len</span>(evenResult)&gt; <span class="built_in">len</span>(r):</span><br><span class="line">                    r=evenResult</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line">    <span class="comment">#从给定的begin和end位置向两边扩展，得到回文字符串                </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getPalindoreStr</span>(<span class="params">self,s,begin,end</span>):</span><br><span class="line">        <span class="keyword">while</span> ( begin&gt;=<span class="number">0</span> <span class="keyword">and</span> end&lt;<span class="built_in">len</span>(s) <span class="keyword">and</span> s[begin]==s[end] ):</span><br><span class="line">                begin-=<span class="number">1</span></span><br><span class="line">                end+=<span class="number">1</span></span><br><span class="line">        result=s[begin+<span class="number">1</span>:end] <span class="keyword">if</span>  begin+<span class="number">1</span> &lt;= end <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<p>第二种方法采用的是动态规划，<code>dp[i][j]</code> 表示 s[i:j]
所形成的字符串是否为回文字符串，时间复杂度为 <span
class="math inline">\(O(n^2)\)</span>。代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type s: str</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="literal">False</span> <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n)] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)]</span><br><span class="line">        result = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(xrange(n)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(i, n):</span><br><span class="line">                <span class="keyword">if</span> i == j:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">elif</span> s[i] == s[j]:</span><br><span class="line">                    dp[i][j] = dp[i+<span class="number">1</span>][j-<span class="number">1</span>] <span class="keyword">if</span> i+<span class="number">1</span>&lt;=j-<span class="number">1</span> <span class="keyword">else</span> <span class="literal">True</span></span><br><span class="line">                <span class="keyword">if</span> dp[i][j] <span class="keyword">and</span> j-i+<span class="number">1</span> &gt; <span class="built_in">len</span>(result):</span><br><span class="line">                    result = s[i:j+<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> result   </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>动态规划</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(48)--矩阵的旋转</title>
    <url>/2016/05/12/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(48)--%E7%9F%A9%E9%98%B5%E7%9A%84%E6%97%8B%E8%BD%AC/</url>
    <content><![CDATA[<p><a href="https://leetcode.com/problems/rotate-image/">原题</a>如下:
You are given an n x n 2D matrix representing an image.</p>
<p>Rotate the image by 90 degrees (clockwise).</p>
<p>Follow up: Could you do this in-place? <span id="more"></span>
题目要求将图片顺时针翻转90度。通过用一个额外的图片矩阵来存储这个图片能够轻松完成，但是题目最后说了<code>Could you do this in-place?</code>，意思是能否通过O(1)的空间复杂度完成这项任务。</p>
<p>这就需要一点技巧了，下面以一个例子说明如何不借助额外的图片矩阵完成顺时针90度旋转。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 2 3     7 8 9     7 4 1</span><br><span class="line">4 5 6 --&gt; 4 5 6 --&gt; 8 5 2</span><br><span class="line">7 8 9     1 2 3     9 6 3</span><br></pre></td></tr></table></figure>
首先将图片的行<strong>上下对称交换</strong>，假如有奇数行，中间的行不用动；假如有偶数行，则全部都要对称交换。然后将<strong>矩阵转置</strong>即可。</p>
<p>具体实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rotate</span>(<span class="params">self, matrix</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type matrix: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: void Do not return anything, modify matrix in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = <span class="built_in">len</span>(matrix)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n/<span class="number">2</span>):</span><br><span class="line">            matrix[i], matrix[n-<span class="number">1</span>-i] = matrix[n-<span class="number">1</span>-i], matrix[i]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(i+<span class="number">1</span>,n):</span><br><span class="line">                matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]</span><br></pre></td></tr></table></figure></p>
<p>参考上面的方法，同理可以推出逆时针旋转90度和旋转180度的实现方法。</p>
<p><strong>逆时针旋转90度</strong></p>
<p>将矩阵的列左右对称交换，然后转置。例子如下所示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 2 3     3 2 1     3 6 9</span><br><span class="line">4 5 6 --&gt; 6 5 4 --&gt; 2 5 8</span><br><span class="line">7 8 9     9 8 7     1 4 7</span><br></pre></td></tr></table></figure>
<p><strong>旋转180度</strong>
上下对称交换，然后左右对称交换。例子如下所示： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 2 3     7 8 9     9 8 7</span><br><span class="line">4 5 6 --&gt; 4 5 6 --&gt; 6 5 4</span><br><span class="line">7 8 9     1 2 3     3 2 1</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode解题报告(95,96)--构造二叉搜索树</title>
    <url>/2016/06/11/LeetCode%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(95,96)--%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/</url>
    <content><![CDATA[<p>两个题目均是要求利用给出的整数[1,
n]构造出所有的二叉搜索树（BST），其中<a
href="https://leetcode.com/problems/unique-binary-search-trees-ii/">95.
Unique Binary Search Trees II</a>要求返回所有的二叉树的根节点，<a
href="https://leetcode.com/problems/unique-binary-search-trees/">96.
Unique Binary Search Trees</a>则仅要求返回所有二叉树的数目。</p>
<span id="more"></span>
<p>两个题目均可以通过递归实现，思路如下：
<strong>1）遍历[1,n]中每个整数,并将正在遍历的整数 i 设为根节点 2）将
[1,i-1] 的整数构建出来的子树作为整数 i 构建的根节点的左子树，将 [i+1,n]
的整数构造出来的子树作为整数 i 构建的根节点的右子树
3）对得到的左右子树进行组合，这样便可得到以整数i为根节点的所有二叉树</strong></p>
<p>因此，<a
href="https://leetcode.com/problems/unique-binary-search-trees-ii/">95.
Unique Binary Search Trees II</a>实现代码如下:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generateTrees</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: List[TreeNode]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> n==<span class="number">0</span>: <span class="keyword">return</span> [] </span><br><span class="line">        <span class="keyword">return</span> self.helper(<span class="number">1</span>, n)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">helper</span>(<span class="params">self,begin,end</span>):</span><br><span class="line">        <span class="keyword">if</span> begin &gt; end:</span><br><span class="line">            <span class="keyword">return</span> [<span class="literal">None</span>]</span><br><span class="line">        <span class="keyword">if</span> begin == end:</span><br><span class="line">            <span class="keyword">return</span> [TreeNode(begin)]</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(begin,end+<span class="number">1</span>):</span><br><span class="line">            tmp = []</span><br><span class="line">            left = self.helper(begin, i-<span class="number">1</span>)</span><br><span class="line">            right = self.helper(i+<span class="number">1</span>, end)</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> left:</span><br><span class="line">                <span class="keyword">for</span> n <span class="keyword">in</span> right:</span><br><span class="line">                    root = TreeNode(i)</span><br><span class="line">                    root.left, root.right = m, n</span><br><span class="line">                    result.append(root)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p><a
href="https://leetcode.com/problems/unique-binary-search-trees/">96.
Unique Binary Search Trees</a>
的解决思路类似于上面提到的递归的方法，只是这道题目仅仅要求返回二叉树的数量。因此可以通过一个技巧缩短计算量，这个技巧就是<strong>整数
i 作为根节点和整数 n-i
作为根节点的时候，两者构造的二叉树的数目是一样的。</strong>因此整数 i
作为根节点的左右子树的节点数目与整数 n-i
作为根节点的左右子树的节点数目对称相等。</p>
<p>实现的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numTrees</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> n&lt;=<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n/<span class="number">2</span>):</span><br><span class="line">            left = self.numTrees(i)</span><br><span class="line">            right = self.numTrees(n-i-<span class="number">1</span>)</span><br><span class="line">            result += left * right</span><br><span class="line">        result *= <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> n%<span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">            result += <span class="built_in">pow</span>(self.numTrees(n/<span class="number">2</span>),<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure> 要注意的是当 n
为基数的时候，整数(n+1)/2没有这种对称关系，需要额外计算。</p>
<p>从上面也可以衍生出动态规划的解法，令 dp[m] 表示 m
个节点能够构造的二叉树的数目。那么dp[m+1]的计算方法如下
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">0</span>, m+<span class="number">1</span>):</span><br><span class="line">    dp[m+<span class="number">1</span>] += dp[i]*dp[m+<span class="number">1</span>-i-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<p>实现的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numTrees</span>(<span class="params">self, n</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        dp = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n+<span class="number">1</span>)]</span><br><span class="line">        dp[<span class="number">0</span>],dp[<span class="number">1</span>] = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">2</span>,n+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(i):</span><br><span class="line">                dp[i] += dp[j]*dp[i-j-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> dp[n]</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>树</tag>
        <tag>动态规划</tag>
        <tag>分治法</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode 解题报告(496, 975, 503)-next greater/smaller element</title>
    <url>/2019/03/25/Leetcode%20%E8%A7%A3%E9%A2%98%E6%8A%A5%E5%91%8A(496,%20975,%20503)-next%20greater-smaller%20element/</url>
    <content><![CDATA[<p>本文主要介绍在 LeetCode 题目 <a
href="https://leetcode.com/problems/next-greater-element-i/">496. Next
Greater Element I</a>、<a
href="https://leetcode.com/problems/odd-even-jump/">975. Odd Even
Jump</a>、<a
href="https://leetcode.com/problems/next-greater-element-ii/">503. Next
Greater Element II</a> 中需要解决的共同问题：next greater
element，就是对于一个数组中的每个 element，求出下标和值都比其大的一个
element，根据要求不同，这个问题又可分为 nearest of next greater elements
和 smallest of next greater elements，前者指的是 next greater elements
中离当前 element 最近的那个，后者指的是 next greater elements
中值最小的那个。两个问题都可通过 stack 解决，后者也可通过 treemap
解决。最后会将原来的问题进行的拓展，将原来的数据改成头尾相接的，其解决方法是将来的数组进行
duplicate, 然后把环解开，详细请看后文。</p>
<span id="more"></span>
<h2 id="nearest-of-next-greater-elements">nearest of next greater
elements</h2>
<p><a href="https://leetcode.com/problems/next-greater-element-i/">496.
Next Greater Element I</a> 要解决的就是 nearest of next greater element
的问题，如果直接进行暴力枚举，那时间复杂度是 <span
class="math inline">\(O(n^2)\)</span>, 而借助栈，能够让时间复杂度降为
<span class="math inline">\(O(n)\)</span>,
其过程如下所示（栈用于存储元素的下标）</p>
<ol type="1">
<li>从后往前遍历数组</li>
<li>对于当前下标，假如其对应的值大于栈顶元素对应的值，则将栈顶元素出栈</li>
<li>重复步骤 2
直至栈顶元素对应的值大于等于当前下标对应的值或栈为空，如果是前者，则当前栈顶元素便是当前元素的
nearest of next greater elements, 如果是后者，这样的 element 不存在</li>
<li>将当前下标压栈，回到步骤 1</li>
</ol>
<p>由于每个元素最多只会出栈一次和入栈一次，因此总体的时间复杂度是 <span
class="math inline">\(O(n)\)</span>,
这个方法<strong>减少了时间复杂度的关键点在于出栈，如对当前元素
e1，经过出栈后小于当前元素 e1 的元素都会出栈，假如下一个元素 e2 大于
e1，那么 e2 就不需要再跟那些已经出栈的元素进行比较了，因为那些元素小于
e1，也必定小于 e2。</strong>这样就减少了比较次数，将时间复杂度从原来的
<span class="math inline">\(O(n^2)\)</span> 降低到了 <span
class="math inline">\(O(n)\)</span>。</p>
<p>这里以题目 496. Next Greater Element I 为例，AC 的 pyhton
代码如下所示，</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># traverse from right to left</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nextGreaterElement</span>(<span class="params">self, nums1, nums2</span>):</span><br><span class="line">        record, stack =  &#123;&#125;, []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(nums2) - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> stack[-<span class="number">1</span>] &lt; nums2[i]:</span><br><span class="line">                stack.pop()</span><br><span class="line">            <span class="keyword">if</span> stack:</span><br><span class="line">                record[nums2[i]] = stack[-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                record[nums2[i]] = -<span class="number">1</span></span><br><span class="line">            stack.append(nums2[i])</span><br><span class="line">        <span class="keyword">return</span> [record[num] <span class="keyword">for</span> num <span class="keyword">in</span> nums1]</span><br></pre></td></tr></table></figure>
<p><strong>除了从后往前遍历，利用栈从前往后遍历也能解决这个问题</strong>，原理类似，AC
的 python 代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># traverse from left to right</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nextGreaterElement</span>(<span class="params">self, nums1, nums2</span>):</span><br><span class="line">        stack, record = [], &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums2:</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> stack[-<span class="number">1</span>] &lt; num:</span><br><span class="line">                record[stack.pop()] = num</span><br><span class="line">            stack.append(num)</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> stack:</span><br><span class="line">            record[num] = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> [record[num] <span class="keyword">for</span> num <span class="keyword">in</span> nums1]</span><br></pre></td></tr></table></figure>
<h2 id="smallest-of-next-greater-element">smallest of next greater
element</h2>
<p><a href="https://leetcode.com/problems/odd-even-jump/">975. Odd Even
Jump</a> 要解决的是 smallest of next greater element
这一类问题，题目不是直接求解这个问题，而是结合了动态规划和这个问题。</p>
<p>动态规划比较容易想到，因为一般这类型是否能到达终点的题目都可以通过动态规划求解，如</p>
<ul>
<li><a href="https://leetcode.com/problems/jump-game/">55. Jump
Game</a></li>
<li><a href="https://leetcode.com/problems/climbing-stairs/">70.
Climbing Stairs</a></li>
<li><a href="https://leetcode.com/problems/frog-jump/">403. Frog
Jump</a></li>
<li><a
href="https://leetcode.com/problems/min-cost-climbing-stairs/">746. Min
Cost Climbing Stairs</a></li>
<li>.....</li>
</ul>
<p>回到题目 975. Odd Even Jump 由于在每个点有两种选择，即 odd jump 或者
even jump，则可以建立两个 dp 数组，<code>odd_dp</code> 和
<code>even_dp</code>, <code>odd_dp[i]</code> 表示从 i 以 odd jump
开始能够跳到终点，<code>even_dp[i]</code> 表示从 i 以 even jump
开始能够跳到终点。则 dp 递推式就很简单了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">odd_dp[i] = even_dp[smallest of next greater elements of i]</span><br><span class="line">even_dp[i] = odd_dp[greatest of next smaller elements of i]</span><br></pre></td></tr></table></figure>
<p>最终统计 <code>odd_dp</code> 中为 true 的元素数量即可，
则问题就变成了 smallest of next greater elements 和 greatest of next
smaller elements；解决的方法有两种，stack 和
treemap，两者的时间复杂度均为 <span
class="math inline">\(O(nlgn)\)</span></p>
<h3 id="stack">stack</h3>
<p>利用 stack 求解时,
不再像前面的问题一样可以直接在原来的数组上进行遍历，而是<strong>将每个元素的值带上其下标组成一个新的
tuple，然后根据 tuple
中的元素的值进行从小到大的排序，则此时便将问题转化为了 nearest of next
greater
elements</strong>，即只需要在当前元素后面那些元素中找到第一个下标比当前元素下标大的元素即可。排序的时间复杂素是
<span class="math inline">\(O(nlgn)\)</span>,
遍历进行动态规划的时间复杂度是 <span
class="math inline">\(O(n)\)</span>, 因此总体的时间复杂度是 <span
class="math inline">\(O(nlgn)\)</span>, 求解题目的 python
代码如下所示</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">oddEvenJumps</span>(<span class="params">self, A</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(A)</span><br><span class="line">        sorted_A = <span class="built_in">sorted</span>([(v, i) <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(A)])</span><br><span class="line">        next_greater, greater_stack = [-<span class="number">1</span>] * n, []</span><br><span class="line">        idx = n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> idx &gt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> greater_stack <span class="keyword">and</span> greater_stack[-<span class="number">1</span>] &lt; sorted_A[idx][<span class="number">10</span>]:</span><br><span class="line">                greater_stack.pop()</span><br><span class="line">            <span class="keyword">if</span> greater_stack:</span><br><span class="line">                next_greater[sorted_A[idx][<span class="number">11</span>]] = greater_stack[-<span class="number">1</span>]</span><br><span class="line">            greater_stack.append(sorted_A[idx][<span class="number">12</span>])</span><br><span class="line">            idx -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        sorted_A = <span class="built_in">sorted</span>([(v, -i) <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(A)]) <span class="comment"># -i if for repeated elements</span></span><br><span class="line">        next_smaller, smaller_stack = [-<span class="number">1</span>] * n, []</span><br><span class="line">        idx = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> idx &lt; n:</span><br><span class="line">            <span class="keyword">while</span> smaller_stack <span class="keyword">and</span> smaller_stack[-<span class="number">1</span>] &lt; -<span class="number">1</span>*sorted_A[idx][<span class="number">13</span>]:</span><br><span class="line">                smaller_stack.pop()</span><br><span class="line">            <span class="keyword">if</span> smaller_stack:</span><br><span class="line">                next_smaller[-<span class="number">1</span>*sorted_A[idx][<span class="number">14</span>]] = smaller_stack[-<span class="number">1</span>]</span><br><span class="line">            smaller_stack.append(-<span class="number">1</span>*sorted_A[idx][<span class="number">15</span>])</span><br><span class="line">            idx += <span class="number">1</span></span><br><span class="line">        odd_dp, even_dp = [<span class="literal">False</span>] * n, [<span class="literal">False</span>] * n</span><br><span class="line">        odd_dp[-<span class="number">1</span>], even_dp[-<span class="number">1</span>] = <span class="literal">True</span>, <span class="literal">True</span></span><br><span class="line">        result = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> next_greater[i] &gt;= <span class="number">0</span> <span class="keyword">and</span> even_dp[next_greater[i]]:</span><br><span class="line">                odd_dp[i] = <span class="literal">True</span></span><br><span class="line">                result += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> next_smaller[i] &gt;= <span class="number">0</span> <span class="keyword">and</span> odd_dp[next_smaller[i]]:</span><br><span class="line">                even_dp[i] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h3 id="treemap">treemap</h3>
<p>另一种就是利用 <a
href="https://www.geeksforgeeks.org/treemap-in-java/">treemap</a>，treemap
是通过红黑树实现的一种数据结构, 红黑树是一棵二叉搜索树，因此能够在 <span
class="math inline">\(O(lgn)\)</span> 时间复杂度内找到 next greater
element。c++ 中内置的 map 的数据结构便是 treemap，python中没有 treemap
这种内置的数据结构。因此，对应求解题目的 c++ 代码如下，需要注意的是 map
的两个方法 <code>lower_bound</code> 和 <code>upper_bound</code>
含义如下</p>
<ul>
<li><code>lower_bound</code> 返回第一个大于等于当前值的 iterator</li>
<li><code>upper_bound</code> 返回第一个大于当前值的 iterator</li>
</ul>
<p>因此，下面的 <code>--smaller</code> 表示将返回的 iterator
往后移动，找到一个小于等于当前值的数</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">oddEvenJumps</span><span class="params">(std::vector&lt;<span class="type">int</span>&gt;&amp; A)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = A.<span class="built_in">size</span>();</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">bool</span>&gt; <span class="title">odd_dp</span><span class="params">(n, <span class="literal">false</span>)</span>, <span class="title">even_dp</span><span class="params">(n, <span class="literal">false</span>)</span></span>;</span><br><span class="line">    std::map&lt;<span class="type">int</span>, <span class="type">int</span>&gt; m;</span><br><span class="line">    odd_dp[n<span class="number">-1</span>] = <span class="literal">true</span>;</span><br><span class="line">    even_dp[n<span class="number">-1</span>] = <span class="literal">true</span>;</span><br><span class="line">    <span class="type">int</span> result = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = n - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">      <span class="keyword">auto</span> greater = m.<span class="built_in">lower_bound</span>(A[i]);</span><br><span class="line">      <span class="keyword">if</span> (greater != m.<span class="built_in">end</span>() &amp;&amp; even_dp[greater-&gt;second]) &#123;</span><br><span class="line">        result++;</span><br><span class="line">        odd_dp[i] = <span class="literal">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">auto</span> smaller = m.<span class="built_in">upper_bound</span>(A[i]);</span><br><span class="line">      <span class="keyword">if</span> (smaller != m.<span class="built_in">begin</span>() &amp;&amp; odd_dp[(--smaller)-&gt;second]) even_dp[i] = <span class="literal">true</span>;</span><br><span class="line">      m[A[i]] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="array-to-circle">array to circle</h2>
<p>最后是 <a
href="https://leetcode.com/problems/next-greater-element-ii/">503. Next
Greater Element II</a>，
这个题目在第一题基础上将原来的数组首尾相连，并求每个元素的 next
element，解决方法还是利用栈。</p>
<p>这种形成 circle 的问题一般都会想办法把 circle 去掉，如 <a
href="https://leetcode.com/problems/house-robber-ii/">213. House Robber
II</a>
就是通过列举可能的两种情况来把环去掉。而这道题目是通过<strong>首先在栈按原来数组顺序存储整个数组，栈顶元素为原来数组下标为
0
的元素，然后按照上面的方法从后往前遍历</strong>，这样做有效的原因是<strong>每个元素最多只能比较一圈回到自己本身，</strong></p>
<p>对应的 python 代码如下所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nextGreaterElements</span>(<span class="params">self, nums</span>):</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        result = [-<span class="number">1</span>] * n</span><br><span class="line">        stack = [nums[i] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> stack[-<span class="number">1</span>] &lt;= nums[i]:</span><br><span class="line">                stack.pop()</span><br><span class="line">            <span class="keyword">if</span> stack:</span><br><span class="line">                result[i] = stack[-<span class="number">1</span>]</span><br><span class="line">            stack.append(nums[i])</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<h2 id="summary">summary</h2>
<p>综上，本文主要介绍了 next greater element
问题及其衍生问题的求解方法，最原始的 nearest of next greater elements
通过 stack 能够在 <span class="math inline">\(O(n)\)</span>
的时间复杂度内求解；对于 smallest of next greater elements 问题，可通过
sort+stack 或 treemap 在 <span class="math inline">\(O(nlgn)\)</span>
的时间复杂度内解决；而如果将原来的 array 首尾相连，则只需要先在 stack
内存入整个 array
的元素（从后往前压入栈），因为每个元素最多只能比较一圈后回到自身。上面针对的是
next greater element 问题，但是 next smaller element
求解的原理和方法也是类似的，这里不再赘述。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>树</tag>
        <tag>栈</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell下删除文件名乱码文件</title>
    <url>/2015/11/21/Linux%20shell%E4%B8%8B%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E5%90%8D%E4%B9%B1%E7%A0%81%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<p>当文件名为乱码的时候，无法通过键盘输入文件名，所以在终端下就不能直接利用rm，mv等命令管理文件了。
但是我们知道每个文件都有一个i节点号，我们可以考虑通过i节点号来管理文件。首先，我们要取得文件的
i节点号。这个可以通过ls命令的-i选项获得得。</p>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#ls -i</span><br><span class="line">41697812 a 32983551 di 32983554 ethnet.c 32983543 hard_link</span><br><span class="line">32983542 de.c 32983544 ethnet 32983541 ethnet.h 32983543 kstat</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>每个文件名前面的数字就是文件的i节点号。有了文件的i节点号，我们就可以利用find命令的-inum选项配合
常用的文件管理命令进行文件管理了。例如，如果要删除di文件，命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># find . -inum 32983551 -exec rm &#123;&#125; \;</span><br></pre></td></tr></table></figure>
<p>命令中的“{}”表示find命令找到的文件，
要重命名一个文件，命令也很简单，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ls -i</span><br><span class="line">32983542 de.c 32983554 ethnet.c 32983543 hard_link 32983545 kstat.c</span><br><span class="line">32983544 ethnet 32983541 ethnet.h 32983543 kstat 32983681 sys_link</span><br><span class="line"></span><br><span class="line">$ find . -inum 32983542 -exec mv &#123;&#125; di.c \;</span><br><span class="line">$ ls -i</span><br><span class="line">32983542 di.c 32983554 ethnet.c 32983543 hard_link 32983545 kstat.c</span><br><span class="line">32983544 ethnet 32983541 ethnet.h 32983543 kstat 32983681 sys_link</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>de.c文件被重命名为di.c了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux shell下常用快捷键</title>
    <url>/2015/11/21/Linux%20shell%E4%B8%8B%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<p>下述所有命令在 Linux/unix 的 shell 下有效，这里以 bash
为主。如有出入，以你自己的服务器为准。本文所指的 Linux 主要指
RHEL/CentOS，unix 指的是 FreeBSD，这也是服务器中用得最多的版本。
<span id="more"></span></p>
<p><code>Ctrl + a</code> 切换到命令行开始 这个操作跟 Home
实现的结果一样的，但 Home 在某些 unix
环境下无法使用，便可以使用这个组合；在 Linux 下的
vim，这个也是有效的；另外，在 windows
的许多文件编辑器里，这个也是有效的。</p>
<p><code>Ctrl + e</code> 切换到命令行末尾 这个操作跟 END
实现的结果一样的，但 End 键在某些 unix
环境下无法使用，便可以使用这个组合；在 Linux 下的
vim，这个也是有效的；另外，在 windows
的许多文件编辑器里，这个也是有效的。</p>
<p><code>Ctrl + l</code> 清除屏幕内容 效果等同于 clear</p>
<p><code>Ctrl + u</code> 清除剪切光标之前的内容</p>
<p><code>Ctrl + k</code> 剪切清除光标之后的内容</p>
<p><code>Ctrl + y</code> 粘贴刚才所删除的字符
此命令比较强悍，删除的字符有可能是几个字符串，但极有可能是一行命令。</p>
<p><code>Ctrl + r</code> 在历史命令中查找
输入关键字就调出以前的命令了，强烈推荐，有时 history
比较多时，想找一个比较复杂的，直接在这里，shell
会自动查找并调用，方便极了。</p>
<p><code>Ctrl + c</code> 终止命令</p>
<p><code>Ctrl + z</code> 转入后台运行 不过，由 Ctrl + z
转入后台运行的进程在当前用户退出后就会终止，所以用这个不如用 nohup
命令&amp;，因为 nohup
命令的作用就是用户退出之后进程仍然继续运行，而现在许多脚本和命令都要求在
root 退出时仍然有效。</p>
<p><code>Ctrl + d</code> 退出 shell，logout</p>
<p><code>!!</code> 重复执行最后一条命令</p>
<p><code>history</code>
显示你所有执行过的编号+历史命令。这个可以配合!编辑来执行某某命令</p>
<p><code>!$</code> 显示系统最近的一条参数.比如我先用 cat
/etc/sysconfig/iptables，然后我想用 vim 编辑。一般的做法是先用↑
显示最后一条命令，然后用 Home 移动到命令最前，删除 cat，然后再输入 vim
命令。其实完全可以用 vim !$ 来代替。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下安装sun/oracle的jdk</title>
    <url>/2015/11/26/Linux%E4%B8%8B%E5%AE%89%E8%A3%85sun-oracle%E7%9A%84jdk/</url>
    <content><![CDATA[<p>Linux
自带的jdk是<code>openjdk</code>，但是sun/oracle的jdk更加常用一些，据说bug也更少。所以下面就是卸载openjdk安装sun/oralce
jdk的一个教程。</p>
<span id="more"></span>
<h2 id="检查openjdk是否已经安装">检查OpenJDK是否已经安装</h2>
<p><code>rpm -q &lt; rpm package name&gt;</code>
用来查询一个包是否被安装，而<code>rpm -qa</code>则列出了所有被安装的rpm包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ rpm -qa | grep java</span><br><span class="line">tzdata-java-2013b-1.el6.noarch</span><br><span class="line">java-1.6.0-openjdk-1.6.0.0-1.61.1.11.11.el6_4.x86_64</span><br><span class="line">java-1.7.0-openjdk-1.7.0.19-2.3.9.1.el6_4.x86_64</span><br></pre></td></tr></table></figure>
<h2 id="检查openjdk版本">检查OpenJDK版本</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ java -version</span><br><span class="line">java version &quot;1.7.0_19&quot;</span><br><span class="line">OpenJDK Runtime Environment (rhel-2.3.9.1.el6_4-x86_64)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 23.7-b01, mixed mode)</span><br></pre></td></tr></table></figure>
<h2 id="卸载openjdk">卸载Openjdk</h2>
<p>用root用户登录终端,<code>rpm -e --nodeps</code>
表示强制卸载某个rpm包，因为采用<code>rpm -e</code>删除时有时会出现<code>... is needed by ...</code>的依赖提示而不能卸载这个包
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ rpm -e --nodeps java-1.7.0-openjdk-1.7.0.19-2.3.9.1.el6_4.x86_64</span><br><span class="line">$ rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.61.1.11.11.el6_4.x86_64</span><br><span class="line">$ rpm -e --nodeps tzdata-java-2013b-1.el6.noarch</span><br></pre></td></tr></table></figure></p>
<h2
id="下载并安装jdk-7u17-linux-x64.rpm">下载并安装jdk-7u17-linux-x64.rpm</h2>
<p>下载地址：http://pan.baidu.com/share/link?shareid=397488&amp;uk=638583574，<code>rpm -ivh &lt;rpm package&gt;</code>为安装某个rpm包的命令，参数<code>ivh</code>各自的意义如下所示
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-i, --install   install package(s)</span><br><span class="line">-v, --verbose   provide more detailed output</span><br><span class="line">-h, --hash      print hash marks as package installs (good with -v)</span><br></pre></td></tr></table></figure> 而<code>rpm -Uvh</code>则表示升级一个软件包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cd /jdk1.7所在目录</span><br><span class="line">$ rpm -ivh jdk-7u17-linux-x64.rpm</span><br><span class="line">Preparing...                ########################################### [100%]</span><br><span class="line">   1:jdk                    ########################################### [100%]</span><br><span class="line">Unpacking JAR files...</span><br><span class="line">    rt.jar...</span><br><span class="line">Error: Could not open input file: /usr/java/jdk1.7.0_17/jre/lib/rt.pack</span><br><span class="line">    jsse.jar...</span><br><span class="line">Error: Could not open input file: /usr/java/jdk1.7.0_17/jre/lib/jsse.pack</span><br><span class="line">    charsets.jar...</span><br><span class="line">Error: Could not open input file: /usr/java/jdk1.7.0_17/jre/lib/charsets.pack</span><br><span class="line">    tools.jar...</span><br><span class="line">Error: Could not open input file: /usr/java/jdk1.7.0_17/lib/tools.pack</span><br><span class="line">    localedata.jar...</span><br><span class="line">Error: Could not open input file: /usr/java/jdk1.7.0_17/jre/lib/ext/localedata.pack</span><br><span class="line">以上那些错误可以忽略，不影响jdk到安装和使用</span><br></pre></td></tr></table></figure>
<h2 id="配置环境变量">配置环境变量</h2>
<p>这是很关键的一步，jdk使用过程中绝大部分问题都跟环境变量的配置有关，需要配置的变量有<code>JAVA_HOME</code>，<code>PATH</code>和<code>CLASSPATH</code>,其中<code>JAVA_HOME</code>表示Java的安装目录，<code>PATH</code>是为了让系统在任何路径下都可以识别出java的命令，<code>CLASSPATH</code>则指定Java运行时查找class文件的路径，尤其需要注意CLASSPATH需要包含当前目录，也就是<code>.</code>，而且还要包含工具类库<code>tool.jar</code>；如果需要Swing包，还可以添加<code>dt.jar</code>。所以上面这三个变量的最简配置如下所示：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$vi /etc/profile #在最后加入以下内容：</span><br><span class="line">JAVA_HOME=/usr/java/jdk1.7.0_17</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">CLASSPATH=.:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export JAVA_HOME  PATH CLASSPATH</span><br></pre></td></tr></table></figure> 使环境变量立即生效 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$source /etc/profile</span><br></pre></td></tr></table></figure> ## 测试安装是否成功
依次输入<code>java,java -version,javac</code>，看到输出信息即可,例如
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># java -version</span><br><span class="line">java version &quot;1.7.0_17&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.7.0_17-b02)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 23.7-b01, mixed mode)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下的环境变量</title>
    <url>/2015/11/21/Linux%E4%B8%8B%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url>
    <content><![CDATA[<h2 id="linux环境变量种类">linux环境变量种类</h2>
<p>按照生成周期看，可以分为二类</p>
<ul>
<li>永久的（需要修改配置文件，变量永久生效）</li>
<li>临时的，使用export命令声明即可，变量在关闭shell时失效.</li>
</ul>
<span id="more"></span>
<h2 id="设置变量三种方法">设置变量三种方法</h2>
<p>（1）在/etc/profile文件中添加变量(对所有用户生效,永久的)例如添加CLASSPATH变量，</p>
<pre><code># vi /etc/profile
JAVA_HOME=/usr/java/jdk1.7.0_17
JRE_HOME=/usr/java/jdk1.7.0_17/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/
export JAVA_HOME JRE_HOME PATH CLASSPATH
</code></pre>
<p>要想马上生效，需要 <code>source /etc/profile</code></p>
<p>（2）在用户目录下的.bash_profile文件添加变量(对单一用户生效，永久的)
（3）直接运行export , 对当前shell有效</p>
<h2 id="环境变量查看">环境变量查看</h2>
<ul>
<li>查看所有环境变量, 命令 env</li>
<li>查看单个 echo $CLASSPATH</li>
<li>set查看本地定义环境变量 , unset可以删除指定环境变量</li>
</ul>
<h2 id="常用环境变量介绍">常用环境变量介绍</h2>
<ul>
<li>PATH 指定shell在那个目录下寻找命令或程序</li>
<li>HOME 当前用户登录名</li>
<li>HISTORY 历史记录</li>
<li>LOGNAME 当前用户登录名</li>
<li>HOSTNAME 指定主机名称</li>
<li>SHELL 当前shell类型</li>
<li>LANGUGE 语言相关环境变量</li>
<li>MAIL 当前邮件存放目录</li>
<li>PSI 基本提示符，对root 是# 普通用户$</li>
</ul>
<h2 id="设置linux的环境变量语法解释">设置Linux的环境变量,语法解释</h2>
<ul>
<li>在修改了PATH值或任何环境变量后,都要用export将其输出,新的PATH值才能生效.</li>
<li><code>PATH=\$PATH:路径1:路径2:...:路径n</code>
意思是可执行文件的路径<strong>包括原先设定的路径</strong>,也包括从
<code>路径1</code> 到 <code>路径n</code>
的所有路径.当用户输入一个一串字符并按回车后,shell会依次在这些路径里找对应的可执行文件并交给系统核心
<code>$PATH</code> 表示原先设定的路径仍然有效,注意不要漏掉。</li>
<li>与DOS/Window不同,UNIX类系统环境变量中路径名<strong>用冒号分隔,不是分号</strong>.另外,软件越装越多,环境变量越添越多,为了避免造成混乱,建议所有语句都<strong>添加在文件结尾,按软件的安装顺序添加</strong>,格式如下()：
<code># 软件名-版本号-安装日期</code></li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux传输文件的小工具lrzsz</title>
    <url>/2015/11/28/Linux%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7lrzsz/</url>
    <content><![CDATA[<p>常常有些小文件需要从本地的Windows传到Linux服务器或者从Linux服务器下载到本地，如果用ftp就显得杀鸡用牛刀了，这时候工具<code>lrzsz</code>就显得比较有用了</p>
<span id="more"></span>
<p>　　首先需要安装这个工具，以CentOS为例，通过yum安装即可，即
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install lrzsz</span><br></pre></td></tr></table></figure>
可用的命令为<code>rz</code>和<code>sz</code>,可通过下面的方式来记忆</p>
<ul>
<li>sz中的s意为send（发送），告诉客户端，我（服务器）要发送文件 send to
cilent，就等同于客户端在下载。</li>
<li>rz中的r意为received（接收），告诉客户端，我（服务器）要接收文件
received by cilent，就等同于客户端在上传。
<strong>记住一点，不论是send还是received，动作都是在服务器上发起的。</strong></li>
</ul>
<p>　　运行命令rz，Xshell(或SecureCrt)就会弹出文件选择对话框，选好文件以及传输方式（文本还是二进制）之后关闭对话框，文件就会上传到linux里的当前目录。</p>
<p>　　运行命令<code>sz file</code>
就是发文件到Windows上（保存的目录是可以配置,因为sz利用了ZModem协议来传输文件，所以一般可在使用的连接工具（如Xshell等）中设置）；常用的参数如下所示：
- -a 以文本方式传输（ascii） - -b 以二进制方式传输（binary） - -e
对控制字符转义（escape），这可以保证文件传输正确</p>
<p>也可将文件先压缩成一个压缩文件再传输。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux命令的系统调用和库函数的调用</title>
    <url>/2015/11/21/Linux%E5%91%BD%E4%BB%A4%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E5%92%8C%E5%BA%93%E5%87%BD%E6%95%B0%E7%9A%84%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<p>查看Linux命令的系统调用和库函数的调用可通过下面的命令。</p>
<ul>
<li><strong>strace -c
command</strong>：判断command命令的系统调用的类型、次数、消耗时间（-f则连同command命令fork出来的子进程一同统计，-e指定列出某一具体的系统调用的参数）</li>
<li>ltrace
用法同strace,但是追踪的是命令调用的库函数，strace追踪的是系统调用</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux挂载NTFS文件系统</title>
    <url>/2015/11/30/Linux%E6%8C%82%E8%BD%BDNTFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>最近将服务器内的数据迁移到移动硬盘上做备份时，发现Centos
6.5识别不了NTFS文件系统的移动硬盘，google了一下才发现原因是Linux内核不支持NTFS。重新编译内核是一种方法，但是也可以采用安装一个软件来解决，本文就是讲述如何安装这个软件以及在Linux挂载NTFS文件系统的移动硬盘。</p>
<span id="more"></span>
<p>这个软件就是NTFS-3G。NTFS-3g是一个开源软件，它支持在Linux下面读写NTFS格式的分区。更多信息可参考NTFS-3G官网：http://www.ntfs-3g.org</p>
<h2 id="安装">安装</h2>
<p>安装方式有两种： ### yum源安装
　　如果配置的yum源有ntfs-3g这个包，那么可以通过<code>yum install ntfs-3g</code>来直接安装，如果配置的yum源没有这个包，可以参照下一种安装方式
### 编译安装
下载地址为：http://www.tuxera.com/community/open-source-ntfs-3g/,也可通过wget下载，安装过程如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># wget https://tuxera.com/opensource/ntfs-3g_ntfsprogs-2015.3.14.tgz</span><br><span class="line"># tar -zxvf ntfs-3g_ntfsprogs-2015.3.14.tgz</span><br><span class="line"># cd ntfs-3g_ntfsprogs-2015.3.14</span><br><span class="line"># ./configure</span><br><span class="line"># make </span><br><span class="line"># make install</span><br></pre></td></tr></table></figure>
<h2 id="使用">使用</h2>
<p>###　获取NFTS设备名称 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#fdisk -l | grep -i ntfs</span><br><span class="line"> /dev/sdb1    1     10443  83883366   7  HPFS/NTFS</span><br></pre></td></tr></table></figure>
可知设备名为<code>/dev/sdb1</code></p>
<h3 id="建立挂载点并挂载">建立挂载点并挂载</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># mkdir /mnt/ntfs</span><br><span class="line"># mount -t ntfs-3g /dev/sda1 /mnt/ntfs</span><br></pre></td></tr></table></figure>
<p>这样访问<code>/mnt/ntfs</code>目录便可往硬盘进行读写了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux的CPU调度</title>
    <url>/2015/11/21/Linux%E7%9A%84CPU%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="内核版本与cpu调度算法">内核版本与CPU调度算法</h2>
<p>早期 Linux
版本中的调度算法非常简单易懂：<strong>在每次进程切换时，内核扫描可运行进程的链表，计算进程的优先权，然后选择“最佳”进程来运行</strong>。这个算法的主要缺点是选择“最佳”进程所要消耗的时间与可运行的进程数量相关，因此，这个算法的开销太大，在运行数千个进程的高端系统中，要消耗太多的时间。</p>
<p>Linux 2.6
的调度算法就复杂多了。通过设计，该算法较好地解决了与可运行进程数量的比例关系，因为它<strong>在固定的时间内（时间复杂度O(1)）选中要运行的进程</strong>。它也很好地处理了与处理器数量的比例关系，因为<strong>每个
CPU
都拥有自己的可运行进程队列</strong>。而且，新算法较好地解决了区分交互式进程和批处理进程的问题。因此，在高负载的系统中，用户感到在
Linux2.6 中交互应用的响应速度比早期的 Linux 版本要快。</p>
<span id="more"></span>
<h2 id="调度方式">调度方式</h2>
<p>内核2.6版本有5种调度方式，分别是</p>
<ul>
<li>SCHED_FIFO</li>
<li>SCHED_RR</li>
<li>SCHED_IDLE</li>
<li>SCHED_BATCH</li>
<li>SCHED_OTHER</li>
</ul>
<p>##两种类型进程比较</p>
<table style="width:100%;">
<colgroup>
<col style="width: 44%" />
<col style="width: 33%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="header">
<th>两种进程</th>
<th>动态优先级进程(非实时进程)</th>
<th>静态优先级进程(实时进程)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>优先级</td>
<td>低</td>
<td>高</td>
</tr>
<tr class="even">
<td>能否调整</td>
<td>用户可调nice值，但最终由系统动态调整</td>
<td>用户可通过chrt改，系统不会动态调整</td>
</tr>
<tr class="odd">
<td>应用</td>
<td>一般用户进程</td>
<td>内核进程</td>
</tr>
<tr class="even">
<td>调度方式</td>
<td>SCHED_IDLE(BATCH/OTHER)</td>
<td>SCHED_FIFO(RR)</td>
</tr>
<tr class="odd">
<td>top显示的pr值</td>
<td>大于0</td>
<td>RT或负值</td>
</tr>
</tbody>
</table>
<p>由此可知，<strong>top命令显示的pr值越小，优先级越高</strong></p>
<h2 id="chrt工具">chrt工具</h2>
<p>通过chrt（change real
time）工具可以改变<strong>实时进程优先级</strong>和<strong>所有进程的调度方式</strong>，其可调整的内容如下所示：</p>
<p>[][1]</p>
<p>用top显示出的pr值与进程实际优先级的关系</p>
<p>[][2] 　　
[1]:https://wulc.me/imgs/d26a3eab-a2f3-11e5-9531-e55c4553df92.png
[2]:https://wulc.me/imgs/imagepriority.png</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux锁定用户与解锁</title>
    <url>/2015/12/06/Linux%E9%94%81%E5%AE%9A%E7%94%A8%E6%88%B7%E4%B8%8E%E8%A7%A3%E9%94%81/</url>
    <content><![CDATA[<h2 id="禁止个别用户登录">禁止个别用户登录</h2>
<p>禁止单个用户的登录有两种方法。下面以禁止test用户登录为例</p>
<h3 id="方法一">方法一</h3>
<p>直接命令禁止 <code>passwd -l test</code>
这条命令的意思是锁定test用户，这样该用户就不能登录了。
<code>passwd -u test</code> 对锁定的用户test进行解锁，用户可登录了。</p>
<span id="more"></span>
<h3 id="方法二">方法二</h3>
<p>修改/etc/passwd文件中用户登录的shell</p>
<p>vi /etc/passwd test:x:500:500::/home/test:/bin/<code>bash</code>
更改为： test:x:500:500::/home/lynn:/sbin/<code>nologin</code>
该用户就无法登录了。</p>
<h2 id="禁止所有用户登录">禁止所有用户登录</h2>
<p>touch /etc/nologin 除root以外的用户不能登录了！</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Long Tail Problem In Item Recommendation</title>
    <url>/2022/04/04/Long%20Tail%20Problem%20In%20Item%20Recommendation/</url>
    <content><![CDATA[<p>长尾问题在推荐/广告系统是一个较为常见的问题(这里主要针对 item
的长尾)，原因可能比较多，笔者理解的主要原因是由于系统存在 feedback
loop(即训练数据由模型产生，同时又会被模型用于训练)
的特性，在没有外部干预的情况下，马太效应会天然导致头部效应的现象比较严重，少部分的
item 主导了整个系统。</p>
<p>比如说推荐系统中，很多视频/文章并没有展示机会，在训练集中压根没出现过，高热的视频/文章在不同的用户中排序都比较靠前，进而得到多次被推荐的机会；在广告系统中，部分计划的消耗会特别高，而一些计划压根投不出去；这导致了用户或者广告主体验不佳，而这种现象往往也会被归为生态问题。</p>
<p>既然没有干预时，系统天然的特性导致了头部效应(或者说二八效应)比较严重，那强行干预系统的分布能不能改变这个问题？答案是可以的，而且目前绝大部分的方法都是在做这一类事情，常用手段往往有
2 种</p>
<p>（1）策略层面，根据系统和业务特性设计规则，比如说对长尾的 item
有特定的扶持，强行让这些 item 能触达到更多的用户
（2）模型层面，<strong>核心思想就是让模型能更好地学习到 long tail item
的 representation</strong>，因为这个问题的根本原因就是 long tail item
的样本过少，进而导致模型学习的不好；而具体的手段比较多，这部分会在后面详细介绍。</p>
<p>这篇文章主要介绍的几篇
paper都是模型层面的，因为策略层面的往往需要根据实际业务需求来拍一些规则，模型层面的一些方法更为通用。</p>
<span id="more"></span>
<h2 id="dual-transfer-learning-framework">Dual Transfer Learning
Framework</h2>
<p>这个方法来自 google 的一篇 paper, <a
href="https://arxiv.org/abs/2010.15982">A Model of Two Tales: Dual
Transfer Learning Framework for Improved Long-tail Item
Recommendation</a></p>
<p>paper 名字中提到的 dual transfer learning，分别是 model-level 和
item-level 的 transfer learning，简单来说，前者让样本少的模型(few-shot
model)的参数尽可能往样本多的模型(many-shot
model)的参数靠拢(这里根据样本量分为 2 个模型来建模)，后者则是让 long
tail item 的 representation 与 head item 的尽可能接近，这里的
representation 其实就是上面提到的 few-shot model 和 many-shot model
吐出来的 embedding，因此 paper 提出的总体框架如下如所示</p>
<figure>
<img src="https://wulc.me/imgs/DualTransfer_MIRec.jpg" alt="MIRec" />
<figcaption aria-hidden="true">MIRec</figcaption>
</figure>
<p>上图中的一些符号含义如下</p>
<!-- ![notation][3] -->
<p><img src="https://wulc.me/imgs/DualTransfer_Notataion.jpg" height="50%" width="50%"></p>
<p>从上图中可以看到，根据样本量分为了 many-shot model 和 few-shot model
两个模型来分别建模，核心是 meta-level knowledge transfer 和 curriculum
transfer，分别对应前面的 model-level 和 item-level, 下面分别介绍</p>
<h3 id="model-level">model-level</h3>
<p>其思想比较简单，就是要学习一个 meta learner <span
class="math inline">\(\mathcal{F}\)</span>, 其输入和输出都是 few-shot
model 的 parameter，监督信号是输出的 parameter 要与 many-shot model 的
parameter 接近，最终作用方式是在 loss 上</p>
<p>base learner 的 loss 是常规的 softmax loss，<span
class="math inline">\(r(u,i)\)</span> 取值为 1/0 表示是否有 feedback(如
click 等)</p>
<!-- ![base learner][4] -->
<p><img src="https://wulc.me/imgs/DualTransfer_baselearner.jpg" height="50%" width="50%"></p>
<p>meta learner <span class="math inline">\(\mathcal{F}\)</span>
则是采用了 mse 的 loss，并且作为一个 regularization 项加到 few-shot
model 原始的 loss 上，则最终 few-shot model 的 loss 如下公式(5)所示</p>
<!-- ![meta learner][5] -->
<p><img src="https://wulc.me/imgs/DualTransfer_metalearner.jpg" height="50%" width="50%"></p>
<p>meta learner <span class="math inline">\(\mathcal{F}\)</span>
具体的结构有很多种，这里采用的是简单的 fully connected layer</p>
<h3 id="item-level">item-level</h3>
<p>这部分主要通过 <a href="https://arxiv.org/abs/2007.12865">curriculum
learning</a> 来训练模型，curriculum learning
的基本思想是在训练时组织好样本进模型的顺序，前面的综述的链接里的话是这么说的</p>
<blockquote>
<p>Curriculum learning (CL) is a training strategy that trains a machine
learning model from easier data to harder data, which imitates the
meaningful learning order in human curricula. As an easy-to-use plug-in,
the CL strategy has demonstrated its power in improving the
generalization capacity and convergence rate of various models in a wide
range of scenarios such as computer vision and natural language
processing etc.</p>
</blockquote>
<p>回到 paper 里，这部分主要做的则是构造好上面提到的两个 training
dataset：<span class="math inline">\(\Omega^{*}\)</span> 和 <span
class="math inline">\(\Omega(k)\)</span></p>
<!-- ![many-shot dataset][7] -->
<p><img src="https://wulc.me/imgs/DualTransfer_manyshot_dataset.jpg" height="50%" width="50%"></p>
<p><span class="math inline">\(\Omega(k)\)</span>
的构造方法如下，这部分样本包含 2 部分 item，一部分是 <span
class="math inline">\(I_{h}(k)\)</span> 中那些刚好有 k 个sample 的
item，另一部分则是 <span class="math inline">\(I_{t}(k)\)</span>
中的全部 sample</p>
<!-- ![few-shot dataset][8] -->
<p><img src="https://wulc.me/imgs/DualTransfer_fewshot_dataset.jpg" height="50%" width="50%"></p>
<p>paper 里称这么做主要有以下 2 个原因，但是笔者觉得核心还是把 long tail
item 的样本单独出来，不至于被 head item dominate</p>
<blockquote>
<ol type="1">
<li>tail items are fully trained in both the many-shot model and
few-shot model to ensure the high quality of the learned item
representations in both many-shot and few-shot models (2）In the
few-shot model training, the distribution of tail items relatively keeps
the same as the original distribution. It can alleviate the bias among
tail items that brings by the new distribution</li>
</ol>
</blockquote>
<h3 id="training-serving">training &amp; serving</h3>
<p>因此，总体的 training 流程如下图所示,
可以分为两个阶段，阶段一是通过常规的方法训练 many-shot
model，阶段二则是通过 many-shot model 的 parameter 和 meta learner
来训练 few-shot model</p>
<!-- ![train][9] -->
<p><img src="https://wulc.me/imgs/DualTransfer_training.jpg" height="50%" width="50%"></p>
<p>而最终模型 serving 时，则是会对两个 model 输出的 score
做一个常规的加权</p>
<!-- ![serving][10] -->
<p><img src="https://wulc.me/imgs/DualTransfer_prediction.jpg" height="50%" width="50%"></p>
<h3 id="experiment">experiment</h3>
<p>paper 里的实验用了 2 个公开的数据集，MovieLens1M 和
Bookcrossing，采用的评估指标是Hit Ratio at top K (HR@K) 和 NDCG at top K
(NDCG@K) ，这里的 HR@K 其实就是召回率</p>
<p>实验预期的目标是在总体效果不变差的前提下，提升 long tail item
的表现；因此上面的两个评估指标 HR@K 和 NDCG@K 分别在all item、head item
和 tail item 上进行了评估</p>
<p>paper 里的实验着重回答了以下四个问题</p>
<blockquote>
<p>RQ1: How well does the dual transfer learning framework MIRec perform
compared to the state-of-the-art methods? RQ2: How do different
components (meta-learning and curriculum learning) of MIRec perform
individually? Could they complement each other? RQ3: How does our
proposed curriculum learning strategy compare with the alternatives?
RQ4: Besides downstream task performance, are we actually learning
better representations for tail items? Could we see the differences
visually?</p>
</blockquote>
<p>第一个问题是跟其他的 sota 方法比较，结论是 paper
提出的最好，具体数据这里就不贴了</p>
<p>第二个问题是做了一个消融实验，结论是单独的 meta-learning 或
curriculum learning 都是正向的，且加起来效果最好</p>
<p>第三个问题是对比不同的 curriculum learning strategy 对 training 和
validation 时的 loss 的值的影响；主要对比了 head2tail 和 tail2head
两个策略，前者先用 head item 训练，再用 tail item
训练，后者则刚好相反，这部分效果如下图所示，也可以归纳出以下 3
点结论</p>
<blockquote>
<ol type="1">
<li>Compared to the tail item loss in different curriculums (column 3),
our proposed curriculum can bring a two-stage decent for both the
training and validation loss</li>
<li><strong>When the model is trained based on only head/tail items, the
validation performance for the other part of items decreases</strong>.
The different changes of head and tail loss indicate the large
variations between head and tail items</li>
<li>It is easily to get validation loss increases if the model is
trained purely based on head/tail items, as shown in first column of the
first two rows</li>
</ol>
</blockquote>
<figure>
<img src="https://wulc.me/imgs/DualTransfer_CL_compare.jpg"
alt="CL compare" />
<figcaption aria-hidden="true">CL compare</figcaption>
</figure>
<p>第四个问题是对学习出来的 embedding 进行可视化，主要想说明通过 paper
的方法学到的方法在可视化上后区分性也比较强，不过只做了两个 case
分析，数据有限，这里就不贴出来了</p>
<h2 id="self-supervised-learning-framework">Self-supervised Learning
Framework</h2>
<p>这个方法来自 google 的另一篇 paper <a
href="https://arxiv.org/abs/2110.04596">Self-supervised Learning for
Large-scale Item Recommendations</a>, 也是在解决 item
的长尾问题，提升的点也主要在 representation learning 上，如 paper
描述所示</p>
<blockquote>
<p>The framework is designed to tackle the label sparsity problem by
learning better latent relationship of item features. Specifically, SSL
improves item representation learning as well as serving as additional
regularization to improve generalization. Furthermore, we propose a
novel data augmentation method that utilizes feature correlations within
the proposed framework.</p>
</blockquote>
<h3 id="ssl-framework">SSL Framework</h3>
<p>paper 提出的总体的 framework
如下图所示，基本符号的含义都在图片下方的注释里，</p>
<!-- ![ssl framework][13] -->
<p><img src="https://wulc.me/imgs/SelfSupervisedLearningFramework.jpg" height="50%" width="50%"></p>
<p>而上图中的 <span class="math inline">\(x_i\)</span>、<span
class="math inline">\(x_j\)</span> 表示训练时一个 batch
中的两条样本(推荐中的样本往往有三种含义，query/item/query-item
pair，paper 里特指的是
item)，这里的核心思想是<strong>同一条样本经过不同的变换后的
representation 应该还是相似的，不同的样本则相反</strong></p>
<p>因此，通过 <span class="math inline">\(h, g, \mathcal{H},
\mathcal{G}\)</span> 得到的 representation 中，<span
class="math inline">\((z_i, z_i^{&#39;})\)</span> 是正例，而 <span
class="math inline">\((z_i, z_j^{&#39;})\)</span>
是负例，因此，对于一个包含 <span class="math inline">\(N\)</span>
条样本的 batch 中，第 <span class="math inline">\(i\)</span> 条样本的
self supervised 的 loss 形式如下</p>
<p><span class="math display">\[\mathcal{L}_{self}(x_i) = -\log
\frac{\exp(s(z_i, z_i^{&#39;})/\tau)}{\sum_{j=1}^{N}\exp(s(z_i,
z_j^{&#39;})/\tau)}\]</span></p>
<p>上面公式中的 <span class="math inline">\(\tau\)</span>
为一个超参(softmax temperature),<span class="math inline">\(s(z_i,
z_j^{&#39;})\)</span> 为两个 embedding 的 cosin 相似性，即 <span
class="math inline">\(s(z_i, z_j^{&#39;})=&lt; z_i,
z_j^{&#39;}&gt;/(||z_i|| \cdot ||z_j^{&#39;}||)\)</span></p>
<p>总体的 batch 内的 self supervised loss 为</p>
<p><span class="math display">\[\mathcal{L}_{self}(\lbrace x_i \rbrace;
\mathcal{H}, \mathcal{G}) = - \frac{1}{N} \sum_{i=1}^{N} \log
\frac{\exp(s(z_i, z_i^{&#39;})/\tau)}{\sum_{j=1}^{N}\exp(s(z_i,
z_j^{&#39;})/\tau)}\]</span></p>
<p>得到 embedding 的两个 emcoder： <span
class="math inline">\(\mathcal{H}\)</span> 和 <span
class="math inline">\(\mathcal{G}\)</span>，在 paper
中是共享参数的(这部分在后面讲模型结构时也会提及)</p>
<p>而如果两种 data augmentation 方法 <span
class="math inline">\(h\)</span> 和 <span
class="math inline">\(g\)</span> 也是相同的话，上面的 <span
class="math inline">\(\mathcal{L}_{self}(\lbrace x_i \rbrace;
\mathcal{H}, \mathcal{G})\)</span>
会退化成如下形式，此时损失函数的目标是不同样本的相似性 <span
class="math inline">\(s(z_i, z_j^{&#39;})\)</span> 尽可能小</p>
<p><span class="math display">\[-\frac{1}{N} \sum_{i=1}^{N} \log
\frac{\exp(1/\tau)}{ \exp(1/\tau) + \sum_{j \ne i}\exp(s(z_i,
z_j^{&#39;})/\tau)}\]</span></p>
<h3 id="two-stage-data-augmentation">two-stage data augmentation</h3>
<p>这里主要讲上面框架提到的两种 data augmentation 方法： <span
class="math inline">\(h\)</span> 和 <span
class="math inline">\(g\)</span> ，paper 称这个方法的关键在于：<strong>A
good transformation and data augmentation should make minimal amount of
assumptions on the data such that it can be generally applicable to a
large variety of tasks and models</strong>.</p>
<p>paper 里采用的方法则是 mask, 这里借鉴了 bert 的思想，但是这里没有
sequence 的概念，因此这里 mask 掉的是 item feature，实际使用的是一个
two-stage 的方法，即 masking + dropout, 两个方法主要操作如下</p>
<blockquote>
<p><strong>Masking</strong>. Apply a masking pattern on the set of item
features. We use a <strong>default embedding</strong> in the input layer
to represent the features that are masked. <strong>Dropout</strong>.For
categorical features with <strong>multiple values,we drop out each value
with a certain probability</strong>. It further reduces input
information and increase the hardness of SSL task.</p>
</blockquote>
<p>至于具体的 mask 方法，paper 里没有采用随机
mask，而是基于特征之间的互信息(<a
href="https://en.wikipedia.org/wiki/Mutual_information">mutual
information</a>)来进行 mask，核心思想是 <strong>mask
掉相关性较强的特征</strong>，paper 这样做的原因是
<code>the SSL contrastive learning task may exploit the shortcut of highly correlated features between the two augmented examples, making the SSL task too easy</code></p>
<p>具体的方法的方法是每次每次随机选择一个 feature <span
class="math inline">\(f_{seed}\)</span>，通过预先计算好的互信息选择与这个
feature 最相关的 <span class="math inline">\(k/2\)</span> 个
feature，最终 mask 掉的是这 <span class="math inline">\(k/2 + 1\)</span>
个 feature</p>
<h3 id="training-serving-1">training &amp; serving</h3>
<p>前面的 self supervised loss（ <span
class="math inline">\(\mathcal{L}_{self}(\lbrace x_i
\rbrace)\)</span>）只是一个辅助的 loss,</p>
<p>而主任务的 loss 是计算 query-item 的 loss，paper 这里采用的是 batch
softmax loss，形式跟self supervised loss其实是一样的，只是计算相似性从
item-item 变为了 query-item，具体形式如下</p>
<p><span class="math display">\[\mathcal{L}\_{main} = -\frac{1}{N}
\sum_{i=1}^{N} \log \frac{\exp(s(q_i,
x_i)/\tau)}{\sum_{j=1}^{N}\exp(s(q_i, x_j)/\tau)}\]</span></p>
<p>则总体的 loss 为</p>
<p><span class="math display">\[\mathcal{L} = \mathcal{L}\_{main} +
\alpha \mathcal{L}\_{self}\]</span></p>
<p>则最终的模型如下所示，注意这里的 3 个 item twoer 的参数是共享的</p>
<figure>
<img src="https://wulc.me/imgs/SelfSupervisedTraining.jpg"
alt="train" />
<figcaption aria-hidden="true">train</figcaption>
</figure>
<p>至于 serving，由于只是加了一个 auxiliary loss，所以按正常预估即可</p>
<h3 id="experiment-1">experiment</h3>
<p>实验主要回答了如下 4 个问题</p>
<blockquote>
<p>RQ1: Does the proposed SSL Framework improve deep models for
recommendations?</p>
<p>RQ2:SSL is designed to improve primary supervised task through
introduced SSL task on unlabeled examples. What is the impact of the
amount of training data on the improvement from SSL?</p>
<p>RQ3: How do the SSL parameters, i.e., loss multiplier <span
class="math inline">\(\alpha\)</span> and dropout rate in data
augmentation, affect model quality?</p>
<p>RQ4: How does RFM perform compared to CFM? What is the benefit of
leveraging feature correlations in data augmentation?</p>
</blockquote>
<p>RQ1，通过与其他 3 个 baseline 进行了比较，采用了 2
个公开数据，评估指标是 MAP@10/50 和 Recall@10/50, 跟前一篇 paper
一样，做了总体 item、head item 和 tail item 各自的评估</p>
<p>RQ2 主要回答数据量对 SSL
的影响，结论是数据量越多，效果越好，感觉这个结论比较符合直觉，不知道
paper 为什么要单独拎出来说</p>
<p>RQ3 主要回答 <span class="math inline">\(\alpha\)</span>
大小对效果的影响，paper 里对比 spread-out regularization loss 和 paper
提出的 self supervised loss，结论是取相同的值时均是 self supervised loss
效果更好，关于 <a href="https://arxiv.org/pdf/1708.06320.pdf">spread-out
regularization loss</a> 可参考这篇 paper，也是一种 constrasive
loss，但是没有 data augmentation</p>
<p>RQ4 主要回答随机 mask 的方法(RFM) 和基于相关性 mask
的方法(CFM)哪种效果更好，结论是CFM在四项指标上效果均优于 RFM</p>
<p>此外，paper 还补充了在线 ab 实验，结论也是比较显著的</p>
<h2 id="小结">小结</h2>
<p>本文主要介绍了从模型层面缓解长尾问题的两篇 paper，两篇 paper
的核心思想都是要更好地学习到长尾 item 的 representation</p>
<p>第一篇提出了一个 dual transfer framework(model-level + item-level),
通过 2 个模型分别建模 head item 和 tail item，在 model-level 令 tail
item 的模型参数往 head item 的模型学习，而在 item-level 通过 curriculum
learning 组织样本进模型的顺序，serving
阶段需要用两个模型的预估分融合</p>
<p>第二篇 paper 则提出了 self-supervised learning framework, 通过
in-batch 的 data augmentation 方法(mask + dropout)，增加一个 auxiliary
loss，其目标是同一个 item 经过变换后的 embedding 应该是相似的，不同 item
的则相反；离线和在线的实验都验证了有效性。</p>
<p>笔者感觉实际业界中，第一种方法的成本要高于第二种，而第一种方法没有做在线的
ab 实验不知道具体在线效果，且第二种方法这种通过 in-batch
样本来构造新的样本对的 self-supervised learning，普适性会更好</p>
<p>除了推荐领域的，CV 领域也有一篇关于长尾问题的综述，<a
href="https://arxiv.org/abs/2110.04596">Deep Long-Tailed Learning: A
Survey</a>，总体的方法论会更全，思路也涵盖了上面说的两篇 paper，但是 cv
跟 recommendation 还是有不少差异的(比如 recommendation 的 item 数往往比
cv 的要多得多)，具体在业务的应用也不确定，这里就不详细展开了。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning with Spark 简介</title>
    <url>/2017/11/05/MachineLearning%20with%20Spark%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>本文主要介绍 《<a
href="https://www.amazon.com/Machine-Learning-Spark-Powerful-Algorithms/dp/1783288515/ref=sr_1_sc_1?ie=UTF8&amp;qid=1509631766&amp;sr=8-1-spell&amp;keywords=macine%20learning%20with%20spark">Machine
Learning with
Spark</a>》这本书各章节的主要内容，以及提供该书各章节对应的 python
代码。</p>
<span id="more"></span>
<p>这本书主要介绍了如何通过 spark
处理大规模的数据，以及利用这些处理过的数据通过 MLlib
进行模型的训练。全书共分为10章，涵盖了数据的预处理，推荐模型，分类模型，回归模型，聚类模型，数据降维，文本处理以及
Spark 流式处理等内容。</p>
<p>书中的代码大部分是 scala， 某些章节是 python，这里全部通过 python
重写，全部代码参见 <a
href="https://github.com/WuLC/MachineLearningWithSpark">github</a>，为了便于交互，采用了
Jupyter Notebook 的形式，且通过 HDFS
存储数据文件，关于环境的搭建可参考<a
href="http://wulc.me/2017/09/13/Spark%20%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%92%8C%20Jupyter%20Notebook%20%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/">这篇文章</a>。</p>
<p>下面简单介绍各个章节的内容（从第三章开始），更多细节可参考具体代码</p>
<h2
id="chapter-3obtaining-processing-and-preparing-data-with-spark">Chapter
3：Obtaining, Processing, and Preparing Data with Spark</h2>
<p>这章主要介绍了如何通过 spark 提供的 API
从原始数据中提取特征，如一些常用的函数 <code>map</code>,
<code>filter</code>, <code>reduceByKey</code> 等，以及如何通过 spark
进行特征的归一化和处理以下几种 feature</p>
<ol type="1">
<li><strong>category feature</strong>：one-hot 编码</li>
<li><strong>text feature</strong>：抽取文本 -&gt; 分词 -&gt;
创建字典，为每个单词分配一个唯一的id -&gt; 将文本转为向量</li>
<li><strong>derived
feature</strong>：这个主要是指从非结构化的特征中抽取出结构化的特征，如给出一个日期，可以提取出其中的小时部分，然后进行分段，分为
morning，noon，afternoon，evening四个阶段，然后再进行 one-hot 编码</li>
</ol>
<h2 id="chapter-4building-a-recommendataion-engine-with-spark">Chapter
4：Building a Recommendataion Engine with Spark</h2>
<p>这一章主要介绍如何通过 spark 构建一个推荐系统，采用了电影评分数据集
<a
href="http://files.grouplens.org/datasets/%20movielens/ml-100k.zip">MovieLens
100k</a>，使用的是经典的协同过滤技术，而 spark 的 MLlib 则提供了
alternating least squares (ALS)
这种基于矩阵分解的方法用于求解协同过滤问题，通过
ALS对用户-物品评分矩阵进行分解，能够为每个用户或物品推荐 top k
个最相似的用户或物品。度量 ALS 算法效果的指标为 MSE，RMSE等。</p>
<h2 id="chapter-5building-a-classifcation-model-with-spark">Chapter
5：Building a Classifcation Model with Spark</h2>
<p>这一章主要介绍分类模型，采用了 <a
href="http://www.kaggle.com/c/stumbleupon/data">Kaggle
上的一个数据集</a>，通过 MLlib 提供的
LogisticsRegression，SVM，NaiveBayes，DecisionTree
等分类器对其进行分类，并且比较了进行 feature standardization
前后的效果。</p>
<h2 id="chapter-6building-a-regression-model-with-spark">Chapter
6：Building a Regression Model with Spark</h2>
<p>这一章主要介绍了回归模型，采用了 <a
href="http://archive.ics.uci.edu/ml/%20datasets/Bike+Sharing+Dataset">bike
sharing 数据集</a>，主要通过 MLlib 提供的回归模型 Linear Regression 和
Decision
Tree进行了预测，并且对目标变量进行了log变换，目的是让目标变量更加接近
正态分布，因为像 Linear Regression
这一类模型对目标函数值的分布做了正态分布的假设。</p>
<h2 id="chapter-7building-a-clustering-model-with-spark">Chapter
7：Building a Clustering Model with Spark</h2>
<p>这一章主要介绍了聚类模型，采用的是前面提到的 MovieLens 100k
数据集，通过 ALS
进行矩阵分解，为每个用户(物品)提取出一个隐含属性向量作为用户(物品)的特征向量。然后通过
K-Means 进行聚类。</p>
<p>聚类结果的评估有两种方法：一种是 Internal
evaluation，也就是只用数据本身进行评估，一般通过 <a
href="https://en.wikipedia.org/wiki/K-means_clustering">WCSS</a>
(within-cluster sums of squares) 评估；第二种则是 External
evaluation，即还通过数据的标签进行评估，评估的方法就是常见的准确率等指标。由于聚类往往是无监督方法，因此数据往往是不带标签的，
因此第一种评估方法比较常见。</p>
<h2 id="chapter-8dimensionality-reduction-with-spark">Chapter
8：Dimensionality Reduction with Spark</h2>
<p>这一章主要介绍了spark中的降维技术，采用了 <a
href="http://vis-www.cs.umass.edu/lfw/%20lfw-a.tgz">LFW</a>（Labeled
Faces in the Wild）
人脸数据集，因此也介绍了图像处理的一些基本操作(基于python的opencv库)，然后通过两种方法：PCA和SVD，进行了数据的降维，实际上这两种方法的关系非常密切，且可以达到相同的效果。同时介绍了
Eigenface
的概念，Eigenface实际上就是PCA提取出来的特征向量再变为人脸图像。</p>
<h2 id="chapter-9advanced-text-processing-with-spark">Chapter
9：Advanced Text Processing with Spark</h2>
<p>这一章主要介绍了 Spark 中的文本处理技术，采用了 <a
href="http://qwone.com/~jason/20Newsgroups">20 Newsgroups
数据集</a>，介绍了文本处理的基本操作</p>
<ol type="1">
<li>分词</li>
<li>过滤停止词，低频词</li>
<li>构建词典</li>
<li>基于词典为每篇文本构造一个向量</li>
</ol>
<p>在向量的基础上加上 TF-IDF 便可算出表示文本的 TF-IDF 向量，基于这个
TF-IDF 向量可做文本相似性的比较，而如果文本本身是有标签的，可以将 TF-IDF
向量作为文本特征，进而训练一个分类模型。</p>
<p>最后这章还简单介绍了 Word2Vec 模型及其简单应用。</p>
<h2
id="chapter-10real-time-machine-learning-with-spark-streaming">Chapter
10：Real-time Machine Learning with Spark Streaming</h2>
<p>这章主要介绍了用于处理实时流的 Spark Streaming, 模拟了产生实时流的
producer ，通过 Spark Streaming 处理这些信息流后训练了一个 streaming
regression 模型，并通过 online 的方式评估了这个模型的效果。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>分布式</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Makefile 简介</title>
    <url>/2018/12/05/Makefile%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>C/C++ 在 linux 下可通过 gcc
进行编译，当文件数量少，文件依赖关系简单时可通过命令进行编译，但是当文件数量庞大且关系复杂时，就要依赖于
make 和 Makefile 管理这些复杂关系了。MakeFile 类似于 shell
脚本，定义了文件的依赖关系，以及编译的先后顺序。本文主要介绍 Makefile
的基本语法，本系列文章主要参考了 <a
href="http://wiki.ubuntu.org.cn/%E8%B7%9F%E6%88%91%E4%B8%80%E8%B5%B7%E5%86%99Makefile:%E6%A6%82%E8%BF%B0">跟我一起写Makefile</a>。</p>
<span id="more"></span>
<h2 id="基本格式">基本格式</h2>
<p><code>Makefile</code> 书写格式一般如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 方式一</span><br><span class="line">target : prerequisites </span><br><span class="line">	command</span><br><span class="line"></span><br><span class="line"># 方式二</span><br><span class="line">target : prerequisites; command</span><br></pre></td></tr></table></figure>
<ul>
<li>target 可以是一个 object
file(目标文件)，也可以是一个执行文件，还可以是一个标签（label）</li>
<li>prerequisites 是要生成那个 target 所需要的文件或是目标。</li>
<li>command 也就是 make 需要执行的命令，如果其不与 targets :
prerequisites 在一行，那么，必须以 <code>Tab键</code>开头，如果和
prerequisites 在一行，那么可以用分号做为分隔。</li>
</ul>
<p>这是一个文件的依赖关系，也就是说，target 这一个或多个的目标文件依赖于
prerequisites 中的文件，其生成规则定义在 command
中。说白一点就是说，<strong>prerequisites 中如果有一个以上的文件比
target 文件要新的话，command 所定义的命令就会被执行。这就是 Makefile
的规则。也就是 Makefile 中最核心的内容。</strong></p>
<h2 id="示例">示例</h2>
<p>如果一个工程有3个头文件，和8个c文件，我们为了完成前面所述的那三个规则，我们的
Makefile 应该是下面这个样子的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 如果后面这些.o文件比edit可执行文件新,那么才会去执行命令</span><br><span class="line">edit : main.o kbd.o command.o display.o \</span><br><span class="line">		insert.o search.o files.o utils.o       </span><br><span class="line">	cc -o edit main.o kbd.o command.o display.o \</span><br><span class="line">		insert.o search.o files.o utils.o</span><br><span class="line"></span><br><span class="line">main.o : main.c defs.h</span><br><span class="line">	cc -c main.c</span><br><span class="line">kbd.o : kbd.c defs.h command.h</span><br><span class="line">	cc -c kbd.c</span><br><span class="line">command.o : command.c defs.h command.h</span><br><span class="line">	cc -c command.c</span><br><span class="line">display.o : display.c defs.h buffer.h</span><br><span class="line">	cc -c display.c</span><br><span class="line">insert.o : insert.c defs.h buffer.h</span><br><span class="line">	cc -c insert.c</span><br><span class="line">search.o : search.c defs.h buffer.h</span><br><span class="line">	cc -c search.c</span><br><span class="line">files.o : files.c defs.h buffer.h command.h</span><br><span class="line">	cc -c files.c</span><br><span class="line">utils.o : utils.c defs.h</span><br><span class="line">	cc -c utils.c</span><br><span class="line">clean :</span><br><span class="line">	rm edit main.o kbd.o command.o display.o \</span><br><span class="line">		insert.o search.o files.o utils.o</span><br></pre></td></tr></table></figure>
<p>我们可以把这个内容保存在名字为 “makefile” 或 “Makefile”
的文件中，然后在该目录下直接输入命令 “make”
就可以生成执行文件edit。如果要删除执行文件和所有的中间目标文件，那么，只要简单地执行一下
make clean 就可以了。</p>
<p>在定义好依赖关系后，后续的那一行定义了如何生成目标文件的操作系统命令，一定要以一个tab键作为开头。记住，make
并不管命令是怎么工作的，他只管执行所定义的命令。make 会比较 targets
文件和 prerequisites 文件的修改日期，<strong>如果 prerequisites
文件的日期要比 targets
文件的日期要新，或者target不存在的话，那么，make就会执行后续定义的命令</strong>。</p>
<p>输入 make 命令后，发生了如下的动作</p>
<ol type="1">
<li>make 会在当前目录下找名字叫 “Makefile” 或 “makefile”
的文件。如果找到，它会<strong>找文件中的第一个目标文件（target）作为最终的目标文件</strong>，在上面的例子中即为
edit 这个文件</li>
<li>如果 edit 文件不存在，或是 edit 所依赖的后面的 <code>.o</code>
文件的文件修改时间要比 edit
这个文件新，那么，他就会执行后面所定义的命令来生成 edit 这个文件。</li>
<li>如果 edit 所依赖的 <code>.o</code> 文件也不存在，那么 make
会在当前文件中找目标为 <code>.o</code>
文件的依赖性，如果找到则再根据那一个规则生成 <code>.o</code>
文件。（这有点像一个堆栈的过程）</li>
</ol>
<p>这就是整个make的依赖性，<strong>make
会一层又一层地去找文件的依赖关系，直到最终编译出第一个目标文件</strong>,
在找寻的过程中，如果出现错误，比如最后被依赖的文件找不到，那么 make
就会直接退出并报错。</p>
<p>而像 clean
这种<strong>没有被第一个目标文件直接或间接关联，那么它后面所定义的命令将不会被自动执行</strong>，但可以通过
make clean 进行显式执行，以此来清除所有的目标文件，以便重编译。</p>
<p>如果这个工程已被编译过，当我们修改了其中一个源文件时，比如
<code>file.c</code>，那么根据我们的依赖性，我们的目标
<code>file.o</code> 会被重编译, 因此 <code>file.o</code>
文件修改时间要比edit要新，所以 edit 也会被重新链接了</p>
<h2 id="使用变量与自动推导">使用变量与自动推导</h2>
<p>上面同一个 <code>.o</code>
文件在多个地方都重复了，因此可通过变量的方式简化 Makefile，Makefile
的变量也就是一个字符串，类似于 C 语言的宏，通过 <code>$(变量名)</code>
来访问变量内容</p>
<figure class="highlight make"><table><tr><td class="code"><pre><span class="line">objects = main.o kbd.o command.o display.o \</span><br><span class="line">		insert.o search.o files.o utils.o</span><br><span class="line"></span><br><span class="line">edit : <span class="variable">$(objects)</span></span><br><span class="line">	cc -o edit <span class="variable">$(objects)</span></span><br><span class="line">main.o : main.c defs.h</span><br><span class="line">	cc -c main.c</span><br><span class="line">kbd.o : kbd.c defs.h command.h</span><br><span class="line">	cc -c kbd.c</span><br><span class="line">command.o : command.c defs.h command.h</span><br><span class="line">	cc -c command.c</span><br><span class="line">display.o : display.c defs.h buffer.h</span><br><span class="line">	cc -c display.c</span><br><span class="line">insert.o : insert.c defs.h buffer.h</span><br><span class="line">	cc -c insert.c</span><br><span class="line">search.o : search.c defs.h buffer.h</span><br><span class="line">	cc -c search.c</span><br><span class="line">files.o : files.c defs.h buffer.h command.h</span><br><span class="line">	cc -c files.c</span><br><span class="line">utils.o : utils.c defs.h</span><br><span class="line">	cc -c utils.c</span><br><span class="line">clean :</span><br><span class="line">	rm edit <span class="variable">$(objects)</span></span><br></pre></td></tr></table></figure>
<p>make 能够自动推导文件以及文件依赖关系后面的命令，即只要make看到一个
<code>.o</code> 文件，它就会自动的把 <code>.c</code>
文件加在依赖关系中，如果 make 找到一个 <code>whatever.o</code>，那么
<code>whatever.c</code>，就会是 <code>whatever.o</code> 的依赖文件。并且
<code>cc -c whatever.c</code> 也会被推导出来，于是，我们的 Makefile
再也不用写得这么复杂。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">objects = main.o kbd.o command.o display.o \</span><br><span class="line">		insert.o search.o files.o utils.o</span><br><span class="line"> cc = gcc</span><br><span class="line"></span><br><span class="line">edit : $(objects)</span><br><span class="line">	cc -o edit $(objects)</span><br><span class="line"></span><br><span class="line">main.o : defs.h</span><br><span class="line">kbd.o : defs.h command.h</span><br><span class="line">command.o : defs.h command.h</span><br><span class="line">display.o : defs.h buffer.h</span><br><span class="line">insert.o : defs.h buffer.h</span><br><span class="line">search.o : defs.h buffer.h</span><br><span class="line">files.o : defs.h buffer.h command.h</span><br><span class="line">utils.o : defs.h</span><br><span class="line"></span><br><span class="line">.PHONY : clean</span><br><span class="line">clean :</span><br><span class="line">	-rm edit $(objects)</span><br></pre></td></tr></table></figure>
<p><code>.PHONY</code> 意思表示clean是一个<strong>伪目标</strong>。而在
rm
命令前面加了一个小减号的意思是当某些文件出现问题时不要管，继续做后面的事。当然，clean
的规则不要放在文件的开头，这就会变成 make
的默认目标。不成文的规矩是<strong>clean从来都是放在文件的最后</strong></p>
<h2 id="引用其他-makefile">引用其他 MakeFile</h2>
<p>在 Makefile 使用 include 关键字可以把别的 Makefile 包含进来，这很像
C/C++ 语言的
<code>#include</code>，被包含的文件会原模原样的放在当前文件的包含位置。include的语法是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include &lt;filename&gt;;</span><br></pre></td></tr></table></figure>
<p>filename可以是当前操作系统Shell的文件模式（可以包含路径和通配符）</p>
<p>比如有这样几个Makefile：a.mk、b.mk、c.mk，还有一个文件叫
foo.make，以及一个变量 <code>$(bar)</code>，其包含了
e.mk和f.mk，那么，下面两个语句等价：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">include foo.make *.mk $(bar)</span><br><span class="line"></span><br><span class="line">include foo.make a.mk b.mk c.mk e.mk f.mk</span><br></pre></td></tr></table></figure>
<p>make 命令开始时，会找寻 include 所指出的其它
Makefile，并把其内容安置在当前的位置。类似 C/C++的 <code>#include</code>
指令一样。<strong>如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，如果当前目录下没有找到，那么，make还会在下面的几个目录下找</strong>：</p>
<ul>
<li>如果 make 执行时，有 <code>-I</code> 或 <code>--include-dir</code>
参数，那么 make 就会在这个参数所指定的目录下去寻找。</li>
<li>如果目录
<code>&lt;prefix&gt;/include</code>（一般是：/usr/local/bin或/usr/include）存在的话，make也会去找。
如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成makefile的读取，
make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。</li>
</ul>
<p>如果想让 make 忽略那些无法读取的文件，可以在include前加一个减号
<code>-</code>, 即</p>
<p><code>-include &lt;filename&gt;;</code></p>
<p>表示无论 include
过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。</p>
<h2 id="小结">小结</h2>
<p>Makefile里主要包含了五个东西：显式规则、隐晦规则、变量定义、文件指示和注释。</p>
<ol type="1">
<li>显式规则: 说明了如何生成一个或多个目标文件。这是由 Makefile
的书写者明显指出，要生成的文件，文件的依赖文件，生成的命令。</li>
<li>隐晦规则: make
有自动推导的功能，所以隐晦的规则可以让我们比较简略地书写
Makefile，这是由make所支持的。</li>
<li>变量的定义。在 Makefile
中我们要定义一系列的变量，变量一般都是字符串，这个有点 C 语言中的宏，当
Makefile 被执行时，其中的变量都会被扩展到相应的引用位置上。</li>
<li>文件指示。其包括了三个部分，一个是在一个 Makefile 中引用另一个
Makefile，就像 C语言中的 <code>#include</code>
一样；另一个是指根据某些情况指定 Makefile
中的有效部分，就像C语言中的预编译 <code>#if</code> 一样；
还有就是定义一个多行的命令。有关这一部分的内容，我会在后续的部分中讲述。</li>
<li>注释。Makefile
中<strong>只有行注释，和UNIX的Shell脚本一样，其注释是用 <code>#</code>
字符</strong>，这个就像C/C++中的 <code>//</code> 一样。</li>
</ol>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>MLE 与 MAP 简介</title>
    <url>/2019/01/25/MLE%20%E4%B8%8E%20MAP%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>最近看到一篇关于 MLE(Maximum Likelihood Estimation) 和 MAP（Maximum A
Posteriori) 的文章，写的很好，非常值得一看，文章链接为 <a
href="https://zhuanlan.zhihu.com/p/32480810">聊一聊机器学习的MLE和MAP：最大似然估计和最大后验估计</a>，本文几乎不加修改地转载了文章，侵删。</p>
<span id="more"></span>
<h2 id="概述">概述</h2>
<p>有时候和别人聊天，对方会说自己有很多机器学习经验，深入一聊发现，对方竟然对MLE和MAP一知半解，至少在我看来，这位同学的机器学习基础并不扎实。难道在这个深度学习盛行的年代，不少同学都只注重调参数？</p>
<p><strong>现代机器学习的终极问题都会转化为解目标函数的优化问题，MLE 和
MAP
是生成这个函数的很基本的思想</strong>，因此我们对二者的认知是非常重要的。这次就和大家认真聊一聊
MLE 和 MAP 这两种 estimator。</p>
<h2 id="两大学派的争论">两大学派的争论</h2>
<p>抽象一点来讲，频率学派(Frequentist)和贝叶斯学派(Bayesian)对世界的认知有本质不同：频率学派认为世界是确定的，有一个本体，这个本体的真值是不变的，我们的目标就是要找到这个真值或真值所在的范围；而贝叶斯学派认为世界是不确定的，人们对世界先有一个预判，而后通过观测数据对这个预判做调整，我们的目标是要找到最优的描述这个世界的概率分布。</p>
<p><strong>在对事物建模时，用 <span
class="math inline">\(\theta\)</span>
表示模型的参数，解决问题的本质就是求 <span
class="math inline">\(\theta\)</span></strong>
。那么频率学派和贝叶斯学派的区别在于：</p>
<ul>
<li><p><strong>频率学派：存在唯一真值 <span
class="math inline">\(\theta\)</span></strong>
。举一个简单直观的例子--抛硬币，我们用 <span
class="math inline">\(P(head)\)</span> 来表示硬币的
bias。抛一枚硬币100次，有20次正面朝上，要估计抛硬币正面朝上的 bias <span
class="math inline">\(P(head)=\theta\)</span> 。在频率学派来看，<span
class="math inline">\(\theta\)</span> = 20 / 100 =
0.2，很直观。当数据量趋于无穷时，这种方法能给出精准的估计；然而缺乏数据时则可能产生严重的偏差。例如，对于一枚均匀硬币，即
<span class="math inline">\(\theta\)</span> = 0.5，抛掷5次，出现5次正面
(这种情况出现的概率是 1/2^5=3.125%)，频率学派会直接估计这枚硬币 <span
class="math inline">\(\theta\)</span> = 1，出现严重错误。</p></li>
<li><p><strong>贝叶斯学派： <span class="math inline">\(\theta\)</span>
是一个随机变量，符合一定的概率分布。</strong>在贝叶斯学派里有两大输入和一大输出，输入是先验
(prior) 和似然 (likelihood)，输出是后验 (posterior)。先验，即 <span
class="math inline">\(P(\theta)\)</span>
，指的是在没有观测到任何数据时对
的预先判断，例如给我一个硬币，一种可行的先验是认为这个硬币有很大的概率是均匀的，有较小的概率是是不均匀的；似然，即
<span class="math inline">\(P(X|\theta)\)</span> ，是假设 <span
class="math inline">\(\theta\)</span>
已知后我们观察到的数据应该是什么样子的；后验，即 <span
class="math inline">\(P(\theta|X)\)</span>
，是最终的参数分布。贝叶斯估计的基础是贝叶斯公式，如下：</p></li>
</ul>
<p><span class="math display">\[P(\theta|X)=\frac{P(X|\theta) \times
P(\theta)}{P(X)}\]</span></p>
<p>同样是抛硬币的例子，对一枚均匀硬币抛5次得到5次正面，如果先验认为大概率下这个硬币是均匀的
(例如最大值取在0.5处的Beta分布)，那么 <span
class="math inline">\(P(head)\)</span> ，即 <span
class="math inline">\(P(\theta|X)\)</span>
，是一个distribution，最大值会介于0.5~1之间，而不是武断的 <span
class="math inline">\(\theta\)</span> = 1。</p>
<p>这里有两点值得注意的地方：</p>
<ol type="1">
<li>随着数据量的增加，参数分布会越来越向数据靠拢，先验的影响力会越来越小</li>
<li><strong>如果先验是 uniform
distribution，则贝叶斯方法等价于频率方法</strong>。因为直观上来讲，先验是uniform
distribution本质上表示对事物没有任何预判</li>
</ol>
<h2 id="mle---最大似然估计">MLE - 最大似然估计</h2>
<p>Maximum Likelihood Estimation, MLE是频率学派常用的估计方法！</p>
<p>假设数据 <span class="math inline">\(x\_1, x\_2, ..., x\_n\)</span>
是 i.i.d.的一组抽样，<span class="math inline">\(X = (x\_1, x\_2, ...,
x\_n)\)</span> 。其中i.i.d.表示Independent and identical
distribution，独立同分布。那么MLE对 <span
class="math inline">\(\theta\)</span> 的估计方法可以如下推导：</p>
<p><span class="math display">\[\begin{align\*}
\hat{\theta}\_\text{MLE} &amp;= \arg \max P(X; \theta) \\\
&amp;= \arg \max P(x\_1; \theta) P(x\_2; \theta) \cdot\cdot\cdot\cdot
P(x\_n;\theta) \\\
&amp; = \arg \max\log \prod\_{i=1}^{n} P(x\_i; \theta) \\\
&amp;= \arg \max \sum\_{i=1}^{n} \log P(x\_i; \theta) \\\
&amp;= \arg \min - \sum\_{i=1}^{n} \log P(x\_i; \theta)
\end{align\*}\]</span></p>
<p>最后这一行所优化的函数被称为 <strong>Negative Log Likelihood
(NLL)</strong>，这个概念和上面的推导是非常重要的！</p>
<p>我们经常在不经意间使用MLE，例如</p>
<p>上文中关于频率学派求硬币概率的例子，其方法其实本质是由优化NLL得出。
给定一些数据，求对应的高斯分布时，我们经常会算这些数据点的均值和方差然后带入到高斯分布的公式，其理论依据是优化NLL
深度学习做分类任务时所用的cross entropy loss，其本质也是MLE</p>
<h2 id="map---最大后验估计">MAP - 最大后验估计</h2>
<p>Maximum A Posteriori, MAP是贝叶斯学派常用的估计方法！</p>
<p>同样的，假设数据 <span class="math inline">\(x\_1, x\_2, ...,
x\_n\)</span> 是i.i.d.的一组抽样，<span class="math inline">\(X = (x\_1,
x\_2, ..., x\_n)\)</span> 。那么MAP对 <span
class="math inline">\(\theta\)</span> 的估计方法可以如下推导：</p>
<p><span class="math display">\[\begin{align\*}
\hat{\theta}\_\text{MAP} &amp;= \arg \max P(\theta | X) \\\
&amp;= \arg \min -\log P(\theta | X) \\\
&amp; = \arg \min -\log P(X|\theta) - \log P(\theta) + \log P(X) \\\
&amp;= \arg \min -\log P(X|\theta ) - \log P(\theta)
\end{align\*}\]</span></p>
<p>其中，第二行到第三行使用了贝叶斯定理，第三行到第四行 <span
class="math inline">\(P(X)\)</span> 可以丢掉因为与 <span
class="math inline">\(\theta\)</span> 无关。注意 <span
class="math inline">\(-\log P(X|\theta )\)</span>
其实就是NLL，所以MLE和MAP在优化时的不同就是在于先验项 <span
class="math inline">\(- \log P(\theta)\)</span>
。好的，那现在我们来研究一下这个先验项，假定先验是一个高斯分布，即</p>
<p><span class="math display">\[P(\theta) = \text{constant} \times
e^{-\frac{\theta^2}{2\sigma^2}}\]</span></p>
<p>那么， <span class="math inline">\(-\log P(\theta) = \text{constant}
+ \frac{\theta^2}{2\sigma^2}\)</span> 。至此，一件神奇的事情发生了：</p>
<p><strong>在MAP中使用一个高斯分布的先验等价于在MLE中采用L2的regularizaton！</strong></p>
<hr />
<p>参考:</p>
<ul>
<li><a
href="http://www.utdallas.edu/~nrr150130/cs7301/2016fa/lects/Lecture_14_Bayes.pdf">Bayesian
Methods</a></li>
<li><a
href="http://www.cs.cmu.edu/~aarti/Class/10701_Spring14/slides/MLE_MAP_Part1.pdf">MLE,
MAP, Bayes classification</a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数学</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>Makefile 语法详解(1)-文件搜索、伪目标与命令执行</title>
    <url>/2018/12/06/Makefile%20%E8%AF%AD%E6%B3%95%E8%AF%A6%E8%A7%A3(1)-%E6%96%87%E4%BB%B6%E6%90%9C%E7%B4%A2%E3%80%81%E4%BC%AA%E7%9B%AE%E6%A0%87%E4%B8%8E%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/</url>
    <content><![CDATA[<p>本文内容是之前的文章 <a
href="http://wulc.me/2018/12/05/Makefile%20%E7%AE%80%E4%BB%8B/">Makefile
简介</a> 的补充，详细介绍了 Makefile 中的文件搜索（即通过 VPATH 和 vpath
进行源文件的搜索）、伪目标（定义多个生成目标）以及执行多条命令的一些做法。</p>
<span id="more"></span>
<h2 id="文件搜索">文件搜索</h2>
<p>在一些源文件较多的大工程中，通常会把源文件分类并存放在不同的目录中(比如自定义的头文件放在
<code>include</code> 目录，源文件放在 <code>src</code> 目录)，而当 make
需要去找寻文件的依赖关系时，可以在文件前加上路径，但最好的方法是把一个路径告诉
make，让 make 自动去搜索。</p>
<p>Makefile 文件中的<strong>特殊变量 VPATH</strong>
就是完成这个功能的，如果没有指明这个变量，make只会在当前的目录中去找寻依赖文件和目标文件。如果定义了这个变量，make就会<strong>在当前目录找不到的情况下，到所指定的目录中去找寻文件</strong>。</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">VPATH = src:../headers</span><br></pre></td></tr></table></figure>
<p>上面的的定义指定两个目录，<code>src</code> 和
<code>../headers</code>，make 会按照这个顺序进行搜索。目录由
<code>:</code>分隔; 然，当然，在此之前会在当前目录查找</p>
<p>另一个设置文件搜索路径的方法是使用 make 的 <strong>vpath
关键字</strong>（全小写），这不是变量，这是一个 make
的关键字，这和上面提到的那个 VPATH
变量很类似，但是它更为灵活。它可以指定不同的文件在不同的搜索目录中。这是一个很灵活的功能。它的使用方法有三种：</p>
<p>1、<code>vpath &lt;pattern&gt; &lt;directories&gt;</code> 在目录
<code>&lt;directories&gt;</code> 中搜索符合模式
<code>&lt;pattern&gt;</code> 的文件</p>
<p>2、<code>vpath &lt;pattern&gt;</code> 清除符合模式
<code>&lt;pattern&gt;</code> 的文件的搜索路径</p>
<p>3、<code>vpath</code> 清除所有已被设置好了的文件搜索目录。</p>
<p>vpath 使用方法中的 <code>&lt;pattern&gt;</code> 需要包含
<code>%</code> 字符。<code>%</code>
的意思是匹配零或若干字符，如，<code>%.h</code> 表示所有以
<code>.h</code> 结尾的文件。<code>&lt;pattern&gt;</code>
指定了要搜索的文件集，而 <code>&lt;directories&gt;</code> 则指定了
<code>&lt;pattern&gt;</code> 的文件集的搜索的目录。例如：</p>
<p><code>vpath %.h ../headers</code> 表示要 make 在
<code>../headers</code> 目录下搜索所有以 <code>.h</code>
结尾的文件。（如果某文件在当前目录没有找到的话）</p>
<p>我们可以连续地使用 <code>vpath</code>
语句，以指定不同搜索策略。如果连续的 <code>vpath</code>
语句中出现了相同的 <code>&lt;pattern&gt;</code>，或是被重复了的
<code>&lt;pattern&gt;</code>，那么，make 会按照 vpath
语句的先后顺序来执行搜索。如：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">vpath</span> %.c foo</span><br><span class="line"><span class="keyword">vpath</span> %.c blish</span><br><span class="line"><span class="keyword">vpath</span> %.c bar</span><br></pre></td></tr></table></figure>
<p>其表示“.c”结尾的文件，先在 <code>foo</code> 目录，然后是
<code>blish</code> ，最后是 <code>bar</code> 目录。</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">vpath</span> %.c foo:bar</span><br><span class="line"><span class="keyword">vpath</span> %.c blish</span><br></pre></td></tr></table></figure>
<p>而上面的语句则表示 <code>.c</code> 结尾的文件，先在 <code>foo</code>
目录，然后是 <code>bar</code> 目录，最后才是 <code>blis</code>
目录。</p>
<h2 id="伪目标">伪目标</h2>
<p>最早先的一个例子中，我们提到过一个 <code>clean</code>
的目标，这是一个“伪目标”，因为并不生成“clean”这个文件</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">clean:</span></span><br><span class="line">	rm *.o temp</span><br></pre></td></tr></table></figure>
<p>为了避免伪目标名称和文件重名的这种情况，可以使用一个特殊的标记
<code>.PHONY</code> 来显式地指明一个目标是伪目标, 如下所示</p>
<p><code>.PHONY : clean</code></p>
<p>只要有这个声明，不管是否有 clean 文件，要运行 clean
这个目标，只能运行 make clean。于是整个过程可以这样写：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">.PHONY : clean</span><br><span class="line">clean :</span><br><span class="line">	rm *.o temp</span><br></pre></td></tr></table></figure>
<p><strong>伪目标一般没有依赖的文件,但是也可以为伪目标指定所依赖的文件。伪目标同样可以作为“默认目标”，只要将其放在第一个</strong>。一个常用的做法就是，如果你的
Makefile 需要一次生成若干个可执行文件，可以通过伪目标实现，如下所示</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">all : prog1 prog2 prog3</span><br><span class="line">.PHONY : all</span><br><span class="line"></span><br><span class="line">prog1 : prog1.o utils.o</span><br><span class="line">	cc -o prog1 prog1.o utils.o</span><br><span class="line"></span><br><span class="line">prog2 : prog2.o</span><br><span class="line">	cc -o prog2 prog2.o</span><br><span class="line"></span><br><span class="line">prog3 : prog3.o sort.o utils.o</span><br><span class="line">	cc -o prog3 prog3.o sort.o utils.o</span><br></pre></td></tr></table></figure>
<p>由于 Makefile 中的第一个目标会被作为其默认目标，上面声明的伪目标
<code>all</code> 会作为默认目标，但由于 <code>all</code>
又是一个伪目标，所以不会有 <code>all</code> 文件产生,
但是会生成其依赖的三个文件</p>
<p>从上面的例子我们可以看出，目标也可以成为依赖。所以，<code>伪目标同样也可成为依赖</code>。看下面的例子：
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">.PHONY : cleanall cleanobj cleandiff</span><br><span class="line"></span><br><span class="line">cleanall : cleanobj cleandiff</span><br><span class="line">	rm program</span><br><span class="line"></span><br><span class="line">cleanobj :</span><br><span class="line">	rm *.o</span><br><span class="line"></span><br><span class="line">cleandiff :</span><br><span class="line">	rm *.diff</span><br></pre></td></tr></table></figure></p>
<p><code>make cleanall</code>
将清除所有要被清除的文件。<code>cleanobj</code> 和
<code>cleandiff</code> 这两个伪目标有点像“子程序”的意思。我们可以输入
<code>make cleanall</code> 和 <code>make cleanobj</code> 和
<code>make cleandiff</code> 命令来达到清除不同种类文件的目的。</p>
<h2 id="命令执行">命令执行</h2>
<h3 id="执行连续命令">执行连续命令</h3>
<p>执行多条命令时可以分多行写；但是如果要让上一条命令的结果应用在下一条命令时，应该<strong>使用分号或
&amp;&amp;
分隔这两条命令</strong>。比如第一条命令是cd命令，并且希望第二条命令在 cd
之后的基础上运行，那么就不能把这两条命令写在两行上，而应该把这两条命令写在一行上，用分号分隔。如：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例一：</span></span><br><span class="line"><span class="section">exec:</span></span><br><span class="line">	cd /usr/lib/</span><br><span class="line">	pwd</span><br><span class="line">	</span><br><span class="line"><span class="comment"># 示例二：</span></span><br><span class="line"><span class="section">exec:</span></span><br><span class="line">	cd /usr/lib/; pwd 或 cd /usr/lib/ &amp;&amp; pwd</span><br></pre></td></tr></table></figure>
<p>当我们执行 <code>make exec</code> 时，第一个例子中的 cd
没有起到作用，pwd 会打印出当前的 Makefile
目录，而第二个例子中，cd就起作用了，pwd 会打印出
<code>/usr/lib/</code></p>
<h3 id="嵌套执行make">嵌套执行make</h3>
<p>在一些大的工程中，往往会把不同模块或是不同功能的源文件放在不同的目录中，<strong>可以在每个目录中都书写一个该目录的
Makefile，这有利于 Makefile
变得更加地简洁且更容易维护</strong>，而不至于把所有的东西全部写在一个
Makefile 中，这个技术对于我们模块编译和分段编译有着非常大的好处。</p>
<p>例如，有一个子目录叫subdir，这个目录下有个 Makefile
文件，来指明了这个目录下文件的编译规则。那么我们总控的Makefile可以这样书写：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">subsystem:</span></span><br><span class="line">        cd subdir &amp;&amp; <span class="variable">$(MAKE)</span></span><br><span class="line">或</span><br><span class="line"><span class="section">subsystem:</span></span><br><span class="line">        <span class="variable">$(MAKE)</span> -C subdir</span><br></pre></td></tr></table></figure>
<p><code>$(MAKE)</code> 是自定义的宏变量，不直接使用 make 命令，而是定义
<code>$(MAKE)</code> 这个宏变量的原因是 make
有时需要一些参数，所以定义成一个变量比较利于维护。</p>
<p>如果要传递变量到下级 Makefile 中，那么可以使用这样的声明
<code>export variable_name</code> 如果不想让某些变量传递到下级 Makefile
中，那么可以这样声明 <code>unexport variable_name</code>
如果你要传递所有的变量，那么，只要一个 export 就行了;
后面什么也不用跟，表示传递所有的变量。</p>
<h3 id="定义命令包">定义命令包</h3>
<p>如果 Makefile
中出现一些相同命令序列，那么可以为这些相同的命令序列定义成一个变量。定义这种命令序列的语法以
<code>define</code> 开始，以 <code>endef</code> 结束，如：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">define</span> run-action</span><br><span class="line">action 1</span><br><span class="line">action 2</span><br><span class="line">action 3</span><br><span class="line"><span class="keyword">endef</span></span><br><span class="line"></span><br><span class="line">foo.o : foo.c</span><br><span class="line">        $(run-action)</span><br></pre></td></tr></table></figure>
<p>这里的 <code>run-action</code> 是这个命令包的名字，在
<code>define</code> 和 <code>endef</code>
中的三行就是命令序列；可以看到，使用这个命令包就好像使用变量一样。</p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Makefile 语法详解(2)-变量、条件判断与函数</title>
    <url>/2018/12/07/Makefile%20%E8%AF%AD%E6%B3%95%E8%AF%A6%E8%A7%A3(2)-%E5%8F%98%E9%87%8F%E3%80%81%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E4%B8%8E%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>本文内容是之前的文章 <a
href="http://wulc.me/2018/12/05/Makefile%20%E7%AE%80%E4%BB%8B/">Makefile
简介</a> 的补充，详细介绍了 Makefile
中的变量（包括变量的定义、批量替换、局部变量等）、条件判断和函数（内置函数和自定义函数）。</p>
<span id="more"></span>
<h2 id="变量">变量</h2>
<p>在 Makefile 中的定义的变量，就像是 C/C++
语言中的宏一样，代表了一个文本字串，在 Makefile
中执行的时候其会自动地展开在所使用的地方。其与C/C++所不同的是，可以在
Makefile 中改变其值。</p>
<p>变量在声明时需要给予初值，而在使用时，需要给在变量名前加上
<code>$</code> 符号，但最好用小括号 <code>()</code>或是大括号
<code>&#123;&#125;</code> 把变量给包括起来。如果你要使用真实的 <code>$</code>
字符，那么你需要用 <code>$$</code> 来表示。</p>
<h3 id="变量的赋值">变量的赋值</h3>
<p>定义 Makefile
中为变量赋值可用四种操作符：<code>=</code>、<code>:=</code>、<code>?=</code>、<code>+=</code>，
参考 StackOverflow 上的问题 <a
href="https://stackoverflow.com/questions/6283320/vs-in-make-macros?lq=1">What
is the difference between the GNU Makefile variable assignments =, ?=,
:= and +=?</a>, 这四个符号的主要区别是</p>
<ol type="1">
<li><code>=</code> 赋值是 lazy
的，也就是在使用的时候才会递归的获取变量的值（递归指的是可以通过一个变量为另一个变量赋值）</li>
<li><code>:=</code> 则是在声明的时候变量的值就确定了</li>
<li><code>?=</code> 表示在变量没有值的时候才给其赋值</li>
<li><code>+=</code> 则是在原来的值上 append
一个其他的值（自动添加空格）</li>
</ol>
<p>其中 <code>=</code>
赋值是的递归获取值比较难理解，简单来说就是右侧中的变量不一定非要是已定义好的值，也可以使用<strong>后面定义</strong>的值。如下是一个简单地例子</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">foo = <span class="variable">$(bar)</span></span><br><span class="line">bar = <span class="variable">$(ugh)</span></span><br><span class="line">ugh = Haha</span><br><span class="line"></span><br><span class="line"><span class="section">all:</span></span><br><span class="line">    echo <span class="variable">$(foo)</span></span><br></pre></td></tr></table></figure>
<p>执行 <code>make all</code> 时输出的值是 <code>Haha</code>, 而是用
<code>:=</code> 赋值时就不允许这么赋值，在 <code>:=</code>
右边的值必须只能是字符串或者<strong>前面定义</strong>的变量，也就是在
<code>:=</code> 右边的值必须要是目前为止已经确定的值。</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例 1</span></span><br><span class="line">x := foo</span><br><span class="line">y := <span class="variable">$(x)</span> bar</span><br><span class="line">x := later</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例 2</span></span><br><span class="line">y := <span class="variable">$(x)</span> bar</span><br><span class="line">x := foo</span><br></pre></td></tr></table></figure>
<p>上面示例1 中的 y 的值为 foo bar，示例2 中的值为 bar。</p>
<h3 id="变量值的替换">变量值的替换</h3>
<p>我们可以替换变量中的共有的部分，其格式是 <code>$(var:a=b)</code> 或是
<code>$(var: %a=%b)</code>，其意思是，把变量 <code>var</code> 中所有以
<code>a</code> 字串结尾的那些值从 <code>a</code> 替换成 <code>b</code>;
如下是一个简单的示例</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">foo := a.o b.o c.o</span><br><span class="line">bar := $(foo:.o=.c) 或 bar := $(foo:%.o=%.c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># bar 的值是 a.c b.c c.c</span></span><br></pre></td></tr></table></figure>
<h3 id="把变量值当做变量名">把变量值当做变量名</h3>
<p>Makefile 中如果变量 a 的值是变量 b 的名称，那么可以把变量 a
的值直接当做变量 b 使用，如下是一些简单的例子</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例一</span></span><br><span class="line">x = y</span><br><span class="line">y = z</span><br><span class="line">z = u</span><br><span class="line">a := $($(<span class="variable">$(x)</span>)) <span class="comment"># u</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例二</span></span><br><span class="line">x = <span class="variable">$(y)</span></span><br><span class="line">y = z</span><br><span class="line">z = Hello</span><br><span class="line">a := $(<span class="variable">$(x)</span>) <span class="comment"># Hello</span></span><br></pre></td></tr></table></figure>
<h3 id="局部变量">局部变量</h3>
<p>前面我们所讲的在 Makefile 中定义的变量都是全局变量,
但是也可以为某个目标设置局部变量，这种变量被称为 Target-specific
Variable，<strong>因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值</strong>，因为局部变量的名称可与全局变量的名称相同。</p>
<p>其一般语法如下，首先在 target 中定义局部变量，则在 <strong>target
及其依赖的目标</strong>中使用该变量即可 <figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">target : local_variable assignment</span><br><span class="line">target : use variable</span><br></pre></td></tr></table></figure></p>
<p>如下是个简单的例子 <figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">prog : CFLAGS = -g</span><br><span class="line">prog : prog.o foo.o bar.o</span><br><span class="line">        <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> prog.o foo.o bar.o</span><br><span class="line"></span><br><span class="line">prog.o : prog.c</span><br><span class="line">        <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> prog.c</span><br><span class="line"></span><br><span class="line">foo.o : foo.c</span><br><span class="line">        <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> foo.c</span><br><span class="line"></span><br><span class="line">bar.o : bar.c</span><br><span class="line">        <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> bar.c</span><br></pre></td></tr></table></figure></p>
<p>除了 Target-specific Variable，还有 Pattern-specific
Variable，即不是在某个特定的 target 中定义局部变量，而是在某个特定的
pattern 中定义局部变量，其语法与上面的类似，如下所示是定义了所有以
<code>.o</code> 结尾的目标中的一个局部变量</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">%.o : CFLAGS = -O</span><br></pre></td></tr></table></figure>
<h2 id="条件判断">条件判断</h2>
<p>使用条件判断，可以让 make
根据运行时的不同情况选择不同的执行分支，主要有以下几个关键字：
<code>ifeq</code>、<code>ifneq</code>、<code>ifdef</code>、<code>ifndef</code>、<code>else</code>
和 <code>endif</code>;</p>
<p>根据名称其实也能基本能猜出各个关键字的作用了, <code>ifeq</code> 和
<code>ifneq</code>
是一对关键字，表示其后面跟随的两个参数是够相等，<code>ifdef</code> 和
<code>ifndef</code>
是一对关键字，表示其后跟随的变量是否已经被定义过。</p>
<p>如下是一个简单的例子，表示目标 foo 可以根据变量 <code>$(CC)</code>
值来选取不同的函数库来编译 <figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">libs_for_gcc = -lgnu</span><br><span class="line">normal_libs =</span><br><span class="line"></span><br><span class="line"><span class="section">foo: <span class="variable">$(objects)</span></span></span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(CC)</span>,gcc)</span><br><span class="line">        <span class="variable">$(CC)</span> -o foo <span class="variable">$(objects)</span> <span class="variable">$(libs_for_gcc)</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        <span class="variable">$(CC)</span> -o foo <span class="variable">$(objects)</span> <span class="variable">$(normal_libs)</span></span><br><span class="line"><span class="keyword">endif</span></span><br></pre></td></tr></table></figure></p>
<p>当 <code>$(CC)</code> 是 gcc 时，目标 foo 的规则是</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">foo: <span class="variable">$(objects)</span></span></span><br><span class="line">    <span class="variable">$(CC)</span> -o foo <span class="variable">$(objects)</span> <span class="variable">$(libs_for_gcc)</span></span><br></pre></td></tr></table></figure>
<p>因此，上面的写法可以写成如下更简洁且容易理解的形式</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">libs_for_gcc = -lgnu</span><br><span class="line">normal_libs =</span><br><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span> (<span class="variable">$(CC)</span>, gcc)</span><br><span class="line">  libs=<span class="variable">$(libs_for_gcc)</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  libs=<span class="variable">$(normal_libs)</span></span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line"><span class="section">foo: <span class="variable">$(objects)</span></span></span><br><span class="line">        <span class="variable">$(CC)</span> -o foo <span class="variable">$(objects)</span> <span class="variable">$(libs)</span></span><br></pre></td></tr></table></figure>
<p>需要注意的一点是<strong>在关键字所在的这一行上，多余的空格是被允许的，但是不能以
Tab 键做为开始，否则就被认为是命令</strong></p>
<p>使用 <code>ifeq</code> 可有若干种形式，如下所示的五种形式都是等价的,
<code>ifneq</code> 的使用方法相同</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ifeq</span> (&lt;arg1&gt;, &lt;arg2&gt;) </span><br><span class="line"><span class="keyword">ifeq</span> &#x27;&lt;arg1&gt;&#x27; &#x27;&lt;arg2&gt;&#x27; </span><br><span class="line"><span class="keyword">ifeq</span> <span class="string">&quot;&lt;arg1&gt;&quot;</span> <span class="string">&quot;&lt;arg2&gt;&quot;</span> </span><br><span class="line"><span class="keyword">ifeq</span> <span class="string">&quot;&lt;arg1&gt;&quot;</span> &#x27;&lt;arg2&gt;&#x27; </span><br><span class="line"><span class="keyword">ifeq</span> &#x27;&lt;arg1&gt;&#x27; <span class="string">&quot;&lt;arg2&gt;&quot;</span> </span><br></pre></td></tr></table></figure>
<p><code>ifdef</code> 和 <code>ifndef</code>
的使用方法也类似，只是其后面只跟着一个变量。</p>
<h2 id="函数">函数</h2>
<p>GNU make 内置了一些函数，在 Makefile
中使用函数来处理变量，可以让我们的命令或是规则更为的灵活</p>
<p>函数调用很像变量的使用，也是以 <code>$</code>
来标识的，其语法如下，其中 <code>&lt;function&gt;</code>
就是函数名，<code>&lt;arguments&gt;</code> 为函数的参数，参数间以逗号
<code>,</code> 分隔，而函数名和参数之间以空格分隔</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">$(&lt;function&gt; &lt;arguments&gt;)</span><br><span class="line">或</span><br><span class="line">$&#123;&lt;function&gt; &lt;arguments&gt;&#125;</span><br></pre></td></tr></table></figure>
<p>以下是 GNU make 内置的一些函数</p>
<h3 id="字符串处理函数">字符串处理函数</h3>
<ul>
<li><p><strong>subst</strong>
用法：<code>$(subst &lt;from&gt;,&lt;to&gt;,&lt;text&gt;)</code>
功能：把字串 <code>&lt;text&gt;</code> 中的 <code>&lt;from&gt;</code>
字符串替换成 <code>&lt;to&gt;</code>。
返回：函数返回被替换过后的字符串。</p></li>
<li><p><strong>patsubst</strong>
用法：<code>$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt;)</code>
功能：查找 <code>&lt;text&gt;</code> 中的单词是否符合模式
<code>&lt;pattern&gt;</code>，如果匹配的话，则以
<code>&lt;replacement&gt;</code>替换。这里，<code>&lt;pattern&gt;</code>
可以包括通配符 <code>%</code>，表示任意长度的字串。如果
<code>&lt;replacement&gt;</code> 中也包含
<code>%</code>，那么，<code>&lt;replacement&gt;</code>中的这个
<code>%</code> 将是 <code>&lt;pattern&gt;</code> 中的那个 <code>%</code>
所代表的字串。（可以用<code>\</code>来转义）
返回：函数返回被替换过后的字符串
示例：<code>$(patsubst %.c,%.o,x.c.c bar.c)</code> 返回的结果是
<code>x.c.o bar.o</code></p></li>
<li><p><strong>findstring</strong>
用法：<code>$(findstring &lt;find&gt;,&lt;string&gt;)</code>
功能：在字串 <code>&lt;string&gt;</code> 中查找
<code>&lt;find&gt;</code> 字串。 返回：如果找到，那么返回
<code>&lt;find&gt;</code>，否则返回空字符串。</p></li>
<li><p><strong>sort</strong> 用法：<code>$(sort &lt;list&gt;)</code>
功能：给字符串 <code>&lt;list&gt;</code> 中的单词排序（空格分隔）。
返回：返回排序后的字符串。 示例：<code>$(sort foo bar lose)</code> 返回
<code>bar foo lose</code> 。</p></li>
<li><p><strong>word</strong>
用法：<code>$(word &lt;n&gt;,&lt;text&gt;)</code> 功能：取字符串
<code>&lt;text&gt;</code> 中第 <code>&lt;n&gt;</code>
个单词。（从1开始） 返回：返回字符串 <code>&lt;text&gt;</code> 中第
<code>&lt;n&gt;</code> 个单词 示例：<code>$(word 2, foo bar baz)</code>
返回值是 <code>bar</code></p></li>
</ul>
<h3 id="foreach-函数">foreach 函数</h3>
<p>foreach 函数是用作循环的，其用法如下</p>
<p><code>$(foreach  &lt;var&gt;,&lt;list&gt;,&lt;text&gt;)</code></p>
<p>该函数的意思是，把参数 <code>&lt;list&gt;</code>
中的单词逐一取出放到参数所指定的变量 <code>&lt;var&gt;</code>
中，然后再执行 <code>&lt; text&gt;</code> 所包含的表达式。每一次
<code>&lt;text&gt;</code>
会返回一个字符串，循环过程中，<code>&lt;text&gt;</code>
的所返回的每个字符串会以空格分隔，最后当整个循环结束时，<code>&lt;text&gt;</code>所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。</p>
<p>如下是一个简单的例子</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">names := a b c d</span><br><span class="line"></span><br><span class="line">files := <span class="variable">$(<span class="built_in">foreach</span> n,<span class="variable">$(names)</span>,<span class="variable">$(n)</span>.o)</span></span><br></pre></td></tr></table></figure>
<p>上面的例子中，<code>$(name)</code> 中的单词会被挨个取出，并存到变量 n
中，<code>$(n).o</code> 每次根据 <code>$(n)</code>
计算出一个值，这些值以空格分隔，最后作为 foreach
函数的返回值，所以，<code>$(files)</code> 的值是
<code>a.o b.o c.o d.o</code></p>
<p><strong>需要注意的是，foreach
中的参数是一个临时的局部变量，foreach函数执行完后，参数的变量将不在作用，其作用域只在foreach函数当中。</strong></p>
<h3 id="call函数">call函数</h3>
<p>call 函数可以用来创建自定义函数。其语法是：</p>
<p><code>$(call &lt;expression&gt;,&lt;parm1&gt;,&lt;parm2&gt;,&lt;parm3&gt;,...)</code></p>
<p>当 make 执行这个函数时，<code>&lt;expression&gt;</code> 参数中的变量:
<code>$(1)，$(2)，$(3)</code>等，会被参数
<code>&lt;parm1&gt;，&lt;parm2&gt;，&lt;parm3&gt;</code>依次取代。而
<code>&lt;expression&gt;</code> 的返回值就是 <code>call</code>
函数的返回值。例如：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">reverse =  $(2) $(1) </span><br><span class="line">foo = <span class="variable">$(<span class="built_in">call</span> reverse,a,b)</span></span><br></pre></td></tr></table></figure>
<p>经过上面的表达式得到的 foo 的值是 <code>b a</code>。当然，可以为
reverse 定义更复杂的操作。</p>
<h3 id="shell函数">shell函数</h3>
<p>，shell函数把执行操作系统命令后的输出作为函数返回。因此可以用操作系统命令以及字符串处理命令
<code>awk，sed</code> 等等命令来生成一个变量，如：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">contents := <span class="variable">$(<span class="built_in">shell</span> cat foo)</span></span><br><span class="line">files := <span class="variable">$(<span class="built_in">shell</span> echo *.c)</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown 图片免费上传工具</title>
    <url>/2019/04/20/Markdown%20%E5%9B%BE%E7%89%87%E5%85%8D%E8%B4%B9%E4%B8%8A%E4%BC%A0%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>对于习惯用 markdown
写作的人，日常最烦恼的问题之一应该是如何显示自己的图片，markdown
文本存储的是图片的地址（本地路径或url），而最为常用的是
url，至少我写文章是这样的。某些 markdown 编辑器也提供了 markdown
图床服务，如有道云笔记，cmd_markdown等,
但是这些编辑器要么太丑（有道云笔记，说的就是你），要么就是比较小众（cmd
markdown），生怕哪天停止运营了文章里的图片就没了，而且这些服务一般是要收费的。</p>
<p>那么有没有一种方法能够为本地图片生成 public
url，同时保证数据有较高的可用性，而且最好是免费的。Github
其实已经间接为我们提供了这样的服务，只是这个步骤较为繁琐，本文就是针对这一点开发了一个小工具来简化这个过程，代码已开源，见
<a
href="https://github.com/WuLC/MarkdownImageUploader">MarkdownImageUploader</a>，本文主要介绍其基本原理和使用方法。</p>
<span id="more"></span>
<h2 id="原理">原理</h2>
<p>这个方法是基于 Github 会为 repository 中的每张图片生成一个 public
url，假设你的 Github 某个 repository 的有某张图片, 那么访问这张图片的
public url 为</p>
<p><code>https://raw.githubusercontent.com/&#123;user&#125;/&#123;repository&#125;/&#123;branch&#125;/&#123;img_path&#125;</code></p>
<p>其中，<code>&#123;user&#125;</code> 就是你的 Github
用户名称，<code>&#123;repository&#125;</code>
是你的仓库名称，<code>&#123;branch&#125;</code>
是你的分支名称，<code>&#123;img_path&#125;</code> 则是这张图片在这个 repository
中的路径；如对于<a
href="https://wulc.me/imgs/GFS_Architecture.png?1556003688166">这张图片</a>，其
public url 为</p>
<p><code>https://wulc.me/imgs/GFS_Architecture.png</code></p>
<p>所以此时问题就变得很直观了，只需要将需要生成 public url 的图片 push
到 github，然后按照上面的规则生成图片的 public url 即可，感谢
Github。</p>
<h2 id="使用">使用</h2>
<p>但是这个过程如果重复多次也会显得重复而繁琐，每次都要
<code>add &amp;&amp; commit &amp;&amp; push</code>,
因此，本文开发了一个简单的小工具 <a
href="https://github.com/WuLC/MarkdownImageUploader">MarkdownImageUploader</a>
来让这个过程更为便捷。</p>
<p>MarkdownImageUploader
主要思想就是通过提供一个简单的界面，通过按钮来提供上面的功能，按钮按下后执行
<code>git commit</code> 等操作，因此使用前需要确保</p>
<p><strong>1. git 已经安装且在 PATH 环境变量中</strong> <strong>2.
上传的图片的仓库是 public 且具备修改权限</strong></p>
<p>建议在使用前首先在 github 上建立一个 public
repository，专门用于存储图片；并配置 MarkdownImageUploader 的
repo_address 为其地址，然后配置本地存储这个 repository
的路径，这个配置只需要在第一次使用时进行配置，之后 MarkdownImageUploader
会在 config
目录下生成文件保存这些信息，之后的使用也可随时更新这些信息。该过程如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/configure.gif" alt="configure" />
<figcaption aria-hidden="true">configure</figcaption>
</figure>
<p>在配置后，点击 <code>commit &amp; push</code>
进行图片的上传，程序首先会检查配置的本地 repository
的路径中是否已经存在了这个 repository，没有的话会先 clone
到本地，然后填写 commit message 进行 commit 和
push，需要注意这两者都不能为空，我一般会将文章的标题作为 commit
message。该过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/upload.gif" alt="upload" />
<figcaption aria-hidden="true">upload</figcaption>
</figure>
<p>Windows 用户可直接从<a
href="https://github.com/WuLC/MarkdownImageUploader/releases">release</a>下载可执行文件，win10
和 win7 的 64 位系统测试过都可用，32位系统的不确定，但是也可通过源码和
<a href="https://www.pyinstaller.org/">PyInstaller</a> 进行构建；Linux
和 Mac 可以下载源码，然后直接运行 <code>python main.py</code>
为后台程序，但是需要安装依赖库 <a
href="https://github.com/PySimpleGUI/PySimpleGUI">PySimpleGUI</a>，而且
<a
href="https://github.com/PySimpleGUI/PySimpleGUI#platforms">PySimpleGUI
在 Mac 上适配性不太好</a>，不确保能顺利运行。</p>
<h2 id="代码">代码</h2>
<p>代码使用的 GUI 库是 <a
href="https://github.com/PySimpleGUI/PySimpleGUI#platforms">PySimpleGUI</a>，一个小众但是比较方便的库；调用
git 命令使用的 python 的 subprocess 库，调用 git
命令时会捕获异常并弹窗提醒，但是当前的异常没有细分（比如说 commit &amp;
push 失败后，并不知道是 commit 或 push
环节失败的）；所以直接使用时建议先在命令行跑通 git 这几条命令。</p>
<p>代码很简单，所有代码不到 200 行（见<code>main.py</code>), 程序的 UI
极丑（捂脸），但是目前基本能满足我的使用需求，先使用一段时间看看，后续如果有
bug 或新的需求再更改。</p>
<p>最后， Github 生成的图片的 url 的域名是
<code>githubusercontent.com</code>, 万一哪天 Github
放弃了这个域名或不再提供单张图片的
url，那就凉凉了，不过在当前看来短期发生这个事情的可能性不大。而其实通过付费使用大厂提供的
markdown
图床也是很方便的，如果有道云笔记把界面做得更好看一点，其实我还是挺愿意为其付费的。</p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>《Modeling Delayed Feedback in Display Advertising》 阅读笔记</title>
    <url>/2020/05/17/Modeling%20Delayed%20Feedback%20in%20Display%20Advertising%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>在计算广告中，转化是有延迟的，即在点击发生后过一段时间用户可能才会发生转化，且往往转化漏斗越深，延迟的时间越长；因此在训练
cvr/deepcvr
模型时，会有两种情况出现（1）过早把样本送入模型，把最终会转化但是还没回传
label
的事件当做负例，导致模型低估（2）过晚把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，导致模型没能及时更新</p>
<p>因此在建模时需要对转化的回传延时进行建模，这篇 paper 《<a
href="http://olivier.chapelle.cc/pub/delayedConv.pdf">Modeling Delayed
Feedback in Display Advertising</a>》是 <a
href="https://www.criteo.com/">criteo</a>
针对这个问题提供的一个解决方法，主要思想就是<strong>对于还未观察到
conversion 的样本，不直接将其当做负样本，而是当前考虑 click
已发生的时间长短给模型不同大小的 gradient</strong>；paper 里称在 criteo
的真实的数据上验证了该方法的有效性。此外，文章从问题的建模到求解的思路不错，值得一看。</p>
<span id="more"></span>
<h2 id="为什么要对延迟建模">为什么要对延迟建模</h2>
<p>与转化的回传紧密相关的一个话题就是归因（attribution），即将转化归到哪一个
click 上，paper 中用了常用的 last-click 归因，归因窗口固定在 30
天内，即在点击后30天以内回传的转化才认为是有效的。</p>
<p>对回传延迟建模往往要先分析延迟的分布，且对于不同的广告主、行业等，这个值的差异往往还是比较大的，在paper中统计结果如下图一所示，结果显示约35%的转化会在一小时内回传，50%
会在24小时内回传。</p>
<p>此外，paper
中还提到了新计划的问题，主要的观点是每天都会有大量的新计划被创建（如下图二所示），如果不能尽快将这些新计划对应的样本喂给模型，会导致模型在这些新计划上预估得不好</p>
<figure>
<img src="https://wulc.me/imgs/WhyNeedModelDelay.jpg" alt="graph" />
<figcaption aria-hidden="true">graph</figcaption>
</figure>
<p>上面这两张图正好对应着文章开头说的要对 delayed conversion
进行建模的原因；图一表明如果样本不延迟做归因，会把最终会转化但是还没回传
label
的事件当做负例，导致模型低估，图二则表明如果等待过长时间才把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，会导致模型没能及时更新</p>
<h2 id="问题建模">问题建模</h2>
<p>下面的建模采用到的一些符号及其含义如下所示</p>
<ul>
<li><span class="math inline">\(X\)</span>: 特征</li>
<li><span class="math inline">\(Y \in \lbrace 0, 1\rbrace\)</span>:
当前时刻 conversion 是否已经发生了</li>
<li><span class="math inline">\(C \in \lbrace 0,
1\rbrace\)</span>：conversion 最终是否会发生</li>
<li><span class="math inline">\(D\)</span>：回传延迟的真正时间</li>
<li><span class="math inline">\(E\)</span>：当前已过去的时间</li>
</ul>
<p>则当前如果</p>
<ul>
<li>观察到转化还没发生即 <span
class="math inline">\(Y=0\)</span>，有两种可能
<ul>
<li><ol type="1">
<li>转化最终不会发生 <span class="math inline">\(C=0\)</span></li>
</ol></li>
<li><ol start="2" type="1">
<li>转化最终会发生，但是 <span
class="math inline">\(D&gt;E\)</span></li>
</ol></li>
</ul></li>
<li>观察到转化已发生即 <span class="math inline">\(Y=1\)</span>,
则肯定有 <span class="math inline">\(C=1\)</span>；即 <span
class="math inline">\(Y=1\)</span> 是 <span
class="math inline">\(C=1\)</span> 的充分条件</li>
</ul>
<p>且 paper 中做了如下的假设，<strong>当前已过去的时间 <span
class="math inline">\(E\)</span>
与最终是否的转化时间以及是否会转化无关</strong>，即</p>
<p><span class="math display">\[P(C,D|X,E) = P(C,D|X)\]</span></p>
<p>这个假设也是比较合理的，因为最终是否转化及转化的延迟时间与当前已经过去的时间长短无关。</p>
<p>paper 中对将问题分为两部分来建模，第一部分是常见的 ctr
预估模型，如下公式(1) 所示，第二部分是通过指数分布来建模回传延迟 <span
class="math inline">\(D\)</span>, 如下公式(2)所示；除了指数分布，<a
href="https://en.wikipedia.org/wiki/Weibull_distribution">weibull
分布</a>、<a
href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma
分布</a>、<a
href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal
分布</a> 也常被用来建模事件发生的时间间隔，这些分布是 <a
href="https://en.wikipedia.org/wiki/Survival_analysis#General_formulation">Survival
analysis</a> 这个研究领域里常用的分布。</p>
<p><span class="math display">\[P(C=1|X=x)=p(x)=\frac{1}{1+\exp(-w\_cx)}
\tag{1}\]</span></p>
<p><span class="math display">\[P(D=d|X=x,
C=1)=\lambda(x)\exp(-\lambda(x)d) \tag{2}\]</span></p>
<p>其中 <span class="math inline">\(\lambda(x)\)</span> 在 survival
analysis 中被称为 <a
href="https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function">hazard
function</a>，其含义表示的是<strong>事件发生的频率/强度</strong>;
如对于指数分布，如果这个值越大，表示事件发生频率越大，事件间的时间间隔越短，则概率密度函数会越陡峭，如下图所示。此外，为了保证
<span class="math inline">\(\lambda(x) \gt 0\)</span>, 这里令 <span
class="math inline">\(\lambda(x) = \exp(w\_dx)\)</span></p>
<figure>
<img src="https://wulc.me/imgs/ExpProbDenFunc.jpg"
alt="exp prob density" />
<figcaption aria-hidden="true">exp prob density</figcaption>
</figure>
<p>此外，指数分布用来建模两个事件发生的时间间隔，而泊松分布则用来建模某段时间里事件发生的次数，详细的讲解可参考知乎上的这个回答
<a
href="https://www.zhihu.com/question/24796044/answer/673838656">指数分布公式的含义是什么？</a></p>
<p>有了公式(1)和公式(2) 后，我们就可以推导在考虑回传延迟下 pvr
预估问题了；下面可<strong>分两种情况写出样本的似然：即已观察到
conversion 的样本和未观察到 conversion 的样本</strong></p>
<h3 id="已观察到-conversion-的样本的似然">已观察到 conversion
的样本的似然</h3>
<p>即当前观察到 conversion 的概率可写成</p>
<p><span class="math display">\[
\begin{split}
p\_1&amp;=p(Y=1, D=d\_i|X = x\_i, E=e\_i) \\\
&amp;= p(Y=1,D=d\_i|X = x\_i) \\\
&amp;= p(C=1,D=d\_i|X = x\_i) \\\
&amp;= p(D=d\_i|X=x\_i, C=1)*p(C=1|X=x\_i)
\end{split}
\]</span></p>
<p>上面的推导的三步主要利用了以下三点</p>
<ul>
<li>针对该问题的假设：当前已过去的时间 <span
class="math inline">\(E\)</span>
与最终是否会转化无关，同时与转化时间无关</li>
<li><span class="math inline">\(Y=1\)</span> 是 <span
class="math inline">\(C=1\)</span> 的充分条件</li>
<li>条件概率公式 <span class="math inline">\(p(a|b,c) * p(b|c) =
p(a,b|c)\)</span></li>
</ul>
<p>最后可将概率表示成公式(1) 和公式（2）的乘积，则</p>
<p><span class="math display">\[p\_1=p(Y=1, D=d\_i|X = x\_i,
E=e\_i)=\lambda(x\_i)\exp(-\lambda(x\_i)d\_i) * p(x\_i)
\tag{3}\]</span></p>
<h3 id="未观察到-conversion-的样本的似然">未观察到 conversion
的样本的似然</h3>
<p>同理，可写出当前还没观察到 conversion 的样本的概率 <span
class="math inline">\(p\_0\)</span> 为</p>
<p><span class="math display">\[
\begin{split}
p\_0&amp;=p(Y=0|X = x\_i, E=e\_i) \\\
&amp;=p(Y=0|C=0, X = x\_i, E=e\_i)p(C=0|X=x\_i) +\\\
&amp;p(Y=0|C=1, X = x\_i, E=e\_i)p(C=1|X=x\_i) \\\
&amp;=p(C=0|X=x\_i) + p(Y=0|C=1, X = x\_i, E=e\_i)p(C=1|X=x\_i)
\end{split}
\]</span></p>
<p>上面的推导的两步主要利用了以下两点</p>
<ul>
<li>全概率公式 + 条件概率
<ul>
<li><span
class="math inline">\(p(a|c)=\sum\_{b\_i}p(ab\_i)\)</span></li>
<li><span class="math inline">\(p(ab\_i|c)=\sum\_{b\_i}p(a|b\_i,
c)p(b\_i|c)\)</span></li>
</ul></li>
<li><span class="math inline">\(p(Y=0|C=0, X = x\_i,
E=e\_i)=1\)</span></li>
</ul>
<p>则上面的推导关键点在于求出条件概率 <span
class="math inline">\(p(Y=0|C=1, X = x\_i, E=e\_i)\)</span>,
该条件概率的含义是<strong>当前未观察到 conversion
的样本最终会转化的概率，换种描述就是最终的延时<span
class="math inline">\(D\)</span>大于当前已过去时间<span
class="math inline">\(E\)</span>的概率</strong>，即可表示成如下公式</p>
<p><span class="math display">\[
\begin{split}
&amp;p(Y=0|C=1, X = x\_i, E=e\_i) \\
&amp;=p(D&gt;E|C=1,X=x\_i, E=e\_i) \\
&amp;=\int\_{e\_i}^{\infty} \lambda(x)\exp(\lambda(x)t)dt \\
&amp;=\exp(-\lambda(x)e\_i)
\end{split}
\]</span></p>
<p>即最终有 <span class="math display">\[p\_0=p(Y=0|X = x\_i,
E=e\_i)=1-p(x\_i) + p(x\_i) * \exp(-\lambda(x\_i)e\_i)
\tag{4}\]</span></p>
<h3 id="小结">小结</h3>
<p>综上</p>
<ul>
<li>对于当前观察到conversion的样本，其似然函数为公式(3)即,</li>
</ul>
<p><span
class="math display">\[p\_1=\lambda(x\_i)\exp(-\lambda(x\_i)d\_i) *
p(x\_i) \]</span></p>
<ul>
<li>对于当前未观察到conversion的样本，其似然函数为公式(4)即</li>
</ul>
<p><span class="math display">\[p\_0=1-p(x\_i) + p(x\_i) *
\exp(-\lambda(x\_i)e\_i) \]</span></p>
<p>可以看到，这里 <span class="math inline">\(p\_0 + p\_1 \ne
1\)</span>, 跟我们常见的建模方式不一样</p>
<h2 id="问题求解">问题求解</h2>
<p>上面的问题的解法的基本原理是
MLE(极大似然估计)，但是根据是否显式地写出变量 <span
class="math inline">\(C\)</span> 的条件概率有两种解法，第一种是将 <span
class="math inline">\(C\)</span> 当做隐变量，通过 EM
算法求解；<strong>第二种没有直接写出隐变量 <span
class="math inline">\(C\)</span> 的概率密度函数，而是直接写出样本集的
likelihood，因为从上面的问题建模中已经基于当前观察到的 <span
class="math inline">\(y\_i\)</span> 写出对应的似然函数了。</strong></p>
<h3 id="em-算法">EM 算法</h3>
<p>关于 EM 算法的推导，CS229 的讲义 <a
href="http://cs229.stanford.edu/notes/cs229-notes8.pdf">EM algorithm</a>
里讲得比较详细了，证明的基本流程就是</p>
<ol type="1">
<li>在似然函数中通过全概率公式引入隐变量</li>
<li>通过 Jensen’s inequality 把隐变量提出来</li>
<li>优化目标转转为最大化 Jensen’s inequality 的下界，让 Jensen’s
inequality 取等号得到隐变量的概率密度函数(E-step)</li>
<li>将隐变量的概率密度函数带入似然函数中做MLE即可(M-step)</li>
</ol>
<p>知乎上也有一个比较通俗的回答<a
href="https://zhuanlan.zhihu.com/p/36331115">人人都懂EM算法</a>，因此证明过程这里就不再展开赘述了</p>
<p>简单来说，EM 算法中的 <strong>E-step是为了通过条件概率 <span
class="math inline">\(p(z|x;\theta)\)</span> 来表示隐变量 <span
class="math inline">\(H\)</span>，从而替换掉似然函数中的隐变量；进而在
M-step 中只针对 <span class="math inline">\(\theta\)</span>
来进行进行极大似然即可</strong>.如下图所示是 CS229
讲义里的一次迭代的流程, 里面的 <span class="math inline">\(i\)</span>
表示隐变量可能的状态</p>
<figure>
<img src="https://wulc.me/imgs/EM_algorithm.jpg" alt="EM" />
<figcaption aria-hidden="true">EM</figcaption>
</figure>
<p>EM 算法的证明中通过证明了算法会随着 E-step + M-step
逐步收敛的，但是不能保证收敛到全局最优，如果我们的优化目标是凸的，则EM算法可以保证收敛到全局最优，因为对于凸函数局部最优即全局最优。</p>
<p>回到这个问题，由于 <span class="math inline">\(C\)</span>
是隐变量，则 E-step 和 M-step 的过程分别如下</p>
<p><strong>E-step</strong></p>
<p>给定一个样本 <span class="math inline">\((x\_i, y\_i, e\_i)\)</span>,
令隐变量的条件概率为</p>
<p><span class="math display">\[p(C=1|X=x\_i, Y=y\_i) :=
w\_i\]</span></p>
<p>相比于上面的 EM 算法的流程，我们这还多了一个 <span
class="math inline">\(y\_i\)</span>, 因此还要对 <span
class="math inline">\(y\_i\)</span> 的值进行分类讨论</p>
<ul>
<li>当 <span class="math inline">\(y\_i=1\)</span> 时，可知 <span
class="math inline">\(w\_i=1\)</span>（因为 <span
class="math inline">\(Y=1\)</span> 是 <span
class="math inline">\(C=1\)</span> 的充分条件）</li>
<li>当 <span class="math inline">\(y\_i=0\)</span> 时，其计算方法如下,
即</li>
</ul>
<p><span class="math display">\[
\begin{split}
w\_i&amp;=p(C=1|Y=0,X=x\_i,E=e\_i) \\\
&amp;=p(Y=0|C=1, X = x\_i, E=e\_i)p(C=1|X=x\_i) \\\
&amp;=p(x\_i) * \exp(-\lambda(x\_i)e\_i)
\end{split}
\]</span></p>
<p>计算出 <span class="math inline">\(w\_i=p(C=1|X=x\_i,
Y=y\_i)\)</span> 后，<span class="math inline">\(p(C=0|X=x\_i, Y=y\_i) =
1-w\_i\)</span></p>
<p><strong>M-step</strong></p>
<p>M step 最大化的似然函数根据<span class="math inline">\(Y\)</span> 和
<span class="math inline">\(C\)</span> 的值可分为四项，分别对应与上图中
M-step 中的两层 <span class="math inline">\(\sum\)</span> 嵌套，且在
<span class="math inline">\(Y=1\)</span> 的情况下 <span
class="math inline">\(C=0\)</span> 的概率为0，最终M-step
的似然函数如下所示</p>
<p><span class="math display">\[
\begin{split}
L&amp;=\sum\_{i,y\_i=1}w\_i \* \log p(Y=1,D=d\_i|X=x\_i,E=e\_i) + \\\
&amp;\sum\_{i,y\_i=0}[ w\_i \* \log p(Y=0,C=1|X=x\_i,E=e\_i) + \\\
&amp;(1-w\_i) \* \log p(Y=0,C=0|X=x\_i,E=e\_i)]
\end{split}
\]</span></p>
<p>且由前面可知，<span class="math inline">\(w\_i\)</span> 取值为</p>
<p><span class="math display">\[
w_i = \begin{cases}
1 &amp; &amp;y_i =1 \\\
p(x_i) * \exp(-\lambda(x_i)e_i) &amp; &amp;y_i =0
\end{cases}
\]</span></p>
<p>因此，利用公式(3)和公式(4)的推导，导入上式最终化简得到结果为</p>
<p><span class="math display">\[
\begin{split}
L&amp;=\sum\_{i}w\_i \log p(x\_i) + (1-w\_i) \log(1-p(x\_i)) \\\
&amp;+\sum\_{i} \log(\lambda(x\_i))y\_i - \lambda(x\_i)t\_iw\_i
\end{split}\tag{5}
\]</span></p>
<p>除了 <span class="math inline">\(w\_i\)</span> 的值要根据 <span
class="math inline">\(y\_i\)</span> 的值变化外，公式 (5) 中的 <span
class="math inline">\(t\_i\)</span> 也需要根据 <span
class="math inline">\(y\_i\)</span> 的值变化，即如下所示</p>
<p><span class="math display">\[
t_i = \begin{cases}
e_i &amp;y_i =1 \\\
d_i &amp;y_i =0
\end{cases}
\]</span></p>
<p>至此，可通过公式(5)对 <span class="math inline">\(p\)</span> 和 <span
class="math inline">\(\lambda\)</span> 进行 MLE
了，且从公式(5)中可看到，<strong>对 <span
class="math inline">\(p\)</span> 执行的优化是一个 weighted logistics
regression 的过程，而对 <span class="math inline">\(\lambda\)</span>
执行的优化构成则是一个 exponential regression</strong></p>
<h3 id="joint-optimization">Joint Optimization</h3>
<p>在上面的问题建模中，基于当前观察到的 <span
class="math inline">\(y\_i\)</span>
已经能写出样本对应的似然函数了，因此虽然问题中包含隐变量 <span
class="math inline">\(C\)</span>, 但是不一定要显示的将 <span
class="math inline">\(C\)</span>
的条件概率写出来（<strong>当无法写出样本对应的似然函数了需要这一步，这个时候就一定要通过
EM 算法求解了</strong>）</p>
<p>根据MLE，求解的问题可表示成如下形式</p>
<p><span class="math display">\[\arg \min\_{w\_c,w\_d}
L(w\_c,w\_d)+\frac{\mu}{2}(||w\_c||\_2^2 + ||w\_d||\_2^2)\]</span></p>
<p>上面的公式中加入了 L2 regularization，要求教的 <span
class="math inline">\(w\_c,w\_d\)</span> 分别是 <span
class="math inline">\(p\)</span> 和 <span
class="math inline">\(\lambda\)</span> 的参数；根据公式 (3) 和 (4),
可写出 <span class="math inline">\(L(w\_c,w\_d)\)</span> 为</p>
<p><span class="math display">\[
L(w\_c,w\_d) = -\sum\_{i, y\_i=1} \log(p(x\_i)+ \log
\lambda(x\_i)-\lambda(x\_i)d\_i  - \\\
\sum\_{i, y\_i=0} \log[1-p(x\_i) + p(x\_i) \exp(-\lambda(x\_i)e\_i)]
\]</span></p>
<p>其中，<span
class="math inline">\(p(x)=\frac{1}{1+\exp(-w\_cx)}\)</span> , <span
class="math inline">\(\lambda(x) = \exp(w\_dx)\)</span></p>
<p>则对 <span class="math inline">\(w\_c\)</span> 和 <span
class="math inline">\(w\_d\)</span> 的导数如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/gradient_formula.jpg" alt="gradient" />
<figcaption aria-hidden="true">gradient</figcaption>
</figure>
<p>从上面的求导的表达式可知，对于当前 <span
class="math inline">\(y\_i=0\)</span> 即label还没回传的样本，其对 <span
class="math inline">\(w\_c\)</span> 的影响可从下面两方面去了解</p>
<p>(1)当 <span class="math inline">\(\lambda(x\_i)e\_i \ll 1\)</span>,
即当前已经过去的时间 <span class="math inline">\(e\_i\)</span>
远小于平均的回传时间 <span
class="math inline">\(\lambda(x\_i)^{-1}\)</span> 时，<strong><span
class="math inline">\(\sum\_{i, y\_i}\)</span>
这一项几乎为0，表示click发生的时间还很短，没法完全确认最终是没有
conversion 的</strong> (2)<span class="math inline">\(\lambda(x\_i)e\_i
\gg 1\)</span>, 即当前已经过去的时间 <span
class="math inline">\(e\_i\)</span> 远大于平均的回传时间 <span
class="math inline">\(\lambda(x\_i)^{-1}\)</span> 时，<strong>对 <span
class="math inline">\(w\_c\)</span> 贡献的梯度是 <span
class="math inline">\(1/(1-p(x\_i))\)</span>, 相当于在 logistics
regression
中的一个负样本的梯度，表示已经过了较长时间还没观察到conversion，可认为这个样本是负样本了</strong></p>
<h3 id="小结-1">小结</h3>
<p>前面主要讲了求解建模好的问题的两种解法，第一种方法是显式地写出了隐变量
<span class="math inline">\(C\)</span> 的条件概率，并通过 EM
算法求解；第二种方法则是直接写出所有样本的似然函数直接求解。值得注意的是，<strong>在serving的时候只使用ctr预估模型，而不用建模延时的指数回归模型，因为在做反向传播过程中已经考虑了回传延迟对参数进行了修正</strong></p>
<h2 id="实验">实验</h2>
<p>实验数据：实验数据使用了 criteo 里的真实数据（但是 paper
里附的实验数据链接打不开了）；7天测试数据，每天的测试数据对应的训练数据是其前3周的数据（约600w条样本）</p>
<p>实验设置：为了与实验提出来的 DFM
模型作对比，对照组里提供了若干个模型</p>
<ul>
<li>Short Term Conversion(STC): 采用了两个模型
<ul>
<li>第1个模型用来预估样本在某段时间内转化的概率，即<span
class="math inline">\(p(C=1,D \le 1 day|X=x)\)</span></li>
<li>第2个模型用来预估在这段时间内转化的样本占所有转化样本的比例，即
<span class="math inline">\(p(D \le 1 day|C=1, X=x) = p(C=1,D \le 1
day|X=x)/p(C=1|X=x)\)</span></li>
<li>则最终预估的概率是 <span class="math inline">\(p(C=1|X=x)=\)</span>,
即是上面两个模型预估值之比</li>
</ul></li>
<li>NAIVE: 不考虑样本的转化的回传延迟</li>
<li>SHIFTED：所有样本都等待30天后，确认每个样本的 label
都是准确后才把模型送入样本进行训练</li>
<li>ORACLE:
拥有上帝视角的模型，即在样本送入模型时就能知道这个样本最终是否会转化</li>
<li>RESCALE：与 NAIVE 一样，但是预估的 cvr 会除以一个常数，</li>
</ul>
<p>实验结果如下图所示，<strong>评估指标是平均 <a
href="https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/">negative
log-likelihood</a>(NLL)，因为 NLL 比起AUC等指标更能反映预估 cvr
值的准确性</strong>。</p>
<figure>
<img src="https://wulc.me/imgs/DelayFeedBackExp.jpg" alt="exp" />
<figcaption aria-hidden="true">exp</figcaption>
</figure>
<p>实验中提供了两套评估数据集，overall 和
recent，前者是全集，后者则是专门针对新计划的，从实验结果来看，DFM
模型的预估结果次优于有上帝视角的 ORACLE 模型。</p>
<h2 id="小结-2">小结</h2>
<p>综上，paper
针对转化回传有延迟的问题提出了一种建模方法，建模的思想是不把还没观察到
conversion 的样本直接当做负样本去处理，而是考虑其距离当前 click
发生的时间长短给予模型不同权重的梯度。</p>
<p>除了之外，这个问题另一种思路就是直接用regression model
来建模回传延迟的时间。而转化回传的延迟除了会影响cvr模型的预估，<strong>还会影响以保成本为目标的
bidding 方式</strong>，即当前 conversion
还没回传时，不能直接认为没有conversion，而是要考虑一种更为平滑的 pacing
策略。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL的锁机制</title>
    <url>/2016/08/16/MySQL%E7%9A%84%E9%94%81%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>在计算机科学中，锁是在执行多线程时用于强行限制资源访问的同步机制，即用于在并发控制中保证对互斥要求的满足。</p>
<p>本文主要以MySQL为例，讲述几个锁的概念(行级锁、页级锁、表级锁、共享锁、排它锁等)，这些概念的范畴不限于MySQL，在并发系统上均有应用。</p>
<span id="more"></span>
<h2 id="行级锁页级锁表级锁">行级锁，页级锁，表级锁</h2>
<p>在DBMS中，可以按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎
)。</p>
<h3 id="行级锁">行级锁</h3>
<p>行级锁是Mysql中<strong>锁定粒度最细</strong>的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。<strong>行级锁分为共享锁
和 排他锁。</strong></p>
<p><strong>特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。</strong></p>
<h3 id="表级锁">表级锁</h3>
<p>表级锁是MySQL中<strong>锁定粒度最大</strong>的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，<strong>被大部分MySQL引擎支持</strong>。最常使用的MYISAM与INNODB都支持表级锁定。<strong>表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。</strong></p>
<p><strong>特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。</strong></p>
<h3 id="页级锁">页级锁</h3>
<p>页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁</p>
<p><strong>特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</strong></p>
<h3 id="常用存储引擎及其锁机制">常用存储引擎及其锁机制</h3>
<ol type="1">
<li><p>MyISAM和MEMORY采用表级锁(table-level locking)</p></li>
<li><p>BDB采用页面锁(page-level
locking)或表级锁，<strong>默认为页面锁</strong></p></li>
<li><p>InnoDB支持行级锁(row-level
locking)和表级锁,<strong>默认为行级锁</strong></p></li>
</ol>
<h4 id="innodb中的行锁与表锁">Innodb中的行锁与表锁</h4>
<p>前面提到过，在Innodb引擎中既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候或只锁住一行呢？</p>
<p><strong>InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。</strong>InnoDB这种行锁实现特点意味着：<strong>只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！</strong></p>
<p>值得注意的是，<strong>DBMS
对于主键会自动生成唯一索引，所以主键也是一个特殊的索引</strong>。即通过主键进行查询也能实现行级锁。</p>
<p>在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。</p>
<p><strong>行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。</strong>行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。</p>
<h4 id="行级锁与死锁">行级锁与死锁</h4>
<p><strong>MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。</strong></p>
<p>在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。</p>
<p>在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key
locking。</p>
<p>当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。</p>
<p>发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。</p>
<h4 id="避免死锁">避免死锁</h4>
<p>如何避免死锁，这里只介绍常见的三种</p>
<p>1、如果不同程序会并发存取多个表，尽量<strong>约定以相同的顺序访问表</strong>，可以大大降低死锁机会。</p>
<p>2、在同一个事务中，尽可能做到<strong>一次锁定所需要的所有资源</strong>，减少死锁产生概率；</p>
<p>3、对于非常容易产生死锁的业务部分，可以尝试使用<strong>升级锁定颗粒度</strong>，通过表级锁定来减少死锁产生的概率</p>
<h2 id="共享锁排它锁意向锁">共享锁，排它锁，意向锁</h2>
<p>行级锁分为共享锁和排他锁两种，下面将详细介绍共享锁及排他锁的概念、使用方式及注意事项等。</p>
<h3 id="共享锁share-lockslock">共享锁(Share Lock，SLock)</h3>
<p>共享锁又称<strong>读锁</strong>，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。</p>
<p><strong>如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。</strong></p>
<p>语法：<code>SELECT ... LOCK IN SHARE MODE;</code></p>
<p>在查询语句后面增加<code>LOCK IN SHARE MODE</code>，Mysql会对查询结果中的每行都加共享锁，<strong>当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。</strong></p>
<h3 id="排他锁exclusive-lockxlock">排他锁（eXclusive Lock，XLock）</h3>
<p>排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。</p>
<p>语法：<code>SELECT ... FOR UPDATE;</code></p>
<p>在查询语句后面增加<code>FOR UPDATE</code>，Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。</p>
<h3 id="意向锁intent-lock">意向锁（Intent Lock）</h3>
<p>InnoDB还有两个表锁：</p>
<p><strong>意向共享锁（IS）</strong>：表示事务准备给数据行加入共享锁，也就是说<strong>给一个数据行加共享锁前必须先取得该表的IS锁</strong></p>
<p><strong>意向排他锁（IX）</strong>：类似上面，表示事务准备给数据行加入排他锁，说明事务<strong>在一个数据行加排他锁前必须先取得该表的IX锁</strong></p>
<p><strong>意向锁是InnoDB自动加的，不需要用户干预。</strong></p>
<p><strong>对于insert、update、delete，InnoDB会自动给涉及的数据加排他锁（X）；对于一般的Select语句，InnoDB不会加任何锁，事务可以通过以下语句给显示加共享锁或排他锁</strong>。</p>
<p>共享锁：<code>SELECT ... LOCK IN SHARE MODE;</code></p>
<p>排他锁：<code>SELECT ... FOR UPDATE;</code></p>
<h2 id="乐观锁悲观锁">乐观锁，悲观锁</h2>
<p>数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。</p>
<p><strong>乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。</strong></p>
<p>无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。其实不仅仅是关系型数据库系统中有乐观锁和悲观锁的概念，像memcache、hibernate、tair等都有类似的概念。</p>
<p>针对于不同的业务场景，应该选用不同的并发控制方式。所以，不要把乐观并发控制和悲观并发控制狭义的理解为DBMS中的概念，更不要把他们和数据中提供的锁机制（行锁、表锁、排他锁、共享锁）混为一谈。其实，在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。</p>
<h3 id="悲观锁">悲观锁</h3>
<p>悲观并发控制（又名“悲观锁”，Pessimistic Concurrency
Control，缩写“PCC”）是一种并发控制的方法。</p>
<p>悲观锁，正如其名，它指的是<strong>对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度(悲观)</strong>
，因此，在整个数据处理过程中，将数据处于锁定状态。</p>
<p><strong>悲观锁的实现，往往依靠数据库提供的锁机制</strong>
（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）</p>
<p>在数据库中，悲观锁的流程如下：
（1）在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive
locking）。
（2）如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。
具体响应方式由开发者根据实际需要决定。
（3）如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。</p>
<p>下面讲述在MySQL
InnoDB中使用悲观锁，要使用悲观锁，我们<strong>必须关闭MySQL数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="number">0.</span>关闭自动提交属性</span><br><span class="line"><span class="keyword">set</span> autocommit<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="number">1.</span>开始事务</span><br><span class="line"><span class="keyword">begin</span>;<span class="operator">/</span><span class="keyword">begin</span> work;<span class="operator">/</span><span class="keyword">start</span> transaction; </span><br><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="number">2.</span>查询出商品信息</span><br><span class="line"><span class="keyword">select</span> status <span class="keyword">from</span> t_goods <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="number">3.</span>根据商品信息生成订单</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_orders (id,goods_id) <span class="keyword">values</span> (<span class="keyword">null</span>,<span class="number">1</span>);</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="number">4.</span>修改商品status为<span class="number">2</span></span><br><span class="line"><span class="keyword">update</span> t_goods <span class="keyword">set</span> status<span class="operator">=</span><span class="number">2</span>;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span><span class="number">4.</span>提交事务</span><br><span class="line"><span class="keyword">commit</span>;<span class="operator">/</span><span class="keyword">commit</span> work;  </span><br></pre></td></tr></table></figure>
<p>上面的查询语句中，我们使用了<code>select…for update</code>的方式，这样就通过<strong>排他锁</strong>的实现了悲观锁。此时在<code>t_goods</code>表中，id
为 1
的那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。</p>
<p>优点与不足：悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数</p>
<h3 id="乐观锁">乐观锁</h3>
<p>乐观并发控制（又名“乐观锁”，Optimistic Concurrency
Control，缩写“OCC”）是一种并发控制的方法。</p>
<p>乐观锁（ Optimistic Locking ）
相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以<strong>在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。</strong></p>
<p>相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的<strong>实现乐观锁的方式就是记录数据版本</strong>。实现数据版本可以通过使用版本号或使用时间戳。实现流程如下：</p>
<p>（1）为数据表增加一个表示版本标识的字段，用于存储版本号或时间戳
（2）当读取数据时，将版本标识的值一同读出
（3）当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本标识与第一次取出来的版本标识值相等，则同时更新数据和版本号，否则认为是过期数据，返回错误给用户处理</p>
<p>下图为该流程的示意过程：</p>
<p><img
src="https://wulc.me/imgs/image_1aqrd8t7gnf183g1lqr1ndaf5o9.png" /></p>
<table style="width:10%;">
<colgroup>
<col style="width: 9%" />
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;">参考: <a
href="http://www.hollischuang.com/archives/914">MySQL中的行级锁,表级锁,页级锁</a>
<a
href="http://www.hollischuang.com/archives/923">MySQL中的共享锁与排他锁</a>
<a
href="http://www.hollischuang.com/archives/934">深入理解乐观锁与悲观锁</a>
<a
href="http://chenzhou123520.iteye.com/blog/1860954">mysql悲观锁总结和实践</a>
<a
href="http://chenzhou123520.iteye.com/blog/1863407">mysql乐观锁总结和实践</a></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven的安装、配置及使用入门</title>
    <url>/2016/02/18/Maven%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>这是一篇关于maven入门的相当好的文章，文章有点长，但是非常值得看。<a
href="http://www.cnblogs.com/dcba1112/archive/2011/05/01/2033805.html">原文链接</a></p>
<h2 id="maven简介">Maven简介</h2>
<h3 id="何为maven">何为Maven</h3>
<p>Maven这个词可以翻译为“知识的积累”，也可以翻译为“专家”或“内行”。本书将介绍Maven这一跨平台的项目管理工具。作为Apache组织中的一个颇为成功的开源项目，<strong>Maven主要服务于基于Java平
台的项目构建、依赖管理和项目信息管理。</strong>无论是小型的开源类库项目，还是大型的企业级应用；无论是传统的瀑布式开发，还是流行的敏捷模式，Maven都能
大显身手。 <span id="more"></span> #### 何为构建</p>
<p>不管你是否意识到，构建（build）是每一位程序员每天都在做的工作。早上来到公司，我们做的第一件事情就是从源码库签出最新的源码，然后进行单元测试，如果发现失败的测试，会找相关的同事一起调试，修复错误代码。接着回到自己的工作上来，编写自己的单元测试及产品代码，我们会感激IDE随时报出的编译错误提示。</p>
<p>忙到午饭时间，代码编写得差不多了，测试也通过了，开心地享用午餐，然后休息。下午先在昏昏沉沉中开了个例会，会议结束后喝杯咖啡继续工作。刚才在会上经理要求看测试报告，于是找了相关工具集成进IDE，生成了像
模像样的测试覆盖率报告，接着发了一封电子邮件给经理，松了口气。谁料QA小组又发过来了几个bug，没办法，先本地重现再说，于是熟练地用IDE生成了一个WAR包，部署到Web容器下，启动容器。看到熟悉的界面了，遵循bug报告，一步步重现了bug……快下班的时候，bug修好了，提交代码，通知
QA小组，在愉快中结束了一天的工作。</p>
<p>仔细总结一下，我们会发现，<strong>除了编写源代码，我们每天有相当一部分时间花在了编译、运行单元测试、生成文档、打包和部署等烦琐且不起眼的工作上，这就是构建。</strong>如果我们现在还手工这样做，那成本也太高了，于是有人用软件的方法让这一系列工作完全自动化，使得软件的构建可以像全自动流水线一样，只需要一条简单的命令，所有烦琐的步骤都能够自动完成，很快就能得到最终结果。</p>
<h4 id="maven是优秀的构建工具">Maven是优秀的构建工具</h4>
<p>前面介绍了<strong>Maven的用途之一是服务于构建，它是一个异常强大的构建工具，能够帮我们自动化构建过程，从清理、编译、测试到生成报告，再到打包和部署。</strong>我们不需要也不应该一遍又一遍地输入命令，一次又一次地点击鼠标，我们要做的是使用Maven配置好项目，然后输入简单的命令(如mvn
clean install)，Maven会帮我们处理那些烦琐的任务。</p>
<p>Maven是跨平台的，这意味着无论是在Windows上，还是在Linux或者Mac上，都可以使用同样的命令。</p>
<p>我们一直在不停地寻找避免重复的方法。设计的重复、编码的重复、文档的重复，当然还有构建的重复。Maven最大化地消除了构建的重复，抽象了构建生命周期，并且为绝大部分的构建任务提供了已实现的插件，我们不再需要定义过程，甚至不需要再去实现这些过程中的一些任务。最简单的例子是测试，我们没必要告诉Maven去测试，更不需要告诉Maven如何运行测试，只需要遵循Maven的约定编写好测试用例，当我们运行构建的时候，这些测试便会自动运行。</p>
<p>想象一下，Maven抽象了一个完整的构建生命周期模型，这个模型吸取了大量其他的构建脚本和构建工具的优点，总结了大量项目的实际需求。如果遵循这个模型，可以避免很多不必要的错误，可以直接使用大量成熟的Maven插件来完成我们的任务（很多时候我们可能都不知道自己在使用Maven插件）。此外，如果有非常特殊的需求，我们也可以轻松实现自己的插件。</p>
<p><strong>Maven还有一个优点，它能帮助我们标准化构建过程</strong>。在Maven之前，十个项目可能有十种构建方式；有了Maven之后，所有项目的构建命令都是简单一致的，这极大地避免了不必要的学习成本，而且有利于促进项目团队的标准化。</p>
<p>综上所述，Maven作为一个构建工具，不仅能帮我们自动化构建，还能够抽象构建过程，提供构建任务实现；它跨平台，对外提供了一致的操作接口，这一切足以使它成为优秀的、流行的构建工具。</p>
<h4 id="maven不仅仅是构建工具">Maven不仅仅是构建工具</h4>
<p>Java不仅是一门编程语言，还是一个平台，通过JRuby和Jython，我们可以在Java平台上编写和运行Ruby和Python程序。我们也应该认识到，<strong>Maven不仅是构建工具，还是一个依赖管理工具和项目信息管理工具。
它提供了中央仓库，能帮我们自动下载构件。</strong></p>
<p>在这个开源的年代里，几乎任何Java应用都会借用一些第三方的开源类库，这些类库都可通过依赖的方式引入到项目中来。随着依赖的增多，版本不一致、版本冲突、依赖臃肿等问题都会接踵而来。手工解决这些问题是十分枯燥的，幸运的是<strong>Maven提供了一个优秀的解决方案，它通过一个坐标系统准确地定位每一个构件（artifact），也就是通过一组坐标Maven能够找到任何一个
Java类库（如jar文件）。</strong>Maven给这个类库世界引入了经纬，让它们变得有秩序，于是我们可以借助它来有序地管理依赖，轻松地解决那些繁杂的依赖问题。</p>
<p>Maven还能帮助我们管理原本分散在项目中各个角落的项目信息，包括项目描述、开发者列表、版本控制系统地址、许可证、缺陷管理系统地址等。这些微小的变化看起来很琐碎，并不起眼，但却在不知不觉中为我们节省了大量寻找信息的时间。除了直接的项目信息，通过Maven自动生成的站点，以及一些已有的插件，我们还能够轻松获得项目文档、测试报告、静态分析报告、源码版本日志报告等
非常具有价值的项目信息。</p>
<p>Maven还为全世界的Java开发者提供了一个免费的中央仓库，在其中几乎可以找到任何的流行开源类库。通过一些Maven的衍生工具（如Nexus），我们还能对其进行快速地搜索。只要定位了坐标，Maven就能够帮我们自动下载，省去了手工劳动。</p>
<p>使用Maven还能享受一个额外的好处，即Maven对于项目目录结构、测试用
例命名方式等内容都有既定的规则，只要遵循了这些成熟的规则，用户在项目间切换的时候就免去了额外的学习成本，可以说是约定优于配置
（Convention Over Configuration）。</p>
<h3 id="为什么需要maven">为什么需要Maven</h3>
<p><strong>Maven不是Java领域唯一的构建管理的解决方案。本节将通过一些简单的例子解释Maven的必要性，并介绍其他构建解决方案，如IDE、Make和Ant，并将它们与Maven进行比较。</strong></p>
<h4 id="组装pc和品牌pc">组装PC和品牌PC</h4>
<p>笔者初中时开始接触计算机，到了高中时更是梦寐以求希望拥有一台自己的计算机。我的第一台计算机是赛扬733的，选购是一个漫长的过程，我先阅读了大量的杂志以了解各类配件的优劣，CPU、内存、主板、显卡，甚至声卡，我都仔细地挑选，后来还跑了很多商家，调货、讨价还价，组装好后自己装操作系统和驱动程序……虽然这花费了我大量时间，但我很享受这个过程。可是事实证明，装出来的机器稳定性不怎么好。</p>
<p>一年前我需要配一台工作站，这时候我已经没有太多时间去研究电脑配件了。我选择了某知名PC供应商的在线商店，大概浏览了一下主流的机型，选择了我需要的配置，然后下单、付款。接着PC供应商帮我组装电脑、安装操作系统和驱动程序。一周后，物流公司将电脑送到我的家里，我接上显示器、电源、鼠标和键盘就能直接使用了。这为我节省了大量时间，而且这台电脑十分稳定，商家在把电脑发送给我之前已经进行了很好的测试。对了，我还能享受两年的售后服务。</p>
<p>使用脚本建立高度自定义的构建系统就像买组装PC，耗时费力，结果也不一定很好。当然，你可以享受从无到有的乐趣，但恐怕实际项目中无法给你那么多时间。使用Maven就像购买品牌PC，省时省力，并能得到成熟的构建系统，还能得到来自于Maven社区的大量支持。唯一与购买品牌PC不同的是，Maven是开源的，你无须为此付费。如果有兴趣，你还能去了解Maven是如何工作的，而我们无法知道那些PC巨头的商业秘密。</p>
<h4 id="ide不是万能的">IDE不是万能的</h4>
<p>当然，我们无法否认优秀的IDE能大大提高开发效率。当前主流的IDE如Eclipse和NetBeans等都提供了强大的文本编辑、调试甚至重构功能。虽然使用简单的文本编辑器和命令行也能完成绝大部分开发工作，但很少有人愿意那样做。然而，IDE是有其天生缺陷的：</p>
<ul>
<li><strong>IDE依赖大量的手工操作</strong>。编译、测试、代码生成等工作都是相互独立的，很难一键完成所有工作。手工劳动往往意味着低效，意味着容易出错。</li>
<li><strong>很难在项目中统一所有的IDE配置，每个人都有自己的喜好</strong>。也正是由于这个原因，一个在机器A上可以成功运行的任务，到了机器B的IDE中可能就会失败。</li>
</ul>
<p>我们应该合理利用IDE，而不是过多地依赖它。对于构建这样的任务，在IDE中一次次地点击鼠标是愚蠢的行为。Maven是这方面的专家，而且主流IDE都集成了Maven，我们可以在IDE中方便地运行Maven执行构建。</p>
<h4 id="make">Make</h4>
<p>Make也许是最早的构建工具，它由Stuart
Feldman于1977年在Bell实验室创建。Stuart
Feldman也因此于2003年获得了ACM国际计算机组织颁发的软件系统奖。目前Make有很多衍生实现，包括最流行的GNU
Make和BSD Make，还有Windows平台的Microsoft nmake等。</p>
<p><strong>Make由一个名为Makefile的脚本文件驱动，该文件使用Make自己定义的语法格式。</strong>其基本组成部分为一系列规则（Rules），而<strong>每一条规则又包括目标（Target）、依赖（Prerequisite）和命令（Command）</strong>。Makefile的基本结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TARGET… : PREREQUISITE…</span><br><span class="line">COMMAND  </span><br><span class="line">…  </span><br><span class="line">…  </span><br></pre></td></tr></table></figure>
<p>Make通过一系列目标和依赖将整个构建过程串联起来，同时利用本地命令完成每个目标的实际行为。<strong>Make的强大之处在于它可以利用所有系统的本地命令，尤其是UNIX/Linux系统，丰富的功能、强大的命令能够帮助Make快速高效地完成任务。</strong></p>
<p>但是，Make将自己和操作系统绑定在一起了。也就是说，使用Make，就不能实现（至少很难）跨平台的构建，这对于Java来说是非常不友好的。此外，Makefile的语法也成问题，很多人抱怨Make构建失败的原因往往是一个难以发现的空格或Tab使用错误。</p>
<h4 id="ant">Ant</h4>
<p>Ant不是指蚂蚁，而是意指“另一个整洁的工具”（Another Neat
Tool），它最早用来构建著名的Tomcat，其作者James Duncan
Davidson创作它的动机就是因为受不了Makefile的语法格式。我们可以将Ant看成是一个Java版本的Make，也正因为使用了Java，Ant是跨平台的。此外，Ant使用XML定义构建脚本，相对于Makefile来说，这也更加友好。</p>
<p>与Make类似，Ant有一个构建脚本build.xml，如下所示： <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">name</span>=<span class="string">&quot;Hello&quot;</span> <span class="attr">default</span>=<span class="string">&quot;compile&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">target</span> <span class="attr">name</span>=<span class="string">&quot;compile&quot;</span> <span class="attr">description</span>=<span class="string">&quot;compile the Java source code to class files&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mkdir</span> <span class="attr">dir</span>=<span class="string">&quot;classes&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">javac</span> <span class="attr">srcdir</span>=<span class="string">&quot;.&quot;</span> <span class="attr">destdir</span>=<span class="string">&quot;classes&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">target</span> <span class="attr">name</span>=<span class="string">&quot;jar&quot;</span> <span class="attr">depends</span>=<span class="string">&quot;compile&quot;</span> <span class="attr">description</span>=<span class="string">&quot;create a Jar file &quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">jar</span> <span class="attr">destfile</span>=<span class="string">&quot;hello.jar&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">fileset</span> <span class="attr">dir</span>=<span class="string">&quot;classes&quot;</span> <span class="attr">includes</span>=<span class="string">&quot;**/*.class&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">attribute</span> <span class="attr">name</span>=<span class="string">&quot;Main.Class&quot;</span> <span class="attr">value</span>=<span class="string">&quot;HelloProgram&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">jar</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>build.xml的基本结构也是目标（target）、依赖（depends），以及实现目标的任务。</strong>比如在上面的脚本中，jar目标用来创建应用程序jar文件，该目标依赖于compile目标，后者执行的任务是创建一个名为classes的文件夹，编译当前目录的java文件至classes目录。compile目标完成后，jar目标再执行自己的任务。Ant有大量内置的用Java实现的任务，这保证了其跨平台的特质，同时，Ant也有特殊的任务exec来执行本地命令。</p>
<p><strong>和Make一样，Ant也都是过程式的，开发者显式地指定每一个目标，以及完成该目标所需要执行的任务。针对每一个项目，开发者都需要重新编写这一过程，这里其实隐含着很大的重复。</strong></p>
<p>Maven是声明式的，项目构建过程和过程各个阶段所需的工作都由插件实现，并且大部分插件都是现成的，开发者只需要声明项目的基本元素，Maven就执行内置的、完整的构建过程。这在很大程度上消除了重复。</p>
<p><strong>Ant是没有依赖管理的</strong>，所以很长一段时间Ant用户都不得不手工管理依赖，这是一个令人头疼的问题。幸运的是，Ant用户现在可以借助Ivy管理依赖。而对于Maven用户来说，依赖管理是理所当然的，Maven不仅内置了依赖管理，更有一个可能拥有全世界最多Java开源软件包的中央仓库，Maven用户无须进行任何配置就可以直接享用。</p>
<h4 id="不重复发明轮子">不重复发明轮子</h4>
<p>【该小节内容整理自网友Arthas最早在Maven中文MSN的群内的讨论，在此表示感谢】
小张是一家小型民营软件公司的程序员，他所在的公司要开发一个新的Web项目。经过协商，决定使用Spring、iBatis和Tapstry。jar包去哪里找呢？公司里估计没有人能把Spring、iBatis和Tapstry所使用的jar包一个不少地找出来。大家的做法是，先到Spring的站点上去找一个spring.with.dependencies，然后去iBatis的网站上把所有列出来的jar包下载下来，对Tapstry、Apache
commons等执行同样的操作。项目还没有开始，WEB.INF/lib下已经有近百个jar包了，带版本号的、不带版本号的、有用的、没用的、相冲突的，怎一个“乱”字了得！</p>
<p>在项目开发过程中，小张不时地发现版本错误和版本冲突问题，他只能硬着头皮逐一解决。项目开发到一半，经理发现最终部署的应用的体积实在太大了，要求小张去掉一些没用的jar包，于是小张只能加班加点地一个个删……</p>
<p>小张隐隐地觉得这些依赖需要一个框架或者系统来进行管理。</p>
<p>小张喜欢学习流行的技术，前几年Ant十分流行，他学了，并成为了公司这方面的专家。小张知道，Ant打包，无非就是创建目录，复制文件，编译源代码，使用一堆任务，如copydir、fileset、classpath、ref、target，然后再jar、zip、war，打包就成功了。</p>
<p>项目经理发话了：“兄弟们，新项目来了，小张，你来写Ant脚本！”</p>
<p>“是，保证完成任务！”接着，小张继续创建一个新的XML文件。target clean;
target compile; target jar; ……
不知道他是否想过，在他写的这么多的Ant脚本中，有多少是重复劳动，有多少代码会在一个又一个项目中重现。既然都差不多，有些甚至完全相同，为什么每次都要重新编写？</p>
<p>终于有一天，小张意识到了这个问题，想复用Ant脚本，于是在开会时他说：“以后就都用我这个规范的Ant脚本吧，新的项目只要遵循我定义的目录结构就可以了。”经理听后觉得很有道理：“嗯，确实是个进步。”</p>
<p>这时新来的研究生发言了：“经理，用Maven吧，这个在开源社区很流行，比Ant更方便。”小张一听很惊讶，Maven真比自己的“规范化Ant”强大？其实他不知道自己只是在重新发明轮子，Maven已经有一大把现成的插件，全世界都在用，你自己不用写任何代码！</p>
<h2 id="maven的安装和配置">Maven的安装和配置</h2>
<p>前面介绍了Maven是什么，以及为什么要使用Maven，我们将从本章实际开始实际接触Maven。本章首先将介绍如何在主流的操作系统下安装Maven，并详细解释Maven的安装文件；其次还会介绍如何在主流的IDE中集成Maven，以及Maven安装的最佳实践。</p>
<h3 id="在windows上安装maven">在Windows上安装Maven</h3>
<h4 id="检查jdk安装">检查JDK安装</h4>
<p>在安装Maven之前，首先要确认你已经正确安装了JDK。Maven可以运行在JDK
1.4及以上的版本上。本书的所有样例都基于JDK
5及以上版本。打开Windows的命令行，运行如下的命令来检查你的Java安装：</p>
<pre><code>C:\Users\Juven Xu&gt;echo %JAVA_HOME%
C:\Users\Juven Xu&gt;java -version</code></pre>
<p>结果如下图所示：</p>
<p><img
src="https://wulc.me/imgs/e4f32577-29ad-35a7-b384-753eb4df2e37.jpg" /></p>
<p>上述命令首先检查环境变量JAVA_HOME是否指向了正确的JDK目录，接着尝试运行java命令。如果Windows无法执行java命令，或者无法找到JAVA_HOME环境变量。你就需要检查Java是否安装了，或者环境变量是否设置正确。关于环境变量的设置，请参考2.1.3节。</p>
<h4 id="下载maven">下载Maven</h4>
<p>请访问Maven的下载页面：http://maven.apache.org/download.html，其中包含针对不同平台的各种版本的Maven下载文件。对于首次接触Maven的读者来说，推荐使用Maven3.0，因此下载apache-maven-3.0-bin.zip。当然，如果你对Maven的源代码感兴趣并想自己构建Maven，还可以下载apache-maven-3.0
-src.zip。该下载页面还提供了md5校验和（checksum）文件和asc数字签名文件，可以用来检验Maven分发包的正确性和安全性。</p>
<p>在本书编写的时候，Maven 2的最新版本是2.2.1，Maven 3基本完全兼容Maven
2，而且较之于Maven
2它性能更好，还有不少功能的改进，如果你之前一直使用Maven
2，现在正犹豫是否要升级，那就大可不必担心了，快点尝试下Maven 3吧！</p>
<h4 id="本地安装">本地安装</h4>
<p>将安装文件解压到你指定的目录中，如：</p>
<pre><code>D:\bin&gt;jar xvf &quot;C:\Users\Juven Xu\Downloads\apache-maven-3.0--bin.zip&quot;</code></pre>
<p>这里的Maven安装目录是D:-maven-3.0，接着需要设置环境变量，将Maven安装配置到操作系统环境中。</p>
<p>打开系统属性面板（桌面上右键单击“我的电脑”→“属性”），点击高级系统设置，再点击环境变量，在系统变量中新建一个变量，变量名为M2_HOME，变量值为Maven的安装目录D:-maven-3.0。点击确定，接着在系统变量中找到一个名为Path的变量，在变量值的末尾加上%M2_HOME%;，注意多个值之间需要有分号隔开，然后点击确定。至此，环境变量设置完成</p>
<p>现在打开一个新的cmd窗口（这里强调新的窗口是因为新的环境变量配置需要新的cmd窗口才能生效），运行如下命令检查Maven的安装情况：</p>
<pre><code>C:\Users\Juven Xu&gt;echo %M2_HOME%
C:\Users\Juven Xu&gt;mvn -v</code></pre>
<p>第一条命令echo
%M2_HOME%用来检查环境变量M2_HOME是否指向了正确的Maven安装目录；而mvn
–version执行了第一条Maven命令，以检查Windows是否能够找到正确的mvn执行脚本。</p>
<h4 id="升级maven">升级Maven</h4>
<p>Maven还比较年轻，更新比较频繁，因此用户往往会需要更新Maven安装以获得更多更酷的新特性，以及避免一些旧的bug。</p>
<p><strong>在Windows上更新Maven非常简便，只需要下载新的Maven安装文件，解压至本地目录，然后更新M2_HOME环境变量便可。</strong>例如，假设Maven推出了新版本3.1，我们将其下载然后解压至目录D:-maven-3.1，接着遵照前一节描述的步骤编辑环境变量M2_HOME，更改其值为D:-maven-3.1。至此，更新就完成了。同理，如果你需要使用某一个旧版本的Maven，也只需要编辑M2_HOME环境变量指向旧版本的安装目录。</p>
<h3 id="在基于unix的系统上安装maven">在基于Unix的系统上安装Maven</h3>
<p>Maven是跨平台的，它可以在任何一种主流的操作系统上运行，本节将介绍如何在基于Unix的系统（包括Linux、Mac
OS以及FreeBSD等）上安装Maven。</p>
<h4 id="下载和安装">下载和安装</h4>
<p>首先，与在Windows上安装Maven一样，需要检查JAVA_HOME环境变量以及Java命令，细节不再赘述，命令如下：</p>
<pre><code>juven@juven-ubuntu:~$ echo $JAVA_HOME
juven@juven-ubuntu:~$ java –version</code></pre>
<p>接着到http://maven.apache.org/download.html
下载Maven安装文件，如apache-maven-3.0-bin.tar.gz，然后解压到本地目录：</p>
<pre><code>juven@juven-ubuntu:bin$ tar -xvzf apache-maven-3.0-bin.tar.gz</code></pre>
<p>现在已经创建好了一个Maven安装目录apache-maven-3.0，虽然直接使用该目录配置环境变量之后就能使用Maven了，但这里我更<strong>推荐做法是，在安装目录旁平行地创建一个符号链接，以方便日后的升级</strong>：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">juven@juven-ubuntu:bin$ <span class="built_in">ln</span> -s apache-maven-3.0 apache-maven</span><br><span class="line">juven@juven-ubuntu:bin$ <span class="built_in">ls</span> -l</span><br><span class="line">total 4</span><br><span class="line">lrwxrwxrwx 1 juven juven   18 2009-09-20 15:43 apache-maven -&gt; apache-maven-3.0</span><br><span class="line">drwxr-xr-x 6 juven juven 4096 2009-09-20 15:39 apache-maven-3.0</span><br></pre></td></tr></table></figure>
<p>接下来，我们需要设置M2_HOME环境变量指向符号链接apache-maven-，并且把Maven安装目录下的bin/文件夹添加到系统环境变量PATH中去：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">juven@juven-ubuntu:bin$ export M2_HOME=/home/juven/bin/apache-maven</span><br><span class="line">juven@juven-ubuntu:bin$ export PATH=$PATH:$M2_HOME/bin</span><br></pre></td></tr></table></figure>
一般来说，需要将这两行命令加入到系统的登录shell脚本中去，以我现在的Ubuntu
8.10为例，编辑~/.bashrc文件，添加这两行命令。这样，每次启动一个终端，这些配置就能自动执行。</p>
<p>至此，安装完成，我们可以运行以下命令检查Maven安装：</p>
<pre><code>juven@juven-ubuntu:bin$ echo $M2_HOME
juven@juven-ubuntu:bin$ mvn –version</code></pre>
<h4 id="升级maven-1">升级Maven</h4>
<p><strong>在基于Unix的系统上，可以利用符号链接这一工具来简化Maven的升级，不必像在Windows上那样，每次升级都必须更新环境变量。</strong></p>
<p>前一小节中我们提到，解压Maven安装包到本地之后，平行地创建一个符号链接，然后在配置环境变量时引用该符号链接，这样做是为了方便升级。现在，假设我们需要升级到新的Maven
3.1版本，同理，将安装包解压到与前一版本平行的目录下，然后更新符号链接指向3.1版的目录便可：</p>
<pre><code>juven@juven-ubuntu:bin$ rm apache-maven</code></pre>
<p>juven@juven-ubuntu:bin$ ln -s apache-maven-3.1/ apache-maven
juven@juven-ubuntu:bin$ ls -l total 8 lrwxrwxrwx 1 juven juven 17
2009-09-20 16:13 apache-maven -&gt; apache-maven-3.1 / drwxr-xr-x 6
juven juven 4096 2009-09-20 15:39 apache-maven-3.0drwxr-xr-x 2 juven
juven 4096 2009-09-20 16:09 apache-maven-3.1</p>
<p>同理，可以很方便地切换到Maven的任意一个版本。现在升级完成了，可以运行mvn
-v进行检查。</p>
<h3 id="安装目录分析">安装目录分析</h3>
<p>本章前面的内容讲述了如何在各种操作系统中安装和升级Maven。现在我们来仔细分析一下Maven的安装文件。</p>
<h4 id="m2_home">M2_HOME</h4>
<p>前面我们讲到设置M2_HOME环境变量指向Maven的安装目录，本书之后所有使用M2_HOME的地方都指代了该安装目录，让我们看一下该目录的结构和内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin</span><br><span class="line">boot</span><br><span class="line">conf</span><br><span class="line">lib</span><br><span class="line">LICENSE.txt</span><br><span class="line">NOTICE.txt</span><br><span class="line">README.txt</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>Bin</strong>：
该目录包含了mvn运行的脚本，这些脚本用来配置Java命令，准备好classpath和相关的Java系统属性，然后执行Java命令。其中mvn是基于UNIX平台的shell脚本，mvn.bat是基于Windows平台的bat脚本。在命令行输入任何一条mvn命令时，实际上就是在调用这些脚本。该目录还包含了mvnDebug和mvnDebug.bat两个文件，同样，前者是UNIX平台的shell脚本，后者是windows的bat脚本。那么mvn和mvnDebug有什么区别和关系呢？打开文件我们就可以看到，两者基本是一样的，只是mvnDebug多了一条MAVEN_DEBUG_OPTS配置，作用就是在运行Maven时开启debug，以便调试Maven本身。此外，该目录还包含m2.conf文件，这是classworlds的配置文件，稍微会介绍classworlds。</p></li>
<li><p><strong>Boot</strong>： 该目录只包含一个文件，以maven
3.0为例，该文件为plexus-classworlds-2.2.3.jar。plexus-classworlds是一个类加载器框架，相对于默认的java类加载器，它提供了更丰富的语法以方便配置，Maven使用该框架加载自己的类库。更多关于classworlds的信息请参考http://classworlds.codehaus.org/。对于一般的Maven用户来说，不必关心该文件。</p></li>
<li><p><strong>Conf</strong>：
该目录包含了一个非常重要的文件settings.xml。直接修改该文件，就能在机器上全局地定制Maven的行为。一般情况下，我们更偏向于复制该文件至<sub>/.m2/目录下（这里</sub>表示用户目录），然后修改该文件，在用户范围定制Maven的行为。本书的后面将会多次提到该settings.xml，并逐步分析其中的各个元素。</p></li>
<li><p><strong>Lib</strong>：
该目录包含了所有Maven运行时需要的Java类库，Maven本身是分模块开发的，因此用户能看到诸如mavn-core-3.0.jar、maven-model-3.0.jar之类的文件，此外这里还包含一些Maven用到的第三方依赖如common-cli-1.2.jar、google-collection-1.0.jar等等。（对于Maven
2来说，该目录只包含一个如maven-2.2.1-uber.jar的文件原本各为独立JAR文件的Maven模块和第三方类库都被拆解后重新合并到了这个JAR文件中）。可以说，这个lib目录就是真正的Maven。关于该文件，还有一点值得一提的是，用户可以在这个目录中找到Maven内置的超级POM，这一点在8.5小节详细解释。其他：
LICENSE.txt记录了Maven使用的软件许可证Apache License Version 2.0；
NOTICE.txt记录了Maven包含的第三方软件；而README.txt则包含了Maven的简要介绍，包括安装需求及如何安装的简要指令等等。</p></li>
</ul>
<h4 id="m2">~/.m2</h4>
<p>在讲述该小节之前，我们先运行一条简单的命令：mvn
help:system。该命令会打印出所有的Java系统属性和环境变量，这些信息对我们日常的编程工作很有帮助。这里暂不解释help:system涉及的语法，运行这条命令的目的是为了让Maven执行一个真正的任务。我们可以从命令行输出看到Maven会下载maven-help-plugin，包括pom文件和jar文件。这些文件都被下载到了Maven本地仓库中。</p>
<p>现在打开用户目录，比如当前的用户目录是C:Xu，你可以在Vista和Windows7中找到类似的用户目录。如果是更早版本的Windows，该目录应该类似于C:and
SettingsXu。在基于Unix的系统上，直接输入cd
回车，就可以转到用户目录。为了方便，本书统一使用符号 ~
指代用户目录。</p>
<p>在用户目录下，我们可以发现.m2文件夹。默认情况下，该文件夹下放置了Maven本地仓库.m2/repository。所有的Maven构件（artifact）都被存储到该仓库中，以方便重用。我们可以到~/.m2/repository/org/apache/maven/plugins/maven-help-plugins/目录下找到刚才下载的maven-help-plugin的pom文件和jar文件。Maven根据一套规则来确定任何一个构件在仓库中的位置，这一点本书第6章将会详细阐述。由于Maven仓库是通过简单文件系统透明地展示给Maven用户的，有些时候可以绕过Maven直接查看或修改仓库文件，在遇到疑难问题时，这往往十分有用。</p>
<p>默认情况下，<sub>/.m2目录下除了repository仓库之外就没有其他目录和文件了，不过大多数Maven用户需要复制M2_HOME/conf/settings.xml文件到</sub>/.m2/settings.xml。这是一条最佳实践，我们将在本章最后一小节详细解释。</p>
<h3 id="设置http代理">设置HTTP代理</h3>
<p>有时候你所在的公司由于安全因素考虑，要求你使用通过安全认证的代理访问因特网。这种情况下，就需要为Maven配置HTTP代理，才能让它正常访问外部仓库，以下载所需要的资源。</p>
<p>首先确认自己无法直接访问公共的Maven中央仓库，直接运行命令ping
repo1.maven.org可以检查网络。如果真的需要代理，先检查一下代理服务器是否畅通，比如现在有一个IP地址为218.14.227.197，端口为3128的代理服务，我们可以运行telnet
218.14.227.197
3128来检测该地址的该端口是否畅通。如果得到出错信息，需要先获取正确的代理服务信息；如果telnet连接正确，则输入ctrl+]，然后q，回车，退出即可。</p>
<p>检查完毕之后，编辑~/.m2/settings.xml文件（如果没有该文件，则复制$M2_HOME/conf/settings.xml）。添加代理配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;settings&gt;</span><br><span class="line">…  </span><br><span class="line">&lt;proxies&gt;</span><br><span class="line">    &lt;proxy&gt;</span><br><span class="line">      &lt;id&gt;my-proxy&lt;/id&gt;</span><br><span class="line">      &lt;active&gt;true&lt;/active&gt;</span><br><span class="line">      &lt;protocol&gt;http&lt;/protocol&gt;</span><br><span class="line">      &lt;host&gt;218.14.227.197&lt;/host&gt;</span><br><span class="line">      &lt;port&gt;3128&lt;/port&gt;</span><br><span class="line">      &lt;!--</span><br><span class="line">      &lt;username&gt;***&lt;/username&gt;</span><br><span class="line">      &lt;password&gt;***&lt;/password&gt;</span><br><span class="line">      &lt;nonProxyHosts&gt;repository.mycom.com|*.google.com&lt;/nonProxyHosts&gt;</span><br><span class="line">      --&gt;</span><br><span class="line">    &lt;/proxy&gt;</span><br><span class="line">  &lt;/proxies&gt;</span><br><span class="line">  …</span><br><span class="line">&lt;/settings&gt;</span><br></pre></td></tr></table></figure>
<p>这段配置十分简单，proxies下可以有多个proxy元素，如果你声明了多个proxy元素，则默认情况下第一个被激活的proxy会生效。这里声明了一个id为my-proxy的代理，active的值为true表示激活该代理，protocol表示使用的代理协议，这里是http。当然，最重要的是指定正确的主机名（host元素）和端口（port元素）。上述XML配置中我注释掉了username、password、nonProxyHost几个元素，当你的代理服务需要认证时，就需要配置username和password。nonProxyHost元素用来指定哪些主机名不需要代理，可以使用
|
符号来分隔多个主机名。此外，该配置也支持通配符，如*.google.com表示所有以google.com结尾的域名访问都不要通过代理。</p>
<h3 id="安装m2eclipse">安装m2eclipse</h3>
<p>Eclipse是一款非常优秀的IDE。除了基本的语法标亮、代码补齐、XML编辑等基本功能外，最新版的Eclipse还能很好地支持重构，并且集成了JUnit、CVS、Mylyn等各种流行工具。可惜Eclipse默认没有集成对Maven的支持。幸运的是，由Maven之父Jason
Van
Zyl创立的Sonatype公司建立了m2eclipse项目，这是Eclipse下的一款十分强大的Maven插件，可以访问http://m2eclipse.sonatype.org/
了解更多该项目的信息。</p>
<p>本小节将先介绍如何安装m2eclipse插件，本书后续的章节会逐步介绍m2eclipse插件的使用。</p>
<p>现在我以Eclipse
3.6为例逐步讲解m2eclipse的安装。启动Eclipse之后，在菜单栏中选择Help，然后选择Install
New Software…，接着你会看到一个Install对话框，点击Work
with:字段边上的Add按钮，你会得到一个新的Add
Repository对话框，在Name字段中输入m2e，Location字段中输入http://m2eclipse.sonatype.org/sites/m2e，然后点击OK。Eclipse会下载m2eclipse安装站点上的资源信息。等待资源载入完成之后，我们再将其全部展开，就能看到下图所示的界面：</p>
<p><img
src="https://wulc.me/imgs/1ae54751-ad82-3066-ba5a-e8818cfc504d.jpg" /></p>
<p>如图显示了m2eclipse的核心模块Maven Integration for Eclipse
(Required)，选择后点击Next
&gt;，Eclipse会自动计算模块间依赖，然后给出一个将被安装的模块列表，确认无误后，继续点击Next
&gt;，这时我们会看到许可证信息，m2eclipse使用的开源许可证是Eclipse
Public License v1.0，选择I accept the terms of the license
agreements，然后点击Finish，接着就耐心等待Eclipse下载安装这些模块，如下图所示：</p>
<p><img
src="https://wulc.me/imgs/d36bea18-262e-35e3-8a44-e3bac9ba225b.jpg" /></p>
<p>除了核心组件之外，m2eclipse还提供了一组额外组件，主要是为了方便与其它工具如Subversion进行集成，这些组件的安装地址为http://m2eclipse.sonatype.org/sites/m2e-extras。使用前面类似的安装方法，我们可以看到如下图的组件列表：</p>
<p><img
src="https://wulc.me/imgs/8c938c76-5859-33ea-aee2-b1f6e3a182ac.jpg" /></p>
<p>下面简单解释一下这些组件的用途：</p>
<p><strong>1.重要的</strong> Maven SCM handler for
Subclipse(Optional）：Subversion是非常流行的版本管理工具，该模块能够帮助我们直接从Subversion服务器签出Maven项目，不过前提是需要首先安装Subclipse（http://subclipse.tigris.org/）。
Maven SCM Integration
(Optional）：Eclipse环境中Maven与SCM集成核心的模块，它利用各种SCM工具如SVN实现Maven项目的签出和具体化等操作。</p>
<p><strong>2. 不重要的</strong> Maven issue tracking configurator for
Mylyn 3.x
(Optional）：该模块能够帮助我们使用POM中的缺陷跟踪系统信息连接Mylyn至服务器。
Maven SCM handler for Team/CVS
(Optional）：该模块帮助我们从CVS服务器签出Maven项目，如果你还在使用CVS，就需要安装它。
Maven Integration for WTP
(Optional）：使用该模块可以让Eclipse自动读取POM信息并配置WTP项目。、
M2eclipse Extensions Development Support
(Optional)：用来支持扩展m2eclipse，一般用户不会用到。 Project
configurators for commonly used maven plugins
(temporary)：一个临时的组件，用来支持一些Maven插件与Eclipse的集成，建议安装。
读者可以根据自己的需要安装相应组件，具体步骤不再赘述。</p>
<p>待安装完毕后，重启Eclipse，现在让我们验证一下m2eclipse是否正确安装了。首先，点击菜单栏中的Help，然后选择About
Eclipse，在弹出的对话框中，点击Installation
Details按钮，会得到一个对话框，在Installed
Software标签栏中，检查刚才我们选择的模块是否在这个列表中 <img
src="https://wulc.me/imgs/c6793b02-251d-3e1f-833c-8ff12d14ba05.jpg" />
如果一切没问题，我们再检查一下Eclipse现在是否已经支持创建Maven项目，依次点击菜单栏中的File→New→Other，在弹出的对话框中，找到Maven一项，再将其展开，你应该能够看到如下所示的对话框：</p>
<p><img
src="https://wulc.me/imgs/897a084a-6965-3d4a-b437-36c3a4ea5c09.jpg" /></p>
<p>如果一切正常，说明m2eclipse已经正确安装了。</p>
<p>最后，关于m2eclipse的安装，需要提醒的一点是，你可能会在使用m2eclipse时遇到类似这样的错误：</p>
<p>09-10-6 上午01时14分49秒: Eclipse is running in a JRE, but a JDK is
required Some Maven plugins may not work when importing projects or
updating source folders.</p>
<p>这是因为<strong>Eclipse默认是运行在JRE上的，而m2eclipse的一些功能要求使用JDK</strong>，解决方法是配置Eclipse安装目录的eclipse.ini文件，添加vm配置指向JDK，如：</p>
<pre><code>--launcher.XXMaxPermSize
256m
-vm
D:\java\jdk1.6.0_07\bin\javaw.exe
-vmargs
-Dosgi.requiredJavaVersion=1.5
-Xms128m
-Xmx256m</code></pre>
<h3 id="maven安装最佳实践">Maven安装最佳实践</h3>
<p>本节介绍一些在安装Maven过程中不是必须的，但十分有用的实践。</p>
<h4 id="设置maven_opts环境变量">设置MAVEN_OPTS环境变量</h4>
<p>本章前面介绍Maven安装目录时我们了解到，<strong>运行mvn命令实际上是执行了Java命令，既然是运行Java，那么运行Java命令可用的参数当然也应该在运行mvn命令时可用</strong>。这个时候，MAVEN_OPTS环境变量就能派上用场。</p>
<p>我们通常需要设置MAVEN_OPTS的值为：-Xms128m
-Xmx512m，因为<strong>Java默认的最大可用内存往往不能够满足Maven运行的需要，比如在项目较大时，使用Maven生成项目站点需要占用大量的内存，如果没有该配置，我们很容易得到java.lang.OutOfMemeoryError。</strong>因此，一开始就配置该变量是推荐的做法。</p>
<p>关于如何设置环境变量，请参考前面设置M2_HOME环境变量的做法，尽量不要直接修改mvn.bat或者mvn这两个Maven执行脚本文件。因为如果修改了脚本文件，升级Maven时你就不得不再次修改，一来麻烦，二来容易忘记。同理，我们应该尽可能地不去修改任何Maven安装目录下的文件。</p>
<h4 id="配置用户范围settings.xml">配置用户范围settings.xml</h4>
<p><strong>Maven用户可以选择配置$M2_HOME/conf/settings.xml或者~/.m2/settings.xml。前者是全局范围的，整台机器上的所有用户都会直接受到该配置的影响，而后者是用户范围的，只有当前用户才会受到该配置的影响。</strong></p>
<p>我们推荐使用用户范围的settings.xml，主要原因是为了避免无意识地影响到系统中的其他用户。当然，如果你有切实的需求，需要统一系统中所有用户的settings.xml配置，当然应该使用全局范围的settings.xml。</p>
<p>除了影响范围这一因素，配置用户范围settings.xml文件还便于Maven升级。直接修改conf目录下的settings.xml会导致Maven升级不便，每次升级到新版本的Maven，都需要复制settings.xml文件，如果使用~/.m2目录下的settings.xml，就不会影响到Maven安装文件，升级时就不需要触动settings.xml文件。</p>
<h4 id="不要使用ide内嵌的maven">不要使用IDE内嵌的Maven</h4>
<p>无论是Eclipse还是NetBeans，当我们集成Maven时，都会安装上一个内嵌的Maven，这个内嵌的Maven通常会比较新，但不一定很稳定，而且往往也会和我们在命令行使用的Maven不是同一个版本。这里有会出现两个潜在的问题：首先，较新版本的Maven存在很多不稳定因素，容易造成一些难以理解的问题；其次，除了IDE，我们也经常还会使用命令行的Maven，如果版本不一致，容易造成构建行为的不一致，这是我们所不希望看到的。因此，我们应该在IDE中配置Maven插件时使用与命令行一致的Maven。</p>
<p>在m2eclipse环境中，点击菜单栏中的Windows，然后选择Preferences，在弹出的对话框中，展开左边的Maven项，选择Installation子项，在右边的面板中，我们能够看到有一个默认的Embedded
Maven安装被选中了，点击Add…然后选择我们的Maven安装目录M2_HOME，添加完毕之后选择这一个外部的Maven，如下图所示：
<img
src="https://wulc.me/imgs/93cb4cf7-4027-397d-9e42-185acb6fc868.jpg" />
### 小结</p>
<p>本章详细介绍了在各种操作系统平台上安装Maven，并对Maven安装目录进行了深入的分析，在命令行的基础上，本章又进一步介绍了Maven与主流IDE
Eclipse及NetBeans的集成，本章最后还介绍了一些与Maven安装相关的最佳实践。本书下一章会创建一个Hello
World项目，带领读者配置和构建Maven项目。</p>
<h2 id="maven使用入门">Maven使用入门</h2>
<p>到目前为止，我们已经大概了解并安装好了Maven，现在，我们开始
创建一个最简单的Hello
World项目。如果你是初次接触Maven，我建议你按照本章的内容一步步地编写代码并执行，可能你会碰到一些概念暂时难以理解，不用着急，记下这些疑
难点，相信本书的后续章节会帮你逐一解答。</p>
<p><strong>就像Make的Makefile，Ant的build.xml一样，Maven项目的核心是pom.xml。POM（Project
Object
Model，项目对象模型）定义了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。</strong></p>
<h3 id="编写pom.xml文件">编写pom.xml文件</h3>
<p>现在我们先为Hello World项目编写一个最简单的pom.xml。</p>
<p>首先创建一个名为hello-world的文件夹（本书中各章的代码都会对应一个以ch开头的项目），打开该文件夹，新建一个名为pom.xml的文件，输入其内容如代码清单3-1：</p>
<p>代码清单3-1：Hello World的POM</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span>  </span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span>  </span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0  </span></span></span><br><span class="line"><span class="string"><span class="tag">http://maven.apache.org/maven-v4_0_0.xsd&quot;</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.juvenxu.mvnbook<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hello-world<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>Maven Hello World Project<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span>   </span><br></pre></td></tr></table></figure>
<p>代码的第一行是XML头，指定了该xml文档的版本和编码方式。紧接着是project元素，<strong>project是所有pom.xml的根元素</strong>，它还声明了一些POM相关的命名空间及xsd元素，虽然这些属性不是必须的，但使用这些属性能够让第三方工具（如IDE中的XML编辑器）帮助我们快速编辑POM。</p>
<p>根元素下的第一个子元素modelVersion指定了当前POM模型的版本，对于Maven2及Maven
3来说，它只能是4.0.0。</p>
<p>这段代码中<strong>最重要的是groupId，artifactId和version三行。这三个元素定义了一个项目基本的坐标，在Maven的世界，任何的jar、pom或者war都是以基于这些基本的坐标进行区分的。</strong></p>
<ul>
<li><p><strong>groupId定义了项目属于哪个组，这个组往往和项目所在的组织或公司存在关联</strong>，譬如你在googlecode上建立了一个名为myapp的项目，那么groupId就应该是com.googlecode.myapp，如果你的公司是mycom，有一个项目为myapp，那么groupId就应该是com.mycom.myapp。本书中所有的代码都基于groupId
com.juvenxu.mvnbook。</p></li>
<li><p><strong>artifactId定义了当前Maven项目在组中唯一的ID</strong>，我们为这个Hello
World项目定义artifactId为hello-world，本书其他章节代码会被分配其他的artifactId。而在前面的groupId为com.googlecode.myapp的例子中，你可能会为不同的子项目（模块）分配artifactId，如：myapp-util、myapp-domain、myapp-web等等。</p></li>
<li><p><strong>version指定了Hello
World项目当前的版本——1.0-SNAPSHOT</strong>。<em>SNAPSHOT意为快照，说明该项目还处于开发中，是不稳定的版本</em>。随着项目的发展，version会不断更新，如升级为1.0、1.1-SNAPSHOT、1.1、2.0等等。本书的6.5小节会详细介绍SNAPSHOT，第13章介绍如何使用Maven管理项目版本的升级发布。</p></li>
</ul>
<p>最后一个name元素声明了一个对于用户更为友好的项目名称，虽然这不是必须的，但我还是推荐为每个POM声明name，以方便信息交流。</p>
<p><strong>没有任何实际的Java代码，我们就能够定义一个Maven项目的POM，这体现了Maven的一大优点</strong>，它能让项目对象模型最大程度地与实际代码相独立，我们可以称之为解耦，或者正交性，这在很大程度上避免了Java代码和POM代码的相互影响。比如当项目需要升级版本时，只需要修改POM，而不需要更改Java代码；而在POM稳定之后，日常的Java代码开发工作基本不涉及POM的修改。</p>
<h3 id="编写主代码">编写主代码</h3>
<p><strong>项目主代码和测试代码不同，项目的主代码会被打包到最终的构件中（比如jar），而测试代码只在运行测试时用到，不会被打包。</strong>默认情况下，Maven假设项目主代码位于src/main/java目录，我们遵循Maven的约定，创建该目录，然后在该目录下创建文件com/juvenxu/mvnbook/helloworld/HelloWorld.java，其内容如代码清单3-2：</p>
<p>代码清单3-2：Hello World的主代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.juvenxu.mvnbook.helloworld;  </span><br><span class="line">   </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWorld</span>  </span><br><span class="line">&#123;  </span><br><span class="line">   <span class="keyword">public</span> String <span class="title function_">sayHello</span><span class="params">()</span>  </span><br><span class="line">   &#123;  </span><br><span class="line">     <span class="keyword">return</span> <span class="string">&quot;Hello Maven&quot;</span>;  </span><br><span class="line">   &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span></span><br><span class="line">  &#123;</span><br><span class="line">  System.out.print( <span class="keyword">new</span> <span class="title class_">HelloWorld</span>().sayHello());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p>这是一个简单的Java类，它有一个sayHello()方法，返回一个String。同时这个类还带有一个main方法，创建一个HelloWorld实例，调用sayHello()方法，并将结果输出到控制台。</p>
<p>关于该Java代码有两点需要注意。首先，在95%以上的情况下，我们<strong>应该把项目主代码放到src/main/java/目录下（遵循Maven的约定），而无须额外的配置，Maven会自动搜寻该目录找到项目主代码。</strong>其次，该Java类的包名是com.juvenxu.mvnbook.helloworld，这与我们之前在POM中定义的groupId和artifactId相吻合。<strong>一般来说，项目中Java类的包都应该基于项目的groupId和artifactId，这样更加清晰，更加符合逻辑，也方便搜索构件或者Java类。</strong></p>
<p>代码编写完毕后，我们使用Maven进行编译，在项目根目录下运行命令
<code>mvn clean compile</code>，我们会得到如下输出：</p>
<pre><code>[INFO] Scanning for projects...  
[INFO] ------------------------------------------------------------------------  
[INFO] Building Maven Hello World Project  
[INFO]    task-segment: [clean, compile]  
[INFO] ------------------------------------------------------------------------  
[INFO] [clean:clean &#123;execution: default-clean&#125;]  
[INFO] Deleting directory D:\code\hello-world\target  
[INFO] [resources:resources &#123;execution: default-resources&#125;]  
[INFO] skip non existing resourceDirectory D: \code\hello-world\src\main\resources  
[INFO] [compiler:compile &#123;execution: default-compile&#125;]  
[INFO] Compiling 1 source file to D: \code\hello-world\target\classes  
[INFO] ------------------------------------------------------------------------  
[INFO] BUILD SUCCESSFUL  
[INFO] ------------------------------------------------------------------------  
[INFO] Total time: 1 second  
[INFO] Finished at: Fri Oct 09 02:08:09 CST 2009  
[INFO] Final Memory: 9M/16M  
[INFO] ------------------------------------------------------------------------  </code></pre>
<p>clean告诉Maven清理输出目录target，compile告诉Maven编译项目主代码，从输出中我们看到Maven首先执行了clean:clean任务，删除target/目录，<strong>默认情况下Maven构建的所有输出都在target/目录中</strong>；接着执行resources:resources任务（未定义项目资源，暂且略过）；最后执行compiler:compile任务，将项目主代码编译至target/classes目录(编译好的类为com/juvenxu/mvnbook/helloworld/HelloWorld.Class）。</p>
<p>上文提到的clean:clean、resources:resources，以及compiler:compile对应了一些Maven插件及插件目标，比如clean:clean是clean插件的clean目标，compiler:compile是compiler插件的compile目标，后文会详细讲述Maven插件及其编写方法。</p>
<p>至此，Maven在没有任何额外的配置的情况下就执行了项目的清理和编译任务，接下来，我们编写一些单元测试代码并让Maven执行自动化测试。</p>
<h3 id="编写测试代码">编写测试代码</h3>
<p>为了使项目结构保持清晰，主代码与测试代码应该分别位于独立的目录中。3.2节讲过Maven项目中默认的主代码目录是src/main/java，对应地，Maven项目中默认的测试代码目录是src/test/java。因此，在编写测试用例之前，我们先创建该目录。</p>
<p>在Java世界中，由Kent Beck和Erich
Gamma建立的<strong>JUnit是事实上的单元测试标准。要使用JUnit，我们首先需要为Hello
World项目添加一个JUnit依赖</strong>，修改项目的POM如代码清单3-3：</p>
<p>代码清单3-3：为Hello World的POM添加依赖</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;  </span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  </span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  </span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0  </span><br><span class="line">http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;  </span><br><span class="line">  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  </span><br><span class="line">  &lt;groupId&gt;com.juvenxu.mvnbook&lt;/groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;hello-world&lt;/artifactId&gt;  </span><br><span class="line">  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  </span><br><span class="line">  &lt;name&gt;Maven Hello World Project&lt;/name&gt;  </span><br><span class="line">  &lt;dependencies&gt;  </span><br><span class="line">    &lt;dependency&gt;  </span><br><span class="line">       &lt;groupId&gt;junit&lt;/groupId&gt;  </span><br><span class="line">       &lt;artifactId&gt;junit&lt;/artifactId&gt;  </span><br><span class="line">       &lt;version&gt;4.7&lt;/version&gt;  </span><br><span class="line">       &lt;scope&gt;test&lt;/scope&gt;  </span><br><span class="line">    &lt;/dependency&gt;  </span><br><span class="line">  &lt;/dependencies&gt;  </span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure>
<p>代码中添加了dependencies元素，该元素下可以包含多个dependency元素以声明项目的依赖，这里我们添加了一个依赖——groupId是junit，artifactId是junit，version是4.7。前面我们提到groupId、artifactId和version是任何一个Maven项目最基本的坐标，JUnit也不例外，有了这段声明，Maven就能够自动下载junit-4.7.jar。也许你会问，Maven从哪里下载这个jar呢？<strong>在Maven之前，我们可以去JUnit的官网下载分发包。而现在有了Maven，它会自动访问中央仓库（http://repo1.maven.org/maven2/），下载需要的文件。</strong>读者也可以自己访问该仓库，打开路径junit/junit/4.7/，就能看到junit-4.7.pom和junit-4.7.jar。本书第6章会详细介绍Maven仓库及中央仓库。</p>
<p>上述POM代码中还有一个值为test的元素scope，scope为依赖范围，若依赖范围为test则表示该依赖只对测试有效，换句话说，测试代码中的import
JUnit代码是没有问题的，但是如果我们在主代码中用import
JUnit代码，就会造成编译错误。如果不声明依赖范围，那么默认值就是compile，表示该依赖对主代码和测试代码都有效。</p>
<p>配置了测试依赖，接着就可以编写测试类，回顾一下前面的HelloWorld类，现在我们要测试该类的sayHello()方法，检查其返回值是否为“Hello
Maven”。在src/test/java目录下创建文件，其内容如代码清单3-4：</p>
<p>代码清单3-4：Hello World的测试代码</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.juvenxu.mvnbook.helloworld;  </span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.assertEquals;  </span><br><span class="line"><span class="keyword">import</span> org.junit.Test;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWorldTest</span>  </span><br><span class="line">&#123;  </span><br><span class="line">    <span class="meta">@Test</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSayHello</span><span class="params">()</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="type">HelloWorld</span> <span class="variable">helloWorld</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HelloWorld</span>();  </span><br><span class="line">        <span class="type">String</span> <span class="variable">result</span> <span class="operator">=</span> helloWorld.sayHello();  </span><br><span class="line">        assertEquals( <span class="string">&quot;Hello Maven&quot;</span>, result );  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure>
<p><strong>一个典型的单元测试包含三个步骤： 1.准备测试类及数据；
2.执行要测试的行为； 3.检查结果。</strong></p>
<p>上述样例中，我们首先初始化了一个要测试的HelloWorld实例，接着执行该实例的sayHello()方法并保存结果到result变量中，最后使用JUnit框架的Assert类检查结果是否为我们期望的”Hello
Maven”。在JUnit
3中，约定所有需要执行测试的方法都以test开头，这里我们使用了JUnit
4，但我们仍然遵循这一约定，在JUnit
4中，需要执行的测试方法都应该以@Test进行标注。</p>
<p>测试用例编写完毕之后就可以调用Maven执行测试，运行
<code>mvn clean test</code> ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[INFO] Scanning for projects...  </span><br><span class="line">[INFO] ------------------------------------------------------------------------  </span><br><span class="line">[INFO] Building Maven Hello World Project  </span><br><span class="line">[INFO]    task-segment: [clean, test]  </span><br><span class="line">[INFO] ------------------------------------------------------------------------  </span><br><span class="line">[INFO] [clean:clean &#123;execution: default-clean&#125;]  </span><br><span class="line">[INFO] Deleting directory D:\git-juven\mvnbook\code\hello-world\target  </span><br><span class="line">[INFO] [resources:resources &#123;execution: default-resources&#125;]  </span><br><span class="line">…  </span><br><span class="line">Downloading: http://repo1.maven.org/maven2/junit/junit/4.7/junit-4.7.pom  </span><br><span class="line">1K downloaded  (junit-4.7.pom)  </span><br><span class="line">[INFO] [compiler:compile &#123;execution: default-compile&#125;]  </span><br><span class="line">[INFO] Compiling 1 source file to D: \code\hello-world\target\classes  </span><br><span class="line">[INFO] [resources:testResources &#123;execution: default-testResources&#125;]  </span><br><span class="line">…  </span><br><span class="line">Downloading: http://repo1.maven.org/maven2/junit/junit/4.7/junit-4.7.jar  </span><br><span class="line">226K downloaded  (junit-4.7.jar)  </span><br><span class="line">[INFO] [compiler:testCompile &#123;execution: default-testCompile&#125;]  </span><br><span class="line">[INFO] Compiling 1 source file to D:\ code\hello-world\target\test-classes  </span><br><span class="line">[INFO] ------------------------------------------------------------------------  </span><br><span class="line">[ERROR] BUILD FAILURE  </span><br><span class="line">[INFO] ------------------------------------------------------------------------  </span><br><span class="line">[INFO] Compilation failure  </span><br><span class="line">D:\code\hello-world\src\test\java\com\juvenxu\mvnbook\helloworld\HelloWorldTest.java:[8,5] -source 1.3 中不支持注释  </span><br><span class="line">（请使用 -source 5 或更高版本以启用注释）  </span><br><span class="line">    @Test  </span><br><span class="line">[INFO] ------------------------------------------------------------------------  </span><br><span class="line">[INFO] For more information, run Maven with the -e switch  </span><br><span class="line">  …  </span><br></pre></td></tr></table></figure>
<p>不幸的是构建失败了，不过我们先耐心分析一下这段输出（为了本书的简洁，一些不重要的信息我用省略号略去了）。命令行输入的是mvn
clean
test，而Maven实际执行的可不止这两个任务，还有clean:clean、resources:resources、compiler:compile、resources:testResources以及compiler:testCompile。暂时我们需要了解的是，在Maven执行测试（test）之前，它会先自动执行项目主资源处理，主代码编译，测试资源处理，测试代码编译等工作，这是Maven生命周期的一个特性，本书后续章节会详细解释Maven的生命周期。</p>
<p>从输出中我们还看到：Maven从中央仓库下载了junit-4.7.pom和junit-4.7.jar这两个文件到本地仓库（~/.m2/repository）中，供所有Maven项目使用。</p>
<p>构建在执行compiler:testCompile任务的时候失败了，Maven输出提示我们需要使用-source
5或更高版本以启动注释，也就是前面提到的JUnit
4的@Test注解。这是Maven初学者常常会遇到的一个问题。<strong>由于历史原因，Maven的核心插件之一compiler插件默认只支持编译Java
1.3，因此我们需要配置该插件使其支持Java 5</strong>，见代码清单3-5：</p>
<p>代码清单3-5：配置maven-compiler-plugin支持Java 5</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;project&gt;  </span><br><span class="line">…  </span><br><span class="line">  &lt;build&gt;  </span><br><span class="line">    &lt;plugins&gt;  </span><br><span class="line">       &lt;plugin&gt;  </span><br><span class="line">         &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  </span><br><span class="line">         &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;  </span><br><span class="line">         &lt;configuration&gt;  </span><br><span class="line">           &lt;source&gt;1.5&lt;/source&gt;  </span><br><span class="line">           &lt;target&gt;1.5&lt;/target&gt;  </span><br><span class="line">         &lt;/configuration&gt;  </span><br><span class="line">       &lt;/plugin&gt;  </span><br><span class="line">    &lt;/plugins&gt;  </span><br><span class="line">  &lt;/build&gt;  </span><br><span class="line">…  </span><br><span class="line">&lt;/project&gt;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>该POM省略了除插件配置以外的其他部分，我们暂且不去关心插件配置的细节，只需要知道compiler插件支持Java
5的编译。现在再执行mvn clean test，输出如下：</p>
<pre><code>[INFO] Compiling 1 source file to D: \code\hello-world\target\test-classes  
[INFO] [surefire:test &#123;execution: default-test&#125;]  
[INFO] Surefire report directory: D:\code\hello-world\target\surefire-reports  
 
 T E S T S  
 
Running com.juvenxu.mvnbook.helloworld.HelloWorldTest  
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 sec  
Results :  
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0  
[INFO] 
[INFO] BUILD SUCCESSFUL  
[INFO] </code></pre>
<p>我们看到compiler:testCompile任务执行成功了，测试代码通过编译之后在target/test-classes下生成了二进制文件，紧接着surefire:test任务运行测试，surefire是Maven世界中负责执行测试的插件，这里它运行测试用例HelloWorldTest，并且输出测试报告，显示一共运行了多少测试，失败了多少，出错了多少，跳过了多少。显然，我们的测试通过了——BUILD
SUCCESSFUL。</p>
<h3 id="打包和运行">打包和运行</h3>
<p>将项目进行编译、测试之后，下一个重要步骤就是打包（package）。Hello
World的POM中没有指定打包类型，使用默认打包类型jar，我们可以简单地执行命令
<code>mvn clean package</code> 进行打包，可以看到如下输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">…  </span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0  </span><br><span class="line">  </span><br><span class="line">[INFO] [jar:jar &#123;execution: default-jar&#125;]  </span><br><span class="line">[INFO] Building jar: D:\code\hello-world\target\hello-world-1.0-SNAPSHOT.jar  </span><br><span class="line">[INFO]   </span><br><span class="line"></span><br><span class="line">[INFO] BUILD SUCCESSFUL  </span><br><span class="line">…  </span><br></pre></td></tr></table></figure>
<p>类似地，Maven会在打包之前执行编译、测试等操作。这里我们看到jar:jar任务负责打包，实际上就是jar插件的jar目标将项目主代码打包成一个名为hello-world-1.0-SNAPSHOT.jar的文件，<strong>该文件也位于target/输出目录中，它是根据artifact-version.jar规则进行命名的</strong>，如有需要，我们还可以使用finalName来自定义该文件的名称，这里暂且不展开，本书后面会详细解释。</p>
<p>至此，我们得到了项目的输出，如果有需要的话，就可以复制这个jar文件到其他项目的Classpath中从而使用HelloWorld类。但是，<strong>如何才能让其他的Maven项目直接引用这个jar呢？</strong>我们还需要一个安装的步骤，执行
<code>mvn clean install</code>：</p>
<p>[INFO] [jar:jar {execution: default-jar}]<br />
[INFO] Building jar: D: -world-world-1.0-SNAPSHOT.jar<br />
[INFO] [install:install {execution: default-install}]<br />
[INFO] Installing D:-world-world-1.0-SNAPSHOT.jar to
C:.m2-world\1.0-SNAPSHOT-world-1.0-SNAPSHOT.jar<br />
[INFO]</p>
<p>[INFO] BUILD SUCCESSFUL</p>
<p>在打包之后，我们又执行了安装任务install:install，从输出我们看到该任务将项目输出的jar安装到了Maven本地仓库中，我们可以打开相应的文件夹看到Hello
World项目的pom和jar。之前讲述JUnit的POM及jar的下载的时候，我们说只有构件被下载到本地仓库后，才能由所有Maven项目使用，这里是同样的道理，只有将Hello
World的构件安装到本地仓库之后，其他Maven项目才能使用它。</p>
<p>我们已经将体验了Maven最主要的命令：<code>mvn clean compile</code>、<code>mvn clean test</code>、<code>mvn clean package</code>、<code>mvn clean install</code>。<strong>执行test之前是会先执行compile的，执行package之前是会先执行test的，而类似地，install之前会执行package</strong>。我们可以在任何一个Maven项目中执行这些命令，而且我们已经清楚它们是用来做什么的。</p>
<p>到目前为止，我们还没有运行Hello
World项目，不要忘了HelloWorld类可是有一个main方法的。默认打包生成的jar是不能够直接运行的，因为带有main方法的类信息不会添加到manifest中(我们可以打开jar文件中的META-INF/MANIFEST.MF文件，将无法看到Main-Class一行)。为了生成可执行的jar文件，我们需要借助maven-shade-plugin，配置该插件如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;plugin&gt;  </span><br><span class="line">&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  </span><br><span class="line">  &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;  </span><br><span class="line">  &lt;version&gt;1.2.1&lt;/version&gt;  </span><br><span class="line">  &lt;executions&gt;  </span><br><span class="line">    &lt;execution&gt;  </span><br><span class="line">      &lt;phase&gt;package&lt;/phase&gt;  </span><br><span class="line">      &lt;goals&gt;  </span><br><span class="line">        &lt;goal&gt;shade&lt;/goal&gt;  </span><br><span class="line">      &lt;/goals&gt;  </span><br><span class="line">      &lt;configuration&gt;  </span><br><span class="line">        &lt;transformers&gt;  </span><br><span class="line">          &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;            &lt;mainClass&gt;com.juvenxu.mvnbook.helloworld.HelloWorld&lt;/mainClass&gt;  </span><br><span class="line">         &lt;/transformer&gt;  </span><br><span class="line">       &lt;/transformers&gt;  </span><br><span class="line">     &lt;/configuration&gt;  </span><br><span class="line">     &lt;/execution&gt;  </span><br><span class="line">  &lt;/executions&gt;  </span><br><span class="line">&lt;/plugin&gt;  </span><br></pre></td></tr></table></figure>
<p>plugin元素在POM中的相对位置应该在<code>&lt;project&gt;&lt;build&gt;&lt;plugins&gt;</code>下面。我们配置了mainClass为com.juvenxu.mvnbook.helloworld.HelloWorld，项目在打包时会将该信息放到MANIFEST中。现在执行
mvn clean install
，待构建完成之后打开target/目录，我们可以看到hello-world-1.0-SNAPSHOT.jar和original-hello-world-1.0-SNAPSHOT.jar，前者是带有Main-Class信息的可运行jar，后者是原始的jar，打开hello-world-1.0-SNAPSHOT.jar的META-INF/MANIFEST.MF，可以看到它包含这样一行信息：</p>
<pre><code>Main-Class: com.juvenxu.mvnbook.helloworld.HelloWorld</code></pre>
<p>现在，我们在项目根目录中执行该jar文件：</p>
<pre><code>D: \code\hello-world&gt;java -jar target\hello-world-1.0-SNAPSHOT.jar
Hello Maven</code></pre>
<p>控制台输出为 Hello Maven，这正是我们所期望的。</p>
<p>本小节介绍了Hello
World项目，侧重点是Maven而非Java代码本身，介绍了POM、Maven项目结构、以及如何编译、测试、打包，等等。</p>
<h3 id="使用archetype生成项目骨架">使用Archetype生成项目骨架</h3>
<p>Hello
World项目中有一些Maven的约定：在项目的根目录中放置pom.xml，在src/main/java目录中放置项目的主代码，在src/test/java中放置项目的测试代码。我之所以一步一步地展示这些步骤，是为了能让可能是Maven初学者的你得到最实际的感受。我们称这些基本的目录结构和pom.xml文件内容称为项目的骨架，当你第一次创建项目骨架的时候，你还会饶有兴趣地去体会这些默认约定背后的思想，第二次，第三次，你也许还会满意自己的熟练程度，但第四、第五次做同样的事情，就会让程序员恼火了，为此<strong>Maven提供了Archetype以帮助我们快速勾勒出项目骨架。</strong></p>
<p>还是以Hello World为例，我们使用maven
archetype来创建该项目的骨架，离开当前的Maven项目目录。 如果是Maven
3，简单的运行：</p>
<pre><code>mvn archetype:generate</code></pre>
<p>如果是Maven 2，最好运行如下命令：</p>
<pre><code>mvn org.apache.maven.plugins:maven-archetype-plugin:2.0-alpha-5:generate</code></pre>
<p>很多资料会让你直接使用更为简单的 mvn archetype:generate
命令，但在Maven2中这是不安全的，因为该命令没有指定archetype插件的版本，于是Maven会自动去下载最新的版本，进而可能得到不稳定的SNAPSHOT版本，导致运行失败。然而在Maven
3中，即使用户没有指定版本，Maven也只会解析最新的稳定版本，因此这是安全的，具体内容见7.7小节。</p>
<p>我们实际上是在运行插件<strong>maven-archetype-plugin</strong>，注意冒号的分隔，其格式为
groupId:artifactId:version:goal ，org.apache.maven.plugins
是maven官方插件的groupId，maven-archetype-plugin
是archetype插件的artifactId，2.0-alpha-5
是目前该插件最新的稳定版，generate是我们要使用的插件目标。</p>
<p>紧接着我们会看到一段长长的输出，有很多可用的archetype供我们选择，包括著名的Appfuse项目的archetype，JPA项目的archetype等等。每一个archetype前面都会对应有一个编号，同时命令行会提示一个默认的编号，其对应的archetype为maven-archetype-quickstart，我们直接回车以选择该archetype，紧接着Maven会提示我们输入要创建项目的groupId、artifactId、
version、以及包名package，如下输入并确认：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Define value for groupId: : com.juvenxu.mvnbook  </span><br><span class="line">Define value for artifactId: : hello-world  </span><br><span class="line">Define value for version:  1.0-SNAPSHOT: :  </span><br><span class="line">Define value for package:  com.juvenxu.mvnbook: : com.juvenxu.mvnbook.helloworld  </span><br><span class="line">Confirm properties configuration:  </span><br><span class="line">groupId: com.juvenxu.mvnbook  </span><br><span class="line">artifactId: hello-world  </span><br><span class="line">version: 1.0-SNAPSHOT  </span><br><span class="line">package: com.juvenxu.mvnbook.helloworld  </span><br><span class="line"> Y: : Y  </span><br></pre></td></tr></table></figure>
<p>Archetype插件将根据我们提供的信息创建项目骨架。在当前目录下，Archetype插件会创建一个名为hello-world（我们定义的artifactId）的子目录，从中可以看到项目的基本结构：基本的pom.xml已经被创建，里面包含了必要的信息以及一个junit依赖；主代码目录src/main/java已经被创建，在该目录下还有一个Java类com.juvenxu.mvnbook.helloworld.App，注意这里使用到了我们刚才定义的包名，而这个类也仅仅只有一个简单的输出Hello
World!的main方法；测试代码目录src/test/java也被创建好了，并且包含了一个测试用例com.juvenxu.mvnbook.helloworld.AppTest。</p>
<p>Archetype可以帮助我们迅速地构建起项目的骨架，在前面的例子中，我们完全可以在Archetype生成的骨架的基础上开发Hello
World项目以节省我们大量时间。</p>
<p>此外，我们这里仅仅是看到了一个最简单的archetype，如果你有很多项目拥有类似的自定义项目结构以及配置文件，你完全可以一劳永逸地开发自己的archetype，然后在这些项目中使用自定义的archetype来快速生成项目骨架，本书后面的章节会详细阐述如何开发Maven
Archetype。</p>
<h3 id="m2eclipse简单使用">m2eclipse简单使用</h3>
<p>介绍前面Hello
World项目的时候，我们并没有涉及IDE，如此简单的一个项目，使用最简单的编辑器也能很快完成，但对于稍微大一些的项目来说，没有IDE就是不可想象的，本节我们先介绍m2eclipse的基本使用。</p>
<h4 id="导入maven项目">导入Maven项目</h4>
<p>第2章介绍了如何安装m2eclipse，现在，我们使用m2ecilpse导入Hello
World项目。选择菜单项File，然后选择Import，我们会看到一个Import对话框，在该对话框中选择General目录下的Maven
Projects，然后点击Next，就会出现Import
Projects对话框，在该对话框中点击Browse…选择Hello
World的根目录（即包含pom.xml文件的那个目录），这时对话框中的Projects:部分就会显示该目录包含的Maven项目，如下图所示：
<img
src="https://wulc.me/imgs/9a71aa9f-dc5e-32e1-8d0e-f71de55de5e9.jpg" /></p>
<p>点击Finish之后，m2ecilpse就会将该项目导入到当前的workspace中，导入完成之后，我们就可以在Package
Explorer视图中看到如下图的项目结构：</p>
<p><img
src="https://wulc.me/imgs/dc2c1bfc-ce95-3395-a5d7-16bdf5894101.jpg" /></p>
<p>我们看到主代码目录src/main/java和测试代码目录src/test/java成了Eclipse中的资源目录，包和类的结构也十分清晰，当然pom.xml永远在项目的根目录下，而从这个视图中我们甚至还能看到项目的依赖junit-4.7.jar，其实际的位置指向了Maven本地仓库（这里我自定义了Maven本地仓库地址为D:，后续章节会介绍如何自定义本地仓库位置）。</p>
<h4 id="创建maven项目">创建Maven项目</h4>
<p>创建一个Maven项目也十分简单，选择菜单项File -&gt; New -&gt;
Other，在弹出的对话框中选择Maven下的Maven Project，然后点击Next
&gt;，在弹出的New Maven
Project对话框中，我们使用默认的选项（不要选择Create a simple
project选项，那样我们就能使用Maven Archetype），点击Next
&gt;，此时m2eclipse会提示我们选择一个Archetype，我们选择maven-archetype-quickstart，再点击Next
&gt;。由于m2eclipse实际上是在使用maven-archetype-plugin插件创建项目，因此这个步骤与上一节我们使用archetype创建项目骨架类似，输入groupId,、artifactId、version、package（暂时我们不考虑Properties），如下图所示：
<img
src="https://wulc.me/imgs/bb255ca9-2341-37fb-aa9c-de619c2bf80a.jpg" />
注意，为了不和前面已导入的Hello
World项目产生冲突和混淆，我们使用不同的artifactId和package。OK，点击Finish，Maven项目就创建完成了，其结构与前一个已导入的Hello
World项目基本一致。</p>
<h4 id="运行mvn命令">运行mvn命令</h4>
<p>我们需要在命令行输入如mvn clean
install之类的命令来执行maven构建，m2eclipse中也有对应的功能，在Maven项目或者pom.xml上右击，再选择Run
As，就能看到如下的常见Maven命令，如下图所示： <img
src="https://wulc.me/imgs/09f3ec72-eb31-3f25-97af-545213fe4793.jpg" />
选择想要执行的Maven命令就能执行相应的构建，同时我们也能在Eclipse的console中看到构建输出。这里常见的一个问题是，默认选项中没有我们想要执行的Maven命令怎么办？比如，默认带有mvn
test，但我们想执行mvn clean test，很简单，选择Maven buid…
以自定义Maven运行命令，在弹出对话框中的Goals一项中输入我们想要执行的命令，如clean
test，设置一下Name，点击Run即可。并且，下一次我们选择Maven
build，或者使用快捷键Alt + Shift + X,
M快速执行Maven构建的时候，上次的配置直接就能在历史记录中找到。</p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Java</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>ROC 曲线与 PR 曲线</title>
    <url>/2018/06/16/ROC%20%E6%9B%B2%E7%BA%BF%E4%B8%8E%20PR%20%E6%9B%B2%E7%BA%BF/</url>
    <content><![CDATA[<p>ROC 曲线和 PR
曲线是评估机器学习算法性能的两条重要曲线，两者概念比较容易混淆，但是两者的使用场景是不同的。本文主要讲述两种曲线的含义以及应用的场景。</p>
<span id="more"></span>
<h2 id="定义">定义</h2>
<p>ROC 曲线和 PR 曲线都是用在二分类中，且涉及到下图的几个概念(摘自 <a
href="https://www.biostat.wisc.edu/~page/rocpr.pdf">The Relationship
Between Precision-Recall and ROC Curves</a>)</p>
<figure>
<img src="https://wulc.me/imgs/image_1cfpcf7brpr9i4k1h0aklg8vt9.png"
alt="roc vs pr" />
<figcaption aria-hidden="true">roc vs pr</figcaption>
</figure>
<p>上面四个指标用大白话解释如下</p>
<p><strong>Recall：查全率，正样本中被预测出来是正的比例(越大越好)
Precision：查准率，预测的正样本中被正确预测的比例(越大越好) True
Positive Rate：跟 Recall 定义一样 （越大越好) FPR :
负样本中被预测为正的比例(越小越好)</strong></p>
<p>对于一个二分类问题，往往要设定一个 threshold，当预测值大于这个
threshold 时预测为正样本，小于这个 threshold 时预测为负样本。如果以
Recall 为横轴，Precision 为纵轴，那么设定一个 threshold
时，便可在坐标轴上画出一个点，设定多个 threshold
则可以画出一条曲线，这条曲线便是 PR 曲线。</p>
<p><strong>PR 曲线是以 Recall 为横轴，Precision 为纵轴；而 ROC曲线则是以
FPR 为横轴，TPR 为纵轴。</strong></p>
<p>那么两者的关系是怎样的？</p>
<h2 id="对比">对比</h2>
<p><a href="https://www.biostat.wisc.edu/~page/rocpr.pdf">The
Relationship Between Precision-Recall and ROC Curves</a>
中证明了以下两条定理</p>
<p><strong>定理1</strong>：对于一个给定的的数据集，ROC空间和PR空间存在一一对应的关系，因为二者包含完全一致的混淆矩阵。我们可以将ROC曲线转化为PR曲线，反之亦然。</p>
<p><strong>定理2</strong>：对于一个给定数目的正负样本数据集，曲线 A 在
ROC 空间优于曲线 B ，当且仅当在 PR 空间中曲线 A 也优于曲线 B。</p>
<p>定理 2 中 “曲线A优于曲线B” 是指曲线 B 的所有部分与曲线 A 重合或在曲线
A
之下。<strong>而在ROC空间，ROC曲线越凸向左上方向效果越好。与ROC曲线左上凸不同的是，PR曲线是右上凸效果越好。</strong></p>
<p>从定理 2 来看，ROC 空间和 PR
空间两个指标似乎具有冗余性，那么为什么还需要这同时两个指标呢？答案是在<strong>两者在样本不均衡的情况下表现有较大差异</strong>。</p>
<p>下图是ROC曲线和Precision-Recall曲线的对比，摘自 <a
href="https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf">An
introduction to ROC analysis</a></p>
<figure>
<img src="https://wulc.me/imgs/ROC_PR.png" alt="ROC_PR.png-89.5kB" />
<figcaption aria-hidden="true">ROC_PR.png-89.5kB</figcaption>
</figure>
<p>图 (a) 和 (b) 是在样本正负比例为 1:1 下的 ROC 曲线和PR 曲线，图(c) 和
(d) 是在样本正负比例为 1:100 下的 ROC 曲线和PR 曲线。</p>
<p>从结果来看：<strong>当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。</strong></p>
<p>文章 <a
href="http://alexkong.net/2013/06/introduction-to-auc-and-roc/">ROC和AUC介绍以及如何计算AUC</a>
以及<a
href="https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf">An
introduction to ROC analysis</a>
中都认为这是个优点，原因是在实际的数据集中经常会出现类不平衡（class
imbalance）现象，即负样本比正样本多很多（或者相反），而 <strong>ROC
这种对不平衡样本的鲁棒性使得其曲线下的面积 AUC
不会发生突变</strong>。</p>
<p>那么，AUC 意味这什么？首先 <strong>AUC
值是一个概率值，表示随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率</strong>。</p>
<p>因此，AUC值实际上反映了模型的 rank
能力，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面。这个指标尤其适用在某些场景下(如
CTR 预估)，每次要返回的是最有可能点击的若干个广告(根据CTR排序,
选择排在前面的若干个)，实际上便是在考验模型的排序能力。除此之外，CTR
中存在着样本不均衡的问题，正负样本比例通常会大于 1:100，如果采用 PR
曲线，则会导致 AUC 发生剧变，无法较好反映模型效果。</p>
<p>然而，<strong>ROC
曲线不会随着类别分布的改变而改变的优点在一定程度上也是其缺点</strong>。因为
ROC 曲线这种不变性其实影响着的是 AUC
值，或者说是评估分类器的整体性能。但是在<strong>某些场景下，我们会更关注正样本，这时候就要用到
PR 曲线了。</strong></p>
<p>比如说信用卡欺诈检测，我们会更关注 precision 和
recall，比如说如果要求预测出为欺诈的人尽可能准确，那么就是要提高
precision；而如果要尽可能多地预测出潜在的欺诈人群，那么就是要提高
recall。一般来说，提高二分类的 threshold 就能提高 precision，降低
threshold 就能提高 recall，这时便可观察 PR 曲线，得到最优的
threshold。</p>
<p>除此之外，Quora 上的问题 <a
href="https://www.quora.com/What-is-the-difference-between-a-ROC-curve-and-a-precision-recall-curve-When-should-I-use-each">What
is the difference between a ROC curve and a precision-recall curve? When
should I use each?</a> 中也举了一下的例子说明了在欺诈检测的问题中，PR
曲线更能反映结果的变化。</p>
<blockquote>
<p>Let's take an example of fraud detection problem where there are 100
frauds out of 2 million samples.</p>
<p>Algorithm 1: 90 relevant out of 100 identified Algorithm 2: 90
relevant out of 1000 identified</p>
<p><strong>Evidently, algorithm 1 is more preferable because it
identified less number of false positive</strong>.</p>
<p>In the context of ROC curve, Algorithm 1: TPR=90/100=0.9, FPR=
10/1,999,900=0.00000500025 Algorithm 2: TPR=90/100=0.9,
FPR=910/1,999,900=0.00045502275 The FPR difference is 0.0004500225</p>
<p>For PR Curve Algorithm 1: precision=0.9, recall=0.9 Algorithm 2:
Precision=90/1000=0.09, recall= 0.9 Precision difference= 0.81</p>
<p><strong>The difference is more apparent in PR curve</strong></p>
</blockquote>
<h2 id="总结">总结</h2>
<p>综上，有以下几条结论（参考 <a
href="https://zhuanlan.zhihu.com/p/34655990">机器学习之类别不平衡问题
(2) —— ROC和PR曲线</a>）</p>
<ol type="1">
<li><p>ROC曲线由于兼顾正例与负例，所以适用于评估分类器的整体性能(通常是会计算AUC，表示模型的rank性能)，相比而言PR曲线完全聚焦于正例。</p></li>
<li><p>如果有<strong>多份数据且存在不同的类别分布</strong>。比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为类别分布改变可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合。</p></li>
<li><p>如果想要评估在<strong>相同的类别分布下正例的预测情况</strong>，则宜选PR曲线。类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。(参考上面
Quora 的例子)</p></li>
<li><p>最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1
score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。</p></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Segment Tree 简介</title>
    <url>/2016/08/05/Segment%20Tree%20%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h2 id="简介">简介</h2>
<p>本文主要通过实际例子介绍<code>segment tree</code>这种数据结构及其应用。以LeetCode上的一道题目
<a href="https://leetcode.com/problems/range-sum-query-mutable/">307.
Range Sum Query - Mutable</a> 为例说明。</p>
<span id="more"></span>
<p>这道题目<a
href="https://leetcode.com/problems/range-sum-query-mutable/">307. Range
Sum Query -
Mutable</a>要求求数组的区间和，但是有个额外条件，就是<strong>会进行多次数组区间求和以及数组元素的更新的操作。</strong></p>
<p>从正常的思路出发，每次求和的时间复杂度为<span
class="math inline">\(O(n)\)</span>， 更新数组元素的时间复杂度为<span
class="math inline">\(O(1)\)</span>, 因此总体的时间复杂度为 <span
class="math inline">\(O(n)\)</span>。而参考 <a
href="https://leetcode.com/problems/range-sum-query-immutable/">303.
Range Sum Query - Immutable</a> 可以实现求和的时间复杂度为<span
class="math inline">\(O(1)\)</span>, 但更新数组元素的时间复杂度为<span
class="math inline">\(O(n)\)</span>，所以总体的时间复杂度也是 <span
class="math inline">\(O(n)\)</span>。</p>
<p><strong>上面两种方法的总体时间复杂度均为<span
class="math inline">\(O(n)\)</span>, 但是通过我们下面要介绍的Segment
Tree，能够将求和以及更新数组元素操作的时间复杂度均变为</strong> <span
class="math inline">\(O(log_2n)\)</span>。</p>
<p>Segment
Tree是一棵二叉树，其特点为<strong>叶子节点个数与数组的长度相同
从左到右依次为数组中下标从小到大的元素的值，父节点的值为其左右的叶子节点的值的和</strong>。如下图是一个简单的例子</p>
<p><img
src="https://wulc.me/imgs/image_1aq9tfpv116lq1o751cb45a5cjkg.png" /></p>
<p>因此可以看到每个非叶子节点的值均是代表了数组某个区间的和。下面分别讲述如何构造这棵树，更新某个元素的值以及对特定区间求和。</p>
<h2 id="建树">建树</h2>
<p>虽然逻辑上是一棵二叉树，但是实际存储时可以通过数组来实现，通过父子节点的下标的数值关系可以访问父节点的子节点。然后需要求出数组的大小，<strong>因为这是一棵满二叉树（full
binary
tree，具体定义见下），而且数组下标必须是连续的，因此需要的最大空间</strong>为<span
class="math inline">\({\displaystyle \sum
_{k=0}^{m}2^k}\)</span>,其中m为二叉树的高度(从0开始计算，如上图的高度为3)。</p>
<p><img
src="https://wulc.me/imgs/image_1aq9ubbr119e88cf1coe1j9v172jt.png" /></p>
<p>具体实现则通过递归，每次记录当前的节点的下标以及表示的数组的范围，如下为建树的python代码,其中<code>seg_tree</code>为建立的segment
tree，<code>nums</code>为原数组，<code>curr</code> 为segmen
tree中当前节点的下标，<code>start、end</code> 为以 <code>curr</code>
包含的 <code>nums</code> 数组的下标范围。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_tree</span>(<span class="params">start, end, curr</span>):</span><br><span class="line">        <span class="keyword">if</span> start &gt; end: <span class="keyword">return</span> </span><br><span class="line">        <span class="keyword">if</span> start == end:</span><br><span class="line">            seg_tree[curr] = nums[start]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mid = start + (end - start)/<span class="number">2</span></span><br><span class="line">            seg_tree[curr] = build_tree(start, mid, curr*<span class="number">2</span>+<span class="number">1</span>) + build_tree(mid+<span class="number">1</span>, end, curr*<span class="number">2</span>+<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> seg_tree[curr]</span><br></pre></td></tr></table></figure>
<h2 id="更新元素">更新元素</h2>
<p>更新元素需要更新两个地方，一是原数组对应的下标的值，另外一个是包含了这个元素的segment
tree中的节点的值。具体也是通过递归实现，下面是更新segment
tree中所有包含原数组下标为 <code>idx</code>
的元素的节点的值的python代码，
diff是下标为<code>idx</code>的新值与旧值之差。可见时间复杂度为<span
class="math inline">\(O(log_2n)\)</span>,n为原数组元素的个数。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update_sum</span>(<span class="params"> start, end, idx, curr, diff</span>):</span><br><span class="line">        seg_tree[curr] += diff</span><br><span class="line">        <span class="keyword">if</span> start == end: <span class="keyword">return</span></span><br><span class="line">        mid = start + (end - start)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> start &lt;= idx &lt;= mid:</span><br><span class="line">            update_sum(start, mid, idx, curr*<span class="number">2</span>+<span class="number">1</span>, diff)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            update_sum(mid+<span class="number">1</span>, end, idx, curr*<span class="number">2</span>+<span class="number">2</span>, diff)</span><br></pre></td></tr></table></figure>
<h2 id="求区间和">求区间和</h2>
<p>求区间和也是通过递归实现，关键在于根据当前节点表示的范围以及需要求的区间的范围的关系进行求和。下面是实现的求区间<code>[qstart, qend]</code>的和的python代码。可见时间复杂度为<span
class="math inline">\(O(log_2n)\)</span>,n为原数组元素的个数。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_sum</span>(<span class="params">start, end, qstart, qend, curr</span>):</span><br><span class="line">        mid = start + (end - start)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> qstart &gt; end <span class="keyword">or</span> qend &lt; start:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> start &gt;= qstart <span class="keyword">and</span> end &lt;= qend:</span><br><span class="line">            <span class="keyword">return</span> seg_tree[curr]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> get_sum(start, mid, qstart, qend, curr*<span class="number">2</span>+<span class="number">1</span>) + get_sum(mid+<span class="number">1</span>, end, qstart, qend, curr*<span class="number">2</span>+<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="实际例子">实际例子</h2>
<p>下面结合上面讲述的三个步骤以及LeetCode上的题目<a
href="https://leetcode.com/problems/range-sum-query-mutable/">307. Range
Sum Query - Mutable</a> 给出完整的AC代码入下:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NumArray</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        initialize your data structure here.</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span>: <span class="keyword">return</span></span><br><span class="line">        max_size = <span class="number">2</span> * <span class="built_in">pow</span>(<span class="number">2</span>, <span class="built_in">int</span>(math.ceil(math.log(n, <span class="number">2</span>)))) - <span class="number">1</span></span><br><span class="line">        self.seg_tree = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(max_size)]</span><br><span class="line">        self.nums = nums[:]</span><br><span class="line">        self.build_tree(<span class="number">0</span>, n-<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_tree</span>(<span class="params">self, start, end, curr</span>):</span><br><span class="line">        <span class="keyword">if</span> start &gt; end: <span class="keyword">return</span> <span class="comment"># empty list</span></span><br><span class="line">        <span class="keyword">if</span> start == end:</span><br><span class="line">            self.seg_tree[curr] = self.nums[start]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mid = start + (end - start)/<span class="number">2</span></span><br><span class="line">            self.seg_tree[curr] = self.build_tree(start, mid, curr*<span class="number">2</span>+<span class="number">1</span>) + self.build_tree(mid+<span class="number">1</span>, end, curr*<span class="number">2</span>+<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> self.seg_tree[curr]        </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, i, val</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type i: int</span></span><br><span class="line"><span class="string">        :type val: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        diff = val - self.nums[i]</span><br><span class="line">        self.nums[i] = val</span><br><span class="line">        self.update_sum(<span class="number">0</span>, <span class="built_in">len</span>(self.nums)-<span class="number">1</span>, i, <span class="number">0</span>, diff)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_sum</span>(<span class="params">self, start, end, idx, curr, diff</span>):</span><br><span class="line">        self.seg_tree[curr] += diff</span><br><span class="line">        <span class="keyword">if</span> start == end: <span class="keyword">return</span></span><br><span class="line">        mid = start + (end - start)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> start &lt;= idx &lt;= mid:</span><br><span class="line">            self.update_sum(start, mid, idx, curr*<span class="number">2</span>+<span class="number">1</span>, diff)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.update_sum(mid+<span class="number">1</span>, end, idx, curr*<span class="number">2</span>+<span class="number">2</span>, diff)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumRange</span>(<span class="params">self, i, j</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        sum of elements nums[i..j], inclusive.</span></span><br><span class="line"><span class="string">        :type i: int</span></span><br><span class="line"><span class="string">        :type j: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.get_sum(<span class="number">0</span>, <span class="built_in">len</span>(self.nums)-<span class="number">1</span>, i, j, <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_sum</span>(<span class="params">self, start, end, qstart, qend, curr</span>):</span><br><span class="line">        mid = start + (end - start)/<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> qstart &gt; end <span class="keyword">or</span> qend &lt; start:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> start &gt;= qstart <span class="keyword">and</span> end &lt;= qend:</span><br><span class="line">            <span class="keyword">return</span> self.seg_tree[curr]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.get_sum(start, mid, qstart, qend, curr*<span class="number">2</span>+<span class="number">1</span>) + self.get_sum(mid+<span class="number">1</span>, end, qstart, qend, curr*<span class="number">2</span>+<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 集群部署和 Jupyter Notebook 配置注意事项</title>
    <url>/2017/09/13/Spark%20%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%92%8C%20Jupyter%20Notebook%20%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
    <content><![CDATA[<p>文章主要记录了 spark 2.1.0 集群部署注意事项以及如何通过 Jupyter
Notebook 访问 spark 集群。</p>
<span id="more"></span>
<h2 id="spark-集群安装注意事项">spark 集群安装注意事项</h2>
<p>安装过程主要参考了 spark 官方文档
https://spark.apache.org/docs/latest/spark-standalone.html</p>
<p>一些需要注意的事项如下</p>
<ul>
<li>每台机器需要先安装 Java，并配置环境变量 <code>JAVA_HOME</code> 和
<code>PATH</code></li>
<li>安装包解压到每台机器上，保持目录一致性，master 能够通过密钥 ssh
到其他 workers</li>
<li>修改 <code>/etc/hosts</code> 文件，保证每台主机能够通过主机名称 ping
通其他机器，注意，如果原来 <code>/etc/hosts</code> 文件中有类似于
<code>127.0.0.1 hostname</code> 的解释需要注释掉（因为会与前面设置
<code>ip hostname</code>冲突）</li>
<li>master 创建 <code>conf/slaves</code>,每行包含一个 worker 的
hostname</li>
<li>各个主机的 python
路径和版本要一致，在各台主机上的<code>conf/spark-env.sh</code>中定义如下
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PYSPARK_PYTHON=/opt/miniconda2/bin/python</span><br><span class="line">export PYSPARK_DRIVER_PYTHON=ipython</span><br></pre></td></tr></table></figure></li>
<li>通过 <code>sbin</code> 中的script <code>start-all.sh</code>
启动整个集群</li>
<li>默认情况下 worker(slave) 所有的 cores 都会使用，但是内存默认只会使用
1g(可通过 <code>http://SparkMaster:8080/</code>查看，SparkMaster 为
master 的ip)，如果需要修改可用的资源，需要修改
<code>conf/spark-defaults.conf</code> 文件，如下是设置了每个 worker 分配
4 个 core 和 6g 内存给 executor，同时设定了 driver program 使用的 core
的数量和内存大小。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.executor.cores            4</span><br><span class="line">spark.executor.memory           6g</span><br><span class="line">spark.driver.cores              4</span><br><span class="line">spark.driver.memory             6g</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>这里需要注意的是 <code>conf/spark-env.sh</code>
也有内存和cores相关的设定，但是设定的是可使用的最大值，并不是实际的使用值，设定实际的使用值必须要在文件
<code>conf/spark-defaults.conf</code> 中设置，且当
<code>conf/spark-defaults.conf</code> 设定值大于
<code>conf/spark-env.sh</code>
时，该项不生效，也就是实际的资源值会变为0。</strong></p>
<p>另外，spark
只是一个计算框架，并不提供存储的功能，往往需要结合其他的分布式数据库
HBase 或分布式文件系统 HDFS 等使用，
从中读取数据并进行将结果保存在其中。</p>
<h2 id="jupyter-notebook-配置">jupyter notebook 配置</h2>
<p><code>jupyter notebook</code> 的前身是
<code>ipython notebook</code>，网上的基本是通过 <code>ipython</code>
建立 profile 文件来解决，但是 <code>jupyter notebook</code> 已经不支持
profile 参数了，因此这种方法无效。</p>
<p>通过 <code>Apache Toree</code> 可以建立 <code>jupyter notebook</code>
使用的 kernel，从而将 kernel
连接到spark上，本来通过<code>pip install toree</code>可以简单地安装toree，但是由于使用
spark 的版本是 2.1.0, 其对应的Scala的版本是2.11, 这个版本的 Scala 与
toree 中的 2.10 的 Scala
版本不符。因此需要重新编译toree并安装，编译toree并安装可参考以下教程。</p>
<p>主要过程如下</p>
<p><strong>1.如果没有安装sbt，需要先安装sbt</strong> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;deb https://dl.bintray.com/sbt/debian /&quot; | sudo tee -a /etc/apt/sources.list.d/sbt.list</span><br><span class="line">sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 642AC823</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install sbt</span><br></pre></td></tr></table></figure></p>
<p><strong>2.下载并编译toree的源码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/apache/incubator-toree</span><br><span class="line">cd incubator-toree/</span><br></pre></td></tr></table></figure>
<p>编译前需要先修改 MakeFile 文件中的
<code>APACHE_SPARK_VERSION</code>、<code>SCALA_VERSION</code>为对应的版本。我这里使用spark
2.1.0，因此修改成如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">APACHE_SPARK_VERSION?=2.1.0</span><br><span class="line">SCALA_VERSION?=2.11</span><br></pre></td></tr></table></figure>
<p>然后执行 <code>make dist &amp;&amp; make release</code> 这时会报错
<code>/bin/sh: 1: docker: not found</code>,主要原因是没安装docker，可以忽略这个错误，因为docker主要作用是将安装文件打包在一起再通过pip安装，但是这些文件已经生成在
<code>dist</code>
目录下，可以直接安装，因此可以执行下面的命令进行安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd dist/toree-pip/</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>通过 toree 生成相应的 kernel 供jupyter notebook使用</li>
</ol>
<p>可以通过
<code>jupyter toree install --spark_home= path_to_spark-2.1.0 --interpreters=PySpark/SparkR/SQL/Scala</code>
安装对应的kernel，然后在web界面选择相应的kernel即可。</p>
<p>最后的问题，toree
默认使用的是单机模式，如果需要使用集群模式，需要通过环境变量设置提交时的参数，从这个脚本文件
<code>/usr/local/share/jupyter/kernels/apache_toree_pyspark/bin/run.sh</code>
可以看出提交任务时的参数通过 <code>SPART_OPTS</code>
获取，因此可以将这个换件变量的值设置为
<code>--master spark://ip:7077</code> 从而通过集群运行任务。</p>
<p>通过上面搭建的环境与 Spark 集群进行交互的一些 Jupyter Notebook
样例可参考 https://github.com/WuLC/MachineLearningWithSpark</p>
<hr />
<p>参考资料</p>
<p><a
href="https://medium.com/@faizanahemad/machine-learning-with-jupyter-using-scala-spark-and-python-the-setup-62d05b0c7f56">Machine
Learning with Jupyter using Scala, Spark and Python: The Setup</a> <a
href="https://gist.github.com/WuLC/1307d57d54b29941771e44876142ee67">Installing
Toree+Spark 2.1 on Ubuntu 16.04</a></p>
]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Supervisor的简介与使用</title>
    <url>/2016/08/23/Supervisor%E7%9A%84%E7%AE%80%E4%BB%8B%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p><a href="http://supervisord.org/introduction.html">Supervisor</a> 是
Linux
下一个进程管理的工具，主要的功能包括让<strong>程序自动启动、程序奔溃后自动重启，指定进程的数目等</strong>。本文主要讲述Supervisor在Linux下的安装与使用。</p>
<span id="more"></span>
<h2 id="安装">安装</h2>
<p>由于 Supervisor 是用 python 写的，因此推荐利用
<code>easy_install supervisor</code>或<code>pip install supervisor</code>
进行安装。除此之外，还可通过 Linux
的包管理命令进行安装（源中需要包含这个包），如 Centos 下可通过
<code>yum  install supervisor</code>进行安装，Ubuntu
下可以通过<code>apt install supervisor</code>安装。</p>
<h2 id="配置">配置</h2>
<p>Supervisor
的配置文件就只有一个，在安装完成后通过<code>echo_supervisord_conf &gt; /etc/supervisord.conf</code>
将创建一个默认的配置文件<code>/etc/supervisord.conf</code>,当然也可以指定配置文件在其他目录下。配置文件以<code>[]</code>来隔离每部分的配置内容，并且以<code>;</code>为注释符号。</p>
<p><strong>因为 Supervisor
由三部分组成：<code>supervisord</code>、<code>supervisorctl</code>、<code>inet_http_server</code>。因此配置文件也分别根据这三部分阐述。需要注意的是<code>supervisorctl</code>、<code>inet_http_server</code>并非是必须要配置的，这两个均是连接supervisord的客户端，用于观察和管理
supervisord 监控的程序。</strong></p>
<h3 id="supervisord">supervisord</h3>
<p><code>supervisord</code>
是Supervisor的核心，主要用与启动程序，在程序奔溃时自动重启，设定程序的进程数目、输出的日志文件路径等。</p>
<p><code>supervisored</code>
有多个参数，下面主要讲述其中几种较为重要的最简配置，每个参数的含义可参考<a
href="http://supervisord.org/configuration.html#supervisord-section-settings">官方文档</a>。</p>
<p>下面就是<code>supervisord</code>配置的一个简单例子 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[supervisord]</span><br><span class="line">logfile=/var/log/supervisor/supervisord.log ;日志文件的目录</span><br><span class="line">pidfile=/var/run/supervisord.pid ; pid文件目录</span><br><span class="line">; logfile_maxbytes = 50MB ;默认的日志文件的大小</span><br><span class="line">; loglevel = info ; 默认的日志的记录等级</span><br><span class="line">; umask = 002; 默认的进程umask</span><br><span class="line">; nodaemon = false ;默认在后台启动，若为true则在前台启动</span><br></pre></td></tr></table></figure>
上面注释掉的配置项为 <code>supervisord</code>
的默认配置项，可以不配置。</p>
<p>除了配置 <code>supervisord</code>
外，还需要配置被其管理的程序。详细的参数可见<a
href="http://supervisord.org/configuration.html#program-x-section-settings">官方文档</a>，下面是一个简单的例子
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[program:robot] ; 标示一个程序[program:XXX],XXX为自定义的程序名称</span><br><span class="line">command = /usr/bin/xvfb-run python /home/amazon/v0/Robot.py;运行程序所需命令</span><br><span class="line">;autostart=true ;默认跟随supervisord启动而启动</span><br><span class="line">autorestart=true ;程序退出后自动重启</span><br><span class="line">; startretries = 3; 程序出错时，连续重启的最大次数，超过该次数后，进程进入FATAL转态</span><br><span class="line">; startsecs = 1; 程序启动后多少秒内认为其启动成功</span><br><span class="line">; numprocs = 1  ;启动的进程数目，默认为1</span><br><span class="line">; priority = 999 ; 程序的优先级，默认为999，该值越小，表示优先级越高</span><br><span class="line">user=root ;程序启动的用户，只用root用户才能指定这一项；不指定时该值为启动supervisord的用户</span><br><span class="line">stdout_logfile = /home/amazon/log/Robot.log ;存储程序标准输出流的文本文件</span><br><span class="line">stderr_logfile = /home/amazon/log/Robot_err.log ; 存储程序出错时错误提示的文件</span><br><span class="line">; stopasgroup = false;以进程组的方式停止进程，默认为false，以上面为例，假如为false时，停止该程序时只会停止 python运行的程序，而不会停止 xvfb 程序</span><br></pre></td></tr></table></figure>
上面注释的配置项为程序默认的配置，可以不配置。上面给出的<code>supervisord</code>和<code>program</code>为最简配置，仅配置这两项就可以运行supervisor。运行方式为
<code>supervisord -c /etc/supervisord.conf</code>,
<code>-c</code>参数指定了配置文件的路径，不指定该参数时会以一定的路径顺序寻找配置文件，并且会抛出warning，因此建议启动时要带有此参数。</p>
<p>上面的配置虽然能启动这些程序，但是当supervisord管理多个程序时，需要关闭或开启其中的一个程序就必须关闭supervisord，然后修改配置文件并重启。为了单独管理这些程序，并直观看到每个程序的运行状态，就需要配置下面的<code>supervisorctl</code>和<code>inet_http_server</code>。</p>
<h3 id="inet_http_server">inet_http_server</h3>
<p><code>inet_http_server</code>是supervisord
内置的一个http浏览器，用于查看、管理每个程序的运行状态，配置项如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[inet_http_server]</span><br><span class="line">port = 110.64.55.128:9001</span><br><span class="line">username = XXXX</span><br><span class="line">password = XXXX</span><br></pre></td></tr></table></figure>
<p>上面的配置应该比较容易理解，访问<code>port</code>后输入用户名和密码验证身份后即可观察到程序运行的状态，下图为访问时观察到的效果。</p>
<p><img
src="https://wulc.me/imgs/image_1ar80vgub7ge1tr41st9sor6l213.png" /></p>
<p>上图可以看到每个程序的运行状态，pid以及运行时长，还可以改变程序的运行状态。</p>
<h3 id="supervisorctl">supervisorctl</h3>
<p><code>supervisorctl</code>的功能与<code>inet_http_server</code>一样，只是<code>inet_http_server</code>是有界面的，而<code>supervisorctl</code>是在命令行下使用的，配置项如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[supervisorctl]</span><br><span class="line">serverurl = http://110.64.55.128:9001 ;http服务器的地址</span><br><span class="line">username = XXXX ;与 [inet_http_server] 配置项的username相同</span><br><span class="line">password = XXXX ;与 [inet_http_server] 配置项的password相同</span><br></pre></td></tr></table></figure>
<p>通过
<code>supervisorctl</code>即可观察到程序运行的状态，如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1ar80udog1img0316rm8ig1i94m.png" /></p>
<p>同时可以通过
<code>supervisorctl start|stop|restrt XXX</code>来启动、停止、重启程序XXX，其中XXX为配置<code>[program:XXX]</code>指定的名称。</p>
<p>下面是综合以上所说的完整的<code>supervisord.conf</code>配置文件
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[supervisord]</span><br><span class="line">logfile=/var/log/supervisor/supervisord.log  </span><br><span class="line">pidfile=/var/run/supervisord.pid  </span><br><span class="line"></span><br><span class="line">[program:robot] </span><br><span class="line">command = /usr/bin/xvfb-run python /home/amazon/v0/Robot.py</span><br><span class="line">autorestart=true </span><br><span class="line">stdout_logfile = /home/amazon/log/Robot.log </span><br><span class="line">stderr_logfile = /home/amazon/log/Robot_err.log </span><br><span class="line"></span><br><span class="line">[inet_http_server]</span><br><span class="line">port = 110.64.55.128:9001</span><br><span class="line">username = XXXX</span><br><span class="line">password = XXXX</span><br><span class="line"></span><br><span class="line">[supervisorctl]</span><br><span class="line">serverurl = http://110.64.55.128:9001 </span><br><span class="line">username = XXXX </span><br><span class="line">password = XXXX </span><br></pre></td></tr></table></figure></p>
<p>从上面可知，既然<code>supervisorctl</code>提供的功能和<code>inet_http_server</code>的相同，那么是否可以不启动http服务器，仅仅通过<code>supervisorctl</code>进行观察呢?</p>
<p>答案是可以的，但是要通过 unix socket 与 supervisord
通信，将上面的<code>[inet_http_server]</code>部分改成<code>[unix_http_server]</code>，并修改<code>[supervisorctl]</code>的<code>serverurl</code>部分，完整的配置文件如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[supervisord]</span><br><span class="line">logfile=/var/log/supervisor/supervisord.log  </span><br><span class="line">pidfile=/var/run/supervisord.pid  </span><br><span class="line"></span><br><span class="line">[program:robot] </span><br><span class="line">command = /usr/bin/xvfb-run python /home/amazon/v0/Robot.py</span><br><span class="line">autorestart=true </span><br><span class="line">stdout_logfile = /home/amazon/log/Robot.log </span><br><span class="line">stderr_logfile = /home/amazon/log/Robot_err.log </span><br><span class="line"></span><br><span class="line">[unix_http_server]</span><br><span class="line">file=/var/run/supervisor.sock   ; (the path to the socket file)</span><br><span class="line">username = XXXX</span><br><span class="line">password = XXXX</span><br><span class="line"></span><br><span class="line">[supervisorctl]</span><br><span class="line">serverurl = unix:///var/run/supervisor.sock</span><br><span class="line">username = XXXX </span><br><span class="line">password = XXXX </span><br></pre></td></tr></table></figure>
<h2 id="使用">使用</h2>
<p>综上，supervisor的一般的使用方法为如下：</p>
<p>1）配置好需要启动的程序
2）通过<code>supervisord -c /etc/supervisord.conf</code>启动supervisord
3）通过<code>supervicorctl</code>和日志文件查看每个程序状态，通过<code>supervicorctl start|stop|restart XXX</code>在不影响其他程序的情况下改变某个程序的运行状态。</p>
<p>更详细的内容请参考<a
href="http://supervisord.org/introduction.html">官方文档</a></p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>Wand 算法介绍与实现</title>
    <url>/2018/03/18/Wand%20%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>本文主要介绍 Wand(Weak And) 算法的原理和实现, Wand
算法是一个搜索算法，应用在 query 有多个关键词或标签，同时每个document
也有多个关键词或标签的情形（如搜索引擎）；尤其是在 query
中的关键词或标签较多的时候，通过 Wand 能够快速的选择出 Top n 个相关的
document，算法的原始论文见 <a
href="http://7viirv.com1.z0.glb.clouddn.com/4331f68fcd_wand.pdf">Efficient
Query Evaluation using a Two-Level Retrieval
Process</a>，本文主要讲述这个算法的原理以及通过 python
实现这个算法。</p>
<span id="more"></span>
<p>一般来说，检索往往会利用倒排索引，倒排索引能够根据 query
中的关键词快速检索到候选文档，然而当候选文档集合较大时，遍历整个候选文档所需要的时间也很大。</p>
<p>但是检索需要得到的往往只是 Top n
个结果，在遍历候选文档过程中能否跳过一些与 query
相关性较低的文档，从而加速检索的过程呢？Wand 算法就是干这个事的。</p>
<h2 id="wand-原理介绍">Wand 原理介绍</h2>
<p><strong>Wand
算法通过计算每个词的贡献上限来估计文档的相关性上限，并与预设的阈值比较，进而跳过一些相关性一定达不到要求的文档，从而得到提速的效果。</strong></p>
<p>上面这句话涵盖了Wand 算法的思想，下面进行详细说明：</p>
<p>Wand 算法首先要估计<strong>每个词对相关性贡献的上限（upper
bound）</strong>，最简单的相关性就是
TF-IDF，一般IDF是固定的，因此只需要估计一个词在各个文档中的词频TF上限(即这个词在各个文档中最大的TF)，该步骤通过线下计算即可完成。</p>
<p>线下计算出各个词的相关性上限，可以计算出<strong>一个 query
和一个文档的相关性上限值</strong>，就是他们共同出现的词的相关性上限值的和，通过与预设的阈值比较，如果query
与文档的相关性大于阈值，则进行下一步的计算，否则丢弃。</p>
<p>在上面过程中，如果还是将 query
和一个一个文档分别计算相关性，并没有减少时间复杂度， Wand
算法通过一种巧妙的方式使用倒排索引，从而能够跳过一些相关性肯定达不到要求的文档。</p>
<p>Wand 算法步骤如下</p>
<ol type="1">
<li>建立倒排索引，记录每个单词所在的所有文档ID(DID)，ID
按照从小到大排序</li>
<li>初始化 posting 数组，使得 posting[pTerm] 为词 pTerm
倒排索引中第一个文档的 index</li>
<li>初始化 curDoc = 0（文档ID从1开始）</li>
</ol>
<p>接着可以执行下面的 next 函数(摘自原始论文),</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8smp7961m9shgd1oqpnvgngp9.png"
alt="next function" />
<figcaption aria-hidden="true">next function</figcaption>
</figure>
<p>上面流程中用到的几个函数的含义如下</p>
<p><strong>1. sort(terms, posting)</strong>：根据 posting
数组指向的当前文档 ID，对所有的 terms 从小到大排序。如下是三个 term
及其对应的索引文档的 ID，此时的 posting 数组为 <code>[1, 0, 1]</code>,
则根据各个 term 当前文档 ID 排序的结果应该是 t1, t2, t3</p>
<p>t0: [3, <strong>26</strong>] t1: [<strong>4</strong>, 10, 100] t2:
[2, <strong>5</strong>, 56]</p>
<p><strong>2. findPivotTerm(terms,
θ)</strong>：按照之前得到的排序，从第一个 term 开始累加各个 term
的相关性贡献的上限（upper
bound，UB），这个在之前已经通过离线计算出来；直到累加和大于等于设定的阈值
θ, 返回当前的 term。这里应用<a
href="http://www.cnblogs.com/daremen/p/3289694.html">这篇文章</a>的一个例子，下面为通过
sort(terms, posting) 后的倒排索引，假设阈值 θ = 8</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8spjme31hqsbd81h88b3d6ob13.png"
alt="pivot term" />
<figcaption aria-hidden="true">pivot term</figcaption>
</figure>
<p>对于doc 2，其可能的最大得分为2&lt;8<br />
对于doc 4，其可能的最大得分为2+1=3&lt;8<br />
对于doc 5，其可能的最大得分为2+1+4=7&lt;8<br />
对于doc 23，其可能的最大得分为2+1+4+3=10&gt;8 因此，t3 为pivotTerm，doc
23 为pivot</p>
<p><strong>3.
pickTerm(terms[0..pTerm])</strong>：在0到pTerm(不包含pTerm)中选择一个term，关于选择策略，当然是以<strong>可以跳过最多的文档</strong>为原则，论文中选择了
IDF 最大的term。以上面的图为例子，此时可以选择 t2, t1 或 t4, 根据其 IDF
值选择最大的 term 即可</p>
<p><strong>4. aterm.iterator.next(n)</strong>：返回 aterm
这个单词对应的倒排索引中的文档ID(DID)，这个DID要满足DID &gt;= n。则
<code>posting[aterm] ← aterm.iterator.next(n)</code> 其实就是更新了
aterm 在 posting 数组中的当前文档，从而跳过 aterm
对应的索引中一些不必要计算的文档。</p>
<p>还是以上面的图为例子，假如选择的 aterm 为 t2, 则 t2 中指向 2
的指针要往后移动直至 DID &gt;= 23 ,这样便跳过了部分不必计算文档。</p>
<p><strong>实际上，t1, t4 也可以执行上面这个操作，因为在 doc 23 之前的
doc 的得分不可能达到阈值 θ(因为 DID 是经过排序的) ，所以t2、t1、t4对应的
posting
数组中的项都可以直接跳到大于等于doc23的位置，但是论文中每次只选择一个
term ，虽然多迭代几次也能达到同样效果，但是我认为这里可以三个 Term
可以一起跳。</strong></p>
<p>介绍了上面过程中几个重要函数，下面来看一下上面的几个分支分别表示情况</p>
<ol type="1">
<li><code>if (pTerm = null) return (NoMoreDocs)</code>表示当前所有 term
的 upper bound 和达不到阈值 θ ，结束算法</li>
<li><code>if (pivot = lastID) return (NoMoreDocs)</code>
表示当前已经没有满足相关性大于阈值 θ 的文档，结束算法</li>
<li><code>if (pivot ≤ curDoc)</code> 表示当前 pivot 指向的 DID
已经计算过相关性，需要跳过，这部分代码会在下面第4步执行后在进入循环时执行</li>
<li><code>if (posting[0].DID = pivot)</code> 表示当前 pivot
对应的文档的相关性有可能满足大于阈值 θ ，返回这篇文档的 ID
并计算这篇文档和 query
的相关性；<strong><code>posting[0].DID = pivot</code>
表示从第一个term到当前的term所指向的文档都是同一篇</strong></li>
<li><code>if (posting[0].DID = pivot) 对应的else语句</code>
表示前面遍历过的那些 term 的当前 DID 都不可能满足大于阈值
θ，因此需要跳过，也正是这里大大减少了需要计算相关性的文档数量</li>
</ol>
<h2 id="wand-的实现代码">Wand 的实现代码</h2>
<p>实现 Wand 算法的 Python 代码见<a
href="https://github.com/WuLC/CodeSnippets/blob/master/Wand.py">这里</a>，参考<a
href="http://www.cnblogs.com/daremen/p/3289694.html">这篇文章</a>的代码进行了修改，并增加了评估文档和query相似性的函数，代码中有以下几点需要注意</p>
<ol type="1">
<li>当一个 term 对应的所有 document
遍历完后，有两种处理方法。第一种方法是直接删除，这样会降低每次排序的时间复杂度和内存占用率，但是每次删除时候是要在一个有序列表内删除，时间复杂度为
<span class="math inline">\(O(n)\)</span>, <span
class="math inline">\(n\)</span> 为 terms 的个数；第二种方法是在每个
term 的 document list
最后增加一个比所有文档ID都要大的数(LastID)，这样被遍历完的term会自然被排序到最后，整个代码更加简洁。两种方法都尝试了一下，详细代码可见上面的代码连接的提交历史</li>
<li><code>pickTerm</code> 方法原论文采用的是选择 idf
最大值的term，这里直接选择第一个，因为代码仅用于阐述算法的流程，各个
term 没有 idf 值。当然，如果有各个 term 的 idf 值，是可以根据 idf
选择的</li>
<li>上面伪代码的算法流程中最后的 else 语句是选择 pivotTerm
中的任意一个并跳过相关性低的文档，但是从前面的解释可知，可以 pivotTerm
前面的所有 term 都可进行这一操作，因此代码里面的这部分跟伪代码不同</li>
</ol>
<p>这里还是给出完整代码，可以对照着上面的伪代码看，命名方法基本都保持了一致，如有错漏，欢迎指出</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line">UB = &#123;<span class="string">&quot;t0&quot;</span>:<span class="number">0.5</span>,<span class="string">&quot;t1&quot;</span>:<span class="number">1</span>,<span class="string">&quot;t2&quot;</span>:<span class="number">2</span>,<span class="string">&quot;t3&quot;</span>:<span class="number">3</span>,<span class="string">&quot;t4&quot;</span>:<span class="number">4</span>&#125; <span class="comment">#upper bound of term&#x27;s value</span></span><br><span class="line">LAST_ID = <span class="number">999999999999</span> <span class="comment"># a large number, larger than all the doc id in the inverted index</span></span><br><span class="line">THETA = <span class="number">2</span> <span class="comment"># theta, threshold for chechking whether to calculate the relevence between query and doc</span></span><br><span class="line">TOPN = <span class="number">3</span> <span class="comment">#max result number </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WAND</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, InvertIndex</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;init inverted index and necessary variable&quot;&quot;&quot;</span></span><br><span class="line">        self.result_list = [] <span class="comment">#result list</span></span><br><span class="line">        self.inverted_index = InvertIndex <span class="comment">#InvertIndex: term -&gt; docid1, docid2, docid3 ...</span></span><br><span class="line">        self.current_doc = <span class="number">0</span></span><br><span class="line">        self.current_inverted_index = &#123;&#125; <span class="comment">#posting</span></span><br><span class="line">        self.query_terms = []</span><br><span class="line">        self.sort_terms = []</span><br><span class="line">        self.threshold = THETA</span><br><span class="line">        self.last_id = LAST_ID</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init_query</span>(<span class="params">self, query_terms</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;init variable with query&quot;&quot;&quot;</span></span><br><span class="line">        self.current_doc = <span class="number">0</span></span><br><span class="line">        self.current_inverted_index = &#123;&#125;</span><br><span class="line">        self.query_terms = []</span><br><span class="line">        self.sort_terms = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> term <span class="keyword">in</span> query_terms:</span><br><span class="line">            <span class="keyword">if</span> term <span class="keyword">in</span> self.inverted_index:  <span class="comment"># terms may not appear in inverted_index</span></span><br><span class="line">                doc_id = self.inverted_index[term][<span class="number">0</span>]</span><br><span class="line">                self.query_terms.append(term)</span><br><span class="line">                self.current_inverted_index[term] = [doc_id, <span class="number">0</span>] <span class="comment">#[ docid, index ]</span></span><br><span class="line">                self.sort_terms.append([doc_id, term])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__pick_term</span>(<span class="params">self, pivot_index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;select the term before pivot_index in sorted term list</span></span><br><span class="line"><span class="string">         paper recommends returning the term with max idf, here we just return the firt term,</span></span><br><span class="line"><span class="string">         also return the index of the term instead of the term itself for speeding up&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__find_pivot_term</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;find pivot term&quot;&quot;&quot;</span></span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.sort_terms)):</span><br><span class="line">            score += UB[self.sort_terms[i][<span class="number">1</span>]]</span><br><span class="line">            <span class="keyword">if</span> score &gt;= self.threshold:</span><br><span class="line">                <span class="keyword">return</span> [self.sort_terms[i][<span class="number">1</span>], i] <span class="comment">#[term, index]</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="literal">None</span>, <span class="built_in">len</span>(self.sort_terms)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iterator_invert_index</span>(<span class="params">self, change_term, docid, pos</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;find the new_doc_id in the doc list of change_term such that new_doc_id &gt;= docid,</span></span><br><span class="line"><span class="string">        if no new_doc_id satisfy, the self.last_id&quot;&quot;&quot;</span></span><br><span class="line">        doc_list = self.inverted_index[change_term]</span><br><span class="line">        <span class="comment"># new_doc_id, new_pos = self.last_id, len(doc_list)-1 # the case when new_doc_id not exists</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(pos, <span class="built_in">len</span>(doc_list)):</span><br><span class="line">            <span class="keyword">if</span> doc_list[i] &gt;= docid:   <span class="comment"># since doc_list contains self.last_id, this inequation will always be satisfied</span></span><br><span class="line">                new_pos = i</span><br><span class="line">                new_doc_id = doc_list[i]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> [new_doc_id, new_pos]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__advance_term</span>(<span class="params">self, change_index, doc_id </span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;change the first doc of term self.sort_terms[change_index] in the current inverted index</span></span><br><span class="line"><span class="string">        return whether the action succeed or not&quot;&quot;&quot;</span></span><br><span class="line">        change_term = self.sort_terms[change_index][<span class="number">1</span>]</span><br><span class="line">        pos = self.current_inverted_index[change_term][<span class="number">1</span>]</span><br><span class="line">        new_doc_id, new_pos = self.__iterator_invert_index(change_term, doc_id, pos)</span><br><span class="line">        self.current_inverted_index[change_term] = [new_doc_id, new_pos]</span><br><span class="line">        self.sort_terms[change_index][<span class="number">0</span>] = new_doc_id</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            self.sort_terms.sort() <span class="comment">#sort terms by doc id</span></span><br><span class="line">            pivot_term, pivot_index = self.__find_pivot_term() <span class="comment">#find pivot term &gt; threshold</span></span><br><span class="line">            <span class="keyword">if</span> pivot_term == <span class="literal">None</span>: <span class="comment">#no more candidate</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            pivot_doc_id = self.current_inverted_index[pivot_term][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> pivot_doc_id == self.last_id: <span class="comment"># no more candidate</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            <span class="keyword">if</span> pivot_doc_id &lt;= self.current_doc:</span><br><span class="line">                change_index = self.__pick_term(pivot_index)</span><br><span class="line">                self.__advance_term(change_index, self.current_doc + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                first_doc_id = self.sort_terms[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> pivot_doc_id == first_doc_id:</span><br><span class="line">                    self.current_doc = pivot_doc_id</span><br><span class="line">                    <span class="keyword">return</span> self.current_doc <span class="comment"># return the doc for fully calculating</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># pick all preceding term instead of just one, then advance all of them to pivot</span></span><br><span class="line">                    change_index = <span class="number">0</span></span><br><span class="line">                    <span class="keyword">while</span> change_index &lt; pivot_index:</span><br><span class="line">                        self.__advance_term(change_index, pivot_doc_id)</span><br><span class="line">                        change_index += <span class="number">1</span></span><br><span class="line">            <span class="comment"># print(self.sort_terms, self.current_doc, pivot_doc_id)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__insert_heap</span>(<span class="params">self, doc_id, score</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;store the Top N result&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.result_list) &lt; TOPN:</span><br><span class="line">            heapq.heappush(self.result_list, (score, doc_id))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            heapq.heappushpop(self.result_list, (score, doc_id))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__calculate_doc_relevence</span>(<span class="params">self, docid</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;fully calculate relevence between doc and query&quot;&quot;&quot;</span></span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> term <span class="keyword">in</span> self.query_terms:</span><br><span class="line">            <span class="keyword">if</span> docid <span class="keyword">in</span> self.inverted_index[term]:</span><br><span class="line">                score += UB[term]</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">perform_query</span>(<span class="params">self, query_terms</span>):</span><br><span class="line">        self.__init_query(query_terms)</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            candidate_docid = self.__<span class="built_in">next</span>()</span><br><span class="line">            <span class="keyword">if</span> candidate_docid == <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment">#insert candidate_docid to heap</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;candidata doc&#x27;</span>, candidate_docid)</span><br><span class="line">            full_doc_score = self.__calculate_doc_relevence(candidate_docid)</span><br><span class="line">            self.__insert_heap(candidate_docid, full_doc_score)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;result list &quot;</span>, self.result_list)</span><br><span class="line">        <span class="keyword">return</span> self.result_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    testIndex = &#123;&#125;</span><br><span class="line">    testIndex[<span class="string">&quot;t0&quot;</span>] = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">26</span>, LAST_ID]</span><br><span class="line">    testIndex[<span class="string">&quot;t1&quot;</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">10</span>, <span class="number">100</span>, LAST_ID]</span><br><span class="line">    testIndex[<span class="string">&quot;t2&quot;</span>] = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">34</span>, <span class="number">56</span>, LAST_ID]</span><br><span class="line">    testIndex[<span class="string">&quot;t3&quot;</span>] = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">23</span>, <span class="number">70</span>, <span class="number">200</span>, LAST_ID]</span><br><span class="line">    testIndex[<span class="string">&quot;t4&quot;</span>] = [<span class="number">5</span>, <span class="number">14</span>, <span class="number">78</span>, LAST_ID]</span><br><span class="line">    </span><br><span class="line">    w = WAND(testIndex)</span><br><span class="line">    final_result = w.perform_query([<span class="string">&quot;t0&quot;</span>, <span class="string">&quot;t1&quot;</span>, <span class="string">&quot;t2&quot;</span>, <span class="string">&quot;t3&quot;</span>, <span class="string">&quot;t4&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=================final result=======================&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(final_result))):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;doc &#123;0&#125;, relevence score &#123;1&#125;&quot;</span>.<span class="built_in">format</span>(final_result[i][<span class="number">1</span>], final_result[i][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<hr />
<p>参考资料</p>
<p><a href="http://www.cnblogs.com/daremen/p/3289694.html">wand(weak
and)算法基本思路</a> <a
href="https://yanyiwu.com/work/2014/08/18/wand-core-shuli.html">WAND算法核心部分梳理</a></p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>docker 使用小记</title>
    <url>/2017/11/25/docker%20%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<p>由于最近需要在几台电脑上配置相同的环境，几台电脑的操作系统不一样，而且配置一台所需要的步骤是比较繁琐的，因此就想到了用
docker，下面是使用 docker
构造镜像并且在不同的电脑上使用这个镜像的记录。</p>
<span id="more"></span>
<p>docker 支持多个平台，各个平台上具体的安装步骤可参考<a
href="https://docs.docker.com/engine/installation/">官方文档</a>。</p>
<p>docker
提供了一个镜像仓库，当从docker镜像仓库中下载的镜像不能满足我们的需求时，我们可以通过以下两种方式对镜像进行更改</p>
<ol type="1">
<li>从已经创建的容器中更新镜像，并且提交这个镜像</li>
<li>使用 Dockerfile 指令来创建一个新的镜像</li>
</ol>
<p>这里采用的是第一种方法，由于我这里需要的是python环境，因此先 pull
一个 python 镜像作为基础镜像（可以通过 <code>docker search python</code>
找到相关的镜像，这里 pull 的是官方的pytohn 3.5 镜像）, 命令如下</p>
<p><code>docker pull python:3.5</code></p>
<p>等到镜像 pull 下来后，可以通过以下命令进入镜像中</p>
<p><code>docker run -t -i python:3.5 /bin/bash</code></p>
<p>这里 <code>-t -i</code> 含义如下</p>
<p><code>-t</code> : 在新容器内指定一个伪终端或终端。 <code>-i</code> :
允许你对容器内的标准输入 (STDIN) 进行交互</p>
<p>这样便可进入装有 python
3.5的系统（默认是ubuntu），然后在其中像普通的系统一样通过 apt 和 pip
配置所需要的软件和库即可</p>
<p><strong>配置完成后注意不能马上退出这个容器，因为在这个容器中的修改默认是不会影响到原来的镜像的</strong>，也就是说如果退出后在进入
python:3.5
镜像所创建的容器中，所安装的这些库会完全消失，因此需要将这个配置过的容器另存为一个新的镜像，具体做法如下</p>
<p>首先原来的容器不能退出，另开一个终端，通过 <code>docker ps</code>
命令获得修改过的容器的 id ，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bvnbnvk51b0p3qv1h1a45k16qf9.png"
alt="docker ps" />
<figcaption aria-hidden="true">docker ps</figcaption>
</figure>
<p>然后 <code>docker commit id new_image</code>
命令将这个修改过的容器存为新的镜像，这里的 id
不一定要写全，只要能跟其他的容器id区分开来，写前几个字符也可以。</p>
<p>如下所示是将前面的容器另存为镜像 <code>modified_python</code>,
并且通过 <code>docker images</code> 查看到该创建的镜像的时间和大小。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bvnbsfev34m1c34r6r7of1434m.png"
alt="docker commit" />
<figcaption aria-hidden="true">docker commit</figcaption>
</figure>
<p>如果要将这个容器分发到其他机器，可以先将这个镜像上传到 docker
官方的中央仓库(需要注册账号），其他机器再从中央仓库 pull
下来，但是这样可能会存在着网速过慢的问题，因此可以在本地导出容器，然后直接拷贝到其他机器导入，具体操作如下</p>
<p>首先通过 <code>docker ps -a</code> 查看本地使用的容器，然后通过
<code>docker export id &gt; tar_file</code> 将容器导出到
<code>tar_file</code> 中, 其中容器 id
的书写规则同上。如下是将上面配置过的 python 环境导出到
<code>ubuntu_python.tar</code></p>
<figure>
<img src="https://wulc.me/imgs/image_1bvncsf1a14h9mmvbg843f1f6913.png"
alt="docker export" />
<figcaption aria-hidden="true">docker export</figcaption>
</figure>
<p>通过这个文件导入为镜像也很简单，通过
<code>cat tar_file | docker import image_name</code> 即可将
<code>tar_file</code> 导入为 <code>image_name</code> 镜像</p>
<figure>
<img src="https://wulc.me/imgs/image_1bvnd0dlg1s231lkmriu6k1v1v1g.png"
alt="docker import" />
<figcaption aria-hidden="true">docker import</figcaption>
</figure>
<p>其他的一些值得注意的地方就是 -v 参数可以将本地的目录挂到 docker
的目录中，从而可以在容器中写入本地磁盘，具体语法为
<code>-v local_dir:contain_dir</code>, 当容器中的
<code>container_dir</code> 不存在时会自动创建这个目录。</p>
<hr />
<p>参考资料：</p>
<p><a href="https://docs.docker.com/engine/installation/">Install
Docker</a> <a
href="http://www.runoob.com/docker/docker-tutorial.html">Docker 教程</a>
<a
href="http://www.cnblogs.com/ivictor/p/4834864.html">关于Docker目录挂载的总结</a>
<a
href="http://www.docker.org.cn/book/docker/docer-save-changes-10.html">保存对容器的修改</a>
<a
href="https://yeasy.gitbooks.io/docker_practice/content/container/import_export.html">导出和导入容器</a></p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>/etc/ld.so.conf文件详解</title>
    <url>/2015/11/21/etc-ld-so-conf%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="可执行程序的类型"><strong>可执行程序的类型</strong></h2>
<p>Linux系统上有两类不同的Linux可执行程序。</p>
<ul>
<li><p>第一类是<strong>静态链接的可执行程序</strong>。静态可执行程序包含执行所需的所有函数
—
换句话说，它们是“完整的”。因为这一原因，静态可执行程序不依赖任何外部库就可以运行。</p></li>
<li><p>第二类是<strong>动态链接的可执行程序</strong>。动态可执行程序是"不完整"的程序，它依靠外部共享库来提供运行所需的许多函数。
　　 <span id="more"></span></p></li>
</ul>
<h2
id="静态可执行程序与动态可执行程序比较"><strong>静态可执行程序与动态可执行程序比较</strong></h2>
<p>我们可以<strong>用 ldd
命令来确定某一特定可执行程序是否为静态链接</strong>的：</p>
<pre><code>#ldd /sbin/sln
not a dynamic executable</code></pre>
<p>“not a dynamic executable”是 ldd 说明 sln
是静态链接的一种方式。现在，让我们比较 sln 与其非静态同类 ln
的大小：</p>
<pre><code># ls -l /bin/ln /sbin/sln
　　-rwxr-xr-x    1 root     root        23000 Jan 14 00:36 /bin/ln
　　-rwxr-xr-x    1 root     root       381072 Jan 14 00:31 /sbin/sln</code></pre>
<p>sln 的大小超过 ln 十倍。ln比sln小这么多是因为它是动态可执行程序.</p>
<h2 id="动态链接相关性"><strong>动态链接相关性</strong></h2>
<p><strong>查看 ln 依赖的所有共享库的列表，可以使用 ldd 命令</strong>：
　　</p>
<pre><code># ldd /bin/ln
　libc.so.6 =&gt; /lib/libc.so.6 (0x40021000)
　/lib/ld-linux.so.2 =&gt; /lib/ld-linux.so.2 (0x40000000)</code></pre>
<p>可见，ln
依赖外部共享库libc.so.6和ld-linux.so.2。通常，动态链接的程序比其静态链接的等价程序小得多。不过，静态链接的程序可以在某些低级维护任务中发挥作用。例如，sln
是修改位于 /lib中的不同库符号链接的极佳工具。但通常您会发现几乎所有
Linux 系统上的可执行程序都是某种动态链接的变体。 　　 ##
<strong>动态装入器</strong></p>
<p>那么，如果动态可执行程序不包含运行所需的所有函数，Linux
的哪部分负责将这些程序和所有必需的共享库一起装入，以使它们能正确执行呢？答案是<strong>动态装入器（dynamic
loader），它实际上是在 ln 的ldd 清单中看到的作为共享库相关性列出的
ld-linux.so.2
库。</strong>动态装入器负责装入动态链接的可执行程序运行所需的共享库。那么，<strong>动态装入器如何在系统上找到适当的共享库？</strong></p>
<p>动态装入器找到共享库要依靠两个文件
<code>/etc/ld.so.conf 和 /etc/ld.so.cache</code></p>
<h3 id="etcld.so.conf文件"><strong>/etc/ld.so.conf文件</strong></h3>
<p>文件进行cat操作，您可能会看到一个与下面类似的清单：</p>
<pre><code>  $ cat /etc/ld.so.conf
　　/usr/X11R6/lib
　　/usr/lib/gcc-lib/i686-pc-linux-gnu/2.95.3
　　/usr/lib/mozilla
　　/usr/lib/qt-x11-2.3.1/lib
　　/usr/local/lib</code></pre>
<p>ld.so.conf 文件包含一个所有目录（/lib 和 /usr/lib
除外，它们会自动包含在其中）的清单，动态装入器将在其中查找共享库。 ###
<strong>/etc/ld.so.cache文件</strong></p>
<p>在动态装入器能“看到”<code>/etc/ld.so.conf</code>里面的信息之前，必须将它转换到
<code>ld.so.cache</code>文件中。可以通过运行 <code>ldconfig</code>
命令做到这一点：</p>
<pre><code># ldconfig</code></pre>
<p>当 ldconfig 操作结束时，您会有一个最新的
<code>/etc/ld.so.cache</code> 文件，它反映对
<code>/etc/ld.so.conf</code>
所做的更改。从这一刻起，动态装入器在寻找共享库时会查看在
<code>/etc/ld.so.conf</code> 中指定的所有新目录。 　　 ###
<strong>ldconfig 技巧</strong> 　　 要查看 ldconfig
可以“看到”的所有共享库，可以输入：</p>
<pre><code># ldconfig -p | less</code></pre>
<p>还有另一个方便的技巧可以用来配置共享库路径。有时候希望告诉动态装入器在尝试任何
<code>/etc/ld.so.conf</code>
路径以前先尝试使用特定目录中的共享库。在运行的较旧的应用程序不能与当前安装的库版本一起工作的情况下，可以通过<code>LD_LIBRARY_PATH</code>这个环境变量来实现，计入需要指示动态装入器首先检查某个目录，需要将
LD_LIBRARY_PATH
变量设置成希望搜索的目录。多个路径之间用冒号分隔；例如：</p>
<pre><code># export LD_LIBRARY_PATH=&quot;/usr/lib/old:/opt/lib&quot;</code></pre>
<p>执行上面命令后，所有从当前shell启动的动态链接可执行程序都将使用
<code>/usr/lib/old</code> 或 <code>/opt/lib</code>
中的库，如果仍不能满足一些共享库相关性要求，则转回到
<code>/etc/ld.so.conf</code> 中指定的库。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>format 函数常用语法</title>
    <url>/2018/06/03/format%20%E5%87%BD%E6%95%B0%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<p>python 的 <code>format</code>
函数能够对输出做格式化从而使得符合输出的要求，这里记录其一些常见用法，主要参考了博客
<a
href="https://blog.csdn.net/handsomekang/article/details/9183303">飘逸的python
- 增强的格式化字符串format函数</a></p>
<span id="more"></span>
<h2 id="位置映射">位置映射</h2>
<p>下面是通过参数的位置(从0开始)将参数映射到字符串具体位置</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="string">&#x27;&#123;0&#125;,&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;kzc&#x27;</span>,<span class="number">18</span>)  </span><br><span class="line">Out[<span class="number">1</span>]: <span class="string">&#x27;kzc,18&#x27;</span>  </span><br><span class="line">In [<span class="number">2</span>]: <span class="string">&#x27;&#123;&#125;,&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;kzc&#x27;</span>,<span class="number">18</span>)  </span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">&#x27;kzc,18&#x27;</span>  </span><br><span class="line">In [<span class="number">3</span>]: <span class="string">&#x27;&#123;1&#125;,&#123;0&#125;,&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;kzc&#x27;</span>,<span class="number">18</span>)  </span><br><span class="line">Out[<span class="number">3</span>]: <span class="string">&#x27;18,kzc,18&#x27;</span></span><br></pre></td></tr></table></figure>
<p>字符串的 <code>format</code>
函数可以接受不限个参数，位置可以不按顺序，可以不用或者用多次</p>
<h2 id="名称映射">名称映射</h2>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: <span class="string">&#x27;&#123;name&#125;,&#123;age&#125;&#x27;</span>.<span class="built_in">format</span>(age=<span class="number">18</span>,name=<span class="string">&#x27;kzc&#x27;</span>)  </span><br><span class="line">Out[<span class="number">5</span>]: <span class="string">&#x27;kzc,18&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="对象映射">对象映射</h2>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,age</span>):  </span><br><span class="line">        self.name,self.age = name,age  </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):  </span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;This guy is &#123;self.name&#125;,is &#123;self.age&#125; old&#x27;</span>.<span class="built_in">format</span>(self=self)  </span><br><span class="line">In [<span class="number">2</span>]: <span class="built_in">str</span>(Person(<span class="string">&#x27;kzc&#x27;</span>,<span class="number">18</span>))  </span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">&#x27;This guy is kzc,is 18 old&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="listtuple-的下标映射">list/tuple 的下标映射</h2>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">7</span>]: p=[<span class="string">&#x27;kzc&#x27;</span>,<span class="number">18</span>]</span><br><span class="line">In [<span class="number">8</span>]: <span class="string">&#x27;&#123;0[0]&#125;,&#123;0[1]&#125;&#x27;</span>.<span class="built_in">format</span>(p)</span><br><span class="line">Out[<span class="number">8</span>]: <span class="string">&#x27;kzc,18&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="填充与对齐">填充与对齐</h2>
<p>填充常跟对齐一起使用
<code>^</code>、<code>&lt;</code>、<code>&gt;</code>分别是<strong>居中、左对齐、右对齐，后面带宽度</strong>
<code>:</code>号后面带填充的字符，只能是一个字符，不指定的话默认是用空格填充</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">15</span>]: <span class="string">&#x27;&#123;:&gt;8&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;189&#x27;</span>)</span><br><span class="line">Out[<span class="number">15</span>]: <span class="string">&#x27;     189&#x27;</span></span><br><span class="line">In [<span class="number">16</span>]: <span class="string">&#x27;&#123;:0&gt;8&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;189&#x27;</span>)</span><br><span class="line">Out[<span class="number">16</span>]: <span class="string">&#x27;00000189&#x27;</span></span><br><span class="line">In [<span class="number">17</span>]: <span class="string">&#x27;&#123;:a&gt;8&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;189&#x27;</span>)</span><br><span class="line">Out[<span class="number">17</span>]: <span class="string">&#x27;aaaaa189&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="精度与类型f">精度与类型f</h2>
<p>精度常跟类型f一起使用 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">44</span>]: <span class="string">&#x27;&#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="number">321.33345</span>)</span><br><span class="line">Out[<span class="number">44</span>]: <span class="string">&#x27;321.33&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>其中.2表示长度为2的精度，f表示float类型。</p>
<h2 id="进制转换">进制转换</h2>
<p>主要就是进制了，<code>b</code>、<code>d</code>、<code>o</code>、<code>x</code>
分别是二进制、十进制、八进制、十六进制, 用 <code>,</code>
号还能用来做金额的千位分隔符。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In [54]: &#x27;&#123;:b&#125;&#x27;.format(17)</span><br><span class="line">Out[54]: &#x27;10001&#x27;</span><br><span class="line">In [55]: &#x27;&#123;:d&#125;&#x27;.format(17)</span><br><span class="line">Out[55]: &#x27;17&#x27;</span><br><span class="line">In [56]: &#x27;&#123;:o&#125;&#x27;.format(17)</span><br><span class="line">Out[56]: &#x27;21&#x27;</span><br><span class="line">In [57]: &#x27;&#123;:x&#125;&#x27;.format(17)</span><br><span class="line">Out[57]: &#x27;11&#x27;</span><br><span class="line">In [58]: &#x27;&#123;:,&#125;&#x27;.format(1234567890)</span><br><span class="line">Out[58]: &#x27;1,234,567,890&#x27;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>ipdb 使用小记</title>
    <url>/2018/12/21/ipdb%20%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<p>最近在魔改 loss
function，涉及到很多矩阵运算，而矩阵运算中维度的对齐免不了要多次的调试；沿袭着之前的
print 大法弄了一段时间后，不仅代码凌乱不堪，而且心累：每次
<code>import tensorflow as tf</code> 都要十几秒，然后 print
完之后想进一步看其他变量的信息，又要重新执行一遍。后来找到了 <a
href="https://pypi.org/project/ipdb/">ipdb</a>
这个好用的工具，才发现自己过去调试程序的方法是多么的低效和 naive。</p>
<span id="more"></span>
<p>python 提供了一个默认的 debugger：<a
href="https://docs.python.org/3.5/library/pdb.html">pdb</a>，而 ipdb
则是 pdb 的增强版，提供了补全、语法高亮等功能，类似于 ipython 与 python
默认的交互终端的关系，通过 <code>pip install ipdb</code> 即可安装
ipdb。</p>
<h2 id="使用方式">使用方式</h2>
<p>ipdb
的使用方法一般有两种：<strong>集成到源代码或通过命令交互</strong>。</p>
<p>集成到源代码可以直接在代码指定位置插入断点。如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ipdb</span><br><span class="line">var1 = <span class="number">23</span></span><br><span class="line">ipdb.set_trace()</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>上面的代码会在执行完 <code>var1 = 23</code> 这条语句之后停止，展开
ipython 环境，之后就可以自由地调试了。</p>
<p>上面的方式虽然简单，但是存在着两个较为比较明显的问题：</p>
<ol type="1">
<li>插入的断点代码会污染原来的代码空间</li>
<li>每次插入断点都需要修改源码</li>
</ol>
<p>因此，相比于上面的方式，交互式的命令式调试方法更加方便。启动命令式调试环境的方法也很简单：</p>
<p><code>python -m ipdb code.py</code></p>
<p>接着就是通过一些常用的命令来进行
debug了，如上面插入断点的样例代码就可以通过以下命令达到同样效果：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">$python -m ipdb code.py</span><br><span class="line">ipdb&gt; b <span class="number">3</span></span><br><span class="line">Breakpoint <span class="number">1</span> at /test.py:<span class="number">3</span></span><br><span class="line">ipdb&gt; c</span><br></pre></td></tr></table></figure>
<p>上面的命令 <code>b 3</code> 表示在第三行设置一个断点，然后通过命令
<code>c</code> 一直执行至断点处，接着就会展开 ipython
环境进行调试了。（<code>b</code> 和 <code>c</code> 分别代表了 break 和
continue，可以用整条命令，也可以只用首字母）</p>
<h2 id="常用命令">常用命令</h2>
<p>上面的设置断点和一直执行至断点是比较常见的用法，除此之外，还有其他一些常用命令。</p>
<h3 id="帮助">帮助</h3>
<p>通过命令 <code>h</code> 可以列出所有命令，后面跟上具体的命令如
<code>h command</code>
则可以显示出这条命令的具体作用，非常有用，依靠这条命令能够节省不少
google 的次数。</p>
<h3 id="断点">断点</h3>
<p>上面提到了断点的一种常见用法，即命令 <code>b line_number</code> 和
<code>c</code> 的组合，<code>b line_number</code>
默认是对当前文件设置断点，也可以在 line_number
前加上其他文件名（比如说要将要引用的其他文件），即
<code>b file_name:line_number</code>；file_name 需要在
<code>sys.path</code> 中，当前目录已经默认存在 <code>sys.path</code> ,
也可通过 <code>..</code> 引用上一层目录的文件。</p>
<p>另外，<strong>通过 <code>b</code> 设置的断点在重新运行 debug 程序
(命令 <code>restart</code> 或 <code>run</code>)
后会依然保留</strong>，如果要忽略这些断点，有两种做法</p>
<ol type="1">
<li>通过 <code>disable</code> 关闭这些断点，<code>enable</code>
打开这些断点</li>
<li>通过命令 <code>clear</code> 或 <code>cl</code> 清除这些断点</li>
</ol>
<p>此外，除了上面那种一直存在的断点，ipdb
中还有一种<strong>只生效一次的断点，命令为 <code>tbreak</code>,
使用方法同命令 <code>b</code>。</strong></p>
<p>上面的断点都是直接指定的，pdb
中还有一种<strong>条件断点</strong>，即只有当某个条件成立时，才设置断点，其使用命令为
<code>condition line_num bool_expression</code>, condition
为关键字，line_num 为设定断点的位置，只有当 expression 为 true 时,
才会设置这个断点。</p>
<p>如果需要列出已经设置的所有断点，可以单独使用命令 <code>b</code>。</p>
<h3 id="逐行执行">逐行执行</h3>
<p>有两条命令可以进行逐行执行： <code>s</code>（step) 或
<code>n</code>（next),
两个命令的主要区别是：<strong>假如当前行调用了某个函数，<code>s</code>
会进入这个函数，<code>n</code>
则不会</strong>。因此，如果需要了解函数内部执行的细节，需要
<code>s</code> 命令进入函数内部进行 debug。</p>
<p><strong>进入了函数之后</strong>，通过命令 <code>a</code>（argument）
可列出当前的函数的参数，通过 <code>r</code>（return）则可以直接执行至
return 语句。</p>
<h3 id="忽略某段代码">忽略某段代码</h3>
<p>使用 <code>j line_number</code> 可以忽略某段代码，下一步直接从
line_number 开始执行。</p>
<h3 id="查看源码">查看源码</h3>
<p>通过命令 <code>l</code> 或 <code>ll</code> 可查看源码，
<code>ll</code> 是查看整个源码文件， <code>l</code>
可指定需要查看的行数，默认是当前往后 11 行，也可指定具体的范围，如
<code>l 2,5</code> 是查看第 2-5 行的源码。</p>
<h3 id="重启或退出-debugger">重启或退出 debugger</h3>
<p>上面已经提到了重启 debugger 可通过 <code>restart</code> 或
<code>run</code> 命令，需要注意的是，<strong>重启 debugger
后断点、debugger 的设置等是会保留的。</strong>如果要一个全新的
debugger，可通过命令 <code>q</code>、<code>quit</code> 或
<code>exit</code> 退出 debugger 后进入。</p>
<h2 id="小结">小结</h2>
<p>以上就是 ipdb 的一些基本用法, 除此之外，更多的用法可参考 <a
href="https://docs.python.org/3.5/library/pdb.html">pdb
的官方文档</a>，ipdb 的命令跟 pdb 是一样的。另外，gdb
也是一个类似的命令行 debugger，只是一般用来调试 C/C++
而已，使用的方法类似，甚至很多命令的名称更 pdb 都一样，具体可参考 <a
href="http://wiki.ubuntu.org.cn/%E7%94%A8GDB%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F">用GDB调试程序</a>。</p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>python 中使用SQLAlchemy</title>
    <url>/2016/06/08/python%20%E4%B8%AD%E4%BD%BF%E7%94%A8SQLAlchemy/</url>
    <content><![CDATA[<p>数据库表是一个二维表，包含多行多列。通过python获取数据库中的内容时，可以用一个list表示获取的多行记录，每一个元素的类型是tuple，表示一行记录，比如，包含id和name的user表：</p>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">    (&#x27;1&#x27;, &#x27;Michael&#x27;),</span><br><span class="line">    (&#x27;2&#x27;, &#x27;Bob&#x27;),</span><br><span class="line">    (&#x27;3&#x27;, &#x27;Adam&#x27;)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>通过ORM技术：<code>Object-Relational Mapping</code>，可以把关系数据库的表结构映射到对象上。如：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">id</span>, name</span>):</span><br><span class="line">        self.<span class="built_in">id</span> = <span class="built_in">id</span></span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">[</span><br><span class="line">    User(<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;Michael&#x27;</span>),</span><br><span class="line">    User(<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>),</span><br><span class="line">    User(<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;Adam&#x27;</span>)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>ORM框架就是用来完成这种装换的，在Java中最常用的是Hibernate，而在Python中，最有名的ORM框架是SQLAlchemy。SQLAlchemy
的简单使用如下</p>
<h2 id="创建表">创建表</h2>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入:</span></span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> Column, String, create_engine</span><br><span class="line"><span class="keyword">from</span> sqlalchemy.orm <span class="keyword">import</span> sessionmaker</span><br><span class="line"><span class="keyword">from</span> sqlalchemy.ext.declarative <span class="keyword">import</span> declarative_base</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建对象的基类:</span></span><br><span class="line">Base = declarative_base()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义User对象:</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">Base</span>):</span><br><span class="line">    <span class="comment"># 表的名字:</span></span><br><span class="line">    __tablename__ = <span class="string">&#x27;user&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 表的结构:</span></span><br><span class="line">    <span class="built_in">id</span> = Column(String(<span class="number">20</span>), primary_key=<span class="literal">True</span>)</span><br><span class="line">    name = Column(String(<span class="number">20</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化数据库连接:</span></span><br><span class="line">engine = create_engine(<span class="string">&#x27;mysql+mysqlconnector://root:password@localhost:3306/test&#x27;</span>)</span><br><span class="line"><span class="comment"># 创建DBSession类型:</span></span><br><span class="line">DBSession = sessionmaker(bind=engine)</span><br></pre></td></tr></table></figure>
<p><code>create_engine()</code>用来初始化数据库连接。SQLAlchemy用一个字符串表示连接信息：</p>
<p><code>数据库类型+数据库驱动名称://用户名:口令@机器地址:端口号/数据库名</code></p>
<h2 id="插入记录">插入记录</h2>
<p>由于有了ORM，我们<strong>向数据库表中添加一行记录，可以视为添加一个User对象</strong>：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建session对象:</span></span><br><span class="line">session = DBSession()</span><br><span class="line"><span class="comment"># 创建新User对象:</span></span><br><span class="line">new_user = User(<span class="built_in">id</span>=<span class="string">&#x27;5&#x27;</span>, name=<span class="string">&#x27;Bob&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加到session:</span></span><br><span class="line">session.add(new_user)</span><br><span class="line"><span class="comment"># 提交即保存到数据库:</span></span><br><span class="line">session.commit()</span><br><span class="line"><span class="comment"># 关闭session:</span></span><br><span class="line">session.close()</span><br></pre></td></tr></table></figure></p>
<p>session对象可视为当前数据库连接。关键是获取session，然后把对象添加到session，最后提交并关闭。</p>
<h2 id="查询记录">查询记录</h2>
<p>通过ORM查询出来的可以不再是tuple，而是User对象。SQLAlchemy提供的查询接口如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建Session:</span></span><br><span class="line">session = DBSession()</span><br><span class="line"><span class="comment"># 创建Query查询，filter是where条件，最后调用one()返回第一行，如果调用all()则返回所有行:</span></span><br><span class="line">user = session.query(User).<span class="built_in">filter</span>(User.<span class="built_in">id</span>==<span class="string">&#x27;5&#x27;</span>).one()</span><br><span class="line"><span class="comment"># 打印类型和对象的name属性:</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;type:&#x27;</span>, <span class="built_in">type</span>(user)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;name:&#x27;</span>, user.name</span><br><span class="line"><span class="comment"># 关闭Session:</span></span><br><span class="line">session.close()</span><br></pre></td></tr></table></figure></p>
<p>运行结果如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="built_in">type</span>: &lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.User&#x27;</span>&gt;</span><br><span class="line">name: Bob</span><br></pre></td></tr></table></figure></p>
<p>关SQLAlchemy更详细的用法可参考<a
href="http://docs.sqlalchemy.org/en/latest/">官方文档</a></p>
<hr />
<p>参考：http://www.liaoxuefeng.com/</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>python 中 * 与 ** 的参数传递</title>
    <url>/2016/09/01/python%20%E4%B8%AD%E6%98%9F%E5%8F%B7%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/</url>
    <content><![CDATA[<p>在 python
中，经常可以看到定义函数或调用函数时<code>f(*arg)</code>和<code>f(**args)</code>类型的参数，本文主要讲述这两个形式的参数的含义以及应用。</p>
<span id="more"></span>
<h2 id="定义函数时参数加上-和">定义函数时参数加上 <code>*</code> 和
<code>**</code></h2>
<p>首先这两个类型的参数都表示<strong>不确定具体参数个数</strong>，怎么理解这句话呢？通常在定义函数的时候，定义了几个参数，调用是也要传入几个参数(默认参数除外，可传可不传)，但是只要在定义函数的时候将参数写成<code>*</code>或<code>**</code>的形式，就可以传入多个参数。如下面的例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">a</span>(<span class="params">*args</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> <span class="built_in">type</span>(args)</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> i <span class="keyword">in</span> args:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span> i</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;tuple&#x27;</span>&gt;</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a([<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;tuple&#x27;</span>&gt;</span><br><span class="line">[<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a()</span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;tuple&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p>从上面的例子可以看到，通过 <code>*</code>
声明的参数在调用是可以传入0~n个参数，且<strong>不管传入的参数为何类型，在函数内部都被存放在以形参名为标识符的tuple中，无法进行修改</strong>。</p>
<p>同理,通过<code>**</code>声明的参数也是可以传入多个参数，但是传入的参数类型需要为<code>k1=v1,k2=v2.....</code>的类型,且参数在函数内部将被存放在以形式名为标识符的dictionary中，这种方法在需要声明多个默认参数的时候特别有用。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">a</span>(<span class="params">**args</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> <span class="built_in">type</span>(args)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> args</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> k, v <span class="keyword">in</span> args.items():</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span> k,v</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> args[<span class="string">&#x27;k1&#x27;</span>]</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a(k1=<span class="number">1</span>, k2=<span class="number">2</span>, k3=<span class="number">3</span>, k4=<span class="number">4</span>)</span><br><span class="line">&lt;<span class="built_in">type</span> <span class="string">&#x27;dict&#x27;</span>&gt;</span><br><span class="line">&#123;<span class="string">&#x27;k3&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;k2&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;k1&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;k4&#x27;</span>: <span class="number">4</span>&#125;</span><br><span class="line">k3 <span class="number">3</span></span><br><span class="line">k2 <span class="number">2</span></span><br><span class="line">k1 <span class="number">1</span></span><br><span class="line">k4 <span class="number">4</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>下面显示了如何通过这两个参数使代码变得简洁(注意 <code>*args</code> 和
<code>**kwargs</code> 可以同时在函数的定义中,但是 *args 必须在 **kwargs
前面)</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params">*values, **options</span>):</span><br><span class="line">    s = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> values:</span><br><span class="line">        s = s + i</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;neg&quot;</span> <span class="keyword">in</span> options <span class="keyword">and</span> options[<span class="string">&quot;neg&quot;</span>]:</span><br><span class="line">        s = -s</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">s = <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)            <span class="comment"># returns 15</span></span><br><span class="line">s = <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, neg=<span class="literal">True</span>)  <span class="comment"># returns -15</span></span><br><span class="line">s = <span class="built_in">sum</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, neg=<span class="literal">False</span>) <span class="comment"># returns 15</span></span><br></pre></td></tr></table></figure>
<p>除此之外，<code>*args</code> 和 <code>**kwargs</code>
也可以和命名参数一起混着用。命名参数首先获得参数值，然后所有的其他参数都传递给
<code>*args</code> 和 <code>**kwargs</code>
.命名参数在列表的最前端.例如:</p>
<p><code>def table_things(titlestring, *args, **kwargs)</code></p>
<h2 id="调用函数时参数加上-和">调用函数时参数加上 <code>*</code> 和
<code>**</code></h2>
<p>除了在定义函数时可以加上 <code>*</code>或<code>**</code>,
还可以在调用函数时加上<code>*</code>或<code>**</code>,
表示<strong>将输入的
集合（序列）类型参数拆开</strong>，见下面的例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># values = set()</span></span><br><span class="line"><span class="comment"># values.add(1)</span></span><br><span class="line"><span class="comment"># values.add(2)</span></span><br><span class="line"></span><br><span class="line">values = (<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># values = [1,2]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># values = &#123;1:3, 2:4&#125;</span></span><br><span class="line"></span><br><span class="line">s = <span class="built_in">sum</span>(*values)</span><br></pre></td></tr></table></figure>
<p>无论是集合、列表、元组还是字典,
在作为参数输入时加上<code>*</code>，表示将里面的元素拆开，然后一个个传进去，所以上面执行的结果相当于<code>s = sum(1, 2)</code>,由于字典比较特殊，传入参数时只会拆开
key 然后传入。下面结合上面定义函数时参数加上<code>*</code>来讲述这个
<code>*</code> 的含义,例子如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params">*args</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> args[<span class="number">0</span>]</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>val = (<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sum</span>(val)</span><br><span class="line">(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sum</span>(*val)</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>上面的sum函数输出传入的第一个参数，由于<code>sum(val)</code>将整个val元组作为参数传入，相当于<code>sum((1,2))</code>,所以会输出(1,2);而<code>sum(*val)</code>则会将val拆开，相当于<code>sum（1,2）</code>，因此输出为
1</p>
<p>而在调用参数时加上<code>**</code>,作用也是将传入的参数拆开，只是<strong>输入的参数必须为字典，且每个
key
必须要为函数的某个形参，key对应的value为该参数的值</strong>。详见下面的例子:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">parrot</span>(<span class="params">voltage, state=<span class="string">&#x27;a stiff&#x27;</span>, action=<span class="string">&#x27;voom&#x27;</span></span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;-- This parrot wouldn&#x27;t&quot;</span>, action, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;if you put&quot;</span>, voltage, <span class="string">&quot;volts through it.&quot;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;E&#x27;s&quot;</span>, state, <span class="string">&quot;!&quot;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = &#123;<span class="string">&quot;voltage&quot;</span>: <span class="string">&quot;four million&quot;</span>, <span class="string">&quot;state&quot;</span>: <span class="string">&quot;bleedin&#x27; demised&quot;</span>, <span class="string">&quot;action&quot;</span>: <span class="string">&quot;VOOM&quot;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parrot(**d)</span><br><span class="line">-- This parrot wouldn<span class="string">&#x27;t VOOM if you put four million volts through it. E&#x27;</span>s bleedin<span class="string">&#x27; demised !</span></span><br></pre></td></tr></table></figure>
<p>上面的<code>parrot(**d)</code>相当于<code>parrot(voltage = "four million", state = "bleedin' demised", action = "VOOM")</code>通过上面的方法，可以先将所有参数用字典封装，再通过
<code>**</code> 传递。</p>
<p>结合定义函数时参数加上<code>**</code> 有以下例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">b</span>(<span class="params">**args</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> k,v <span class="keyword">in</span> args.items():</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span> k,v</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>val = &#123;<span class="string">&#x27;keke&#x27;</span>:<span class="number">1</span>, <span class="string">&#x27;hehe&#x27;</span>:<span class="number">2</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b(**val)</span><br><span class="line">keke <span class="number">1</span></span><br><span class="line">hehe <span class="number">2</span></span><br></pre></td></tr></table></figure>
<hr />
<p>参考：
http://stackoverflow.com/questions/2921847/what-does-the-star-operator-mean-in-python
https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists</p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python 中的字符串与编码</title>
    <url>/2017/08/28/python%20%E4%B8%AD%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%8E%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<p>本文主要参考了<a
href="https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386819196283586a37629844456ca7e5a7faa9b94ee8000">这篇文章</a>，该文章比较清楚地讲述了字符串的编码问题，并且在
python2 和 python3 中如何区分使用两者。</p>
<span id="more"></span>
<h2 id="字符编码">字符编码</h2>
<p><strong>因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。</strong>最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制
11111111 = 十进制
255），如果要表示更大的整数，就必须用更多的字节。比如两个字节可以表示的最大整数是65535，4个字节可以表示的最大整数是4294967295。</p>
<p><strong>由于计算机是美国人发明的，因此，最早只有127个字母被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为
<code>ASCII</code>
编码</strong>，比如大写字母A的编码是65，小写字母z的编码是122。</p>
<p>但是<strong>要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和
<code>ASCII</code> 编码冲突，所以，中国制定了 <code>GB2312</code>
编码，用来把中文编进去。</strong></p>
<p>你可以想得到的是，全世界有上百种语言，日本把日文编到
<code>Shift_JIS</code> 里，韩国把韩文编到 <code>Euc-kr</code>
里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。</p>
<p>因此，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。</p>
<p><strong>Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。</strong></p>
<p>现在，捋一捋ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。</p>
<p>字母A用ASCII编码是十进制的65，二进制的01000001；</p>
<p>字符0用ASCII编码是十进制的48，二进制的00110000，注意字符'0'和整数0是不同的；</p>
<p>汉字中已经超出了ASCII编码的范围，用Unicode编码是十进制的20013，二进制的01001110
00101101。</p>
<p>你可以猜测，<strong>如果把ASCII编码的A用Unicode编码，只需要在前面补0就可以</strong>，因此，A的Unicode编码是00000000
01000001。</p>
<p>新的问题又出现了：<strong>如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。</strong></p>
<p>所以，<strong>本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节</strong>，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间；注意UTF-8并不是唯一对Unicode进行编码的编码方式。</p>
<table>
<thead>
<tr class="header">
<th>字符</th>
<th>ASCII</th>
<th>Unicode</th>
<th>UTF-8</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>01000001</td>
<td>00000000 01000001</td>
<td>01000001</td>
</tr>
<tr class="even">
<td>中</td>
<td>x</td>
<td>01001110 00101101</td>
<td>11100100 10111000 10101101</td>
</tr>
</tbody>
</table>
<p>从上面的表格还可以发现，UTF-8编码有一个额外的好处，就是<strong>ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作</strong>。</p>
<p>搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：</p>
<p><strong>在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。</strong></p>
<p>如用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件：</p>
<figure>
<img src="https://wulc.me/imgs/image_1bp5udd9h10002fb1a1h1be712hl9.png"
alt="记事本编码转换例子" />
<figcaption aria-hidden="true">记事本编码转换例子</figcaption>
</figure>
<p>而浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器：</p>
<figure>
<img src="https://wulc.me/imgs/image_1bp5uhp4b1d7r1fkihnkqa5sspm.png"
alt="浏览网页编码转换例子" />
<figcaption aria-hidden="true">浏览网页编码转换例子</figcaption>
</figure>
<p>所以你看到很多网页的源码上会有类似
<code>&lt;meta charset="UTF-8" /&gt;</code>
的信息，表示该网页正是用的UTF-8编码。</p>
<h2 id="python中的字符串">python中的字符串</h2>
<p>搞清楚了令人头疼的字符编码问题后，我们再来研究Python对Unicode的支持。</p>
<p><strong>因为Python的诞生比Unicode标准发布的时间还要早，所以最早的Python只支持ASCII编码，普通的字符串'ABC'在Python内部都是ASCII编码的</strong>。Python提供了
<code>ord()</code> 和 <code>chr()</code>
函数，可以把字母和对应的数字相互转换：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">ord</span>(<span class="string">&#x27;A&#x27;</span>)</span><br><span class="line"><span class="number">65</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">chr</span>(<span class="number">65</span>)</span><br><span class="line"><span class="string">&#x27;A&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Python在后来添加了对Unicode的支持，以Unicode表示的字符串用
<code>u'...'</code> 表示，比如：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> <span class="string">u&#x27;中文&#x27;</span></span><br><span class="line">中文</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">u&#x27;中&#x27;</span></span><br><span class="line"><span class="string">u&#x27;\u4e2d&#x27;</span></span><br></pre></td></tr></table></figure>
<p>写 <code>u'中'</code> 和 <code>u'\u4e2d'</code>
是一样的，。因此，<code>u'A'</code>和<code>u'\u0041'</code>也是一样的。</p>
<p>两种字符串如何相互转换？字符串'xxx'虽然是ASCII编码，但也可以看成是UTF-8编码，而u'xxx'则只能是Unicode编码。</p>
<p>把 <code>u'xxx'</code> 转换为UTF-8编码的 <code>'xxx'</code> 用
<code>encode('utf-8')</code> 方法：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">u&#x27;ABC&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;ABC&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">u&#x27;中文&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;\xe4\xb8\xad\xe6\x96\x87&#x27;</span></span><br></pre></td></tr></table></figure>
<p>英文字符转换后表示的UTF-8的值和Unicode值相等（但占用的存储空间不同），而<strong>中文字符转换后1个Unicode字符将变为3个UTF-8字符，上面的<code>\xe4</code>就是其中一个字节，因为它的值是228，没有对应的字母可以显示，所以以十六进制显示字节的数值</strong>。<code>len()</code>函数可以返回字符串的长度：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">u&#x27;ABC&#x27;</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">u&#x27;中文&#x27;</span>)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">&#x27;\xe4\xb8\xad\xe6\x96\x87&#x27;</span>)</span><br><span class="line"><span class="number">6</span></span><br></pre></td></tr></table></figure>
<p>反过来，把UTF-8编码表示的字符串<code>'xxx'</code>转换为Unicode字符串<code>u'xxx'</code>用<code>decode('utf-8')</code>方法：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;abc&#x27;</span>.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="string">u&#x27;abc&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;\xe4\xb8\xad\xe6\x96\x87&#x27;</span>.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="string">u&#x27;\u4e2d\u6587&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> <span class="string">&#x27;\xe4\xb8\xad\xe6\x96\x87&#x27;</span>.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">中文</span><br></pre></td></tr></table></figure></p>
<p><strong>两者的转换方式总结来说就是从 Unicode 到 UTF-8 通过
<code>encode()</code> 方法， 而从 UTF-8 到 Unicode 通过
<code>decode()</code> 方法, 而且UTF-8并不是唯一的编码方式</strong></p>
<p>在编写 python
程序时，如果代码中有中文，那么就需要在代码的开始地方加上
<code># -*- coding: utf-8 -*-</code>,
这是为了是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。而且这样声明了UTF-8编码并不意味着<code>.py</code>文件就是UTF-8编码的，必须并且要确保编辑器在保存文件的时候使用
UTF-8 编码方式。</p>
<p>最后需要注意的是，由于历史遗留问题，<strong>python 2.x里的字符串用
<code>'xxx'</code> 表示 <code>str</code>，Unicode字符串用
<code>u'xxx'</code>
表示unicode，而在3.x中，所有字符串都被视为unicode，因此，写
<code>u'xxx'</code> 和 <code>'xxx'</code> 是完全一致的，而在2.x中以
<code>'xxx'</code> 表示的str就必须写成
<code>b'xxx'</code>，以此表示“二进制字符串”</strong>.</p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python 中的可迭代对象(iterable)、迭代器(iterator)与生成器(generator)</title>
    <url>/2016/09/08/python%20%E4%B8%AD%E7%9A%84%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1(iterable)%E3%80%81%E8%BF%AD%E4%BB%A3%E5%99%A8(iterator)%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8(generator)/</url>
    <content><![CDATA[<p>本文主要讲述python中的几个概念：可迭代对象(iterable)、迭代器(iterator)与生成器(generator)。</p>
<span id="more"></span>
<h2 id="可迭代对象iterable-与-迭代器iterator">可迭代对象(iterable) 与
迭代器(iterator)</h2>
<p>对于
<code>string</code>、<code>list</code>、<code>dict</code>、<code>tuple</code>
等这类容器对象，可以使用 for
循环对其进行遍历。像这种可以被遍历的对象被称为可迭代对象。</p>
<p>通过 for 语句对遍历可迭代对象时，实际上是调用可迭代对象内部的
<code>__iter__()</code> 方法（因此<strong>一个可迭代对象必须要实现
<code>__iter__()</code>
方法</strong>），调用了这个方法会返回一个迭代器(iterator)，通过迭代器便可遍历可迭代对象。见下面的例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = <span class="built_in">iter</span>(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = <span class="built_in">iter</span>(x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(y)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.<span class="built_in">next</span>()</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(z)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(x)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;list&#x27;</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(y)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;list_iterator&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>
<p>这里 x 是一个列表，是一个可迭代对象。<strong>y 和 z
是两个独立的迭代器，迭代器内部持有一个状态，该状态用于记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。</strong></p>
<p>迭代器也分具体的迭代器类型，比如
<code>list_iterator</code>，<code>set_iterator</code>。<code>iter(x)</code>语句实际上是调用了
x 内部的 <code>__iter__</code> 方法的, 调用 <code>__iter__</code>
方法后会返回一个迭代器，由于迭代器内部实现了 <code>next</code> 方法
（python2中是 <code>next</code> 方法，python3是 <code>__next__</code>
方法,<strong>一个迭代器必须实现此方法</strong>），因此可通过
<code>next()</code> 方法来遍历可迭代对象。</p>
<p>因此，执行下面语句：</p>
<p><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"> x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">for</span> elem <span class="keyword">in</span> x:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p>
<p>相当于以下流程</p>
<p><img
src="https://wulc.me/imgs/image_1asu3d67o1ekr17ib1ecghrbqrk9.png" /></p>
<p>上图中调用 <code>next()</code>
方法直到没有后续元素时，<code>next()</code> 会抛出一个
<code>StopIteration</code> 异常，通知for语句循环结束。如</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = <span class="built_in">iter</span>(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.<span class="built_in">next</span>()</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(b)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(b)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure>
<p>上面说的都是 python
自带的容器对象，它们都实现了相应的迭代器方法，那如果是自定义类需要遍历怎么办？</p>
<p>方法很简单，假如我们需要自定义一个有遍历功能的类
<code>IterClass</code>，那么只需要在这个类的内部实现一个
<code>__iter__(self)</code> 方法，使其返回一个带有
<code>__next__(self)</code> 方法的对象就可以了。如果你在
<code>IterClass</code> 刚好也定义了 <code>__next__(self)</code>
方法（一般使用迭代器都会定义），那在 <code>__iter__()</code> 里只要返回
self 就可以。下面是具体的实例：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">IterClass</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">max</span></span>):</span><br><span class="line">        self.<span class="built_in">max</span> = <span class="built_in">max</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        self.a = <span class="number">0</span></span><br><span class="line">        self.b = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self</span>):</span><br><span class="line">        fib = self.a</span><br><span class="line">        <span class="keyword">if</span> fib &gt; self.<span class="built_in">max</span>:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        self.a, self.b = self.b, self.a + self.b</span><br><span class="line">        <span class="keyword">return</span> fib</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    fib = IterClass(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> fib:</span><br><span class="line">        <span class="built_in">print</span> i</span><br></pre></td></tr></table></figure>
<p>上面输出的结果为: <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure></p>
<p>上面的代码定义了一个 <code>IterClass</code> 类，用于生成 fibonacci
序列。用for遍历时会逐个打印生成的fibonacci数，max是生成的fibonacci序列中数字大小的上限。</p>
<p>在类的实现中，定义了一个 <code>__iter__(self)</code>
方法，这个方法是在遍历时被 <code>iter()</code>
调用，返回一个迭代器。<strong>因为在遍历的时候，是直接调用 python
的内置函数 <code>iter()</code>，由 <code>iter()</code> 通过调用
<code>__iter__(self)</code> 获得对象的迭代器。</strong></p>
<p>有了迭代器，就可以逐个遍历元素了。而逐个遍历的时候，也是使用 python
的内置 的 <code>next()</code> 函数，<code>next()</code>
函数通过调用对象的 <code>next(self)</code> 方法（python 3 为
<code>__next__(self)</code> 方法）对迭代器对象进行遍历。因为同时实现
<code>__iter__(self)</code> 和 <code>next(self)</code> ， 所以
<code>IterClass</code> 既是可迭代对象，也是迭代器，在实现
<code>__iter__(self)</code> 的时候，直接返回self就可以。</p>
<p>为了更好地理解，对上面的内容的小结如下：<strong>在循环遍历自定义容器对象时,会使用
python 内置函数 <code>iter()</code> 调用遍历对象的
<code>__iter__(self)</code> 获得一个迭代器,之后再循环对这个迭代器使用
<code>next()</code> 调用迭代器对象的 <code>next(self)</code> 或
<code>__next__(self)</code>。<code>__iter__</code> 只会被调用一次,而
<code>__next__</code> 会被调用 n 次。</strong></p>
<h2 id="生成器generator">生成器(generator)</h2>
<p><strong>生成器其实是一种特殊的迭代器，不过这种迭代器更加简洁和高效,它自动创建了
<code>__iter__()</code> 和 <code>next()</code>
方法（因此生成器其实既是一个可迭代对象，也是一个迭代器）,
除了创建和保存程序状态的自动方法,当发生器终结时,还会自动抛出
<code>StopIteration</code> 异常。它不需要再像上面的类一样写
<code>__iter__()</code> 和 <code>next ()</code> 方法了，只需要一个
<code>yiled</code>
关键字。生成器一定是迭代器（反之不成立）。</strong></p>
<p>一个带有关键词 <code>yield</code>
的函数就是一个生成器,它和普通函数不同,生成一个 generator
看起来像函数调用,但不会执行任何函数代码,直到对其显式或隐式地调用
<code>next()</code> (<strong>在 for 循环中会隐式自动调用
<code>next()</code></strong>)
才开始执行。虽然执行流程仍按函数的流程执行,但<strong>每执行到一个
<code>yield</code> 语句就会中断,并返回一个迭代值,下次执行时从
<code>yield</code>
的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被
<code>yield</code> 中断了数次,每次中断都会通过 yield
返回当前的迭代值</strong>（yield暂停一个函数，next()从其暂停处恢复其运行）。见下面的例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">reverse</span>(<span class="params">data</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> data[index]</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> char <span class="keyword">in</span> reverse(<span class="string">&#x27;hello&#x27;</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(char)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">o</span><br><span class="line">l</span><br><span class="line">l</span><br><span class="line">e</span><br><span class="line">h</span><br></pre></td></tr></table></figure>
<p>用生成器来实现上面的斐波那契数列的例子是：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fib</span>():</span><br><span class="line">    prev, curr = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">yield</span> curr</span><br><span class="line">        prev, curr = curr, curr + prev</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(itertools.islice(f, <span class="number">0</span>, <span class="number">10</span>))</span><br><span class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">13</span>, <span class="number">21</span>, <span class="number">34</span>, <span class="number">55</span>]</span><br></pre></td></tr></table></figure>
<p>生成器在Python中是一个非常强大的编程结构，可以用更少地中间变量写流式代码，此外，相比其它容器对象它更能节省内存和CPU，它也可以用更少的代码来实现相似的功能。如果构造一个列表的目的仅仅是传递给别的函数,
那么就可以用生成器来代替。但凡看到类似： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">something</span>():</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> ... <span class="keyword">in</span> ...:</span><br><span class="line">        result.append(x)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
都可以用生成器函数来替换： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">iter_something</span>():</span><br><span class="line">    <span class="keyword">for</span> ... <span class="keyword">in</span> ...:</span><br><span class="line">        <span class="keyword">yield</span> x</span><br></pre></td></tr></table></figure>
只需要在接收函数返回值的时候将其转为 list 类型即可。</p>
<p>另外对于生成器，python还提供了一个<strong>生成器表达式(generator
expression)</strong>：类似与一个 <code>yield</code>
值的匿名函数。表达式本身看起来像列表推导式,
但<strong>不是用方括号而是用圆括号包围起来</strong>,
它<strong>返回的是一个生成器对象而不是列表对象</strong>。见下面的例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = (i*i <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">5</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> num <span class="keyword">in</span> a:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> num</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">9</span></span><br><span class="line"><span class="number">16</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">&lt;generator <span class="built_in">object</span> &lt;genexpr&gt; at <span class="number">0x02B707D8</span>&gt;</span><br></pre></td></tr></table></figure>
<hr />
<p>参考： https://segmentfault.com/a/1190000002900850
http://foofish.net/blog/109/iterators-vs-generators</p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python 中使用 SQLite</title>
    <url>/2016/06/07/python%20%E4%BD%BF%E7%94%A8SQLite/</url>
    <content><![CDATA[<p>SQLite是一款轻量级的关系型数据库，相比MySQL等CS模式的数据库，SQLite有以下特点：
<span id="more"></span> - 不需要一个单独的服务器进程或操作的系统（无服务器的）。 -
SQLite 不需要配置，这意味着不需要安装或管理。 - SQLite
是非常小的，是轻量级的，完全配置时小于400KiB，省略可选功能配置时小于250KiB。
- 一个完整的
SQLite数据库是存储在一个<strong>单一的跨平台的磁盘文件</strong>。 -
SQLite事务是完全兼容 ACID 的，允许从多个进程或线程安全访问。
这里科普一下ACID的定义，摘自维基百科</p>
<blockquote>
<p>ACID，是指数据库管理系统（DBMS）在写入/更新资料的过程中，为保证事务（transaction）是正确可靠的，所必须具备的四个特性：原子性（atomicity，或称不可分割性）、一致性（consistency）、隔离性（isolation，又称独立性）、持久性（durability）。
<strong>原子性</strong>：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。
<strong>一致性</strong>：在<strong>事务开始之前和事务结束以后</strong>，数据库的完整性没有被破坏。
<strong>隔离性</strong>：数据库允许<strong>多个并发事务</strong>同时对齐数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
<strong>持久性</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>
</blockquote>
<ul>
<li>SQLite 可在 UNIX（Linux, Mac OS-X, Android, iOS）和 Windows（Win32,
WinCE, WinRT）中运行。</li>
</ul>
<p>由于SQLite本身是C写的，而且体积很小，所以，经常被集成到各种应用程序中，甚至在iOS和Android的App中都可以集成。</p>
<p>Python就内置了SQLite3，所以，在Python中使用SQLite，不需要安装任何东西，直接使用。</p>
<p>python中使用SQLite的步骤与使用MySQL的步骤非常类似，主要分为下面三步：</p>
<p><strong>1.获取连接 2.获取游标 3.执行语句并提交事务</strong></p>
<p>下面是操作SQLite的一个简单例子</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"></span><br><span class="line">DB = <span class="string">&#x27;test.db&#x27;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    conn = sqlite3.connect(DB)</span><br><span class="line">    cursor = conn.cursor()</span><br><span class="line">    cursor.execute(<span class="string">&#x27;create table student(id varchar(10),name varchar(20))&#x27;</span>)</span><br><span class="line">    cursor.execute(<span class="string">&#x27;insert into student values(&quot;2012&quot;,&quot;lc&quot;)&#x27;</span>)</span><br><span class="line">    cursor.execute(<span class="string">&#x27;select * from student where name=?&#x27;</span>,(<span class="string">&#x27;lc&#x27;</span>,))</span><br><span class="line">    result = cursor.fetchall()</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> result:</span><br><span class="line">        <span class="built_in">print</span> row</span><br><span class="line"><span class="keyword">except</span> sqlite3.Error <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span> e</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    cursor.close()</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure>
<p>以下几点将有助于更好地理解上面的代码：</p>
<ul>
<li>由于SQLite是一个嵌入式的本地数据库，所以连接时不需要指定服务器地址、用户等。只需要通过<code>sqlite3.connect(DB)</code>便可连接数据库DB，假如没有该数据库时会自动创建。</li>
<li>由于SQLite是关系型数据库，所以绝大部分的SQL语句规范与MySQL等类似</li>
<li>如果执行的SQL语句需要从外部传入变量，则需要在SQL语句中将变量替换成<code>？</code>,并在<code>execute</code>方法增加第二个参数（tuple类型）</li>
<li><code>fetchall()</code>会返回一个list，list中的每个元素都是一个tuple，代表数据库中的一行记录</li>
<li>执行完语句后需要关闭cursor和conn，并且<strong>在关闭conn前需要进行commit(),否则修改不会生效</strong></li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>python 并行编程概述</title>
    <url>/2016/05/29/python%20%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="程序并行化的形式">程序并行化的形式</h2>
<p>程序并行化有以下三种形式，分别是：<strong>并发编程（Concurrent
Programming）、并行编程（Parallel Programming ）、分布式编程(Distributed
Programming)</strong></p>
<span id="more"></span>
<h3 id="并发编程concurrent-programming">并发编程（Concurrent
Programming）</h3>
<p>并发编程（Concurrent Programming）的模型图如下所示：</p>
<p><img src="https://wulc.me/imgs/concurrent_programming.png" /></p>
<p>从图中可知，并发编程类似操作系统中的<strong>伪并行</strong>，任一时刻只有一个进程占用CPU，通过调度控制不同的进程在不同时刻访问CPU。</p>
<h3 id="并行编程parallel-programming">并行编程（Parallel Programming
）</h3>
<p>并行编程的模型图如下所示：</p>
<p><img src="https://wulc.me/imgs/parallel_programming.png" /></p>
<p>并行编程指在<strong>多核环境</strong>中，同一时间每个核都可以允许一个进程运行，这可以认为是真正意义上的并行</p>
<h3 id="分布式编程distributed-programming">分布式编程(Distributed
Programming)</h3>
<p>分布式编程的模型图如下所示：</p>
<p><img src="https://wulc.me/imgs/distribute_programming.png" /></p>
<p>分布式编程指在不同机器上同时完成同一项任务，是物理上的隔离。如Hadoop中的MapReduce就是分布式编程的一个典型例子。</p>
<h2 id="并行化编程的通信方式">并行化编程的通信方式</h2>
<p>由于并行化后的进程要完成的是同一项任务，所以程序间的通信是必须的。程序的通信方式一般有以下两种：<strong>共享状态（shared
state）、消息传递（message passing）</strong></p>
<h3 id="共享状态shared-state">共享状态（shared state）</h3>
<p>这种方法就是共享进程间的资源，<strong>类似于同一进程里所有的线程共享进程的资源一样</strong>。</p>
<p>这种方法有以下不足：任一进程对共享资源的错误操作都会影响其他的进程；难以应用在分布式编程中。</p>
<p>在这种通信方式下，对于只读的数据可以不加保护措施，但是对于可写的数据，必须要防止多个进程同时修改这个数据。如在操作系统中的互斥量（mutex），线程锁等就是这类型的防护措施。</p>
<h3 id="消息传递message-passing">消息传递（message passing）</h3>
<p>消息传递能够避免上面提到的问题，而且也能够应用在分布式编程中。每进行一次消息传递，都会复制一份数据，因此数据的一致性大大提升。</p>
<p>虽然这种方法占用的内存比第一种要大，但是这种方法有以下优势： -
数据的一致性大大增强 -
消息能够在本地传输（多进程）或者在分布式环境中传输 -
解决可伸缩问题并允许不同系统间的相互操作 - 对于编程人员来说便于实现</p>
<h2 id="并行化编程存在的问题">并行化编程存在的问题</h2>
<p>在并行化编程中有可能会遇到以下问题</p>
<h3 id="死锁deadlock">死锁(DeadLock)</h3>
<p>与操作系统中的死锁问题一样，发生在<strong>多个进程中每个都需要其他进程的资源，同时又不肯释放自己的资源，导致资源的需求关系形成闭合的环状。</strong></p>
<p>如下图所示，进程A需要进程C的资源，进程C需要进程B的资源，而进程B需要进程A的资源。并且<strong>在进程释放自己的资源前，其他进程无法获取，而进程需要获得其他进程的资源才能完成自己的任务并释放资源</strong>，这样就是一个死锁的局面。</p>
<p><img
src="https://wulc.me/imgs/image_1ajrvpokaoac1ro5sqn1och1u3m9.png" /></p>
<h3 id="饿死starvation">饿死(Starvation)</h3>
<p>饿死概念与操作系统中的也是一样，指的是某个进程一直得不到自己的资源，无法继续运行。</p>
<p>如进程 A 的优先级比 B
要高，所以优先运行A，但是进程A由于需要完成的任务繁重，所以一直占用着CPU，导致进程B一直无法运行，就称为进程B被饿死。</p>
<h3 id="竞争条件race-conditons">竞争条件(Race conditons)</h3>
<p>竞争条件是操作系统和电子电路中的一个常见概念，维基百科对其定义如下：</p>
<blockquote>
<p>A race condition or race hazard is the behavior of an electronic,
software or other system where the output is dependent on the sequence
or timing of other uncontrollable events. It becomes a bug when events
do not happen in the order the programmer intended. The term originates
with the idea of two signals racing each other to influence the output
first.</p>
</blockquote>
<p>大意就是多个具有不确定性（无法知道何时会到达或执行指定操作）的对象（进程或电子信号），必须要按照时间序列（time
sequence）执行,假如这种同步被破坏，那么多个进程会没有顺序地修改同一个变量，导致数据出错。如下面的简单例子：</p>
<p>假设图中的husband和wife是两个进程，两者同时操作账户里的钱，正常情况下是这样的</p>
<p><img
src="https://wulc.me/imgs/image_1ajsv7k2toa3ggn1il41v55aoj9.png" /></p>
<p>而假如两者不按照time sequences执行操作，同步会被破坏，导致出现race
conditions，如下图所示：</p>
<p><img
src="https://wulc.me/imgs/image_1ajsvce541v111a2tke15a01dvum.png" /></p>
<h2 id="python中实现并行化编程工具">python中实现并行化编程工具</h2>
<ul>
<li><a
href="https://docs.python.org/2/library/threading.html">threading</a>
模块，python自带的多线程模块</li>
<li><a
href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing</a>模块，python自带的多进程模块</li>
<li><a href="http://www.parallelpython.com/">parallel
Python</a>模块，具有运行过程调整进程数目、动态负载平衡的第三方模块</li>
<li><a href="http://www.celeryproject.org/">Celery</a>
模块，用于分布式编程的一个分布式任务队列模块</li>
</ul>
<hr />
<p>参考： Parallel Programming with Python</p>
]]></content>
      <categories>
        <category>python</category>
        <category>并行编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>python 语法杂记--迭代器、生成器、上下文管理器</title>
    <url>/2018/12/17/python%20%E8%AF%AD%E6%B3%95%E6%9D%82%E8%AE%B0--%E7%94%9F%E6%88%90%E5%99%A8%E3%80%81%E8%BF%AD%E4%BB%A3%E5%99%A8%E3%80%81%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8/</url>
    <content><![CDATA[<p>本文主要介绍 python 中几个重要的
"器"（迭代器、生成器、上下文管理器）的原理、实现与使用，还有一个装饰器在前面一篇文章已经进行了介绍，本文主要参考了
<a href="http://funhacks.net/explore-python/">Python 之旅</a>
中的相关章节。</p>
<span id="more"></span>
<h2 id="迭代器">迭代器</h2>
<p>迭代器（iterator）就是用来遍历可迭代对象的（iterable），这两个概念要区分开。</p>
<h3 id="iterable">iterable</h3>
<p>像 list，tuple 等可以通过 <code>for..in..</code>
进行遍历的对象就是可迭代对象，更严谨的定义则是：</p>
<p><strong>含有 <code>__iter__()</code> 方法或
<code>__getitem__()</code> 方法的对象称之为可迭代对象</strong>.</p>
<p>可以使用 Python 内置的 hasattr()
函数来判断一个对象是不是可迭代的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>((), <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>([], <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(&#123;&#125;, <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(<span class="number">123</span>, <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(<span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(<span class="string">&#x27;abc&#x27;</span>, <span class="string">&#x27;__getitem__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>另外，也可使用 isinstance() 进行判断：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterable</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>((), Iterable)        <span class="comment"># 元组</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>([], Iterable)        <span class="comment"># 列表</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(&#123;&#125;, Iterable)        <span class="comment"># 字典</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="string">&#x27;abc&#x27;</span>, Iterable)     <span class="comment"># 字符串</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="number">100</span>, Iterable)       <span class="comment"># 数字</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h3 id="iterator">iterator</h3>
<p>迭代器是一个对象，但比较特别，它需要遵循迭代器协议，具体协议如下</p>
<blockquote>
<p>迭代器协议（iterator protocol）是指要实现对象的
<code>__iter()__</code> 和 <code>next()</code> 方法（注意：Python3
要实现 <code>__next__()</code> 方法），其中，<code>__iter()__</code>
方法返回迭代器对象本身，<code>next()</code>
方法返回容器的下一个元素，在没有后续元素时抛出 StopIteration 异常。</p>
</blockquote>
<p>这里需要注意的是，<strong>虽然元组、列表和字典等对象是可迭代的，但它们却不是迭代器</strong></p>
<p>首先，可以使用 hasattr() 进行判断： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), <span class="string">&#x27;next&#x27;</span>)  <span class="comment"># 有 __iter__ 方法但是没有 next 方法，不是迭代器</span></span><br><span class="line"><span class="literal">False</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;next&#x27;</span>)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;, <span class="string">&#x27;__iter__&#x27;</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">hasattr</span>(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;, <span class="string">&#x27;next&#x27;</span>)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>同样也可以使用 <code>isinstance()</code> 进行判断：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterator</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>((), Iterator)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>([], Iterator)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(&#123;&#125;, Iterator)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="string">&#x27;&#x27;</span>, Iterator)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="number">123</span>, Iterator)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>虽然这些可迭代对象不是迭代器，但是<strong>可以使用 Python 内置的
<code>iter()</code> 函数获得它们的迭代器对象</strong>，如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Iterator</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="built_in">iter</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), Iterator)  <span class="comment"># 使用 iter() 函数，获得迭代器对象</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>(<span class="built_in">iter</span>(<span class="string">&#x27;abc&#x27;</span>), Iterator)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>事实上，<strong>Python 的 for 循环就是先通过内置函数
<code>iter()</code> 获得一个迭代器，然后再不断调用 <code>next()</code>
函数实现的</strong>，即：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">    <span class="built_in">print</span> i</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">it = <span class="built_in">iter</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        x = <span class="built_in">next</span>(it)</span><br><span class="line">        <span class="built_in">print</span> x</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="comment"># 没有后续元素，退出循环</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>下面是一个斐波那契数列迭代器，根据迭代器的定义，我们需要实现
<code>__iter()__</code> 和 <code>next()</code> 方法（在 Python3 中是
<code>__next__()</code> 方法）</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回迭代器对象本身</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回容器下一个元素</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = self.b, self.a + self.b</span><br><span class="line">        <span class="keyword">return</span> self.a</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    fib = Fib()    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> fib:</span><br><span class="line">        <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="built_in">print</span> i</span><br></pre></td></tr></table></figure>
<p>因此，关于迭代器和可迭代对象，需要注意下面三点</p>
<p><strong>1.
元组、列表、字典和字符串对象是可迭代的，但不是迭代器，不过我们可以通过
<code>iter()</code> 函数获得一个迭代器对象</strong> <strong>2. Python 的
for 循环实质上是先通过内置函数 <code>iter()</code>
获得一个迭代器，然后再不断调用 <code>next()</code> 函数实现的</strong>
<strong>3. 定义迭代器需要实现对象的 <code>__iter()__</code>和
<code>next()</code> 方法（Python3 要实现 <code>__next__()</code>
方法），其中，<code>__iter()__</code>
方法返回迭代器对象本身，<code>next()</code>
方法返回容器的下一个元素，在没有后续元素时抛出 StopIteration
异常。</strong></p>
<h2 id="生成器">生成器</h2>
<h3 id="yield">yield</h3>
<p><strong>生成器也是迭代器的一种</strong>，一个带有关键字
<code>yield</code> 的函数就是一个生成器函数，而当我们使用 yield
时，它帮我们自动创建了 <code>__iter__()</code> 和 <code>next()</code>
方法，而且在没有数据时，也会抛出 <code>StopIteration</code>
异常，非常简洁和高效。如下是一个简单的例子</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">generator_function</span>():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> <span class="string">&#x27;hello 1&#x27;</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> <span class="string">&#x27;hello 2&#x27;</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> <span class="string">&#x27;hello 3&#x27;</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g = generator_function()  <span class="comment"># 函数没有立即执行，而是返回了一个生成器</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g.<span class="built_in">next</span>()  <span class="comment"># 当使用 next()(或 next(g))的时候开始执行，遇到 yield 暂停并返回</span></span><br><span class="line">hello <span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g.<span class="built_in">next</span>()    <span class="comment"># 从原来暂停的地方继续执行</span></span><br><span class="line">hello <span class="number">2</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>g.<span class="built_in">next</span>()    <span class="comment"># 从原来暂停的地方继续执行，没有 yield，抛出异常</span></span><br><span class="line">hello <span class="number">3</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure>
<p>从上面的例子可知，带有 yield 的函数执行过程如下</p>
<p><strong>1.
调用该函数的时候不会立即执行代码，而是返回了一个生成器对象；</strong>
<strong>2. 当使用 <code>next()</code> (在 for 循环中会自动调用
<code>next()</code>) 作用于返回的生成器对象时，函数开始执行，在遇到
<code>yield</code> 的时候会『暂停』并返回 yield 后的值</strong>
<strong>3. 当再次使用 <code>next()</code>
的时候，函数会从原来『暂停』的地方继续执行，直到遇到 yield
语句，如果没有 yield 语句，则抛出异常</strong>**</p>
<p>相比于迭代器，生成器这样的 lazy evaluation
能够节省更多的内存，同时让代码更加简洁，如前面定义的斐波那契数列迭代器，通过生成器实现的代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">fib</span>():</span><br><span class="line"><span class="meta">... </span>    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="meta">... </span>        a, b = b, a + b</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> a</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> item <span class="keyword">in</span> f:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> item &gt; <span class="number">10</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> item</span><br><span class="line">...</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<h3 id="send-throw-close"><code>send()</code>, <code>throw()</code>,
<code>close()</code></h3>
<p>除了上面提到的
yield，生成器还有一些其他的特殊方法：<code>send()</code>,
<code>throw()</code> 和
<code>close()</code>，分别用于给生成器发送消息、异常和关闭生成器。
具体用法如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="keyword">def</span> <span class="title function_">generator_function</span>():</span><br><span class="line">   ...:     <span class="comment"># test send()</span></span><br><span class="line">   ...:     value1 = <span class="keyword">yield</span> <span class="number">0</span></span><br><span class="line">   ...:     <span class="built_in">print</span>(<span class="string">&#x27;value1 is &#x27;</span>, value1)</span><br><span class="line">   ...:</span><br><span class="line">   ...:     <span class="comment"># test throw()</span></span><br><span class="line">   ...:     <span class="keyword">try</span>:</span><br><span class="line">   ...:         <span class="keyword">yield</span> <span class="string">&#x27;Normal&#x27;</span></span><br><span class="line">   ...:     <span class="keyword">except</span> ValueError:</span><br><span class="line">   ...:         <span class="keyword">yield</span> <span class="string">&#x27;Error&#x27;</span></span><br><span class="line">   ...:</span><br><span class="line">   ...:     <span class="comment"># test close()</span></span><br><span class="line">   ...:     <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line">   ...:     <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line">   ...:     <span class="keyword">yield</span> <span class="number">3</span></span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: g = generator_function()</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: <span class="built_in">next</span>(g)</span><br><span class="line">Out[<span class="number">4</span>]: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: g.send(<span class="number">10</span>)</span><br><span class="line">value1 <span class="keyword">is</span>  <span class="number">10</span></span><br><span class="line">Out[<span class="number">5</span>]: <span class="string">&#x27;Normal&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: g.throw(ValueError)</span><br><span class="line">Out[<span class="number">6</span>]: <span class="string">&#x27;Error&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: <span class="built_in">next</span>(g)</span><br><span class="line">Out[<span class="number">7</span>]: <span class="number">1</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: g.close()</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: <span class="built_in">next</span>(g)</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">StopIteration                             Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">9</span>-5f315c5de15b&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> <span class="built_in">next</span>(g)</span><br><span class="line"></span><br><span class="line">StopIteration:</span><br></pre></td></tr></table></figure>
<p>在上面的代码中，先调用 <code>next()</code>
方法，使函数开始执行，代码执行到 yield 0 的时候暂停，返回了
0；接着，执行 <code>send()</code>
方法，它会恢复生成器的运行，并将发送的值赋给上次中断时 yield
表达式的执行结果，也就是 value1，这时控制台打印出 value1
的值，并继续执行，直到遇到 yield 后暂停，此时返回 'Normal',
因此，<strong>简单地说，<code>send()</code> 方法就是 <code>next()</code>
的功能，加上传值给 yield</strong></p>
<p>接着， <code>throw()</code> 方法向生成器函数传递了 ValueError
异常，此时代码进入 except ValueError 语句，遇到 yield
'Error'，暂停并返回 Error 字符串, 因此，<strong>简单的说，throw() 就是
next() 的功能，加上传异常给 yield。</strong></p>
<p>最后使用了 <code>close()</code>
方法来关闭一个生成器。生成器被关闭后，再次调用 <code>next()</code>
方法，不管能否遇到 yield 关键字，都会抛出 StopIteration 异常</p>
<h2 id="上下文管理器">上下文管理器</h2>
<h3 id="enter__-__exit__"><code>__enter__()</code> &amp;
<code>__exit__()</code></h3>
<p>上下文(context)在计算机中是个很常见的词汇，可以简单将其理解为运行时的环境，如进程上下文指的是进程在执行时
CPU
的所有寄存器中的值、进程的状态以及堆栈上的内容等，当系统需要切换到其他进程时，系统会保留当前进程的上下文，也就是运行时的环境，以便再次执行该进程。</p>
<p>而在 python 中上下文管理器最常见的场景便是 <code>with</code>
语句，<code>with</code>
一般用于对资源进行访问的场景，确保执行过程中出现异常情况时也可以对资源进行回收，比如自动关闭文件等。</p>
<p>类似迭代器协议（Iterator Protocol），上下文管理器（Context
manager）也有上下文管理协议（Context Management Protocol）。</p>
<ul>
<li><strong>上下文管理器协议</strong>，是指要实现对象的
<code>__enter__()</code> 和 <code>__exit__()</code> 方法。</li>
<li><strong>上下文管理器</strong>也就是支持上下文管理器协议的对象，也就是实现了
<code>__enter__()</code> 和 <code>__exit__()</code> 方法的对象。</li>
</ul>
<p>如下是一个简单的上下文管理器的例子</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt, <span class="built_in">pow</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;initialize x and y&#x27;</span></span><br><span class="line">        self.x, self.y = x, y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__enter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Entering context&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__exit__</span>(<span class="params">self, <span class="built_in">type</span>, value, traceback</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Exiting context&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_distance</span>(<span class="params">self</span>):</span><br><span class="line">        distance = sqrt(<span class="built_in">pow</span>(self.x, <span class="number">2</span>) + <span class="built_in">pow</span>(self.y, <span class="number">2</span>))</span><br><span class="line">        <span class="keyword">return</span> distance</span><br></pre></td></tr></table></figure>
<p>使用 <code>with</code> 语句调用上下文管理器如下所示</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> Point(<span class="number">3</span>, <span class="number">4</span>) <span class="keyword">as</span> pt:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;distance: &#x27;</span>, pt.get_distance()</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">initialize x <span class="keyword">and</span> y   <span class="comment"># 调用了 __init__ 方法</span></span><br><span class="line">Entering context     <span class="comment"># 调用了 __enter__ 方法</span></span><br><span class="line">distance:  <span class="number">5.0</span>       <span class="comment"># 调用了 get_distance 方法</span></span><br><span class="line">Exiting context      <span class="comment"># 调用了 __exit__ 方法</span></span><br></pre></td></tr></table></figure>
<p>上面的 with 语句执行过程如下：</p>
<ol type="1">
<li>Point(3, 4) 生成了一个上下文管理器；</li>
<li>调用上下文管理器的 <code>__enter__()</code> 方法，并<strong>将
<code>__enter__()</code> 方法的返回值赋给 as 字句中的变量
pt</strong>;</li>
<li>执行语句体（指 with 语句包裹起来的代码块）内容，输出 distance；</li>
<li><strong>不管执行过程中是否发生异常，都执行上下文管理器的
<code>__exit__()</code> 方法</strong>。</li>
</ol>
<p>一般来说，<code>__exit__()</code>
方法负责执行清理工作，如释放资源，关闭文件等。如果执行过程没有出现异常，或者语句体中执行了语句
break/continue/return，则以 None 作为参数调用
<code>__exit__(None, None, None)</code>；如果执行过程中出现异常，则使用
<code>sys.exc_info</code> 得到的异常信息为参数调用
<code>__exit__(exc_type, exc_value, exc_traceback)</code>.
同时<strong>出现异常时，如果
<code>__exit__(type, value, traceback)</code> 返回 False 或
None，则会重新抛出异常，让 <code>with</code>
之外的语句逻辑来处理异常；如果返回
True，则忽略异常，不再对异常进行处理。</strong></p>
<p>上面的 with 语句执行过程没有出现异常，下面是出现异常的情形：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> Point(<span class="number">3</span>, <span class="number">4</span>) <span class="keyword">as</span> pt:</span><br><span class="line">    pt.get_length()        <span class="comment"># 访问了对象不存在的方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">initialize x <span class="keyword">and</span> y</span><br><span class="line">Entering context</span><br><span class="line">Exiting context</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AttributeError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">216</span>-ab4a0e6b6b4a&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">      <span class="number">1</span> <span class="keyword">with</span> Point(<span class="number">3</span>, <span class="number">4</span>) <span class="keyword">as</span> pt:</span><br><span class="line">----&gt; <span class="number">2</span>     pt.get_length()</span><br><span class="line"></span><br><span class="line">AttributeError: <span class="string">&#x27;Point&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;get_length&#x27;</span></span><br></pre></td></tr></table></figure>
<p>对前面的 <code>__exit__()</code> 方法修改如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__exit__</span>(<span class="params">self, <span class="built_in">type</span>, value, traceback</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;Exception has been handled&quot;</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;Exiting context&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>则执行相同过的代码的结果如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> Point(<span class="number">3</span>, <span class="number">4</span>) <span class="keyword">as</span> pt:</span><br><span class="line">    pt.get_length()      <span class="comment"># 访问了对象不存在的方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">initialize x <span class="keyword">and</span> y</span><br><span class="line">Entering context</span><br><span class="line">Exception has been handled</span><br><span class="line">Exiting context</span><br></pre></td></tr></table></figure>
<h3 id="contextlib">contextlib</h3>
<p>除了在类中定义 <code>__enter__</code> 和 <code>__exit__</code>
方法来实现上下文管理器，我们还可以<strong>通过生成器函数和装饰器来实现上下文管理器</strong>，这个装饰器就在
python 提供的 contextlib 模块中。如下是个简单的例子</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> contextmanager</span><br><span class="line"></span><br><span class="line"><span class="meta">@contextmanager</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">point</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;before yield&#x27;</span></span><br><span class="line">    <span class="keyword">yield</span> x * x + y * y</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;after yield&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> point(<span class="number">3</span>, <span class="number">4</span>) <span class="keyword">as</span> value:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;value is: %s&#x27;</span> % value</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">before <span class="keyword">yield</span></span><br><span class="line">value <span class="keyword">is</span>: <span class="number">25</span></span><br><span class="line">after <span class="keyword">yield</span></span><br></pre></td></tr></table></figure>
<p>可以看到，<strong>yield 产生的值赋给了 as 子句中的 value
变量</strong>。</p>
<p>另外，需要强调的是，虽然<strong>通过使用 contextmanager
装饰器，可以不必再编写 <code>__enter__</code> 和 <code>__exit__</code>
方法，但是获取和清理资源的操作仍需要我们自己编写：获取资源的操作定义在
yield 语句之前，释放资源的操作定义在 yield 语句之后。</strong></p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python 语法杂记--装饰器，类的特殊方法，常量类</title>
    <url>/2018/12/15/python%20%E8%AF%AD%E6%B3%95%E6%9D%82%E8%AE%B0--%E8%A3%85%E9%A5%B0%E5%99%A8%EF%BC%8C%E7%B1%BB%E7%9A%84%E7%89%B9%E6%AE%8A%E6%96%B9%E6%B3%95%EF%BC%8C%E5%B8%B8%E9%87%8F%E7%B1%BB/</url>
    <content><![CDATA[<p>最近在看 python 一些语法知识，虽然 python
代码写了不少，但是对于一些高级语法的了解还不够深入；因此本文主要记录了一些比较生疏的知识点，主要包括了装饰器，类的特殊方法，常量类这三个方面的知识。</p>
<span id="more"></span>
<h2 id="装饰器">装饰器</h2>
<p><strong>装饰器本质上是一个高阶函数，以被装饰的函数为参数，并返回一个包装后的函数给被装饰函数。</strong></p>
<p>装饰器的一般使用形式如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorator</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>等价于下面的形式： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">func = decorator(func)</span><br></pre></td></tr></table></figure></p>
<p>装饰器可以定义多个，离函数定义最近的装饰器先被调用，比如：
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorator_one</span></span><br><span class="line"><span class="meta">@decorator_two</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">func = decorator_one(decorator_two(func))</span><br></pre></td></tr></table></figure>
<h3 id="对带参数的函数进行装饰">对带参数的函数进行装饰</h3>
<p>对带参数的函数进行装饰这个需求很常见，简单来说，<strong>装饰带参数的函数时，需要将参数传递给装饰器内部需要返回的函数(也叫内嵌包装函数)</strong>，也就是说内嵌包装函数的参数跟被装饰函数的参数对应，如下所示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">makeitalic</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapped</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        ret = func(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&lt;i&gt;&#x27;</span> + ret + <span class="string">&#x27;&lt;/i&gt;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> wrapped</span><br><span class="line"></span><br><span class="line"><span class="meta">@makeitalic</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;hello %s&#x27;</span> % name</span><br><span class="line"></span><br><span class="line"><span class="meta">@makeitalic</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello2</span>(<span class="params">name1, name2</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;hello %s, %s&#x27;</span> % (name1, name2)</span><br></pre></td></tr></table></figure>
<p>可以看到，装饰器内部需要返回的函数 <code>wrapped</code> 带上了参数
<code>(*args, **kwargs)</code>, 目的是为了适应可变参数。使用如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello(<span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&lt;i&gt;hello python&lt;/i&gt;&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>hello2(<span class="string">&#x27;python&#x27;</span>, <span class="string">&#x27;java&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&lt;i&gt;hello python, java&lt;/i&gt;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="带参数的装饰器">带参数的装饰器</h3>
<p>上面的例子，我们增强了函数 hello 的功能，给它的返回加上了标签
<code>&lt;i&gt;...&lt;/i&gt;</code>，现在，我们想改用标签
<code>&lt;b&gt;...&lt;/b&gt;</code> 或
<code>&lt;p&gt;...&lt;/p&gt;</code>。是不是要像前面一样，再定义一个类似
<code>makeitalic</code>
的装饰器呢？其实，我们可以可以使用带参数的装饰器，简单来说，就是<strong>在原来的装饰器基础上再封装一层函数，将标签作为参数，返回一个装饰器</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">wrap_in_tag</span>(<span class="params">tag</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decorator</span>(<span class="params">func</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapped</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            ret = func(*args, **kwargs)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&lt;&#x27;</span> + tag + <span class="string">&#x27;&gt;&#x27;</span> + ret + <span class="string">&#x27;&lt;/&#x27;</span> + tag + <span class="string">&#x27;&gt;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> wrapped</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> decorator</span><br></pre></td></tr></table></figure>
<p>现在，我们可以根据需要生成想要的装饰器了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">makebold = wrap_in_tag(&#x27;b&#x27;)  # 根据 &#x27;b&#x27; 返回 makebold 生成器`</span><br><span class="line">@makebold</span><br><span class="line">def hello(name):</span><br><span class="line">    return &#x27;hello %s&#x27; % name</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; hello(&#x27;world&#x27;)</span><br><span class="line">&#x27;&lt;b&gt;hello world&lt;/b&gt;&#x27;</span><br></pre></td></tr></table></figure>
<p>上面的形式也可以写得更加简洁： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@wrap_in_tag(&#x27;b&#x27;)</span><br><span class="line">def hello(name):</span><br><span class="line">    return &#x27;hello %s&#x27; % name</span><br></pre></td></tr></table></figure></p>
<p>这就是带参数的装饰器，其实就是在装饰器外面多了一层包装，根据不同的参数返回不同的装饰器。</p>
<h2 id="私有成员">私有成员</h2>
<p>python 不像 C++ 有 private
之类的关键字，但是<strong>可以在属性或方法的名称前面加上两个下划线
<code>__</code>, 来限制用户访问对象的属性或方法</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">class</span> <span class="title class_">Animal</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">   ...:     <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">   ...:         self.__name = name</span><br><span class="line">   ...:     <span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">self</span>):</span><br><span class="line">   ...:         <span class="built_in">print</span> (<span class="string">&#x27;Hello, I am %s.&#x27;</span> % self.__name)</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: a = Animal(<span class="string">&quot;dog&quot;</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: a.__name</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">AttributeError                            Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">5</span>-5d5520ef9fe0&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> a.__name</span><br><span class="line"></span><br><span class="line">AttributeError: <span class="string">&#x27;Animal&#x27;</span> <span class="built_in">object</span> has no attribute <span class="string">&#x27;__name&#x27;</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: a.greet()</span><br><span class="line">Hello, I am dog.</span><br></pre></td></tr></table></figure>
<h2 id="类方法-vs-静态方法">类方法 vs 静态方法</h2>
<p>python
中的类有两个特殊的方法：<strong>类方法和静态方法</strong>，两个方法主要有以下特点</p>
<ol type="1">
<li>两个方法均是<strong>属于类</strong>而不是属于对象的</li>
<li>两个方法都是通过内置的装饰器定义（<code>@classmethod</code> 和
<code>@staticmethod</code>）</li>
<li>类方法可以访问类属性，静态方法则不能</li>
</ol>
<p>如下是类方法的一个例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    bar = <span class="number">1</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">class_foo</span>(<span class="params">cls</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Hello, &#x27;</span>, cls</span><br><span class="line">        <span class="built_in">print</span> cls.bar</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A.class_foo()   <span class="comment"># 直接通过类来调用方法</span></span><br><span class="line">Hello,  &lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.A&#x27;</span>&gt;</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>在上面，我们使用了 <code>classmethod</code> 装饰方法
<code>class_foo</code>，它就变成了一个类方法，<code>class_foo</code>
的参数是 <strong><code>cls</code>，代表类本身</strong>，当我们使用
<code>A.class_foo()</code> 时，cls 就会接收 A 作为参数。另外，被
<code>classmethod</code> 装饰的方法由于持有 cls
参数，因此我们可以在方法里面调用类的属性、方法，比如 cls.bar</p>
<p>上面的类方法是可以修改类的属性的，静态方法定义方式类似，但是不会改变类和实例状态；如下所示，静态方法没有
self 和 cls
参数，因此没法改变类的属性，可以把它看成是一个普通的函数，甚至可以把它写到类外面，但是有时候，类就是需要这么一类方法，如果写到外面，一是不利于类的完整性，二是不利于命名空间的整洁性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">static_foo</span>():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Hello&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = A()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.static_foo()</span><br><span class="line">Hello</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>A.static_foo()</span><br><span class="line">Hello</span><br></pre></td></tr></table></figure>
<p>那么，这两个方法该在什么时候使用呢？参考 <a
href="https://www.geeksforgeeks.org/class-method-vs-static-method-python/">class
method vs static method in Python</a> 如下</p>
<blockquote>
<p>We generally use class method to create factory methods. Factory
methods return class object ( similar to a constructor ) for different
use cases. We generally use static methods to create utility
functions.</p>
</blockquote>
<p>如下是个比较形象的例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Python program to demonstrate </span></span><br><span class="line"><span class="comment"># use of class method and static method. </span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>: </span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, age</span>): </span><br><span class="line">		self.name = name </span><br><span class="line">		self.age = age </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># a class method to create a Person object by birth year. </span></span><br><span class="line"><span class="meta">	@classmethod</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">fromBirthYear</span>(<span class="params">cls, name, year</span>): </span><br><span class="line">		<span class="keyword">return</span> cls(name, date.today().year - year) </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># a static method to check if a Person is adult or not. </span></span><br><span class="line"><span class="meta">	@staticmethod</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">isAdult</span>(<span class="params">age</span>): </span><br><span class="line">		<span class="keyword">return</span> age &gt; <span class="number">18</span></span><br><span class="line"></span><br><span class="line">person1 = Person(<span class="string">&#x27;mayank&#x27;</span>, <span class="number">21</span>) </span><br><span class="line">person2 = Person.fromBirthYear(<span class="string">&#x27;mayank&#x27;</span>, <span class="number">1996</span>) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> person1.age </span><br><span class="line"><span class="built_in">print</span> person2.age </span><br><span class="line"></span><br><span class="line"><span class="comment"># print the result </span></span><br><span class="line"><span class="built_in">print</span> Person.isAdult(<span class="number">22</span>) </span><br></pre></td></tr></table></figure>
<h2 id="魔法方法">魔法方法</h2>
<p>以双下划线 <code>__</code> 包裹起来的方法，比如最常见的
<code>__init__</code>，这些方法被称为魔法方法（magic
method）或特殊方法（special method）,这些方法可以给 Python
的类提供特殊功能，方便我们定制一个类。</p>
<h3 id="new__"><code>__new__</code></h3>
<p>在 Python 中，<strong>当我们创建一个类的实例时，类会先调用
<code>__new__(cls[, ...])</code> 来创建并返回实例，然后
<code>__init__</code>
方法再对该实例（self）中的变量进行初始化</strong>。</p>
<p>关于 <code>__new__</code> 和 <code>__init__</code>
有以下几点需要注意：</p>
<ol type="1">
<li><code>__new__</code> 是在 <code>__init__</code> 之前被调用的</li>
<li><code>__new__</code> 是类方法，<code>__init__</code> 是实例方法</li>
<li>重载 <code>__new__</code> 方法，需要返回类的实例</li>
</ol>
<p>一般情况下，我们不需要重载 <code>__new__</code>
方法。但在某些情况下，我们想控制实例的创建过程，这时可以通过重载
<code>__new__</code> 方法来实现。 比如说，下面的例子通过了
<code>__new__</code> 来实现单例模式</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    _instance = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__new__</span>(<span class="params">cls, *args, **kw</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> cls._instance:</span><br><span class="line">            cls._instance = <span class="built_in">super</span>(Singleton, cls).__new__(cls, *args, **kw)  </span><br><span class="line">        <span class="keyword">return</span> cls._instance  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span>(<span class="title class_ inherited__">Singleton</span>):  </span><br><span class="line">    a = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="str__-__repr__"><code>__str__</code> &amp;
<code>__repr__</code></h3>
<p>这两个方法主要是在直接打印类时候调用的，通过下面两个例子可以比较直观地看到如何使用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        self.name = name</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Foo object (name: %s)&#x27;</span> % self.name</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> Foo(<span class="string">&#x27;ethan&#x27;</span>)      <span class="comment"># 使用 print</span></span><br><span class="line">Foo <span class="built_in">object</span> (name: ethan)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">str</span>(Foo(<span class="string">&#x27;ethan&#x27;</span>))       <span class="comment"># 使用 str</span></span><br><span class="line"><span class="string">&#x27;Foo object (name: ethan)&#x27;</span></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Foo(<span class="string">&#x27;ethan&#x27;</span>)             <span class="comment"># 直接显示</span></span><br><span class="line">&lt;__main__.Foo at <span class="number">0x10c37a490</span>&gt;</span><br></pre></td></tr></table></figure>
<p>可以看到，<strong>使用 print 和 str 输出的是 <code>__str__</code>
方法返回的内容</strong>，但如果直接显示则不能，因为这个是
<code>__repr__</code> 方法负责的, 如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        self.name = name</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Foo object (name: %s)&#x27;</span> % self.name</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Foo(<span class="string">&#x27;ethan&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;Foo object (name: ethan)&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="iter__"><code>__iter__</code></h3>
<p>在某些情况下，我们希望实例对象可被用于 <code>for...in</code>
循环，这时我们需要在类中定义 <code>__iter__</code> 和
<code>next</code>（在 Python3 中是
<code>__next__</code>）方法，其中，<strong><code>__iter__</code>
返回一个迭代对象，<code>next</code>
返回容器的下一个元素</strong>，在没有后续元素时抛出
<code>StopIteration</code> 异常</p>
<p>如下是一个斐波那契数列的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):  <span class="comment"># 返回迭代器对象本身</span></span><br><span class="line">        <span class="keyword">return</span> self      </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self</span>):      <span class="comment"># 返回容器下一个元素</span></span><br><span class="line">        self.a, self.b = self.b, self.a + self.b</span><br><span class="line">        <span class="keyword">return</span> self.a    </span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fib = Fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> fib:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> i</span><br><span class="line">...</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<h3 id="getitem__-__setitem__-__delitem__"><code>__getitem__</code>
&amp; <code>__setitem__</code> &amp; <code>__delitem__</code></h3>
<p>有时，我们希望可以使用 <code>obj[n]</code>
这种方式对实例对象进行取值，比如对斐波那契数列，我们希望可以取出其中的某一项，这时我们需要在类中实现
<code>__getitem__</code> 方法，比如下面的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, n</span>):</span><br><span class="line">        a, b = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> xrange(n):</span><br><span class="line">            a, b = b, a + b</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fib = Fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fib[<span class="number">0</span>], fib[<span class="number">1</span>], fib[<span class="number">2</span>], fib[<span class="number">3</span>], fib[<span class="number">4</span>], fib[<span class="number">5</span>]</span><br><span class="line">(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<p>类似地，<code>__setitem__</code> 用于设置值，<code>__delitem__</code>
用于删除值，让我们看下面一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.coordinate = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">return</span> self.coordinate.get(key)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        self.coordinate[key] = value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__delitem__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">del</span> self.coordinate[key]</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;delete %s&#x27;</span> % key</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.coordinate)</span><br></pre></td></tr></table></figure>
<p>在上面，我们定义了一个 Point 类，它有一个属性
coordinate（坐标），是一个字典，让我们看看使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; p = Point()</span><br><span class="line">&gt;&gt;&gt; p[&#x27;x&#x27;] = 2    # 对应于 p.__setitem__(&#x27;x&#x27;, 2)</span><br><span class="line">&gt;&gt;&gt; p[&#x27;y&#x27;] = 5    # 对应于 p.__setitem__(&#x27;y&#x27;, 5)</span><br><span class="line">&gt;&gt;&gt; len(p)        # 对应于 p.__len__</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; p[&#x27;x&#x27;]        # 对应于 p.__getitem__(&#x27;x&#x27;)</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; del p[&#x27;x&#x27;]    # 对应于 p.__delitem__(&#x27;x&#x27;)</span><br><span class="line">&gt;&gt;&gt; len(p)</span><br><span class="line">1</span><br></pre></td></tr></table></figure>
<h3 id="call__"><code>__call__</code></h3>
<p>我们一般使用 obj.method()
来调用对象的方法，那能不能直接在实例本身上调用呢？在 Python
中，只要我们在类中定义 <code>__call__</code>
方法，就可以对实例进行调用，比如下面的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        self.x, self.y = x, y</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, z</span>):</span><br><span class="line">        <span class="keyword">return</span> self.x + self.y + z</span><br></pre></td></tr></table></figure>
<p>使用如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = Point(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">callable</span>(p)     <span class="comment"># 使用 callable 判断对象是否能被调用</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p(<span class="number">6</span>)            <span class="comment"># 传入参数，对实例进行调用，对应 p.__call__(6)</span></span><br><span class="line"><span class="number">13</span>                  <span class="comment"># 3+4+6</span></span><br></pre></td></tr></table></figure>
<h3 id="slots__"><code>__slots__</code></h3>
<p><code>__slots__</code>
跟前面的方法不太一样，因为这是一个类的属性，当我们创建了一个类的实例后，我们还可以给该实例绑定任意新的属性和方法，如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span>(<span class="title class_ inherited__">object</span>):    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x=<span class="number">0</span>, y=<span class="number">0</span></span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p = Point(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z = <span class="number">5</span>    <span class="comment"># 绑定了一个新的属性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.z</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p.__dict__</span><br><span class="line">&#123;<span class="string">&#x27;x&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;y&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;z&#x27;</span>: <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>
<p>这样其实是违背了 OOP
的封装性的理念，而且会消耗更多的内存，为了禁止这一属性，可以使用
<code>__slots__</code> 来告诉 Python
只给一个固定集合的属性分配空间，对上面的代码做一点改进，如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    __slots__ = (<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>)       <span class="comment"># 只允许使用 x 和 y</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x=<span class="number">0</span>, y=<span class="number">0</span></span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br></pre></td></tr></table></figure>
<p>我们给 <code>__slots__</code>
设置了一个元组，来限制类能添加的属性。现在，如果想绑定一个新的属性，就会出错了</p>
<h2 id="常量类">常量类</h2>
<p>在 Python 中使用常量一般来说有以下两种方式：</p>
<ol type="1">
<li>通过命名风格来提醒使用者该变量代表的意义为常量，如常量名所有字母大写，用下划线连接各个单词，PEP8
给出的编程风格就是这样的</li>
<li>通过自定义的类实现常量功能。这要求符合<strong>命名全部为大写</strong>和<strong>值一旦绑定便不可再修改</strong>
这两个条件。下面是一种较为常见的解决办法，将常量放到同一个文件中</li>
</ol>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># FileName：constant.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_const</span>:</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">ConstError</span>(<span class="title class_ inherited__">TypeError</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">ConstCaseError</span>(<span class="title class_ inherited__">ConstError</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setattr__</span>(<span class="params">self, name, value</span>):</span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> self.__dict__:</span><br><span class="line">            <span class="keyword">raise</span> self.ConstError, <span class="string">&quot;Can&#x27;t change const value!&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name.isupper():</span><br><span class="line">            <span class="keyword">raise</span> self.ConstCaseError, <span class="string">&#x27;const &quot;%s&quot; is not all letters are capitalized&#x27;</span> %name</span><br><span class="line">        self.__dict__[name] = value</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.modules[__name__] = _const()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> constant</span><br><span class="line">constant.MAX_COUNT = <span class="number">10</span></span><br><span class="line">constant.JOBS = <span class="number">5</span></span><br><span class="line">constant.PROCESSES = <span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>简单解释一下，对象的所有属性及属性的值都存储在 <code>__dict__</code>
中， 上面的 <code>__setattr__</code>
方法在对象每次创建新常量的时候会判断常量是否已经被定义过，如果已经定义过则
raise error，从而确保了已经创建的常量不可修改。</p>
<p><code>sys.modules[__name__] = _const()</code> 则确保了当上面的文件被
import 时，其 module 名称(也就是 <code>__name__</code>
的值，当文件被运行时 <code>__name__</code> 的值为 <code>__main__</code>,
被 import 时 <code>__name__</code> 的值则是 module 名称)对应的是一个
<code>_const()</code>
对象，从而可以直接通过其创建常量。因此，使用的方法如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import constant</span><br><span class="line">print(constant.MAX_COUNT)</span><br></pre></td></tr></table></figure>
<hr />
<p>参考：</p>
<p><a
href="https://www.geeksforgeeks.org/class-method-vs-static-method-python/">class
method vs static method in Python</a> <a
href="https://docs.python.org/3/reference/datamodel.html">Data model</a>
<a href="http://funhacks.net/explore-python/">Python 之旅</a></p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python中的多进程</title>
    <url>/2015/12/15/python%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<p>本文提到了python中实现多进程的几种方法（fork、multiprocessing、pool）以及进程间的简单通信。
<span id="more"></span></p>
<h2 id="fork函数">fork()函数</h2>
<p>Unix/Linux操作系统提供了一个<code>fork()</code>系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是<strong>fork()调用一次，返回两次</strong>，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。</p>
<p><strong>子进程永远返回0，而父进程返回子进程的ID</strong>。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。</p>
<p>Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># multiprocessing.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Parent Process (%s) start...&#x27;</span> % os.getpid()</span><br><span class="line">pid = os.fork()</span><br><span class="line"><span class="keyword">if</span> pid==<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;I am child process (%s) and my parent is %s.&#x27;</span> % (os.getpid(), os.getppid())</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;I (%s) just created a child process (%s).&#x27;</span> % (os.getpid(), pid)</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Parent Process (876) start...</span><br><span class="line">I (876) just created a child process (877).</span><br><span class="line">I am child process (877) and my parent is 876.</span><br></pre></td></tr></table></figure>
<p>由于<strong>Windows没有fork调用，上面的代码在Windows上无法运行</strong>。</p>
<p>有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。</p>
<h2 id="multiprocessing模块">multiprocessing模块</h2>
<p>如果你打算编写多进程的服务程序，Unix/Linux无疑是正确的选择。由于Windows没有fork调用，难道在Windows上无法用Python编写多进程的程序？</p>
<p>由于Python是跨平台的，自然也应该提供一个跨平台的多进程支持。<strong>multiprocessing模块就是跨平台版本的多进程模块。</strong></p>
<p>multiprocessing模块提供了一个Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="comment">#多进程</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span>  ctime,sleep</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子进程要执行的代码</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_proc</span>(<span class="params">name</span>):</span><br><span class="line">	<span class="built_in">print</span> <span class="string">&#x27;Run child process %s (%s),parent pid is (%s),start at %s...&#x27;</span> % (name, os.getpid(),os.getppid(),ctime())</span><br><span class="line">	sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">processes=[]</span><br><span class="line">p1 = Process(target=run_proc, args=(<span class="string">&#x27;p1&#x27;</span>,))</span><br><span class="line">processes.append(p1)</span><br><span class="line">p2=Process(target=run_proc,args=(<span class="string">&#x27;p2&#x27;</span>,))</span><br><span class="line">processes.append(p2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Parent Process pid(%s),start at %s...&#x27;</span> %(os.getpid(),ctime())</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">    	p.start()</span><br><span class="line">    	p.join()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;all over at %s&quot;</span> %ctime()</span><br></pre></td></tr></table></figure>
<p>上面的代码也是在Linux上执行（如果要在Windows下执行，可以去掉os的getppid()方法）执行结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Parent Process pid(30994),start at Tue Jan 12 10:37:48 2016...</span><br><span class="line">Run child process p1 (30995),parent pid is (30994),start at Tue Jan 12 10:37:48 2016...</span><br><span class="line">Run child process p2 (31013),parent pid is (30994),start at Tue Jan 12 10:37:50 2016...</span><br><span class="line">all over at Tue Jan 12 10:37:52 2016</span><br></pre></td></tr></table></figure>
<p>创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单。</p>
<p><strong>join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。</strong></p>
<p>如何理解上面这句话？将上面的代码中的<code>p.join()</code>去掉，执行结果如下：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Parent Process pid(31038),start at Tue Jan 12 10:39:27 2016...</span><br><span class="line">all over at Tue Jan 12 10:39:27 2016</span><br><span class="line">Run child process p1 (31039),parent pid is (31038),start at Tue Jan 12 10:39:27 2016...</span><br><span class="line">Run child process p2 (31040),parent pid is (31038),start at Tue Jan 12 10:39:27 2016...</span><br></pre></td></tr></table></figure>
从输出可以看到父进程还没等子进程结束就执行了最后的<code>print "all over at %s" %ctime()</code>语句，而且两个子进程的开始执行时间也相同。</p>
<h2 id="pool模块">Pool模块</h2>
<p>如果要启动大量的子进程，可以用<strong>进程池的方式</strong>批量创建子进程：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#进程池</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> os, time, random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">child_task</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Child Process %s (%s) starts&#x27;</span> % (name, os.getpid())</span><br><span class="line">    start = time.time()</span><br><span class="line">    time.sleep(random.random() * <span class="number">2</span>)</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Child Process %s runs %0.2f seconds.&#x27;</span> % (name, (end - start))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Parent Process %s starts&#x27;</span> % os.getpid()</span><br><span class="line">    p = Pool()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        p.apply_async(child_task, args=(i,))</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Waiting for all subprocesses done...&#x27;</span></span><br><span class="line">    p.close()</span><br><span class="line">    p.join()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;All subprocesses done.&#x27;</span></span><br></pre></td></tr></table></figure>
<p>执行结果如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Parent Process 6028 starts</span><br><span class="line">Waiting for all subprocesses done...</span><br><span class="line">Child Process 0 (6448) starts</span><br><span class="line">Child Process 1 (6912) starts</span><br><span class="line">Child Process 2 (5176) starts</span><br><span class="line">Child Process 3 (7676) starts</span><br><span class="line">Child Process 2 runs 0.86 seconds.</span><br><span class="line">Child Process 4 (5176) starts</span><br><span class="line">Child Process 3 runs 0.98 seconds.</span><br><span class="line">Child Process 0 runs 1.80 seconds.</span><br><span class="line">Child Process 4 runs 1.97 seconds.</span><br><span class="line">All subprocesses done.</span><br></pre></td></tr></table></figure> 代码解读：</p>
<p>对Pool对象调用join()方法会等待所有子进程执行完毕，<strong>调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了</strong>。</p>
<p>请注意输出的结果，Child Process 0，1，2，3是立刻执行的，而Child
Process要等待前面某个Child
Process完成后才执行，这是因为<strong>Pool的默认大小是CPU的核数，如果你不幸拥有8核CPU，你要提交至少9个子进程才能看到上面的等待效果。</strong>我的笔记本是四核的，所以创建五个进程的时候有一个需要等待。</p>
<p>但是如果只有一核，输出会如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Parent Process 32075 starts</span><br><span class="line">Waiting for all subprocesses done...</span><br><span class="line">Child Process 0 (32076) starts</span><br><span class="line">Child Process 0 runs 1.99 seconds.</span><br><span class="line">Child Process 1 (32076) starts</span><br><span class="line">Child Process 1 runs 0.39 seconds.</span><br><span class="line">Child Process 2 (32076) starts</span><br><span class="line">Child Process 2 runs 0.75 seconds.</span><br><span class="line">Child Process 3 (32076) starts</span><br><span class="line">Child Process 3 runs 0.98 seconds.</span><br><span class="line">Child Process 4 (32076) starts</span><br><span class="line">Child Process 4 runs 1.97 seconds.</span><br><span class="line">All subprocesses done.</span><br></pre></td></tr></table></figure>
<p>这是Pool有意设计的限制，并不是操作系统的限制。如果改成：<code>p = Pool(5)</code>就可以同时跑5个进程。</p>
<h2 id="进程间通信">进程间通信</h2>
<p>Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了<code>Queue、Pipes</code>等多种方式来交换数据。</p>
<p>我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="comment">#进程间的通信s</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue</span><br><span class="line"><span class="keyword">import</span> os, time, random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写数据进程执行的代码:</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write</span>(<span class="params">q</span>):</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>]:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Put %s to queue...&#x27;</span> % value</span><br><span class="line">        q.put(value)</span><br><span class="line">        time.sleep(random.random()*<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读数据进程执行的代码:</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">q</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        value = q.get(<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Get %s from queue.&#x27;</span> % value</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 父进程创建Queue，并传给各个子进程：</span></span><br><span class="line">    q = Queue()</span><br><span class="line">    pw = Process(target=write, args=(q,))</span><br><span class="line">    pr = Process(target=read, args=(q,))</span><br><span class="line">    <span class="comment"># 启动子进程pw，写入:</span></span><br><span class="line">    pw.start()</span><br><span class="line">    <span class="comment"># 启动子进程pr，读取:</span></span><br><span class="line">    pr.start()</span><br><span class="line">    <span class="comment"># 等待pw结束:</span></span><br><span class="line">    pw.join()</span><br><span class="line">    <span class="comment"># pr进程里是死循环，无法等待其结束，只能强行终止:</span></span><br><span class="line">    pr.terminate()</span><br></pre></td></tr></table></figure>
<p>运行结果如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Put A to queue...</span><br><span class="line">Get A from queue.</span><br><span class="line">Put B to queue...</span><br><span class="line">Get B from queue.</span><br><span class="line">Put C to queue...</span><br><span class="line">Get C from queue.</span><br></pre></td></tr></table></figure></p>
<p>在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过<strong>pickle序列化</strong>再传到子进程去，所有，<strong>如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了</strong>。</p>
<h2 id="小结">小结</h2>
<ul>
<li><p>在Unix/Linux下，可以使用fork()调用实现多进程。</p></li>
<li><p>要实现跨平台的多进程，可以使用multiprocessing模块。</p></li>
<li><p>进程间通信是通过Queue、Pipes等实现的。</p></li>
</ul>
<p>参考：<a
href="http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/0013868323401155ceb3db1e2044f80b974b469eb06cb43000">多进程</a></p>
]]></content>
      <categories>
        <category>python</category>
        <category>并行编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>python中的模块与包</title>
    <url>/2015/12/19/python%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/</url>
    <content><![CDATA[<p>文章为转载，原文见<a
href="http://docspy3zh.readthedocs.org/en/latest/tutorial/modules.html">这里</a>，侵删</p>
<p>python中的Module是比较重要的概念。常见的情况是，事先写好一个<code>.py</code>文
件，<strong>在另一个文件中需要 import 时，将事先写好的.py文件拷贝
到当前目录，或者是在<code>sys.path</code>中增加事先写好的.py文件所在的目录，然后import。</strong>这样的做法，对于少数文件是可行的，但如果<strong>程序数目很
多，层级很复杂</strong>，就很吃力了。</p>
<p>有没有办法，像Java的Package一样，将多个.py文件组织起来，以便在外部统一调用，和在内部互相调用呢？答案是有的。</p>
<span id="more"></span>
<p>主要是用到python的包的概念，python
<code>__init__.py</code>在包里起一个比较重要的作用</p>
<p>要弄明白这个问题，首先要知道，python在执行import语句时，到底进行了什么操作，按照python的文档，它执行了如下操作：
第1步，创建一个新的，空的module对象（它可能包含多个module）；
第2步，把这个module对象插入sys.module中
第3步，装载module的代码（如果需要，首先必须编译）
第4步，执行新的module中对应的代码。</p>
<p>在执行第3步时，首先要找到module程序所在的位置，搜索的顺序是：<strong>当前路径
（以及从当前目录指定的sys.path）-&gt;然后是PYTHONPATH-&gt;然后是python的安装设置相关的默认路径</strong>。</p>
<p>正因为存在这样的顺序，<strong>如果当前
路径或PYTHONPATH中存在与标准module同样的module，则会覆盖标准module。</strong>也就是说，如果当前目录下存在xml.py，那么执
行import xml时，导入的是当前目录下的module，而不是系统标准的xml。</p>
<p>了解了这些，我们就可以先构建一个package，以普通module的方式导入，就可以直接访问此package中的各个module了。</p>
<p>Python中的package定义很简单，其层次结构与程序所在目录的层次结构相同，这一点与Java类似，唯一不同的地方在于，python中的package必须包含一个__init__.py的文件。
例如，我们可以这样组织一个package:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">package1/</span><br><span class="line">    __init__.py</span><br><span class="line">    subPack1/</span><br><span class="line">        __init__.py</span><br><span class="line">        module_11.py</span><br><span class="line">        module_12.py</span><br><span class="line">        module_13.py</span><br><span class="line">    subPack2/</span><br><span class="line">        __init__.py</span><br><span class="line">        module_21.py</span><br><span class="line">        module_22.py</span><br><span class="line">    ……</span><br></pre></td></tr></table></figure>
<p><strong><code>__init__.py</code>可以为空，但是必须要存在，只要它存在，就表明此目录应被作为一个package处理。</strong>当然，<strong>init</strong>.py中也可以设置相应的内容，下文详细介绍。</p>
<p>好了，现在我们在module_11.py中定义一个函数：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">funA</span>():</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;funcA in module_11&quot;</span></span><br><span class="line">    <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>在顶层目录（也就是package1所在的目录，当然也参考上面的介绍，将package1放在解释器能够搜索到的地方）运行python:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">from</span> package1.subPack1.module_11 <span class="keyword">import</span> funcA</span><br><span class="line">&gt;&gt;&gt;funcA()</span><br><span class="line">funcA <span class="keyword">in</span> module_11</span><br></pre></td></tr></table></figure>
<p>这样，我们就按照package的层次关系，正确调用了module_11中的函数。</p>
<p>有时在import语句中会出现通配符*，<strong>导入某个module中的所有元素</strong>，这是怎么实现的呢？</p>
<p>答案就在__init__.py中。我们在subPack1的__init__.py文件中写</p>
<p><code>__all__ = ['module_13', 'module_12']</code></p>
<p>然后进入python <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">from</span> package1.subPack1 <span class="keyword">import</span> *</span><br><span class="line">&gt;&gt;&gt;module_11.funcA()</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">ImportError: No module named module_11</span><br></pre></td></tr></table></figure></p>
<p>也就是说，**以*导入时，package内的module是受<code>__init__.py</code>中的<code>__all__</code>列表限制的**。</p>
<p>为了避免<code>import</code>后面跟的层级过长，可以在<code>__init__.py</code>中先导入所需的module。比如上面的例子可以改为下面所示</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#package1的 __init__.py</span></span><br><span class="line"><span class="keyword">from</span> subPack1 <span class="keyword">import</span> *</span><br><span class="line">__all__=[<span class="string">&#x27;module_11&#x27;</span>,<span class="string">&#x27;module_13&#x27;</span>]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;<span class="keyword">from</span> package1 <span class="keyword">import</span> *</span><br><span class="line">&gt;&gt;&gt;module_11.funcA()</span><br><span class="line">funcA <span class="keyword">in</span> module_11</span><br><span class="line">&gt;&gt;&gt;module_12.funcA()</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">ImportError: No module named module_12</span><br></pre></td></tr></table></figure>
<p>下面看一下package内部互相调用</p>
<p>如果希望调用同一个package中的module，则直接import即可。也就是说，在module_12.py中，可以直接使用</p>
<p><code>import module_11</code></p>
<p>如果<strong>不在同一个package中</strong>，例如我们希望在module_21.py中调用module_11.py中的FuncA，则应该这样：</p>
<p><code>from module_11的包名.module_11 import funcA</code></p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python语法杂记</title>
    <url>/2016/05/23/python%20%E8%AF%AD%E6%B3%95%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要记录一些学习过程中遇到的一些比较零碎的python语法知识。
<span id="more"></span></p>
<h2 id="常见易错用法">常见易错用法</h2>
<h3 id="for循环中修改下标的值">for循环中修改下标的值</h3>
<p>python中的for循环一般会写成这样 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    ....</span><br></pre></td></tr></table></figure>
上面的语句中循环了10此，i的值从0增到9。在<strong>Java中可以在for循环中修改i的值，从而跳过一些i的值不处理</strong>，但是在上面的语法中无效,因为range实际上生成了一个0到9的list，每次i会取其中的一个值，所以如果没有break的话，i会取遍10个值。</p>
<p>如果要达到修改i的值跳过一些值不处理，建议使用<code>while</code>语句。</p>
<h2 id="字典">字典</h2>
<h3 id="初始化">初始化</h3>
<p>可通过<code>&#123;&#125;</code>或<code>dict()</code>函数进行初始化，通过<code>dict()</code>初始化时，可以选择是否传入参数，传入参数初始化时，参数格式为包含若干kv的一个list，每个kv用一个tuple表示，如
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;d = <span class="built_in">dict</span>(</span><br><span class="line">    [(<span class="string">&#x27;foozelator&#x27;</span>, <span class="number">123</span>),</span><br><span class="line">     (<span class="string">&#x27;frombicator&#x27;</span>, <span class="number">18</span>), </span><br><span class="line">     (<span class="string">&#x27;spatzleblock&#x27;</span>, <span class="number">34</span>), </span><br><span class="line">     (<span class="string">&#x27;snitzelhogen&#x27;</span>, <span class="number">23</span>)</span><br><span class="line">    ])</span><br><span class="line">&gt;&gt;&gt;d</span><br><span class="line">&#123;<span class="string">&#x27;foozelator&#x27;</span>: <span class="number">123</span>, <span class="string">&#x27;frombicator&#x27;</span>: <span class="number">18</span>, <span class="string">&#x27;snitzelhogen&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;spatzleblock&#x27;</span>: <span class="number">34</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="删除一个key">删除一个key</h3>
<p>－　从字典中删除一个key：<code>dict.pop(key[, default])</code>,存在key时返回key对应的value，不存在时返回default。不存在且没有default时返回KeyError。</p>
<h3 id="遍历字典">遍历字典</h3>
<ul>
<li><code>dict.keys()</code>返回字典dict所有keys组成的一个<strong>list</strong></li>
<li><code>dict.values()</code>返回字典dict所有values组成的一个<strong>list</strong></li>
<li><code>dict.items()</code>返回字典dict所有kv组成的一个<strong>list</strong>，kv以tuple的形式存储</li>
</ul>
<h3 id="对字典排序">对字典排序</h3>
<p>通过sorted函数可以根据字典的key或value对字典排序，并返回一个元素类型为tuple为的list，每个tuple代表字典中的一个元素。排序不会改变原来字典中的值。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">a = &#123;<span class="number">1</span>:<span class="number">2</span>,<span class="number">2</span>:<span class="number">1</span>&#125;</span><br><span class="line"><span class="comment"># 根据key对字典排序,reverse = True表示从大到小，默认是从小到大</span></span><br><span class="line"><span class="built_in">sorted</span>(a.items(), key = <span class="keyword">lambda</span> x:x[<span class="number">0</span>], reverse = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 输出为[(2,1),(1,2)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据value对字典从小到大排序</span></span><br><span class="line"><span class="built_in">sorted</span>(a.items(), key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 输出为[(2:1),(1:2)]</span></span><br></pre></td></tr></table></figure>
<h2 id="集合">集合</h2>
<h3 id="可变集合">可变集合</h3>
<p>用{}或set()函数来生成可变集合，集合中不含有相同元素。 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">s=&#123;&#125; <span class="comment"># 非法</span></span><br><span class="line">s=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125; <span class="comment"># 合法</span></span><br><span class="line">s=<span class="built_in">set</span>() <span class="comment"># 也可用s = set(list),用一个集合提取list中的不重复元素</span></span><br></pre></td></tr></table></figure>
### 不可变集合
对应于元组（tuple）与列表（list）的关系，对于集合（set），Python提供了一种叫做不可变集合（frozen
set）的数据结构。</p>
<p>创建一个不可变集合 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;s = <span class="built_in">frozenset</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>])</span><br><span class="line">&gt;&gt;&gt;s</span><br><span class="line"><span class="built_in">frozenset</span>(&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">&#x27;a&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
不可变集合的一个主要应用是用来作为字典的键，例如用一个字典来记录两个城市之间的距离：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;flight_distance = &#123;&#125;</span><br><span class="line">&gt;&gt;&gt;city_pair = <span class="built_in">frozenset</span>([<span class="string">&#x27;Los Angeles&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>])</span><br><span class="line">&gt;&gt;&gt;flight_distance[city_pair] = <span class="number">2498</span></span><br><span class="line">&gt;&gt;&gt;flight_distance[<span class="built_in">frozenset</span>([<span class="string">&#x27;Austin&#x27;</span>, <span class="string">&#x27;Los Angeles&#x27;</span>])] = <span class="number">1233</span></span><br><span class="line">&gt;&gt;&gt;flight_distance[<span class="built_in">frozenset</span>([<span class="string">&#x27;Austin&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>])] = <span class="number">1515</span></span><br><span class="line">&gt;&gt;&gt;flight_distance</span><br><span class="line">&#123;<span class="built_in">frozenset</span>(&#123;<span class="string">&#x27;Austin&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>&#125;): <span class="number">1515</span>,</span><br><span class="line"> <span class="built_in">frozenset</span>(&#123;<span class="string">&#x27;Austin&#x27;</span>, <span class="string">&#x27;Los Angeles&#x27;</span>&#125;): <span class="number">1233</span>,</span><br><span class="line"> <span class="built_in">frozenset</span>(&#123;<span class="string">&#x27;Los Angeles&#x27;</span>, <span class="string">&#x27;New York&#x27;</span>&#125;): <span class="number">2498</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="集合的一些方法">集合的一些方法</h3>
<ul>
<li>添加元素，<code>s.add(item)</code></li>
<li>交集，<code>s1&amp;s2</code>或<code>s1.intersection(s2)</code>,返回集合s1和集合s2的交集</li>
<li>并集，<code>s1|s2</code>或<code>s1.union(s2)</code>,返回集合s1和集合s2的并集</li>
<li>差集，<code>s1-s2</code>或<code>s1.defference(s2)</code>返回s1中有但s2中没有的元素的集合</li>
<li>对称差集,<code>s1^s2</code>或<code>s1.symmetric_difference(s2)</code>返回s1中有但s2中没有的元素和s2中有但s1中没有的元素的合集</li>
<li>子集，<code>s1.issubset(s2)</code>或<code>s1&lt;=s2</code>判断s1是否s2的子集；反之也可用<code>s2.issuperset(s1)</code>达到上面的效果</li>
<li>删除一个元素<code>s.remove(element)</code>或<code>s.pop(element)</code>后者会返回这个值元素的值而前者不会；不存在该元素时均会报错。<code>s.discard(element)</code>作用跟remove一样，区别在于<strong>不存在该元素时discard()不会报错</strong></li>
</ul>
<h2 id="列表">列表</h2>
<h3 id="列表合并">列表合并</h3>
<p>可通过加号<code>+</code>按顺序合并两个列表，如 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">&gt;&gt;&gt;b = [<span class="number">3.2</span>, <span class="string">&#x27;hello&#x27;</span>]</span><br><span class="line">&gt;&gt;&gt;a + b</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3.2</span>, <span class="string">&#x27;hello&#x27;</span>]</span><br></pre></td></tr></table></figure>
列表的<code>extend()</code>方法也能实现相同功能。如： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;a = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">&gt;&gt;&gt;b = [<span class="number">3.2</span>, <span class="string">&#x27;hello&#x27;</span>]</span><br><span class="line">&gt;&gt;&gt;a.extend(b)</span><br><span class="line">&gt;&gt;&gt;a</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3.2</span>, <span class="string">&#x27;hello&#x27;</span>]</span><br></pre></td></tr></table></figure></p>
<h3 id="列表排序">列表排序</h3>
<p>列表可用内置函数，分为两种类型：<strong>排序后改变原列表和排序后不改变列表</strong></p>
<p>排序后改变原列表的方法是<code>listName.sort()</code>,不改变原列表的方法是<code>sorted(listName)</code>。具体见下面例子
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;s = [<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]</span><br><span class="line">&gt;&gt;&gt;s.sort()</span><br><span class="line">&gt;&gt;&gt;s</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">&gt;&gt;&gt;s = [<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]</span><br><span class="line">&gt;&gt;&gt;<span class="built_in">sorted</span>(s)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">&gt;&gt;&gt;s</span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>
默认是从小到大排序，也可从大到小排序，只需要加入<code>reverse=True</code>的参数即可
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;s=[<span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">&gt;&gt;&gt;<span class="built_in">sorted</span>(s,reverse=<span class="literal">True</span>)</span><br><span class="line">[<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">&gt;&gt;&gt;s</span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br><span class="line">&gt;&gt;&gt;s.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">&gt;&gt;&gt;s</span><br><span class="line">[<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<h3 id="列表推导式list-comprehension">列表推导式(List
comprehension)</h3>
<p>也叫列表生成式。</p>
<p>将多条语句写成一条，如要求列表a中所有偶数的和，可写成 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">sum</span>([i <span class="keyword">for</span> i <span class="keyword">in</span> a <span class="keyword">if</span> i%<span class="number">2</span>==<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
sum()是求一个<strong>列表</strong>内所有元素的和的内置函数，传入的参可以为一个列表，而<code>[i for i in a if i%2==0]</code>则是列表推导式，该语句生成了列表[2,4,6]</p>
<p>但是，<strong>Python会生成这个列表，然后再将它放到垃圾回收机制中</strong>（因为没有变量指向它），这毫无疑问是种浪费。</p>
<p>为了解决这种问题，与<code>rang()</code>和<code>xrange()</code>的问题类似，Python使用生成器（<a
href="http://pythoncentral.io/python-generators-and-yield-keyword/">generator</a>）表达式来解决这个问题：</p>
<p>将sum中代表list的括号去掉即可，修改后如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">sum</span>(i <span class="keyword">for</span> i <span class="keyword">in</span> a <span class="keyword">if</span> i%<span class="number">2</span>==<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
上面的<code>(i for i in a if i%2==0)</code>就是一个生成器，<strong>与列表生成式最大的不同是列表生成式会在执行语句的时候生成完整的列表，而生成器会在在循环的过程中不断推算出后续的元素</strong></p>
<p>除了上面这种定义生成器的方法，还可以在函数中通过<code>yield</code>关键字实现一个生成器。如下面生成斐波那契数列的例子：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_fibona</span>(<span class="params">n</span>):</span><br><span class="line">    a,b=<span class="number">0</span>,<span class="number">1</span>,</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">yield</span> b</span><br><span class="line">        a,b = b,a+b</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> print_fibona(<span class="number">8</span>):</span><br><span class="line">    <span class="built_in">print</span> i,</span><br></pre></td></tr></table></figure> 输出结果为： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 1 2 3 5 8 13 21</span><br></pre></td></tr></table></figure>
<code>print_fibona</code>不是普通函数，而是generator，在执行过程中，遇到yield就中断，下次又继续执行。</p>
<h3 id="列表的其他一些方法">列表的其他一些方法</h3>
<ul>
<li>查找某一元素在列表中出现了几次，<code>list.count(element)</code>返回element在list中出现的次数</li>
<li>查找某一元素在列表中第一次出现的位置，<code>list.index(element)</code>返回element在list中第一次出现的位置,不存在element元素时会报错</li>
<li>在特定位置插入某一元素，其他元素依次往后移动一步，<code>list.insert(index,element)</code>在index处插入element，原来在index处及后面的元素依次往后移动一位</li>
<li>删除元素，有两种方法，<code>list.remove(element)</code>会将list中第一次出现的element删除；<code>list.pop(index)</code>则会将list中下标为index的元素删除且返回该元素的值。</li>
<li>列表反转，<code>list.reverse()</code>回将list中的元素反转</li>
</ul>
<h3 id="map方法生成序列">map方法生成序列</h3>
<p>可以通过 map 的方式利用函数来生成序列,例子如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sqr</span>(<span class="params">x</span>): </span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">a = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">map</span>(sqr, a)</span><br></pre></td></tr></table></figure>
<p>输出为 <code>[4, 9, 16]</code></p>
<p>其用法为<code>map(aFun, aSeq)</code>,将函数 <code>aFun</code>
应用到序列 <code>aSeq</code>
上的每一个元素上，返回一个列表，不管这个序列原来是什么类型。</p>
<p>事实上，根据函数参数的多少，map
可以接受多组序列，将其对应的元素作为参数传入函数,例子如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">x, y</span>): </span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line"></span><br><span class="line">a = (<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">b = [<span class="number">10</span>,<span class="number">5</span>,<span class="number">3</span>]</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">map</span>(add,a,b)</span><br></pre></td></tr></table></figure> 结果为<code>[12, 8, 7]</code></p>
<h3 id="序列赋值">序列赋值</h3>
<p>序列（list,tuple,str)可以将其值逐一赋值给变量，详见下面的例子
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a,b,c=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> a,b,c</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a,b,c=(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> a,b,c</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a,b,c=<span class="string">&quot;123&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> a,b,c</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<h2 id="数值">数值</h2>
<h3 id="整形int和长整形long">整形（int）和长整形（long）</h3>
<p>整型数字的最大最小值</p>
<ul>
<li>在 32 位系统中，一个整型 4 个字节，最小值 -2,147,483,648，最大值
2,147,483,647。</li>
<li>在 64 位系统中，一个整型 8 个字节，最小值
-9,223,372,036,854,775,808，最大值 9,223,372,036,854,775,807。</li>
</ul>
<p>当<strong>整型超出范围时，Python会自动将整型转化为长整型</strong>，长整型就是在数字后面加上一个大写的<code>L</code></p>
<h3 id="复数">复数</h3>
<p>Python 使用 j 来表示复数的虚部： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">a = <span class="number">1</span> + <span class="number">2j</span></span><br><span class="line"><span class="built_in">type</span>(a)</span><br><span class="line">a.real <span class="comment"># 实部</span></span><br><span class="line">a.imag <span class="comment"># 虚部</span></span><br><span class="line">a.conjugate() <span class="comment"># 共轭</span></span><br></pre></td></tr></table></figure> ###
内置的一些数值函数 <code>abs(n)</code>求n的绝对值
<code>round(n)</code>求n的整数部分，返回的是float类型
<code>max(n,m)</code>求m，n的最大值
<code>min(n,m)</code>求m,n的最小值</p>
<h3 id="其他的一些表示方法">其他的一些表示方法</h3>
<ul>
<li><strong>科学计数法</strong>，<code>1e-6</code>表示 <span
class="math inline">\(10^{-6}\)</span></li>
<li><strong>16进制</strong>，前面加上<code>0x</code>修饰，后面的数字范围为0~F</li>
<li><strong>8进制</strong>，前面加上<code>0</code>修饰，后面的数字范围为0~7</li>
<li><strong>2进制</strong>，前面加上<code>0b</code>修饰，后面数字范围为0~1</li>
</ul>
<h2 id="字符串">字符串</h2>
<h3 id="常用的字符串方法">常用的字符串方法</h3>
<ul>
<li><code>s.split(c)</code>,以符号c为分隔符将字符串s分割，返回<strong>字符串列表</strong></li>
<li><code>c.join(sList)</code>，作用跟上面的相反，以符号c为连接符将字符串数组sList连接起来</li>
<li><code>s.repalce(a,b)</code>,将字符串中的a替换为b，并返回替换后的字符串，注意<strong>s本身不变</strong></li>
<li><code>s.upper()</code>，将s中的英文字母转为大写的并返回，但是<strong>s本身不变</strong></li>
<li><code>s.lower()</code>，将s中的英文字母转为小写的并返回，但是<strong>s本身不变</strong></li>
<li><code>s.strip()</code>，去掉字符串s前后的空格并返回，但是<strong>s本身不变</strong>
<ul>
<li><code>s.lstrip()</code>，去掉字符串s前的空格并返回，但是<strong>s本身不变</strong></li>
<li><code>s.rstrip()</code>，去掉字符串s后的空格并返回，但是<strong>s本身不变</strong>
可通过<code>dir(str)</code>查找更多方法</li>
</ul></li>
</ul>
<h3 id="数字与字符的转换">数字与字符的转换</h3>
<h4 id="整数转字符串">整数转字符串</h4>
<ul>
<li>16进制：<code>hex(255)</code>返回'0xff'</li>
<li>8进制：<code>oct(255)</code>返回'0377'</li>
<li>2进制：<code>bin(255)</code>返回'0b11111111'</li>
</ul>
<h4 id="字符串转整数">字符串转整数</h4>
<p>通过<code>int(s)</code>转换，还可以指定特定的进制，默认是十进制。如下面的方法均返回255</p>
<ul>
<li>int('ff',16)</li>
<li>int('377',8)</li>
<li>int('111111111',2)</li>
<li>int('255')</li>
</ul>
<h4 id="ascii码与字符的转换">ASCII码与字符的转换</h4>
<ul>
<li>数字转ASCII码：<code>chr(97) --&gt; 'a'</code></li>
<li>ASCII码转数字：<code>ord('A') --&gt; 65</code></li>
</ul>
<h3 id="字符串的分片与索引">字符串的分片与索引</h3>
<p><strong>索引</strong>指的是可以通过下标来寻找字符串中的某个字符，0下标代表第一个，-1下标代表倒数第一个，-2下标代表倒数第二个</p>
<p><strong>分片</strong>指的是提取子字符串，一般格式为<code>[start:end:step]</code>,<strong>start和end都是指字符串的下标</strong>，省略时默认为字符串的头和尾；step指每次取字符串的步长，省略时为1，也即是<strong>从start到end-1每个字符串都取</strong>，step也可取负值，表示从后往前按step的绝对值来取。如<code>s[::-1]</code>表示反转字符串</p>
<h2 id="函数">函数</h2>
<h3 id="高阶函数higher-order-function">高阶函数（Higher-order
function）</h3>
<p><strong>把另外一个函数作为参数传入</strong>的函数称为高阶函数，<strong>函数式编程</strong>就是指这种高度抽象的编程范式。</p>
<h3 id="mapreduce-函数">map/reduce 函数</h3>
<ul>
<li>map函数：<strong>两个参数，第一个参数为接收一个参数的函数，第二个参数为一个序列</strong>，利用第一个参数所代表的函数对序列中的每个元素操作，返回操作后的序列</li>
<li>reduce函数：<strong>两个参数，第一个参数为接收两个参数的函数，第二个参数为一个序列</strong>，利用第一个参数代表的函数对序列中的两个首元素操作，返回的结果与序列的下一元素再进行函数的操作，直到遍历完序列。</li>
</ul>
<p>例子： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用map函数对列表中每个数进行平方操作</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">map</span>(<span class="keyword">lambda</span> x:x**<span class="number">2</span>,[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">[<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用reduce函数实现sum()函数的功能</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce((<span class="keyword">lambda</span> x,y:x+y),[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line"><span class="number">15</span></span><br></pre></td></tr></table></figure>
上面均利用了<code>lambda</code>函数，也可以将lambda函数改成<code>def</code>定义好的函数。</p>
<h3 id="filter函数">filter函数</h3>
<p>Python内建的filter()函数用于过滤序列。
和map()类似，filter()也接收一个函数和一个序列。和map()不同的时，filter()把传入的函数依次作用于每个元素，然后根据<strong>返回值是True还是False</strong>决定保留还是丢弃该元素。</p>
<p>例子：过滤掉1~100中的素数并返回结果 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_prime</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="built_in">int</span>(math.sqrt(num))+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> num%i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">filter</span>(is_prime,<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>))</span><br></pre></td></tr></table></figure></p>
<h3 id="sorted函数">sorted函数</h3>
<p>sorted函数除了可以用来给列表排序外，还可以通过排序函数作为传入参数，进行指定的排序。</p>
<p><strong>排序函数通常规定，对于两个元素x和y，如果认为x &lt;
y，则返回-1或负数，如果认为x == y，则返回0，如果认为x &gt;
y，则返回1或正数</strong>。python内部定义的排序函数规则就是这样的，根据这样的原理，我们可以自定义一个排序函数进行降序排序。例子如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">descend_sort</span>(<span class="params">x,y</span>):</span><br><span class="line">    <span class="keyword">if</span> x&gt;y:</span><br><span class="line">        <span class="keyword">return</span>  -<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">sorted</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">101</span>),descend_sort)</span><br></pre></td></tr></table></figure>
<p>上面的代码也可以简单写成<code>sorted(range(1,101),lambda x,y:y-x)</code></p>
<h3 id="返回函数">返回函数</h3>
<p>高阶函数除了可以接受函数作为参数外，还可以把函数作为结果值返回
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lazy_sum</span>(<span class="params">*args</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sum</span>():</span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> args:</span><br><span class="line">            s+=i</span><br><span class="line">        <span class="keyword">return</span> s</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br></pre></td></tr></table></figure></p>
<p>调用lazy_sum()时，返回的并不是求和结果，而是求和函数：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = lazy_sum(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f</span><br><span class="line">&lt;function <span class="built_in">sum</span> at <span class="number">0x10452f668</span>&gt;</span><br></pre></td></tr></table></figure>
<p>调用函数f时，才真正计算求和的结果：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>f()</span><br><span class="line"><span class="number">25</span></span><br></pre></td></tr></table></figure>
<p>在这个例子中，我们在函数<code>lazy_sum</code>中又定义了函数<code>sum</code>，并且，内部函数<code>sum</code>可以引用外部函数<code>lazy_sum</code>的参数和局部变量，当<code>lazy_sum</code>返回函数<code>sum</code>时，相关参数和变量都保存在返回的函数中，这种程序称为<strong><a
href="https://zh.wikipedia.org/wiki/%E9%97%AD%E5%8C%85_%28%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%29">闭包（Closure）</a></strong></p>
<p>另一个需要注意的问题是，返回的函数并没有立刻执行，而是直到调用了f()才执行。例子如下
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">count</span>():</span><br><span class="line">    fs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">f</span>():</span><br><span class="line">             <span class="keyword">return</span> i*i</span><br><span class="line">        fs.append(f)</span><br><span class="line">    <span class="keyword">return</span> fs</span><br><span class="line"></span><br><span class="line">f1, f2, f3 = count()</span><br></pre></td></tr></table></figure>
在上面的例子中，每次循环，都创建了一个新的函数，然后，把创建的3个函数都返回了。</p>
<p>你可能认为调用f1( )，f2( )和f3( )结果应该是1，4，9，但实际结果是：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="built_in">print</span>  f1(),f2(),f3()</span><br><span class="line"><span class="number">9</span> <span class="number">9</span> <span class="number">9</span></span><br></pre></td></tr></table></figure>
全部都是9！原因就在于返回的函数引用了变量i，但它并非立刻执行。等到3个函数都返回时，它们所引用的变量i已经变成了3，因此最终结果为9。</p>
<p>返回闭包时牢记的一点就是：<strong>返回函数不要引用任何循环变量，或者后续会发生变化的变量。</strong></p>
<p>如果一定要引用循环变量怎么办？方法是<strong>再创建一个函数</strong>，用该函数的参数绑定循环变量当前的值，无论该循环变量后续如何更改，已绑定到函数参数的值不变.如下面的例子
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">count</span>():</span><br><span class="line">    fs = [<span class="keyword">lambda</span> x=y:x**<span class="number">2</span> <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">4</span>)]</span><br><span class="line">    <span class="keyword">return</span> fs</span><br><span class="line"></span><br><span class="line">f1,f2,f3 = count()</span><br><span class="line"><span class="built_in">print</span> f1(),f2(),f3()</span><br></pre></td></tr></table></figure> 最后打印出来的结果是<code>1 4 9</code></p>
<h3 id="装饰器">装饰器</h3>
<p>有一个函数我们希望将其运行前后打印某些信息，却又不希望改变这个函数的代码，那么久可以通过装饰器（decorator）来实现这个功能。
例子如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;before %s&#x27;</span> %func.__name__</span><br><span class="line">        <span class="keyword">return</span> func()</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@log</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello</span>():</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"></span><br><span class="line">hello()</span><br></pre></td></tr></table></figure> 输出结果为： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before hello_world</span><br><span class="line">hello</span><br></pre></td></tr></table></figure>
实际上执行hello()时相当于执行了hello=log(hello)，即将hello指向了返回的wrapper函数，而这也带来了一个问题，就是hello的<code>__name__</code>属性变为了wrapper的<code>__name__</code>属性。也就是加入在上面的程序的最后加上<code>print hello_world.__name__</code>打印出来的是<code>wrapper</code>。所以，**需要把原始函数的__name__等属性复制到wrapper()函数中，否则，有些依赖函数签名的代码执行就会出错**。</p>
<p>这些事情不用我们自己做，Python内置的<code>functools.wraps</code>就是干这个事的，所以，上面的规范写法如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;before %s&#x27;</span> %func.__name__</span><br><span class="line">        <span class="keyword">return</span> func()</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@log</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello_world</span>():</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"></span><br><span class="line">hello_world()</span><br><span class="line"><span class="built_in">print</span> hello_world.__name__</span><br></pre></td></tr></table></figure> 这时打印出来的结果是 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before hello_world</span><br><span class="line">hello</span><br><span class="line">hello_world</span><br></pre></td></tr></table></figure></p>
<p>上面的例子中装饰器均没有参数，下面给出装饰器带有参数的例子：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">log_a</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decorator_a</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">        @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper_a</span>():</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;args in the decorator is %s&#x27;</span>%text</span><br><span class="line">            func()</span><br><span class="line">        <span class="keyword">return</span> wrapper_a</span><br><span class="line">    <span class="keyword">return</span> decorator_a</span><br><span class="line"></span><br><span class="line"><span class="meta">@log_a(<span class="params"><span class="string">&#x27;haha&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hello_world_a</span>():</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"></span><br><span class="line">hello_world_a()</span><br><span class="line"><span class="built_in">print</span> hello_world_a.__name__</span><br></pre></td></tr></table></figure> 输出结果如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">args in the decorator is haha</span><br><span class="line">hello</span><br><span class="line">hello_world_a</span><br></pre></td></tr></table></figure>
执行<code>hello_world_a()</code>相当于执行了<code>hello_world_a()=log('haha')(hello_world_a())</code>,其中的<code>log('haha')</code>返回了装饰器函数<code>decorator_a</code>.</p>
<h2 id="类与对象">类与对象</h2>
<h3 id="私有变量">私有变量</h3>
<p>python中没有private关键字来限定变量的私有性，假如变量名是以两根下划线开头，那么就认为是私有变量，如为类s定义了一个<code>__age</code>的变量，那么不能通过<code>s.__age</code>在外部修改这个变量，只能通过在类的内部定义set和get方法。</p>
<h3 id="获取对象的信息">获取对象的信息</h3>
<p>通过<code>type(object)</code>函数或<code>isinstance(object，type)</code>函数可以判断一个类或对象的类型，通过<code>dir(object)</code>函数可以找到一个对象的所有属性和方法。通过<code>hasattr(object, 'x')</code>
判断object是否有属性x</p>
<p>通过<code>dir(object)</code>列出一个类的所有属性和方法会发现有很多<code>__XXX___</code>方法，类似<code>__xxx__</code>的属性和方法在Python中都是有特殊用途的，比如<code>__len__</code>方法返回长度。在Python中，如果你调用len()函数试图获取一个对象的长度，实际上，在len()函数内部，它自动去调用该对象的__len__()方法，所以，下面的代码是等价的：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(<span class="string">&#x27;ABC&#x27;</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&#x27;ABC&#x27;</span>.__len__()</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>
如果试图获取不存在的属性，会抛出<strong>AttributeError</strong>的错误</p>
<h3 id="动态绑定属性和方法">动态绑定属性和方法</h3>
<p>定义了一个class，或者创建了一个class的实例后，我们可以给该类或实例绑定任何属性和方法，这就是动态语言的灵活性。如下面的例子
先定义一个类 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure> 然后，尝试给实例绑定一个属性：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = Student()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s.name = <span class="string">&#x27;hello&#x27;</span> <span class="comment"># 动态给实例绑定一个属性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span> s.name</span><br><span class="line">hello</span><br></pre></td></tr></table></figure>
如果要限定能够绑定的属性，可以在原来的类中添加<code>__slots__</code>变量，变量的内容设为能够动态绑定的属性即可。</p>
<h3 id="隐藏getter和setter为类的属性">隐藏getter和setter为类的属性</h3>
<p>通过装饰器<code>@property</code>可以隐藏类对某个属性的get方法和set方法，见下面的例子
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">birth</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self._birth</span><br><span class="line"></span><br><span class="line"><span class="meta">    @birth.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">birth</span>(<span class="params">self, value</span>):</span><br><span class="line">        self._birth = value</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2014</span> - self._birth</span><br></pre></td></tr></table></figure>
把一个getter方法变成属性，只需要加上<code>@property</code>就可以了，此时，<span
class="citation"
data-cites="property本身又创建了另一个装饰器">@property本身又创建了另一个装饰器</span><code>@birth.setter</code>，这个装饰器负责把一个setter方法变成属性赋值，并且在这个方法内可以限制复制的的范围等。</p>
<p>调用方法如下所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;s = Student()</span><br><span class="line">&gt;&gt;&gt;s.birth = <span class="number">2001</span> </span><br><span class="line">&gt;&gt;&gt;<span class="built_in">print</span> s.birth,s.age</span><br><span class="line"><span class="number">2001</span> <span class="number">13</span></span><br></pre></td></tr></table></figure> 上面的<code>s.birth = 2001</code>
实际上是执行了装饰器<code>@birth.setter</code>装饰的birth方法，因此可在这个方法内加上赋值的限制条件,过滤不合法的赋值。</p>
<p>也可以将一个属性定义为只读属性，只定义getter方法即可。如上面的age方法。</p>
<h3 id="类的一些内部函数">类的一些内部函数</h3>
<h4 id="str__"><code>__str__</code></h4>
<p>该函数是在直接打印对象时输出的内容，如下例子所示 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">s = Student()</span><br><span class="line"><span class="built_in">print</span> s</span><br></pre></td></tr></table></figure>
输出内容为<code>&lt;__main__.Student object at 0x02124DF0&gt;</code>,表示对象在内存中的地址，可以重写这个函数的输出，见下面的例子
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">    	<span class="keyword">return</span> <span class="string">&#x27;object student&#x27;</span></span><br><span class="line"></span><br><span class="line">s = Student()</span><br><span class="line"><span class="built_in">print</span> s</span><br></pre></td></tr></table></figure> 再次执行的时候会输出<code>object student</code>。</p>
<h4 id="repr__"><code>__repr__</code></h4>
<p>该函数与<code>__str__</code>函数很类似，只是在直接显示变量调用的不是<code>__str__()</code>，而是<code>__repr__()</code>，两者的作用的区别是<code>__str__()</code>返回<strong>用户看到的字符串</strong>，而<code>__repr__()</code>返回<strong>程序开发者看到的字符串</strong>，也就是说，<code>__repr__()</code>是<strong>为调试服务</strong>。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">`&gt;&gt;&gt; <span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">    	<span class="keyword">return</span> <span class="string">&#x27;object student&#x27;</span></span><br><span class="line"><span class="meta">... </span>... ... </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s=Student()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s</span><br><span class="line">&lt;__main__.Student <span class="built_in">object</span> at <span class="number">0x02859930</span>&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="iter__"><code>__iter__</code></h4>
<p>如果一个类想被用于<code>for ... in</code>循环，类似list或tuple那样，就必须实现一个<code>__iter__()</code>方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的next()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环。</p>
<p>以斐波那契数列为例，写一个Fib类，可以作用于for循环： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = <span class="number">0</span>, <span class="number">1</span> <span class="comment"># 初始化两个计数器a，b</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self <span class="comment"># 实例本身就是迭代对象，故返回自己</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self</span>):</span><br><span class="line">        self.a, self.b = self.b, self.a + self.b <span class="comment"># 计算下一个值</span></span><br><span class="line">        <span class="keyword">if</span> self.a &gt; <span class="number">100000</span>: <span class="comment"># 退出循环的条件</span></span><br><span class="line">            <span class="keyword">raise</span> StopIteration();</span><br><span class="line">        <span class="keyword">return</span> self.a <span class="comment"># 返回下一个值</span></span><br></pre></td></tr></table></figure>
把Fib实例作用于for循环： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> n <span class="keyword">in</span> Fib():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> n</span><br><span class="line">...</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line">...</span><br><span class="line"><span class="number">46368</span></span><br><span class="line"><span class="number">75025</span></span><br></pre></td></tr></table></figure></p>
<h4 id="getitem__"><code>__getitem__</code></h4>
<p>Fib实例虽然能作用于for循环，看起来和list有点像，但是，把它当成list来使用还是不行，比如，取第5个元素：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>Fib()[<span class="number">5</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="string">&#x27;Fib&#x27;</span> <span class="built_in">object</span> does <span class="keyword">not</span> support indexing</span><br></pre></td></tr></table></figure>
要表现得像list那样按照下标取出元素，需要实现__getitem__()方法：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Fib</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, n</span>):</span><br><span class="line">        a, b = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            a, b = b, a + b</span><br><span class="line">        <span class="keyword">return</span> a</span><br><span class="line">```        </span><br><span class="line">现在，就可以按下标访问数列的任意一项了：</span><br><span class="line">```py</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = Fib()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">1</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f[<span class="number">3</span>]</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<h4 id="call__"><code>__call__</code></h4>
<p>一个对象实例可以有自己的属性和方法，当我们调用实例方法时，我们用instance.method()来调用。能不能直接在实例本身上调用呢？类似instance()？在Python中，答案是肯定的。</p>
<p>任何类，只需要定义一个<code>__call__()</code>方法，就可以直接对实例进行调用。请看示例：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;My name is %s.&#x27;</span> % self.name)</span><br></pre></td></tr></table></figure></p>
<p>调用方式如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = Student(<span class="string">&#x27;Michael&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s()</span><br><span class="line">My name <span class="keyword">is</span> Michael.</span><br></pre></td></tr></table></figure></p>
<p><code>__call__()</code>还可以定义参数。对实例进行直接调用就好比对一个函数进行调用一样</p>
<p>判断一个对象是否能被调用，能被调用的对象就是一个Callable对象，比如函数和我们上面定义的带有__call()__的类实例：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">callable</span>(Student())</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">callable</span>(<span class="built_in">max</span>)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">callable</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">callable</span>(<span class="literal">None</span>)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">callable</span>(<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
通过callable()函数，我们就可以判断一个对象是否是“可调用”对象。</p>
<h2 id="错误调试和测试">错误、调试和测试</h2>
<h3 id="概念">概念</h3>
<p>常用的调试结构</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span></span><br><span class="line">....</span><br><span class="line"><span class="keyword">except</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">else</span> <span class="comment"># 没有捕捉到exception时执行该语句</span></span><br><span class="line">....</span><br><span class="line"><span class="keyword">finally</span></span><br></pre></td></tr></table></figure>
<p>Python所有的错误都是从<code>BaseException</code>类派生的，常见的错误类型和继承关系看这里：
https://docs.python.org/2/library/exceptions.html#exception-hierarchy</p>
<p>logging模块可以把错误记录到日志文件里，方便事后排查</p>
<h3 id="抛出错误">抛出错误</h3>
<p>因为错误是class，捕获一个错误就是捕获到该class的一个实例。因此，错误并不是凭空产生的，而是有意创建并抛出的。Python的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。</p>
<p>如果要抛出错误，首先根据需要，可以定义一个错误的class，选择好继承关系，然后，用<code>raise</code>语句抛出一个错误的实例：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FooError</span>(<span class="title class_ inherited__">StandardError</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">s</span>):</span><br><span class="line">    n = <span class="built_in">int</span>(s)</span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">raise</span> FooError(<span class="string">&#x27;invalid value: %s&#x27;</span> % s)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span> / n</span><br></pre></td></tr></table></figure>
<p>只有在必要的时候才定义我们自己的错误类型。如果可以选择Python已有的内置的错误类型（比如ValueError，TypeError），尽量使用Python内置的错误类型。</p>
<p>另一种错误处理的方式：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">s</span>):</span><br><span class="line">    n = <span class="built_in">int</span>(s)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span> / n</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bar</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> foo(s) * <span class="number">2</span></span><br><span class="line">    <span class="keyword">except</span> StandardError, e:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Error!&#x27;</span></span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    bar(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<p>在bar()函数中，我们明明已经捕获了错误，但是，打印一个Error!后，又把错误通过raise语句抛出去了，这不有病么？</p>
<p>其实这种错误处理方式不但没病，而且相当常见。<strong>捕获错误目的只是记录一下，便于后续追踪。但是，由于当前函数不知道应该怎么处理该错误，所以，最恰当的方式是继续往上抛，让顶层调用者去处理。</strong></p>
<p><strong>raise语句如果不带参数，就会把当前错误原样抛出。此外，在except中raise一个Error，还可以把一种类型的错误转化成另一种类型：</strong></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="number">10</span> / <span class="number">0</span></span><br><span class="line"><span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">&#x27;input error!&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>只要是合理的转换逻辑就可以，但是，决不应该把一个IOError转换成毫不相干的ValueError。</p>
<h3 id="调试">调试</h3>
<h4 id="printassert语句">print、assert语句</h4>
<p>最基础的调试就是通过<code>print</code>语句打印出变量的值，但是这样每次调试后都要注释或删除<code>print</code>语句。</p>
<p>因此也可使用<code>assert</code>语句，该语句的结构为<code>assert condition,'message'</code>,只有当condition为<strong>False</strong>时，才会抛出一个<code>AssertionError</code>并打印出<code>message</code></p>
<h4 id="logging模块">logging模块</h4>
<p>和assert比，logging不会抛出错误，而且可以输出到文件。并且可以指定输出的信息的级别，包括有<code>debug，info，warning，error</code>等几个级别</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO)</span><br><span class="line">s = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">n = <span class="built_in">int</span>(s)</span><br><span class="line">logging.info(<span class="string">&#x27;n = %d&#x27;</span> % n)</span><br><span class="line"><span class="built_in">print</span> <span class="number">10</span> / n</span><br></pre></td></tr></table></figure>
<p>上面的<code>logging.basicConfig</code>就是设置输出的日志的等级，<code>logging.info</code>为输出的内容。</p>
<p>输出的内容如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">INFO:root:n = <span class="number">0</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;XX.py&quot;</span>, line X, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="built_in">print</span> <span class="number">10</span> / n</span><br><span class="line">ZeroDivisionError: integer division <span class="keyword">or</span> modulo by zero</span><br></pre></td></tr></table></figure></p>
<h4 id="pdb">pdb</h4>
<p>pdb(Python
Debugger)是Python的调试器，可以让程序以单步方式运行，并随时查看运行状态。</p>
<p>通过<code>python -m pdb XXX.py</code>可以启动调试器调试<code>XXX.py</code>，<code>n</code>命令执行当前代码并转到下一行，<code>p 变量名</code>打印出具体的变量，<code>q</code>命令退出调试程序。</p>
<p>除了上面的使用方法，还可以在可能出错的地方放一个<code>pdb.set_trace()</code>，相当于设置一个断点。运行代码时，程序会自动在<code>pdb.set_trace()</code>暂停并进入pdb调试环境，可以用命令<code>p</code>查看变量，或者用命令<code>c</code>继续运行</p>
<h2 id="多进程和多线程">多进程和多线程</h2>
<h3 id="多进程">多进程</h3>
<p>python提供的跨平台多进程模块为<code>multiprocessing</code>,
使用的方式如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">target_func</span>(<span class="params">arg1,arg2</span>):</span><br><span class="line">    ....</span><br><span class="line">    </span><br><span class="line">p1 = Process(target=target_func,args=(arg1,arg2))</span><br><span class="line">p2 = Process()</span><br><span class="line">p1.start()</span><br><span class="line">p1.join()</span><br></pre></td></tr></table></figure>
上面启动了一个进程，并执行任务<code>target_func</code>,注意同时执行任务的最大进程数等于该机器的核数。</p>
<p>更详细的用法参考<a
href="http://wulc.me/2015/12/15/python%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%BF%9B%E7%A8%8B/">这篇文章</a>
### 多线程
python提供的多线程模块为<code>thread</code>模块和<code>threading</code>模块，后者是高级模块，除了封装了前者还封装了很多其他方法。</p>
<p>一般的使用有两种：1）继承<code>threading.Thread</code>构造自己的线程类。2）类似多进程将需要执行的任务作为参数构造线程。</p>
<p>详细的语法可参考<a
href="http://wulc.me/2016/03/26/python%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B/">这篇文章</a>。需要注意的是多线程同时修改进程中的公共变量时记得加线程锁。</p>
<h3 id="threadlocal">ThreadLocal</h3>
<p>在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。</p>
<p>但是局部变量也有问题，就是在函数调用的时候必须要通过参数传递。如下面的例子：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_student</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Hello, %s (in %s)&#x27;</span> % (name, threading.current_thread().name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_thread</span>(<span class="params">name</span>):</span><br><span class="line">    process_student(name)</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target= process_thread, args=(<span class="string">&#x27;Alice&#x27;</span>,), name=<span class="string">&#x27;Thread-A&#x27;</span>)</span><br><span class="line">t2 = threading.Thread(target= process_thread, args=(<span class="string">&#x27;Bob&#x27;</span>,), name=<span class="string">&#x27;Thread-B&#x27;</span>)</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br></pre></td></tr></table></figure>
当参数多了的时候，这样一层层传下去就会显得比较麻烦。因此引入了ThreadLocal的概念，可将上面的代码改写成如下的样式实现相同的功能。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全局ThreadLocal对象:</span></span><br><span class="line">local_school = threading.local()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_student</span>():</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Hello, %s (in %s)&#x27;</span> % (local_school.student, threading.current_thread().name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_thread</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="comment"># 绑定ThreadLocal的student:</span></span><br><span class="line">    local_school.student = name</span><br><span class="line">    process_student()</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target= process_thread, args=(<span class="string">&#x27;Alice&#x27;</span>,), name=<span class="string">&#x27;Thread-A&#x27;</span>)</span><br><span class="line">t2 = threading.Thread(target= process_thread, args=(<span class="string">&#x27;Bob&#x27;</span>,), name=<span class="string">&#x27;Thread-B&#x27;</span>)</span><br><span class="line">t1.start()</span><br><span class="line">t2.start()</span><br><span class="line">t1.join()</span><br><span class="line">t2.join()</span><br></pre></td></tr></table></figure></p>
<p><strong>全局变量</strong><code>local_school</code>就是一个ThreadLocal对象，每个Thread对它都可以读写student属性，但互不影响。你可以把<code>local_school</code>看成全局变量，但每个属性如<code>local_school.student</code>都是线程的<strong>局部变量</strong>，可以任意读写而互不干扰，也<strong>不用管理锁的问题</strong>，ThreadLocal内部会处理。</p>
<p>可以理解为全局变量<code>local_school</code>是一个dict，<strong>不但可以用<code>local_school.student</code>，还可以绑定其他变量，如<code>local_school.teacher</code>等等</strong>。</p>
<p>ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。</p>
<h2 id="常用内建模块">常用内建模块</h2>
<h3 id="collections">collections</h3>
<p>collections 提供了许多有用的集合类</p>
<ul>
<li><p><strong>namedtuple</strong>
namedtuple是一个函数，它用来创建一个<strong>自定义的tuple对象</strong>，并且规定了tuple元素的个数，并<strong>可以用属性而不是索引来引用tuple的某个元素</strong>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line">&gt;&gt;&gt;Coordinate = namedtuple(<span class="string">&quot;corr&quot;</span>,[<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;y&#x27;</span>])</span><br><span class="line">&gt;&gt;&gt;c = Coordinate(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">&gt;&gt;&gt;c.x</span><br><span class="line"><span class="number">1</span></span><br><span class="line">&gt;&gt;&gt;c.y</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>deque</strong>
deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q = deque([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.append(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q.appendleft(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q</span><br><span class="line">deque([<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;x&#x27;</span>])</span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>defaultdict</strong>
使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd = defaultdict(<span class="keyword">lambda</span>: <span class="string">&#x27;N/A&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">&#x27;key1&#x27;</span>] = <span class="string">&#x27;abc&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">&#x27;key1&#x27;</span>] <span class="comment"># key1存在</span></span><br><span class="line"><span class="string">&#x27;abc&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dd[<span class="string">&#x27;key2&#x27;</span>] <span class="comment"># key2不存在，返回默认值</span></span><br><span class="line"><span class="string">&#x27;N/A&#x27;</span></span><br></pre></td></tr></table></figure>
注意默认值是调用函数返回的，而<strong>函数在创建defaultdict对象时传入</strong>。</p></li>
</ul>
<p>除了在Key不存在时返回默认值，defaultdict的其他行为跟dict是完全一样的。</p>
<ul>
<li><p><strong>OrderedDict</strong>
使用dict时，Key是无序的。在<strong>对dict做迭代时，我们无法确定Key的顺序。</strong>如果要保持Key的顺序，可以用OrderedDict：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = <span class="built_in">dict</span>([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d <span class="comment"># dict的Key是无序的</span></span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>od = OrderedDict([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>od <span class="comment"># OrderedDict的Key是有序的</span></span><br><span class="line">OrderedDict([(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="number">3</span>)])</span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>Counter</strong>
Counter是一个简单的计数器，例如，统计字符出现的个数： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = Counter()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> ch <span class="keyword">in</span> <span class="string">&#x27;programming&#x27;</span>:</span><br><span class="line"><span class="meta">... </span>    c[ch] = c[ch] + <span class="number">1</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line">Counter(&#123;<span class="string">&#x27;g&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;m&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;r&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;i&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;o&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;n&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;p&#x27;</span>: <span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>
Counter实际上也是dict的一个子类</p></li>
</ul>
<h3 id="base64">base64</h3>
<p>Base64是一种用64个字符来表示任意二进制数据的方法。</p>
<p>首先要理解的问题就是为什么要用字符来表是二进制的数据。<a
href="https://en.wikipedia.org/wiki/Binary-to-text_encoding">维基百科的解释</a>如下：
&gt;A binary-to-text encoding is encoding of data in plain text. More
precisely, it is an encoding of binary data in a sequence of characters.
These encodings are necessary for transmission of data when the channel
does not allow binary data, such as when one might attach an image file
to an e-mail message, to accomplish this, the data is encoded in some
way, such that eight-bit data is encoded into seven-bit ASCII
characters</p>
<p>大意就是在数据传输时，某些协议或系统只支持字符的传输（如email），因此如果需要传输二进制的数据，就要将二进制数据转为字符格式。而Base64是一种最常见的二进制编码方法。</p>
<p>Base64的原理很简单，首先，准备一个包含64个字符的数组：
如<code>['A', 'B', 'C', ... 'a', 'b', 'c', ... '0', '1', ... '+', '/']</code>然后对二进制数据进行处理，每3个字节一组，一共是3x8=24bit，划为4组，每组正好6个bit,
计算6个bit表示的数字大小（范围在0~63）之间，然后查上面的表，这样我们得到4个数字作为索引，然后查表，获得相应的4个字符，就是编码后的字符串。</p>
<p>因此，<strong>Base64编码会把3字节的二进制数据编码为4个字符的文本数据</strong></p>
<p>如果要编码的二进制数据的字节数不是3的倍数，最后会剩下1个或2个字节怎么办？Base64用00字节在二进制数据末尾补足后，再在编码的末尾加上1个或2个=号，表示补了一个会两个字节，解码的时候，会自动去掉。
例子如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> base64 <span class="keyword">as</span> b64</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b64.b64encode(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;LA==&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b64.b64encode(<span class="string">&#x27;l,&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;bCw=&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b64.b64encode(<span class="string">&#x27;ll,&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;bGws&#x27;</span></span><br><span class="line">&gt;&gt;&gt;b64.b64decode(<span class="string">&#x27;LA==&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;,&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>由于标准的Base64编码后可能出现字符+和/，在URL中就不能直接作为参数，所以又有一种"url
safe"的base64编码，其实就是把字符+和/分别变成-和_</strong>：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>base64.b64encode(<span class="string">&#x27;i\xb7\x1d\xfb\xef\xff&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;abcd++//&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>base64.urlsafe_b64encode(<span class="string">&#x27;i\xb7\x1d\xfb\xef\xff&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;abcd--__&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>base64.urlsafe_b64decode(<span class="string">&#x27;abcd--__&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;i\xb7\x1d\xfb\xef\xff&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>Base64适用于小段内容的编码，比如数字证书签名、Cookie的内容等。</p>
<p><strong>由于=字符也可能出现在Base64编码中，但=用在URL、Cookie里面会造成歧义，所以，很多Base64编码后会把=去掉</strong>,如下所示：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 标准Base64:</span></span><br><span class="line"><span class="string">&#x27;abcd&#x27;</span> -&gt; <span class="string">&#x27;YWJjZA==&#x27;</span></span><br><span class="line"><span class="comment"># 自动去掉=:</span></span><br><span class="line"><span class="string">&#x27;abcd&#x27;</span> -&gt; <span class="string">&#x27;YWJjZA&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>去掉=后怎么解码呢？因为Base64是把3个字节变为4个字节，所以，<strong>Base64编码的长度永远是4的倍数，因此，需要加上=把Base64字符串的长度变为4的倍数，就可以正常解码了</strong>。如下面的例子
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>base64.b64decode(<span class="string">&#x27;YWJjZA==&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;abcd&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>base64.b64decode(<span class="string">&#x27;YWJjZA&#x27;</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  ...</span><br><span class="line">TypeError: Incorrect padding</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">safe_b64decode</span>(<span class="params">s</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> base64.b64decode(s+<span class="string">&#x27;=&#x27;</span>*(<span class="number">4</span>-<span class="built_in">len</span>(s)%<span class="number">4</span>))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>safe_b64decode(<span class="string">&#x27;YWJjZA&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;abcd&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="struct">struct</h3>
<p>python中的struct模块的主要作用就是<strong>对python基本类型值与用python字符串格式表示的C语言中struct类型间的转化</strong>（<a
href="https://docs.python.org/2/library/struct.html">This module
performs conversions between Python values and C structs represented as
Python
strings</a>.）。stuct模块提供了很简单的几个函数，下面写几个例子。</p>
<p>struct提供用format specifier方式对数据进行打包和解包（Packing and
Unpacking）。例如:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"><span class="keyword">import</span> binascii</span><br><span class="line">values = (<span class="number">1</span>, <span class="string">&#x27;abc&#x27;</span>, <span class="number">2.7</span>)</span><br><span class="line">s = struct.Struct(<span class="string">&#x27;I3sf&#x27;</span>)</span><br><span class="line">packed_data = s.pack(*values)</span><br><span class="line">unpacked_data = s.unpack(packed_data)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Original values:&#x27;</span>, values</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Format string :&#x27;</span>, s.<span class="built_in">format</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Uses :&#x27;</span>, s.size, <span class="string">&#x27;bytes&#x27;</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Packed Value :&#x27;</span>, binascii.hexlify(packed_data)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Unpacked Type :&#x27;</span>, <span class="built_in">type</span>(unpacked_data), <span class="string">&#x27; Value:&#x27;</span>, unpacked_data</span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Original values: (1, &#x27;abc&#x27;, 2.7) </span><br><span class="line">Format string : I3sf </span><br><span class="line">Uses : 12 bytes </span><br><span class="line">Packed Value : 0100000061626300cdcc2c40 </span><br><span class="line">Unpacked Type : &lt;type &#x27;tuple&#x27;&gt;  Value: (1, &#x27;abc&#x27;, 2.700000047683716)</span><br></pre></td></tr></table></figure></p>
<p>代码中，首先定义了一个元组数据，包含int、string、float三种数据类型，然后定义了struct对象，并制定了format‘I3sf’，I
表示int，3s表示三个字符长度的字符串，f 表示
float。最后通过struct的pack和unpack进行打包和解包。<strong>通过输出结果可以发现，value被pack之后，转化为了一段二进制字节串，而unpack可以把该字节串再转换回一个元组</strong>.但是值得注意的是对于float的精度发生了改变，这是由一些比如操作系统等客观因素所决定的。打包之后的数据所占用的字节数与C语言中的struct十分相似。</p>
<p>关于struct的更多的具体用法可参考
https://docs.python.org/2/library/struct.html
http://www.cnblogs.com/coser/archive/2011/12/17/2291160.html</p>
<h3 id="xml">XML</h3>
<p><strong>操作XML有两种方法：DOM和SAX。DOM会把整个XML读入内存，解析为树，因此占用内存大，解析慢，优点是可以任意遍历树的节点。SAX是流模式，边读边解析，占用内存小，解析快，缺点是我们需要自己处理事件。</strong></p>
<p>SAX只允许读XML，而DOM则允许对XML文件进行读写操作。在只读的情况下，优先考虑SAX，因为DOM实在太占内存。</p>
<p>除了python自带的xml包可用于处理XML文件，第三发库如lxml也可以被用来处理XML文件。</p>
<p>python自带的xml包具体使用的实例代码可参考：
http://www.tutorialspoint.com/python/python_xml_processing.htm</p>
<p>参考：
http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000</p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python中的多线程</title>
    <url>/2016/03/26/python%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<p>本文主要讲述了python中多线程的使用、线程锁以及多线程在python中是否能够提高效率。</p>
<h2 id="多线程的概念">多线程的概念</h2>
<p>进程的相信大家都听说过，而线程可以理解为比进程更小一级的概念，<strong>一个进程内至少有一个线程,如果有多个线程，那么他们就共享进程的资源，共同完成进程的任务。</strong></p>
<p>使用多线程一般有两个不同的目的：
一是把程序细分成几个功能相对独立的模块，防止其中一个功能模块阻塞导致整个程序假死（GUI程序是典型）
另一个就是提高运行效率，比如多个核同时跑，或者单核里面，某个线程进行IO操作时，另一个线程可以同时执行。具体可以参考<a
href="http://ifeve.com/benefits/">这篇文章</a></p>
<span id="more"></span>
<p>相比进程，线程有以下优点</p>
<ul>
<li>创建和销毁的代价比进程要小得多，尤其是在windows下，<a
href="https://www.zhihu.com/question/19901763">可以参考这个回答</a>。而且线程间彼此切换所需的时间也远远小于进程间切换所需要的时间</li>
<li>线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过通信的方式进行。而由于同一进程下的线程之间共享数据空间，降低了通信的开销。</li>
</ul>
<p>除了优点，
线程间方便的通信机制源于线程间数据的共享，同时也带来了其他问题，如需要保护变量不能同时被两个线程所修改，这也需要一定的开销，而且需要开发者处理好这个调度。</p>
<h2 id="python中的多线程">python中的多线程</h2>
<p>python中提供了两个模块实现多线程，分别是<code>thread</code>和<code>threading</code>，<code>thread</code>是比较低级的模块,而<code>threading</code>在其基础上封装了其他许多高级特性，故本文主要讲述<code>threading</code>模块的使用，若要了解<code>thread</code>模块的使用，请参考<a
href="https://docs.python.org/2/library/thread.html#module-thread">官方文档</a>。</p>
<p>创建进程有两种方式，分别是<strong>继承threading.Thread类创建自己的线程子类</strong>和<strong>将需要线程执行的函数传入线程构造函数中</strong>。下面分别讲述</p>
<h3 id="继承threading.thread类">继承threading.Thread类</h3>
<p>继承threading.Thread类<strong>只能重写（override）<code>__init__</code>函数和<code>run()</code>函数</strong>，<code>__init__</code>函数就是构造函数，<code>run()</code>函数就是创建线程后线程需要执行的任务。下面是一个简单的demo
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">sleepThread</span>(threading.Thread):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        <span class="built_in">print</span> self.name+ <span class="string">&#x27; is created!&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        randomTime = random.randint(<span class="number">1</span>,<span class="number">9</span>) <span class="comment"># 生成 1~9的随机整数</span></span><br><span class="line">        time.sleep(randomTime)</span><br><span class="line">        <span class="built_in">print</span> self.name+ <span class="string">&#x27; slept for &#x27;</span>+<span class="built_in">str</span>(randomTime)+<span class="string">&#x27; seconds&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    threads = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># 创建5个进程</span></span><br><span class="line">        th = sleepThread()</span><br><span class="line">        threads.append(th)</span><br><span class="line">        th.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">        t.join() </span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;all threads finished&#x27;</span></span><br><span class="line">    </span><br></pre></td></tr></table></figure></p>
<p>在上面的例子中，我们编写了自己的线程类<code>sleepThread</code>,然后创建了5个线程，用<code>start()</code>启动了各个线程，<code>start()</code>实际上是执行了线程类的<code>run()</code>函数。这时输出如下所示：</p>
<p><img src="https://wulc.me/imgs/1.png" /></p>
<p>其中，默认线程的名称是<code>Thread-i</code>，i就是创建的第i个线程。<code>join()</code>函数的作用是等待线程执行完成再执行下面任务,实际的应用场景比如说进程要合并多个线程的处理结果，那么这时候<code>join()</code>函数就必不可少了。假如没有<code>join()</code>函数，即主函数改成下面的样子。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># 创建5个进程</span></span><br><span class="line">        th = sleepThread()</span><br><span class="line">        th.start()  </span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;all threads finished&#x27;</span></span><br></pre></td></tr></table></figure> 那么输出就像下面所示：</p>
<p><img src="https://wulc.me/imgs/2.png" /></p>
<p>那为什么不在<code>thread.start()</code>后执行join()呢？即主函数改成以下样子。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):  <span class="comment"># 创建5个进程</span></span><br><span class="line">        th = sleepThread()</span><br><span class="line">        th.start()  </span><br><span class="line">        th.join()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;all threads finished&#x27;</span></span><br></pre></td></tr></table></figure> 这样输出的结果就像下面一样：</p>
<p><img src="https://wulc.me/imgs/3.png" /></p>
<p>原因是线程join()后会阻塞后面线程的创建，导致线程无法并行，这样多线程就没有意义了。</p>
<h3
id="将需要线程执行的函数传入线程构造函数中">将需要线程执行的函数传入线程构造函数中</h3>
<p>上面是线程的一种创建方式，实现上面相同功能的另外一种创建方式如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sleepThread</span>(<span class="params">threadName</span>):</span><br><span class="line">    randomTime = random.randint(<span class="number">1</span>,<span class="number">9</span>) <span class="comment"># 生成 1~9的随机整数</span></span><br><span class="line">    time.sleep(randomTime)</span><br><span class="line">    <span class="built_in">print</span> threadName+ <span class="string">&#x27; slept for &#x27;</span>+<span class="built_in">str</span>(randomTime)+<span class="string">&#x27; seconds&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    threads = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        th = threading.Thread(target=sleepThread,args=(<span class="string">&#x27;Thread-&#x27;</span>+<span class="built_in">str</span>(i),))</span><br><span class="line">        threads.append(th)</span><br><span class="line">        th.start()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">        t.join()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;all threads finished&#x27;</span></span><br></pre></td></tr></table></figure>
利用了<code>threading.Thread</code>自身的构造函数，传入的target参数作为线程的<code>run</code>函数,args参数则为传入的run函数的参数。</p>
<p>输出结果如下所示：</p>
<p><img src="https://wulc.me/imgs/2016-03-26_210528.png" /></p>
<p>线程还有比较常用的方法比如说setdaemon(True),字面上的意思是设为守护线程，但是这个守护线程跟守护进程有很大的区别，<strong>实际上setdaemon(True)的作用是保证主线程（就是任何进程最开始的那个线程）退出时，派生出来的线程也必须退出。</strong>详细例子见http://stackoverflow.com/questions/5127401/setdaemon-function-in-thread</p>
<h2 id="线程锁">线程锁</h2>
<p>因为多线程共享一个进程内的资源，所以<strong>多个线程同时修改同一个变量时会发生冲突。这时候就需要线程锁</strong>了。比如说下面这段代码;
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">count = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modifyThread</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">        count -= num</span><br><span class="line">        count += num</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    threads = []</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;before modifying, count=%s &#x27;</span>%count</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        th = threading.Thread(target=modifyThread,args=(i,))</span><br><span class="line">        threads.append(th)</span><br><span class="line">        th.start()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">        t.join()</span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;after modifying, count=%s &#x27;</span>%count</span><br><span class="line"></span><br></pre></td></tr></table></figure> 执行的的时候每次输出结果都不一样，例如下图：</p>
<p><img src="https://wulc.me/imgs/5.png" /></p>
<p>这是因为count是被多个线程同时修改了，解决方法就是利用线程锁<code>threading.Lock()</code>,每次需要修改count时先获取线程锁，修改完再释放。实例代码如下所示：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">count = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modifyThread</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    threadLock.acquire()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">            count -= num</span><br><span class="line">            count += num</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        threadLock.release()</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    threads = []</span><br><span class="line">    threadLock = threading.Lock()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;before modifying, count=%s &#x27;</span>%count</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        th = threading.Thread(target=modifyThread,args=(i,))</span><br><span class="line">        threads.append(th)</span><br><span class="line">        th.start()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">        t.join()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;after modifying, count=%s &#x27;</span>%count</span><br></pre></td></tr></table></figure>
当多个线程同时执行threadLock.acquire()时，只有一个线程能成功地获取锁，然后继续执行代码，其他线程就继续等待直到获得锁为止。</p>
<p>在其中一个线程获取了线程锁（threadLock.acquire()）后，其他线程便无法修改count，但是修改完后一定要记得释放线程锁（threadLock.release()），否则其他线程会一直处于blocked的状态，上面采用了<code>try-finally</code>保证锁一定被释放。除了<code>try-finally</code>,还可通过
<code>with</code> 语句实现锁的自动获取和释放, 也就是说上面的
<code>modifyThread</code> 函数可以写成下面的形式</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">modifyThread</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    <span class="keyword">with</span> threadLock:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">            count -= num</span><br><span class="line">            count += num</span><br></pre></td></tr></table></figure>
<p>通过加锁的方法修改 count, 最终得到的count的值不变。</p>
<p>线程锁(Lock)是线程同步的一种方式，除此之外，还有RLocks, Semaphores,
Condition, Events 和 Queues，具体可参考<a
href="https://docs.python.org/2/library/threading.html#lock-objects">官方文档</a>和<a
href="http://www.laurentluce.com/posts/python-threads-synchronization-locks-rlocks-semaphores-conditions-events-and-queues/">Python
threads synchronization: Locks, RLocks, Semaphores, Conditions, Events
and Queues</a></p>
<h2 id="多线程是否提高了效率">多线程是否提高了效率</h2>
<p>常常会听到有人说，<strong>因为python多线程只能使用一个核，所以多线程实际上并没有提高效率</strong>。这句话可以说一半正确，一半不正确。原因如下：</p>
<p><strong>python多线程只能使用一个核</strong>这句话针对部分python解析器如CPython等是正确的，而且是相对与Java、C++那些一个线程就可以占一个核的程序而言。python的<a
href="https://wiki.python.org/moin/GlobalInterpreterLock">官方文档</a>描述如下：
&gt;In CPython, the global interpreter lock, or GIL, is a mutex that
prevents multiple native threads from executing Python bytecodes at
once. This lock is necessary mainly because CPython's memory management
is not thread-safe</p>
<p>原因是python的解析器（如CPython）因为内存管理问题设计了一个GIL（全局解析锁），GIL保证了任何时候都只能有一个线程执行其字节码。这就限制了<strong>同一进程内同一时间只能有一个线程在执行其字节码</strong>，也就是说无论一个进程无论创建多少线程都只能使用一个核。</p>
<p>而且，这个GIL也只在CPython等解释器有，其他的如 <code>Jython</code> 或
<code>IronPython</code>
中没有GIL，多线程可以利用多个核。另外，即使是CPython解释器，也可通过多进程来达到利用多个核的目的。</p>
<p>那第二句话<strong>多线程实际上并没有提高效率</strong>是否正确？可以说也是部分正确，实际上<strong>针对CPU密集型的
python 进程，多线程没有提高效率，而针对IO密集型的 python
进程会提高效率</strong>。</p>
<p>从上面的解释我们知道，GIL是限制了多线程并发执行的一个关键因素，而<strong>GIL仅仅是限制了同一时间同一进程只能有一个线程执行字节码</strong>，执行字节码是在CPU中的，对于CPU密集型的多线程，会一直占据着CPU导致其效果跟单线程一样。</p>
<p>而<strong>对于IO密集型的多线程，线程的执行时间会较多地消耗在IO上，因而CPU可供多线程轮流使用</strong>。比如说我曾用python爬取几个输入法的词库的，多线程比单线程要快了好几倍，原因就是爬虫属于IO密集型的任务，线程执行字节码所需的时间很短，而把大部分时间放在了下载和存储在本地上，线程执行完字节码后会释放GIL，从而其他线程也能够执行其字节码。从而在总体上提高了下载效率。</p>
<p>文章为博主个人理解总结，如有错误，欢迎指出交流。</p>
<p>参考：</p>
<p><a
href="https://docs.python.org/2/library/threading.html#lock-objects">threading
— Higher-level threading interface</a> <a
href="https://wiki.python.org/moin/GlobalInterpreterLock">GlobalInterpreterLock</a>
<a
href="http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386832360548a6491f20c62d427287739fcfa5d5be1f000">多线程</a></p>
]]></content>
      <categories>
        <category>python</category>
        <category>并行编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>python中的类属性和实例属性</title>
    <url>/2016/02/14/python%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%B1%9E%E6%80%A7%E5%92%8C%E5%AE%9E%E4%BE%8B%E5%B1%9E%E6%80%A7/</url>
    <content><![CDATA[<p>面向对象语言中，一般会有“静态变量”，也就是给整个类共享的变量，如C++，java中static修饰的变量。但是在
python 中并没有 static
这个关键字，实现类似功能需要依靠python中的类属性和实例属性的语法特点。本文主要就是讲述这两种属性的区别。</p>
<span id="more"></span>
<p>在讲述之前，需要清楚下面两个事实： <strong>1）python
中类创建的对象叫实例
2）类和实例均是对象，均有自己的对象属性,可通过<code>__dict__</code>查看</strong></p>
<p>下面先看一个例子： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TestAttribute</span>:</span><br><span class="line">    content = []</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addContent</span>(<span class="params">self,x</span>):</span><br><span class="line">        self.content.append(x)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t1 = TestAttribute()</span><br><span class="line">    t2 = TestAttribute()</span><br><span class="line">    t1.addContent(<span class="string">&#x27;t1&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t1:&#x27;</span>, t1.content, t1.__dict__</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t2:&#x27;</span>, t2.content, t2.__dict__</span><br></pre></td></tr></table></figure></p>
<p>输出结果： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">object t1: [&#x27;t1&#x27;] &#123;&#125;</span><br><span class="line">object t2: [&#x27;t1&#x27;] &#123;&#125;</span><br></pre></td></tr></table></figure> 从例子可以看到，这时的 content
就相当于一个static
变量，被所有实例共享。<strong>注意后面那个花括号{}表示实例的所有对象属性，只是当前实例没有自己的属性</strong>。</p>
<p>那假如各个实例要有自己独立的变量的？也很简单，**只需要在类的构造函数（也就是__init__函数)为变量赋值即可.**</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TestAttribute</span>:</span><br><span class="line">    content = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span>  <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.content=[]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addContent</span>(<span class="params">self,x</span>):</span><br><span class="line">        self.content.append(x)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t1 = TestAttribute()</span><br><span class="line">    t2 = TestAttribute()</span><br><span class="line">    t1.addContent(<span class="string">&#x27;t1&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t1:&#x27;</span>, t1.content ,t1.__dict__</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t2:&#x27;</span>, t2.content ,t2.__dict__</span><br></pre></td></tr></table></figure>
<p>输出的结果如下所示： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">object t1: [&#x27;t1&#x27;] &#123;&#x27;content&#x27;:[&#x27;t1&#x27;]&#125;</span><br><span class="line">object t2: [] &#123;&#x27;content&#x27;:[]&#125;</span><br></pre></td></tr></table></figure></p>
<p>从结果可知，现在的t1,t2的变量独立了。那原因是什么呢？</p>
<p>原因是<strong>Python中对象属性的获取是按照从下到上的顺序来查找属性</strong></p>
<p>怎么理解上面这句话呢？以上面代码为例，类和实例的关系如下所示：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> TestAttribute</span><br><span class="line">  ____|____</span><br><span class="line"> |         |</span><br><span class="line">t1         t2</span><br></pre></td></tr></table></figure> <strong>输出<code>t1.content</code>时，python
解析器会先查看对象 t1
中是否有content这个属性，有的话输出这个属性的值，没有的话就往上查找
TestAttribute 中是否有这个属性并输出。</strong></p>
<p>在上面的例一中，因为<strong>t1和t2的属性均为空，所以输出 t1.content
和 t2.content时实际上是输出 TestAttribute 的属性</strong>。又因为
TestAttribute 的 content 属性被修改了 t1 修改了，所以最后输出的的
t1.content 和 t2.content 内容一致。</p>
<p>而在例二中，因为<strong>在构造函数中的为content复制的操作使得每个被创建的实例均有自己的content属性</strong>，所以
t1 修改 content 时查到自己有content的属性，就只会修改自己的
content。不影响t2 的 content 和 TestAttribute 的
content。这个可以从下面的例子看出，假如将例二的代码修改成如下所示：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TestAttribute</span>:</span><br><span class="line">    content = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span>  <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.content=[]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addContent</span>(<span class="params">self,x</span>):</span><br><span class="line">        self.content.append(x)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t1 = TestAttribute()</span><br><span class="line">    t2 = TestAttribute()</span><br><span class="line">    t1.addContent(<span class="string">&#x27;t1&#x27;</span>)</span><br><span class="line">    TestAttribute.content.append(<span class="string">&#x27;tt&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t1:&#x27;</span>, t1.content ,t1.__dict__</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t2:&#x27;</span>, t2.content ,t2.__dict__</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;class TestAttribute:&#x27;</span>, TestAttribute.content</span><br></pre></td></tr></table></figure> 那输出结果是： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">object t1: [&#x27;t1&#x27;] &#123;&#x27;content&#x27;:[&#x27;t1&#x27;]&#125;</span><br><span class="line">object t2: [] &#123;&#x27;content&#x27;:[]&#125;</span><br><span class="line">class TestAttribute: [&#x27;tt&#x27;]</span><br></pre></td></tr></table></figure>
可以看到这三个对象的属性均独立。</p>
<p>那么如何为一个实例添加属性呢？</p>
<p><strong>答案是通过赋值号 = 给实例所需添加的属性赋值。</strong>
通过赋值号 =
给实例所需添加的属性赋值实际上是将这个属性指向了新的引用，也就是新的内存空间。</p>
<p>如在例一中没有通过赋值号为 content 赋值，所以这个属性并没有成为 t1
自己的属性，输出t1.__dict__
为空。而在例二中的构造函数里面为每个实例的content均赋值，所以例二中的三个对象的content属性独立。通过下面的例子可以更深入说明这点：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TestAttribute</span>:   </span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t1 = TestAttribute()</span><br><span class="line">    t2 = TestAttribute()</span><br><span class="line">    </span><br><span class="line">    t1.num = <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t1:&#x27;</span>, t1.num, t1.__dict__</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;object t2:&#x27;</span>, t2.num, t2.__dict__ </span><br></pre></td></tr></table></figure>
<p>输出结果： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">object t1: 1 &#123;&#x27;num&#x27;: 1&#125;</span><br><span class="line">object t2: 0 &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>最后，小结如下： <strong>1.Python中的类和实例是两个完全独立的对象；
2.Python中属性的获取是按照从下到上的顺序来查找属性；
3.为实例添加属性的方法：通过赋值号 =
给实例所需添加的属性赋值</strong></p>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python内置的排序函数</title>
    <url>/2016/07/23/python%E5%86%85%E7%BD%AE%E7%9A%84%E6%8E%92%E5%BA%8F%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>排序是非常常见的操作，常见的排序算法的时间复杂度一般为<span
class="math inline">\(O(n^2)\)</span>（冒泡、选择、插入）或<span
class="math inline">\(O(nlogn)\)</span>(快排、归并等)。虽然这些算法对于编程人员来说是基础，但是在实际工程中往往会使用语言内置的排序函数，主要是考虑到编程效率和自己编写排序函数时涵盖情况不全的问题。因此本文主要讲述python中的内置函数。</p>
<span id="more"></span>
<p>python内置的排序函数主要有两个：<code>sort</code>和<code>sorted</code>，两者主要以下几点区别
<strong>（1）针对的数据类型不同，sort只能对list类型排序，sorted可对list、tuple、dictionary以及自定义的类等数据类型排序
（2）sort会修改原来的list，sorted不会修改原来的数据结构，而是将排好序的结果以list形式返回,因此sorted才能对不可变的数据类型tuple进行排序
（3）语法不同，sort的使用方法是list.sort(),sorted的使用方法是sorted(list|tuple|dict)</strong></p>
<p>除此之外，两者的参数完全一致，都含有<code>reverse，key，cmp</code>这几个参数，这几个参数的用法在两个函数中一致，下面以<code>sorted</code>为例分别讲述这几个参数的作用。</p>
<h2 id="reverse-参数">reverse 参数</h2>
<p>reverse参数的作用是决定从小到大还是从大到小排列结果，默认情况下<code>reverse=False</code>，从小到大排列结果。如果要从大到小排列结果，添加<code>reverse=True</code>参数即可。示例如下所示：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;B&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(a)</span><br><span class="line">[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="string">&#x27;abundunt&#x27;</span>,<span class="string">&#x27;Array&#x27;</span>,<span class="string">&#x27;bunch&#x27;</span>,<span class="string">&#x27;</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; sorted(a, reverse = True)</span></span><br><span class="line"><span class="string">[&#x27;</span>bunch<span class="string">&#x27;, &#x27;</span>abundunt<span class="string">&#x27;, &#x27;</span>But<span class="string">&#x27;, &#x27;</span>Array<span class="string">&#x27;]</span></span><br></pre></td></tr></table></figure></p>
<p>数字大小的判断很容易理解，这里比较的是字符串的大小，比较时会根据<strong>字符串首字符的ASCII码的大小</strong>进行排序。</p>
<h2 id="key-参数">key 参数</h2>
<p>上面的例子是根据单个元素来排序的，假如需要对多个元素组合而成的元素来排序（如<code>b = [(2,1),(1,3),(4,2)]</code>），就需要用key来指定以哪个元素作为排序的依据。</p>
<p>下面是对tuple组成的tuple的排序 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = ((<span class="number">2</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">2</span>))</span><br><span class="line"><span class="comment"># 不用key参数时也不会报错，这时排序依据默认是组合元素中的第一个元素，但是为了程序的清晰性，还是建议使用key参数</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(b) </span><br><span class="line">[(<span class="number">1</span>, <span class="number">3</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">2</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(b, key = <span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">[(<span class="number">1</span>, <span class="number">3</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">2</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(b, key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line">[(<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">3</span>)]</span><br></pre></td></tr></table></figure>
给key参数传进去的是一个函数，上面使用<code>lambda</code>实现，<strong>传入的是需要排序的组合元素，返回的是根据组合元素中哪个元素排序，从下标0开始计算</strong>。</p>
<p>对于字典的key或value排序也是如此，但此时的下标就只有0和1了，分别代表key和value。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = &#123;<span class="number">2</span>:<span class="number">1</span>, <span class="number">4</span>:<span class="number">3</span>, <span class="number">1</span>:<span class="number">6</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(d.items(), key = <span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">[(<span class="number">1</span>, <span class="number">6</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">3</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">&#123;<span class="number">1</span>: <span class="number">6</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">4</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(d.items(), key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>])</span><br><span class="line">[(<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">3</span>), (<span class="number">1</span>, <span class="number">6</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">&#123;<span class="number">1</span>: <span class="number">6</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">4</span>: <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>
<p>除了内部的list、tuple等数据类型，key还可以针对自定义的数据类型进行排序。实例如下
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">Student</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, grade, age</span>):</span><br><span class="line">                self.name = name</span><br><span class="line">                self.grade = grade</span><br><span class="line">                self.age = age</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">repr</span>((self.name, self.grade, self.age))</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">weighted_grade</span>(<span class="params">self</span>):</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&#x27;CBA&#x27;</span>.index(self.grade) / <span class="built_in">float</span>(self.age)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>student_objects = [</span><br><span class="line">        Student(<span class="string">&#x27;john&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="number">15</span>),</span><br><span class="line">        Student(<span class="string">&#x27;jane&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">12</span>),</span><br><span class="line">        Student(<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">10</span>),</span><br><span class="line">]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">sorted</span>(student_objects, key=<span class="keyword">lambda</span> student: student.age)   <span class="comment"># sort by age</span></span><br><span class="line">[(<span class="string">&#x27;dave&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">10</span>), (<span class="string">&#x27;jane&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">12</span>), (<span class="string">&#x27;john&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="number">15</span>)]</span><br></pre></td></tr></table></figure></p>
<h2 id="cmp-参数">cmp 参数</h2>
<p>利用上面两个参数已经能解决大部分的问题了，还有一些较特殊的排序需要编写特定的排序函数，这时就需要利用<code>cmp</code>参数。</p>
<p>如LeetCode上的这道题目<a
href="https://leetcode.com/problems/largest-number/">179. Largest
Number</a>，就是一道排序的题目，且排序的要求是对于两个字符串s1，s2
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">排序规则如下：</span><br><span class="line">(1)假如 s1+s2 &gt; s2+s1,则 s1 &gt; s2</span><br><span class="line">(2)假如 s1+s2 &lt; s2+s1,则 s1 &lt; s2</span><br><span class="line">(3)以上两种情况均不符合，则s1 = s2</span><br></pre></td></tr></table></figure></p>
<p>这种情况下上面所提到的两种方法都无法实现，因为上面的两个参数都是针对单个元素的特性的，而这种方法则是针对两个元素之间的关系。因此需要定义自己的排序函数。
不指定cmp参数的时候，<code>cmp = lambda x,y: cmp(x, y)</code>，这里需要注意第一个cmp是sort函数的参数，第二个cmp则是python的一个内置函数。其定义如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cmp(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">-<span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cmp(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cmp(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="number">0</span></span><br></pre></td></tr></table></figure> 对于<code>cmp(x, y)</code>,当 x 大于、等于、小于 y
时，分别会返回
1,0,-1。这个默认的cmp函数也可以写成<code>cmp = lambda x,y: x-y</code>,这种情况下是从小到大排序的，那么从大到小的排序可以写成<code>cmp = lambda x,y: y-x</code>。这等价于<code>reverse = True</code>。</p>
<p>回到题目<a href="https://leetcode.com/problems/largest-number/">179.
Largest
Number</a>上，利用内置的sorted函数，我们可以写出下面较为简洁的代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="comment"># @param &#123;integer[]&#125; nums</span></span><br><span class="line">    <span class="comment"># @return &#123;string&#125;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">largestNumber</span>(<span class="params">self, nums</span>):</span><br><span class="line">        snums = [<span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> nums]</span><br><span class="line">        snums.sort(cmp=<span class="keyword">lambda</span> x,y: cmp(y+x,x+y))</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(snums).lstrip(<span class="string">&#x27;0&#x27;</span>) <span class="keyword">or</span> <span class="string">&#x27;0&#x27;</span></span><br></pre></td></tr></table></figure>
<p>关键点在<code>snums.sort(cmp=lambda x,y: cmp(y+x,x+y))</code>这句话，首先是<code>cmp(y+x,x+y)</code>,当
<code>y+x &gt; x+y</code>时, <code>y&gt;x</code>,
此时<code>cmp(y+x,x+y)</code>返回1，而由上面的知识可知这是从大到小的排序。</p>
<p>上面可以说是比较抽象的代码，下面是通过自己实现的快排解决上面的题目，跟上面的答案一样能够AC。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="comment"># @param &#123;integer[]&#125; nums</span></span><br><span class="line">    <span class="comment"># @return &#123;string&#125;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">largestNumber</span>(<span class="params">self, nums</span>):</span><br><span class="line">        snums = [<span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> nums]</span><br><span class="line">        self.quick_sort(<span class="number">0</span>, <span class="built_in">len</span>(snums)-<span class="number">1</span>, snums)</span><br><span class="line">        tmp = <span class="string">&#x27;&#x27;</span>.join(snums).lstrip(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> tmp <span class="keyword">if</span> tmp <span class="keyword">else</span> <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">quick_sort</span>(<span class="params">self, left, right, nums</span>):</span><br><span class="line">        <span class="keyword">if</span> left &gt; right:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        pivot, start, end = left, left, right</span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[right]+nums[pivot] &lt;= nums[pivot]+nums[right]:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[left]+nums[pivot] &gt;= nums[pivot]+nums[left]:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> left &lt; right:</span><br><span class="line">                nums[left], nums[right] =nums[right], nums[left]</span><br><span class="line">        <span class="keyword">if</span> left == right:</span><br><span class="line">            nums[pivot], nums[left] = nums[left], nums[pivot]</span><br><span class="line">        self.quick_sort(start, left-<span class="number">1</span>, nums)</span><br><span class="line">        self.quick_sort(left+<span class="number">1</span>, end, nums)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python批量下载文件</title>
    <url>/2015/12/02/python%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<p>　最近感觉要练练口语了，所以就上<a
href="http://www.putclub.com/">普特</a>逛逛有哪些资源比较好的，发现<a
href="http://www.putclub.com/html/course/middleIdioms/index.html">美国惯用语板块</a>挺好的,但是点进去想下载音频时，发现浏览器已经解释了这个MP3格式的音频文件；要下载就只能右键另存为，总共有900多个，这么点来点去岂不是要点一天才能下完。
　　 <span id="more"></span></p>
<p>　　正当蛋疼之时，忽然发现了播放MP3文件的url格式比较统一，比如说下面这几个
　　<img src="https://wulc.me/imgs/2015-12-28_192255.jpg" /> 　　<img
src="https://wulc.me/imgs/2015-12-28_192318.jpg" /> 　　<img
src="https://wulc.me/imgs/2015-12-28_192345.jpg" />
　　前面的前缀都是相同的，可以推测在服务器上这些音频文件都是放到同一个文件夹下，而且会依据数字来加上前缀来命名，这就为脚本自动下载提供了一个很好的条件。
　　首先，从最简单的入手，就是下载给出url所代表的资源，代码如下
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">url=<span class="string">&quot;http://down02.putclub.com/homepage/courses/middle/oftenused/wi_01.mp3&quot;</span></span><br><span class="line">f=urllib2.urlopen(url)</span><br><span class="line">data=f.read()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;1.mp3&quot;</span>,<span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.write(data)</span><br></pre></td></tr></table></figure></p>
<p>　　如果资源url的确存在，那执行脚本后会在当前目录生成跟一个名为1.mp3的音频文件，当然名称也可以自己取，这里为了简便就直接用数字来作为文件名了。如果资源url不存在则在<code>urlopen</code>时就会抛出一个<code>URLError</code>(实际上也的确有某几期不提供音频文件)。根据测试，发现音频文件的前缀有<code>wi</code>、<code>wi_</code>、<code>putclub_mgxgy</code>、<code>wi_0</code>这几种。所以总体思路就是先得到合法的url，再将其下载；因为基于数字命名，所以可以通过循环来批量下载。是不是很简单，这里给出完整的代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="comment">#下载普特英语文音频件的脚本</span></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="comment">#得到合法的资源url</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getLegalUrl</span>(<span class="params">i</span>):</span><br><span class="line">    base_url=<span class="string">&quot;http://down02.putclub.com/homepage/courses/middle/oftenused/&quot;</span></span><br><span class="line">    url_preletter_list=[<span class="string">&#x27;wi_&#x27;</span>,<span class="string">&#x27;wi&#x27;</span>,<span class="string">&#x27;putclub_mgxgy&#x27;</span>,<span class="string">&#x27;wi_0&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> url_preletter_list:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url=base_url+j+<span class="built_in">str</span>(i)+<span class="string">&#x27;.mp3&#x27;</span></span><br><span class="line">            f=urllib2.urlopen(url)</span><br><span class="line">            <span class="keyword">return</span> url   <span class="comment">#不合法的url会抛出URLError的错误，不抛出则说明url存在</span></span><br><span class="line">        <span class="keyword">except</span> urllib2.URLError:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#下载给定的合法的url的资源</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">url,i</span>):</span><br><span class="line">    f=urllib2.urlopen(url)</span><br><span class="line">    data=f.read()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="built_in">str</span>(i)+<span class="string">&#x27;.mp3&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        file.write(data) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">600</span>):</span><br><span class="line">        url=getLegalUrl(i)</span><br><span class="line">        <span class="keyword">if</span> url == <span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="comment">#记录无法下载的那几期，以便验证是否资源本来就没有</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;download.log&quot;</span>,<span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> log:</span><br><span class="line">                log.write(<span class="built_in">str</span>(i)+<span class="string">&#x27; not found\n&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            download(url,i)</span><br><span class="line">            </span><br></pre></td></tr></table></figure>
<p>等到脚本执行完，在文件夹下就能得到下面这些文件,密集恐惧者可忽略 <img
src="https://wulc.me/imgs/2015-12-28_195823.jpg" />
日志如下，经检查，这些资源本来就不存在 <img
src="https://wulc.me/imgs/2015-12-30_101519.jpg" /></p>
<p>这个方法只限于那些资源名称有规律的文件下载，但是好像普特上的文件都是这么存储的，所以以后就能愉快的下载了。
对于我这种小白而言只能想出这种方法，如果你有更好的方法，欢迎交流。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>python网络编程</title>
    <url>/2016/06/03/python%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<p>网络编程根据协议划分可以划分为TCP编程和UDP编程。两者的主要区别在于效率和可靠性，下面分别讲述两者在python中的实现</p>
<span id="more"></span>
<h2 id="tcp编程">TCP编程</h2>
<h3 id="客户端">客户端</h3>
<p>要创建一个基于TCP连接的Socket，可以这样做： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br></pre></td></tr></table></figure>
创建Socket时，<code>AF_INET</code>指定使用IPv4协议，如果要用更先进的IPv6，就指定为<code>AF_INET6</code>。<code>SOCK_STREAM</code>指定使用面向流的TCP协议，这样，一个Socket对象就创建成功，但是还没有建立连接。</p>
<p>客户端要主动发起TCP连接，必须知道服务器的IP地址和端口号.接着上面的代码，通过创建的socket连接到本地服务器上。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">host = (<span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">80</span>) <span class="comment"># tuple类型</span></span><br><span class="line">s.connect(host)</span><br><span class="line">s.send(<span class="string">&#x27;GET / HTTP/1.1\r\nHost: 127.0.0.1\r\nConnection: close\r\n\r\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>建立TCP连接后，我们就可以向服务器发送请求。但是由于<strong>TCP连接创建的是双向通道，双方都可以同时给对方发数据</strong>。但是<strong>谁先发谁后发，怎么协调，要根据具体的协议来决定</strong>。例如，HTTP协议规定客户端必须先发请求给服务器，服务器收到后才发数据给客户端。</p>
<p>发送的文本格式必须<strong>符合HTTP标准</strong>，如果格式没问题，接下来就可以接收服务器返回的数据了：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 接收数据:</span></span><br><span class="line">buffer = []</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 每次最多接收1k字节:</span></span><br><span class="line">    d = s.recv(<span class="number">1024</span>)</span><br><span class="line">    <span class="keyword">if</span> d:</span><br><span class="line">        buffer.append(d)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">data = <span class="string">&#x27;&#x27;</span>.join(buffer)</span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure>
接收数据时，调用<code>recv(max)</code>方法，<strong>一次最多接收指定的字节数</strong>，因此，在一个while循环中反复接收，直到recv()返回空数据，表示接收完毕，退出循环。当我们接收完数据后，调用<code>close()</code>方法关闭Socket，这样，一次完整的网络通信就结束了：</p>
<h3 id="服务器端">服务器端</h3>
<p>服务器进程首先要<strong>绑定一个端口并监听</strong>来自其他客户端的连接。如果某个客户端连接过来了，服务器就与该客户端建立Socket连接，随后的通信就靠这个Socket连接了</p>
<p>服务器需要同时响应多个客户端的请求，所以，<strong>每个连接都需要一个新的进程或者新的线程来处理，否则，服务器一次就只能服务一个客户端了</strong>。</p>
<p>首先，创建一个基于IPv4和TCP协议的Socket：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br></pre></td></tr></table></figure>
<p>然后，我们要绑定监听的地址和端口。<strong>服务器可能有多块网卡，可以绑定到某一块网卡的IP地址上，也可以用0.0.0.0绑定到所有的网络地址</strong>，还可以用127.0.0.1绑定到本机地址。<strong>127.0.0.1是一个特殊的IP地址，表示本机地址，如果绑定到这个地址，客户端必须同时在本机运行才能连接</strong>，也就是说，外部的计算机无法连接进来。</p>
<p>端口号需要预先指定。因为我们写的这个服务不是标准服务，所以用9999这个端口号。请注意，<strong>小于1024的端口号必须要有管理员权限才能绑定</strong>,紧接着，调用<code>listen()</code>方法开始监听端口，<strong>传入的参数指定等待连接的最大数量</strong>：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绑定并监听端口:</span></span><br><span class="line">s.bind((<span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">9999</span>))</span><br><span class="line">s.listen(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Waiting for connection...&#x27;</span></span><br></pre></td></tr></table></figure>
<p>接下来，服务器程序通过一个<strong>永久循环</strong>来接受来自客户端的连接，<code>accept()</code>会等待并返回一个客户端的连接:
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 接受一个新连接:</span></span><br><span class="line">    sock, addr = s.accept()</span><br><span class="line">    <span class="comment"># 创建新线程来处理TCP连接:</span></span><br><span class="line">    t = threading.Thread(target=tcplink, args=(sock, addr))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure></p>
<p>每个连接都必须创建新线程（或进程）来处理，否则，单线程在处理连接的过程中，无法接受其他客户端的连接：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tcplink</span>(<span class="params">sock, addr</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Accept new connection from %s:%s...&#x27;</span> % addr</span><br><span class="line">    sock.send(<span class="string">&#x27;Welcome!&#x27;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = sock.recv(<span class="number">1024</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> data == <span class="string">&#x27;exit&#x27;</span> <span class="keyword">or</span> <span class="keyword">not</span> data:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        sock.send(<span class="string">&#x27;Hello, %s!&#x27;</span> % data)</span><br><span class="line">    sock.close()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Connection from %s:%s closed.&#x27;</span> % addr</span><br></pre></td></tr></table></figure></p>
<p>要测试这个服务器程序，示例的客户端程序如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line"><span class="comment"># 建立连接:</span></span><br><span class="line">s.connect((<span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">9999</span>))</span><br><span class="line"><span class="comment"># 接收欢迎消息:</span></span><br><span class="line"><span class="built_in">print</span> s.recv(<span class="number">1024</span>)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> [<span class="string">&#x27;Michael&#x27;</span>, <span class="string">&#x27;Tracy&#x27;</span>, <span class="string">&#x27;Sarah&#x27;</span>]:</span><br><span class="line">    <span class="comment"># 发送数据:</span></span><br><span class="line">    s.send(data)</span><br><span class="line">    <span class="built_in">print</span> s.recv(<span class="number">1024</span>)</span><br><span class="line">s.send(<span class="string">&#x27;exit&#x27;</span>)</span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure> ##
UDP编程</p>
<h3 id="客户端-1">客户端</h3>
<p>客户端使用UDP时，首先要创建基于UDP的Socket，然后，不需要调用<code>connect()</code>，直接通过<code>sendto()</code>给服务器发数据：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> [<span class="string">&#x27;Michael&#x27;</span>, <span class="string">&#x27;Tracy&#x27;</span>, <span class="string">&#x27;Sarah&#x27;</span>]:</span><br><span class="line">    <span class="comment"># 发送数据:</span></span><br><span class="line">    s.sendto(data, (<span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">9999</span>))</span><br><span class="line">    <span class="comment"># 接收数据:</span></span><br><span class="line">    <span class="built_in">print</span> s.recv(<span class="number">1024</span>)</span><br><span class="line">s.close()</span><br></pre></td></tr></table></figure></p>
<p>创建Socket时，<code>SOCK_DGRAM</code>指定了这个Socket的类型是UDP,TCP则是<code>SOCK_STREAM</code>。</p>
<p>从服务器接收数据仍然调用<code>recv()</code>方法。</p>
<h3 id="服务器端-1">服务器端</h3>
<p>TCP是建立可靠连接，相对TCP，UDP则是面向无连接的协议。</p>
<p>使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直接发数据包。但是，能不能到达就不知道了。</p>
<p>虽然用UDP传输数据不可靠，但它的优点是和TCP比，速度快，对于不要求可靠到达的数据，就可以使用UDP协议。</p>
<p>和TCP类似，使用UDP的通信双方也分为客户端和服务器。服务器首先需要绑定端口：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</span><br><span class="line"># 绑定端口:</span><br><span class="line">s.bind((&#x27;127.0.0.1&#x27;, 9999))</span><br></pre></td></tr></table></figure>
创建Socket时，<code>SOCK_DGRAM</code>指定了这个Socket的类型是UDP,TCP则是<code>SOCK_STREAM</code>。绑定端口和TCP一样，但是不需要调用<code>listen()</code>方法，而是直接接收来自任何客户端的数据：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Bind UDP on 9999...&#x27;</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 接收数据:</span></span><br><span class="line">    data, addr = s.recvfrom(<span class="number">1024</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Received from %s:%s.&#x27;</span> % addr</span><br><span class="line">    s.sendto(<span class="string">&#x27;Hello, %s!&#x27;</span> % data, addr)</span><br></pre></td></tr></table></figure>
<p><code>recvfrom()</code>方法返回数据和客户端的地址与端口，这样，服务器收到数据后，直接调用<code>sendto()</code>就可以把数据用UDP发给客户端。</p>
<hr />
<p>参考：
http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/00138683226192949cd41410a6d4f1ebfa9ba40bbd1399d000</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>python读取文件夹下所有文件的一种方法</title>
    <url>/2016/02/10/python%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>在数据挖掘中需要大量的数据，这些数据往往存储在数据库中或者文件中。存储数据库中比较好理解，可通过
<code>程序数据库接口+SQL语句</code>
获取。存储在文件中则往往有多个按日期命名的文件夹，数据以文本格式存储，且有特定的分割符。本文主要就是讲述如何通过python读取后一类的数据。</p>
<span id="more"></span>
<p><strong>总体思路就是先获取给定目录下所有文件的绝对路径，包括给定目录下的子目录；然后再读取每个文件的内容。</strong></p>
<p>首先要获取给定目录下的所有文件的绝对路径，python的<code>os.listdir(dirPath)</code>方法可以列出<code>dirPath</code>下的所有文件和文件夹。为了处理<code>dirPath</code>下的子目录，需要判断读出的一个对象a是否为文件夹，可以通过<code>os.path.isdir(a)</code>来判断读出的a是否为一个文件夹，如果是，则<strong>递归读出下面的文件</strong>。</p>
<p>实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="comment"># 功能：读取传入的目录下所有的文件（包括该目录下的所有子目录）的绝对路径，并以列表形式返回所有文件的绝对路径</span></span><br><span class="line"><span class="comment"># 要求传入的路径参数最后不能有斜杠,目的是为了递归时格式统一</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">readDir</span>(<span class="params">dirPath</span>):</span><br><span class="line">    <span class="keyword">if</span> dirPath[-<span class="number">1</span>] == <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">u&#x27;文件夹路径末尾不能加/&#x27;</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    allFiles = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(dirPath):</span><br><span class="line">        fileList = os.listdir(dirPath)</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> fileList:</span><br><span class="line">            f = dirPath+<span class="string">&#x27;/&#x27;</span>+f</span><br><span class="line">            <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">                subFiles = readDir(f)</span><br><span class="line">                allFiles = subFiles + allFiles <span class="comment">#合并当前目录与子目录的所有文件路径</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                allFiles.append(f)</span><br><span class="line">        <span class="keyword">return</span> allFiles</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Error,not a dir&#x27;</span></span><br></pre></td></tr></table></figure></p>
<p>将上面的代码命名为<code>ReadDirFiles.py</code>,便于被下面调用。现在已经可以得到某一目录下所有文件的绝对路径，下面只需要读出这些文件里面的内容即可。</p>
<p><strong>为了存储的便利性，用文件存储数据时往往一行存储一条记录，一条记录中不同字段以特定分隔符分开。</strong>下面的代码就是解决这类型的数据的</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="comment"># 功能：解析文件中按行存放的数据，行内数据以SOH（\001）分割</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ReadDirFiles</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">readFile</span> (filePath):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filePath) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">            data = line.split(<span class="string">&#x27;\001&#x27;</span>) <span class="comment">#以列表形式返回分割了的行数据</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">                <span class="built_in">print</span> i</span><br><span class="line">             </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dirPath = <span class="string">&#x27;G:/20160107&#x27;</span></span><br><span class="line">    fileList=ReadDirFiles.readDir(dirPath)</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> fileList:</span><br><span class="line">        readFile(f)</span><br></pre></td></tr></table></figure>
<p>上面有两个需要注意的地方：</p>
<p>1）建议采用
<code>with open(filePath) as f</code>方法打开文件，因为这种方法不需要显示调用<code>f.close()</code>来关闭文件。open函数可在第二个形参位置决定打开文件的模式，有读（a）、写（w）、追加（a）等，省略时默认为读。</p>
<p>2）读取文件的行时，有readline和readlines两种方法，前者每次读一行，后者一次把文件全部行读入内存，显然后者的效率比前者要高。只有当内存太小或文件过大，无法一次全部读入内存才建议采用第一种方法。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python连接mysql及其注意事项</title>
    <url>/2016/02/24/python%E8%BF%9E%E6%8E%A5mysql%E5%8F%8A%E5%85%B6%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/</url>
    <content><![CDATA[<p>本文主要讲述利用 python
连接数据库的过程和部分注意事项。文章不会涉及到连接的原理，只是简单介绍连接的步骤，以及
mysql 不同的引擎连接的过程的细微区别。 <span id="more"></span></p>
<p>基本上任何语言与数据库进行交互都需要引入外部的数据库驱动，在 python
操作mysql数据库中常用的就是<code>MySQLdb</code>这个驱动，后面也会以这个为例子进行讲解。</p>
<p>数据库的最常见的操作就是“增删查改”，实现这几个功能需要对应的SQL语句。而通过程序连接数据库实际上就是获得与数据库的连接，通过这个连接执行SQL命令，得到返回结果（如果有返回结果的话）。</p>
<p>因此，通过 python 操作 mysql 的步骤可以概括为下面3个步骤：
<strong>1.获得连接 2.获取游标
3.通过游标执行SQL语句，获取返回结果（如果有）</strong></p>
<h2 id="获得连接">** 获得连接**</h2>
<p>获得连接的代码如下 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line">HOST = XXXX</span><br><span class="line">PORT = XXXX</span><br><span class="line">USER = XXXX</span><br><span class="line">PASSWD = XXXX</span><br><span class="line">DB = XXXX</span><br><span class="line">CHARSET = XXXX</span><br><span class="line"></span><br><span class="line">conn = MySQLdb.connect(host=HOST,port=PORT,user=USER,passwd=PASSWD,db=DB,charset=CHARSET)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
一开始声明的几个常量表示要连接到哪台机器的哪个数据库以及采用的编码，<strong>注意除了PORT为整数类型，其余都为字符类型。</strong></p>
<p>假如在某个工程中有多个地方需要操作数据库，可以将这个写成一个函数。如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">connectDB</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        conn = MySQLdb.connect(passwd=PASSWD, host=HOST, user=USER, port=PORT, db=DB, charset=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> conn</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>可通过返回值是不是0判断是否建立了正常连接。</p>
<h2 id="获取游标"><strong>获取游标</strong></h2>
<p>获得连接后，我们希望做的就是执行我们的 SQL
语句，但是在MySQLdb中，conn并不能执行此操作。<strong>需要通过游标（cursor）来执行命令并保存执行的结果，而游标可通过第一步得到的连接获取</strong>。代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cursor = conn.cursor()</span><br></pre></td></tr></table></figure>
<h2
id="执行sql语句获得返回结果"><strong>执行SQL语句，获得返回结果</strong></h2>
<p>可以通过<code>cursor.execute(SQL)</code>来执行SQL语句，通过<code>cursor.fetchall()</code>获取返回的结果（针对select语句）
这里获取返回结果针对的是查询（select）语句。</p>
<p><strong>查询</strong>的代码代码如下 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">SQL = <span class="string">&quot;select * from table&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    cursor.execute(SQL)</span><br><span class="line">    resultSet = cursor.fetchall()</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> resultSet:</span><br><span class="line">       <span class="keyword">for</span> i <span class="keyword">in</span> row:</span><br><span class="line">           <span class="built_in">print</span> i</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;error while querying&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span> </span><br><span class="line"><span class="keyword">finally</span>:</span><br></pre></td></tr></table></figure>
执行的SQL语句返回的结果集可以认为是一个嵌套的两级列表，数据库中每一条记录是一级列表中的一个元素。</p>
<p><strong>插入新纪录</strong>的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line">SQL = <span class="string">&#x27;insert into table(field) values(%s) &#x27;</span> %record</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    cursor.execute(SQL)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;error while querying&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>     </span><br></pre></td></tr></table></figure></p>
<p>另外删除和更新的代码也类似，只是SQL语句不同而已。</p>
<p><strong>这里需要注意的一点就是上面的代码有可能执行成功，但是数据库中不会更新记录。</strong></p>
<p>原因是mysql的引擎问题，<strong>假如mysql的引擎是MyISAM，那么上面的代码就没问题，但是假如mysql的引擎是InnoDB，那么上面的插入新纪录的代码将不会执行成功。</strong>因为InnoDB的是支持事务处理的，执行更新的操作会在mysql事先分配的缓存中进行，只有提交后，修改才能生效。提交的操作也很简单,就是在cursor.execute()后加上这句：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">conn.commit()</span><br></pre></td></tr></table></figure> 关于这个问题，<a
href="http://mysql-python.sourceforge.net/MySQLdb.html">MySQLdb官网说明</a>如下：</p>
<blockquote>
<p>commit() If the database and the tables support transactions, this
commits the current transaction; otherwise this method successfully does
nothing. rollback() If the database and tables support transactions,
this rolls back (cancels) the current transaction; otherwise a
NotSupportedError is raised.</p>
</blockquote>
<p>从说明中可以看到，commit()函数对于支持事务的引擎生效，对于不支持事务的引擎也不会报错，所以<strong>建议在代码中均使用</strong>。除了commit()函数外，对于支持事务的引擎还有一个rollback()函数用于执行失败后的回滚，但是这个只能在支持事务的引擎上使用。</p>
<p>最后，上个完整的代码 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="comment"># 将数据文件的数据导入到mysql数据库中</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"><span class="keyword">import</span> ReadDirFiles</span><br><span class="line"></span><br><span class="line">HOST = XXXX</span><br><span class="line">PORT = XXXX</span><br><span class="line">USER = XXXX</span><br><span class="line">PASSWD = XXXX</span><br><span class="line">DB = XXXX</span><br><span class="line">CHARSET = XXXX</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">connectDB</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        conn = MySQLdb.connect(host=HOST, user=USER, passwd=PASSWD, port=PORT, db=DB, charset=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> conn</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;error connecting the database&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">importData</span>():</span><br><span class="line">    conn = connectDB()</span><br><span class="line">    <span class="keyword">if</span> conn == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    cursor = conn.cursor()</span><br><span class="line">    SQL = <span class="string">&#x27;insert into `ad_log` values(&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;) &#x27;</span> %<span class="built_in">tuple</span></span><br><span class="line">    <span class="comment"># print SQL # 检查SQL语句是否正确</span></span><br><span class="line">    <span class="comment"># 下面的代码是一个事务</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cursor.execute(SQL)</span><br><span class="line">        conn.commit()  </span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;successfully insert the record&#x27;</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        conn.rollback() <span class="comment">#引擎不支持事务时会报错</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        cursor.close()</span><br><span class="line">        conn.close()</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>sae上通过python获取访问网站ip及其来源</title>
    <url>/2015/12/22/sae%E4%B8%8A%E9%80%9A%E8%BF%87python%E8%8E%B7%E5%8F%96%E8%AE%BF%E9%97%AE%E7%BD%91%E7%AB%99ip%E5%8F%8A%E5%85%B6%E6%9D%A5%E6%BA%90/</url>
    <content><![CDATA[<p>这篇文章是当时在新浪云上搭建博客时写的，后来因为新浪云开始各种收费了，所以就把博客转到了github上。这里还是把文章贴出来，做个记录</p>
<p>常常看到有些网站会显示访问过该网站的所有人数及其分布地点，所以就琢磨着这个怎么实现，好给自己的网站也添加上去；在google上搜了一下发现大都是通过分析日志得出的，而新浪云上也提供了日志访问的API，所以下面就说说怎么通过这个API获取访问的IP及其来源地。</p>
<span id="more"></span>
<p>大致的步骤就是<strong>先通过身份校验获取访问日志的权限，然后通过HTTP请求摘取日志中表示访问ip和访问次数的段记录。剔除其中的私网IP，再获取IP所在地，存入数据库。</strong></p>
<p>下面为具体的实施步骤</p>
<h2
id="获取访问的ip及其访问次数"><strong>获取访问的IP及其访问次数</strong></h2>
<h3 id="身份验证">身份验证</h3>
<p>这个是新浪提供的用于校验身份的一个api，校验身份是通过应用的<strong>ACESSKEY和SECRETKEY</strong>来实现的。</p>
<p>代码下载链接地址：https://raw.githubusercontent.com/sinacloud/sae-python-dev-guide/master/examples/apibus/apibus_handler.py</p>
<p>也可复制下面的代码创建一个python源文件，命名为<code>apibus_handler.py</code>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*-coding: utf8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">SAE API auth handler for urllib2 and requests</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">urllib2:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>import urllib2</span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>apibus_handler = SaeApibusAuthHandler(ACCESSKEY, SECRETKEY)</span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>opener = urllib2.build_opener(apibus_handler)</span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>print opener.open(&#x27;http://g.sae.sina.com.cn/log/http/2015-06-18/1-access.log&#x27;).read()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">requests:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>import requests</span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>print requests.get(&#x27;http://g.sae.sina.com.cn/log/http/2015-06-18/1-access.log?head/0/10|fields/ /1/2/3/4&#x27;, auth=SaeApibusAuth(ACCESSKEY, SECRETKEY)).content</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hmac</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> urllib2 <span class="keyword">import</span> BaseHandler, Request</span><br><span class="line"></span><br><span class="line">_APIBUS_URL_PREFIX = <span class="string">&#x27;http://g.sae.sina.com.cn/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SaeApibusAuthHandler</span>(<span class="title class_ inherited__">BaseHandler</span>):</span><br><span class="line">    <span class="comment"># apibus handler must be in front</span></span><br><span class="line">    handler_order = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, accesskey, secretkey</span>):</span><br><span class="line">        self.accesskey = accesskey</span><br><span class="line">        self.secretkey = secretkey</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">http_request</span>(<span class="params">self, req</span>):</span><br><span class="line">        orig_url = req.get_full_url()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> orig_url.startswith(_APIBUS_URL_PREFIX):</span><br><span class="line">            <span class="keyword">return</span> req</span><br><span class="line"></span><br><span class="line">        timestamp = <span class="built_in">str</span>(<span class="built_in">int</span>(time.time()))</span><br><span class="line">        headers = [</span><br><span class="line">            (<span class="string">&#x27;x-sae-timestamp&#x27;</span>, timestamp),</span><br><span class="line">            (<span class="string">&#x27;x-sae-accesskey&#x27;</span>, self.accesskey),</span><br><span class="line">        ]</span><br><span class="line">        req.headers.update(headers)</span><br><span class="line"></span><br><span class="line">        method = req.get_method()</span><br><span class="line">        resource = urllib.unquote(req.get_full_url()[<span class="built_in">len</span>(_APIBUS_URL_PREFIX)-<span class="number">1</span>:])</span><br><span class="line">        sae_headers = [(k.lower(), v.lower()) <span class="keyword">for</span> k, v <span class="keyword">in</span> req.headers.items() <span class="keyword">if</span> k.lower().startswith(<span class="string">&#x27;x-sae-&#x27;</span>)]</span><br><span class="line">        req.add_header(<span class="string">&#x27;Authorization&#x27;</span>, _signature(self.secretkey, method, resource, sae_headers))</span><br><span class="line">        <span class="keyword">return</span> req</span><br><span class="line"></span><br><span class="line">    https_request = http_request</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> requests.auth <span class="keyword">import</span> AuthBase</span><br><span class="line"></span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">SaeApibusAuth</span>(<span class="title class_ inherited__">AuthBase</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Attaches HTTP Basic Authentication to the given Request object.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, accesskey, secretkey</span>):</span><br><span class="line">            self.accesskey = accesskey</span><br><span class="line">            self.secretkey = secretkey</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, r</span>):</span><br><span class="line">            timestamp = <span class="built_in">str</span>(<span class="built_in">int</span>(time.time()))</span><br><span class="line">            r.headers[<span class="string">&#x27;x-sae-timestamp&#x27;</span>] = timestamp</span><br><span class="line">            r.headers[<span class="string">&#x27;x-sae-accesskey&#x27;</span>] = self.accesskey</span><br><span class="line">            resource = urllib.unquote(r.url[<span class="built_in">len</span>(_APIBUS_URL_PREFIX)-<span class="number">1</span>:])</span><br><span class="line">            <span class="comment">#resource = r.url[len(_APIBUS_URL_PREFIX)-1:]</span></span><br><span class="line">            sae_headers = [(k.lower(), v.lower()) <span class="keyword">for</span> k, v <span class="keyword">in</span> r.headers.items() <span class="keyword">if</span> k.lower().startswith(<span class="string">&#x27;x-sae-&#x27;</span>)]</span><br><span class="line">            r.headers[<span class="string">&#x27;Authorization&#x27;</span>] = _signature(self.secretkey, r.method, resource, sae_headers)</span><br><span class="line">            <span class="keyword">return</span> r</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="comment"># requests was not present!</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_signature</span>(<span class="params">secret, method, resource, headers</span>):</span><br><span class="line">    msgToSign = <span class="string">&quot;\n&quot;</span>.join([</span><br><span class="line">        method, resource,</span><br><span class="line">        <span class="string">&quot;\n&quot;</span>.join([(k + <span class="string">&quot;:&quot;</span> + v) <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">sorted</span>(headers)]),</span><br><span class="line">    ])</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;SAEV1_HMAC_SHA256 &quot;</span> + base64.b64encode(hmac.new(secret, msgToSign, hashlib.sha256).digest())</span><br></pre></td></tr></table></figure></p>
<h3 id="通过http请求获取日志">通过http请求获取日志</h3>
<p>提供了通过requests包和urllib包两种方式，代码来源后面的参考文章,将下面代码保存成<code>sae_log_util.py</code>即可：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-*-coding: utf8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#sae_log_util.py</span></span><br><span class="line"><span class="comment">#sae log utility based on sae apibus_handler</span></span><br><span class="line"><span class="comment">#author blog: http://bookshadow.com</span></span><br><span class="line"><span class="comment">#src date: 2015-09-17</span></span><br><span class="line"></span><br><span class="line">status_code_dict = &#123;<span class="number">200</span> : <span class="string">&#x27;OK&#x27;</span>, <span class="number">206</span> : <span class="string">&#x27;Partial Content&#x27;</span>, <span class="number">400</span> : <span class="string">&#x27;Bad Request&#x27;</span>, \</span><br><span class="line">                              <span class="number">500</span> : <span class="string">&#x27;Internal Server Error&#x27;</span> , <span class="number">404</span> : <span class="string">&#x27;Not Found&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">service_ident_dict = &#123;<span class="string">&#x27;http&#x27;</span>: [<span class="string">&#x27;access&#x27;</span>, <span class="string">&#x27;error&#x27;</span>, <span class="string">&#x27;alert&#x27;</span>, <span class="string">&#x27;debug&#x27;</span>, <span class="string">&#x27;warning&#x27;</span>, <span class="string">&#x27;notice&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;taskqueue&#x27;</span> : [<span class="string">&#x27;error&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;cron&#x27;</span> : [<span class="string">&#x27;error&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;mail&#x27;</span>: [<span class="string">&#x27;access&#x27;</span>, <span class="string">&#x27;error&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;rdc&#x27;</span> : [<span class="string">&#x27;error&#x27;</span>, <span class="string">&#x27;warning&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;storage&#x27;</span> : [<span class="string">&#x27;access&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;push&#x27;</span> : [<span class="string">&#x27;access&#x27;</span>], \</span><br><span class="line">    <span class="string">&#x27;fetchurl&#x27;</span> : [<span class="string">&#x27;access&#x27;</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">_URL_PREFIX = <span class="string">&#x27;http://g.sae.sina.com.cn/log/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SaeLogFetcher</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, access_key, secret_key</span>):</span><br><span class="line">        self.access_key = access_key</span><br><span class="line">        self.secret_key = secret_key</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fetch_log</span>(<span class="params">self, service, date, ident, fop = <span class="string">&#x27;&#x27;</span>, version = <span class="number">1</span></span>):</span><br><span class="line">        <span class="keyword">assert</span> self.access_key, <span class="string">&#x27;access_key should not be empty&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> self.secret_key, <span class="string">&#x27;secret_key should not be empty&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> service <span class="keyword">in</span> service_ident_dict, <span class="string">&#x27;invalid service parameter&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> ident <span class="keyword">in</span> service_ident_dict[service], <span class="string">&#x27;invalid ident parameter&#x27;</span></span><br><span class="line"></span><br><span class="line">        url = _URL_PREFIX + service + <span class="string">&#x27;/&#x27;</span> + date + <span class="string">&#x27;/&#x27;</span> + <span class="built_in">str</span>(version) + <span class="string">&#x27;-&#x27;</span> + ident + <span class="string">&#x27;.log&#x27;</span></span><br><span class="line">        content = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> requests</span><br><span class="line">            <span class="keyword">from</span> apibus_handler <span class="keyword">import</span> SaeApibusAuth</span><br><span class="line">            r = requests.get(url + (<span class="string">&#x27;?&#x27;</span> + fop <span class="keyword">if</span> fop <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span>), \</span><br><span class="line">                     auth=SaeApibusAuth(self.access_key, self.secret_key))</span><br><span class="line">            status_code, status = r.status_code, status_code_dict.get(r.status_code, <span class="string">&#x27;Unknown&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> status_code == <span class="number">200</span>:</span><br><span class="line">                content = r.content</span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            <span class="comment"># requests was not present!</span></span><br><span class="line">            <span class="keyword">from</span> apibus_handler <span class="keyword">import</span> SaeApibusAuthHandler</span><br><span class="line">            <span class="keyword">import</span> urllib, urllib2</span><br><span class="line">            apibus_handler = SaeApibusAuthHandler(self.access_key, self.secret_key)</span><br><span class="line">            opener = urllib2.build_opener(apibus_handler)</span><br><span class="line">            <span class="keyword">if</span> fop:</span><br><span class="line">                url += <span class="string">&#x27;?&#x27;</span> + urllib.quote(fop, safe=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            content = opener.<span class="built_in">open</span>(url).read()</span><br><span class="line">        <span class="keyword">return</span> content</span><br></pre></td></tr></table></figure></p>
<h3 id="调用上面的代码">调用上面的代码</h3>
<p>下面通过代码获取访问过的ip及次数,代码也是来源于参考链接，可将代码复制后另存为<code>ip_counter.py</code>：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#-*-coding: utf8 -*-</span><br><span class="line">#ip_counter.py</span><br><span class="line">#ip counter based on  sae_log_util</span><br><span class="line">#author blog: http://bookshadow.com</span><br><span class="line">#src date: 2015-09-17</span><br><span class="line"></span><br><span class="line">from collections import Counter</span><br><span class="line">from sae_log_util import SaeLogFetcher</span><br><span class="line"></span><br><span class="line">date = &#x27;2015-09-16&#x27;</span><br><span class="line">service = &#x27;http&#x27;</span><br><span class="line">ident = &#x27;access&#x27;</span><br><span class="line">fop = &#x27;fields/ /2&#x27; #fetch ip only</span><br><span class="line">version = 1</span><br><span class="line"></span><br><span class="line">ACCESSKEY = &#x27;&lt;&lt;ACCESSKEY&gt;&gt;&#x27;</span><br><span class="line">SECRETKEY = &#x27;&lt;&lt;SECRETKEY&gt;&gt;&#x27;</span><br><span class="line"></span><br><span class="line">log_fetcher = SaeLogFetcher(ACCESSKEY, SECRETKEY)</span><br><span class="line"></span><br><span class="line">result = log_fetcher.fetch_log(service, date, ident, fop, version)</span><br><span class="line"></span><br><span class="line">content = result.split(&#x27;\n&#x27;)[:-1]</span><br><span class="line"></span><br><span class="line">for e, c in Counter(content).most_common():</span><br><span class="line">    print e, c</span><br></pre></td></tr></table></figure>
将代码内的<code>&lt;&lt;ACCESSKEY&gt;&gt;</code>与<code>&lt;&lt;SECRETKEY&gt;&gt;</code>替换为你的sae应用具体的值。</p>
<p>然后将上面的代码放到同一个工作目录，执行<code>ip_counter.py</code>这个文件，即可获取访问的ip，</p>
<h2 id="剔除私网ip">剔除私网IP</h2>
<p>上面显示出出来的结果会显示出有私网ip，猜测是sae内部一些服务器间的通信，比如说<code>memcached</code>、<code>mysql</code>等服务与应用不在同一台服务器等，但是无论如何，这些私网ip都是我们不希望看到的，所以下面是剔除私网IP的过程。</p>
<p>私网IP总共有A、B、C三类，而每一类IP的nei-id均是固定的，详见下面所示：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A类：10.0.0.0/8： 10.0.0.0～10.255.255.255</span><br><span class="line">B类：172.16.0.0/12： 172.16.0.0～172.31.255.255</span><br><span class="line">C类：192.168.0.0/16： 192.168.0.0～192.168.255.255</span><br></pre></td></tr></table></figure>
这样便可将IP移位后与三类私网IP的net-id比较，从而判断该IP是否属于私网IP。实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ip_into_int</span>(<span class="params">ip</span>):</span><br><span class="line">    <span class="comment">#以192.168.1.13为例，先把 192.168.1.13 变成16进制的 c0.a8.01.0d ，再去了“.”后转成10进制的 3232235789 即可。</span></span><br><span class="line">    <span class="comment">#(((((192 * 256) + 168) * 256) + 1) * 256) + 13</span></span><br><span class="line">    <span class="keyword">return</span> reduce(<span class="keyword">lambda</span> x,y:(x&lt;&lt;<span class="number">8</span>)+y,<span class="built_in">map</span>(<span class="built_in">int</span>,ip.split(<span class="string">&#x27;.&#x27;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_internal_ip</span>(<span class="params">ip</span>):</span><br><span class="line">    ip = ip_into_int(ip)</span><br><span class="line">    net_a = ip_into_int(<span class="string">&#x27;10.255.255.255&#x27;</span>) &gt;&gt; <span class="number">24</span></span><br><span class="line">    net_b = ip_into_int(<span class="string">&#x27;172.31.255.255&#x27;</span>) &gt;&gt; <span class="number">20</span></span><br><span class="line">    net_c = ip_into_int(<span class="string">&#x27;192.168.255.255&#x27;</span>) &gt;&gt; <span class="number">16</span></span><br><span class="line">    <span class="keyword">return</span> ip &gt;&gt; <span class="number">24</span> == net_a <span class="keyword">or</span> ip &gt;&gt;<span class="number">20</span> == net_b <span class="keyword">or</span> ip &gt;&gt; <span class="number">16</span> == net_c</span><br></pre></td></tr></table></figure>
<h2 id="查询ip所在地">查询IP所在地</h2>
<p>可以通过<a
href="http://ip.taobao.com/">淘宝</a>提供的API来查询IP所在地，查询代码如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入的ip的数据结构为字典:&#123;&#x27;ip&#x27;:具体的ip地址&#125;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_ip_place</span>(<span class="params">ip</span>):</span><br><span class="line">    URL = <span class="string">&#x27;http://ip.taobao.com/service/getIpInfo.php&#x27;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(URL, params=ip, timeout=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        json_data = r.json()</span><br><span class="line">        <span class="keyword">if</span> json_data[<span class="string">&#x27;code&#x27;</span>] == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">u&#x27;所在国家:&#x27;</span>,json_data[<span class="string">u&#x27;data&#x27;</span>][<span class="string">u&#x27;country&#x27;</span>]</span><br><span class="line">            <span class="built_in">print</span> <span class="string">u&#x27;所在地区:&#x27;</span>,json_data[<span class="string">u&#x27;data&#x27;</span>][<span class="string">u&#x27;area&#x27;</span>]</span><br><span class="line">            <span class="built_in">print</span> <span class="string">u&#x27;所在省份:&#x27;</span>,json_data[<span class="string">u&#x27;data&#x27;</span>][<span class="string">u&#x27;region&#x27;</span>]</span><br><span class="line">            <span class="built_in">print</span> <span class="string">u&#x27;所在城市:&#x27;</span>,json_data[<span class="string">u&#x27;data&#x27;</span>][<span class="string">u&#x27;city&#x27;</span>]</span><br><span class="line">            <span class="built_in">print</span> <span class="string">u&#x27;所属运营商:&#x27;</span>,json_data[<span class="string">u&#x27;data&#x27;</span>][<span class="string">u&#x27;isp&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;查询失败,请稍后再试！&#x27;</span></span><br></pre></td></tr></table></figure>
<p>然后就可以将获取到的关于ip的信息存入数据库，同时存入更新时间，这样便在数据库中有了访问网站的记录，便于后续的可视化分析。</p>
<p>为了方便，还是利用了sae的cron服务每天定时将昨天的访问记录存入数据库。</p>
<p>参考： <a
href="http://bookshadow.com/weblog/2015/09/17/sae-log-api-ip-counter/">使用SAE实时日志API统计IP来访次数</a>
<a
href="http://bookshadow.com/weblog/2015/07/22/sae-log-api-python-note/">SAE实时日志API
Python使用小记</a> <a
href="http://www.cnblogs.com/xupeiyuan/p/4246854.html">Python判断内网IP</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>stacking 的基本思想及代码实现</title>
    <url>/2018/01/21/stacking%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>本文主要介绍机器学习中的一种集成学习的方法 stacking，本文首先介绍
stacking 这种方法的思想，然后提供一种实现 stacking
的思路，能够简单地拓展 stacking 中的基本模型。</p>
<span id="more"></span>
<h2 id="stacking-的基本思想">stacking 的基本思想</h2>
<p>stacking
就是将一系列模型（也称基模型）的输出结果作为新特征输入到其他模型，这种方法由于实现了模型的层叠，即第一层的模型输出作为第二层模型的输入，第二层模型的输出作为第三层模型的输入，依次类推，最后一层模型输出的结果作为最终结果。本文会以两层的
stacking 为例进行说明。</p>
<p>stacking
的思想也很好理解，这里以论文审稿为例，首先是三个审稿人分别对论文进行审稿，然后分别返回审稿意见给总编辑，总编辑会结合审稿人的意见给出最终的判断，即是否录用。对应于stacking，这里的三个审稿人就是第一层的模型，其输出（审稿人意见）会作为第二层模型（总编辑）的输入，然后第二层模型会给出最终的结果。</p>
<p>stacking
的思想很好理解，但是在实现时需要注意<strong>不能有泄漏（leak）的情况，也就是说对于训练样本中的每一条数据，基模型输出其结果时并不能用这条数据来训练</strong>。否则就是用这条数据来训练，同时用这条数据来测试，这样会造成最终预测时的过拟合现象，即经过stacking后在训练集上进行验证时效果很好，但是在测试集上效果很差。</p>
<p>为了解决这个泄漏的问题，需要通过 K-Fold
方法分别输出各部分样本的结果，这里以 5-Fold 为例，具体步骤如下</p>
<ol type="1">
<li>将数据划分为 5 部分，每次用其中 1 部分做验证集，其余 4
部分做训练集，则共可训练出 5 个模型</li>
<li>对于训练集，每次训练出一个模型时，通过该模型对没有用来训练的验证集进行预测，将预测结果作为验证集对应的样本的第二层输入，则依次遍历5次后，每个训练样本都可得到其输出结果作为第二层模型的输入</li>
<li>对于测试集，每次训练出一个模型时，都用这个模型对其进行预测，则最终测试集的每个样本都会有5个输出结果，对这些结果取平均作为该样本的第二层输入</li>
</ol>
<p>上述过程图示如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1c4c8nmgvru315ci15f8ia4f3m9.png"
alt="stacking" />
<figcaption aria-hidden="true">stacking</figcaption>
</figure>
<p>除此之外，用 stacking 或者说 ensemble
这一类方法时还需要注意以下两点：</p>
<ol type="1">
<li>Base Model 之间的相关性要尽可能的小，从而能够互补模型间的优势</li>
<li>Base Model 之间的性能表现不能差距太大，太差的模型会拖后腿</li>
</ol>
<h2 id="代码实现">代码实现</h2>
<p>由于需要 stacking
中每个基模型都需要对数据集进行划分后进行交叉训练，如果为每个模型都写这部分的代码会显得非常冗余，因此这里提供一种简便实现
stacking 的思路。</p>
<p><strong>具体做法就是先实现一个父类，父类中实现了交叉训练的方法，因为这个方法对所有模型都是一致的，然后声明两个方法：<code>train</code>
和
<code>predict</code>，由于采用的基模型不同，这两个方法的具体实现也不同，因此需要在子类中实现。</strong>下面以
python 为例进行讲解</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parent class of basic models&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, x_train, y_train, x_val, y_val</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;return a trained model and eval metric of validation data&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, model, x_test</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;return the predicted result of test data&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_oof</span>(<span class="params">self, x_train, y_train, x_test, n_folds = <span class="number">5</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;K-fold stacking&quot;&quot;&quot;</span></span><br><span class="line">        num_train, num_test = x_train.shape[<span class="number">0</span>], x_test.shape[<span class="number">0</span>]</span><br><span class="line">        oof_train = np.zeros((num_train,)) </span><br><span class="line">        oof_test = np.zeros((num_test,))</span><br><span class="line">        oof_test_all_fold = np.zeros((num_test, n_folds))</span><br><span class="line">        aucs = []</span><br><span class="line">        KF = KFold(n_splits = n_folds, random_state=<span class="number">2017</span>)</span><br><span class="line">        <span class="keyword">for</span> i, (train_index, val_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(KF.split(x_train)):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;0&#125; fold, train &#123;1&#125;, val &#123;2&#125;&#x27;</span>.<span class="built_in">format</span>(i, </span><br><span class="line">                                                        <span class="built_in">len</span>(train_index),</span><br><span class="line">                                                        <span class="built_in">len</span>(val_index)))</span><br><span class="line">            x_tra, y_tra = x_train[train_index], y_train[train_index]</span><br><span class="line">            x_val, y_val = x_train[val_index], y_train[val_index]</span><br><span class="line">            model, auc = self.train(x_tra, y_tra, x_val, y_val)</span><br><span class="line">            aucs.append(auc)</span><br><span class="line">            oof_train[val_index] = self.predict(model, x_val)</span><br><span class="line">            oof_test_all_fold[:, i] = self.predict(model, x_test)</span><br><span class="line">        oof_test = np.mean(oof_test_all_fold, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;all aucs &#123;0&#125;, average &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(aucs, np.mean(aucs)))</span><br><span class="line">        <span class="keyword">return</span> oof_train, oof_test</span><br></pre></td></tr></table></figure>
<p>上面最重要的就是进行 K-fold 训练的 <code>get_oof</code>
方法，<strong>该方法最终返回训练集和测试集在基模型上的预测结果，也就是两个一维向量，长度分别是训练集和测试集的样本数。</strong></p>
<p>下面以两个基模型为例进行 stacking，分别是 xgboost 和
lightgbm，这两个模型都只需要实现 <code>BasicModel</code> 中的
<code>train</code> 和 <code>predict</code> 方法</p>
<p>第一个基模型 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XGBClassifier</span>(<span class="title class_ inherited__">BasicModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;set parameters&quot;&quot;&quot;</span></span><br><span class="line">        self.num_rounds=<span class="number">1000</span></span><br><span class="line">        self.early_stopping_rounds = <span class="number">15</span></span><br><span class="line">        self.params = &#123;</span><br><span class="line">            <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;eta&#x27;</span>: <span class="number">0.1</span>,</span><br><span class="line">            <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">8</span>,</span><br><span class="line">            <span class="string">&#x27;eval_metric&#x27;</span>: <span class="string">&#x27;auc&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;seed&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="string">&#x27;silent&#x27;</span> : <span class="number">0</span></span><br><span class="line">         &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, x_train, y_train, x_val, y_val</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;train with xgb model&#x27;</span>)</span><br><span class="line">        xgbtrain = xgb.DMatrix(x_train, y_train)</span><br><span class="line">        xgbval = xgb.DMatrix(x_val, y_val)</span><br><span class="line">        watchlist = [(xgbtrain,<span class="string">&#x27;train&#x27;</span>), (xgbval, <span class="string">&#x27;val&#x27;</span>)]</span><br><span class="line">        model = xgb.train(self.params, </span><br><span class="line">                          xgbtrain, </span><br><span class="line">                          self.num_rounds)</span><br><span class="line">                          watchlist,</span><br><span class="line">                          early_stopping_rounds = self.early_stopping_rounds)</span><br><span class="line">        <span class="keyword">return</span> model, <span class="built_in">float</span>(model.<span class="built_in">eval</span>(xgbval).split()[<span class="number">1</span>].split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, model, x_test</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;test with xgb model&#x27;</span>)</span><br><span class="line">        xgbtest = xgb.DMatrix(x_test)</span><br><span class="line">        <span class="keyword">return</span> model.predict(xgbtest)</span><br></pre></td></tr></table></figure></p>
<p>第二个基模型</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LGBClassifier</span>(<span class="title class_ inherited__">BasicModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.num_boost_round = <span class="number">2000</span></span><br><span class="line">        self.early_stopping_rounds = <span class="number">15</span></span><br><span class="line">        self.params = &#123;</span><br><span class="line">            <span class="string">&#x27;task&#x27;</span>: <span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;dart&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;metric&#x27;</span>: &#123;<span class="string">&#x27;auc&#x27;</span>, <span class="string">&#x27;binary_logloss&#x27;</span>&#125;,</span><br><span class="line">            <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">80</span>,</span><br><span class="line">            <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.05</span>,</span><br><span class="line">            <span class="comment"># &#x27;scale_pos_weight&#x27;: 1.5,</span></span><br><span class="line">            <span class="string">&#x27;feature_fraction&#x27;</span>: <span class="number">0.5</span>,</span><br><span class="line">            <span class="string">&#x27;bagging_fraction&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">&#x27;bagging_freq&#x27;</span>: <span class="number">5</span>,</span><br><span class="line">            <span class="string">&#x27;max_bin&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">            <span class="string">&#x27;is_unbalance&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">            <span class="string">&#x27;lambda_l2&#x27;</span>: <span class="number">5.0</span>,</span><br><span class="line">            <span class="string">&#x27;verbose&#x27;</span> : -<span class="number">1</span></span><br><span class="line">            &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, x_train, y_train, x_val, y_val</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;train with lgb model&#x27;</span>)</span><br><span class="line">        lgbtrain = lgb.Dataset(x_train, y_train)</span><br><span class="line">        lgbval = lgb.Dataset(x_val, y_val)</span><br><span class="line">        model = lgb.train(self.params, </span><br><span class="line">                          lgbtrain,</span><br><span class="line">                          valid_sets = lgbval,</span><br><span class="line">                          verbose_eval = self.num_boost_round,</span><br><span class="line">                          num_boost_round = self.num_boost_round)</span><br><span class="line">                          early_stopping_rounds = self.early_stopping_rounds)</span><br><span class="line">        <span class="keyword">return</span> model, model.best_score[<span class="string">&#x27;valid_0&#x27;</span>][<span class="string">&#x27;auc&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, model, x_test</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;test with lgb model&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> model.predict(x_test, num_iteration=model.best_iteration)</span><br></pre></td></tr></table></figure>
<p>下一个步骤就是将这两个基模型的输出作为第二层模型的输入，这里选用的第二层模型是
<code>LogisticsRegression</code>，</p>
<p>首先需要将各个基模型的输出 <code>reshape</code> 和
<code>concatenate</code> 成合适的大小</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">lgb_classifier = LGBClassifier()</span><br><span class="line">lgb_oof_train, lgb_oof_test = lgb_classifier.get_oof(x_train, y_train, x_test)</span><br><span class="line">   </span><br><span class="line">xgb_classifier = XGBClassifier()</span><br><span class="line">xgb_oof_train, xgb_oof_test = xgb_classifier.get_oof(x_train, y_train, x_test)</span><br><span class="line"></span><br><span class="line">input_train = [xgb_oof_train, lgb_oof_train] </span><br><span class="line">input_test = [xgb_oof_test, lgb_oof_test]</span><br><span class="line"></span><br><span class="line">stacked_train = np.concatenate([f.reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> f <span class="keyword">in</span> input_train], axis=<span class="number">1</span>)</span><br><span class="line">stacked_test = np.concatenate([f.reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="keyword">for</span> f <span class="keyword">in</span> input_test], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>然后用第二层模型进行训练和预测 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">final_model = LinearRegression()</span><br><span class="line">final_model.fit(stacked_train, y_train)</span><br><span class="line">test_prediction = final_model.predict(stacked_test)</span><br></pre></td></tr></table></figure></p>
<p>上述实现的完整代码见下面的链接</p>
<p>https://github.com/WuLC/MachineLearningAlgorithm/blob/master/python/Stacking.py</p>
<p>如有错漏，欢迎交流指正</p>
<hr />
<p>参考</p>
<p><a
href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python">Introduction
to Ensembling/Stacking in Python</a> <a
href="https://dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/">如何在
Kaggle 首战中进入前 10%</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>vim中SuperTab的安装与使用</title>
    <url>/2015/12/01/vim%E4%B8%ADSuperTab%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>vim是Linux下常用的编辑器，但是默认是没有补全功能的，所以插件SuperTab就是实现这个功能的。</p>
<p>下载链接：http://www.vim.org/scripts/script.php?script_id=1643</p>
<p>下载<code>.vmb</code>文件即可,下载后可通过<code>rz</code>命令上传（需要安装<code>lrzsz</code>）</p>
<p>安装步骤也非常简单 1.
先用vim打开下载的文件，<code>vim supertab.vmb</code> 2.
在命令模式下输入<code>:source %</code></p>
<p>至此就可以使用SuperTab的功能了，在vim编辑模式时，输入文件中已经有的字符串的前几个字母，再按<code>Tab</code>键即可补全这个字符串，只能补全文件中已经出现的字符串。</p>
<p>SuperTab的github地址：https://github.com/ervandew/supertab</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>《Advanced Web Metrics with Google Analytics》读书笔记(1)</title>
    <url>/2016/01/20/%E3%80%8AAdvanced%20Web%20Metrics%20with%20Google%20Analytics%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/</url>
    <content><![CDATA[<p>《Advanced Web Metrics with Google Analytics》是 Google
一位数据分析专家 Brian Clifton
出版的书，主要介绍了涉及网站分析的一些概念和方法以及如何利用 Google
Analytics 进行网站分析。Google Analytics 是 Google
免费提供的一个用于网站分析的工具。 <span id="more"></span>
本系列文章是笔者在阅读本书过程中总结整理的一些笔记。</p>
<p><strong>本文是本书中 Chapter
1的阅读笔记，主要介绍了网站分析的一些概念以及为什么要进行网站分析。</strong></p>
<h2 id="为什么要进行网站分析">为什么要进行网站分析</h2>
<p>在进行网站分析前需要考虑的一个问题是<strong>通过网站分析能够给你带来的价值</strong>，这种价值可以表现在商业上，如某家公司的网站是否能够给实际销量带来提升，也可以表现在个人上，如个人网站的访问量、影响力如何。</p>
<h2 id="网站分析能够获取的信息">网站分析能够获取的信息</h2>
<p>一般的网站分析均能够获取下面的信息：</p>
<ul>
<li>每天的访客人数</li>
<li>平均转化率（conversion rate），就是销量、注册量和下载量等</li>
<li>网站上访问最多的页面</li>
<li>访客的每次平均访问时间和访问的频率</li>
<li>访客的地理分布</li>
</ul>
<p>假如你的网站是商业网站，还能够获取以下信息：</p>
<ul>
<li>网站产生的盈利</li>
<li>网站的顾客来自哪里</li>
<li>网站最畅销的商品是那些</li>
</ul>
<p>随着挖掘的深入还可以获取到以下的信息：</p>
<ul>
<li>一个顾客对于网站的价值</li>
<li>如何量化一个网页的价值</li>
<li>老顾客和新顾客在使用网站的方式上是否有区别</li>
<li>访问量以及转化率如何被将顾客引导到本站的外站的影响</li>
<li>页面跳出率受何影响</li>
<li>站内搜索是否对转化率有利</li>
<li>平均需要多长时间才能让一位访客成为一位顾客</li>
</ul>
<h2 id="如何利用网站分析得到的结果">如何利用网站分析得到的结果</h2>
<p>　　从前面的分析可知，网站的分析能够提供很多信息，这些繁杂的信息会让许多初学者感到无从下手。因此，在<strong>进行网站分析前一定要确定希望通过网站分析达到的目标</strong>。
　　目标根据网站具体类型有所区别，总的来说，<strong>目标就是希望访客在离开网页之前要完成的内容</strong>。如对于购物网站，目标可能是希望顾客购买了产品，对于个人网站而言，可能希望顾客能够对网站留言给出建议等。更进一步说，目标就是在访客好你的网站之间建立起的任何一种关系，而不是仅仅一个PV量，如留言，订阅网站RSS，下载了一个PDF文件等。
　　有了目标，便可以从复杂繁多的数据中找到所需要的数据。进而分析这些数据，并采取相应的措施。如最简单的购物网站需要判断那种物品销量较好，哪种较差，进而修改相应的进货量；便可商品的购买量、PV量等进行分析。</p>
<p>上面只是对本书的内容做了一个很笼统的总结，具体的实现方法、原理及注意事项会在后续文章介绍。</p>
<p>因为这本书主要就是讲述通过Google Analytics
进行网站分析，所以有必要了解一下Google Analytics
中的一些专用术语。下面是 Google Analytics 中一些常用的术语，更详细的可见
<code>http:// www.google.com/support/googleanalytics/bin/topic.py?topic=11285</code></p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">术语</th>
<th style="text-align: center;">含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Bounced Visitor</td>
<td
style="text-align: center;">只在你的网页上浏览过一次的访客，这个数值当然越小越好</td>
</tr>
<tr class="even">
<td style="text-align: center;">Google Analytics Tracking
Code（GATC）</td>
<td style="text-align: center;">Google Analytics
工具提供的一段js代码，用来追踪网站的访问情况</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Goal Conversion</td>
<td style="text-align: center;">也可简称为 goal 或
conversion，表示希望网站达到的一个目标，如购买页面的一次访问量或一次下载</td>
</tr>
<tr class="even">
<td style="text-align: center;">Funnel</td>
<td style="text-align: center;">表示达到Goal
Conversion所需要经过的一个流程</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Landing Page</td>
<td style="text-align: center;">网站的首页</td>
</tr>
<tr class="even">
<td style="text-align: center;">Referrer</td>
<td style="text-align: center;">含有你的网站超链接的页面</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Return On Investment(ROI)</td>
<td
style="text-align: center;">检验网站分析效果的一种指标，计算公式：纯利润/支出</td>
</tr>
<tr class="even">
<td style="text-align: center;">Session</td>
<td
style="text-align: center;">也叫会话，指一个访客在网站停留的时间，一个会话在访客关闭页面后结束，也会在访客在一段时间内对网站无任何操作情况下结束</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Site Search</td>
<td style="text-align: center;">网站的内部搜索功能</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Google Analytics</category>
      </categories>
      <tags>
        <tag>Google Analytics</tag>
      </tags>
  </entry>
  <entry>
    <title>《Advanced Web Metrics with Google Analytics》读书笔记(2)</title>
    <url>/2016/01/22/%E3%80%8AAdvanced%20Web%20Metrics%20with%20Google%20Analytics%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89/</url>
    <content><![CDATA[<p>《 Advanced Web Metrics with Google Analytics 》是 Google
一位数据分析专家 Brian Clifton
出版的书，主要介绍了涉及网站分析的一些概念和方法以及如何利用 Google
Analytics 进行网站分析。Google Analytics 是 Google
免费提供的一个用于网站分析的工具。</p>
<span id="more"></span>
<p>本系列文章是笔者在阅读本书过程中总结整理的一些笔记。</p>
<p><strong>本文是本书中 Chapter 2
的阅读笔记，主要介绍了网站分析常用的两种途径以及网站分析的数据的准确性。</strong></p>
<h2 id="网站分析的两种手段">网站分析的两种手段</h2>
<p><strong>页面标签（page
tags）和日志文件（logfiles）是网站分析的两种常用手段</strong>。</p>
<p>页面标签一般是在html页面中嵌入js代码段，浏览页面时js代码会将浏览记录发送到远端服务器，远端服务器将对浏览页面进行统计，并提供可视
web 界面，GoogleAnalytics 就是属于这种手段。</p>
<p>日志文件则是利用 web
服务器软件（如Apache、Tomcat等）产生的日志文件进行统计，日志文件能够记录访问的ip和页面等信息；然后在本地服务器上统计并生成所需结果。</p>
<p>除了上面两种途径，还可通过网络流量情况、web服务器软件提供的api等方式进行数据的采集和统计。但是最常用的手段就是上面提到的两种。所以下面详细列出这两种方法的优点点和不足。</p>
<table>
<colgroup>
<col style="width: 38%" />
<col style="width: 30%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">方法</th>
<th style="text-align: left;">Page Tags</th>
<th style="text-align: left;">Logfiles</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Advantages</td>
<td style="text-align: left;">(1)不受代理服务器和缓存服务器的影响
<br>(2)能够实时处理客户端产生的数据<br>(3)数据采集程序的升级以及数据的存储仅需服务商提供<br></td>
<td
style="text-align: left;">(1)能够保留历史数据<br>(2)不会受到防火墙影响<br>(3)跟踪带宽及下载情况，区分完全下载和部分下载<br>(4)能够跟踪网络爬虫的来源<br></td>
</tr>
<tr class="even">
<td style="text-align: center;">Disadvantage</td>
<td
style="text-align: left;">(1)部署的不恰当或导致数据的丢失且无法重新找到<br>(2)防火墙可能会拦截这种方法的流量<br>(3)不能够获取带宽或者下载具体情况，即不能确定是否下载成功<br>(4)不能跟踪网络爬虫的来源</td>
<td
style="text-align: left;">(1)代理服务器和缓存服务器会影响数据准确性<br>(2)需要维护服务器的程序正确性以及数据的存储等<br>(3)网络爬虫会使得访问者的数量比实际的大</td>
</tr>
</tbody>
</table>
<p>从上面的比较分析可以看到，两种方法的优点和缺点几乎是互补的，所以<strong>在实际中不需要局限于一种方法，而可以混合多种方法进行分析。</strong></p>
<h2 id="cookies-在网站分析中的作用">Cookies 在网站分析中的作用</h2>
<p>页面标签（page tags）是通过 cookies 来追踪访客的。cookies
是以文本方式存储在客户端本地的一系列 key-value
对，用来存储客户端的一些信息，每次客户端请求服务器端的资源时，服务器端都可以获取客户端对应的cookie，不同的
cookie 根据不同的域名来区分。</p>
<p>cookies 有几种分类：</p>
<p>如<strong>根据生存时间</strong>可以分为永久 cookies （persistent
cookies）和 会话 cookies （session cookies），永久 cookies
指那些关闭浏览器后再重新打开时依然有效的cookies（前提是客户端不会清理cookies），而
会话 cookies 则指那些只在浏览网站期间有效的cookies，关闭浏览器后 cookies
会自动失效。</p>
<p><strong>根据来源</strong>可以分为第一方 cookie （first-party
cookie）和第三方 cookie （third-party
cookie），第一方cookie指你<strong>访问的url
所属的域名在你的电脑上留下的cookie</strong>，我们之前已经提到过：不同的cookie通过不同的域名进行识别。第三方
cookie
则刚好相反，是你<strong>访问一个url后所获得的cookies中，那些不属于这个url所属域名的cookie</strong>，如一些网页中嵌入的一些广告可能会留下cookies，这些cookies不属于所访问的页面所属的域名，这个就可以算为第三方
cookie。两者的区别在于<strong>第一方 cookie
只能由设定这个cookie的域名所获取；而第三方 cookie
则允许列出可以获取这个cookie的所有域名。</strong></p>
<p>cookies
在网站分析中的一些常见作用包括：<strong>能够判断访客是否第一次访问这个网站，每隔一定时间会有多少访客再次访问，每位访客具体的访问间隔时间等</strong>。</p>
<h2 id="数据准确性">数据准确性</h2>
<p>无论是网页标签（page
tags），还是日志文件（logfiles），任何一种手段均存在采集数据的不准确性问题。下面分别讲述这两种方法存在一些问题以及解决方法</p>
<h3 id="日志文件中的数据不准确性">日志文件中的数据不准确性</h3>
<h4 id="动态分配ip"><strong>动态分配IP</strong></h4>
<p><strong>动态分配IP会使得统计出来的访客人数比实际要大。</strong>
现今为家庭提供网络服务的 ISP
一般都是分配动态IP,美国曾统计过（http://www.comscore.com/Press_Events/Presentations_Whitepapers/2007/Cookie_Deletion_Whitepape）一个家庭平均每个月会使用10.5个IP地址，这会导致通过日志文件统计出来的访客数量要大于实际的。因为日志文件是通过不同IP来区分不同的访客的，按照上面的情况，会将一个访客统计为10个访客，因为这个人在访问网站时IP会变化。
这类问题可通过cookie 来解决。</p>
<h4 id="缓存"><strong>缓存</strong></h4>
<p><strong>缓存会使得统计出来的访客人数比实际要小。</strong>
缓存又可以分为客户端的缓存和服务器端的缓存。
客户端的缓存指的是用户在访问网站后，用户使用的浏览器会缓存其访问过的某些页面，使得用户再次访问这个页面时浏览器可以从本地获取，从而加快其访问速度。但是这样服务器的日志文件就无法记录这次的访问信息了。
服务器端的缓存的作用与客户算的类似，也是将一些常被访问的页面缓存起来，加快客户端的访问速度，我们常听到的CDN就是其中的一种。
对于这种问题，貌似目前还没有比较好的解决方法。</p>
<h4 id="网络爬虫"><strong>网络爬虫</strong></h4>
<p><strong>网络爬虫会使得统计出来的访客人数比实际要大。</strong>
网络爬虫在搜索引擎等领域使用得非常广泛，可以理解为通过程序获取页面信息。这会产生大量非实际访客访问的PV量，这就导致了统计出来的PV量比实际的要大。
可以通过追踪爬虫的来源从而在日志中过滤掉这个爬虫的访问记录。但是因为爬虫的数量很多，往往难以完全过滤掉所有爬虫的访问记录。</p>
<h3 id="网页标签中的数据不准确性">网页标签中的数据不准确性</h3>
<h4 id="代码部署不全"><strong>代码部署不全</strong></h4>
<p>因为网页标签（page tags）的方法是通过在网站的每个网页上嵌入一段 JS
代码实现，所以在一开始部署这段代码的时候有可能会存在部署不全的情况，就是没有在每个网页上部署这段代码。这种情况在一些较大的网站上普遍存在。</p>
<h4 id="js代码发生错误"><strong>JS代码发生错误</strong></h4>
<p>除了采集访问信息的js代码外，网页中不可避免会有完成其他功能的js代码，这些js代码假如发生了错误并且在网页源码中的位置处于采集访问信息的js代码前，会导致<strong>浏览器解析脚本引擎停滞工作</strong>，从而在下面的采集访问信息的js代码段将没有执行。</p>
<h4 id="防火墙的阻挡"><strong>防火墙的阻挡</strong></h4>
<p>因为网页标签（page
tags）方法会将数据发送给指定的数据采集服务器，所以防火墙能够阻挡这一动作。除此之外，防火墙还能够阻挡或者自动删除cookies。</p>
<h3 id="cookies中的数据不准确性">Cookies中的数据不准确性</h3>
<h4
id="访客拒绝或删除cookies"><strong>访客拒绝或删除cookies</strong></h4>
<p>因为cookies是存储在访客本地的电脑的，故可以将已有的cookies删除掉，也可以在浏览器设置中距拒绝cookies。据调查显示，第一方cookies的接受率可达95%，而第三方cookies则常被防火墙或反病毒软件拦截。</p>
<h4
id="访客有多台设备或共享一台设备"><strong>访客有多台设备或共享一台设备</strong></h4>
<p>这里的设备可以指电脑、平板、手机等，现今同一个人同时拥有这几种设备是很常见的事情，同时有些家庭也共用一台电脑，这就导致了下面可能存在的问题。</p>
<p><strong>同一个访客有多台设备</strong>：用这些设备访问统一网页时均会生成cookies，这样统计时会将同一用户产生的三个cookies当做是不同用户产生的。
<strong>多个访客共享同一台设备</strong>：这样访问一个同一个网站只会产生一个cookies，但是分析cookies时只会将这个当做一个用户，显然分析结果不合理。</p>
<p>解决这类问题可以设置用户登录这一步骤，从而在cookies中标记不同的用户区分cookies的来源。</p>
]]></content>
      <categories>
        <category>Google Analytics</category>
      </categories>
      <tags>
        <tag>Google Analytics</tag>
      </tags>
  </entry>
  <entry>
    <title>vim编辑器使用</title>
    <url>/2015/11/30/vim%E7%BC%96%E8%BE%91%E5%99%A8/</url>
    <content><![CDATA[<p>vim是Linux下非常常用的一个编辑工具，所以有必要了解一下vim的一下使用
技巧。</p>
<span id="more"></span>
<p>这里将vim的状态分成两大类：命令模式和编辑模式。当你输入命令<code>vim filename</code>时就进入了命令模式，而此时按下<code>i</code>即可进入编辑模式,进入编辑模式后可同过按<code>ESC</code>退回命令模式</p>
<h2 id="跳到某一行">跳到某一行</h2>
<ul>
<li>跳到第一行：在命令模式下，连续两次按下g</li>
<li>跳到最后一行：在命令模式下，<code>shift+g</code>即可</li>
<li>跳到某一行：命令行模式下，通过冒号加行号即可实现，如<code>:15</code>即可跳到第15行。</li>
<li>跳到当前行往上或往下的n行：命令模式下，先按数字n，然后按往上或往下的按钮（就是键盘上的上下左右的按钮）</li>
<li>跳到一行的开头：可以使用键盘上的编辑键<code>Home</code>,也可以在命令模式中使用快捷键<code>"^"（即Shift+6）</code>或0（数字0)</li>
<li>跳到一行的末尾：以使用编辑键<code>End</code>，也可以在命令模式中使用快捷键<code>"$"（Shift+4）</code>。快捷键"$"前可以加上数字表示移动的行数。例如使用"1$"表示当前行的行尾，"2$"表示当前行的下一行的行尾。</li>
</ul>
<h2 id="查找字符串">查找字符串</h2>
<ul>
<li>往前查找：命令模式下输入<code>?word</code>,按<code>n</code>往前查找下一个，<code>shift+n</code>往后查找下一个</li>
<li>往后查找：命令模式下输入<code>/word</code>,按<code>n</code>往后查找下一个，<code>shift+n</code>往前查找下一个
注：这里的往前和往后指的是文本的顺序，其实只需要记住按n是顺序查找，shift+n是逆序查找即可</li>
</ul>
<h2 id="删除">删除</h2>
<ul>
<li>删除一行：命令模式下，光标定位到要删除的那一行，连续按下两次<code>d</code>即可</li>
<li>删除多行：命令模式下，光标定位到要删除的那一行，先按下数字n，然后连续按下两次<code>d</code>，表示删除n行（包括当前行）</li>
</ul>
<h2 id="修改">修改</h2>
<ul>
<li>替换字符串：命令模式下输入<code>:n1,n2s/w1/w2/g</code>,表示将n1到n2行的w1转为w2（1代表第一行，$代表最后一行，没数字为整个文本），注意前面有冒号</li>
<li>复制：命令模式下，将光标移到需要复制的那行，然后连续两次按下y，即可复制当前行，如果要复制多行，在按下<code>yy</code>前需要按下数字n，表示复制包括当前光标一下的n行，原理同删除操作</li>
<li>块复制：命令模式下，通过<code>ctrl+v</code>进入块复制模式，选择高亮后按y复制</li>
<li>剪切：实际上上面提到的删除命令除了将所选的内容删除掉，还将其复制到了剪切板上，按下p即可粘贴；所以剪切实际上就是<code>dd+p</code>。</li>
<li>粘贴：命令模式下，按下p即可将已经复制或剪切的内容复制到光标所在行下面的的一行或多行</li>
</ul>
<h2 id="撤销与恢复前一步的操作">撤销与恢复前一步的操作</h2>
<ul>
<li>撤销前一步的工作:命令模式下按<code>u</code></li>
<li>撤消后恢复前一步的工作：命令模式下按<code>Ctrl+u</code></li>
</ul>
<h2 id="另存为">另存为</h2>
<ul>
<li>命令模式下输入<code>:n1,n2 w new_file_name</code>可将修改文本n1到n2行（不加数字为整个文本）另存为其他文件</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>《Budget Pacing for Targeted Online Advertisements at LinkedIn》 阅读笔记</title>
    <url>/2018/10/25/%E3%80%8ABudget%20Pacing%20for%20Targeted%20Online%20Advertisements%20at%20LinkedIn%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>《<a
href="https://github.com/wzhe06/Ad-papers/blob/master/Budget%20Control/Budget%20Pacing%20for%20Targeted%20Online%20Advertisements%20at%20LinkedIn.pdf">Budget
Pacing for Targeted Online Advertisements at LinkedIn</a>》 是 LinkedIn
在 2014
年发表的一篇关于预算控制的论文，里面的预算控制的策略并不复杂，并且具有很强的实践性和工程性。本文主要是根据论文总结了这个方法的基本原理、工程实现以及实验效果。</p>
<span id="more"></span>
<p>顾名思义，预算控制（budget
control）在广告系统中的作用就是该<strong>如何合理花掉广告主的预算</strong>。在实际中经常会出现广告主预算消耗过快的问题，这会导致广告主早早退出竞价，不仅会影响广告主体验，也会导致整个广告生态的竞争力下降（因为那些有竞争力的广告主消耗早早就花光了），在二价的机制下，直接影响了平台的收入。论文为了解决这个问题，提出了一个
budget pacing 的算法。</p>
<h2 id="原理">原理</h2>
<p>算法的主要思想就是<strong>令每个
campaign（推广计划）的消耗趋势与其曝光变化趋势基本保持一致，以天为时间单位，campaign
为预算控制单位</strong>，首先为每个 campaign
预测出其在当天的曝光情况；然后基于其曝光情况，在当前时间片，假如
<code>已消耗/当天预算</code> 的比例大于 <code>已曝光/预测的总曝光</code>
的比例，则说明预算已经消耗过快，需要减小消耗的速度，反之则要加快消耗的速度。</p>
<p>下面详细讲述这个算法的原理</p>
<p>对于某个 campaign <span class="math inline">\(i\)</span>，记其出价为
<span class="math inline">\(b\_i\)</span>，当天预算为 <span
class="math inline">\(d\_i\)</span>。一天的时间被划分为 <span
class="math inline">\(T\)</span> 个时间窗口， <span
class="math inline">\(s\_{i,t}(0 \le t \lt T)\)</span> 表示截止到第
<span class="math inline">\(t\)</span> 个时间窗口开始时的累积预算，<span
class="math inline">\(f\_{i,t}\)</span> 与 <span
class="math inline">\(s\_{i,t}\)</span> 对应，表示截止到第 <span
class="math inline">\(t\)</span> 个时间窗口开始时的累积曝光(<span
class="math inline">\(f\_{i,t}\)</span> 是预测出来的，下式的 <span
class="math inline">\(f\_{i,T}\)</span> 表示预测出来 campaign <span
class="math inline">\(i\)</span> 在当天的总曝光)。则在时间窗口 <span
class="math inline">\(t\)</span> 开始时，有</p>
<p><span class="math display">\[a\_{it} := \frac{f\_{i, t}}{f\_{i,
T}}d\_i\]</span></p>
<p>根据上面的比例，<strong>在每次竞价开始时，为 campaign <span
class="math inline">\(i\)</span> 算出其参与这次竞价的概率 <span
class="math inline">\(p\_{i,t}\)</span></strong>，论文称这个概率为
PTR（pass through rate）, 计算方式如下</p>
<p><span class="math display">\[p\_{i,t} =
\begin{cases} p\_{i, t-1}\*(1 + r\_t)&amp; s\_{i, t} \le a\_{i, t}\\\
p\_{i, t-1}\*(1 - r\_t)&amp; s\_{i, t} \gt a\_{i, t}
\end{cases}\]</span></p>
<p>上式中的 <span class="math inline">\(r\_t(0 &lt; r\_t &lt;
1)\)</span> 称作调整速率（adjustment rate）。</p>
<p>对于 campaign <span class="math inline">\(i\)</span> , <span
class="math inline">\(a\_{it}\)</span> 在当天开始已经确定，因为 <span
class="math inline">\(f\_{i,t}\)</span> 是预测出来的,
因此控制预算就完全是针对 <span class="math inline">\(s\_{i,t}\)</span>
的变化进行。</p>
<p>除了这种调整 campaign
参与竞价概率的控制方式，某些文献也建议通过调整出价的方式进行干预，如下所示是论文
[1] 提出的调价方式</p>
<p><span class="math display">\[b\_i^* = b\_i \psi(s\_{i,
t}/d\_i)\]</span></p>
<p>其中 <span class="math inline">\(\psi(x) = 1 - e^{x-1}\)</span>，但是
LinkedIn
这篇论文的作者不建议采用这种方式，原因是对于那些快耗尽预算的campaign，bid
修改的幅度很小，且出价一般存在着保留价（reserve
price），因此可调整的幅度很小。论文也对这种方式做了实验，结果显示该方式对提升
campaign 的预算消耗时长无帮助。</p>
<p>整个算法就是这么简单，下面主要说一下具体的实现细节。</p>
<h2 id="实现细节">实现细节</h2>
<h3 id="更新-ptr-频率">更新 PTR 频率</h3>
<p>更新 PTR 频率设置成每分钟一次，也就是说<strong>时间窗口的大小为 1
min</strong>，实验证明这个更新频率使得整个系统更快达到一个稳定状态。</p>
<h3 id="预估曝光量">预估曝光量</h3>
<p>上面预估某个 campaign
的曝光量可以说是整个算法至为关键的地方，论文并没有针对这一点提出自己的方法，而是采用了论文
[2] 里面的方法，这篇论文是 Yahoo
在做保量的合约广告时提出的预估流量的方法。这里不详细展开了，会另外写一篇博客加以阐释。</p>
<h3 id="调整速率的设置">调整速率的设置</h3>
<p>调整速率也就是上面的 <span
class="math inline">\(r\_t\)</span>，目的是控制 PTR
变化的快慢，论文将这个值设置为固定的
10%，这不仅实现简单，鲁棒性也很强。另外一种更复杂的设置方法就是将这个值设置成
<span class="math inline">\(s\_{i,t}\)</span> 的变化率，也就是 <span
class="math inline">\(\partial s\_{i,t}/\partial t\)</span>,
表示消耗过快的 campaign
其对应的调整速率也应该较大。然后论文还是选择了固定的 10%
的值，原因有两个</p>
<p>1）<span class="math inline">\(s\_{i,t}\)</span>
表示的曲线并不光滑（一系列离散的点），尤其是对于 CPC
这种有了点击才会扣费的广告，这时候的 <span
class="math inline">\(s\_{i,t}\)</span> 波动会比较大，从而使得计算出来的
<span class="math inline">\(\partial s\_{i,t}/\partial t\)</span> 会比较
noisy 2）PTR 的更新频率比较频繁，因此即使当前 PTR
不在最合适的位置（<span class="math inline">\(\partial s\_{i,t}/\partial
t\)</span>），也能够很快更新到理想位置</p>
<h3 id="设置-ptr-初始值slow-start">设置 PTR 初始值（Slow Start）</h3>
<p>论文将每个 campaign 的 PTR 初始值设置为 10%，并将这种方式称为 slow
start，因为这个初始值较小。设置较小的初始值给予系统以时间来调整每个
campaign 的 PTR，反之若 PTR
一开始就设置得很高，会导致预算很快被花光。</p>
<p>同样，更合理的方式是为每个 campaign 设置一个
PTR，但是论文并没有针对这一点进行深度的探讨。</p>
<h3 id="fast-finish">Fast Finish</h3>
<p>由于系统存在统计偏差，使得 PTR
的值偏低，这会导致当天预算没法完全花出去，而 fast finish
就是针对这个问题的一种解决方法。具体的做法就是修改上面预测的 <span
class="math inline">\(f\_{i,t}\)</span> (allocation
curve)，令最后两个小时的曝光量为 0，这样会导致 budget pacing
这个算法每天会尝试在 22 小时内花光预算。</p>
<h3 id="工程上的设计">工程上的设计</h3>
<p>下图是 LinkedIn 的广告系统概览图，advertiser action
是指广告主的行为，包括创建 campaign、修改 bid 或 budget 等；ad requests
则是指用户浏览而触发的广告请求。在 ad sever 中的 campaign index
记录着每个 campaign 当前的状态（曝光，消耗等情况），pacing module
会根据预设的更新频率从 database 中获取最新的数据来更新 campaign
index。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cquneeh317desbn1f7gd651fl09.png"
alt="engineering design" />
<figcaption aria-hidden="true">engineering design</figcaption>
</figure>
<p>需要注意的是，pacing module
的更新并不是一次立刻完成，而是采用了较为平缓的方式，上文提到了 pacing
的更新频率为每分钟一次，因此在实际更新是大概<strong>每 7s 更新 12%
的campaign</strong>；这种更新频率能够让系统的负载较为均匀，也能够较快达到一个稳定状态。</p>
<h2 id="实验的设计与效果">实验的设计与效果</h2>
<p>由于以上的 pacing 方式是以 campaign 为单位的，因此实验会将所有的
campaign
等分为两部分，分别作为实验组和对照组（当然，也可以采用灰度而不是全量的方式）。</p>
<p>为了避免时间因素（weekly，seasonality）的影响，论文认为设计的实验至少要持续两周，如下图所示是一个
campaign 的实验设置情况，其中 On 表示采用上述的 pacing 算法，Off
表示不采用。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cqus9euh1e21bdslma1v85t3jm.png"
alt="design of experiment" />
<figcaption aria-hidden="true">design of experiment</figcaption>
</figure>
<p>则采用 pacing 的效果是标为 On
的那些天的效果的均值，那么该<strong>采用哪些指标来评估效果</strong>？</p>
<p>首先我们要认识到，<strong>在线广告是一个广告主、平台和用户的三方博弈过程</strong>，因此在考虑任意机制带来的收益或损失时都要同时考虑到这三方的利益；论文也是同时考虑了这三方的利益，设置了以下指标</p>
<ol type="1">
<li><strong>广告主的利益</strong>
<ul>
<li>Campain life time：预算消耗 95% 所消耗的时间</li>
<li>Unique impressions per spend：单位消耗给广告主带来的unique
user数量，计算方式 <code>number of unique user/total spend</code></li>
<li>Number of campaigns：表示当天平台服务的 campaign 的数量</li>
</ul></li>
<li><strong>平台的收益</strong>
<ul>
<li>Cost per request：每次请求的平均收益，计算方式
<code>total revenue/number of requests</code></li>
<li>Over delivery: 超扣的金额占预算的比例</li>
</ul></li>
<li><strong>用户体验</strong>
<ul>
<li>Unique campaings served: 用户看到的所有广告中有几个 unique
campaign，表示用户看到的广告的多样性，论文认为这个值越大越好</li>
</ul></li>
</ol>
<p>论文在 LinkedIn 的两种广告（Direct Ads 和 Sponsored Status
Updates）上分别做了这个实验，结果如下，带加号 <code>+</code> 的指标表示
On 在 oFF 的基础上的变化比例；根据下表，在各个指标上均有较高提升</p>
<figure>
<img src="https://wulc.me/imgs/image_1cqutctu84f72db1rj6177a1ah133.png"
alt="effect 1" />
<figcaption aria-hidden="true">effect 1</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1cquteetoe1r441vp86lf15r450.png"
alt="effect 2" />
<figcaption aria-hidden="true">effect 2</figcaption>
</figure>
<p>且根据 cost per click
指标，可在一定程度上了解目前系统的竞争力情况，该值越大，表示系统竞争越激烈，论文也根据这个指标对比了采用这个策略前后系统的竞争力，如下图所示，可以看到，采用
pacing 后前期的竞争有所缓和（slow
start导致的），而后期的竞争力比原来有所提升，原因是 campaign life time
变长了，因此有竞争力的 campaign 不会早早就退出了竞价环境。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cqutoq7r1bd31bbkrst4pe1s3o5d.png"
alt="competition" />
<figcaption aria-hidden="true">competition</figcaption>
</figure>
<hr />
<p>论文参考文献</p>
<p>[1] A. Mehta, A. Saberi, U. Vazirani, and V. Vazirani.Adwords and
generalized on-line matching. Journal of the ACM, 54(5):Article no. 22,
October 2007 [2] D. Agarwal, D. Chen, L.-j. Lin, J. Shanmugasundaram,
and E. Vee. Forecasting high-dimensional data. In Proceedings of the
2010 ACM SIGMOD International Conference on Management of Data, SIGMOD
’10, pages 1003–1012, New York, NY, USA, 2010. ACM.</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>《Bid Optimization by Multivariable Control in Display Advertising》阅读笔记</title>
    <url>/2020/07/19/%E3%80%8ABid%20Optimization%20by%20Multivariable%20Control%20in%20Display%20Advertising%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>推荐与广告可以说是很多互联网公司的两个重要业务，其中推荐是为了 DAU
的增长，或者说流量的增长，而广告则是利用这些流量进行变现。两者的要解决的问题也很相似，都是在每条流量到来的时候，要从一个庞大的候选集中选出
topk 个候选返回，基本都采用 召回+精排
的架构，中间还可能插入粗排，本质上都是在效果与工程之间做 trade-off。</p>
<p>如果说两者技术上最大的
diff，笔者认为是出价，因为在广告场景中引入了广告主(advertiser)这一角色，因此我们除了考虑用户体验，还需要满足金主爸爸们的诉求（如跑量、成本等），才能带来持续的收入增长，而金主爸爸们表达其诉求的最直接的手段就是出价，其含义就是愿意为每个
click/convert 付出多少钱(truthful telling)。这带出来的就是 bidding
这一研究领域，关于这个领域在 <a
href="https://github.com/wnzhang/rtb-papers">rtb-papers</a>
中有很多相关的 paper。</p>
<p>本文主要讲的是 2019 KDD 阿里的 <a
href="https://arxiv.org/abs/1905.10928">Bid Optimization by
Multivariable Control in Display Advertising</a>，这篇 paper
解决了出价的两个的核心问题：<strong>出价公式和调价策略</strong>，从最优的出价公式的推导到出价控制器的构建，文章的总体的建模思路非常值得学习，整个推导的
paradigm 能够推广到更一般的出价场景, 实践性也较强，推荐读原文。</p>
<span id="more"></span>
<p><strong>出价从技术上可认为主要由两大部分组成：出价公式和控制器</strong>，比如说常见的
cpc 出价公式是 bid * ctr, 最常见的控制器则是 <a
href="https://en.wikipedia.org/wiki/PID_controller#:~:text=A%20proportional%E2%80%93integral%E2%80%93derivative%20controller,applications%20requiring%20continuously%20modulated%20control.">PID</a>。出价公式我们能比较好理解，那为什么要控制器来调价而不是按照广告主给的出价来投呢？笔者认为主要有以下两个原因</p>
<ol type="1">
<li><strong>为了满足广告主的各种诉求</strong>；如需要匀速投放时，即在一天内均匀地花完预算，这样就需要通过控制器来控制运算花费曲线趋势与大盘流量曲线的趋势保持一致；如需要保成本时，需要通过控制器在成本高了时压价,
低了时提价；需要跑量同时允许在成本有略微上涨时，可以在成本可控的情况下更激进一点出出价</li>
<li><strong>ctr/cvr 的预估不是完全准确的</strong>；常见的 ctr/cvr
高估时，容易导致超成本，因为这时候计算出来的 ecpm = bid×ctr×cvr
也相当于是高估了；其根本原因是在 ctr/cvr 预估中没有一个绝对的 ground
truth, 我们能拿到的是点击/转化与否，但是要预估的则是点击/转化的概率</li>
</ol>
<p>前面提到，paper
中主要讲了两部分内容，最优出价公式的推导和控制器，下面描述的内容也会主要从这两方面进行描述</p>
<h2 id="最优出价公式">最优出价公式</h2>
<p>paper
中要解决的场景是在保住点击成本和预算时，最大化广告主的在所有参竞价值(value)，因此这个优化问题可写成如下形式</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_LP1.jpg" alt="LP1" />
<figcaption aria-hidden="true">LP1</figcaption>
</figure>
<p>上式中的各个符号含义如下</p>
<ul>
<li><span class="math inline">\(N\)</span>,
广告计划的总的可参竞次数(opportunities)</li>
<li><span class="math inline">\(x\_i\)</span>, 第 i
次竞价获胜的概率<br />
</li>
<li><span class="math inline">\(wp\_i\)</span>, 第 i 次竞价的 winning
price，即 bid price 要大于等于这个值才能获胜</li>
<li><span class="math inline">\(B\)</span>, 计划的总预算</li>
<li><span class="math inline">\(C\)</span>, 计划设置的点击成本</li>
</ul>
<p>值得注意的是，我们<strong>不需要直接求解出上面的最优化问题的解，而只是需要求出取值为最优时的的解形式，然后作为最优出价公式</strong>，也就是说我们并不关心上面的
<span class="math inline">\(x\_i\)</span>
的最优解取值，而关心的是其他变量满足什么样的形式时，<span
class="math inline">\(x\_i\)</span> 的解是最优的</p>
<h3 id="paper-原始推导">paper 原始推导</h3>
<p>paper 通过最优化中的对偶理论将上面的原问题(primal
problem)转为对偶问题(dual problem)，如下图所示；对偶理论的详细描述可参考
<a
href="http://wulc.me/2017/02/01/%E6%9C%80%E4%BC%98%E5%8C%96%E8%AE%A1%E7%AE%97%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/">最优化计算课程总结</a>
中<strong>对偶理论</strong>这一节内容或 <a
href="https://sites.math.washington.edu/~burke/crs/407/notes/section4.pdf">Duality
Theory</a> 这个讲义</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_dual_problem_LP2.jpg"
alt="LP2" />
<figcaption aria-hidden="true">LP2</figcaption>
</figure>
<p>上图中的 <span class="math inline">\(p,q,r\)</span>
都是对偶问题中变量，对应于原问题中的三类约束：预算，成本和对 <span
class="math inline">\(x\)</span>
的范围的约束，根据互补松弛定理(Complementary Slackness)
，可得到下面两个式子, 互补松弛定理的详细描述同样可参考上面的两个链接</p>
<figure>
<img
src="https://wulc.me/imgs/bidding_optimization_Complementary_Slackness.jpg"
alt="Complementary Slackness" />
<figcaption aria-hidden="true">Complementary Slackness</figcaption>
</figure>
<p>上面的公式中 <span class="math inline">\(x\_i^{\*}\)</span> 和 <span
class="math inline">\(r\_i^{\*}\)</span>
分别表示原问题和对偶问题的最优解，后面带 <code>*</code>
上标的符号均表示最优解，至此为止，上面都是基于最优化理论推导出来的一些公式，但是<strong>接下来这一步就有点跳了</strong>，paper
中直接令最优出价公式为</p>
<p><span class="math display">\[bid^{\*} = \frac{1}{p^\*+q^\*} × CTR\_i
× CVR\_i + \frac{q^\*}{p^\*+q^\*} × C × CTR\_{i}\tag{6}\]</span></p>
<p>则上面那些公式中表示给广告主带来的价值 <span
class="math inline">\(v\_i\)</span> 可写成 <span
class="math inline">\(v\_i = bid\_i - wp\_i\)</span>,
将公式（6）代入这个式子，再将 <span class="math inline">\(v\_i\)</span>
代入上图中的公式(8)，可得到下面的公式（10）及其分类讨论的结果</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_classify_situation.jpg"
alt="分类讨论结果" />
<figcaption aria-hidden="true">分类讨论结果</figcaption>
</figure>
<p>上面的两个分类讨论的结果实际上表明了<strong>无论最优解 <span
class="math inline">\(x^*\)</span> 是赢得这次竞价(<span
class="math inline">\(x=1\)</span>)还是输掉这次竞价(<span
class="math inline">\(x=0\)</span>)，按照公式(6)进行出价时，总能保证解是最优的</strong></p>
<h3 id="另一种推导思路">另一种推导思路</h3>
<p>之所以说上面最后的推导有点跳，是因为公式(6)所表示的那一坨<strong>最优出价公式是怎么给出来的？</strong>随便拍脑袋似乎不太可能，paper
中并没有针对这一点详细描述，笔者在这里尝试提供另一个求解的思路，就是利用拉格朗日对偶来推导出最优出价公式，关于这部分内容可参考
<a
href="http://wulc.me/2017/05/20/%E5%87%B8%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/">凸优化总结</a>
中的拉格朗日对偶部分</p>
<p>对于原问题即上图中的 LP1， 可写出其増广拉格朗日函数为(暂时忽略 <span
class="math inline">\(x\)</span> 的值的约束)</p>
<p><span class="math display">\[L(x,p,q) = \sum\_{i=1\dots
N}-x\_iCTR\_iCVR\_i + p(\sum\_{i=1\dots N}x\_iwp\_i-B) +
q(\sum\_{i=1\dots N}x\_i(wp\_i-CTR\_iC))\]</span></p>
<p>上式中的 <span
class="math inline">\(p&gt;=0,q&gt;=0\)</span>，则原问题可写成如下形式,
详细推导过程可参考上面的凸优化总结的链接</p>
<p><span class="math display">\[\max\_{p,
q}\min\_{x\_i}L(x,p,q)\]</span></p>
<p>如果是要求出这个问题的解，还需要转为拉格朗日对偶问题，通过 SMO
等算法进行求解，但是我们这里不需要确切的解，而是只需要最优解的表达式，因此可令
<span
class="math inline">\(\frac{\partial{L(x,p,q)}}{\partial{x}}=0\)</span>,
求解可得</p>
<p><span class="math display">\[wp\_i = \frac{1}{p+q} × CTR\_{i} ×
CVR\_{i} + \frac{q}{p+q} × C × CTR\_{i}\]</span></p>
<p>可以看到，<strong>winning price <span
class="math inline">\(wp\_i\)</span> 推导出来的形式跟上面给的公式(6)
中的最优出价公式的形式是一样的</strong>！！！</p>
<p>但是上面的推导中的仍有一些问题，上面求解的是最优的 <span
class="math inline">\(wp\_i\)</span>，bid
这个变量没有显示地出现在增广拉格朗日函数中，但是可近似认为两者是相等的；其次是，<strong><span
class="math inline">\(x\_i\)</span> 本身的约束(即取值在 0~1
之间)没有显式的考虑进增广拉格朗日函数中</strong>，针对这一点，笔者的理解是在解决最优化问题时可以忽略某个条件，然后在求解出来之后基于这个条件做分类讨论，而这一部分实际上就是原始
paper 在推导出公式(10)后做的分类讨论。</p>
<h3 id="小结">小结</h3>
<p>综合考虑上面两部分的推导，可以得到最优的出价公式如上面公式(6)所示，公式中的
<span class="math inline">\(p\)</span> 和 <span
class="math inline">\(q\)</span>
是两个超参，是对偶问题中需要求解的变量，<strong>如果需要求解，意味着需要拿到参竞的所有后验数据，但是实际中在参竞时就需要通过这些参数给出参竞的
bid，这似乎就成了一个先有鸡还是先有蛋的问题了</strong>，后面会通过控制器描述如何解决这一问题，具体思想就是不直接求解原始的最优化问题，而是通过近似的方式来逐渐逼近最优解</p>
<p>回到公式(6)的最优出价公式，如果将其写成 <code>c_bid * ctr</code>
的形式，有如下公式</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_cbid.jpg"
alt="click bid" />
<figcaption aria-hidden="true">click bid</figcaption>
</figure>
<p>如果更直观的画出来如下图所示, 从图中可知，哪怕 CVR 为 0 时，bid
也不一定为 0，这跟常见的 ecpm = bid×ctr×cvr 不太一样，这可理解为一些 cvr
低但是 ctr 高的流量也是可以拿的；此外，c_bid 的直线会过两个定点： (-qC,
0) 和 (pC, C), 后面在控制器中会详细描述这两个点的具体含义。</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_cbid_graph.jpg"
alt="bid_optimization_cbid_graph" />
<figcaption aria-hidden="true">bid_optimization_cbid_graph</figcaption>
</figure>
<h2 id="调价策略">调价策略</h2>
<p>前面提到，最优出价公式中的 <span class="math inline">\(p\)</span> 和
<span class="math inline">\(q\)</span>
的最优解求解需要拿到参竞后的后验数据，但是 bid
是要在参竞的时候就给出来，因此这就成了一个先有鸡还是先有蛋的问题。针对这个问题，最直观的一个想法是，我们<strong>可不可以用历史数据来求出最优的
<span class="math inline">\(p\)</span> 和 <span
class="math inline">\(q\)</span>, 然后应用到下一时刻的出价中？</strong>
paper 中也提到了这一点，答案是
no，因为这个方法假设了参竞流量的分布是基本不变的，但是竞价环境是一个受多个因素影响的动态变化环境(包括参竞流量、ctr、cvr
等)，即历史的最优不会是未来的最优。在实际的实践中，笔者的实践经验的确是这样的。</p>
<p>由于竞价环境是实时变化的，因此需要动态调价，在调价策略中，需要先明确两个点：<strong>调控的目标和调控的变量</strong>。以最经典的
PID 控制器为例，如下图所示，调控的目标是 <span
class="math inline">\(r(t)\)</span> 与 <span
class="math inline">\(y(t)\)</span> 尽可能接近，调控的变量是 <span
class="math inline">\(x(t)\)</span>。</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_pid_controller.jpg"
alt="pid" />
<figcaption aria-hidden="true">pid</figcaption>
</figure>
<p>每次调整变量时，需要通过公式(13)计算出当前的
error，然后通过公式(14)计算出控制型号 <span
class="math inline">\(u(t)\)</span>（其中 <span
class="math inline">\(k\_p\)</span>、<span
class="math inline">\(k\_i\)</span>、<span
class="math inline">\(k\_d\)</span> 是三个拍定的超参），最后利用 <span
class="math inline">\(u(t)\)</span> 通过公式(15) 的调控公式(actuator
model) <span class="math inline">\(\phi(x(0), u(t))\)</span>
得到最终调整后的值</p>
<p>PID
对于单变量的控制可以说是比较常用和有效的方法，但是我们的上面提到的问题是一个多变量控制问题，其中<strong>控制变量是
<span class="math inline">\(p\)</span> 和 <span
class="math inline">\(q\)</span>，控制目标是控制好预算花费并保点击成本</strong>;
对于这个问题，一个很直观的想法就是通过双 PID
分别进行独立调控，但是这些<strong>控制变量之间往往不是相互独立的，因此双
PID 不是最优的</strong>, 后面会详细描述这一点。</p>
<h3 id="参数分析">参数分析</h3>
<p>下面首先会分析控制变量<span class="math inline">\(p\)</span> 和 <span
class="math inline">\(q\)</span> 分别影响哪些控制目标</p>
<p>如下图 4 是固定 <span class="math inline">\(q\)</span>，改变 <span
class="math inline">\(p\)</span> 时, <code>c_bid</code>
的变化，其中虚线表示改变前的出价，实线表示改变后的出价；从图中可知</p>
<ul>
<li>出价的直线始终通过 (-qC, 0) 这个点</li>
<li><strong>随着 <span class="math inline">\(p\)</span>
的减小，出价的直线的斜率逐渐增大，表示出价更高</strong>，同时消耗的
budget 也会更多;而随着 <span class="math inline">\(p\)</span>
增大导致的结果则是刚好相反</li>
<li><strong>当 <span class="math inline">\(p\)</span> 取最小值即 0
时，表示没有 budget 的限制</strong>，出价公式退化为 <span
class="math inline">\(C×CTR+\frac{1}{q}CTR×CVR\)</span>,
公式第一项可以认为是只按照点击出价来保点击成本 <span
class="math inline">\(C\)</span>，第二项则是为了达到 <span
class="math inline">\(\max v=CTR×CVR\)</span>的目标</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_controll_qfixed.jpg"
alt="q fixed" />
<figcaption aria-hidden="true">q fixed</figcaption>
</figure>
<p>同理可画出下图 5 中固定 <span class="math inline">\(p\)</span>，改变
<span class="math inline">\(q\)</span> 时, <code>c_bid</code> 的变化;
从图中可知</p>
<ul>
<li>出价的直线始终通过 (pC, C) 这个点</li>
<li><strong>随着 <span class="math inline">\(q\)</span>
的减小，出价的直线的斜率逐渐增大，表示对于 CVR 比 p<em>C
更高的流量出价更高，CVR 比 p</em>C 更低的流量出价更低</strong>, 而随着
<span class="math inline">\(q\)</span> 增大导致的结果则是刚好相反</li>
<li><strong>当 <span class="math inline">\(q\)</span> 取最小值即 0
时，表示没有点击成本的限制</strong>，此时的出价公式退化为 <span
class="math inline">\(\frac{1}{p}CTR×CVR\)</span>，代表出价成本的符号
<span class="math inline">\(C\)</span>
没有出现的出价公式中，总体表示要达到 <span class="math inline">\(\max
v=CTR×CVR\)</span>的目标，同时通过 <span
class="math inline">\(q\)</span> 来控制预算</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_controll_pfixed.jpg"
alt="p fixed" />
<figcaption aria-hidden="true">p fixed</figcaption>
</figure>
<h3 id="控制器">控制器</h3>
<p>通过上面的分析可知，参数 <span class="math inline">\(p\)</span>
是被用来控制预算的使用，而参数 <span class="math inline">\(q\)</span>
则是被用来控制点击成本；其实这与我们上面推导最优出价公式时对应的约束条件是一致的。</p>
<p>因此，一种最简单的策略是用两个独立的 PID 来分别调控变量 <span
class="math inline">\(p\)</span> 和 <span
class="math inline">\(q\)</span>，调控的目标则是预算和点击成本。如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_independent_pid.jpg"
alt="independent pid" />
<figcaption aria-hidden="true">independent pid</figcaption>
</figure>
<p>但是我们前面也提到，这两者并不是完全独立的，比如说为了保点击成本进行提价或降价也会影响到预算的使用，反之亦然。因此两个完全独立的
PID 并不是最优的选择, 而是在控制中要考虑两个变量相互的影响</p>
<p><a
href="https://en.wikipedia.org/wiki/Model_predictive_control">Model
Predict Control</a>(MPC)中有关于这类问题的研究，但是 paper
中并不直接采用这个方法，因为 paper 中认为 "<strong>modelling the highly
non-linear RTB environment is costly and even impratical</strong>"；
而是通过一个线性模型去拟合。笔者认为其可行的原因是调控往往会分为多个时间片，然后在每个时间片内进行调控，<strong>而在每个时间片内用直线去拟合，理论上只要把时间切得足够小，最终总体也能拟合出非线性的曲线</strong>。</p>
<p>主要的建模思想是<strong>通过两个 linear regression model 直接建模变量
<span class="math inline">\(p、q\)</span> 和目标 cost、CPC
的关系</strong>(即原文的model the bidding environment with respect to
cost and CPC）具体的做法如下</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_multivar_control.jpg"
alt="multi-var control" />
<figcaption aria-hidden="true">multi-var control</figcaption>
</figure>
<p>上图中的公式(16)里的 <span class="math inline">\(X\)</span> 和 <span
class="math inline">\(b\)</span> 分别表示 2×2 的矩阵和 2×1
的矩阵，如果展开后其实就是两个 linear regression model</p>
<p>进一步地，公式(17)表示的是给定需要控制的目标 <span
class="math inline">\(\Delta cost\)</span> 和 <span
class="math inline">\(\Delta
CPC\)</span>（调价是分时间片进行调控的，在每次调控前都可以根据当前累积消耗和成本等后验数据，进而进行计算当前时间片需要调控得到的
<span class="math inline">\(\Delta cost\)</span> 和 <span
class="math inline">\(\Delta CPC\)</span>），可以对 p 和 q 分别进行
<span class="math inline">\(\Delta p\)</span> 和 <span
class="math inline">\(\Delta q\)</span>
的调控达到目标，笔者这里有个疑问，<strong>为什么这里的 b
可以被约去</strong>，</p>
<p>虽然 paper
中没有直接提到，但是<strong>笔者认为其实到了公式(17)已经可以进行调控了，只是调控的方式跟
paper 中不太一样</strong>，这里简单描述一下。首先需要获取公式(17)中
<span class="math inline">\(X\)</span>，而 <span
class="math inline">\(X\)</span>
中的参数其实是可通过训练数据获取，训练的数据集<strong>从当前时间往前的若干个个时间片内的
(<span class="math inline">\(\Delta p\)</span>, <span
class="math inline">\(\Delta q\)</span>, <span
class="math inline">\(\Delta p\)</span>, <span
class="math inline">\(\Delta q\)</span>)</strong>，然后<span
class="math inline">\(X\)</span>就可以通过常规的训练方式获取；这样在每个时间片调价时，只需要计算好的
<span class="math inline">\(X\)</span> 和下一时间片的调控目标：<span
class="math inline">\(\Delta cost\)</span> 、 <span
class="math inline">\(\Delta CPC\)</span> ，便能通过 grid search
得到最优的 <span class="math inline">\(\Delta q\)</span> 和 <span
class="math inline">\(\Delta p\)</span>。</p>
<p>公式 (18) 是在公式(17)基础上乘上矩阵 <span
class="math inline">\(X\)</span> 的逆便得到；公式 (19) 则是 paper
中提出的调控方式：首先通过上面的 PID 调控公式(14)可以将公式(18)中的<span
class="math inline">\(\Delta cost\)</span> 、 <span
class="math inline">\(\Delta CPC\)</span> 变为 <span
class="math inline">\(u\_{p}(t)\)</span>、<span
class="math inline">\(u\_{q}(t)\)</span>; 同时只用两个变量 <span
class="math inline">\(\alpha\)</span> 和 <span
class="math inline">\(\beta\)</span> 来近似矩阵 <span
class="math inline">\(X\)</span> 的逆（理论上应该有 4 个的），并认为
<span class="math inline">\(p\)</span>、<span
class="math inline">\(q\)</span> 的 control signal(通过公式 (14) 获取)
<span class="math inline">\(u&#39;\_{p}(t)\)</span>、<span
class="math inline">\(u&#39;\_{q}(t)\)</span>是<span
class="math inline">\(u\_{p}(t)\)</span>、<span
class="math inline">\(u\_{q}(t)\)</span> 的线性组合；paper
称这样做的好处是 <strong>makes the controller more robust and stable
against the changing environment</strong>, paper 中称 <span
class="math inline">\(\alpha\)</span> 和 <span
class="math inline">\(\beta\)</span>
是从训练集中获取的(详见下面的实验效果环节)</p>
<p>因此，根据公式(19), 总体的调控系统变为</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_related_pid.jpg"
alt="related pid" />
<figcaption aria-hidden="true">related pid</figcaption>
</figure>
<h2 id="实验设置与效果评估">实验设置与效果评估</h2>
<h3 id="基本设置">基本设置</h3>
<p>paper 中并没有进行在线实验，而是通过离线方式进行评估</p>
<p>采用的数据集是 taobao 40 个计划总共 20M 条 bid log，每条 bid log
的关键信息是<span class="math inline">\(wp\_i、
CTR、CVR\)</span>；同时根据时间划分了训练集和测试集</p>
<p>评估指标主要有两个</p>
<ul>
<li><span class="math inline">\(CPC\_{ratio}\)</span>:
表示保住点击成本的计划的比例</li>
<li><span
class="math inline">\(Value\_{ratio}\)</span>：表示按最优出价公式重新投放时，每个计划获取的value与其理论最优的比值(<span
class="math inline">\(\le 1\)</span>)</li>
</ul>
<h3 id="实现细节">实现细节</h3>
<p>除此之外，paper 中通过 PID 计算 control signal 时，会<strong>对 err
进行加权</strong>，而传统的 PID 中所有的 err
的权值都是一样的，其加权方法如下公式(21)所示，而前一章提到的 <span
class="math inline">\(u\_{q}(t)\)</span> 计算方式如公式(22)所示</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_weighted_pid_err.jpg"
alt="weighted_pid_err" />
<figcaption aria-hidden="true">weighted_pid_err</figcaption>
</figure>
<p>除了对 err 进行加权，上面的公式（20）也很有意思，就是每次通过 control
signal 调整目标zhi值<span class="math inline">\(x\)</span>
时，<strong>不是基于上一次的值<span
class="math inline">\(x(t)\)</span>，而是基于最开始的值 <span
class="math inline">\(x(0)\)</span></strong></p>
<p>此外，<strong>调价的频率是每小时调整一次，PID 中涉及的超参(<span
class="math inline">\(k\_p、 k\_i、 k\_d\)</span>)以及公式(19)中的 <span
class="math inline">\(\alpha\)</span> 和 <span
class="math inline">\(\beta\)</span> 都是在训练集中通过 grid serach
找到的</strong></p>
<p>因此，总体的实验步骤如下</p>
<ol type="1">
<li>基于训练数据集<strong>计算出最优的 <span
class="math inline">\(p\)</span> 、<span
class="math inline">\(q\)</span> 作为其初始值</strong></li>
<li>在测试数据集上用上面的最优出价公式和调价策略进行模拟竞价
(3）当计划的 budget 消耗完或者所有的日志回放完成则终止</li>
</ol>
<h3 id="效果对比">效果对比</h3>
<p>实验效果如下图所示，其中图 8 是 budget 消耗的情况，图 9
是成本情况，同时左边的图是实时指标，右边的图是累积指标；从图中可知，budget
消耗的幅度无论是实时还是累积都拟合得比较好，而点击成本虽然在实时上由波动，但是累积的成本是比较稳定的。</p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_performance.jpg"
alt="performance" />
<figcaption aria-hidden="true">performance</figcaption>
</figure>
<p>除此之外，paper 还与其他的一些方法进行了比较，结果如下图所示，其中
I-PID 和 M-PID 是本文提出的方法，分别表示 PID
是否相互独立的，从结果可知，采用了 paper
中的出价公式且考虑控制变量的关系的调价方式的效果是最好的，也印证了我们前面提到的<strong>两个完全独立的
PID 并不是最优的选择, 而是在控制中要考虑两个变量相互的影响</strong></p>
<figure>
<img src="https://wulc.me/imgs/bid_optimization_evaluation_result.jpg"
alt="evaluation result" />
<figcaption aria-hidden="true">evaluation result</figcaption>
</figure>
<h2 id="小结-1">小结</h2>
<p>综上，这篇 paper
首先将要求解的方法建模成一个最优化的问题，然后通过对偶理论求解出这个最优化问题的最优解的形式，而不是它的解；接着描述了多变量调控系统中一种考虑控制变量间相互关系的调控策略，并通过实验结果证明这种策略的效果要优于只通过两个独立的
PID
分别调控的效果；美中不足的是没有做在线实验，毕竟离线实验的环境变基本就定下来了，重新进行竞价也不会改变这个环境，不像线上变化那么剧烈；但是
paper 中的总体建模思路还是非常值得学习的，可以作为一个 paradigm
推广到更一般的出价场景。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《Embedding-based Retrieval in Facebook Search》阅读笔记</title>
    <url>/2020/08/30/%E3%80%8AEmbedding-based%20Retrieval%20in%20Facebook%20Search%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a href="https://arxiv.org/abs/2006.11632">Embedding-based Retrieval
in Facebook Search</a> 是 FB 在 2020
年发表的一篇搜索场景下如何做向量化召回的
paper，整篇文章读下来，就像是一个奋战在一线的工程师向你娓娓道来他们是怎么从
0 到 1 构建一个召回系统，从训练数据与特征的选取, 到模型的 training 与
serving、再到把新的召回策略融入现有的 ranking system, 整篇 paper
并没有太多的公式与推导，但是却有很多在实战中总结出来的经验，而且这些经验相信也可以推广搜索以外的推荐/广告领域。本文主要是根据笔者对这篇
paper 的理解做一些提炼，推荐读原文。</p>
<span id="more"></span>
<p>笔者认为这篇 paper 值得关注的点如下</p>
<ol type="1">
<li><strong>召回模型的负样本的选取</strong>（为什么不能只选取曝光未点击的样本作为负样本，easy
negative 与 hard negative）</li>
<li>新的召回策略如何克服当前 ranking system 的 bias</li>
<li>构建一个召回系统的常规流程及每个流程中的一些经验</li>
</ol>
<p>后面介绍的内容与 paper 中的基本保持一致，且主要介绍其中一些关键点</p>
<h2 id="system-overview">System Overview</h2>
<p>在推荐、广告和搜索的场景下基本的架构都是召回(Retrival)+精排（Ranking），因为这三者其实都是要在每条请求到来的时候从一个庞大的候选集中选取出topk个返回给用户，而召回作为这个流程的入口，面对的几乎是整个候选集，为了在延迟上满足要求，召回不会采用太复杂的模型和特征，且往往会对
item 做倒排索引(Inverted Index)。</p>
<p>paper 中的系统总体的架构如下，在每条请求到来的时候会实时计算用户的
embedding，然后利用构建好的 document embedding 倒排索引做
retrival，为了加速，在向量化召回中还会采用 Quantization 技术(在后面的
serving 步骤中介绍)</p>
<figure>
<img src="https://wulc.me/imgs/RetrivalSystem.jpg" alt="sys overview" />
<figcaption aria-hidden="true">sys overview</figcaption>
</figure>
<h2 id="model">Model</h2>
<p>这里的 model 主要指上图中的 Query Embedding Model 与 Document
Embedding Model，即生成 embedding
的模型，采用的也是很经典的双塔模型，如下图所示; 这里的 unified embedding
主要是指这个 embedding 输入的原始 feature 不仅仅包含 query 和 document
本身的文本信息，还有对应的上下文信息(context)信息, 这种做法其实在 google
2016 发表的那篇 Deep Neural Networks for YouTube Recommendations
已经有了，而这也是 NN 模型比起 Matrix Factorization 等方法生成 embedding
的优点；可以添加更多的 feature 到模型中</p>
<figure>
<img src="https://wulc.me/imgs/ModelOverview.jpg"
alt="model overview" />
<figcaption aria-hidden="true">model overview</figcaption>
</figure>
<h3 id="损失函数">损失函数</h3>
<p>模型采用的损失函数是 triple loss，最早是在人脸识别中提出的一个
loss，假设每条训练样本是 <span
class="math inline">\((q^{(i)},d\_+^{(i)}, d\_-^{(i)})\)</span>,
式子中的<span class="math inline">\(d\_+^{(i)}\)</span> 表示与 query
<span class="math inline">\(q^{(i)}\)</span> 相关的 document，而 <span
class="math inline">\(d\_-^{(i)}\)</span>表示与query <span
class="math inline">\(q^{(i)}\)</span> 不相关的 document, 则 paper 中的
loss 定义如下</p>
<p><span class="math display">\[L=\sum\_{i=1}^{N} \max(0,
D(q^{(i)},d\_+^{(i)}) - D(q^{(i)},d\_-^{(i)}) + m)\]</span></p>
<p>上式中的 <span class="math inline">\(m\)</span>
是一个超参，表示正样本与负样本的 enforced margin，<strong>表示正负样本的
distance 假如大于 m，则认为这个是一个 easy example
不需要模型进一步学习去区分了</strong>；paper
中提到了这个超参对结果影响较大，因为不同的任务的最优的 m
往往不一样。</p>
<p>上面的 D 表示距离函数(越小表示越相似)，paper 中采用的 distance 函数是
<span class="math inline">\(D(q,d) = 1-cos(q, d)\)</span>,</p>
<p>此外，<strong>针对 paper 中的训练样本对，其实也可以采用经典的 LTR
中的 pariwise loss</strong>，具体可参考 <a
href="https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf">From
RankNet to LambdaRank to LambdaMART: An Overview</a></p>
<p>此外，paper 中的
<strong>采用的指标是离线评估的召回率（recall），采用的验证集是 10000 个
search session 中每个 query 及其 target result</strong>(paper
中并无明确给出这一标准，只是提到按照点击或人工评估方式来获取均可以)</p>
<h3 id="训练样本">训练样本</h3>
<p>训练样本的选取是 paper
中的一个着重强调的一个点，且<strong>关键点在于负样本的选取</strong>，paper
中选取的正样本是点击样本，而负样本则做了下面的两组对比</p>
<ul>
<li>随机选取负样本</li>
<li>选取曝光未点击的样本作为负样本</li>
</ul>
<p>实验结果显示<strong>选取曝光未点击的样本作为负样本时，其效果比随机选取负样本要差很多</strong>；paper
中对这一现象的解释是</p>
<blockquote>
<p>We believe it is because these negatives bias towards hard cases
which might match the query in one or multiple factors, while the
majority of documents in index are easy cases which do not match the
query at alll. Having all negatives being such hard negatives will
change the representativeness of the training data to the real retrieval
task, which might impose non-trivial bias to the learned embeddings.</p>
</blockquote>
<p>笔者理解采用曝光未点击的样本作为负例，其实就是<strong>造成了 training
与 serving 的不一致性</strong>，因为曝光未点击的样本大部分是 hard
cases，即使最终未被点击，但是与 query
也还是有一定相关性的，但是线上召回时面对的候选集是全部的候选，其中有绝大部分与本次
query 无关的 easy cases。当负例全部采用 hard cases，实际上与最终的
serving 就是不一致的，而 paper 中共则说这种行为 “might impose
non-trivial bias to the learned embeddings”</p>
<p>除了负例，paper
中也探索了正例的选择，关于正例的选择做了下面两组的对比</p>
<ul>
<li>选取点击作为正例</li>
<li>选取曝光作为正例</li>
</ul>
<p><strong>实验结果显示在数据量相同的情况下，两者效果基本一致</strong>，即使是在曝光的正例基础上叠加点击正例，结果也没有进一步的提升。</p>
<p>关于正例的选择，虽然 paper
中称两类正样本差别不大，但是<strong>笔者认为在实际中采用曝光样本作为正例更合适</strong>，原因如下</p>
<ol type="1">
<li>点击一般是比较稀疏的，数据量较少</li>
<li>未点击的样本不应就不是好的样本，有可能只是位置等原因导致的，相比于点击样本，采样这样的样本一定程度上相当于做了
Explore</li>
</ol>
<p><strong>hard mining</strong></p>
<p>这部分内容是 paper
中第六节的内容，但也是训练样本选取的一个关键点，因此放在这里一起说明。</p>
<p>前面提到，选取负样本的时候不能选择曝光未点击的 hard
cases，但是凡事有多个度，<strong>当负例中的样本都是很容易就能跟正例区分开的
easy cases，模型也不一定能学得好</strong>，paper
中对这一现象描述如下</p>
<blockquote>
<p>This motivated us believe that the model was not able to utilize
social features properly yet, and it’s very likely because the negative
training data were too easy as they were random samples which are
usually with different names. To make the model better at
differentiating between similar results, we can use samples that are
closer to the positive examples in the embedding space as hard negatives
in training.</p>
</blockquote>
<p>这里的 hard nagative
指的就是那些与正例相似性较高的负例(现对于随机选取的负例)，但是<strong>这里的
hard nagative 并不是那些曝光未点击的负例</strong>，paper
中提出了两种方法来挖掘 hard nagative：online hard negative mining 和
offline hard nagative mining，两种方法的基本流程如下</p>
<p><strong>online hard negative mining</strong></p>
<p>在每个 batch 的训练中，假设正样本对为 <span
class="math inline">\(\lbrace(q^{(i)},d\_+^{(i)})\rbrace\_{i=1}^{n}\)</span>,
则对于每个query <span class="math inline">\(q^{(i)}\)</span>, 会从 <span
class="math inline">\(\lbrace d\_+^{(1)} \dots d\_+^{(j)} \dots
d\_+^{(n)} | j \ne i\rbrace\)</span> 中随机选出 k 个 document 作为 hard
nagative，paper 中称其场景下 k=2
是最优的，如果多了会导致模型的效果下降</p>
<p>paper 中的实验数据表示加入这样的 hard nagative 后，在不同类型的 iterm
的搜索上的召回率均有提升。</p>
<p>但是实际上<strong>以这种方式选取出来的负样本还不够
hard</strong>，原因也很简单，因为这些 negative 是属于不同的 query
的，不同 query 的相关性不高，因此这些样本的相似性也不高，因此有了
offline hard negative mining</p>
<p><strong>offline hard nagative mining</strong></p>
<p>offline hard nagative 的做法更像 LTR 的 pairwise 样本构造了，其选取
negative 的方式是在每个 query 的所有 document 中，<strong>选择那些排序在
101-500 的位置的样本作为 hard nagative</strong>；值得注意的是，选择那些
hardest 的 negative 的效果并不是最优的（如排序在第二名的那些）</p>
<p>上面提到的是负样本的 mining，但是同样也可以针对正样本做这样的 hard
mining，但是 paper 这一块篇幅较少，细节说的也不是非常清晰，只是提到了
"we mined potential target results for failed search sessions from
searchers’ activity log", 大意就是从那些失败的 search session
的日志中找到那些没被系统召回的但是 positive
的样本，<strong>笔者猜测这些可能是因为工程上的失败导致没被 send
出来但是日志里面已经显示排序的第一名的样本</strong></p>
<p>综上，在召回样本的选取上，paper 强调了<strong>负样本中的要同时包含
easy nagative 和 hard nagative，paper 的观点是 hard nagative 更关注
non-text 的特征（如 social 特征等），而 easy nagative 则更关注 text
的特征</strong>，因此需要混合两者使用，而混合的方式有两种，分别是</p>
<p>(1)<strong>blending</strong>, 即混合两者一起来训练，paper
中给出两者的最优比例大概是 easy:hard ≈ 100:1 (2)<strong>transfer
learning from "hard" model to "easy" model</strong>, 即先用 hard
nagative 训练模型，然后用 easy nagative 训练模型（但是 paper 提到从
"easy" model 到 "hard" model并不能达到相同的效果）</p>
<h2 id="feature-engineering">Feature Engineering</h2>
<p>这里的 Feature Engineering 着重强调的是在 query 和 document 的 text
feature 基础上加入一些其他的 context feature(paper
中主要提出了两种，location feature 和 social embedding feature)
能取得取得较大提升，下面简单介绍一些这几种 feature</p>
<p><strong>text feature</strong></p>
<p>对于文本特征的构建，paper 中采用的是 character n-gram 而不是 word
n-gram，这里的 n-gram 其实就是把连续的 n 个 character 或 word 作为一个
item 输入到 embedding table 中做 embedding lookup，<strong>paper
中通过实验证明了采用 character n-gram 比起 word n-gram
效果要更优，分析其优点如下</strong></p>
<ol type="1">
<li>embedding lookup table 的 size 更小，能更好的学习到 embedding table
中的参数，其实就是降低了 model size</li>
<li>对于出现在训练集以外的单词有更好的鲁棒性，因为 embedding 的粒度是
character</li>
</ol>
<p><strong>location feature</strong></p>
<p>paper 在 query 和 document 中均添加了了 localtion feature；对于
query，添加的 feature 包括 searcher's
<strong>city/region/country/language</strong>, 对于 document，则采用一些
publicly available information 如一些 explicit group location 的 tag
之类的</p>
<p>下面是加入了 localtion feature 前后同一个 query 返回的 document
的对比，可以看到加入 location feature 后，返回的搜索结果中的 document 的
location 信息与 searcher 的更加相似</p>
<figure>
<img src="https://wulc.me/imgs/LocationFeature.jpg"
alt="location feature" />
<figcaption aria-hidden="true">location feature</figcaption>
</figure>
<p><strong>social embedding feature</strong></p>
<p>关于这个 feature paper 中并无详细说明，猜测是通过类似 graph embedding
的方式来得到这个 embedding，然后作为 feature 输入给召回模型</p>
<p>下面是加了 location feature 和 social embedding feature
后得效果提升情况</p>
<figure>
<img src="https://wulc.me/imgs/FeatureEffectiveness.jpg"
alt="feature effectiveness" />
<figcaption aria-hidden="true">feature effectiveness</figcaption>
</figure>
<h2 id="serving">Serving</h2>
<p>serving 采用的是 ANN（Approximate Near Neighbor），且通过
quantization 来进一步缩短向量间相似性的计算时间，quantization
相当于是一种向量压缩的技术；关于 product quantization 可参考 <a
href="http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017/08/05/understanding-product-quantization">理解
product quantization 算法</a> 这篇文章</p>
<p>实际中的<strong>向量化召回系统往往会包含两个步骤，indexing 和
scoring</strong>，indexing 是为了过滤大部分基本无关的候选，而 scoring
则是在相关的候选中进行计算与排序，indexing 常用的技术有
K-means、HNSW、LSH 等，而 scoring 则主要是各种 quantization
及其变种方法</p>
<p>上面这两个步骤在不同的地方的叫法可能也不一样，如在 paper
中这两个步骤就被称为 coarse quantization 和 product quantization；coarse
quantization 其实就是通过聚类的方法将整个候选库中的分为若干个
clsuter，在query 到来的时候，选出 topk 个 cluster，并通过 product
quantization 来计算出分数进行排序。具体工程实现上采用的是 facebook
开源的 <a href="https://github.com/facebookresearch/faiss">faiss</a>
库，关于上面的步骤细节可参考 <a
href="https://blog.csdn.net/u013066730/article/details/106252573">PQ和IVF介绍</a></p>
<p>而在这个过程中 paper 总结的一些经验如下</p>
<ul>
<li>对比 coarse quantization 的算法时，需要固定条数对比召回率(如 paper
中采用的是 1-Recall@10)，其实这种做法也比较常见，因为不同的 coarse
quantization 算法聚类的结果差别比较大，因此在固定 cluster 数量和召回时
topk 中 k 的数值，得到的结果差异也会比较大</li>
<li>当模型有较大(non-trivial)变动时，ann
的一些超参也需要相应进行调整来适应新的模型</li>
<li>PQ 算法中的 <a
href="http://kaiminghe.com/publications/pami13opq.pdf">OPQ</a>(Optimized
Product Quantization) 效果一般较好，值得进行相应的尝试</li>
<li>PQ 算法中对 embedding
进行子空间划分时，划分的空间大小是个超参，理论上这个值越大，计算结果越精确，同时资源开销也越大；paper
中的建议值是4, paper 中表示 “From empirical results, we found that the
accuracy improvement is limited after x &gt; d/4.”</li>
</ul>
<p>实际 serving 的时候，<strong>只会实时计算 query 塔的 embedding，而
document 塔的 embedding
则会离线计算好并构建倒排索引</strong>，且在实际的系统中，新的 document
会不断生成，因此还会计算新 document
作为<strong>增量索引</strong>，而间隔一段时间好需要重新计算全量的倒排索引。</p>
<h2 id="later-stage-optimization">Later-stage Optimization</h2>
<p>这一部分主要描述了所有推荐系统现在存在的一个
bias，就是训练数据都是由当前系统产生的并反哺给系统的，因此很可能会造成“马太效应”，即强者约强，弱者越弱；更广义来说，这也属于一个
E&amp;E 问题.</p>
<p>在 paper
中，这一点体现在<strong>新的ANN召回的结果可能并不会被精排认可</strong>，paper
中描述如下</p>
<blockquote>
<p>since the current ranking stages are designed for existing retrieval
scenarios, this could result in new results returned from embedding
based retrieval to be ranked sub-optimally by the existing rankers</p>
</blockquote>
<p>为了克服这个问题，paper 中提出了两种方法</p>
<ol type="1">
<li>将召回的 embedding 作为精排模型的特征，paper 中称这样做的 motivation
是能更快让精排学到新召回的特性；embedding
加入精排作为特征的方式有：embedding 作为 feature 直接加入精排模型、基于
embedding 计算出的值加入精排模型(如 query embedding 与 document
embedding 的 cosine similarity）等，其中效果最好是通过 cosine similarity
计算出feature 加入精排模型。</li>
<li>人为干预加入新召回后训练数据的分布。为了避免新召回的结果不被 ANN
认可，paper
中并不仅仅依赖系统自身产生的数据作为训练数据，而是通过人工的方式对被召回的结果重新打上
label，但是在实际中感觉这个操作成本会比较高~</li>
</ol>
<h2 id="小结">小结</h2>
<p>这篇 paper 主要讲了 FB 在搜索场景下构建一个 ANN
召回系统的基本步骤，包括训练数据的选择、模型的训练、
serving等，每一部分都给出了一些实战经验，值得参考；而其中比较值得关注的是负样本的选择，paper
将负样本分为 easy negative 与 hard nagative 两大类，并通过实验证明只用
easy nagative 或 hard nagative
训练出来的都不是最优的，而是需要联合两者共同训练。</p>
<p>此外，paper 最后还提到了 embedding ensemble 方法，基本的方法就是
weighted concatentation(parallel，类似 bagging) 和 cascade
model(cascade, 类似
boosting)，但是笔者觉得召回阶段本来的候选就非常大，对耗时要求严格，如果再加上
ensemble，耗时会更严重，在实际中是否具有可行性？ensemble
做在精排是否更合理？</p>
<p>最后，知乎上也有一篇针对这篇 paper 的解读，也值得看一下 <a
href="https://zhuanlan.zhihu.com/p/165064102">负样本为王：评Facebook的向量化召回算法</a>，而关于
embedding 在推荐/广告上的各种应用推荐看 <a
href="https://zhuanlan.zhihu.com/p/143763320">推荐系统 embedding
技术实践总结</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《Forecasting High-Dimensional Data》阅读笔记</title>
    <url>/2018/11/15/%E3%80%8AForecasting%20High-Dimensional%20Data%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>《<a href="https://dl.acm.org/citation.cfm?id=1807277">Forecasting
High-Dimensional Data</a>》 是 Yahoo!
一篇关于流量预估的论文。在合约广告中，需要提前预估某个定向下的流量情况，从而进行合理的售卖和分配。但是由于定向的组合非常多（广告主的多样的需求导致的），而工程上不允许为每个可能的定向预估其流量，因此这篇论文提出了<strong>先预估一些基本定向的流量，然后通过
correlation model
从基本定向的流量计算出各种定向下的流量情况</strong>，具有较强的工程性，也是之前提到的文章
《<a
href="http://wulc.me/2018/10/25/%E3%80%8ABudget%20Pacing%20for%20Targeted%20Online%20Advertisements%20at%20LinkedIn%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">Budget
Pacing for Targeted Online Advertisements at LinkedIn</a>》
中采用的流量预估方法。</p>
<span id="more"></span>
<h2 id="问题定义">问题定义</h2>
<p>前面简单提到了文章解决的问题的背景，文章将一个最基本的定向（如性别为男）称为一个
attribute，而每个广告主的需要的流量就是若干个 attribute 的
combination，因此 combination
的数量是非常庞大的，<strong>文章要求的就是如何有效地预估所有 combination
的流量情况</strong>。</p>
<p>一个最直观的思路就是统计出某个 combination
的历史数据，然后训练模型并进行预估。但是这个方法最致命的地方在于统计
combination
的历史数据以及模型训练所需的耗时在实际中是无法容忍的，需要数小时（文章要求需要在数百毫秒内返回某个
combination
的流量预估值）。那可以将这些放到离线来做么？答案也是不可以的，因为我们不知道哪些
combination 在未来会用到，因此所有的 combination
都需要进行预估，而这个数量过于庞大了。</p>
<h2 id="解决思路">解决思路</h2>
<p>文章提出的解决思路是<strong>先对一小部分有代表性的 combination
进行上面的历史统计和预估操作</strong>，这里的<strong>有代表性的流量</strong>可以从统计的历史数据中得到（如访问量最多的combination
等），也可以手工选择等；然后<strong>结合文章提到的 correlation
model，可以从这一小部分的 combination 中预估出所有的 combination
的流量情况</strong>。</p>
<p>下面具体详细介绍整体的解决思路</p>
<h2 id="系统总览">系统总览</h2>
<p>文章提出的方法系统图如下，每个的 Historical Data Point
实际上就是一个历史 query，包含了某些 attribute
的组合，这些数据主要有两个用途</p>
<p>（1）送入到 Historical Data Aggregator 中对某些有代表性的 Selected
Attribute Combinations
进行历史统计，并通过模型进行时间序列的预估，这里的时间序列预估使用了 <a
href="https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average">SARIMA</a>
模型 （2）用于构建 Correlation Model，并与上面若干 Selected Attribute
Combinations 的预估结果共同对在线的 query 返回预估值</p>
<figure>
<img src="https://wulc.me/imgs/image_1cstndv791jqh17tnago65f10679.png"
alt="system" />
<figcaption aria-hidden="true">system</figcaption>
</figure>
<p>可以看到<strong>文章的重点在于 correlation model 的构建以及
correlation model 在 online 部分是如何工作的</strong>。</p>
<h2 id="correlation-model">Correlation Model</h2>
<p>上文提到了对一部分有代表性的 combination（也就是上图中的 Selected
Attribute Combinations）进行时间序列预估，这里记为 <span
class="math inline">\(Q = \lbrace Q\_1, Q\_2,... Q\_m \rbrace\)</span>,
称其为 base queries。则对于一个在线的 query <span
class="math inline">\(q\)</span>, 其<strong>预估步骤如下</strong></p>
<ol type="1">
<li>选择 <span class="math inline">\(Q\)</span> 中某个 base query <span
class="math inline">\(Q\_k\)</span>, 使得 <span class="math inline">\(q
\subseteq Q\_k\)</span></li>
<li>计算 <span class="math inline">\(Q\_k\)</span> 在未来时间 <span
class="math inline">\(T\)</span> 内的流量，记为 <span
class="math inline">\(B(Q\_k, T)\)</span></li>
<li>计算 <span class="math inline">\(q\)</span> 在 <span
class="math inline">\(Q\_k\)</span> 中出现的概率，记为 <span
class="math inline">\(R(q|Q\_k)\)</span></li>
<li>返回 <span class="math inline">\(q\)</span> 的预估结果为 <span
class="math inline">\(B(Q\_k, T) \times R(q|Q\_k)\)</span></li>
</ol>
<p>Correlation Model 所做的事情就是第3步：计算比例。</p>
<p>而在第一步中，<strong>必然会存在某个 <span
class="math inline">\(Q\_k\)</span>，使得<span class="math inline">\(q
\subseteq Q\_k\)</span></strong>, 为什么呢？</p>
<p>假设总共有 n 个 attribute，那么只要将每个 attribute 作为一个 base
query（这样 <span class="math inline">\(Q\)</span> 中便有了 n 个 base
queries），则 attribute 的任意 combination 肯定会属于 Q 中的某几个 base
queries 的。那如果<strong>不止一个 <span
class="math inline">\(Q\_k\)</span>，使得<span class="math inline">\(q
\subseteq Q\_k\)</span></strong> 时该怎么办？这时候就需要选择一个最小的
<span class="math inline">\(Q\_k\)</span>, 这里的最小指的是不存在某个
<span class="math inline">\(Q\_l\)</span> 同时满足 <span
class="math inline">\(q \subseteq Q\_l\)</span> 且 <span
class="math inline">\(Q\_l \subseteq
Q\_k\)</span>。举个简单的例子，假如有两个 base queries <span
class="math inline">\(Q1 = a\_1 , Q\_2 = a1 \wedge a\_2\)</span>,
则对于某个 query <span class="math inline">\(q = a1 \wedge a\_2 \wedge
a\_3\)</span>，应该选择 <span class="math inline">\(Q\_2\)</span> 作为
<span class="math inline">\(Q\_k\)</span>。</p>
<p>下面分别讲述文中提到的三种 correlation model</p>
<h3 id="full-independence-model-fim">Full Independence Model (FIM)</h3>
<p>FIM 实际上就是个 Naive Bayes，假设了每个 attribute
是相互独立的，也就是</p>
<p><span class="math display">\[R(Gender = male \wedge Age &lt; 30|Q\_k)
= R(Gender = male|Q\_k) \times R(Age &lt; 30|Q\_k)\]</span></p>
<p>也就是只要为 <span class="math inline">\(Q\_k\)</span> 每个单独的
attribute 计算其比例 <span class="math inline">\(R(.| Q\_k)\)</span>
即可。具体计算方法如下</p>
<p>令 <span class="math inline">\(P\_t\)</span> 是截止到时间 <span
class="math inline">\(t\)</span> 时所有的访问量，<span
class="math inline">\(|Q\_k \wedge P\_t|\)</span> 为这些访问量中满足
<span class="math inline">\(|Q\_k|\)</span> 的那些访问量，<span
class="math inline">\(|a\_i \in (Q\_k \wedge P\_t)|\)</span> 为满足
<span class="math inline">\(|Q\_k|\)</span> 的那些访问量中同时满足
attribute <span class="math inline">\(a\_i\)</span>的，则对于
attribute，其计算公式如下</p>
<p><span class="math display">\[R(a\_i|Q\_k) = \frac{|a_i \in (Q\_k
\wedge P\_t)|}{|Q\_k \wedge P\_t|}\]</span></p>
<h3 id="partwise-independence-model-pim">Partwise Independence Model
(PIM)</h3>
<p>将所有的 attribute 都认为是相互独立的显然是不合理的，因为有某些
attribute 之间是相互关联的，比如说年龄和收入一般是存在关联的，因为 PIM
实际上就是将某些可能有关联的 attribute 的比例一起计算。即</p>
<p><span class="math display">\[R(Gender = male \wedge Age &lt; 30
\wedge Incom &gt; 10000|Q\_k) = R(Gender = male|Q\_k) \times R(Age &lt;
30 \wedge Incom &gt; 10000|Q\_k)\]</span>,
而比例的计算公式也跟上面的类似</p>
<h3 id="sampling-based-joint-modelsjm">Sampling-based Joint
Model(SJM)</h3>
<p>上面的两种方法均假设了 attribute
之间的的相互独立性，这依然会存在一定的局限性，能够完全避免独立性的假设呢？这篇文章提出的
Sampling-based Joint Model(SJM) 就避免了独立性的假设。</p>
<p>虽然说是 model ，但是方法还是统计，只是为了避免数量太大，首先做了
sampling，选出经过 sample 后的数据并记为 <span
class="math inline">\(S\)</span>，然后计算 base query <span
class="math inline">\(|Q\_k|\)</span> 在 <span
class="math inline">\(S\)</span> 中的数量 <span
class="math inline">\(|Q\_k \cap S|\)</span>,
这部分会在离线做，然后在线来了一个 query <span
class="math inline">\(q\)</span> 后，会计算在 <span
class="math inline">\(S\)</span> 中满足 <span
class="math inline">\(q\)</span> 的数量并记为 <span
class="math inline">\(n\)</span>。则比例计算公式就很简单了</p>
<p><span class="math display">\[R(q|Q\_k) = \frac{n}{|Q\_k \cap
S|}\]</span></p>
<p>整个过程思路非常简单，没有涉及到 attribute，因此也没有 attribute
independent
的假设。但是关键的问题在于如何高效地算出上面的分子和分母的那些计数。论文使用的是bitmap
index, 且使用了论文 <a
href="https://dl.acm.org/citation.cfm?id=1132864">Optimizing bitmap
indices with efficient compression</a> 中提出的关于 bitmap index
的一种改进方法。</p>
<h2 id="实验效果">实验效果</h2>
<h3 id="数据">数据</h3>
<p>实验采用的数据是
Yahoo！部分页面过去一年的历史访问数据，其中一半用于进行 time-series
forecasting，另一半用于验证效果（按时间划分），且对于某些 combination
用了过去四年累积的数据进行 forecasting。Correlation Model
则用了过去一周的数据进行训练，且 SJM 采样得到了 20 million 的数据。</p>
<h3 id="评估指标">评估指标</h3>
<p>工程上的评估指标有 speed 和 space，就是时间和空间的评估。</p>
<p>效果上的评估指标主要就是 accuracy，采用的是 absolute percentage error
(APE), 假设预估值为 <span class="math inline">\(F\)</span>, 真实值为
<span class="math inline">\(A\)</span>, 则 APE 的定义如下</p>
<p><span class="math display">\[APE = \frac{|F-A|}{A}\]</span></p>
<p>APE 针对的是单个 query，但是往往希望的是验证一系列 query
的效果，其指标为 Root Mean Square Error (RMSE)，定义如下, <span
class="math inline">\(w\_q\)</span> 表示每个 query 的权重，这个值被设为
query 在过去两年的合约中出现的次数</p>
<p><span class="math display">\[RMSE = \sqrt{\frac{\sum\_{q \in
Q}w\_qAPE^2(q)}{\sum\_{q \in Q}w\_q}}\]</span></p>
<h3 id="效果对比">效果对比</h3>
<p>下面是三个模型的 RMSE（取了对数） 效果对比，横轴的 forecast horizon
表示预估未来多少天的时的效果。可以看到假设 attribute independent
会降低最后的效果。</p>
<p>除此之外，每个模型在进行 online 是返回结果的耗时都要小于 50 毫秒；且
FIM 和 PIM 模型的内存占比大概是 500
MB，因为这两个模型只需要存储比例值和预估的趋势曲线，但是 SJM
的内存大概到了 20GB（20 million的data points），空间主要由 bit-map index
消耗。</p>
<figure>
<img src="https://wulc.me/imgs/image_1csvl3andohv1od31prus551h4l26.png"
alt="对比" />
<figcaption aria-hidden="true">对比</figcaption>
</figure>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《Programming Collective Intelligence》读书笔记(1)--梗概</title>
    <url>/2016/01/24/%E3%80%8AProgramming%20Collective%20Intelligence%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0(1)/</url>
    <content><![CDATA[<p>《Programming Collective
Intelligence》（中文名为《集体智慧编程》），是一本关于数据挖掘的书籍，每一章都会通过一个实际的例子来讲述某个机器学习算法，同时会涉及到数据的采集和处理等，是一本实践性很强的书籍。</p>
<p><strong>本文是关于本书的第一章 Introduction to Collective
Intelligence ,主要介绍了 collective intelligence 以及 machine learning
的一些概念。</strong></p>
<span id="more"></span>
<h2 id="什么是-collective-intelligence">什么是 collective intelligence
？</h2>
<p>根据单词直译过来就是“集体智慧”,引用原文的解释如下</p>
<blockquote>
<p>Collecting answers from a large group of people lets you draw
statistical conclusions about the group that no individual member would
have known by themselves. Building new conclusions from independent
contributors is really what collective intelligence is all about.</p>
</blockquote>
<p>可以简单认为就是从一个群体中获取每个个体的信息，经过算法处理后得出能够描述这个群体的一些结论。常见的比如说问卷调查可以认为是一种集体智慧，超市从顾客的购物清单得出顾客的喜好进而调整货物的摆放也可以认为是一种集体智慧。</p>
<h2 id="什么是-machine-learning">什么是 machine learning？</h2>
<p>机器学习，顾名思义，就是让机器具有学习的能力。<strong>具体的做法就是先用一些历史数据来训练一个模型，再利用模型去预测新的数据或趋势</strong>。训练模型的方法就是机器学习算法，根据实际的应用场景也可以分为多种，如直观的决策树算法、较为抽象的神经网络等。</p>
<p>机器学习也有其的局限性，主要体现在两个方面：</p>
<p>第一个方面是机器学习只能凭借其“见过的数据”（也就是用来训练这个模型的数据）来进行预测归纳，这导致了遇到了新的情况可能出现误判的情况。因此在机器学习中用来训练模型的数据集对模型的效果有很大影响。</p>
<p>第二个方面是大部分机器学习存在笼统归纳（overgeneralize）的问题,例如你收到朋友的一份邮件，里面很可能出现“购买”的字眼，而如果垃圾邮件过滤算法认为出现这个字眼即为垃圾邮件，那么便会把这封邮件归为垃圾邮件过滤掉。但是这种情况也存在解决方法，就是在拉结邮件过滤系统中将这位朋友的邮件均标记为合法邮件。这也说明了<strong>只要给机器学习算法更详细的信息进行学习，机器学习算法便能够变得更加精准。</strong></p>
]]></content>
      <categories>
        <category>集体智慧编程</category>
      </categories>
      <tags>
        <tag>集体智慧编程</tag>
      </tags>
  </entry>
  <entry>
    <title>《Programming Collective Intelligence》读书笔记(2)--协同过滤</title>
    <url>/2016/02/22/%E3%80%8AProgramming%20Collective%20Intelligence%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0(2)--%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/</url>
    <content><![CDATA[<p>《Programming Collective
Intelligence》（中文名为《集体智慧编程》），是一本关于数据挖掘的书籍，每一章都会通过一个实际的例子来讲述某个机器学习算法，同时会涉及到数据的采集和处理等，是一本实践性很强的书籍。</p>
<p><strong>本文是关于本书的第二章 Making Recommendations
的前半部分。主要讲述了寻找用户相似性和物品相似性的方法，并在这个基础上讲述如何为用户推荐物品。</strong></p>
<span id="more"></span>
<p>推荐这个功能在很多网站或软件都有实现，如淘宝，当当，网易云音乐等。实现推荐的算法也许有很多。本文主要讲的是<strong>协同过滤</strong>。</p>
<p>下面分为这几部分来讲述： <strong>1.寻找用户相似性的几种方法
2.基于用户相似性为用户推荐物品 3.寻找物品相似性的方法</strong></p>
<p>在讲述之前假定一下的数据集： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 电影评分数据集,用于后面的的测试</span></span><br><span class="line"><span class="comment"># critics 字典里面每一项是一个用户对若干部电影的评分</span></span><br><span class="line">critics=&#123;<span class="string">&#x27;Lisa Rose&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">2.5</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">3.5</span>,<span class="string">&#x27;Just My Luck&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">3.5</span>, <span class="string">&#x27;You, Me and Dupree&#x27;</span>: <span class="number">2.5</span>,<span class="string">&#x27;The Night Listener&#x27;</span>: <span class="number">3.0</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Gene Seymour&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">3.5</span>,<span class="string">&#x27;Just My Luck&#x27;</span>: <span class="number">1.5</span>, <span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">5.0</span>, <span class="string">&#x27;The Night Listener&#x27;</span>: <span class="number">3.0</span>,<span class="string">&#x27;You, Me and Dupree&#x27;</span>: <span class="number">3.5</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Michael Phillips&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">2.5</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">3.0</span>,<span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">3.5</span>, <span class="string">&#x27;The Night Listener&#x27;</span>: <span class="number">4.0</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Claudia Puig&#x27;</span>: &#123;<span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">3.5</span>, <span class="string">&#x27;Just My Luck&#x27;</span>: <span class="number">3.0</span>,</span><br><span class="line"> <span class="string">&#x27;The Night Listener&#x27;</span>: <span class="number">4.5</span>, <span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">4.0</span>,<span class="string">&#x27;You, Me and Dupree&#x27;</span>: <span class="number">2.5</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Mick LaSalle&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">4.0</span>,<span class="string">&#x27;Just My Luck&#x27;</span>: <span class="number">2.0</span>, <span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;The Night Listener&#x27;</span>: <span class="number">3.0</span>,<span class="string">&#x27;You, Me and Dupree&#x27;</span>: <span class="number">2.0</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Jack Matthews&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">4.0</span>,<span class="string">&#x27;The Night Listener&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">5.0</span>, <span class="string">&#x27;You, Me and Dupree&#x27;</span>: <span class="number">3.5</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Toby&#x27;</span>: &#123;<span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">4.5</span>, <span class="string">&#x27;You, Me and Dupree&#x27;</span>: <span class="number">1.0</span>,<span class="string">&#x27;Superman Returns&#x27;</span>: <span class="number">4.0</span>&#125;&#125;</span><br></pre></td></tr></table></figure></p>
<h2
id="寻找用户相似性的几种方法"><strong>寻找用户相似性的几种方法</strong></h2>
<h3 id="欧几里得距离">欧几里得距离</h3>
<p>基于上面的数据集，最容易想到的第一种方法就是衡量他们所评的<strong>分数的距离</strong>。这个怎么理解呢？比如说A对两部电影的评分是1和2，B对两部电影的评分书3和4。那么他们评分的距离就是<span
class="math inline">\(\sqrt{(1-3)^2+(2-4)^2
}\)</span>。如果有多部电影则以此类推。这<strong>相当与把一个用户所有评分用多维空间中的一个点来表示，用户间的相似性用点间的距离来衡量，距离越小，相似度越高。</strong>原文称这种距离为欧几里得距离分数（Euclidean
Distance score）。 通过python实现也很简单： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过欧几里得距离找用户相似性，为了使返回数值越大，表示相似性越高，对得出的距离取倒数即可，范围为（0,1）</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">similarUserWithEuclidean</span>(<span class="params">scores,user1,user2</span>):</span><br><span class="line">    commom = [movie <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user1] <span class="keyword">if</span> movie <span class="keyword">in</span> scores[user2]]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(commom) == <span class="number">0</span>:  <span class="comment">#没有相同喜爱的电影</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    total = <span class="built_in">sum</span>([math.<span class="built_in">pow</span>(scores[user1][movie] - scores[user2][movie], <span class="number">2</span>) <span class="keyword">for</span> movie <span class="keyword">in</span> commom])</span><br><span class="line">    similarity=math.sqrt(total)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(total+<span class="number">1</span>)  </span><br></pre></td></tr></table></figure></p>
<p>上面实现的方法虽然简单，但是存在着<strong>分数膨胀(grade
inflation)</strong>的问题,比如说A和B两个人的评判标准不一样，A比较苛刻，给三部电影打的分数是1、2、1，但是B要求不会那么高，给两部电影打分为4、5、4，如果用第一种方法那他们在二维空间中的距离将会比较大，从而被判为无相似性。那么他们真的是没有相似性吗？</p>
<p>虽然他们在分数值上存在区别，但是<strong>两个人在每部电影的评分差上保持一致性，也可认为他们是相似用户。</strong>因为在对于好和不好的标准上每个人都会有自己的度量，也许对于A来说2就算是好的了，但是对于B来说好的标准是5。假如对于多部电影两者的评分趋势一致，那么可认为两者的品味也是差不多的，可以认为他们有相似性。通过<strong>皮尔逊相关系数（Pearson
Correlation Coefficient）</strong>可以实现上面的功能。</p>
<h3 id="皮尔逊相关系数">皮尔逊相关系数</h3>
<p>皮尔逊相关系数取值范围为[-1,1],数值为正表示正相关，且越大表示相关性越强；数值为负则为负相关，越小则负相关性越强。计算公式如下：</p>
<p><span class="math display">\[sim = \frac{\sum\_{c \in
I\_{ij}}(R\_{i,c} - \overline{R\_i})(R\_{j,c} -
\overline{R\_j})}{\sqrt{\sum\_{c \in I\_{ij}} (R\_{i,c} -
\overline{R\_i})^2} \sqrt{\sum\_{c \in I\_{ij}} (R\_{j,c} -
\overline{R\_j})^2} }\]</span></p>
<p>公式中的符号意义如下：</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(I\_{ij}\)</span></td>
<td>用户 <span class="math inline">\(i\)</span> 和用户 <span
class="math inline">\(j\)</span>
的公共评分集，也就是两者都有评分的物品的集合</td>
</tr>
<tr class="even">
<td><span class="math inline">\(R\_{i,c}\)</span></td>
<td>用户 <span class="math inline">\(i\)</span> 对物品c的评分</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(R\_{j,c}\)</span></td>
<td>用户 <span class="math inline">\(j\)</span> 对物品c的评分</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\overline {R\_i}\)</span></td>
<td>用户 <span class="math inline">\(i\)</span> 对 <span
class="math inline">\(I\_{ij}\)</span> 中物品评分的均值</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\overline {R\_j}\)</span></td>
<td>用户 <span class="math inline">\(j\)</span> 对 <span
class="math inline">\(I\_{ij}\)</span> 中物品评分的均值</td>
</tr>
</tbody>
</table>
<p>皮尔逊系数的公式初看有点长，但是如果对概率论了解的同学可知，对于变量
<span class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> ，上面的皮尔逊系数的表达式其实就是<span
class="math display">\[\frac{X和Y的协方差}{X的标准差\*Y的标准差}\]</span>，而这就是概率论中对相关系数的定义。<strong>实际上概率论中的相关系数就是皮尔逊提出的这个皮尔逊相关系数率</strong>(这里需要注意的是，对于不同测量尺度的变数，有不同的相关系数可用，而我们接触到的概率论教材里，大多是都是讲皮尔逊相关系数，实际上还有<a
href="https://zh.wikipedia.org/wiki/%E7%9B%B8%E5%85%B3">其他的相关系数</a>)。</p>
<p>用图像直观表示皮尔逊相关系数如下所示，假设r为互相关系数：</p>
<p><img src="https://wulc.me/imgs/pearson-2-small.png" /></p>
<p>且一般认为r值范围和相关性的对应关系如下，0表示两者无关：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">相关性强弱</th>
<th style="text-align: center;">对应的r值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">High correlation</td>
<td style="text-align: center;">0.5~1.0 or -0.5~ -1.0</td>
</tr>
<tr class="even">
<td style="text-align: center;">Medium correlation</td>
<td style="text-align: center;">0.3 ~ 0.5 or -0.3~ -0.5</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Low correlation</td>
<td style="text-align: center;">0.1~0.3 or -0.1~ -0.3</td>
</tr>
</tbody>
</table>
<p>关于皮尔逊系数更详细的资料可参考该链接：http://www.statisticshowto.com/what-is-the-pearson-correlation-coefficient</p>
<p>实现该功能的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过 Pearson Correlation Coefficient 计算两个用户的相似性,数值绝对值越大相关性，正负表示正相关或负相关</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">similarUserWithPearson</span>(<span class="params">scores,user1,user2</span>):</span><br><span class="line">    commom = [movie <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user1] <span class="keyword">if</span> movie <span class="keyword">in</span> scores[user2]]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(commom) == <span class="number">0</span>:  <span class="comment">#no common item of the two users</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    average1 = <span class="built_in">float</span>(<span class="built_in">sum</span>(scores[user1][movie] <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user1]))/<span class="built_in">len</span>(scores[user1])</span><br><span class="line">    average2 = <span class="built_in">float</span>(<span class="built_in">sum</span>(scores[user2][movie] <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user2]))/<span class="built_in">len</span>(scores[user2])</span><br><span class="line">    <span class="comment"># denominator</span></span><br><span class="line">    multiply_sum = <span class="built_in">sum</span>( (scores[user1][movie]-average1) * (scores[user2][movie]-average2) <span class="keyword">for</span> movie <span class="keyword">in</span> commom )</span><br><span class="line">    <span class="comment"># member</span></span><br><span class="line">    pow_sum_1 = <span class="built_in">sum</span>( math.<span class="built_in">pow</span>(scores[user1][movie]-average1, <span class="number">2</span>) <span class="keyword">for</span> movie <span class="keyword">in</span> commom )</span><br><span class="line">    pow_sum_2 = <span class="built_in">sum</span>( math.<span class="built_in">pow</span>(scores[user2][movie]-average2, <span class="number">2</span>) <span class="keyword">for</span> movie <span class="keyword">in</span> commom )</span><br><span class="line">    </span><br><span class="line">    modified_cosine_similarity = <span class="built_in">float</span>(multiply_sum)/math.sqrt(pow_sum_1*pow_sum_2)</span><br><span class="line">    <span class="keyword">return</span> modified_cosine_similarity </span><br></pre></td></tr></table></figure></p>
<p>上面两种方法是书中提到的，并且计算皮尔逊相关系数的方法与原书有区别，但是结果是一样的。只是原书上对公式进行了进一步的简化。除此之外，还有一类比较常用的方法是<strong>通过余弦相似性（Cosine
Similarity）判断用户相似性</strong>。原理也是<strong>用空间中的一个多维向量表示用户对所有电影的评分，用户间的相似性可以通过向量间的夹角表示，取值范围也是（-1,1）。但是因为这种方法也存在上面提到的分数膨胀(grade
inflation)，在此基础上提出了修正的余弦相似度（Adjusted Cosine
Similarity）</strong>。</p>
<h3 id="修正的余弦相似性">修正的余弦相似性</h3>
<p>修正的余弦相似度跟上面提到的皮尔逊系数很相似，包括计算公式，区别在于<strong>皮尔逊系数是依据双方共同评分项进行计算，而修正的余弦相似度则对所有项都进行运算</strong>。比如说一部电影A有评分，B没有评分，那么计算皮尔逊系数时就不能采用这不电影作为计算的数据集，但是计算修正的余弦相似性则可以利用这个数据。</p>
<p>修正的余弦相似性的计算公式如下</p>
<p><span class="math display">\[sim = \frac{\sum\_{c \in
I\_{ij}}(R\_{i,c} - \overline{R\_i})(R\_{j,c} -
\overline{R\_j})}{\sqrt{\sum\_{c \in I\_i} (R\_{i,c} -
\overline{R\_i})^2} \sqrt{\sum\_{c \in I\_j} (R\_{j,c} -
\overline{R\_j})^2} }\]</span></p>
<p>公式中的符号意义如下：</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(I\_{ij}\)</span></td>
<td>用户 <span class="math inline">\(i\)</span> 和用户 <span
class="math inline">\(j\)</span>
的公共评分集，也就是均被两者评分的物品的集合</td>
</tr>
<tr class="even">
<td><span class="math inline">\(I\_i\)</span></td>
<td>被用户 <span class="math inline">\(i\)</span>
评分了的物品的集合</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(I\_j\)</span></td>
<td>被用户 <span class="math inline">\(j\)</span>
评分了的物品的集合</td>
</tr>
<tr class="even">
<td><span class="math inline">\(R\_{i,c}\)</span></td>
<td>用户 <span class="math inline">\(i\)</span> 对物品c的评分</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(R\_{j,c}\)</span></td>
<td>用户 <span class="math inline">\(j\)</span> 对物品c的评分</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\overline {R\_i}\)</span></td>
<td>用户 <span class="math inline">\(i\)</span> 所有评分的均值</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\overline {R\_j}\)</span></td>
<td>用户 <span class="math inline">\(j\)</span> 所有评分的均值</td>
</tr>
</tbody>
</table>
<p>这条公式跟上面的皮尔逊相关系数很相似，皮尔逊相关系数的公式如下：</p>
<p><span class="math display">\[sim = \frac{\sum\_{c \in
I\_{ij}}(R\_{i,c} - \overline{R\_i})(R\_{j,c} -
\overline{R\_j})}{\sqrt{\sum\_{c \in I\_{ij}} (R\_{i,c} -
\overline{R\_i})^2} \sqrt{\sum\_{c \in I\_{ij}} (R\_{j,c} -
\overline{R\_j})^2} }\]</span></p>
<p><strong>两者的区别在于分母上，皮尔逊系数的分母采用的评分集是两个用户的共同评分集（就是两个用户都对这个物品有评价），而修正的余弦系数则采用两个用户各自的评分集。</strong></p>
<p>采用修正的余弦系数的实现代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">user_similarity_on_modified_cosine</span>(<span class="params">scores, user1, user2</span>):</span><br><span class="line">    commom = [movie <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user1] <span class="keyword">if</span> movie <span class="keyword">in</span> scores[user2]]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(commom) == <span class="number">0</span>:  <span class="comment">#no common item of the two users</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    average1 = <span class="built_in">float</span>(<span class="built_in">sum</span>(scores[user1][movie] <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user1]))/<span class="built_in">len</span>(scores[user1])</span><br><span class="line">    average2 = <span class="built_in">float</span>(<span class="built_in">sum</span>(scores[user2][movie] <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user2]))/<span class="built_in">len</span>(scores[user2])</span><br><span class="line">    <span class="comment"># denominator</span></span><br><span class="line">    multiply_sum = <span class="built_in">sum</span>( (scores[user1][movie]-average1) * (scores[user2][movie]-average2) <span class="keyword">for</span> movie <span class="keyword">in</span> commom )</span><br><span class="line">    <span class="comment"># member</span></span><br><span class="line">    pow_sum_1 = <span class="built_in">sum</span>( math.<span class="built_in">pow</span>(scores[user1][movie]-average1, <span class="number">2</span>) <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user1] )</span><br><span class="line">    pow_sum_2 = <span class="built_in">sum</span>( math.<span class="built_in">pow</span>(scores[user2][movie]-average2, <span class="number">2</span>) <span class="keyword">for</span> movie <span class="keyword">in</span> scores[user2] )</span><br><span class="line">    </span><br><span class="line">    modified_cosine_similarity = <span class="built_in">float</span>(multiply_sum)/math.sqrt(pow_sum_1*pow_sum_2)</span><br><span class="line">    <span class="keyword">return</span> modified_cosine_similarity </span><br></pre></td></tr></table></figure>
<h3 id="计算最相似的前n个用户">计算最相似的前n个用户</h3>
<p>通过上面任意一种方法找出用户相似度后，可以根据相似度的大小排序，找出前n个最相似的用户，实现代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">findSimilarUsers</span>(<span class="params">scores,user,similarFunction = similarUserWithPearson</span>):</span><br><span class="line">    similarUser = [(similarFunction(critics, user, otherUser), otherUser) <span class="keyword">for</span> otherUser <span class="keyword">in</span> scores <span class="keyword">if</span> otherUser!=user]</span><br><span class="line">    <span class="comment"># 使用了dict会将含有kv对的列表封装成一个字典,无法利用列表自带的排序函数sort</span></span><br><span class="line">    <span class="comment"># similarDict = dict([(similarFunction(user,otherUser),otherUser) for otherUser in scores if otherUser!=user])</span></span><br><span class="line">    similarUser.sort()</span><br><span class="line">    similarUser.reverse()</span><br><span class="line">    <span class="comment">#也可将上面两行改成:similarUser.sort(reverse = True)</span></span><br><span class="line">    <span class="keyword">return</span> similarUser <span class="comment"># 返回相似度从高到低排序的一个列表</span></span><br></pre></td></tr></table></figure> ### 小结</p>
<p>传统的计算相似度的方法就是上面提到的三种：<strong>余弦相似度、修正的余弦相似度和相关相似性（也就是计算皮尔逊系数）</strong>。下面是分别采用上面三种方法为测试数据集中的用户<code>Lisa Rose</code>找到前6个最相似用户的结果。完整的代码见文末</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 欧几里得距离，第一个值是分数，第二个值是具体的用户</span><br><span class="line">(0.4444444444444444, &#x27;Michael Phillips&#x27;)</span><br><span class="line">(0.3333333333333333, &#x27;Mick LaSalle&#x27;)</span><br><span class="line">(0.2857142857142857, &#x27;Claudia Puig&#x27;)</span><br><span class="line">(0.2222222222222222, &#x27;Toby&#x27;)</span><br><span class="line">(0.21052631578947367, &#x27;Jack Matthews&#x27;)</span><br><span class="line">(0.14814814814814814, &#x27;Gene Seymour&#x27;)</span><br><span class="line"></span><br><span class="line"># 皮尔逊系数，第一个值是分数，第二个值是具体的用户</span><br><span class="line">(0.9345507010964664, &#x27;Toby&#x27;)</span><br><span class="line">(0.747017880833996, &#x27;Jack Matthews&#x27;)</span><br><span class="line">(0.5940885257860046, &#x27;Mick LaSalle&#x27;)</span><br><span class="line">(0.5477225575051661, &#x27;Claudia Puig&#x27;)</span><br><span class="line">(0.39605901719066977, &#x27;Gene Seymour&#x27;)</span><br><span class="line">(0.3872983346207417, &#x27;Michael Phillips&#x27;)</span><br><span class="line"></span><br><span class="line"># 修正的余弦相似度，第一个值是分数，第二个值是具体的用户</span><br><span class="line">(0.8093446482740976, &#x27;Toby&#x27;)</span><br><span class="line">(0.747017880833996, &#x27;Jack Matthews&#x27;)</span><br><span class="line">(0.5940885257860046, &#x27;Mick LaSalle&#x27;)</span><br><span class="line">(0.4743416490252569, &#x27;Claudia Puig&#x27;)</span><br><span class="line">(0.39605901719066977, &#x27;Gene Seymour&#x27;)</span><br><span class="line">(0.33541019662496846, &#x27;Michael Phillips&#x27;)</span><br></pre></td></tr></table></figure>
<p>从结果可以看到，<strong>修正的余弦相似度和皮尔逊系数大小虽然不一样，但是预测的整体用户相似度分布一致。</strong></p>
<h2 id="为用户推荐物品"><strong>为用户推荐物品</strong></h2>
<p>经过第一步找出相似用户后，可以直接对相似用户之间进行物品推荐，如A和B相似，且B有部分喜欢的电影A没看过，就可以为A推荐这部分电影。</p>
<p><strong>为了使得推荐结果更具有代表性，需要考虑多几位相似用户，同时也是为了有更多可推荐的选择</strong>，因为可能B看过而A没看过的电影也不多。</p>
<p>实现思路如下：为A找出了若干位相似用户，每个用户都有一个相似度系数（就是上面的皮尔森系数），找出他们看过而A没看过电影集合T。将每个用户的相似度乘上用户对集合T中某部电影的评分便可作为这部电影的得分，得分越高，代表推荐性越强。这乍一看还比较合理。但是一分析也存在一个问题，就是假如一部电影实际上都符合这一批用户的，但是看过的人很少，其他一些不太符合的电影因为看过的人多而的得分高。这就导致了误判。怎么解决呢？</p>
<p><strong>这里需要引入一个因子来调和这种不平衡性，使得结果能够合理，既然这种不平衡是由于评分的人数不同而引起的，那么就可以从这里着手。将上面相加得到的总分除以对这部电影有评分的所有用户的相似性。</strong></p>
<p>例如下图就是为上面Toby推荐的结果：</p>
<p><img src="https://wulc.me/imgs/2016-03-01_220750.png" /></p>
<p>实现的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给用户推荐物品，物品的评分采用与其他用户的相似度乘上其他用户的实际评分</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recommendItem</span>(<span class="params">scores,user</span>):</span><br><span class="line">    userSimilarity = findSimilarUsers(scores, user)</span><br><span class="line">    swapUserSimilarity = &#123;v:k <span class="keyword">for</span> k, v <span class="keyword">in</span> userSimilarity&#125; <span class="comment"># 交换键值，将存储kv对的列表转换为字典，交换后为无序</span></span><br><span class="line">    allMovies = []</span><br><span class="line">    <span class="keyword">for</span> (k,v) <span class="keyword">in</span> critics.items():</span><br><span class="line">        <span class="keyword">for</span> movie <span class="keyword">in</span> v:</span><br><span class="line">            <span class="keyword">if</span> movie <span class="keyword">not</span> <span class="keyword">in</span> allMovies:</span><br><span class="line">                allMovies.append(movie)</span><br><span class="line">    itemScore = []</span><br><span class="line">    <span class="keyword">for</span> movie <span class="keyword">in</span> allMovies:</span><br><span class="line">        scoreSum = <span class="number">0</span></span><br><span class="line">        similaritySum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> similarity, otherUser <span class="keyword">in</span> userSimilarity:</span><br><span class="line">            <span class="keyword">if</span> critics[otherUser].has_key(movie):</span><br><span class="line">                scoreSum += critics[otherUser][movie] * similarity</span><br><span class="line">                similaritySum += swapUserSimilarity[otherUser]</span><br><span class="line">        itemScore.append((scoreSum/similaritySum, movie))</span><br><span class="line"></span><br><span class="line">    itemScore.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">    recommend_movies = [] <span class="comment"># 为user推荐的电影</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;all movies ranking:&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> i,j <span class="keyword">in</span> itemScore:</span><br><span class="line">        <span class="built_in">print</span> i,j</span><br><span class="line">        <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> critics[user]:</span><br><span class="line">            recommend_movies.append(j)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;recommended movies for %s:%s&#x27;</span> %(user, recommend_movies)</span><br></pre></td></tr></table></figure></p>
<h2 id="寻找物品间的相似性"><strong>寻找物品间的相似性</strong></h2>
<p>上面的推荐方法是通过寻找相似用户进行推荐，是一种“A喜欢这个物品，跟他相似的B也可能喜欢这件物品”思想；除此之外，还有一种思想就是“A喜欢物品1，也可能喜欢相似的物品2”。在这里判断1和2的相似性就成了关键，也就是如何寻找物品间的相似性。</p>
<p>乍一看会没有思路，但是实际上很简单，只需要对原始数据做个简单的转换。上面一开始给出的数据集是一个用户对多部电影的评价，现在把换成同一部电影不同用户的评价即可.
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">将</span><br><span class="line"><span class="string">&#x27;Lisa Rose&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">2.5</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">3.5</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Gene Seymour&#x27;</span>: &#123;<span class="string">&#x27;Lady in the Water&#x27;</span>: <span class="number">3.0</span>, <span class="string">&#x27;Snakes on a Plane&#x27;</span>: <span class="number">3.5</span>&#125;&#125;</span><br><span class="line">转换为</span><br><span class="line">&#123;<span class="string">&#x27;Lady in the Water&#x27;</span>:&#123;<span class="string">&#x27;Lisa Rose&#x27;</span>:<span class="number">2.5</span>,<span class="string">&#x27;Gene Seymour&#x27;</span>:<span class="number">3.0</span>&#125;,</span><br><span class="line"><span class="string">&#x27;Snakes on a Plane&#x27;</span>:&#123;<span class="string">&#x27;Lisa Rose&#x27;</span>:<span class="number">3.5</span>,<span class="string">&#x27;Gene Seymour&#x27;</span>:<span class="number">3.5</span>&#125;&#125; etc..</span><br></pre></td></tr></table></figure></p>
<p>这样上面求用户相似性的方法是不是同样可以用来求物品间的相似性了？这种基于物品相似性的方法称为基于物品的协同过滤，而上面基于用户相似性的方法则称为基于用户的协同过滤。</p>
<p>文中完整代码见<a
href="https://github.com/WuLC/MachineLearningAlgorithm/blob/master/python/CollaborativeFiltering.py">这里</a></p>
<p>文章为笔者总结，如有错误，烦请指出</p>
]]></content>
      <categories>
        <category>集体智慧编程</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>集体智慧编程</tag>
      </tags>
  </entry>
  <entry>
    <title>《Programming Collective Intelligence》读书笔记(3)--聚类</title>
    <url>/2017/01/25/%E3%80%8AProgramming%20Collective%20Intelligence%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0(3)--%E8%81%9A%E7%B1%BB/</url>
    <content><![CDATA[<p>《Programming Collective
Intelligence》（中文名为《集体智慧编程》），是一本关于数据挖掘的书籍，每一章都会通过一个实际的例子来讲述某个机器学习算法，同时会涉及到数据的采集和处理等，是一本实践性很强的书籍。</p>
<p><strong>本文是本书的第三章 Discovering Groups的读书笔记
,主要介绍了对文本进行聚类以及对聚类后的结果进行可视化。</strong></p>
<span id="more"></span>
<p>聚类就是将相似的数据聚合在一起，形成一类，与分类比较相似，但是又有不同。一般来说聚类没有明确的类别数目，而分类根据具体的问题在一开始就确定了所有分类的可能，而且一般用于聚类的数据不需要标签,
属于无监督算法，而用于分类的数据则需要，属于有监督的算法。常见的聚类算法有KMeans，SOM（Self-Organized
Feature
Map）等，常见的分类算法则更多，如逻辑回归，朴素贝叶斯，SVM等。</p>
<p>本文主要讲逐层聚类(Hierarchical
Clustering)和KMeans聚类这两个聚类算法,依然会通过一个例子来阐述算法的具体实现。文中所有的数据和代码可从<a
href="https://github.com/WuLC/MachineLearningAlgorithm/tree/master/python/Clustering">这里</a>获取。</p>
<h2 id="获取数据">获取数据</h2>
<p>本文使用的数据为博客文本数据，通过分析博客文本之间的相似性，从而将相似的博客聚类在一起。</p>
<p>通过博客的 <a href="https://en.wikipedia.org/wiki/RSS">RSS</a>
源可以获取博客所有的文本数据，python中提供了 <code>feedparser</code>
这个第三方 package 来实现这个功能，如下代码实现的功能就是获取一个博客的
RSS 中的所有文章的summary
并进行分词统计，注意本文使用的均是英文文本。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> feedparser</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_rss</span>(<span class="params">target_url</span>):</span><br><span class="line">    rss = feedparser.parse(target_url)</span><br><span class="line">    word_count = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    <span class="comment"># traverse all passages of the blog</span></span><br><span class="line">    <span class="keyword">for</span> entry <span class="keyword">in</span> rss.entries:  </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;summary&#x27;</span> <span class="keyword">in</span> entry:</span><br><span class="line">            summary = entry.summary <span class="comment"># su</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            summary = entry.description</span><br><span class="line">        words = extract_words(entry.title+<span class="string">&#x27; &#x27;</span>+summary)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            word_count[word] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> rss.feed.get(<span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;empty title&#x27;</span>), word_count  <span class="comment"># title can be empty sometimes</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_words</span>(<span class="params">content</span>):</span><br><span class="line">    <span class="comment"># remove tag in the form of &lt;XXXX&gt;</span></span><br><span class="line">    txt = re.<span class="built_in">compile</span>(<span class="string">r&#x27;&lt;[^&gt;]+&gt;&#x27;</span>).sub(<span class="string">&#x27;&#x27;</span>,content)  </span><br><span class="line">    <span class="comment"># split words by all non-alpha characters</span></span><br><span class="line">    words = re.<span class="built_in">compile</span>(<span class="string">r&#x27;[^A-Z^a-z]+&#x27;</span>).split(content) </span><br><span class="line">    <span class="comment"># turn all words into lowercase</span></span><br><span class="line">    <span class="keyword">return</span> [word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> word != <span class="string">&#x27;&#x27;</span>] </span><br></pre></td></tr></table></figure>
<p>上面的 <code>parse_rss</code> 函数实现的功能就是从 RSS
的url中提取出所有文本的summary（或description），然后通过<code>extract_words</code>函数剔除html标签并分词，进而统计出该
RSS 源中各个词语所出现的次数。</p>
<p>由于聚类需要多个博客的数据，本文使用了原书提供的100个博客的RSS作为原始数据，并通过原始数据构造一个
<code>blog-word</code>
矩阵，行表示博客，列表示各个具体的词语，矩阵中的值表示某个词语在某个博客中出现的总次数。由于词语数目过多，因此这里会限制出现在矩阵的列的词语必须要在原始数据中出现的频率在一定的百分比。得到
<code>blog-word</code>
矩阵需要一定的运算量，因此将其写入到文件中进行持久化，方便下次的读取。下面就是实现上面功能的代码。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_content_from_feedlist</span>(<span class="params">feed_list, data_file</span>):</span><br><span class="line">    word_appear_count = defaultdict(<span class="built_in">int</span>) <span class="comment"># count thow many blogs does a word appear in</span></span><br><span class="line">    blog_word_count = &#123;&#125; <span class="comment"># words of each blog</span></span><br><span class="line">    empty_title_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> rss_url <span class="keyword">in</span> file(feed_list):</span><br><span class="line">        title, wc = parse_rss(rss_url.strip())</span><br><span class="line">        <span class="keyword">if</span> title == <span class="string">&#x27;empty title&#x27;</span>:  <span class="comment"># cannot get title of some rss</span></span><br><span class="line">            empty_title_count += <span class="number">1</span></span><br><span class="line">            title = title+<span class="string">&#x27; %s&#x27;</span>%empty_title_count</span><br><span class="line">        blog_word_count[title] = wc</span><br><span class="line">        <span class="keyword">for</span> word, count <span class="keyword">in</span> wc.items():</span><br><span class="line">            word_appear_count[word] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># caculate the appearing percentage of each word</span></span><br><span class="line">    <span class="comment"># record those words that appear within maximum and minimum percentage </span></span><br><span class="line">    minimum, maximum = <span class="number">0.1</span>, <span class="number">0.5</span></span><br><span class="line">    word_list = []</span><br><span class="line">    total_blog = <span class="built_in">len</span>(blog_word_count)</span><br><span class="line">    <span class="keyword">for</span> word, count <span class="keyword">in</span> word_appear_count.items():</span><br><span class="line">        <span class="keyword">if</span> minimum &lt;= count*<span class="number">1.0</span>/total_blog &lt;= maximum:</span><br><span class="line">            word_list.append(word)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># write data into data_file </span></span><br><span class="line">    <span class="keyword">with</span> io.<span class="built_in">open</span>(data_file, mode = <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> wf:</span><br><span class="line">        wf.write(<span class="string">&#x27;Blog&#x27;</span>.decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> word_list:</span><br><span class="line">            wf.write((<span class="string">&#x27;\t%s&#x27;</span>%word).decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        wf.write(<span class="string">&#x27;\n&#x27;</span>.decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        <span class="comment"># words of each blog</span></span><br><span class="line">        <span class="keyword">for</span> blog_title, blog_words <span class="keyword">in</span> blog_word_count.items():</span><br><span class="line">            wf.write(blog_title.decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> word_list:</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> blog_words:</span><br><span class="line">                    wf.write((<span class="string">&#x27;\t%s&#x27;</span>%blog_words[word]).decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    wf.write((<span class="string">&#x27;\t&#x27;</span>+<span class="string">&#x27;0&#x27;</span>).decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">            wf.write(<span class="string">&#x27;\n&#x27;</span>.decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>上面的 <code>get_content_from_feedlist</code>中通过获取了
<code>feed_list</code>(每行一个rss源的url)中所有博客的文本，并将那些出现频率在
0.1 到 0.5 间的词语作为 <code>blog-word</code>
矩阵的列，出现频率的计算方法为
<code>词语出现的博客数/总的博客数</code>。然后将<code>blog-word</code>
矩阵写入到 <code>data_file</code> 文件中。至此完成了获取数据的步骤。</p>
<h2 id="聚类">聚类</h2>
<p>下面将讲述两种方法对上面获取的博客数据进行聚类：逐层聚类（Hierarchical
Clustering） 和 KMeans聚类（KMeans Clustering）。</p>
<h3 id="逐层聚类hierarchical-clustering">逐层聚类（Hierarchical
Clustering）</h3>
<p>逐层聚类的思想很简单，每次将距离最近的两个cluster进行聚类，组成一个新的类，然后重复此过程直到只剩下一个最大的cluster。整个过程如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b8ue970m4gnksh14q83vd1jir9.png"
alt="逐层聚类" />
<figcaption aria-hidden="true">逐层聚类</figcaption>
</figure>
<p>这种聚类方法的具体过程如同构造一棵树，其中每个叶子节点表示一个单一的实例，而其他节点表示由多个实例聚成的cluster。</p>
<figure>
<img src="https://wulc.me/imgs/image_1b8uejmpl1iikcki1nj510ds1aj4m.png"
alt="逐层聚类树状图" />
<figcaption aria-hidden="true">逐层聚类树状图</figcaption>
</figure>
<p>算法的思路比较简单，但是有个关键问题就是如何判断cluster 与
cluster之间的距离。这里采用皮尔逊系数，皮尔逊系数在<a
href="http://wulc.me/2016/02/22/%E3%80%8AProgramming%20Collective%20Intelligence%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%282%29/">这篇文章</a>中有比较详细的描述，这里就不详细展开了，实际上皮尔逊系数就是概率论中常用的相关系数，用于表示两者的相关性，范围在
[-1,
1]之间，其中正值表示正相关，负值表示负相关，且绝对值越大，相关性越强，这里的距离越短，表示两个的正相关性越强，因此采用
<code>1-皮尔逊系数</code> 作为距离的值。实现的代码如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pearson</span>(<span class="params">v1,v2</span>):</span><br><span class="line">	<span class="comment"># Simple sums</span></span><br><span class="line">	sum1=<span class="built_in">sum</span>(v1)</span><br><span class="line">	sum2=<span class="built_in">sum</span>(v2)</span><br><span class="line">	<span class="comment"># Sums of the squares</span></span><br><span class="line">	sum1Sq=<span class="built_in">sum</span>([<span class="built_in">pow</span>(v,<span class="number">2</span>) <span class="keyword">for</span> v <span class="keyword">in</span> v1])</span><br><span class="line">	sum2Sq=<span class="built_in">sum</span>([<span class="built_in">pow</span>(v,<span class="number">2</span>) <span class="keyword">for</span> v <span class="keyword">in</span> v2])</span><br><span class="line">	<span class="comment"># Sum of the products</span></span><br><span class="line">	pSum=<span class="built_in">sum</span>([v1[i]*v2[i] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(v1))])</span><br><span class="line">	<span class="comment"># Calculate r (Pearson score)</span></span><br><span class="line">	num=pSum-(sum1*sum2/<span class="built_in">len</span>(v1))</span><br><span class="line">	den=sqrt((sum1Sq-<span class="built_in">pow</span>(sum1,<span class="number">2</span>)/<span class="built_in">len</span>(v1))*(sum2Sq-<span class="built_in">pow</span>(sum2,<span class="number">2</span>)/<span class="built_in">len</span>(v1)))</span><br><span class="line">	<span class="keyword">if</span> den==<span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1.0</span>-num/den</span><br></pre></td></tr></table></figure>
<p>另外一个问题就是如何在 python
中表示一个cluster，从上面的算法过程可知，一个cluster包括了它的两个子cluster（最开始的单实例没有），cluster的中心值等，在
python
并没有符合这种要求的数据结构，因此可以创建一个python类这个cluster。</p>
<p>创建的cluster类如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">hcluster</span>:</span><br><span class="line">	<span class="string">&quot;&quot;&quot;describe a cluster as a node in a tree&quot;&quot;&quot;</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">id</span>, vector, distance=<span class="number">0</span>, left = <span class="literal">None</span>, right = <span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">		self.<span class="built_in">id</span> = <span class="built_in">id</span></span><br><span class="line">		self.vector = vector</span><br><span class="line">		self.distance = distance</span><br><span class="line">		self.left = left</span><br><span class="line">		self.right = right</span><br></pre></td></tr></table></figure></p>
<p>各个变量及其含义如下所示</p>
<table>
<thead>
<tr class="header">
<th>变量</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>id</td>
<td>cluster的唯一标示号</td>
</tr>
<tr class="even">
<td>vector</td>
<td>cluster的值，即cluster的中心点</td>
</tr>
<tr class="odd">
<td>distance</td>
<td>组成cluster的两个子clusters的距离，叶子节点为0</td>
</tr>
<tr class="even">
<td>left，right</td>
<td>组成cluster的两个子clusters，叶子节点为None</td>
</tr>
</tbody>
</table>
<p>通过各个 cluster 的唯一标示号 id 可以方便进行 cluster
的合并和删除，而存储 distance
以及子clusters的便于后面对聚类结果的可视化。下面是逐层聚类的过程的代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hierarchicalClustering</span>(<span class="params">blog_data, distance = pearson</span>):</span><br><span class="line">	<span class="comment"># initi clusters, each node is a cluster</span></span><br><span class="line">	clusters = [hcluster(<span class="built_in">id</span> = i, vector = blog_data[i]) <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(blog_data))] </span><br><span class="line">	<span class="comment"># use negativ number to represent cluster with more than one node</span></span><br><span class="line">	clust_id = -<span class="number">1</span></span><br><span class="line">	<span class="comment"># use distance to store caculated results</span></span><br><span class="line">	distances = &#123;&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">while</span> <span class="built_in">len</span>(clusters) &gt; <span class="number">1</span>:</span><br><span class="line">		similar_pairs = (<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">		closest_distance = distance(clusters[<span class="number">0</span>].vector, clusters[<span class="number">1</span>].vector)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(clusters)):</span><br><span class="line">			<span class="keyword">for</span> j <span class="keyword">in</span> xrange(i+<span class="number">1</span>, <span class="built_in">len</span>(clusters)):</span><br><span class="line">				<span class="keyword">if</span> (clusters[i].<span class="built_in">id</span>, clusters[j].<span class="built_in">id</span>) <span class="keyword">not</span> <span class="keyword">in</span> distances:</span><br><span class="line">					distances[(clusters[i].<span class="built_in">id</span>, clusters[j].<span class="built_in">id</span>)] = distance(clusters[i].vector, clusters[j].vector)</span><br><span class="line">				d = distances[(clusters[i].<span class="built_in">id</span>, clusters[j].<span class="built_in">id</span>)]</span><br><span class="line">				<span class="keyword">if</span> closest_distance &gt; d:</span><br><span class="line">					closest_distance = d</span><br><span class="line">					similar_pairs = (i, j)</span><br><span class="line"></span><br><span class="line">		merged_vector = [(clusters[similar_pairs[<span class="number">0</span>]].vector[i] + clusters[similar_pairs[<span class="number">1</span>]].vector[i])/<span class="number">2.0</span> </span><br><span class="line">						   <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(clusters[similar_pairs[<span class="number">0</span>]].vector))]</span><br><span class="line"></span><br><span class="line">		new_cluster = hcluster(<span class="built_in">id</span> = clust_id, vector = merged_vector, distance = closest_distance, </span><br><span class="line">								left = clusters[similar_pairs[<span class="number">0</span>]], right = clusters[similar_pairs[<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">		<span class="comment"># must delete elements from higher index to lower index</span></span><br><span class="line">		<span class="keyword">del</span> clusters[similar_pairs[<span class="number">1</span>]]</span><br><span class="line">		<span class="keyword">del</span> clusters[similar_pairs[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">		clusters.append(new_cluster)</span><br><span class="line">		clust_id -= <span class="number">1</span></span><br><span class="line">	<span class="keyword">return</span> clusters[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>上面的代码重复
<code>合并两个最邻近cluster为新cluster-&gt;调整新cluster的位置</code>的操作，直到只剩下一个cluster并将该cluster返回。</p>
<h3 id="kmeans-聚类">KMeans 聚类</h3>
<p>KMeans 聚类的思想是一开始就确认了最终需要聚类成 k 个
clusters，然后在训练数据的范围内随机选择 k 个初始点作为初始 k 个 cluster
的中心，并将每个实例聚类到离其最近的一个cluster，所有的点都分到离其最近的cluster后，根据各个cluster中的点重新调整这个cluster的中心。重复这个过程直到每个cluster中的点不变为止。如下图为KMeans的过程</p>
<figure>
<img src="https://wulc.me/imgs/image_1b92sg3ts1epk1v1g1tkd2j5m9rp.png"
alt="KMeans聚类过程" />
<figcaption aria-hidden="true">KMeans聚类过程</figcaption>
</figure>
<p>这里度量距离的方式仍采用皮尔逊系数，下面是实现以上功能的代码：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">kMeans</span>(<span class="params">blog_data, distance = pearson, k = <span class="number">5</span></span>):</span><br><span class="line">	m, n = <span class="built_in">len</span>(blog_data), <span class="built_in">len</span>(blog_data[<span class="number">0</span>])</span><br><span class="line">	max_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)]</span><br><span class="line">	min_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)]</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(m):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> xrange(n):</span><br><span class="line">			max_value[j] = <span class="built_in">max</span>(max_value[j], blog_data[i][j])</span><br><span class="line">			min_value[j] = <span class="built_in">min</span>(min_value[j], blog_data[i][j])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initial random clusters</span></span><br><span class="line">	clusters = []</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(k):</span><br><span class="line">		clusters.append([min_value[j] + random.random()*(max_value[j] - min_value[j]) <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n)])</span><br><span class="line"></span><br><span class="line">	count = <span class="number">0</span></span><br><span class="line">	previous_cluster_nodes = <span class="literal">None</span></span><br><span class="line">	<span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">		count += <span class="number">1</span></span><br><span class="line">		<span class="built_in">print</span> <span class="string">&#x27;iteration count %s&#x27;</span>%count</span><br><span class="line">		curr_cluster_nodes = [[] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(k)]</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> xrange(m):</span><br><span class="line">			closest_distance = distance(blog_data[i], clusters[<span class="number">0</span>])</span><br><span class="line">			cluster = <span class="number">0</span></span><br><span class="line">			<span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">1</span>, k):</span><br><span class="line">				d = distance(blog_data[i], clusters[j])</span><br><span class="line">				<span class="keyword">if</span> closest_distance &gt; d:</span><br><span class="line">					closest_distance = d</span><br><span class="line">					cluster = j</span><br><span class="line">			curr_cluster_nodes[cluster].append(i)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> curr_cluster_nodes == previous_cluster_nodes:</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">		previous_cluster_nodes = curr_cluster_nodes</span><br><span class="line">		<span class="comment"># modify the core of each cluster</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> xrange(k):</span><br><span class="line">			tmp = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> xrange(n)]</span><br><span class="line">			<span class="keyword">for</span> node <span class="keyword">in</span> curr_cluster_nodes[i]:</span><br><span class="line">				<span class="keyword">for</span> j <span class="keyword">in</span> xrange(n):</span><br><span class="line">					tmp[j] += blog_data[node][j] </span><br><span class="line">			clusters[i] = [<span class="built_in">float</span>(tmp[j])/<span class="built_in">len</span>(curr_cluster_nodes) <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n)]</span><br><span class="line">	<span class="keyword">return</span> clusters, curr_cluster_nodes</span><br></pre></td></tr></table></figure>
<p>上面的代码最终返回k个cluster的中心点的值，以及各个cluster中所包含的点（实例）。需要注意的是由于每次选择的初始点是随机的，因此每次运行所获得的结果不一定相同。</p>
<h2 id="可视化">可视化</h2>
<p>下面介绍如何将上面两种聚类算法得到的结果进行可视化，可视化通过python中的
python image library(PIL) 实现。</p>
<h3 id="逐层聚类结果可视化">逐层聚类结果可视化</h3>
<p>从上面的算法描述可知，逐层距离每次将两个cluster聚合在一起，从构造过程来看，实际上最终是构造了一颗二叉树，因此这里会以二叉树的形式将聚类的结果可视化。由于二叉树叶子节点过多，为了便于展示，将二叉树横着放，如下图就是二叉树的放置方式</p>
<figure>
<img src="https://wulc.me/imgs/image_1b8uejmpl1iikcki1nj510ds1aj4m.png"
alt="逐层聚类树状图" />
<figcaption aria-hidden="true">逐层聚类树状图</figcaption>
</figure>
<p><strong>要将这课二叉树可视化，首先需要知道这这棵树以上图放置时的高度和宽度(深度)，然后根据图片的大小进行相应的缩放。</strong></p>
<p>回想上面在逐层聚类中定义的下面的类表示一个cluster <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">hcluster</span>:</span><br><span class="line">	<span class="string">&quot;&quot;&quot;describe a cluster as a node in a tree&quot;&quot;&quot;</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">id</span>, vector, distance=<span class="number">0</span>, left = <span class="literal">None</span>, right = <span class="literal">None</span></span>):</span><br><span class="line">		self.<span class="built_in">id</span> = <span class="built_in">id</span></span><br><span class="line">		self.vector = vector</span><br><span class="line">		self.distance = distance</span><br><span class="line">		self.left = left</span><br><span class="line">		self.right = right</span><br></pre></td></tr></table></figure></p>
<p>通过 <code>self.left</code> 和 <code>self.right</code>
属性可以访问当前cluster的两个子cluster，而 <code>self.distance</code>
则表示两个子cluster的距离的大小，该属性在图中表现为当前cluster到两个子cluster的线段的长短，假如<code>self.distance</code>的值越大，那么这个cluster到两个子cluster的线段也越长。因此可以通过distance的值来获取二叉树的最长深度来作为图片的宽度。获取二叉树深度代码如下所示</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_depth</span>(<span class="params">cluster</span>):</span><br><span class="line">    <span class="comment"># The distance of an endpoint is 0.0</span></span><br><span class="line">    <span class="keyword">if</span> cluster.left==<span class="literal">None</span> <span class="keyword">and</span> cluster.right==<span class="literal">None</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(get_depth(cluster.left),get_depth(cluster.right))+cluster.distance</span><br></pre></td></tr></table></figure>
<p>通过递归的方式将两棵字数中最长的深度加上当前节点到两棵子树的长度，便是以当前节点为根节点的树的深度。</p>
<p>同样地，树的高度也可以通过递归方式获取，由上面的二叉树的放置方法可知，整棵树的高度就是其两棵子树的高度之和。下面便是获取高度的代码</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_height</span>(<span class="params">cluster</span>):</span><br><span class="line">    <span class="keyword">if</span> cluster.left==<span class="literal">None</span> <span class="keyword">and</span> cluster.right==<span class="literal">None</span>:  <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> get_height(cluster.left)+get_height(cluster.right)</span><br></pre></td></tr></table></figure>
<p>整个二叉树中有两种节点：一种是叶子节点，表示一个单一实例，另外的非叶子结点的表示有多个叶子节点组成的cluster。对于叶子节点，只需要在图片上显示其内容即可，而对于非叶子节点则需要画出其两棵子树的分支，通过
<code>self.id</code>
属性可以区分节点是否为叶子节点。下面便是具体的实现代码,（注意这里需要用到PIL了，关于PIL的具体用法可参考<a
href="http://effbot.org/imagingbook/pil-index.htm">这里</a>）</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image,ImageDraw</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_node</span>(<span class="params">draw,cluster,x,y,scaling,blog_names</span>):</span><br><span class="line">    <span class="keyword">if</span> cluster.<span class="built_in">id</span> &lt; <span class="number">0</span>:</span><br><span class="line">        h1=get_height(cluster.left)*<span class="number">20</span></span><br><span class="line">        h2=get_height(cluster.right)*<span class="number">20</span></span><br><span class="line">        top=y-(h1+h2)/<span class="number">2</span></span><br><span class="line">        bottom=y+(h1+h2)/<span class="number">2</span></span><br><span class="line">        <span class="comment"># Line length</span></span><br><span class="line">        ll=cluster.distance*scaling</span><br><span class="line">        <span class="comment"># Vertical line from this cluster to children    </span></span><br><span class="line">        draw.line((x,top+h1/<span class="number">2</span>,x,bottom-h2/<span class="number">2</span>),fill=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))    </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Horizontal line to left item</span></span><br><span class="line">        draw.line((x,top+h1/<span class="number">2</span>,x+ll,top+h1/<span class="number">2</span>),fill=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))    </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Horizontal line to right item</span></span><br><span class="line">        draw.line((x,bottom-h2/<span class="number">2</span>,x+ll,bottom-h2/<span class="number">2</span>),fill=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Call the function to draw the left and right nodes    </span></span><br><span class="line">        draw_node(draw,cluster.left,x+ll,top+h1/<span class="number">2</span>,scaling,blog_names)</span><br><span class="line">        draw_node(draw,cluster.right,x+ll,bottom-h2/<span class="number">2</span>,scaling,blog_names)</span><br><span class="line">    <span class="keyword">else</span>:   </span><br><span class="line">        <span class="comment"># If this is an endpoint, draw the item label</span></span><br><span class="line">        draw.text((x+<span class="number">5</span>,y-<span class="number">7</span>),blog_names[cluster.<span class="built_in">id</span>],(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>上面的 <code>scaling</code>
参数是根据树的深度和图片的宽度的比例得到的缩放因子，在开始画图前需要通过树的深度和图片预定义的宽度获取。下面的代码便是在作图前的需要准备的参数以及调用上面定义好的函数进行作图的过程。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">draw_cluster</span>(<span class="params">cluster, blog_names, jpeg_path</span>):</span><br><span class="line">    <span class="comment"># height and width</span></span><br><span class="line">    h=get_height(cluster)*<span class="number">20</span></span><br><span class="line">    w=<span class="number">1200</span></span><br><span class="line">    depth=get_depth(cluster)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># width is fixed, so scale distances accordingly</span></span><br><span class="line">    scaling=<span class="built_in">float</span>(w-<span class="number">150</span>)/depth</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a new image with a white background</span></span><br><span class="line">    img=Image.new(<span class="string">&#x27;RGB&#x27;</span>,(w,h),(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br><span class="line">    draw=ImageDraw.Draw(img)</span><br><span class="line"></span><br><span class="line">    draw.line((<span class="number">0</span>,h/<span class="number">2</span>,<span class="number">10</span>,h/<span class="number">2</span>),fill=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># Draw the first node</span></span><br><span class="line">    draw_node(draw,cluster,<span class="number">10</span>,h/<span class="number">2</span>,scaling,blog_names)</span><br><span class="line">    img.save(jpeg_path,<span class="string">&#x27;JPEG&#x27;</span>)</span><br></pre></td></tr></table></figure> 上面完整的代码可从<a
href="https://github.com/WuLC/MachineLearningAlgorithm/blob/master/python/Clustering/HierarchicalClustering.py">这里</a>获取</p>
<p>作图的结果如下所示：</p>
<figure>
<img src="https://wulc.me/imgs/clusters.jpg" alt="逐层层聚类的可视化" />
<figcaption aria-hidden="true">逐层层聚类的可视化</figcaption>
</figure>
<h3 id="kmeans聚类结果可视化">KMeans聚类结果可视化</h3>
<p>原书并没有给出KMeans聚类结果的可视化操作，只是提供了一种<a
href="https://en.wikipedia.org/wiki/Multidimensional_scaling">多维缩放(Multidimensional
scaling, MDS)</a>的技术,
用于将高维的数据转换为二维，同时保留数据间的距离关系，这样便可通过图片对其进行可视化。实际上，
MDS 与 PCA 都是一种基于线性变换而进行降维的方法。</p>
<p>MDS的思想是通过点的原始距离矩阵 <span
class="math inline">\(D\)</span>,
计算出变换到新的维度空间中的点的距离矩阵 <span
class="math inline">\(B\)</span>, 然后对 <span
class="math inline">\(B\)</span> 做特征值分解，选取前 <span
class="math inline">\(n\)</span> 个特征值(<span
class="math inline">\(n\)</span>
为所变换到的维度空间的维度值)及其对应的特征向量矩阵，便可得到新的维度空间中各点的坐标。具体的推导过程可以参考周志华的<a
href="https://book.douban.com/subject/26708119/">机器学习</a>中第十章的内容或<a
href="http://blog.csdn.net/Dark_Scope/article/details/53229427#t2">这篇博客</a>，这里不详细展开论述了。</p>
<p>但是该书给出的方案并不是上面讲述的方法，而是先在二维空间中随机初始化
<span class="math inline">\(m\)</span>
个点作为m个实例的初始点，然后根据其在二维空间的距离与高维空间中实际的距离的误差来调整点的位置，是一种迭代的方法。其具体实现如下所示：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scale_dowm</span>(<span class="params">blog_data,distance=pearson,rate=<span class="number">0.01</span></span>):</span><br><span class="line">    n=<span class="built_in">len</span>(blog_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The real distances between every pair of items</span></span><br><span class="line">    real_list=[[distance(blog_data[i],blog_data[j]) <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n)] </span><br><span class="line">             <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Randomly initialize the starting points of the locations in 2D</span></span><br><span class="line">    loc=[[random.random(), random.random()] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)]</span><br><span class="line">    fake_list=[[<span class="number">0.0</span> <span class="keyword">for</span> j <span class="keyword">in</span> xrange(n)] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(n)]</span><br><span class="line"></span><br><span class="line">    lasterror=<span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">1000</span>):</span><br><span class="line">        <span class="comment"># Find projected distances</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">          <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            fake_list[i][j]=sqrt(<span class="built_in">sum</span>([<span class="built_in">pow</span>(loc[i][x]-loc[j][x],<span class="number">2</span>) </span><br><span class="line">                                     <span class="keyword">for</span> x <span class="keyword">in</span> xrange(<span class="built_in">len</span>(loc[i]))]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Move points</span></span><br><span class="line">        grad=[[<span class="number">0.0</span>,<span class="number">0.0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"></span><br><span class="line">        totalerror=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">          <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> j==k <span class="keyword">or</span> real_list[j][k] == <span class="number">0</span>: <span class="keyword">continue</span>  <span class="comment"># acoid the case when real_list[j][k] == 0.0</span></span><br><span class="line">            <span class="comment"># The error is percent difference between the distances</span></span><br><span class="line">            error_term=(fake_list[j][k]-real_list[j][k])/real_list[j][k]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Each point needs to be moved away from or towards the other</span></span><br><span class="line">            <span class="comment"># point in proportion to how much error it has</span></span><br><span class="line">            grad[k][<span class="number">0</span>] += ((loc[k][<span class="number">0</span>]-loc[j][<span class="number">0</span>])/fake_list[j][k])*error_term</span><br><span class="line">            grad[k][<span class="number">14</span>] += ((loc[k][<span class="number">15</span>]-loc[j][<span class="number">16</span>])/fake_list[j][k])*error_term</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Keep track of the total error</span></span><br><span class="line">            totalerror+=<span class="built_in">abs</span>(error_term)</span><br><span class="line">        <span class="comment"># print &#x27;curr error &#123;0&#125;&#x27;.format(totalerror)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># If the answer got worse by moving the points, we are done</span></span><br><span class="line">        <span class="keyword">if</span> lasterror <span class="keyword">and</span> lasterror&lt;totalerror: <span class="keyword">break</span></span><br><span class="line">        lasterror=totalerror</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Move each of the points by the learning rate times the gradient</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">          loc[k][<span class="number">0</span>] -= rate*grad[k][<span class="number">0</span>]</span><br><span class="line">          loc[k][<span class="number">17</span>] -= rate*grad[k][<span class="number">18</span>]</span><br><span class="line">    <span class="keyword">return</span> loc</span><br></pre></td></tr></table></figure>
<p>上面的<code>scale_dowm</code>函数传入原始的博客数据
<code>blog_data</code>,然后进行迭代计算，最终返回这些数据在二维空间中对应的向量。每次的迭代时，根据每个点与其他各个点的距离误差调整该点的距离，并且计算出一个总体误差，当本次调整后的误差比上一次要大或者迭代次数达到最大，就跳出循环。</p>
<p>上面返回了各个高纬向量在二维空间中的坐标，因此通过PIL
可以很自然地作出图。原书讲到这里就结束了，但是结合我们KMeans聚类的结果可知，每个聚类中心的向量长度与博客数据的长度一样，因此可以将KMeans聚类得到的聚类中心一并传入到<code>scale_dowm</code>函数中，然后得到聚类中心在二维空间中的坐标，然后以其为中心，连线到其聚类中的各个点。</p>
<p>作图的实现的代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">draw_clusters</span>(<span class="params">blog_data, clusters, cluster_nodes, blog_names, jpeg_path = <span class="string">&#x27;Clustering_data/mds2d.jpg&#x27;</span></span>):</span><br><span class="line">    img=Image.new(<span class="string">&#x27;RGB&#x27;</span>,(<span class="number">2000</span>,<span class="number">2000</span>),(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br><span class="line">    draw=ImageDraw.Draw(img)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="built_in">len</span>(clusters)):</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> cluster_nodes[i]:</span><br><span class="line">            c_x,c_y = (clusters[i][<span class="number">0</span>] + <span class="number">0.5</span>)*<span class="number">1000</span>, (clusters[i][<span class="number">19</span>] + <span class="number">0.5</span>)*<span class="number">1000</span></span><br><span class="line">            x, y =(blog_data[node][<span class="number">0</span>]+<span class="number">0.5</span>)*<span class="number">1000</span>, (blog_data[node][<span class="number">20</span>]+<span class="number">0.5</span>)*<span class="number">1000</span></span><br><span class="line">            draw.line((c_x, c_y, x, y),fill=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br><span class="line">            draw.text((x,y),blog_names[node],(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>))   </span><br><span class="line">    img.save(jpeg_path ,<span class="string">&#x27;JPEG&#x27;</span>) </span><br></pre></td></tr></table></figure></p>
<p>完整的代码可参见 <a
href="https://github.com/WuLC/MachineLearningAlgorithm/blob/master/python/Clustering/KMeansClustering.py">这里</a></p>
<p>当类别数为3时，上面可视化得到的结果为：</p>
<figure>
<img src="https://wulc.me/imgs/mds2d.jpg" alt="KMeans可视化结果" />
<figcaption aria-hidden="true">KMeans可视化结果</figcaption>
</figure>
<p>除了博客数据，原书还用了 Zebo
网站上的数据进行了聚类，但是采用的聚类算法仍是我们上面提到的两个聚类算法。只是采用度量距离的标准不同，上面博客数据采用的是皮尔逊系数，而从Zebo
网站上获取的数据的值仅仅是0和1，不宜采用皮尔逊系数，而是采用了 <a
href="https://docs.tibco.com/pub/spotfire/6.5.3/doc/html/hc/hc_tanimoto_coefficient.htm">Tanimoto
coefficient</a>, 该系数用于表示两者的重合程度。对于两个长度为 <span
class="math inline">\(m\)</span> ,值为0或1的向量 <span
class="math inline">\(A,B\)</span>，其Tanimoto
coefficient计算公式如下：</p>
<p><span
class="math display">\[\frac{\sum\_{i=1}^{m}a\_ib\_i}{\sum\_{i=1}^{m}(a\_i
+ b\_i + a\_ib\_i)}\]</span></p>
<p>计算出来的值得范围为 [ 0.0, 1.0 ],
且值越大，表示两者相似性越强。下面是求解Tanimoto coefficient
的代码，注意为了用 Tanimoto coefficient 表示距离，最后返回的是 1 -
Tanimoto coefficient，表示距离值越小，两者越相似。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tanamoto</span>(<span class="params">v1,v2</span>):</span><br><span class="line">        c1,c2,shr=<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(v1)):</span><br><span class="line">        <span class="keyword">if</span> v1[i]!=<span class="number">0</span>: c1+=<span class="number">1</span> <span class="comment"># in v1</span></span><br><span class="line">        <span class="keyword">if</span> v2[i]!=<span class="number">0</span>: c2+=<span class="number">1</span> <span class="comment"># in v2</span></span><br><span class="line">        <span class="keyword">if</span> v1[i]!=<span class="number">0</span> <span class="keyword">and</span> v2[i]!=<span class="number">0</span>: shr+=<span class="number">1</span> <span class="comment"># in both</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>-(<span class="built_in">float</span>(shr)/(c1+c2-shr))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>集体智慧编程</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>集体智慧编程</tag>
      </tags>
  </entry>
  <entry>
    <title>《Python简明教程》学习笔记</title>
    <url>/2015/11/19/%E3%80%8APython%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>《python简明教程》python入门的一个非常好的文档。如需下载，请<a
href="http://pan.baidu.com/s/1jHh2qLg">点击这里</a>(密码：grjj)。最近又看了一遍，把里面一些容易忽略的知识点记录下来。</p>
<span id="more"></span>
<h2 id="运算符">运算符</h2>
<ul>
<li><code>**</code> 乘方，2**3=8</li>
<li><code>//</code> 取商的整数部分, 10//3=3</li>
<li><code>&amp;</code> 按位与, 5&amp;3=1</li>
<li><code>|</code> 按位或，5|3=7</li>
<li><code>^</code> 按位异或，5^3=6</li>
<li><strong><code>~</code>
按位取反，~5=-6，取反后数的正负反转，且正数要比负数绝对值小1</strong></li>
<li><code>and、or、not</code>就是Java里面的<code>&amp;&amp;、||、！</code>，但是在python里面<code>&amp;&amp;、||、！</code>是非法字符</li>
</ul>
<h2 id="数据结构">数据结构</h2>
<ul>
<li>python里面常用的数据结构有列表（list）、元组（tuple）、字典（dic)和集合(set)</li>
</ul>
<ol type="1">
<li><strong>list</strong>,用方括号<code>[]</code>括起来,里面元素用逗号分隔，元素有序可变
<ul>
<li>增加元素用<code>append()</code>方法，删除元素用<code>del</code>方法</li>
</ul></li>
<li><strong>tuple</strong>，用圆括号<code>()</code>括起来,里面元素用逗号分隔，元素有序不可变
<ul>
<li>仅有一个元素时也要加<code>,</code>，避免与运算符优先级混淆</li>
<li>常用于打印语句，如<code>print "name:%s,age: %d" %(name,age)</code></li>
</ul></li>
<li><strong>dic</strong>，用花括号<code>&#123;&#125;</code>括起来,里面元素用逗号分隔，元素无序可变，每个元素是用冒号<code>:</code>分隔的键值对
<ul>
<li>通过<code>dic[k]</code>访问元素，<code>dic[newK]=newV</code>
增加元素,<code>del dic[k]</code> 删除元素</li>
<li>遍历的方法为
<code>for k,v in  dic.items():</code>,实际上<code>dic.items()</code>会返回一个元组的列表</li>
<li>判断某一个k是否在dic <code>if k in dic:</code></li>
</ul></li>
<li><strong>序列</strong>，序列不是一种具体的数据结构，而是一类数据结构，<strong>字符串，列表和元组</strong>均属于序列，序列有一些通用的方法
<ul>
<li>通过<code>len()</code>获取序列的长度</li>
<li>表示序列的范围：<code>[a:b]</code>表示下表a到b-1，<code>[a:]</code>表示从下标a到最后一个,<code>[:b]</code>表示从第一个(也就是0)到下标b-1,<code>[:]</code>表示所有元素,默认步长为1，也可以添加多一个参数变为<code>[a:b:c]</code>,这时步长为c，与range()函数相似</li>
<li>对于一个序列，复制这个序列与给这个序列使用一个别名不同，详见下面代码</li>
</ul></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">list1=[1,2,3]</span><br><span class="line">list2=list1     #别名</span><br><span class="line">list3=list1[:]  #复制</span><br><span class="line">del list1[1]</span><br><span class="line">print list2</span><br><span class="line">print list3</span><br><span class="line">         </span><br></pre></td></tr></table></figure>
<h2 id="控制语句">控制语句</h2>
<ul>
<li>python的控制语句有if，while，for，continue，break，但是没有switch</li>
<li>if、while判断条件的判断条件均没有括号</li>
<li>while、for语句均有一个 <strong>可选的</strong>
else语句，while语句条件不成立时退出while并执行else语句；for语句中的else语句则在for循环后执行一次；但是如果在while和for循环里面遇到break退出程序，则不会执行else语句</li>
<li><code>for i in k:</code>语句里，k可以是任何序列，包括字符串、列表、元组、字典等</li>
<li>for里面常用的range函数的范围不包括第二个参数，默认步长为1，可通过第三个参数选择步长</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">range(1,5) --&gt; 1,2,3,4</span><br><span class="line">range(1,5,2)--&gt;1,3</span><br></pre></td></tr></table></figure>
<h2 id="函数">函数</h2>
<ul>
<li>函数没有return语句时默认返回一个None（没有任何东西的特殊类）</li>
<li>pass语句表示一个空的语法句</li>
<li>文档字符串：用来描述<strong>函数或者类</strong>的功能，一般格式：首行以大写字母开始，句号结尾。第二行是空行，从第三行开始是详细的描述</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def printMax(x, y):</span><br><span class="line">&#x27;&#x27;&#x27;Prints the maximum of two numbers.</span><br><span class="line">    </span><br><span class="line">The two values must be integers.&#x27;&#x27;&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>文档字符串也可以通过函数或类的<code>__doc__</code>属性获取</p>
<ul>
<li>一些常见的函数
<ul>
<li><code>range()</code>，一般用于for循环</li>
<li><code>dir(module)</code>,返回module的名称列表，不提供module值时默认是当前module</li>
<li><code>len(arr)</code>,用于获取序列arr的长度，arr可以是list、tuple、dic或者是string</li>
<li><code>os.system(command)</code>，执行系统命令<code>command</code></li>
<li><code>time.strftime()</code>，按指定格式输出当前系统时间,如<code>time.strftime("%Y-%m-%d %H:%M:%S")</code></li>
<li><code>time.sleep(t)</code>,一般用于循环，让系统休眠t秒</li>
<li><code>string.startswith(str)</code>,字符串对象的方法，判断字符串string是否以
str开头</li>
<li><code>string.find(str)</code>,字符串对象的方法，判断
str是否在字符串string里面</li>
<li><code>string.join(list)</code>,字符串对象的方法，用字符串 string
连接list列表</li>
</ul></li>
</ul>
<h2 id="模块">模块</h2>
<ul>
<li>可以导入的模块有两种：（1）标准模块,常见的有os、sys（2）自定义模块，就是.py结尾的python文件</li>
<li><code>import</code>操作会在<code>sys.path</code>列出的目录列表里面查找需要import的模块</li>
<li>为了使导入模块的操作更快，会在第一次导入模块时创建模块的pyc文件（字节编译文件）</li>
<li>每个模块都有一个<code>__name__</code>,当模块被直接执行时，该值为__main__</li>
</ul>
<h2 id="类">类</h2>
<ul>
<li>语法 <code>class 类名:</code></li>
<li>类方法与普通函数形式上最大区别在于类方法的第一个形参必须为<code>self</code>,且该形参不需要实参，<code>self</code>类似于Java中的<code>this</code>指针</li>
<li><code>__init__</code>为构造函数，<code>__del__</code>为析构函数</li>
<li>所有的类成员都是公开的，而以双下划线开头的成员是属于类的，是私有的，作为惯例，一般属于类的成员都以单下划线开头</li>
<li>继承,语法
<code>class son(father):</code>,注意<strong>子类不会自动调用父类的构造函数，因此必须显示调用</strong>，但是不调用时也没有报错。</li>
</ul>
<h2 id="异常捕获">异常捕获</h2>
<ul>
<li>语法</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">try：</span><br><span class="line">    可能抛出异常的方法</span><br><span class="line">except (错误或异常的元组)： #没有指定异常时捕获所有的错误异常</span><br><span class="line">    处理</span><br><span class="line">finally：</span><br><span class="line">    无论是否有异常均要执行</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="其他一些用法">其他一些用法</h2>
<ul>
<li><p>python 程序第一行的 <code>#！</code>
目的是确定使用哪个解释器，一般在Linux平台下写的是
<code>#!/usr/bin/env python</code>
而不是直接写python解析器的位置，目的是即使程序在其他机子上跑时也能够找得到python解析器；而且程序迁移到windows下也不会报错问题，但是
<code>#!/usr/bin/env python</code>
并不适用于Windows默认的cmd窗口，假如直接在dos/powershell下输入python的文件名，是会用文件关联的程序打开（关联程序可以通过右键设置打开方式来设定）。也可在Windows下安装一个<code>git shell</code>，在<code>git shell</code>
下输入python的文件名即可执行。</p></li>
<li><p>可以通过内置的help( )函数来找到函数和类的帮助信息，实际上help(
)是通过抽取文档字符串（DocStrings，也就是函数和类的<code>__doc__</code>属性）并打印输出的</p></li>
<li><p>字符串或者程序在一行放不下时通过反斜杠\可以在下一行继续写,</p></li>
<li><p>字符串前加上<code>u</code>或者<code>U</code>表示采用Unicode编码,字符串的连接可以使用加号+</p></li>
<li><p>print语句的一些技巧：在for循环的print最后加逗号可以避免分行；print
str*i可以重复输出i个str</p></li>
<li><p>强制类型转换一般形式是被转换的内容用圆括号括起来，类型不用扩。如<code>str(5)</code>
是从整数转为字符串 ，<code>int(raw_input('input an integer'))</code>
是从字符串转为整形</p></li>
<li><p>列表综合：从一个已有的列表导出一个新的列表。实例如下：</p></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">list1=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">list2=[i*<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> list1 <span class="keyword">if</span> i&gt;<span class="number">2</span>] <span class="comment">#list2=[6,8,10]</span></span><br></pre></td></tr></table></figure>
<p>也可从一个列表导出一个字典(dict只能接受一个参数，这里为一个列表)
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">l1=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">timesten=<span class="built_in">dict</span>([(v,v*<span class="number">10</span>) <span class="keyword">for</span> v <span class="keyword">in</span> l1 <span class="keyword">if</span> i &gt;<span class="number">1</span>])<span class="comment">#timesten=&#123;2:20,3:30&#125;</span></span><br></pre></td></tr></table></figure> -
函数形参为元组和字典：可用*和**加在形参前，代表这是元组和字典，但是不加也能够正常使用。加上的目的是为了能让函数接受不定参数,例子如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">x, *args</span>):</span><br><span class="line">    total = x</span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> args:</span><br><span class="line">        total += arg</span><br><span class="line">    <span class="keyword">return</span> total</span><br></pre></td></tr></table></figure>
<p>这里的 <code>*args</code>
表示参数数目不定，可以看成一个元组，把第一个参数后面的参数当作元组中的元素。运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;print add(1, 2, 3, 4)</span><br><span class="line">10</span><br><span class="line">&gt;&gt;&gt;print add(1, 2)</span><br><span class="line">3</span><br></pre></td></tr></table></figure>
<p>这样定义的函数不能使用关键词传入参数，要使用关键词，可以这样：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">x, **kwargs</span>):</span><br><span class="line">    total = x</span><br><span class="line">    <span class="keyword">for</span> arg, value <span class="keyword">in</span> kwargs.items():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;adding &quot;</span>, arg</span><br><span class="line">        total += value</span><br><span class="line">    <span class="keyword">return</span> total</span><br></pre></td></tr></table></figure>
<p>这里的 <code>**kwargs</code>
表示参数数目不定，相当于一个字典，关键词和值对应于键值对。运行如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;print add(10, y=11, z=12, w=13)</span><br><span class="line">adding  y</span><br><span class="line">adding  z</span><br><span class="line">adding  w</span><br><span class="line">46</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
        <category>语法</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>《Real-time Personalization using Embeddings for Search Ranking at Airbnb》 阅读笔记</title>
    <url>/2020/06/20/%E3%80%8AReal-time%20Personalization%20using%20Embeddings%20for%20Search%20Ranking%20at%20Airbnb%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a
href="https://dl.acm.org/doi/pdf/10.1145/3219819.3219885">Real-time
Personalization using Embeddings for Search Ranking at Airbnb</a> 是 KDD
2018 的 best paper, 整篇文章读下来，初看好像只是套了 word2vec 来生成
user embedding 和 item
embedding；但是细读下来，会发现其中有不少细节值得考究，这种风格跟
youtube 在 2016 年发表的那篇 <a
href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf">Deep
Neural Networks for YouTube Recommendations</a>
很像，两篇都是实践性很强的 paper，非常值得看。而且两篇文章分别代表着
deep learning 中生成 embedding
的两大流派：无监督和有监督。本文主要讲的是 Airbnb 的这篇 paper
的基本做法和一些细节。</p>
<span id="more"></span>
<p>Airbnb 的这项工作的业务背景是：用户在其租房 app
上搜索时，需要返回一个 list 的推荐结果,在 paper 中提到了 Airbnb
用的是业界比较主流的 Learning To Rank 技术，关于 LTR
的技术细节可参考微软的 <a
href="https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf">From
RankNet to LambdaRank to LambdaMART: An Overview</a>，Airbnb 用的也是
pairwise 模式下的 LambdaRank，而这篇 paper 主要描述的是如何通过 word2vec
的方式生成 user embedding 和 item embedding 作为 feature
供排序模型使用（文章中也将 item 称为
listing，所以后文中这两个词的含义是一样的）。</p>
<p>这篇文章的主要亮点如下</p>
<p><strong>1. 将正反馈（用户最终下单，作为 global
context）和负反馈（商家拒接接单，作为额外的一个data set）的信号加入到
skip-gram 中进行训练</strong> <strong>2. 做 negative sampling
时，考虑到具体业务不仅仅在全集上做负采样</strong> <strong>3. 同一个 uid
的样本较为稀疏，因此 user embedding 从 uid 粒度变为 user type
粒度，避免样本过于稀疏 embedding 学习不充分</strong></p>
<p>这 3
点其实都是作者在考虑到具体业务场景下，所做出的改进，也是笔者认为这篇paper最值得学习的地方：<strong>不要盲目地套算法，而是要充分考虑到当前具体业务然后做出相应的适配和改进</strong></p>
<h2 id="离线训练">离线训练</h2>
<p>paper 中的离线训练可分为两大部分：short-term interest 和 long-term
interest</p>
<p>对于短期(short-term)兴趣, <strong>利用了 800 billion 个 click session
来训练了 listing embedding</strong></p>
<p>对于长期(long-term)兴趣，<strong>利用了 50 million 个用户的 booked
listings 来训练 user type embedding 和 listing type
embedding</strong></p>
<p>具体的训练方法基本就是 word2vec 中的
skip-gram，下面会分别描述这两部分的具体训练细节</p>
<h3 id="listing-embedding">listing embedding</h3>
<p>在 short-term insterest 中只生成 item embedding，训练的样本就是 click
session（类比 nlp 中的一个 sentence），在 paper
中共的定义就是用户一系列的点击事件；在构建这个训练数据集时，核心就是<strong>如何定义session
的长度</strong>，在paper中定义<strong>当用户的两次点击超过 30
分钟时，那这两次点击应该属于两个 session</strong>。</p>
<p>假设总体训练集为 <span class="math inline">\(S\)</span>, 每个 session
为 <span class="math inline">\(s=(l\_1,l\_2...l\_M) \in S\)</span>,
则通过 word2vec 中的 skip-gram 可写出 loss 如下</p>
<p><span class="math display">\[L=\sum\_{s \in S}\sum\_{l\_i \in
s}(\sum\_{-m \le j \le m,j \ne 0}^M \log
p(l\_{i+j}|l\_i))\tag{1}\]</span></p>
<p>上面的 m 是个超参，表示 skip-gram
训练时窗口的大小，且上式的概率可通过 embedding 向量和 softmax
表示成如下形式</p>
<p><span class="math display">\[p(l\_{i+j}|l\_i) =
\frac{\exp(v\_{l\_j}^T
v\_{l\_{i+j}}^{&#39;})}{\sum\_{l=1}^{|V|}\exp(v\_{l\_i}^Tv\_{l}^{&#39;})}\tag{2}\]</span></p>
<p>上式中的 <span class="math inline">\(|V|\)</span> 是所有 item
的集合， <span class="math inline">\(v\)</span> 和 <span
class="math inline">\(v&#39;\)</span> 分表表示 input vector 和 output
vetor，其实就是同一个 item 在 skip gram
模型中两个参数矩阵的表示，即如下图所示的参数矩阵 W 和 W'；具体可参考讲义
<a
href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf">CS224n:
Natural Language Processing with Deep Learning</a></p>
<figure>
<img src="https://wulc.me/imgs/skip_gram_model.jpg" alt="skip gram" />
<figcaption aria-hidden="true">skip gram</figcaption>
</figure>
<p>类似 word2vec
由于这个集合一般很大，算一次公式（2）的概率时分母的累加的耗时会非常长，为了加速训练，word2vec
中提出了 <strong>negative sampling</strong>
的策略，简单来说，就是对于每个 session 内的每个 clicked item，从其窗口 m
内选择一些 positive pairs <span class="math inline">\((l,
c)\)</span>作为 positive set（记为<span
class="math inline">\(D\_p\)</span>）,同时从整个 item 集合 <span
class="math inline">\(|V|\)</span> 中随机选一些 negative pairs <span
class="math inline">\((l, c)\)</span>取一些 item 作为 negative
set(记为<span class="math inline">\(D\_n\)</span>), 不用 softmax 而是用
sigmoid 的方式将要求解的参数写成如下形式</p>
<p><span class="math display">\[ \arg\max\_{\theta} \sum\_{(l,c) \in
D\_p} \log\frac{1}{1+e^{-v\_{c}^{&#39;}v\_l}} + \sum\_{(l,c) \in D\_n}
\log\frac{1}{1+e^{v\_{c}^{&#39;}v\_l}} \tag{3}\]</span></p>
<p>上式中要求解的参数 <span class="math inline">\(\theta\)</span> 就是
每个 item 的 embedding <span
class="math inline">\(v\_l\)</span>，基本就是原始 word2vec 中的
skip-gram 算法了，下面文章中的几个点可以认为是作者根据业务对 word2vec
的一些改动，也是非常值得借鉴的</p>
<p><strong>(1)利用监督信号作为 global context</strong></p>
<p>在 airbnb 的业务中，上面的 session
实际上可分为两大类，分别是最终有下单的 session 和没有下单的
session，paper 中分别称其为 booked session 和 exploratory
sessions，这两个实际上都是监督信号，而在 paper
中<strong>只使用了第一个监督信号</strong>，则公式(3）可写成如下形式</p>
<p><span class="math display">\[ \arg\max\_{\theta} \sum\_{(l,c) \in
D\_p} \log\frac{1}{1+e^{-v\_{c}^{&#39;}v\_l}} + \sum\_{(l,c) \in D\_n}
\log\frac{1}{1+e^{v\_{c}^{&#39;}v\_l}} + \\\
\log \frac{1}{1+e^{-v\_{l\_b}v\_l}}\tag{4}\]</span></p>
<p>公式（4）中的 <span class="math inline">\(v\_{l\_b}\)</span>
表示的是被下单的 item <span class="math inline">\(l\_b\)</span> 的
embedding，下图则是更直观地显示了这个监督信号是如何起作用的,
可以看到，<strong>每个 centeral listing/item 更新时都会与 booked
listing/item 一起算一次概率，因此称这个 listing 为 global
context</strong>，其效果相当于加强用户在购买前点击的所有 item
和最终下单的 item 的联系</p>
<figure>
<img src="https://wulc.me/imgs/global_context.jpg"
alt="global context" />
<figcaption aria-hidden="true">global context</figcaption>
</figure>
<p><strong>(2)控制 negative sampling 的采样空间</strong></p>
<p>上面提到 negative sampling 会随机从全集中抽取 n 个 item
作为负例，但是在 airbnb 的业务中，一个用户往往只会在一个
market(也就是旅游地点) 中下单，而上面做 negative sampling
得到的结果往往是， <span class="math inline">\(D\_p\)</span>
里的候选都是同一个 market 的，<span class="math inline">\(D\_n\)</span>
里的候选往往都不是同一个 market 的，paper 称这样的 imbalanced
并不是最优的，笔者猜测原始是<strong>在做预估时候候选的 item
基本都是同一个 market 的，而这样 <span
class="math inline">\(D\_n\)</span> 的随机性使得同一个 market 内的正负
item 区分度并不高</strong>，因此，在原始的 nagative sampling
基础上增加了一项在同一 market 下随机选取负样本的 <span
class="math inline">\(D\_{m\_n}\)</span>, 因此，最终的 loss 形式如下</p>
<p><span class="math display">\[
\arg\max\_{\theta} \sum\_{(l,c) \in D\_p}
\log\frac{1}{1+e^{-v\_{c}^{&#39;}v\_l}} + \sum\_{(l,c) \in D\_p}
\log\frac{1}{1+e^{v\_{c}^{&#39;}v\_l}} + \\\
\log \frac{1}{1+e^{-v\_{l\_b}v\_l}}+\sum\_{(l,m\_n) \in D\_{m\_n}}
\log\frac{1}{1+e^{v\_{m\_n}^{&#39;}v\_l}}\tag{5}
\]</span></p>
<p><strong>(3)冷启动的 item embedding</strong></p>
<p>在推荐系统中，每天都会有很多新的 item 加入，还有一些 item 压根没有
click session，无法通过上面的 word2vec 训练出对应的
embedding；对于这些处于冷启动的item，paper
中用了一种比较常见且有效的手段来处理：<strong>根据冷启动的 item
的属性选取 k 个与其最相似且有 embedding 的 item 然后做 mean
pooling</strong>，选取的方法则是根据 item 的一些 meta-data，如
price，listing type 等</p>
<h3 id="user_typelisting_type-embeddings">user_type/listing_type
embeddings</h3>
<p>上面的训练方法中只用了 click session，且只生成了 listing
embedding，paper 中认为这个是 <strong>short-term
interest</strong>，其实这从上面对 session
的划分规则就体现了这一点，即两次点击间隔超过 30 min 就认为是两个不同的
session，在这种划分规则下，捕获的就是用户的短期兴趣，且一个 session
内所有的 item 基本上都是同一个 market 的了</p>
<p>为了<strong>（1）捕获用户更长周期的兴趣（2）捕获 cross-market 的
listing embedding 的关联</strong>，paper 中通过 skip-gram 训练出 user
embedding + listing embedding, 且相对于前面只训练出 listing embedding 的
short-term interest，paper 称这个为 long-term interest。</p>
<p>前面的训练数据是 <strong>800 billion 个 click
session</strong>，而这里捕获 long-term interest 的训练则 <strong>利用了
50 million 个用户的 booked listings</strong></p>
<p>假设总体训练集为 <span class="math inline">\(S\_b\)</span>, 每个
booked listing 为 <span
class="math inline">\(s\_b=(l\_{b1},l\_{b2}...l\_{bM}) \in S\)</span>,
表示<strong>某个用户的历史下单的所有 lisitng（按时间排序）</strong></p>
<p>比起上面较为丰富的 click
session，这个问题更为严峻，主要体现在下面几个方面</p>
<ol type="1">
<li>数据更为稀疏，前面的是点击事件，这里则是转化事件</li>
<li>某些用户的 booked listing 的长度可能只有 1，这样没法直接用 skip-gram
来训练</li>
<li>对于每个 entity, 如果需要较充分地学习出其 embedding，<strong>每个
entity 至少要出现 5-10 次</strong>，而实际上不少 listing
被下单的次数是没有 5 次的</li>
</ol>
<p>其中，问题 2 和 3 实际上都是问题 1 的具体表现，因此，paper
中解决上面的三个问题方法就是<strong>将 id 转为 type，本质上就是将 id
特征转为一个更泛化的特征</strong>，基本的装换方法就是根据 user/listing
的一些 meta 信息映射成一个 type，然后用这个 type 来代替 user/listing 的
id，映射表如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/id2type_mapping_rule.jpg"
alt="id2type" />
<figcaption aria-hidden="true">id2type</figcaption>
</figure>
<p>解决上面的数据稀疏问题后，还剩下的一个问题是<strong>如何通过 word2vec
训练出处于同一向量空间的 user_type embedding 和 listing_type
embedding</strong>？因为最原始的 word2vec 中的 sequence
往往都是同一属性的 item 的</p>
<p>paper 中解决这个问题的方法也和直接，就是将前面提到的每个 user
的booked listing <span
class="math inline">\(s\_b=(l\_{b1},l\_{b2}...l\_{bM}) \in S\)</span>
变为 <span
class="math inline">\(s\_b=(u\_{type1},l\_{type1}...u\_{typeM},
l\_{typeM}) \in S\)</span>, 值得注意的是，<strong>虽然每个 session 的
sequence 表示的是同一个user_id，但是其 user_type
是会随时间变化而变化的，但是 paper 中并没有提到改变 user_type
的时间窗口，猜测是一旦发生变化就改变，然后插入到上面的 booked listing
对应的时间位置上</strong>，（这里有个问题，这样做似乎是没法解决那些
booked listing 长度为 1 的数据）</p>
<figure>
<img src="https://wulc.me/imgs/user_type_list_type_skipgram.jpg"
alt="type-skipgram" />
<figcaption aria-hidden="true">type-skipgram</figcaption>
</figure>
<p>做了 negative sampling 后，loss 跟公式 3 是一样的, 如下是 central
item 是 user type 的情况（listing type 同理）</p>
<p><span class="math display">\[ \arg\max\_{\theta} \sum\_{(u\_t,c) \in
D\_{book}} \log\frac{1}{1+e^{-v\_{c}^{&#39;}v\_{u\_t}}} +
\sum\_{(u\_t,c) \in D\_{neg}}
\log\frac{1}{1+e^{v\_{c}^{&#39;}v\_{u\_t}}} \tag{6}\]</span></p>
<p><strong>相比于前面在训练 listing embedding 在做 negative sampling
对同一个 market 中的 item做额外的负采样，但是这里并没有做，原因是这里的
booked session 中对应的 item 已经是包含了不同 market
的，因此没必要做额外的处理</strong></p>
<p>此外，airbnb
的这个业务背景中也有商家的反馈数据，即可能会存在<strong>某些用户下单但是商家不接单的情况（可能的原因是用户信息不完整、评分低等）</strong>，这些负反馈信息对于
user_type embedding 的学习是有好处的，对于这些负反馈信号，airbnb
是按照如下方法加入到模型中的</p>
<p>对于每个 central item，训练的数据除了上面的做 negative sampling
得到的 <span class="math inline">\(D\_{book}\)</span> 和 <span
class="math inline">\(D\_{neg}\)</span>，还定义了一个 <span
class="math inline">\(D\_{rej}\)</span>, 其中包含了 user 历史上被拒绝的
pair <span class="math inline">\((u\_t, l\_t)\)</span>, 则当前的 central
item 是 user（listing 同理） 时， loss 可写成如下形式，</p>
<p><span class="math display">\[ \arg\max\_{\theta} \sum\_{(u\_t,c) \in
D\_{book}} \log\frac{1}{1+e^{-v\_{c}^{&#39;}v\_{u\_t}}} +
\sum\_{(u\_t,c) \in D\_{neg}}
\log\frac{1}{1+e^{v\_{c}^{&#39;}v\_{u\_t}}} + \\\
\sum\_{(u\_t,l\_t) \in D\_{neg}} \log\frac{1}{1+e^{v\_{l\_t}v\_{u\_t}}}
\tag{7}\]</span></p>
<p>则加入了这个监督信号后的 skip gram 则如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/reject_signal_skip_gram.jpg"
alt="reject skip-gram" />
<figcaption aria-hidden="true">reject skip-gram</figcaption>
</figure>
<h3 id="训练细节">训练细节</h3>
<p>上面讲的只是大致的训练过程，但是其中的一些训练细节也是非常重要的，尤其是这种有具体业务背景的工作,
paper 中只讲了训练 listing embedding 的一些细节</p>
<p>训练数据细节</p>
<ul>
<li>如前文所说，用了 800 million 的 click
session，划分的标准就是同一个用户的连续两次点击如果超过 30min
就划分为两个 session，</li>
<li><strong>去掉了一些无效点击（定义为点击后在页面停留时长小于 30s
的）</strong></li>
<li><strong>对于 booked session 做了 5 倍的 upsampling</strong></li>
</ul>
<p>训练细节</p>
<ul>
<li>天级更新，按照时间滑动窗口从当前时间往前取几个月的训练数据</li>
<li><strong>每天都重新训练 listing
embedding</strong>（随机初始化），而不是在之前训练好的基础上做
finetune，paper 称这样的效果比做 finetune 的要好</li>
<li>embedding 的维度是 32（做了效果和资源的 trade-off），skipgram
的时间窗口是 5，训练 10 个 iteration 的效果是最好的</li>
</ul>
<p><strong>值得注意的是，上面之所以每天能重新训练 listing embedding，
是因为 Airbnb 没有直接把 embedding 作为一个 feature 输入到模型中，而是将
embedding 计算出来的 similarity 作为 feature 输入模型；而如果需要把
user/listing embedding 作为 feature 落入样本中，重新训练 listing
embedding 应该是不行的</strong>， 原因分析如下</p>
<p>因为通过 embedding 计算出来的 user/item <strong>similarity 是由
user/item
在训练数据集中的相对位置决定了</strong>，这个信息在每天的训练数据中的变动其实是比较小的；但是每次重新训练
embedding 的时候是随机初始化的，这很容易导致同一个训练集两次训练出来的
embedding 所处的向量空间是不一样的，而如果将embedding 直接作为 feature
输入一个 nn 模型，容易导致同一个 user/item
在昨天和今天的向量差别很大，对于一个feature
来说这样来讲显然是不合理的</p>
<h3 id="embedding-有效性校验">embedding 有效性校验</h3>
<p>embedding
训练出来后，怎么判断其有效性是个值得探讨的问题，尤其是在深度学习缺乏可解释性的情况下，paper
中用到了以下几种方法，都比较值得借鉴</p>
<ol type="1">
<li>可视化</li>
<li>计算 listing embedding 之间的cosine similarity</li>
<li>根据 embedding similarity 对历史日志中的 item 重新排序，看 booked
item 的位置（越小越好）</li>
</ol>
<p>方法（1）是可视化，也是评估 embedding
有效性常用的方法；通常做法是聚类然后看每个类里面的 item
的相关性，对于上面训练的 listing embedding，通过 k-means 聚成 100
个类，且由于 airbnb 中每个 item 可以对应于地图上的某个点，因此 paper
中做了两种可视化，第一种是将不同类的点用不同的颜色在地图上进行可视化，如下图所示，paper
称这样聚类的结果对于重新为每个 travel market
定义其范围也是有好处的，</p>
<figure>
<img src="https://wulc.me/imgs/list_embedding_clustering.jpg"
alt="visulization" />
<figcaption aria-hidden="true">visulization</figcaption>
</figure>
<p>第二种可视化则是对于特定的 listing embedding，选取 k-nearest listing
embedding，直观地看这些 listing 对应的房屋的相似性，如下图所示,
可以看到房屋的相似性还是比较高的</p>
<figure>
<img src="https://wulc.me/imgs/listing_embedding_item_simi.jpg"
alt="item visulization" />
<figcaption aria-hidden="true">item visulization</figcaption>
</figure>
<p>方法（2）是计算 embedding 的 cosine 相似性,如下面两个表中，根据item
的一些 meta 信息来划分 listing embedding，然后计算这些划分好的各个类中的
item embedding 与其他各个 item embedding 的 cos
相似性的均值，从结果可知，<strong>价格、房屋类型越相似的 item，其对应的
listing embedding 的 cos 相似性越高</strong>, 因此这些信息是可以被学习到
listing embedding 中的</p>
<figure>
<img src="https://wulc.me/imgs/list_embedding_similarity.jpg"
alt="similarity" />
<figcaption aria-hidden="true">similarity</figcaption>
</figure>
<p>方法（3）是 paper 根据业务去设计的一种评估 embedding 优劣的方法，其
motivation 是：<strong>利用 embedding 信息来对历史的 search session
重新排序，并与 search rank model 的历史排序效果做比较</strong>。</p>
<p>基本的做法就是：选取用户某个 booked item 所出现过的所有历史 serach
session, 每个 search session 会包含其他的 candidate
items；根据用户历史的 clicked items 对应的 embedding，<strong>计算每个
candidate item 的 embedding与这些 clicked items 的 embedding 的
similarity，并根据similarity 重新排序，观察 booked item
的排序</strong>（越小越靠前）</p>
<p>因为是历史的 session，所以对于 candidate items 已经被 Airbnb 的
search rank 排过序了，因此可作为 baseline，paper 中选取了每个 user 最近
17 次的点击来计算相似性，效果如图所示，</p>
<figure>
<img src="https://wulc.me/imgs/EmbeddingEvaluation.jpg"
alt="embedding evaluation" />
<figcaption aria-hidden="true">embedding evaluation</figcaption>
</figure>
<p>上图中各项含义如下</p>
<ul>
<li>search ranking：排序的后验，即历史 search session 的真正排序</li>
<li>d32: 公式(3) 训练出来的 embedding, 即原始的 word2vec 方法</li>
<li>d32 book: 公式(4) 训练出来的 embedding，即加上 booked item 作为
global context 训练出来的 embedding</li>
<li>d32 book+neg: 公式(5)训练出来的 embedding，即做 nagative sampling
的时候专门考虑与 item 处于同一个 market 的 nagative samples</li>
</ul>
<p>从上图可知，d32 book+neg 的效果是最好的</p>
<h2 id="在线-serving">在线 serving</h2>
<p>上面训练好的 embedding，在 serving 的时候怎么用？paper
中主要用到了两个地方</p>
<ol type="1">
<li>Search Ranking: 用户搜索的排序模型</li>
<li>Similar Listing Recommemdation：物品页面中相似物品动态的推荐</li>
</ol>
<h3 id="search-ranking">Search Ranking</h3>
<p>对于 NN 模型，可以直接把 embedding 当做一个 feature
输进去，但是airbnb 的 ranking model 并不是 NN 模型，而是基于树模型的
LambdaRank，这个模型的细节就不在这里展开了，感兴趣的同学可参考 paper
中的 4.4 节。</p>
<p><strong>使用树模型意味着 embedding
不能直接输入模型，需要构造一些连续值特征</strong>。下面主要讲的是这些特征是如何构建以及线上效果</p>
<p>paper 中主要基于 embedding
间计算出来的相似性作为连续值特征，构造的特征列表如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/AirbnbFeatureList.jpg"
alt="featureList" />
<figcaption aria-hidden="true">featureList</figcaption>
</figure>
<p>上图中的一些符号含义如下</p>
<ul>
<li><span class="math inline">\(H\_c\)</span>: 用户过去两周点击过的
listing ids</li>
<li><span class="math inline">\(H\_{lc}\)</span>:
用户点击过且停留时长超过 60s 的 listing ids</li>
<li><span class="math inline">\(H\_s\)</span>: 用户点击的某个 listing
时跳过的其他的 listing ids（如点击了排序第 4 的，就跳过了前 3 个
listing）</li>
<li><span class="math inline">\(H\_w\)</span>:
用户过去两周添加到心愿单的 listing ids</li>
<li><span class="math inline">\(H\_i\)</span>:
用户过去两周联系过但是没有下单的 listing ids</li>
<li><span class="math inline">\(H\_b\)</span>: 用户过去两周下单过的
listing ids</li>
</ul>
<p>因此，上面的列表中的前 6 个 Feature 表示的都是当前 candidate
与用户在历史发生过交互的 lisitng 的一些相似性。除此之外，paper
还<strong>对 feature 做了 market 的划分</strong>，比如对于 <span
class="math inline">\(H\_c\)</span>, 将其划分为 <span
class="math inline">\(H\_c(market1)\)</span>, <span
class="math inline">\(H\_c(market2)\)</span>..., 然后对同一个 market
内的所有 listing id 的 embedding 做一个 mean-pooling, 称为 market-level
embedding，然后计算 candidate listing 跟各个 market-level embedding 的
similarity 并取最大那个，即对于 candidate <span
class="math inline">\(l\_c\)</span>, 上面第一个 feature 的计算如下</p>
<p><span class="math display">\[EmbClickSim(l\_c, H\_c) = \max\_{m \in
M} cos(v\_{l\_i}, \sum\_{l\_h \in m, l\_h \in
H\_c}v\_{l\_h})\]</span></p>
<p>笔者这里有个疑惑，<strong>为什么要取 max
操作而不是把所有的特征都加进去</strong>？因为上面的做法相当于将 market
和 simlarity 这两个 feature 做了交叉，如果把所有 feature
输进去也能扩大原始的feature 的数量。paper
中并没有针对这一点作出解释，可能是都交叉的时候很多交叉特征的值都为空？</p>
<p>上面 table 后的这两个 feature 计算方法类似，只是没有再分 market
计算，因为这里的并不像前面提到的 listing 有明确的 market 概念，
EmbLastLongClickSim 这个 feature 是为了捕获用户最近的兴趣了，而
UserTypeListingTypeSim 这个 feature
则是为了捕获用户长期更泛化的一些兴趣</p>
<p>上面的特征都攒了 30
天，下面是特征的覆盖度和重要性（通过树模型训练结果获取），airbnb
中的模型有 104 个特征，从图中可知，有 5 个 feature 进入了 top20 的重要
feature；其中有几个点值得关注</p>
<ul>
<li>EmbClickSum 的重要性是这些 embedding 构造出来的 feature
中最重要的，反映了用户短期内的兴趣</li>
<li>描述<strong>下单的特征中，用户的长期兴趣比用户的短期兴趣更好</strong>（UserTypeListingTypeSim重要性高于
EmbBookSim），笔者猜测另一个原因可能是计算 EmbBookSim
数据会更为稀疏，因为一般对于一个用户来说两周内下单一次的频率是很低的</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/featureImportance.jpg"
alt="featureimportance" />
<figcaption aria-hidden="true">featureimportance</figcaption>
</figure>
<p>此外，标题中的 Real-time 体现在哪里, 其实就是 Table 6 中的几个
feature 会随着用户的行为的实时变化而变化。</p>
<h3 id="similar-listing-recommemdation">Similar Listing
Recommemdation</h3>
<p>Similar Listing Recommemdation 做的事情就是在每个 listing
详情页里推荐相似物品，这里主要利用的就是 listing embeddings 的 cos
similarity 来选出 top-k 个最相似的物品， paper 将当前 airbnb
的相似物品推荐策略与这个基于 embedding 的方法作比较，线上的 AB
实验显示这个方法相比与当前的方法 ctr 提升了约 21%，cvr 提升了约 4.9%</p>
<h2 id="小结">小结</h2>
<p>笔者认为这篇 paper 介绍了三个方面的内容</p>
<ol type="1">
<li>如何训练生成 embedding</li>
<li>怎么评估训练出来的 embedding 的有效性</li>
<li>线上怎么使用这些embedding</li>
</ol>
<p>训练方法是用了 word2vec 中的 skip-gram 方法，训练数据用了用户历史的
click session 和 book session，且根据具体业务在 skip-gram
做了一些改动，如做 market-level 的 negative sampling、将用户预定的
listing 作为 global
context、将被商家拒绝的订单作为负例等；同时在转化数据系数情况下，将 id
embedding 转为 type embedding，缓解了数据系数情况下 embedding
无法学得很好的问题。除此之外，一些训练细节也值得参考</p>
<p>评估生成的 embedding 的有效性时，除了最常用的可视化方法，paper
还用了另外两种值得参考方法，第一种是确定某些维度后，比较这些不同维度上的
listing embedding 的相似性，第二种则是根据 listing embedding
相似性对历史排序结果重新排序，同时看最终被下单的 listing
在重新排序后的结果</p>
<p>线上使用 embedding 时，由于 Airbnb 使用的是树模型，不能直接将
embedding 作为 feature 输入模型，paper 中是通过计算出 embedding
间的相似性作为连续值特征输入模型的</p>
<p>最后，知乎上<a
href="https://www.zhihu.com/question/302288216">如何评价Airbnb的Real-time
Personalization获得2018 kdd最佳论文？</a>也有很多值对这篇 paper
的解读，都值得一看，推荐看下<a
href="https://www.zhihu.com/question/302288216/answer/532712103">这个回答</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《Reducing the Dimensionality of Data with Neural Networks》阅读笔记</title>
    <url>/2016/11/28/%E3%80%8AReducing%20the%20Dimensionality%20of%20Data%20with%20Neural%20Networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><a
href="http://science.sciencemag.org/content/313/5786/504.full">Reducing
the Dimensionality of Data with Neural
Networks</a>是对深度学习有重要影响的一篇论文，可以说是拉开了深度学习的帷幕，该论文出自
Hinton
大神之手。本文是读了论文后结合其他一些参考资料整理成的读书笔记。</p>
<span id="more"></span>
<h2 id="简介">简介</h2>
<p>该论文主要讲述了通过神经网络对数据进行降维，并通过多项实验结果证明通过神经网络进行降维的效果要优于传统的降维方法
PCA(Principal component analysis,
主成成分分析)。但是要达到这种效果，需要有一个前提，那就是神经网络中的参数在初始化的时候不能随机初始化，而是要有一个预训练的过程，论文中通过
RBM(Restricted Boltzmann
machine，受限玻尔兹曼机)来实现这个预训练的过程，<strong>利用 RBM
对神经网络中的参数进行逐层预训练</strong>，然后将训练出来的参数作为神经网络的初始化参数。</p>
<h2 id="数据的降维">数据的降维</h2>
<p>在机器学习中，原始数据往往会存在着各种各样的问题，样本的特征数目过多是其中之一，当样本的特征过多的时候往往会存在冗余的信息和噪声；而当特征数目原大于样本数目的时候容易导致过拟合，使得模型的泛化能力弱；除此之外，特征数目过多的样本也需要更长的训练时间，训练的成本较高。</p>
<p>基于上述的原因，在训练模型之前往往需要对数据进行一个降维的操作，常见的降维方法有
PCA
等。降维直观的反映就是样本特征数目的减少，同时原始的信息（包括有用的信息和噪声）也会有损失；从另外一个角度来看降维就是提取原始数据的主要特征，而神经网络的结构特点恰恰为其进行特征提取提供了可能性，下面就讲述如何通过神经网络进行特征的提取，也就是论文的主要工作。</p>
<h2 id="自编码器与逐层预训练">自编码器与逐层预训练</h2>
<p>自编码器(autoencoder)是论文提出的一种特殊的神经网络，由
<code>Encoder</code> 和 <code>Decoder</code> 两部分构成，其中
<code>Encoder</code> 的作用是降维，而 <code>Decoder</code>
的作用是从降维的后的特征中恢复出原始特征。其结构如下所示：</p>
<p><img
src="https://wulc.me/imgs/image_1b32fsja61u4b5ka1tgq9ucqubm.png" /></p>
<p>上图主要展示了<strong>通过自编码器对图像进行特征压缩并复原的过程</strong>。其中左边部分是初始训练时候的状态，<code>Encoder</code>
将原图像2000维的特征压缩到了30维， 而 <code>Decoder</code>
将压缩后得到的30维的图像恢复成原来的2000维，由于还没对网络进行训练，所以此时的图像会比较模糊。右边部分则是通过经典的
BP(Backpropagation, 反向传播)
算法对网络进行训练后的恢复效果，得到的效果与原图像已经非常接近了。</p>
<p>从上面的描述看来，自编码器的训练方法与传统的神经网络的训练没有差别。但是<strong>论文中指出了网络的初始化参数要足够好，才能利用这种训练方法得到比较好的效果。</strong></p>
<p>网络的初始化参数就是上图中的 <span
class="math inline">\(W_1,W_2,W_3,W_4\)</span>,
我们知道，神经网络的主要是通过前向传播和反向传播这两个过程来训练网络中层与层之间的参数，通过这些网络间的参数来拟合数据的内在特性。但是在开始训练前，必须要给网络中的参数赋一个初始值，由于对数据没有任何的先验知识，这种初始化赋值往往是随机的，<strong>在多层网络中随机初始化参数存在着以下问题：当随机初始化的值过大时容易陷入局部最优，当随机初始化的值过小时训练会比较困难（在反向传播的时候梯度很快趋于0，错误信息传不到前面的层）。</strong></p>
<p>而论文中所说的“网络的初始化参数足够好”其实是要通过逐层训练的方法先训练出一批参数值作为初始值赋给
<span
class="math inline">\(W_1,W_2,W_3,W_4\)</span>，然后再进行后面的前向传播和反向传播来训练整个网络。</p>
<p>下面主要讲述如何训练出网络的初始化参数，而这也是本文的最重要的工作。</p>
<h3 id="逐层预训练过程">逐层预训练过程</h3>
<p>在逐层预训练中采用的模型是 RBM, RBM 的结构图如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b32hutvj5qj1m0t5qe14nogr613.png" /></p>
<p>从上面的的结构图可知， RBM
是一个二层全连接的双向网络，二层指的是隐藏层(h节点)和可视层(v节点)，其中各层节点的大小关系没有要求（也就是
m可以大于n也可以小于n），双向指数据既可从可视层传播到隐藏层，也可从隐藏层传输到可视层。</p>
<p>RBM包含的参数有</p>
<ul>
<li>权重矩阵 <span class="math inline">\(W\_{nm}\)</span></li>
<li>隐藏层偏置量 <span class="math inline">\(c = (c\_1, c\_2, c\_3, ...
c\_n)\)</span></li>
<li>可视层偏置量 <span class="math inline">\(b = (b\_1, b\_2, b\_3, ...
b\_m)\)</span></li>
</ul>
<p>其中偏置量的取值为0或1。</p>
<p>由于传播方向是双向的，这里先不加证明给出两个方向的传播的公式，具体的证明看下一节的原理与推导。</p>
<p>从可视层传到隐藏层<span class="math display">\[P(h\_i=1|v) =
\sigma(\sum\_{j=1}^mw\_{ij}v\_j+c\_i)\tag{3-1}\]</span>
从隐藏层传到可视层<span class="math display">\[P(v\_j=1|h) =
\sigma(\sum\_{i=1}^nw\_{ij}h\_i+b\_j)\tag{3-2}\]</span> 其中 <span
class="math display">\[ \sigma(x) = 1/(1+e^{-x})\tag{3-3}\]</span></p>
<p>由上面的传播公式可知，两个传播过程计算出来的都是一个概率值，就是传播的目标点取1的概率，实际中赋值时按照均匀分布产生一个0到1之间的随机浮点数，如果它小于<span
class="math inline">\(P(v\_j=1|h)，v\_j\)</span> 的取值就是1，否则就是
0。</p>
<p>有了上面关于 RBM 的基础知识，下面就是逐层预训练的具体过程</p>
<ol type="1">
<li>正向过程：样本 <span class="math inline">\(v\)</span> 通过公式 (3-1)
从可视层输入得到 <span class="math inline">\(h\)</span></li>
<li>反向过程：隐藏层 <span class="math inline">\(h\)</span> 通过公式
(3-2) 回传到可视层得到 <span class="math inline">\(v&#39;\)</span>, 利用
<span class="math inline">\(v&#39;\)</span>
再进行一次正向传播得到隐藏层的 <span
class="math inline">\(h&#39;\)</span></li>
<li>权重更新过程：更新公式为(其中 <span
class="math inline">\(\alpha\)</span> 为学习率) <span
class="math display">\[W(t+1) = W(t) +
\alpha(vh^T-v&#39;h&#39;^T)\tag{3-4}\]</span></li>
<li>迭代上面过程直至权重 <span class="math inline">\(W\)</span>
收敛</li>
</ol>
<p>上面的公式中的 <span class="math inline">\(v,h,v&#39;,h&#39;\)</span>
均为向量，且公式 (3-4) 在原文表述为 <span class="math inline">\(\Delta
W\_{ij} = \varepsilon ( (v\_jh\_j)\_{data} -
(v\_jh\_j)\_{recon})\)</span>，但是含义是一致的，就是<strong>利用被压缩后再恢复的数据与原始数据的误差来调整二层网络间的参数，使得恢复出来的数据尽可能与原始数据接近，也就是要让被压缩后的数据尽可能的保留着原始数据的特征</strong>。</p>
<p>上面的训练过程中只是训练了相邻两层网络间的参数，而神经网络一般是有多层的，所以需要利用这种方法逐层进行训练，这也是逐层预训练说法的来由。所以上面通过自编码器对图像进行特征压缩并复原的完整过程如下图所示：</p>
<p><img
src="https://wulc.me/imgs/image_1b32l5rhvb9urad4c71lk11f5d9.png" /></p>
<p>首先利用 RBM
逐层训练出网络的初始化参数，后面就是传统神经网络的训练过程了，通过前向传播和反向传播来调整网络间的参数，从而达到收敛。</p>
<h3 id="原理与推导">原理与推导</h3>
<p>上面主要讲述了参数逐层预训练的具体过程，下面主要讲述这种方法的思想以及推导对上面不加证明给出的传播过程的公式。</p>
<p>在自编码器预训练的过程中， <strong>RBM
的主要作用是在隐藏层尽可能保留从可视层输入的数据的主要特征（因为特征维度的压缩会导致数据的损失），而度量其保留程度的指标就是利用压缩了的特征恢复出来的图像与原图像的概率分布的差别，差别越小，保留的特征就越好。</strong>利用这个差别，可以调整
RBM 中的参数，从而使得误差逐步减小。</p>
<p>因此，上面的正向过程( <span class="math inline">\(v \rightarrow
h\)</span> )是一个特征压缩过程，影响了真实数据的特征，而反向过程( <span
class="math inline">\(h \rightarrow v&#39;, v&#39;\ \rightarrow
h&#39;\)</span> )就是利用压缩后的特征(<span
class="math inline">\(h\)</span>)重现真实数据的特征（<span
class="math inline">\(v&#39;\)</span>）,权重更新过程则是利用他们的误差来更新权重矩阵，误差在这里表示为
<span class="math inline">\((vh^T-v&#39;h&#39;^T)\)</span>。</p>
<p>上面的正向过程和反向过程中的两个关键公式 (3-1) 和 (3-2)
我们是不加证明的使用的，下面对其进行简单推导，推导的思路是从 RBM
的能量函数推导出概率模型，再从概率模型推导极大似然估计。</p>
<p>首先， RBM 诞生于统计力学，统计力学中为其定义的一个<a
href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine">能量函数</a>,针对下图的RBM</p>
<p><img
src="https://wulc.me/imgs/image_1b32hutvj5qj1m0t5qe14nogr613.png" /></p>
<p>其能量函数表示如下：<span class="math display">\[E(v,h) =
-\sum\_{i=1}^n\sum\_{j=1}^m
w\_{ij}h\_iv\_j-\sum\_{j=1}^mb\_jv\_j-\sum\_{i=1}^nc\_ih\_i
\tag{3-5}\]</span></p>
<p>定义出这个能量函数又有什么作用呢？根据参考资料，原因有以下几个
&gt;第一、RBM网络是一种无监督学习的方法，无监督学习的目的是最大可能的拟合输入数据，所以<strong>学习RBM网络的目的是让RBM网络最大可能地拟合输入数据</strong>。</p>
<blockquote>
<p>第二、<strong>对于一组输入数据来说，现在还不知道它符合那个分布，那是非常难学的</strong>。例如，知道它符合高斯分布，那就可以写出似然函数，然后求解，就能求出这个是一个什么样个高斯分布；但是要是不知道它符合一个什么分布，那可是连似然函数都没法写的，问题都没有，根本就无从下手。</p>
</blockquote>
<blockquote>
<p>第三，<strong>统计力学的结论表明，任何概率分布都可以转变成基于能量的模型</strong>，而且很多的分布都可以利用能量模型的特有的性质和学习过程，有些甚至从能量模型中找到了通用的学习方法。换句话说，就是<strong>使用能量模型使得学习一个数据的分布变得容易可行</strong>了。</p>
</blockquote>
<p>因此，基于上面的能量函数，可以定义出一个可视节点与隐藏节点间的联合概率
<span class="math display">\[P(v,h) =
\frac{e^{-E(v,h)}}{\sum\_{v,h}e^{-E(v,h)}} \tag{3-6}\]</span></p>
<p>该公式也是根据统计热力学给出的，具体参看<a
href="http://blog.csdn.net/mytestmy/article/details/9150213">参考文献</a>。有了联合概率，就可以求出其条件概率如下所示：</p>
<p><span class="math display">\[P(v) =
\frac{\sum\_he^{-E(v,h)}}{\sum\_{v,h}e^{-E(v,h)}} \tag{3-7}\]</span>
<span class="math display">\[P(h) =
\frac{\sum\_ve^{-E(v,h)}}{\sum\_{v,h}e^{-E(v,h)}} \tag{3-8}\]</span>
<span class="math display">\[P(v|h) =
\frac{e^{-E(v,h)}}{\sum\_ve^{-E(v,h)}} \tag{3-9}\]</span> <span
class="math display">\[P(h|v) = \frac{e^{-E(v,h)}}{\sum\_he^{-E(v,h)}}
\tag{3-10}\]</span></p>
<p>上面的这些概率分布也叫<strong>Gibbs分布</strong>，这样就完成了从能量模型到概率模型的推导，下面是从概率模型推导出极大似然估计。</p>
<p>现在回到<strong>求解的目标:
让RBM网络的表示Gibbs分布最大可能的拟合输入数据的分布</strong>。那么这两个分布的<a
href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL散度</a>如下所示,KL散度主要用于表示两个分布的一个相似度，其值越小，表示两个分布越相似：
<span class="math display">\[KL(q||p) = \sum\_{x \epsilon \Omega} q(x)
ln\frac{q(x)}{p(x)} =\sum\_{x \epsilon \Omega} q(x)lnq(x)-\sum\_{x
\epsilon \Omega} q(x)lnp(x) \tag{3-11}\]</span></p>
<p>上式中的 <span class="math inline">\(q(x)\)</span>
是输入样本的分布，样本确定的时候，该分布也确定了下来，而<span
class="math inline">\(p(x)\)</span>表示通过 RBM
后输出样本的分布，也就是公式 (3-8)
表示的隐藏层的分布。当输入样本确定的时候，要最小化公式
(3-9)的KL距离，实际上就是要最大化公式(3-9)中的 <span
class="math inline">\(lnp(x)\)</span>,而 <span
class="math inline">\(lnp(x)\)</span> 与
RBM网络中的参数相关，实际上就是进行一个极大似然估计求出网络中的参数。具体的数学推导过程参见<a
href="http://blog.csdn.net/mytestmy/article/details/9150213#t12">这里</a>。通过求解便可以得到公式(3-1)
和 (3-2),也就完成了从概率模型到最大似然的推导。</p>
<h2 id="实验效果对比">实验效果对比</h2>
<p>论文通过若干的实验证明了通过自编码器对图像进行压缩后再恢复的效果要优于PCA，需要注意的是图像的压缩实际上就是特征的压缩，也就是一个特征提取或者说降维的过程，下面是具体的实验结果。
### 实验一：曲线图像的压缩与恢复 下图是实验数据 <img
src="https://wulc.me/imgs/image_1b33qroceosghtu1oo71k9b9qt9.png" /></p>
<p>上图中从上到下每一行对应于下表中从上到下的每一行</p>
<table>
<thead>
<tr class="header">
<th>方法</th>
<th>特征数</th>
<th>均方误差</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>原图像</td>
<td>786</td>
<td></td>
</tr>
<tr class="even">
<td>自编码器</td>
<td>6</td>
<td>1.44</td>
</tr>
<tr class="odd">
<td>PCA</td>
<td>6</td>
<td>7.64</td>
</tr>
<tr class="even">
<td>Logistic PCA</td>
<td>18</td>
<td>2.45</td>
</tr>
<tr class="odd">
<td>PCA</td>
<td>18</td>
<td>5.90</td>
</tr>
</tbody>
</table>
<h3
id="实验二手写数字图片的压缩恢复与分类">实验二：手写数字图片的压缩、恢复与分类</h3>
<p>该实验采用 MNIST 数据集，下图是实验数据 <img
src="https://wulc.me/imgs/image_1b33r5cli1ll51nd0v1q1g2itumm.png" /></p>
<p>上图中从上到下每一行对应于下表中从上到下的每一行</p>
<table>
<thead>
<tr class="header">
<th>方法</th>
<th>特征数</th>
<th>均方误差</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>原图像</td>
<td>786</td>
<td></td>
</tr>
<tr class="even">
<td>自编码器</td>
<td>30</td>
<td>3.00</td>
</tr>
<tr class="odd">
<td>Logistic PCA</td>
<td>30</td>
<td>8.01</td>
</tr>
<tr class="even">
<td>PCA</td>
<td>30</td>
<td>13.87</td>
</tr>
</tbody>
</table>
<p>上面是对图像进行压缩与恢复的实验，下面是提取每个手写数字两维的特征（原始维度为786维）进行分类的结果，图A是原始数据进行分类后的结果，图B是通过自编码器中的
<code>Encoder</code>
压缩到两维后再分类的结果。可以看到，通过自编码器得到的两维特征已经能够将各个数字较好分离开。</p>
<p><img
src="https://wulc.me/imgs/image_1b33re6ri1j3sjecrf9ivjcl713.png" /></p>
<h3 id="实验三人脸图像的压缩与恢复">实验三：人脸图像的压缩与恢复</h3>
<p>实验数据如下所示 <img
src="https://wulc.me/imgs/image_1b33trplg1iqqj4v17i41bib1m1h1g.png" /></p>
<p>上图中从上到下每一行对应于下表中从上到下的每一行</p>
<table>
<thead>
<tr class="header">
<th>方法</th>
<th>特征数</th>
<th>均方误差</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>原图像</td>
<td>625</td>
<td></td>
</tr>
<tr class="even">
<td>自编码器</td>
<td>30</td>
<td>126</td>
</tr>
<tr class="odd">
<td>PCA</td>
<td>30</td>
<td>135</td>
</tr>
</tbody>
</table>
<h3 id="实验四词向量的降维与分类">实验四：词向量的降维与分类</h3>
<p>上面的实验均是针对图像的，但是实际上通过自编码器中的
<code>Encoder</code>
对原始数据进行提取特征后，可利用这些特征进行分类和回归。这个实验就是对词向量进行降维后并进行分类，主要比较自编码器和<a
href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">LSA</a>(
Latent Semantic Analysis, 隐性语义分析)对词向量降维后分类的效果。</p>
<p><img
src="https://wulc.me/imgs/image_1b33uavmu123l1a0i13tk9cl2sf1t.png" /></p>
<p>上图中 A
是文档相似性判断的准确率，通过LSA分类要提取文档向量的50维才能达到自编码器提取前10维进行分类的效果，图
B
是采用LSA对提取了2维的词向量(原始为2000维)进行分类的结果，可以看到完全无法分开，而图c是自编码器提取2维后的分类结果，可以看到分类结果要大大优于图B的效果。</p>
<h2 id="总结">总结</h2>
<p>这篇论文由深度学习的开山鼻祖<a
href="http://www.cs.toronto.edu/~hinton/">Geoffrey E. Hinton</a> 2006
年发表在 science
上，论文虽然只有短短的四页，但是做了两个非常重要的工作</p>
<p><strong>(1)
多层的神经网络具有优秀的特征学习能力，能够学习到数据更本质的特征 (2)
多层神经网络的初始化参数可通过逐层预训练获得</strong></p>
<p>从上面的四个实验结果中可以看到自编码器提取的特征均要优于传统的PCA和LSA，也就是上面说的第(1)点；但是多层的神经网络很早就已经提出了，只是因为一直存在着初始化参数赋值的困难（过大陷入局部最优，过小梯度消失）而无法应用到实际中，本论文通过
RBM
逐层预训练得到多层神经网络的初始化参数，从而解决了这个问题，也就是上面说的第(2)点，也正是这个工作为多层神经网络或者说深度学习在实际中的应用拉开了帷幕。</p>
<p>参考文献： <a
href="http://science.sciencemag.org/content/313/5786/504.full">Reducing
the Dimensionality of Data with Neural Networks</a> <a
href="http://blog.csdn.net/mytestmy/article/details/9150213">深度学习读书笔记之RBM（限制波尔兹曼机）</a>
<a
href="http://www.lai18.com/content/708718.html">能量模型(EBM)、限制波尔兹曼机(RBM)</a>
<a
href="http://blog.csdn.net/xbinworld/article/details/44901865">深度学习方法：受限玻尔兹曼机RBM（一）基本概念</a>
<a
href="http://blog.csdn.net/xbinworld/article/details/45013825">深度学习方法：受限玻尔兹曼机RBM（二）网络模型</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《商业产品经理的实战修炼》学习笔记</title>
    <url>/2021/10/30/%E3%80%8A%E5%95%86%E4%B8%9A%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E7%9A%84%E5%AE%9E%E6%88%98%E4%BF%AE%E7%82%BC%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>一直觉得从不同视角去看事情，往往能有更全面的了解，也能得出一些更有趣的结论。因此，习惯了从
rd
视角去看商业化广告，老早就想从产品/运营/销售的视角去看这个事情，最近正好找到关于商业化产品经理的一门课，即《<a
href="https://www.sanjieke.cn/class/3655535.html">商业产品经理的实战修炼</a>》，虽然是几年前的课程，但是其中一些内容放到今天也是值得参考的，也让笔者对商业产品有了进一步的理解。</p>
<p>课程里主要讲了四大部分内容(其实是五章，但是因为对广告进阶这部分比较熟悉，所以略过了这部分)：商业产品的定义及演进、商业产品经理的职责与方法论、有效的商业产品需求、商业产品从0
到
1，下文也是按照这四部分展开，内容经过梳理且只摘录了笔者比较关心的一些内容，推荐看原视频。</p>
<span id="more"></span>
<h2 id="商业产品定义及切入">商业产品定义及切入</h2>
<p>这部分介绍了商业产品的定义、启动时机、模式的选择以及切入点(部分内容是第五讲的，但是笔者觉得放在这里更合适)</p>
<h3 id="定义">定义</h3>
<p>商业产品需要满足以下三个要素</p>
<ol type="1">
<li>收钱对象</li>
<li>服务/产品</li>
<li>定价&amp;分发机制</li>
</ol>
<p>将这三个元素串起来就是：找准收费对象，通过提供特定的服务/产品满足收钱对象的需求，同时需要指定一套定价&amp;分发机制，以此为准则向收钱对象进行收费</p>
<p>常见的商业产品有两种收费模式：<strong>前向收费和后向收费</strong></p>
<p>前向收费面向的是用户，要思考能给用户的最优体验是什么；常见的模式如各种会员,
VIP；收费的规则视频里没有细讲，但是其中的一些逻辑可以参考 <a
href="http://www.woshipm.com/operate/3541530.html">付费会员体系分析</a>
和 <a href="http://www.woshipm.com/operate/2450659.html">VIP
会员套餐的定价策略</a></p>
<p>后向收费面向的是客户，要结合用户行为思考如何最大化客户效果；典型形态是广告；收费的规则就是典型的拍卖
+
GSP/VGG；视频里讲了广告演进的一些内容，包括广告的形态、参与者、收费模式等，但是比较基础这里就不展开了。</p>
<h3 id="启动时机与切入点">启动时机与切入点</h3>
<p>教程里还给了商业化启动时机的参考，简单来说就是<strong>从我们能把用户留住开始</strong>，量化的指标有以下三个</p>
<ol type="1">
<li>用户新增率 &gt; 用户流失率</li>
<li>用户留存率 &gt; 40%</li>
<li>LTV &gt; CPA(至少), LTV &gt; 3CPA(最好)</li>
</ol>
<p>商业化的模式选择就是上面说的前向收费和后向收费，两种方式需要注意的点如下</p>
<ul>
<li>前向收费：需要谨慎，因为用户习惯了免费的模式，可尝试“基础功能免费+增值收费收费”的模式</li>
<li>后向收费：比较常见的是广告，但是也要注意用户体验，让广告更原生化</li>
</ul>
<p>书里举了美团的例子，讲述了美团变现的三个步骤：CPL -&gt; CPT -&gt;
效果广告；后两者比较好理解，CPL
指的是用户购买成功后平台收佣；但存在跳单问题，即商家可能会让用户绕过平台直接下单</p>
<p>那该如何找到商业化的切入点？课程里主要关注如下 2 点</p>
<ol type="1">
<li>客户/用户的需求分析</li>
<li>平台资源的梳理</li>
</ol>
<p>第1步里的需求分析可从以下三个方面挖掘(这里客户可认为是商业产品的使用者，而用户则是用户产品的使用者)</p>
<ol type="1">
<li>客户打开 app/网站 目的是什么</li>
<li>客户达到目的的行为路径是什么</li>
<li>挖掘客户的内在需求(当前的路径存是否存在可优化的地方？)</li>
</ol>
<p>课程里以视频会员为例，介绍了这种模式下的需求挖掘，即用户为了看电影，其传统的行为路径是：先打开搜索引擎
-&gt; 进行资源的搜索和下载 -&gt;
使用电脑播放器打开；而现在常用的一些视频 app
能够更好地满足用户的这些需求，其路径对比如下</p>
<p><img src="https://wulc.me/imgs/action_path_compare.jpg" height="50%" width="50%">　</p>
<p>平台资源的梳理部分，书里没有给明确的方法论，这部分在不同领域需要不同的背景知识，但基本的方法都是<strong>“搜集+分类”</strong>,
“搜集”需要看个人对信息的敏感程度以及信息来源是否足够多，“分类”有一些详细的方法论可参考，笔者之前写的<a
href="https://wulc.me/2021/10/05/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%282%29-%E5%A4%A7%E8%84%91%E5%8D%87%E7%BA%A7/">《认知红利》阅读笔记(2)-大脑升级</a>，里面的结构化思维部分可以参考下，里面提到了两个具体的方法：金字塔结构和平面切割</p>
<h2 id="商业产品经理">商业产品经理</h2>
<h3 id="角色定位">角色定位</h3>
<p>商业产品经理往往有两个角色</p>
<ol type="1">
<li>产品经理</li>
<li>seller</li>
</ol>
<p>第一个角色的职责是设计并推动落地满足行业市场和用户/客户需求的产品，跟用户产品经理的职责基本一样，更详细可划分为:
(1)行业认知与分析、需求挖掘与分析 (2)产品设计力 (3)推动产品实现</p>
<p>第二个角色的职责是把产品卖出去创造收益，这部分更多跟销售环节挂钩，更详细可划分为
(1)目标客户分析，销售、运营协同（2）业务流程规则设计</p>
<p>以广告为例，商业产品经理的职责如下</p>
<p><img src="https://wulc.me/imgs/product_manager.jpg" height="80%" width="80%">　</p>
<p>具体的产品推广链路如下</p>
<p><img src="https://wulc.me/imgs/baidu_fengchao.jpg" height="80%" width="80%">　</p>
<p>课程里注重提到了售前环节，并将其分为以下3步，并概述了每个步骤中销售的职责</p>
<ol type="1">
<li>销售线索搜集: 地推、营销网站(自主开户系统)</li>
<li>售卖: 销售线索的公海、私海、保护期(CRM系统) ，这部分更详细可参考<a
href="http://www.woshipm.com/pd/628327.html">漫谈CRM体系化建设2 –
如何开发客户？</a></li>
<li>宣讲：演示(提供相关的 demo、数据等)</li>
</ol>
<h3 id="方法论">方法论</h3>
<p>教程里给了四点关于“商业产品经理的修炼功法”</p>
<ol type="1">
<li>明确产品定位</li>
<li>会讲故事</li>
<li>用户思维</li>
<li>善用监控表</li>
</ol>
<p><strong>1.明确产品定位</strong></p>
<p>产品定位简单来说就是“<strong>产品在客户心中第一反映</strong>”，如下是一些例子</p>
<p><img src="https://wulc.me/imgs/product_location.jpg" height="80%" width="80%"></p>
<p>进一步地，可以从以下 6 个方面去明晰产品的定位</p>
<ul>
<li>属于什么行业/类型</li>
<li>目标用户/客户是谁</li>
<li>解决用户/客户什么问题</li>
<li>给用户/客户带来什么价值</li>
<li>与竞对的差异</li>
<li>如何匹配和强化产品和用户/客户</li>
</ul>
<p>能较好回答出以上的 6
个问题，才算对产品有一个较为清晰的定位，以上面的百度搜索移动推广为例，这
6 个问题的答案如下</p>
<p><img src="https://wulc.me/imgs/product_location1.jpg" height="60%" width="60%"></p>
<p><strong>2.会讲故事</strong></p>
<p>会讲故事这个技能其实也不限于产品经理了，课程里提到的针对产品经理的方法是：(1)站在客户角度思考
(2)形象描述客户使用后能带来什么收益</p>
<p>如下是一个例子</p>
<p><img src="https://wulc.me/imgs/product_story.jpg" height="80%" width="80%"></p>
<p>讲故事的详细方法论在课程里没有详细讲述，这部分可以参考知乎上的这个答案：<a
href="https://www.zhihu.com/question/27646075/answer/206366888">怎么提高讲故事的能力？
-
废柴潇的回答</a>，简单来说就是<strong>要具体，引起听众的共情</strong></p>
<p><strong>3.用户思维</strong></p>
<p>商业产品是为金主爸爸们服务的，但也要考虑用户体验，也就是站在用户的角度去评估产品的优劣</p>
<p>后向收费进行变现的模式尤其需要注意这部分，以广告为例，出广告时需要注意
(1)让用户不反感：用户在什么场景会被打动
(2)增强互动：用户在媒体平台的行为路径
(3)提升效果：用户在不同客户行业产生转化的决策路径</p>
<p>如下是一个例子</p>
<p><img src="https://wulc.me/imgs/user_thinking.jpg" height="60%" width="60%"></p>
<p>那挖掘用户思维的方法有哪些？课程里简单概述了如下 3 个角度 (1) <a
href="https://zh.wikipedia.org/wiki/%E9%9C%80%E6%B1%82%E5%B1%82%E6%AC%A1%E7%90%86%E8%AE%BA">马斯洛需求层次</a>（生理需求-&gt;精神需求），更简单来说就是饱暖思淫欲
(2) 人性的弱点 (3) 大数据分析（其实就是各种推荐/广告里的模型）</p>
<p><strong>4.善用监控表</strong></p>
<p>使用监控报表是的目的主要有 2 个: (1)了解收入业绩完成情况
(2)了解生意模式是否良性</p>
<ul>
<li>了解收入业绩完成情况：需要监控收入的进度，即当前的收入完成情况是否能跟上时间进度；进一步的细分可从行业、客户类型、广告类型等角度进行</li>
<li>了解生意模式是否良性，即需要关注客户的以下指标
<ul>
<li>流失率：进来的客户有多少不会再购买</li>
<li>续费率：客户的复购情况</li>
<li>新开户、留存、流失对比：产品引入新客情况</li>
<li>客户数=新开+留存-流式，新开&gt;流失才能保证客户数是正增长的</li>
</ul></li>
</ul>
<p>搭建监控报表需要</p>
<p>(1)<strong>指标服务于业务</strong>；需要明确具体业务和使用者是谁？根据使用者决定需要关注的点,
如下面是在广告场景下，针对产品和销售需要提供的不同指标和维度</p>
<p><img src="https://wulc.me/imgs/dashboard_pm.jpg" height="80%" width="80%"></p>
<p><img src="https://wulc.me/imgs/dashboard_seller.jpg" height="80%" width="80%"></p>
<p>(2)<strong>设计整体框架</strong>；即将第一步列出来的点更加具象化，如下所示是五个值得关注的方面</p>
<ul>
<li>业务场景的划分：即监控平台需要支持哪些业务场景</li>
<li>数据指标：用什么样的数据指标体系</li>
<li>分析维度：要从哪些维度去看这些数据指标(如时间、销售渠道)</li>
<li>层次关系：分析维度有没有层次关系,
是否需要下钻(如行业分类，往下是否还有一级行业、二级行业)</li>
<li>呈现形式：用什么图表分析更直观</li>
</ul>
<p>(3)<strong>明确数据源</strong>；需要保证数据源的准确性、时效性、归一性(数据在更大范围内也是可解读的)</p>
<p>(4)<strong>功能模设计</strong>；课程里列举了如下四个模块</p>
<ul>
<li>权限管理：即需要保证数据的机密性</li>
<li>关键指标监控：即直接反映业务目标是否完成的数据</li>
<li>实时收入数据：即除了定期 review
关键数据外，还需要一个实时的监控来预警业务形态是否有问题</li>
<li>总分式结构：即选从不同维度去分析，一般必备的是平台维度(流量,
即平台不同流量上的收入)和行业维度(客户,
即在不同类型客户上的收入情况)</li>
</ul>
<p>(5)<strong>设计原则</strong>，大原则是高效向使用者传递数据信息，可细分为功能设计和界面设计</p>
<p>功能设计需要突出核心指标、突出对比、使用总分式结构(提供细分及下钻)
界面设计需要以简洁为上、避免过多颜色、选择正确的可视化形式</p>
<h2 id="确认有效的商业产品需求">确认有效的商业产品需求</h2>
<h3 id="需求分析">需求分析</h3>
<p>课程在这部分给了经典的福特汽车与马的案例，主要想表明客户存在着显性需求与隐形需求，而隐性需求才体现了客户的本质问题</p>
<p><img src="https://wulc.me/imgs/pm_fute.jpg" height="60%" width="60%"></p>
<p>那怎么挖掘客户隐形的本质需求？课程给出了以下三点建议</p>
<p>1.找准分析对象(目标客户群体)，要为哪些人解决问题
2.明确目标，解决眼前的问题能达到最终目标吗？
3.换位思考，站在客户角度去想问题</p>
<p>这里注重讲一下换位思考这部分，即需要用客户的语言来描述产品或者需求，像客户一样去体验，理解客户显性需求背后的真正需求;
即需要完成从平台思维到客户思维的转变，如下是一些常见的例子</p>
<p><img src="https://wulc.me/imgs/different_view.jpg" height="60%" width="60%"></p>
<p>而挖掘这些需求实际中常用的一些方法包括</p>
<p>(1)问卷 - 常用于已有产品，客观选择题 - 判断客户的满意度/接受度 -
方案优先级排序或方案 N 选 1，一般是3% 回收率</p>
<p>(2)电话 - 常用于需求深入挖掘 - 问题不超过 3 个</p>
<p>(3)面谈 - 常用于对预设问题没有答案/方案，做大而全的需求收集 -
开放式问答，引导客户多说，但是说的有方向性 -
根据客户回答抓住要点追问</p>
<h3 id="数据分析">数据分析</h3>
<p>数据分析有三个关键的要素：找指标、读指标、指标拆解，</p>
<p>1.找指标</p>
<p>指标需要具备简单性、可比较性，且与公司目标保持一致</p>
<p>2.读指标</p>
<p><strong>只有指标和数值无意义，需要参考值</strong>，参考值可从以下 2
方面入手</p>
<ul>
<li>跟自己比：同比、环比看异常点，提升/下降的服务</li>
<li>跟业内经验比：增长、活跃用户数、获客成本等</li>
</ul>
<p>3.指标拆解</p>
<p>这部分有三个具体步骤，确认主指标 -&gt; 确认计算公式 -&gt;
多维度拆解</p>
<ul>
<li>确认主指标：明确当前阶段最有意义的指标</li>
<li>确认计算公式：将目标拆解为可量化的公式，找到影响的相关指标</li>
<li>多维度拆解：商业产品通常从以下两个维度入手：流量(货源)、客户(客源)；</li>
</ul>
<p><img src="https://wulc.me/imgs/Disassemble_case.jpg" height="60%" width="60%"></p>
<p>另外，比较值得关注的商业产品常常可通从 2
个维度入手，即从流量角度看，收入=曝光量×cpm；而从客户角度看，收入=客户数量×arpu</p>
<h3 id="竞品调研">竞品调研</h3>
<p>竞品调研也有 3 个主要关注的要素：目的，手段，结果</p>
<ul>
<li>目的：选择好分析的目标</li>
<li>手段：若干对比分析</li>
<li>结果：讨论和提出解决思路</li>
</ul>
<p>在调研过程中需要常问自己以下四个问题</p>
<p>1.竞品是什么样的 2.什么要这么做 3.是否要学 4.如何学</p>
<p><img src="https://wulc.me/imgs/Competitive_product_research.jpg" height="60%" width="60%"></p>
<p>课程里以 facebook 为例讲了这个过程</p>
<p><img src="https://wulc.me/imgs/Competitive_product_research_case.jpg" height="60%" width="60%"></p>
<h2 id="商业产品从-0-到-1">商业产品从 0 到 1</h2>
<p>商业产品通常的流程是: 需求分析 -&gt; 需求筛选 -&gt; 产品设计 -&gt;
发布验证 -&gt; 上线运营</p>
<h3 id="需求分析-1">需求分析</h3>
<p>其实就是上面第三部分“确认有效的商业产品需求”讲的内容，可分为需求分析、数据分析和竞品分析几个部分</p>
<h3 id="需求筛选">需求筛选</h3>
<p>这部分就是根据
roi，从第一部分得到的候选需求中筛选出重要的需求；这部分内容跟 <a
href="https://wulc.me/2021/08/22/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E6%A6%82%E5%BF%B5%E9%87%8D%E5%A1%91/">《认知红利》阅读笔记(1)-概念重塑</a>
里面的“为想法估值”比较相似，推荐一起看</p>
<p>需求筛选需要通常会从以下四个方面去评估，并提供了参考的综合评分</p>
<p>(1)商业收益评估 (2)实现成本 (3)客户接收程度 (4)法务风险</p>
<p>需求的综合评分的计算公式如下</p>
<p><img src="https://wulc.me/imgs/Demand_screening.jpg" height="60%" width="60%"></p>
<p>但是上面的公式其实也只是一个参考值，实际中使用会更加灵活，但是以下的三个基本原则是需要遵守的</p>
<p><strong>1.以综合评分排序</strong>
<strong>2.风险拥有一票否决权</strong>
<strong>3.不要挑战客户</strong></p>
<h3 id="产品设计">产品设计</h3>
<p>在产品设计环节，最常见的产出物就是需求文档，需求文档又常常分为三类:
BRD(Business Requirement Document)、MRD(Market Requirement Document) 和
PRD(Product Requirement Document)，对应着一个产品从调研到执行的过程,
详细区别见下图</p>
<p>课程里重点讲了PRD 的一些撰写规范，可总结为 3+2+1 个基本要素</p>
<p><img src="https://wulc.me/imgs/PRD.jpg" height="60%" width="60%"></p>
<p>此外，产出文档还需要遵循“<strong>0123 原则</strong>”</p>
<ul>
<li>0: 不需要说明或帮助</li>
<li>1: 一看就会</li>
<li>2: 两秒等待时间</li>
<li>3: 三步以内的操作</li>
</ul>
<h3 id="产品研发">产品研发</h3>
<p>这部分课程里没有详细展开，商业产品经理在这个过程里需要做的应该就是明确开发进度，确保开发进度正常</p>
<h3 id="发布前验证">发布前验证</h3>
<p>这里指的验证就是常见的 ab
小流量实验，基本上有两种模式：圈流量与圈客户，也就是流量侧实验和用户侧实验</p>
<p>用户侧实验也可以分为两种 1. 随机圈客户，不需要客户参与 2.
圈指定客户的实验，需要客户的强参与</p>
<h3 id="上线运营">上线运营</h3>
<p>产品上线后需要和运营联动，扩大产品的覆盖面；常见的手段有以下三个</p>
<p>1.产品宣传 2.产品培训 3.运营激励</p>
<p>产品宣传是将产品披露给用户和相关的运营人员，让他们知道有这么一个产品,
常见有如下手段</p>
<p><img src="https://wulc.me/imgs/Product_promotion.jpg" height="60%" width="60%"></p>
<p>产品培训是教导客户使用这个产品，需要注意从客户视角去看进行这个过程，即要思考能给客户带来什么价值</p>
<p><img src="https://wulc.me/imgs/Product_presentation.jpg" height="60%" width="60%"></p>
<p>运营激励常见的手段有以下2种</p>
<p>1.业绩下发: 即跟业绩强绑定 2.活动激励：申请奖金当做活动的激励</p>
<h2 id="小结">小结</h2>
<p>综上，课程主要讲了以下四个部分的内容，各部分重点如下</p>
<ul>
<li>商业产品定义及切入
<ul>
<li>商业产品定义的三个要素，前向收费和后向收费模式</li>
<li>从能把用户留住后才启动商业化，三个量化条件</li>
<li>从客户需求和平台资源梳理切入商业化</li>
</ul></li>
<li>商业产品经理
<ul>
<li>肩负产品经理和 seller 两种职责</li>
<li>修炼方法论：明确产品定位、会讲故事、用户思维、善用监控表</li>
</ul></li>
<li>有效的商业产品需求
<ul>
<li>需求分析：明确需要为哪些人解决哪些问题，需要换位思考(平台思维与客户思维)</li>
<li>数据分析：找到核心指标，读指标需要有对比值，公式拆解指标，多角度分析(货源和客源)</li>
<li>竞品调研：4 个问题，what、why、whether、how</li>
</ul></li>
<li>商业产品从 0 到 1
<ul>
<li>需求分析(见上)</li>
<li>需求筛选：关注 roi、客户接收程度和法务风险；3 条基本原则</li>
<li>产品设计：3种类型的需求文档，0123 的产出原则</li>
<li>产品研发：把控进度</li>
<li>产品发布验证：即 ab 实验，可分为流量侧和客户侧</li>
<li>产品上线后运营：产品宣传、产品培训和运营激励</li>
</ul></li>
</ul>
<p>总体的脑图如下</p>
<p><img src="https://wulc.me/imgs/Commercial_products.png" height="100%" width="100%"></p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>《Smart Pacing for Effective Online Ad Campaign Optimization》阅读笔记</title>
    <url>/2019/10/03/%E3%80%8ASmart%20Pacing%20for%20Effective%20Online%20Ad%20Campaign%20Optimization%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>《<a href="https://arxiv.org/abs/1506.05851">Smart Pacing for
Effective Online Ad Campaign Optimization</a>》是 Yahoo 在 2015
发表的一篇关于 budget pacing 的论文，与之前写过的 <a
href="http://wulc.me/2018/10/25/%E3%80%8ABudget%20Pacing%20for%20Targeted%20Online%20Advertisements%20at%20LinkedIn%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">Budget
Pacing for Targeted Online Advertisements at LinkedIn</a>
相似，目标也是把预算均匀花完，但是除了这个目标，这篇论文还提出了在预算均匀花完的基础上如何保成本的方法，算是一个多目标优化了。在离线环境和真实环境验证了方法的有效性，是实践性较强的一篇文章，值得一看。</p>
<span id="more"></span>
<h2 id="背景">背景</h2>
<p>预算控制的做法目前可分为两大流派：Probabilistic throttling 和 Bid
modification，其中 Probabilistic throttling 通过一个概率值(下图中的
Pacing Rate)来决定是否计划参竞来控制预算花费速率，而 Bid modification
则通过直接改价的方式来控制花费速率。两种方式的简单区别如下图所示，</p>
<figure>
<img
src="https://wulc.me/imgs/ProbabilisticThrottilingVSBidModification.png"
alt="two methods" />
<figcaption aria-hidden="true">two methods</figcaption>
</figure>
<p>本文使用的方法属于第一种方式即 Probabilistic
throttling，文章说这么做主要原因有以下三个</p>
<ol type="1">
<li>Probabilistic throttling 是直接影响 budget 花费的速度，而 Bid
modification 则是通过改变 win rate 间接达到影响 budget
花费的速度的，<strong>这种方式有可能导致 budget
花费波动较大</strong></li>
<li>bid
landscape(即广告投放中的一些统计信息，能够反映投放的竞争情况，更详细可参考
<a
href="https://developers.google.com/adwords/api/docs/guides/bid-landscapes">Bid
Landscapes</a> 和 <a
href="https://zhuanlan.zhihu.com/p/32664649">DSP的bidding算法</a>)
一般会随着时间变化而变化；以上两点使得通过 Bid modification 来达到
budget pacing 比较困难</li>
<li>使用 Probabilistic throttling 时能够将 pacing control 与 bid
optimization 解耦，能够分别进行优化</li>
</ol>
<p>虽然文章是这么列出这三点优点，但是笔者觉得其中有个很大的问题：就是<strong>不进行
bid modification 时, 假如当前的 bid 太小，即使 pacing rate 调到了 1
也拿不到任何的 impression时 预算岂不是花不出去？</strong></p>
<p>文章提到说 bid 有单独的一个 bid optimization module
也许能解决这个额问题，但是并没有详细展开这个 module
是如何工作的，是否能够解决上面的问题。</p>
<p>这篇 paper 以及 Budget Pacing for Targeted Online Advertisements at
LinkedIn 都是通过 Probabilistic throttling 进行 budget pacing 的，而通过
bid modification 进行的 budget pacing 的 paper
也不少，可以参考以下两篇</p>
<ul>
<li><a
href="http://theory.stanford.edu/~za/AdDelivery/ec224-abrams.pdf">Optimal
delivery of sponsored search advertisements subject to budget
constraints</a></li>
<li><a
href="http://wwwconference.org/www2007/papers/paper089.pdf">Dynamics of
bid optimization in online advertisement auctions</a></li>
</ul>
<h2 id="算法流程">算法流程</h2>
<p>这部分主要描述文章是如何对问题进行建模和近似求解，主要思想是对一个计划的不同
request 分层（根据ctr，cvr 等），在不同的分层采用不同的 pacing
rate；并且根据实时的花费效果调整 pacing
rate，根据是否需要优化效果，算法又分成了 Campaigns without Performance
Goals 和 Campaigns with Performance Goals</p>
<h3 id="问题建模">问题建模</h3>
<p>文章里主要解决两大类问题，<strong>第一类是只让计划均匀花完预算即可，第二类则需要在预算均匀花完基础上保住点击成本(eCPC)</strong>,
对应的方法在文章中称为 Campaigns without Performance Goals 和 Campaigns
with Performance Goals，下面会分别介绍。</p>
<p>文章约定了一些符号以便对问题进行建模</p>
<ul>
<li><span class="math inline">\(r\_i\)</span>: 在第 <span
class="math inline">\(i\)</span> 个请求参竞的概率，就是本文描述的 pacing
rate, <span class="math inline">\(s\_i \sim Bern(r\_i)\)</span>
则表示是否参竞这个事件</li>
<li><span class="math inline">\(w\_i\)</span>：赢得第 <span
class="math inline">\(i\)</span> 个请求的概率</li>
<li><span class="math inline">\(c\_i\)</span>: 赢得第 <span
class="math inline">\(i\)</span> 个请求的 cost</li>
<li><span class="math inline">\(p\_i\)</span>: 在第 <span
class="math inline">\(i\)</span> 个请求能带来用户点击等行为的概率，<span
class="math inline">\(q\_i \sim Bern(p\_i)\)</span>
则表示是否带来点击这个事件</li>
</ul>
<p>通过上述符合可定义</p>
<ul>
<li><p><span class="math inline">\(C = \sum\_i s\_iw\_ic\_i\)</span>
为计划的总 cost</p></li>
<li><p><span class="math inline">\(P = \frac{C}{\sum\_i s\_i w\_i
q\_i}\)</span> 为计划的 performance,
即成本（如点击成本，转化成本等）,文中描述为 eCPC 即点击成本</p></li>
</ul>
<p>此外，计划在一天的总预算 <span class="math inline">\(B\)</span> 和总
cost <span class="math inline">\(C\)</span> 都会被划分到 K
个时间片内，以此来度量 budget pacing 的效果；即 <span
class="math inline">\(B = \sum\_{t=1}^{K}B^{(t)}\)</span>， <span
class="math inline">\(C = \sum\_{t=1}^{K}C^{(t)}\)</span>，则 budget
pacing 的 error 定义如下</p>
<p><span class="math display">\[\Omega(B, C) =
\sqrt{\frac{1}{K}\sum\_{t=1}^{K}(C^{(t)}-B^{(t)})^2}\]</span></p>
<p>则对第一类问题即只需要 pacing 预算的问题文章建模如下</p>
<p><span class="math display">\[
\min\_{r\_i} P \\\
s.t\quad C = B, \Omega(C, B) \le \epsilon
\]</span></p>
<p>上面的 <span class="math inline">\(\epsilon\)</span> 表示可容忍的
pacing 误差，总体表示在满足预算均匀花完时最小化成本即 <span
class="math inline">\(P\)</span></p>
<p>上面建模中一个值得注意问题是<strong>最小化成本是否合理</strong>？由于文章是
DSP
视角出发进行建模的，从仅考虑广告主的利益角度来说，最小化成本是合理的；但是对于一个完整的广告系统即
SSP，ADX 和 DSP 都在同一个平台时，这并不适用；如微信、抖音、微博等 app
的广告，SSP、ADX 和 DSP 往往都由这个 app
所在的公司运作，如果一味的最小化成本会损害平台的利益，因此<strong>更合理的做法是尽可能让广告主的真实成本与其预期成本接近</strong></p>
<p>而对于第二类不仅需要 pacing 预算同时需要保证 performance
的问题，文章建模如下</p>
<p><span class="math display">\[
\min\_{r\_i} \Omega(C, B) \\\
s.t\quad P \le G,  B-C \le \epsilon
\]</span></p>
<p>上面的 <span class="math inline">\(G\)</span>
表示广告主的目标成本，其他符号含义与前面描述一致，表示在广告主成本不超和预算花费不超的情况下，让预算更
pacing 地花完。</p>
<h3 id="问题求解">问题求解</h3>
<p>文章对两种问题提出了两种上面建模，但是在实际求解时并没有对上面这两个最优化问题进行求解，而是通过启发式方法(heuristics)近似求解这个问题,
这个启发式方法其实就是一个控制算法，
而至于<strong>为什么启发式方法能够近似求解上面的最优化问题，文章并没有说明</strong>。</p>
<p>文章的一个亮点是<strong>对一个广告计划的所有 requests
做分层，分层的依据是 request 在这个计划的 ctr</strong>，而不同的 pacing
rate 是不一样的，当一个 request 到来的时候，先判断这个 request
属于哪一个层，然后再取出这个层对应的 pacing rate 作为最终的 pacing
rate；<strong>ctr 越高的层，其对应的 pacing rate 就越大</strong></p>
<p>而每个层的 pacing rate
会在固定时间间隔进行调整，调整的方法就是下文要介绍的两个控制算法。</p>
<h4 id="campaigns-without-performance-goals">Campaigns without
Performance Goals</h4>
<p>这部分的控制算法针对的问题是第一类问题即只需要保证 budget 被
pacin'g</p>
<p>根据上面的分层方法，假设每个广告计划的所有 requests 会被分成 <span
class="math inline">\(L\)</span> 层，则在第 t-1 个时间片内各层的 pacing
rate 记为 <span class="math inline">\(r^{(t-1)} = (r\_1^{(t-1)},
r\_2^{(t-1)}...r\_L^{(t-1)})\)</span>, 且各层的 cost 记为 <span
class="math inline">\(c^{(t-1)} = (c\_1^{(t-1)},
c\_2^{(t-1)}...c\_L^{(t-1)})\)</span></p>
<p>前面提到一天的总预算 <span class="math inline">\(B\)</span>
会根据时间片划分成 <span class="math inline">\(K\)</span> 份小预算，即
<span class="math inline">\(B = (B^{(1)}, B^{(2)}....B^{(K)})\)</span>,
但是实际花费中不能保证每个时间片的 cost
都刚好达到分配的预算值，因此<strong>如果前面的时间片中出现了少投或超投情况，就要把少投或超投那些部分均摊到后面的时间片中</strong>，所以每个时刻的预算需要根据前面的花费来调整，记的<strong>经过调整的预算为
<span class="math inline">\(\hat{C}^{(t)}\)</span></strong>，则 <span
class="math inline">\(\hat{C}^{(t)}\)</span> 可表示为</p>
<p><span class="math display">\[\hat{C}^{(t)} = B^{(t)} + \frac{B\_m -
\sum\_{i=t}^KB^{(i)}}{K-m}\]</span></p>
<p>上式中的 <span class="math inline">\(B\_m\)</span> 表示经过了 <span
class="math inline">\(m\)</span> 个时间片后剩余的实际预算，分母 <span
class="math inline">\(B\_m - \sum\_{i=t}^KB^{(i)}\)</span>
表示当前预算花费是否超过了预期(&lt;0)或者不满足预期(&gt;0)，并通过分母均摊到后面的
<span class="math inline">\(K-m\)</span> 个时间片中。</p>
<p>则调整 <span class="math inline">\(L\)</span> 个的 pacing rate
的控制算法如下图所示，图中的 <span class="math inline">\(R =
\hat{C}^{(t)} - C^{(t-1)}\)</span>, 表示<strong>如果按照前一时间片的
pacing rate 即 <span class="math inline">\(r^{(t-1)}\)</span>
投放时，当前时间片的预算 <span
class="math inline">\(\hat{C}^{(t)}\)</span> 能否花完</strong>。则当
<span class="math inline">\(R &gt; 0\)</span> 时，需要提高当前时间片的
pacing rate，反之需要降低 这一时间片的 pacing rate</p>
<figure>
<img src="https://wulc.me/imgs/AdjustWithoutPerformanceGoal.png"
alt="AdjustWithoutPerformanceGoal" />
<figcaption aria-hidden="true">AdjustWithoutPerformanceGoal</figcaption>
</figure>
<p><strong>上面的算法认为 pacing rate 的大小即 <span
class="math inline">\(r^{(t)}\)</span> 与实际的 cost 即 <span
class="math inline">\(c^{(t)}\)</span> 是成正比的，因此调整 pacing rate
也会根据 cost 的变化比例来调整</strong></p>
<p>除此之外，上面算法还有几点细节需要注意</p>
<ol type="1">
<li><span class="math inline">\(l&#39;\)</span> 层表示pacing rate
为非0的最小的层</li>
<li>当需要提升 pacing rate 时，是从第 <span
class="math inline">\(L\)</span> 层到 <span
class="math inline">\(l&#39;\)</span> 层进行的；而需要降低 pacing rate
时，是从第 <span class="math inline">\(l&#39;\)</span> 层到第 <span
class="math inline">\(L\)</span> 层进行的，其目的都是<strong>优先提升
ctr 高的层的 pacing rate，优先降低 ctr 低的层的 pacing
rate，从而达到上面最小化成本的目的</strong></li>
<li>trial rate 的目的<strong>令 pacing rate 非 0
的最小层的下一层以一个很小的 pacing rate 进行参竞（pacing rate
会随着层数增加而增加）</strong>，目的是后面预算花费加速做准备， trail
rate在这里是一个超参，是一个很小的值，后面会介绍该如何选取</li>
</ol>
<h4 id="campaigns-with-performance-goals">Campaigns with Performance
Goals</h4>
<p>这部分的控制算法除了要保证 budget 被 pacing
花完，还要保证成本小于预设的成本；而每一层的成本在这里记为 <span
class="math inline">\(e = (e\_1, e\_2...e\_L)\)</span>, 其中 <span
class="math inline">\(e\_i = \frac{CPM}{1000*p\_i}\)</span></p>
<p>考虑了成本的算法在主要在上面的算法上增加了一个 ExpPerf
函数，用于计算当前所有层的联合期望成本，该函数的定义如下</p>
<p><span class="math display">\[ExpPerf(c^{(t-1)}, r^{(t-1)}, r^{(t)},
e, i) = \frac{\sum\_{j=i}^{L} \frac{c\_j^{(t-1)}
r\_j^{(t)}}{r\_j^{(t-1)}}}{\sum\_{j=i}^{L} \frac{c\_j^{(t-1)}
r\_j^{(t)}}{r\_j^{(t-1)}e\_j}}\]</span></p>
<p>上面的式子中的分子可理解为各层在当前时间片的 cost
之和，分母可理解为各层在当前时间片的点击数之和，因此总体就是当前的时间片所有层的联合期望成本</p>
<p>则成本约束的 budget pacing 控制算法过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/AdjustWithPerformanceGoal.png"
alt="AdjustWithPerformanceGoal" />
<figcaption aria-hidden="true">AdjustWithPerformanceGoal</figcaption>
</figure>
<p>如果计算出当前的联合期望成本大于目标成本时，会<strong>从第 1 层到第 L
层逐渐减少每层的 pacing rate</strong>，而这分为两种情况</p>
<ol type="1">
<li>如果当前层到第 L 层的联合期望成本大于目标成本，则当前层的 pacing
rate 会直接置为 0；</li>
<li>如果当前层到第 L 层的联合期望成本不大于目标成本，当前层的 pacing
rate 会根据上面算法第 7
行来调整，然后算法就终止了，根据文章描述其含义是<strong>调整当前的层使得总体的期望成本达到目标的期望成本</strong>；</li>
</ol>
<p>但是文章并没具体解释第七行的公式的含义，比如说如分母为0时，<span
class="math inline">\(r\_{l}^{(t)}\)</span> 岂不是变为无穷大？</p>
<h3 id="超参选取">超参选取</h3>
<p>上面提过的算法的流程中涉及到多个超参数，如层数 <span
class="math inline">\(L\)</span> 以及 trial
rate，下面介绍如何选取这两个超参</p>
<p>对于一个新计划，决定其层数 <span class="math inline">\(L\)</span>
的方法如下，首先找到与这个新计划最相似的老计划 <span
class="math inline">\(a\)</span>, 并找到这个老计划最合适的 pacing rate
<span class="math inline">\(r\_G\)</span>, 则新计划的层数可计算为<span
class="math inline">\(L = \lceil \frac{1}{r\_G} \rceil\)</span>,
计算的逻辑其实就是要找到这个计划最合适 pacing rate 粒度对应的层数。</p>
<p>一旦层数决定后，在第一个时间片内会每个层都会通过 <span
class="math inline">\(r\_G\)</span>
初始化，在第一个时间片积累了数据后，后面会根据上面提到的算法调整各层的
pacing rate。</p>
<p>前面提到 trail rate 的目的令 pacing rate 非 0
的最小层的下一层以一个很小的 pacing rate 进行参竞，因为 pacing rate
会随着层数增加而增加，本来这一层的 pacing rate 应该是 0
的，但是这里给了一个很小的 trail
rate，目的是为了让后面加快预算花费做准备。其设置方法如下</p>
<p>将当前时间片的预算 <span class="math inline">\(\hat{C}^{(t)}\)</span>
划分一小部分，记为 <span class="math inline">\(\lambda\)</span>(e.g.
<span class="math inline">\(\lambda\)</span> = 1%), 假设当前层为第 <span
class="math inline">\(l\)</span> 层，则其 trail rate = <span
class="math inline">\(r\_l^{(\*)} ×\frac{\lambda
×\hat{C}^{(t)}}{c\_l^{(\*)}}\)</span> ，而 <span
class="math inline">\(r\_l^{(\*)}\)</span> 和 <span
class="math inline">\(c\_l^{(\*)}\)</span> 则是 <span
class="math inline">\(l\)</span> 层的历史pacing rate 和 cost。</p>
<h2 id="实验效果">实验效果</h2>
<p>文章对提出的方法进行了AB实验评估，并与论文 Budget Pacing for Targeted
Online Advertisements at LinkedIn
中的方法进行了比较，预算的花费时间定义为一天，而时间片定义为15分钟；超参的值为
<span class="math inline">\(r\_G = 0.01\)</span> 以及 <span
class="math inline">\(\lambda = 1\%\)</span></p>
<p>考察的指标主要有三个 1）performance 2）budget spending 3）spending
pattern</p>
<p>而作为对比的 baseline
方法也是使用本文的方法，只是只有一层，下面是选取的三个计划进行 AB
测试的效果，实验组的层数为 8；其中计划 1 和 3 是没有 performance
目标也就是成本约束的，而计划 2 的 ecpc
为2.5，从结果来看也能较好地满足成本约束</p>
<figure>
<img src="https://wulc.me/imgs/SmartPacingExp1.png" alt="exp1" />
<figcaption aria-hidden="true">exp1</figcaption>
</figure>
<p>除此之外，还对比了两种方法在保证成本约束的效果，结果如下图所示，从结果来看，分层处理后能够有效降低成本，同时花费不变</p>
<figure>
<img src="https://wulc.me/imgs/SmartPacingExp2.png" alt="exp2" />
<figcaption aria-hidden="true">exp2</figcaption>
</figure>
<p>同时文章与另外一篇论文 Budget Pacing for Targeted Online
Advertisements at LinkedIn 中的 budget pacing
方法进行了对比，结果如下所示</p>
<figure>
<img src="https://wulc.me/imgs/SmartPacingExp3.png" alt="exp3" />
<figcaption aria-hidden="true">exp3</figcaption>
</figure>
<p>从结果来看，相比于 Budget Pacing for Targeted Online Advertisements
at LinkedIn 中的方法，这篇文章调节 budget
的花费得更为平缓，同时成本的控制也更好，因为 Budget Pacing for Targeted
Online Advertisements at LinkedIn 论文中的方法没有考虑成本问题。</p>
<h2 id="工程实现">工程实现</h2>
<p>本文的方法的工程实现架构如下图所示，架构不复杂，左边的部分通过
message queue(如 kafka) 搜集后验数据，用于更新 in-memory data source
中各层的 pacing rate；右边的 Controller 则会利用 in-memory data source
中的 pacing rate 进行 budget pacing</p>
<figure>
<img src="https://wulc.me/imgs/SmartPacingArchitecture.png"
alt="architecture" />
<figcaption aria-hidden="true">architecture</figcaption>
</figure>
<p>因为 pacing rate 是存储在内存中，存在丢失问题，因此会根据 message
queue 中的日志进行恢复，其原理看起来跟 redis 的 AOF 模式恢复类似。</p>
<h2 id="小结">小结</h2>
<p>这篇文章主要提出了两个基于Probabilistic throttling的算法用于解决
budget pacing 问题，
第一个算法仅解决了如何让预算更平缓地花完，第二个算法在第一个算法的基础上，不仅让预算平缓花完，还能保成本。文章中的方法的一个亮点在于根据
ctr 等指标将 request 分层，不同的层采用不同的 pacing rate，从而能够针对
ctr 高的 request 给予更高的 pacing rate，而这也是文章中的算法能够优化
performance 的原因。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>《认知红利》阅读笔记(1)-概念重塑</title>
    <url>/2021/08/22/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(1)-%E6%A6%82%E5%BF%B5%E9%87%8D%E5%A1%91/</url>
    <content><![CDATA[<p>最近在看《<a
href="https://book.douban.com/subject/34793488/">认知红利</a>》，提到认知，笔者第一时间想到的是<a
href="https://www.zhihu.com/question/265801661">认知的四个阶段</a>：不知道自己不知道
-&gt; 知道自己不知道 -&gt; 知道自己知道 -&gt;
不知道自己知道；以及《三体》里那句有名的
“弱小和无知不是生存的障碍，傲慢才是”，而笔者觉得傲慢的原因正是因为“不知道自己不知道”且不愿意去了解，如同井底之蛙一样的看不到更先进的技术，一如闭关锁国的清末，三体里被水滴几乎团灭的人类太空舰队。</p>
<p>回到这本书，可以说是在解决“不知道自己不知道”的问题，而且书里不仅提供了鸡汤，还提供了勺子(即方法论)。虽然这本书在豆瓣上褒贬不一，诟病之处无非是这本“借鉴”了很多其他作品；但是对笔者这种看不懂那些晦涩的大部头、时间不多的“打工人”来说，也不失为一种较好的选择，因为这本书可以说是对其他一些作品里的内容的提炼。整本书可分为两大部分：<strong>概念重塑和大脑升级</strong>，前者主要是概念重构，后者则侧重方法论。本文主要与概念重塑相关，而且只记录了对笔者而言印象比较深刻的观点，推荐读一下原书。</p>
<span id="more"></span>
<p>关于概念重塑这部分，书中主要分为了三个部分：重新理解财富、重新理解自我和重新理解世界。</p>
<h2 id="重新理解财富">重新理解财富</h2>
<h3 id="注意力是最宝贵的财富">注意力是最宝贵的财富</h3>
<p>书里在这里的观点是<strong>注意力是与生俱来的、可以自主控制的并且还能拥有生产力的财富</strong>，且只有通过注意力，才能更好地利用身体、时间创造出金钱。(笔者认为虽然有些牵强，但是注意力的确很重要)</p>
<p>注意力是宝贵的，但是往往被花费在以下地方（下面引用的例子摘自书里，可能不完全准确，但是核心观点还是<strong>需要有保护注意力，不被无意义地消耗的意识</strong>）</p>
<p><strong>1.被浪费</strong></p>
<blockquote>
<p>有些人，走在大街上看到一群人围在一起，他就会特别好奇，想过去看一下发生了什么，结果一看就是半小时......
还有些人，特别喜欢关注一些明星的动态，比如某某歌手最近参加了一个大赛，竟然拿了一个冠军，你特别不开心，唱得那么差，为什么还能得奖呢?一定有黑幕!还比如，谁和谁最近爆出了地下恋情，你特别吃惊，心想他们是从什么时候开始的啊，我怎么不知道，然后就去百度疯狂地搜索......
还有些人，整天喜欢琢磨各种国家大事，比如南海局势的下一步对策应该是什么......我国的对外贸易政策该如何改善......分分钟你会觉得这哥们儿在公司干销售，真的是太屈才了!</p>
</blockquote>
<p><strong>2.被收割</strong></p>
<blockquote>
<p>在美国有一本畅销很多年的书，书名就叫作《<a
href="https://book.douban.com/subject/30216368/">注意力商人</a>》，书中列举了一系列的方法论，目的就是要想尽一切办法把你吸引过来，并且留住你，让你看上瘾!比如越低俗的内容，越反常的谣言，越可怕的消息......越能吸引你的注意力!
真不真不重要，对不对不重要，你看不看才重要!</p>
</blockquote>
<p><strong>3.被利用</strong></p>
<p>常见的推荐系统,
广告系统本质上就是在做的就是这件事情，其实也可以算在被收割里面；因为一些大厂之间的竞争其实就是在抢占用户时间，收割用户注意力</p>
<blockquote>
<p>在互联网上的任何注意力投放，几乎都会被完整地记录下来。通过对你的注意力轨迹进行大量的分析，商家们就能够更了解你，知道你更愿意把注意力花费在什么样的内容上，那么商家就可以针对你投放更多这方面的内容，继续收割你更多的注意力!
或者，它们还能把这个分析结果直接卖给其他商家，告诉它们你爱看这些内容，那么其他商家也
可以用这些定向内容去更高效地收割你的注意力......</p>
</blockquote>
<p>那注意力应该被消耗在什么地方?</p>
<p><strong>1.聚焦在能产生价值的事情上</strong></p>
<p>应该将所有精力投入到当前的事情上，进入<a
href="https://zh.wikipedia.org/wiki/%E5%BF%83%E6%B5%81%E7%90%86%E8%AB%96">心流模式</a>，具体方法在书里的“大脑升级”部分有介绍。</p>
<p><strong>2.人际关系，特别是亲密关系</strong></p>
<p>即工作之余，千万别忽略了对家人的关注。</p>
<p><strong>3.寻找新的趋势</strong></p>
<p>趋势其实就是大环境，其重要性无需赘述，具体方法论会在本文重新理解世界中讲述</p>
<p><strong>4.自我成长</strong></p>
<p>这是最重要的一点:除了上面说这些方向之外，你应该把所有的注意力，都花在自我成长上!</p>
<h3 id="时间商人的四种模式">时间商人的四种模式</h3>
<p>上面强调了注意力是宝贵的，但是对于绝大多数人来说，最终换取金钱的媒介还是时间，书里认为我们都是时间商人，而时间商人往往有以下四种模式。</p>
<p><strong>1.零售时间</strong></p>
<p>上班族、专车司机、兼职快递员等绝大部分职业都可以算作这种模式，这种模式下提高个人收入的方法：提高你的时间单价。</p>
<p>而提升时间单价，撇去市场调整的影响，最重要的还是自身的能力，对于上班族来讲，基本就是<strong>提升自身价值，卖个好价钱</strong>....</p>
<p><strong>2.批发时间</strong></p>
<p>网红、明星、作家等属于这种模式; 边际成本较低</p>
<blockquote>
<p>这些人的高收入，并不是因为他们在“被买断的那个时间段内”产生了这么多的价值，而是因为他们所创造的产品，比如歌曲、电视剧、电影、娱乐节目，甚至是自己的一张照片、一个微笑......都可以通过他们的影响力，被复制成无数多份，然后批发出售
一个明星，有多少人喜欢，就意味着他的作品有多强的“批发能力”。</p>
</blockquote>
<p><strong>3.买卖时间</strong></p>
<p>雇佣工人的老板属于这种模式</p>
<p>企业为什么会花钱请你来工作，而不是老板自己去做，或者找外包? 主要有 2
个原因:
（1）你在某方面更专业（2）你能称为他们的帮手；实际上，这也对应着公司两种类型的人才（1）创造价值的员工（2）提升效率的员工</p>
<p>“买卖时间”的这种方式并不是说就让你去办个公司，然后花点钱买一堆人的时间，再把它们卖出去，这就能赚差价了，如果这么简单，就不会有那么多创业失败的人了</p>
<p><strong>“买卖时间”的本质其实是一个放大器，就是它得先看“你有什么价值”</strong>,
如下是书里的一个例子</p>
<blockquote>
<p>比如你文章写得不错，一篇文章能换来1000元的稿费。但是现在你只有一个人，除了写稿的时间，你还得花时间寻找甲方，沟通需求，还得自己配图、排版，收集各种案例素材......这些得用去你很多时间，所以你一个月真正能用来
写稿子的时间并不多，因此总价值也并不高
这个时候你就可以开始招人来帮助自己了，你可以先找<strong>效率型的人才</strong>，让他帮你节省时间，比如帮你去和甲方沟通需求，给你写好的文章去配图、排版，帮你收集各种需要的案例素材......你只需要专心写文章就可以了。虽然说多请了一个人，看似成本提高了，但是你创造价值的时间变多了，原来一个月只能写10篇文章，现在能写20篇了。那么减去新增的人员工资，总收入反而提高了</p>
<p>你可能又会有新的想法，比如我写的内容既然有那么多人喜欢，为什么不直接运营一个公众号，经营自己的粉丝圈，让内容的价值变得更大呢?当然可以，可是你并不会经营公众号啊，也不知道如何让公众号拥有商业价值，你只会写文章，怎么办?
这个时候你就需要招聘<strong>创造价值的人才</strong>进入团队了，你不需要自己去学如何运营一个公众号，或者学习如何将公众号变现，这些学习成本很高，你直接把这些领域里的牛人招募进团队就可以了，你还是只管写文章......</p>
</blockquote>
<p><strong>4.收时间税</strong></p>
<p>平台是这种模式；就是你并不需要自己去出售时间，而是创造出一个平台，让其他人到你这个平台上来自由交易他们的时间，而你只需要对他们的每一笔交易进行“抽税”即可。</p>
<p>像淘宝、微信、滴滴专车，国外的亚马逊、Facebook、Uber、苹果的AppStore，还有类似证券交易所、赌场都是这种模式</p>
<p>这里需要注意的一点是：<strong>平台是结果，而不是原因</strong>；很多创业者一上来就搞一个大平台，但是即没买家又没卖家，最终可能导致这只是一个空壳子；当然，资本的力量也是非常强大的，烧钱来买用户，然后垄断的例子也是有的。。。。</p>
<p>但书里认为平台真正的价值在于能<strong>对平台上的人“赋能”</strong>；说人话就是需要为用户(包括卖方和买方)创造价值，切实解决用户问题，用户才会买单，这个价值可能是时间单价，可能是效率，可能是安全等</p>
<h3 id="打造复利效应">打造复利效应</h3>
<p>复利是经济学上的一个基本概念，但是传达的思想是：<strong>当你做了事情A，就会导致结果B，而结果B又会加强A，如此不断循环，循环次数越多，A就越强大</strong>；因此针对生活中的很多事情，都可以打造复利效应，书里提出了
3 个步骤</p>
<p><strong>1.找到因果关系</strong></p>
<p>不要自己去摸索着写个因果关系，然后用自己的时间和金钱来验证它是否正确。因为<strong>你的顿悟，很可能只是别人的基本功</strong>，你要学会站在巨人的肩膀上。因此，最高效的方式是去相关领域中，找到那些已经被验证过的结论，或者是一些基本常识，甚至是数学定律来用作“支点”。</p>
<p><strong>2.设计增强循环</strong></p>
<p>说的其实就是B如何反过来增强A；这里又可分为 2 种情况</p>
<p>第一种情况，它们之间天生就有增强循环；如投资
第二种情况，需要补充要素的增强闭环</p>
<p>其中，第二种情况往往是生活中遇到的大部分情况，书里举了如下例子</p>
<blockquote>
<p>在淘宝上，流量越多，销量越高;销量越高排名就越高，因此获得的流量就会越多。可线下门店呢?没有平台给它排名，销量好并不能直接带来流量，怎么办</p>
<p>这个时候，我们就需要在“销售额”和“门店人流”之间，增加一些环节，让它们之间连成一个“增强闭环”:
比如用赚到的钱，开更多的门店；把利润折换成优惠券的形式，发放给老客户</p>
</blockquote>
<p>如果回到更常见的个人问题，即专业能力与被雇佣获得报酬这两者的关系，又该如何增强这个循环呢？</p>
<p><strong>3.重复与耐性</strong></p>
<p>复利效应天然有个缺陷，就是在初期很漫长的一个时间段里，增效都非常低，低到你几乎感觉不到它在增长。当你已经走到50%的位置的时候，甚至怀疑它的存在</p>
<p>这个时候绝大多数人可能会放弃，因为大部分人对于世界的理解度是线性的，但更多情况下，事物却是以漫长的潜伏震荡后爆发突破的形式发展的，如果明确你做的事情是有复利效应时，当你想要放弃的时候，不妨回来看看这张图，找找自己所在的位置，然后你相信，你的未来一定是这样的一条曲线，只是现在还没走到“里程碑”这个位置而已</p>
<p><img src="https://wulc.me/imgs/%E5%A4%8D%E5%88%A9%E6%95%88%E5%BA%94.jpg" height="50%" width="50%"></p>
<h2 id="重新理解自我">重新理解自我</h2>
<h3 id="角色化与去角色化">角色化与去角色化</h3>
<p>人在社会中都会被角色化(或者说标签化)，比如一个人在单位是员工的领导，在家里是孩子的父亲...那么人为什么会被角色化？书里的观点是便于管理和协作，当每个角色都有其规则时，其行为可以被预期，而预判会让协作变得更加高效。</p>
<p>但同时规则也意味着边界和约束，我们忘记了“真实”是什么:看不见真实的自己;看不见真实的
对方; 做产品时也看不见真实的用户。因此，有必要学会去角色化</p>
<p>那么如何去角色化，首先要了解人，梳理将一个人划为了 5
层：<strong>感知层、角色层、资源结构层、能力层、存在感知层</strong>；从外至内，逐步加深</p>
<ol type="1">
<li>感知层：对一个人的第一印象</li>
<li>角色层：对一个人的基本信息的了解（职业、婚否等）</li>
<li>资源结构层: 一个人的财富资源、人脉资源、精神资源等</li>
<li>能力层:
一个人的各种能力，如管理能力、商业能力、沟通能力、专业技能，等</li>
<li>存在感知层: 对自己存在感的定义，即通过什么“刷存在感”</li>
</ol>
<p>这里有几个笔者比较认可的观点</p>
<ul>
<li>每个人在人生初期时的角色都差不多，一开始都是学生，毕业后都是小职员，但是每个人未来能去向哪，成为另一个什么角色，是由你的能力和资源结构决定的</li>
<li><strong>如果你的资源结构和能力不发生改变，那即便是更换了角色，也是在同层次的角色中跳来跳去，甚至还会变得更糟，因为你不进步别人会进步，而随着你年龄的增大，相对价值也就变小了</strong></li>
<li>要找到自身的存在感知层，需要抛开自身当前的角色，设想如果你身上没有这些职位、身份，你想要的到底是什么?
当前是否已经满足了你的预期？当存在感的需求越高，没有被满足的落差越大，痛苦感也就越大</li>
<li>如果你要想和一个优秀的人在一起，并和他建立深度关系，那你就既要懂他真实的快乐，更要懂他真实的痛苦，并且给予他能量，支持他的存在感</li>
</ul>
<p>至此，我们可以问自己一些问题，你与人相处是看到了他的哪个层次:是与他的角色层相处，还是存在感知层?你看自己是看到了哪一层?看到的是自己的角色，还是角色下自己的能力和资源?还是看到了自己的存在感知?</p>
<p>我们要能够意识到，日常生活中你所接触到的大多数人，其实都是“角色化”的，你以为的他，并不一定是真正的他，他今天对你这么说、这么做，或许是完全基于角色化的考量，而非他真正的本意。<strong>你要学会在与人交往的过程中，把“他”和“他的角色”区别对待</strong>。这里作者举了一个产品的例子</p>
<blockquote>
<p>如果你在创业，或者从事着和产品相关的工作，那么更要对你的用户“刮目相看”，你要知道自己到底在为“他”还是为“他的角色”提供产品或者服务。比如各种协同办公、CRM、任务清单等软件就是为用户
的“角色”提供服务的，你就不能加入娱乐功能，不然用户玩开心了老板就不买单了......</p>
</blockquote>
<h3 id="理解问题-6-个层级">理解问题 6 个层级</h3>
<p>原书这部分本来的标题是“你是第几流人才”，但其实也可看做看待问题的 6
个角度，源自 NLP(神经语言程序学)理论</p>
<blockquote>
<p>“NLP理解层次”把对一件事情的理解分成了六个不同的层次，而这
些层次是有高低之分的。</p>
<p>如果你用低维度的视角去看这个问题，可能会感觉它根本无法解决。但当你站在一个更高的维度去看它，它也许就变成了一个很简单的问题，甚至连问题本身也消失了。就像马车的时代，大家都在寻找更快的马，但是当汽车被发明出来之后，这个问题就不存在了，因为马的快慢已经变得无关紧要了。</p>
</blockquote>
<p>笔者在这里简单将这六类人才概括成如下表格,值得注意的是，这里说的每提高一个层次，并不是说就不要下一个层次了，比如有了方法就不需要努力了，而是在原来的基础上，上升了一个思考层次</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">层级</th>
<th style="text-align: left;">别名</th>
<th style="text-align: left;">所处理解层次</th>
<th style="text-align: left;">典型思考模式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">第五流人才</td>
<td style="text-align: left;">怨妇</td>
<td style="text-align: left;">环境</td>
<td style="text-align: left;">都是你们的错!</td>
</tr>
<tr class="even">
<td style="text-align: left;">第四流人才</td>
<td style="text-align: left;">行动派</td>
<td style="text-align: left;">行动</td>
<td style="text-align: left;">我还不够努力!</td>
</tr>
<tr class="odd">
<td style="text-align: left;">第三流人才</td>
<td style="text-align: left;">战术家</td>
<td style="text-align: left;">能力</td>
<td style="text-align: left;">方法总比问题多!</td>
</tr>
<tr class="even">
<td style="text-align: left;">第二流人才</td>
<td style="text-align: left;">战略家</td>
<td style="text-align: left;">BVR(信念/价值观/规条)</td>
<td style="text-align: left;">什么才是更重要的?</td>
</tr>
<tr class="odd">
<td style="text-align: left;">第一流人才</td>
<td style="text-align: left;">觉醒者</td>
<td style="text-align: left;">身份</td>
<td style="text-align: left;">因为我是×××，所以我会×××</td>
</tr>
<tr class="even">
<td style="text-align: left;">顶级人才</td>
<td style="text-align: left;">领袖/伟人</td>
<td style="text-align: left;">精神/使命</td>
<td style="text-align: left;">人活着就是为了改变世界!</td>
</tr>
</tbody>
</table>
<p>第五流的人才在问题发生时，首先会把问题归结到“<strong>因为环境的不好</strong>”，这类型的人只要一与他们接触，就会感受到这“满满的负能量”，感觉这人世间的不幸都被他们碰巧遇上了，命运多舛得不行；书里给出的一些典型的思考模式如下</p>
<blockquote>
<p>工作不顺利，是因为领导是个蠢蛋......
没有晋升机会，是因为公司的办公室政治严重，没有好的晋升机制......
房子太贵买不起，都是因为那些黑心炒房团、政府调控不到位、没有一个富爸爸......
....</p>
</blockquote>
<p>第四流人才在问题发生的时候，首先会把问题归结到“<strong>因为我的努力还不够</strong>”,这类人往往没有意识到<strong>努力是成功的一个必要条件，但远远不是充分条件</strong>，也就是说用力的方向要正确，书里给出的一些典型的思考方式如下</p>
<blockquote>
<p>都一年没涨工资了，今晚开始多加1个小时的班!
女朋友为什么最近对我变得冷淡了?我要多发些消息，多打些电话去关心她!
公司业绩变差了?那一定是我睡觉睡得太多了，明天开始不睡觉了! ....</p>
</blockquote>
<p>第三流人在问题发生的时候，首先会把问题归结到“<strong>因为我的能力不足</strong>”，然后在“能力”这个层次里去寻找更好的“方法”来解决问题。</p>
<p>这类人有非常强大的学习能力和应用能力，能把学习到的知识，转化为可操作的方法，进而改善效率，解决问题。他们明白，<strong>任何问题都不是孤立存在的，一定有人曾经遇到过，并且已经有更好的解决办法了，只是我还不知道;我不应该在黑暗中独自前行，去重新发明轮子，也许我的顿悟，只是别人的基本功!
我应该要站在巨人的肩膀上，学习更成熟的经验和方法，然后再来解决这个问题。</strong>一些典型的思考方式如下</p>
<blockquote>
<p>线下门店生意不好，是因为我的经营模式太陈旧，我需要学习新的方法......比如，可以通过社群经济的方式来降低我的获客成本，提高客户复购率......
和男朋友关系处理不好，一定是我的沟通能力有问题，我要去学习能改善亲密关系的沟通技巧，比如先看两本沟通方面的畅销书:《关键对话》《幸福的婚姻》......
以前我是做业务的，现在刚成为部门经理，团队业绩下滑，一定是我的管理能力有问题，我以前根本没有系统学习过管理的方法，我得去报个MBA，从“古狄逊定理”开始学起......
...</p>
</blockquote>
<p>第二流人才在问题发生的时候，可能并不会马上给出解决方案，而是会先去思考:这些很可能是表面问题，还有没有藏在这些问题下面的更重要的问题?<strong>如果说“能力层”是做解答题的能力，“BVR层”就是做选择题的能力</strong>，什么可以做，什么不可以做，什么更重要，什么可以忽略不管</p>
<p>那什么是BVR？</p>
<ul>
<li><strong>B(Believe):信念</strong>，即你相信什么是对的?
你相信这个世界应该是怎么样的?往大了说可以是世界观，往小了说就是一个个概念。</li>
<li><strong>V(Value):价值观</strong>，即当出现A/B选择的时候，你认为A和B哪个更重要?</li>
<li><strong>R(Rule):规条</strong>，你做人做事的原则是什么？</li>
</ul>
<p>书里还是举了线下门店业绩出现下滑的例子</p>
<blockquote>
<p>当门店业绩出现下滑，可能的原因有很多，可以先做个简单的分类，比如可以分成:
成本问题:房租涨价，库存积压，已投入的装修成本，进货成本高于淘宝售价......
团队问题:员工士气低落，引发离职......
市场问题:客流减少，人们现在喜欢在网上购物，网上商品的售价更便宜......
营销问题:目前门店没什么营销方式，就是开门迎客;
渠道问题:线下门店是目前唯一的渠道。</p>
<p>如果是处在“能力层”的人，他就会胡子眉毛一把抓，针对这些问题提出各种解决办法，比如针对团队问题，他可能会给出一整套员工激励方案;面对营销问题，他可能会增加户外广告，再运营一个公众号;而面对渠道单一的问题，他就会建议也去开个淘宝店......</p>
<p>如果是处在“BVR层”的人会思考，那么多问题，其中到底哪个才是最关键的问题?经过一番思考，他画出了一个关系图
<img src="https://wulc.me/imgs/BVR_graph.jpg" height="50%" width="50%">
原来，一切的罪魁祸首，都是因为互联网的连接效率变高，导致了原本市场上的交易结构发生了变化，淘宝店家短路掉了中间的总代、省代、区代......等等这些价值传递的环节，让商品可以用更短的距离来到消费者的面前，所以价格才能那么低。由此导致了后面的一连串反应......
因此，可以制定出如下战略 (1)短路经济:
既然淘宝店家能短路掉中间的环节，我实体店为什么 不可以? (2)体验经济:
增强线下门店的体验感</p>
</blockquote>
<p>笔者觉得上面的例子虽然现实指导意义有限，但核心还是希望说明一个问题，那就是要抓住本质的问题去解决。到这里基本是笔者能够理解到的层级了，第一级人才和顶级人才的思维这里就只摘录书里的相关内容了，也许未来的笔者才能理解。</p>
<p>第一流人才，其实就是<strong>明确清楚自己想成为什么样的人(或者说身份)的人才</strong>；因为不同的身份定位，会配套不同的BVR，而BVR决定了你当下的每次选择;
即你的身份层次决定了你的价值判断，进而决定了你的每一次选择。书里在这部分没有给出具体的案例，说的东西有点大而宽，也许是到了这个层级的就是这样？</p>
<blockquote>
<p>联系前面说的角色，可能我们会问：“角色”和“身份”有什么不同?答案是:角色是被动的，是别人给你的;身份是主动的，是你自己想成为的。
前面说的“去角色化”，就是想让你突破角色的束缚，获得一个更“主动”的人生，找到自己的身份层次。因为你身上的“角色”太多，会阻碍你看见自己真实的“身份”。
而当你想清楚自己的身份定位后，就应该围绕它配套相应的BVR，再构建你的能力圈，并做出相应的计划与行动，你就会成为第一流的人才!
处在这个层级的人，能开创出一番自己的事业，设计出令人尖叫的产品，成为上市公司的领军人物。</p>
</blockquote>
<p>顶级人才，所有的思考都围绕着两个字——“<strong>利他</strong>”:我如何选择能够让更多的人获益?如何才能够推动时代的进步?书里在这强调了<strong>理解层次的逐级上升，不能脱离低层次而单独存在高层次</strong>，比如只谈精神理想，而无视自己的身份，更没有相对应的能力和行动</p>
<blockquote>
<p>“精神层”一定要有“身份层”的支撑，换句话说，如果你在身份层想不清楚自己要成为谁，可以试着来到精神层，想想你能为这个世界做些什么;可以不用那么大，哪怕只是在某一方面，能帮助到为数不多的人。
也许这个就能成为你的人生使命，然后再去思考，什么样的身份能够更好地帮你完成这个使命?你就能想清楚身份层次的问题了。</p>
</blockquote>
<p>关于方法论部分，即如何成为顶级人才，书里给的方法不是一级级往上打怪升级，而是直接让自己成为一流人才或者顶级人才，对你的人生做个“<strong>顶层设计</strong>”，从精神层开始往下规划，如下图所示</p>
<p><img src="https://wulc.me/imgs/genius_level.jpg" height="50%" width="50%"></p>
<h3 id="元认知">元认知</h3>
<p>元认知就是你对自己思考过程的认知与理解。其一般模式是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">发生了事件A......</span><br><span class="line">→你有了反应B;</span><br><span class="line">→我为什么会有反应B?反应B是对的吗?</span><br><span class="line">→C好像是更适合的反应;</span><br><span class="line">→于是，你有了反应C。</span><br></pre></td></tr></table></figure>
<p>书里举了如下例子</p>
<blockquote>
<p>当你打开抖音，你发现好多有意思的视频，然后你不断地翻看，结果不知不觉3个小时过去了。这就是没有元认知的状态。</p>
<p>如果你的元认知能力已经被激活了呢?
你还是打开抖音，发现有好多有意思的视频，然后你不断地翻看，但是突然，一个声音进入大脑:“你为什么会不停地翻看?你的注意力
是不是正在被别人收割?”你浑身一颤，于是赶紧关掉抖音，回到了工作当中......</p>
</blockquote>
<p>上面的例子其实是为了说明<strong>大脑也是一个器官，是可以被控制的，而元认知则是大脑的纠错机制</strong>。</p>
<p>因此，元认知有着以下三种重要作用：控制输入、控制大脑、控制输出</p>
<p><strong>1.控制输入</strong>：即控制什么信息要进入大脑，是即时满足还是有价值的知识积累</p>
<p><strong>2.控制大脑</strong>：即控制进入大脑的信息怎么处理，这里提供了三种方法:</p>
<blockquote>
<p>(1)<strong>对无用的信息:丢弃</strong>
知真识假,看多了，自然就知道什么是假的了
先去主动学习大量的正确知识，等累积到一定量之后，你自然就会拥有这双火眼金睛，一眼就能看出某个信息的好坏了。</p>
<p>(2)<strong>对有益的信息:储存</strong>
需要存储的有益的信息可分为以下四大类 a. <strong>概念</strong>:
你对事物的理解，其实就是这本书的上半部分，这个是你理解世界、思考问题的砖瓦。
b. <strong>价值观</strong>:
对事物的正确价值判断，什么是对的，什么是错的，什么是更好的。 c.
<strong>思维方式</strong>: 不同问题的思考方法。 d.
<strong>方法论</strong>: 专项问题的已知最优解法。 结合前面说的理解问题的
6 个层次，可画出下图
<img src="https://wulc.me/imgs/meta_knowledge.jpg" height="50%" width="50%"></p>
<p>(3)<strong>对问题或者任务:处理</strong>
你大脑里可能储存了很多套思考方式，当不同的任务、不同的问题进入大脑之后，你得先判断，它属于哪种问题、什么任务、目的是什么，然后启动不同的“思考方式”“方法论”来处理这些信息</p>
</blockquote>
<p><strong>3.控制输出</strong>：即知行合一，也许你学习过很多时间管理的方法，你也知道它很重要，但是如果你无法调用你的“元认知”，你就无法控制你的大脑，想到却又无法做到，你的焦虑感越来越强</p>
<p>那该如何提升元认知的能力？书里也提供了三种方法：刻意练习，经常反思和练习冥想</p>
<p><strong>1.刻意练习</strong></p>
<p><strong>即使是 10000
小时定律的练习也需要借助套路，套路就是一些储存在能力层里的“思维方式”和“方法论”，</strong>它们是已经被前人验证为做某件事更高效的方式方法，掌握了它们，你就掌握了做某件事情的“诀窍”。比如帮助你提高思维能力的工具:金字塔原理、MECE法则、5W2H、SCQA、二维四象限等；帮助你提高决策能力的工具:KT法、概率决策树、麦穗理论等。</p>
<p>但这些方法你仅仅知道是没用的，当新问题出现时，还是会习惯性地用原来的方式去思考；这时候要通过元认知强迫自己去使用这种方法，虽然会不习惯、有点别扭，但坚持用这种方式“刻意练习”，你大脑中的某些特定区域就会不断被强化，久而久之，你某方面的技能就会甩开普通人一条大街，元认知能力也因此得到了加强。</p>
<p><strong>2.经常反思</strong></p>
<p>每天晚上你可以花半个小时的时间，对今天遇到的事情，自己说过的话、做过的行为进行一次复盘，看看哪些事情做得好，哪些事情做得不好，下一次应该如何提高，哪些行为是被大脑“绑架”了?</p>
<p>除了这种“每日三省吾身”的方式，还有第二种方式——“阅读”，这里的阅读不只是要理解作者想表达的意思，而是作者的思考方式；即他为什么会这样写?他的思考方式是怎么样的?用到了哪些概念和价值观?有没有错误?</p>
<p>如果是自己来写这个内容的话会怎么写?他这种思维方式比自己好在哪里?这样不断地和自己做对比，就像和一个人在对话一样，久而久之，你会慢慢发现你阅读的速度竟然变得更快了，而且学习效率也提高了很多，甚至读了一半，你就能猜到作者之后会写什么，如何写，甚至知道怎么样写才会更好，你不再是被文字牵着走，而是陪着作者一起思考......（笔者觉得这部分跟这篇文章的观点很像，<a
href="https://zhuanlan.zhihu.com/p/51934140">天空之城：拉马努金式思维训练法</a>）</p>
<p><strong>3.练习冥想</strong></p>
<p>冥想这部分在很多外部资料中都讨论的比较多，这里推荐知乎的一个问题：<a
href="https://www.zhihu.com/question/24361064">冥想的具体做法是怎样的</a>？，有很多原理解释和方法指导，核心其实还是<strong>主动控制你的注意力</strong></p>
<h3 id="打造稀缺性">打造稀缺性</h3>
<p>对于个人而言，打造稀缺性其实就是要打造<strong>有效的多维能力</strong>，这里有效体现在</p>
<p>（1）每个能力都有价值，也是别人需要的 （2）每个能力都有关联</p>
<p>比如对于互联网的从业人员，技术能力和管理能力就是有效多维能力，技术能力又可粗略分为工程能力和算法能力，其实就是常说的广度和深度，如果两者都做的足够好，那其实就是稀缺的。</p>
<p>那该如何打造多维能力，书里给出了三个步骤 1.先把一个能力打造成长板
2.让自己兴趣广泛，培养多种能力
3.确定一个目标，并把多种能力组合成多维能力</p>
<p>笔者的实践经验就是先把本职工作的技能打磨好，然后去看同行业的其他人在做什么，选择自己感兴趣的部分去学习，而大目标基本就是你所在行业所要解决的问题了。</p>
<h2 id="重新理解世界">重新理解世界</h2>
<h3 id="趋势">趋势</h3>
<p>这里的趋势其实就是大环境，很多人应该都明白这个道理，要顺势而为；这里是更系统的描述趋势是如何产生的、如何判断趋势等</p>
<p>假设平面上有一个静止的小球，小球只要运动了，这个运动方向就是趋势；那么趋势产生可归结为
2 个原因：外力和势能差</p>
<p><strong>1.外力</strong></p>
<p>现实世界中的热点、重大新闻、科技突破、黑天鹅事件等，都是突发性的“外力”。一旦这种重大意外事件发生，你就得去了解一下它可能会产生什么样的趋势，然后跟进，赚取趋势红利，这也就是我们平时说的追热点。但这种方法有
2 个问题</p>
<p>（1）不知道什么时候来，从哪个位置来，这个很难预测，只能等
（2）即使来了，你也不知道它未来究竟会如何发展</p>
<p>由于这种外力的不可预知性，以及未来发展趋势难以捉摸的特点，书里并不推荐这种方式，因为这更像是一种投机。</p>
<p><strong>2.势能差</strong></p>
<p>寻找势能差，其实就是主动寻找存在“不公平竞争”的地方，然后成为高势能的一方，顺势而为，用“不公平”的方式赢得胜利。就像站在山上和山下的人打仗一样，在万仞之巅推下千钧之石。</p>
<p>书里将势能差分为了四大类：效率势能、规模势能、认知势能和引力势能</p>
<p><strong>（1）效率势能</strong></p>
<p>这部分可提炼为 9 个字：<strong>优打劣、快打慢、廉打贵</strong></p>
<p>优打劣：同样的产品，你提供的的品质更好
快打慢：快一步就意味着抢先占领了市场，用户规模会成为新的势能高地
廉打贵：产品价格更低会更受到消费者的青睐</p>
<p><strong>（2）规模势能</strong></p>
<p><strong>大鱼吃小鱼</strong>，就是用规模去碾压对手。</p>
<p>比如外卖大战、共享单车大战、打车软件大战都是这么一个剧本，一开始大家都势均力敌、打得不可开交，而一旦其中某一方通过资本注入，它就能迅速扩大规模，用规模优势蚕食对手；有一些大公司对与一些刚冒起苗头的小公司，要么收购，要么复制，直接通过用户规模去把小公司绞杀在襁褓里</p>
<p><strong>（3）认知势能</strong></p>
<p>这里类比《三体》就是高级文明打低级文明，用新模式、新科技进行降维打击；也可称之为:
<strong>颠覆式创新</strong></p>
<p>书里举了 2 个例子：被数码相机打败的柯达，被智能手机打败的诺基亚</p>
<p>大企业要做创新，面临着“<strong>创新者的窘境</strong>”:
你要干掉原有业务?想颠覆原有技术?那你面对的就是具有规模势能的既得利益者的压力。</p>
<p>所以现在一般大企业都会通过下面 2 种方式来践行这部分</p>
<p>a.从内部独立出去一个团队，脱离原公司，在创业环境下单独搞新业务;
b.看到好的公司直接买买买</p>
<p><strong>（4）引力势能</strong></p>
<p>这里指得是某个事物，能够像拥有引力一样地吸引周围的事物，让它们成为自己能力的一部分，类似一个黑洞的存在，笔者觉得这就是<strong>马太效应</strong></p>
<p>比如拥有网络效应的平台型公司，它拥有一个互相增益的双边市场，用户越多就会吸引更多的商家来到平台，而更多的商家来到平台，就会吸引更多的用户来平台购物</p>
<p>上面提到了 4
种势能，那该如何站上这些势能高点？书里借鉴了阿里巴巴的曾鸣教授提到过的一个概念:
“<strong>点、线、面、体</strong>”的战略分析框架, 来分析这个问题</p>
<blockquote>
<p>点:可以指个人或者某个单一产品;
线:一个小公司，也可以指大公司里的一条业务线;
面:指平台型公司或者生态型企业，比如阿里巴巴、腾讯;
体:指时代、行业、新的经济体。</p>
</blockquote>
<p>当我们有了这么一个框架，就可以问一下，当前自己到底在哪个位置上？拥有什么势能？怎样获取缺失的势能？因为点线面体上有不同的势能</p>
<blockquote>
<p>“点”自身唯一能把握住的是认知势能，其他基本都不具备;
“线”可以拥有效率势能和认知势能，势能比“面”小一个数量级,
比“点”高一个数量级
规模势能和引力势能是“面”和“体”独有的，而“体”的势能比“面”高出一个数量级
<img src="https://wulc.me/imgs/potential_energy.jpg" height="30%" width="30%"></p>
</blockquote>
<p>而站上势能高点的具体方法，书里给了 2
个：<strong>成为和赋能</strong></p>
<p><strong>成为：让自己成为高势能的一部分</strong></p>
<p>对于个人可以加入一家有势能的公司，对于小公司可以发挥效率势能和认知势能来执行战略，选择在大公司瞧不上的某条业务线上，通过集中的效率势能，在它还没有反应过来的时候，快速将效率势能转化成用户规模</p>
<p><strong>赋能：找到高势能的“线、面、体”来帮助自己提高势能</strong></p>
<p>书里举了 2 个例子</p>
<blockquote>
<p>一个点本身拥有的势能是很小的，单打独斗在这个时代成不了什么气候。但是一些自媒体、一些网红却单干而财富自由了；为什么呢?
原因他们这个“点”在如今这个时代，可以脱离于“线”而直接附着在“面”上了，比如微信、淘宝、抖音、知乎;这些面又附着在一个正在快速崛起的“体”上，也就是移动互联网。他们看似在单干，但其实，是体和面一起在给这些“点”赋能，给他们提供了海量的客户资源，给他们提供了数据支持、技术支持、物流支持......</p>
<p>CEO最重要的工作就是为员工赋能。员工再好再不好，他们都是一个“点”，资源和能力是有限的，势能就那么多，你不应该天天对自己的员工不满意，而应该去外部找有势能的线、面、体，为你的组织赋能，
这才是一个好CEO该干的事。</p>
</blockquote>
<p>如何找到高势能的“线、面、体”，书里虽然给出了一些例子，但是并没有给出具体的方法论，笔者认为<strong>也许具体的高势能“线、面、体”在每个时代都不同，都得靠那个时代的愿意折腾的人去发现吧</strong></p>
<p>书里留了两个思考题，笔者觉得值得每个人去认真想一下答案</p>
<blockquote>
<p>思考题1:你现在附着在哪些线、面、体上呢?它们是在上升还是在沉沦?
思考题2:你可以通过什么方式，找到适合的线、面、体为自己赋能?它们又为什么愿意给你赋能呢?</p>
</blockquote>
<h3 id="为想法估值">为想法估值</h3>
<p>这部分内容更多是针对创业者，但其分析的思路其实也能应用到日常工作中，主要观点是不仅要有想法，而是要考虑想法的可行性，即为想法估值,
考虑想法的
ROI，书里提出了四个维度来进行这个估值：<strong>客户终生价值、获客成本、用户规模和风险成本</strong></p>
<p><strong>1.客户终生价值</strong></p>
<p>客户终生价值，就是一个客户一辈子在你这里花多少钱，其计算公式可简化如下</p>
<p><strong>客户终生价值=(客单价-边际成本)×购买次数</strong></p>
<p>客单价：指的是一个客户在你这里购买一次产品或者服务，平均需要花多少钱
边际成本：指的是每多增加一个客户所增加的总成本</p>
<p>有了这个公式，就可以估算一下产品上线后，客单价会有多高?边际成本是多少?客户可能会来购买几次?</p>
<p>但是当产品没实际运营，会存在估算不准确的问题，书里说的是“对多个要素一起进行估算，通过计算，误差就会彼此对冲掉”；笔者不太理解这句话，但是觉得更可行的方法是去调研当前类似产品的一些数据来做估算。</p>
<p><strong>2.获客成本</strong></p>
<p>获客成本，就是获得一个付费客户所需花费的成本；</p>
<p>为什么有些明星、网红出来创业，一开始就能有很高的估值？其实就是他们存在粉丝价值，很容易做到较低的获客成本。</p>
<p>回到获客成本的估算：你有这方面的存量用户资源吗?你有开发市场的独门秘籍吗?没有资源，你就得花钱打广告；所以我们经常看到，某某创业公司在玩命地烧钱，其真正有效的逻辑是：<strong>客户终生价值-获客成本&gt;0</strong></p>
<p><strong>3.用户规模</strong></p>
<p>用户规模，就是项目最多可以获得多少个用户</p>
<p>估算这部分往往会面临这以下两个问题
（1）<strong>市场总容量</strong>，就是市场的天花板，书里提到这部分数据的获取方式是：“别问我该如何知道这些数据，这些数据你都没法搞到，也就不要创业了”
（2）<strong>市场竞争</strong>, 这里又有 2 点值得思考</p>
<blockquote>
<ol type="a">
<li>如果你发现你进入的这个市场，除了你之外就没有其他玩家了，或者玩家很少。有可能是你认为的这个需求不一定存在</li>
</ol>
<p>b.假定需求是有的，但是真的就没有人做，那意味着你就得教育市场了，教育市场可是一件吃力不讨好的事情，你也许花了一年的时间，好不容易把用户从无到有地培养起来了，结果竞争对手看到你这里有肉吃便蜂拥而至</p>
</blockquote>
<p><strong>4.风险成本</strong></p>
<p>风险成本, 就是你的项目如果失败了，一分钱没挣到，最多会损失多少?</p>
<p>综合以上点，可对想法进行如下的估值,
而最终的公式是：<strong>项目估值=(客户终生价值-获客成本)×用户规模-风险成本</strong></p>
<p><img src="https://wulc.me/imgs/idea_value.jpg" height="50%" width="50%"></p>
<p>上面只是从四方面为想法估值，真正执行的时候还需要考虑趋势、合作的团队等隐私，书里对这部分只是简单概括，这里也不详细展开了。</p>
<h3 id="镜像世界">镜像世界</h3>
<p>笔者觉得这部分的内容跟<a
href="http://wulc.me/2015/11/20/%E6%88%91%E4%BB%AC%E8%BF%99%E4%B8%80%E4%BB%A3%E4%BA%BA%E7%9A%84%E5%9B%B0%E6%83%91/">我们这一代人的困惑</a>里面的内容很像，只是这里更明确地将我们所做的事情划分为四个象限。</p>
<p>书里根据左侧和右侧、光明与黑暗将事情划分为如下图所示的四个象限，其中左侧与右侧、光明与黑暗的含义是</p>
<p><strong>左侧与右侧</strong>：越靠近左侧，因果关系就越强，达成目标主要靠技术，运气的空间很小；越往右侧，因果关系就越弱，行为和结果之间存在很多不确定因素，也就是我们常说的运气成分偏多
<strong>光明与黑暗</strong>：光明指那些你已知的事情，黑暗指那些你还不知道的事情，包括其他人已知，而你不知道，以及所有人都不知道的事情</p>
<p><img src="https://wulc.me/imgs/four_filed.jpg" height="50%" width="50%"></p>
<p>而对于每个领域的事情，都要有不同的策略</p>
<p><strong>1.掌控域：已知、确定</strong></p>
<p>总结来说就是要<strong>积极努力，刻意练习，提高技能水平</strong>；因为技能在这个域内的占比很大，想要获得成功，你就得不断提升技能水平。</p>
<p><strong>2.盲域：未知、确定</strong></p>
<p>总结来说就是要<strong>承认自己的无知，并开始学习与探索</strong>，书里以演讲为例</p>
<blockquote>
<p>你看到别人的演讲非常精彩，既有深度，又有广度，还风趣幽默，讲得你激情澎湃，你觉得这人的“口才”真好，真是天生的演说家。
但其实“演讲”这件事，也是左侧世界的技能，背后是有一套理论框架的:
开场怎么开? 结尾怎么收? 用案例库中的哪些案例?
如何把结构化的知识，用线性的方式讲述出来?
如何将理性的认知和感性的了解结合起来? 如何设计演讲中的峰值与终值?
如何与观众互动? 如何应对挑事的观众? ......</p>
</blockquote>
<p><strong>3.概率域：已知、不确定</strong></p>
<p>总结来说就是要<strong>不赌单次，赌整体，善用数据决策</strong>;</p>
<p>这部分从概率论的角度思考，也许会更好理解，其实就是利用大数定律来判断事情的期望，而且是最好是借鉴他人构造出来的样本和数据</p>
<p><strong>4.风险域：未知、不确定</strong></p>
<p>书里认为这是个恐怖的领域，给出应对策略是如下几种</p>
<p>策略一:避免进入
策略二:增加冗余备份，即多维能力；如个人学习多种能力，公司布局多个领域
策略三:“买彩票”思维，做风险小，收益大的事情，如风投</p>
<p>最后，书里还提出了一条适用于这四个领域的生存法则：<strong>守株待兔，简单翻译就是守住不变的东西，等待机会的来临</strong></p>
<blockquote>
<p>守株指的是:在这个充满变化和不确定的世界里，你首先要牢牢抓住那些正确的概念和不变的规律,
关键在于你能否发现这些“株”，并牢牢地“守”住它们。因此，<strong>你得保持初心，尊重未知，通过不断学习，减少盲域的面积，提高“株”的数量</strong></p>
<p>待兔指的是：等待不确定的机会。兔子可能会来，也可能不会来，也不知道什么时候会来。因此，你不能把你一天所有的口粮都寄托在这些不确定的兔子身上，那风险太大了，几天没抓到兔子，你可能会饿死。<strong>你得花大部分的时间，先把确定的事做好，保证自己的基本生存，如果能等来一个兔子，你就额外赚到了</strong></p>
</blockquote>
<p>怎么赚到这些兔子，书里举了三种方法</p>
<p><strong>1.发展有效人脉</strong>:
所谓的“人脉”，不是能帮到你的人，而是你能帮到他的人。你多帮助别人，就是在往你们之间的“情感账户里存钱”
<strong>2.学习跨界知识</strong>:
你遇到某个问题，也许会在其他领域里找到一个线头，抽出一个很好的解决方案，而这个“好运”就来自于你曾经的广泛学习
<strong>3.投资成长性资产</strong>: 投资股票、创业公司等</p>
<h3 id="提升运气">提升运气</h3>
<p>这部分将“运气”归结到人、事、物这三个方面上，并且给出了每部分给出了一些方法论</p>
<p>常说的运气，往往可归因为三类:</p>
<p>1.人: 获得其他人的帮助。 2.事:
有些事情的发生，增加了你目标事件的成功概率。 3.物:
周围的物理环境，能使用的物品道具，天时地利的变化。比如钻木取火里那个干燥的环境。</p>
<p><strong>1.人</strong></p>
<p>一个人得到另一个人的原因往往有三个：<strong>投资、扶弱、还债</strong>，因此针对这三个原因，我们要做一个什么样的人？书里给出了如下建议</p>
<p>(1)<strong>才华出众</strong>：你在寻找伯乐的同时，伯乐也在寻找千里马
(2)<strong>低调、谦逊、知恩图报</strong>：人们喜欢帮助弱者，其实是源于内心的一种存在感的满足。就是看到对方因为自己的帮助而变得更好，内心会有一种开心的满足感。但如果对方是傲慢自大的，是会恩将仇报的，那这份“意义感”就荡然无存了。
(3)<strong>广结善缘、吃亏是福</strong>:
与别人交往、合作，也要想办法让对方多赚一点，这样，他们会带着一些“亏欠你”的心态与你交往，会更愿意帮助你，愿意介绍自己的朋友给你认识，介绍更多的生意与你合作</p>
<p><strong>2.事</strong></p>
<p>这里的观点是要让你<strong>做的每一件事，都产生“积累”的效果</strong>，前一件事是后一件事的预动作，过去的经验是今天的铺路石，让时间成为你的朋友，产生<strong>复利效应</strong>。</p>
<p><strong>3.物</strong></p>
<p>其实就是前面分析的势能类型，以及如何站到高势能的地方</p>
<h2 id="小结">小结</h2>
<p>本文主要讲述了书里前半部分内容：概念重塑，包括重新理解财富、重新理解自我和重新理解世界三大部分。各部分核心观点如下</p>
<p><strong>1.重新理解财富</strong></p>
<ul>
<li>注意力是最宝贵的财富，要警惕被浪费、被收割</li>
<li>时间商人有四种模式，你是哪一种模式，能不能找到更高效的模式</li>
<li>复利不限于经济领域，3 步建立复利效应</li>
</ul>
<p><strong>2.重新理解自我</strong></p>
<ul>
<li>人会被角色化，角色化是一把双刃剑，需要学会“去角色化”</li>
<li>一个人有 5 个层级，你对自我、对他人理解到了哪个层级</li>
<li>理解问题有 6 个层次，从底层的环境到顶层的精神，你在哪一层</li>
<li>元认知有 3 个重要作用，提升元认知的 3 个手段</li>
<li>打造稀缺性就是在打造有效的多维能力</li>
</ul>
<p><strong>3.重新理解世界</strong></p>
<ul>
<li>趋势由外力和势能产生，势能相对外力更容易把握</li>
<li>势能有四种类型，从“点线面体”理论出发，判断自身处于哪个位置，拥有哪些势能，怎么获取其他势能</li>
<li>为想法估值的四个维度，量化 ROI</li>
<li>根据确定性和掌握的信息量，可以将所做的事情划分为四个领域，每个领域都有不同的生存规则；但其中不变的是“守株待兔”</li>
<li>提升运气可以从人、事、物三个角度出发</li>
</ul>
<p>因为概念较多，所以这里也做了思维导图，如下图所示，原始的 xmind
文件也可以从<a
href="https://github.com/WuLC/resources/blob/master/%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9_%E6%A6%82%E5%BF%B5%E9%87%8D%E5%A1%91.xmind">github</a>下载</p>
<figure>
<img src="https://wulc.me/imgs/concept_rebuild.png"
alt="concept rebuild" />
<figcaption aria-hidden="true">concept rebuild</figcaption>
</figure>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>《链接、装载与库》 阅读笔记(2)-可执行文件的装载</title>
    <url>/2020/06/13/%E3%80%8A%E9%93%BE%E6%8E%A5%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%8E%E5%BA%93%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(2)-%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E7%9A%84%E8%A3%85%E8%BD%BD/</url>
    <content><![CDATA[<p>本文是<a
href="https://book.douban.com/subject/3652388/">链接、装载与库</a>中关于可执行文件装载的过程，主要描述了进程在被装载时虚拟空间是如何分布的，物理内存空间与虚拟地址空间是如何映射的，同时描述了
Linux 系统下装载一个可执行文件的基本过程。</p>
<span id="more"></span>
<h2 id="基本概念">基本概念</h2>
<p>可执行文件只有被装载到内存后才能被 CPU
执行，因为<strong>程序执行时所需要的指令和数据必须在内存中才能正常运行</strong>，这部分细节涉及到
CPU 的内部组成架构，具体可参考文章 <a
href="http://wulc.me/2020/05/30/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week1/">程序的表示、转换与链接-week1</a>
中 现代计算机的模型结构和工作原理部分</p>
<p>而在每个程序被运行起来后都有自己独立的虚拟地址空间(Virtual Address
Space), 这个<strong>虚拟地址空间大小由计算机的硬件平台决定(CPU
的位数)</strong>，如 32 位的 CPU 上寻址空间是 0-2^32-1(4GB)</p>
<p>但实际上这 4GB
的虚拟空间并不能全部被程序使用，因为操作系统会占掉一部分内存。<strong>如果进程访问了未经允许的地址，在
Linux 下会出现 segment fault 的错误</strong></p>
<p>在程序装入内存过程中，往往会出现<strong>某个程序需要的内存比当前物理内存大得多的情况</strong>，这种情况下就需要动态装载了，<strong>动态装载的基本原理：程序运行时是有局部性的，因此可以将程序最常用的部分放在内存中，不常用的放在磁盘中</strong></p>
<p>目前常用的方法是页映射(paging),
就是把内存切成小块（page）再分配，当有新的空间申请时，按照一定算法驱逐已分配内存的空间（如
FIFO、LUR）,如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/pageLoad.jpg" alt="pageload" />
<figcaption aria-hidden="true">pageload</figcaption>
</figure>
<h2 id="从操作系统看可执行文件的装载">从操作系统看可执行文件的装载</h2>
<p>从操作系统的角度来看，一个进程最关键的特征是它拥有独立的虚拟地址空间，这使得该进程能跟其他进程区分开来</p>
<p>从操作系统角度来看，<strong>创建一个进程，然后装载相应的可执行文件并执行，在有虚拟存储的情况下，需要做三件事</strong></p>
<ol type="1">
<li>创建一个独立的虚拟地址空间</li>
<li>读取可执行文件头，建立虚拟空间与可执行文件的映射关系</li>
<li>将 CPU 的指令寄存器设置成可执行文件的入口地址，启动运行</li>
</ol>
<p>宏观来说，步骤 1
相当于是建立虚拟地址空间到物理地址空间的映射关系，步骤 2
则是建立虚拟地址空间到可执行文件的映射关系，步骤 3
则是跳转指至可执行文件的入口（保存在 ELF 文件头中）然后开始执行。</p>
<p>步骤 2 是传统意义上“装载”的过程最重要的一步，因为步骤 1
只分配了一个页目录，具体的映射交给了步骤
2，而<strong>当程序执行发生页错误的时候，操作系统会从物理内存中分配一个物理页，然后将该“缺页”从磁盘读取到内存中，再设置缺页的虚拟页和物理页的映射关系</strong></p>
<p>因此，操作系统捕获到页错误的时候，需要知道程序当前所需要的页在可执行文件中的偏移位置，这就是虚拟空间与可执行文件的映射关系，这种关系会保存在一个数据结构中，<strong>在
Linux
中会保存在进程中，记录每个段对应的虚拟地址范围和所在可执行文件的位置，称为VMA(Virtual
Memory Area)</strong></p>
<p>如下图所示，在进程创建后，进程内部会有一个 <code>.text</code> 段的
VMA ，属性为只读，在虚拟空间的地址为
0x08048000-0x08049000，这个大小就是32 位 IntelIA32 的一个页的大小，哪怕
<code>.text</code> 的数据没这么多也会占用掉一个页的大小</p>
<figure>
<img src="https://wulc.me/imgs/virtualaddressspace.jpg"
alt="virtual addr" />
<figcaption aria-hidden="true">virtual addr</figcaption>
</figure>
<p>那上面提到的页错误（PageFault）指的是什么呢？其实在<strong>做完上面三个步骤后，只是建立了映射关系，可执行文件还没被装载到内存中执行</strong>。以上图为例，在进程开始执行时，会发现入口地址对应的页
0x08048000-0x08049000 是个空页面，进而触发一个页错误，CPU
把控制权交给操作系统，操作系统查询进程的
VMA，计算出相应页面在可执行文件中的位置，进而在物理内存中分配一个物理页，将进程中改虚拟页与物理页简历映射关系，再把控制权交给进程。如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/pageFault.jpg" alt="pageFault" />
<figcaption aria-hidden="true">pageFault</figcaption>
</figure>
<h2 id="进程虚拟空间分布">进程虚拟空间分布</h2>
<h3 id="section-与-segment">section 与 segment</h3>
<p>对于前面提到的可执行文件中的每个段，假如都要在物理内存中分别分配一个
页，这样会导致页面内部碎片情况严重，同时浪费内存，因为一个段的大小可能会远小于一个页的大小</p>
<p>解决这个问题的方法是<strong>将相同权限的段合并到一起当做一个段处理，称为
segment</strong>，如下图所示是将两个 <code>.text</code>
段合并成一个，从而使得原来需要分配三个页的物理内存变成只需要分配两个页</p>
<figure>
<img src="https://wulc.me/imgs/mergeELFsegment.jpg"
alt="mergeSection" />
<figcaption aria-hidden="true">mergeSection</figcaption>
</figure>
<p>在最开始讨论 ELF 文件时也有段的概念，为了与这里的段区分开，在英文中
ELF 文件中原始的“段”被称为 section，虚拟空间地址后被称为
segment，实际上，这是看待 ELF 文件的两个视角，如下图所示，左边的 section
会被合并成右边的 segment</p>
<figure>
<img src="https://wulc.me/imgs/segmentVSsection.jpg"
alt="segmentVSsection" />
<figcaption aria-hidden="true">segmentVSsection</figcaption>
</figure>
<p>因此<strong>最终分配物理内存时是以 segment
来映射</strong>的，通过<code>readelf -S</code>可看到 elf 文件的
section，通过 <code>readelf -l</code> 则可看到 elf 文件的 segment,
如下图是一个简单例子，有 20+的 section，但是只有 5 个 segment，且
segment 中只有类型为 LOAD 的两个段才需要被映射到物理内存中</p>
<figure>
<img src="https://wulc.me/imgs/readelfSection.jpg"
alt="section memory" />
<figcaption aria-hidden="true">section memory</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/readelfSegment.jpg"
alt="segment memory" />
<figcaption aria-hidden="true">segment memory</figcaption>
</figure>
<p><strong>类似 section 有段表，ELF 可执行文件中也有
一个专门的数据结构叫程序头表（program header table），用来保存 segment
的信息，值得注意的是，因为 ELF
目标文件不需要被装载，所以没有程序表头</strong></p>
<p>程序表头的结构体即各个字段的含义如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/programHeader.jpg" alt="programHeader" />
<figcaption aria-hidden="true">programHeader</figcaption>
</figure>
<h3 id="堆与栈">堆与栈</h3>
<p>因为进程在运行过程中需要用到堆和栈，而<strong>堆和栈在虚拟空间中的表现也是以
VMA 形式存在的</strong>，在 Linux 下，可通过查看 <code>/proc</code>
来查看进程的虚拟空间分布，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/proc.jpg" alt="proc" />
<figcaption aria-hidden="true">proc</figcaption>
</figure>
<p>上面结果中主要关注的是几列表示的含义如下：第一列是 VMA
的地址范围，第二列是 VMA 的权限(p表示COW,copy on write), 第三列是 VMA
对应的 segment 在映像文件中的偏移，最后一列是映像文件的路径</p>
<h3 id="进程栈初始化">进程栈初始化</h3>
<p>在进程刚启动的时候，需要知道一些进程运行的环境，如系统环境变量和进程的运行参数；因此<strong>操作系统在进程启动前会将这些信息提前保存到进程的虚拟空间的栈中</strong>（即
VMA 中的 stack VMA）</p>
<p>假设系统中有两个环境变量: <code>HOME=/home/usr</code> 和
<code>PATH=/usr/bin</code>, 如下图运行命令 <code>prog 1234</code>
后，进程的栈分布如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/StackInitialize.jpg"
alt="stackInitialize" />
<figcaption aria-hidden="true">stackInitialize</figcaption>
</figure>
<p>栈顶的 esp
寄存器指向的位置是初始化后的堆栈地址，前面四个字节表示的是命令行参数的格式，这里所谓
2 (即 prog 和 123)，然后就是指向这两个参数的指针，后面跟着一个
0，紧着是指向两个环境变量的字符串的指针（即 <code>HOME</code> 和
<code>PATH</code> 这两个环境变量）</p>
<p><strong>在进程启动后，程序的库部分会把堆栈的初始化信息中的参数信息传给
<code>main()</code> 函数，也就是熟知的 main()函数的两个 argc 和 argv
两个参数</strong>，分别对应于命令行<strong>参数数量</strong>和命令行参数字符串<strong>指针数组</strong>。</p>
<h3 id="小结">小结</h3>
<p>通过上面的例子可知，<strong>进程中的虚拟地址空间可理解为操作系统给进程空间划分出一个个的
VMA
来管理进程的虚拟空间，基本原则是将属性相同、有相同映像文件的映射成同一个
VMA</strong>，一个进程基本可映射成以下几个 VMA（segment）</p>
<ul>
<li>代码 VMA，权限只读、可执行；有映像文件(即 elf 文件)</li>
<li>数据 VMA，权限可读写、可执行；有映像文件</li>
<li>堆 VMA，权限可读写、可执行；无映像文件，可向上拓展</li>
<li>栈 VMA，权限可读写、不可执行；无映像文件，可向下拓展</li>
</ul>
<p>因此，一个进程的虚拟地址空间如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/executable2virtualspace.jpg"
alt="executable2virtualaddress" />
<figcaption aria-hidden="true">executable2virtualaddress</figcaption>
</figure>
<h2 id="linux-内核装载-elf-可执行文件过程">Linux 内核装载 ELF
可执行文件过程</h2>
<p>下面会简单介绍在 Linux 系统的 bash 下输入一个命令执行某个 ELF
程序时，Linux 系统是怎么装载这个 ELF 文件并执行它的。</p>
<p>在用户层面，主要有三个步骤</p>
<ol type="1">
<li>bash 进程会调用 <code>fork()</code> 系统调用来创建一个新的进程</li>
<li>新的进程调用 <code>execve()</code> 系统调用来执行指定的 ELF
文件</li>
<li>bash
进程返回并等待前面启动的进程结束，然后用户再输入新的命令（可以用
<code>&amp;</code> 让程序在后台运行）</li>
</ol>
<p><code>execve()</code>函数定义如下,
其三个参数分别表示可执行文件名、执行参数和环境变量，其中执行参数和环境变量对应于前面提到的进程栈的初始化中存储的相关内容</p>
<p><code>int execve(cosnt char* filename, char *const argv[], char *const envp[]);</code></p>
<p><code>execve()</code> 在找到可执行文件后，首先会读取文件前 128
个字节，其目的是为了判断文件的格式，因为 Linux 执行的可执行文件不知 ELF
一种，还有 Java、以及以 <code>#!</code> 开始的脚本程序等</p>
<p><strong>每种可执行文件
的格式的开头几个字节都是很特殊的</strong>，尤其是开头的四个字节（被称为
magic number），通过 magic number 可判断文件的格式和类型，如 ELF
文件前四个字节是 0x7F、'e'、'l'、'f'；而 Java 可执行文件格式头 4
个字节为 'c'、'a'、'f'、'e'；如果是 shell、python、perl
这类解释型的语言，第一行往往是 <code>#!/bin/bash</code>、
<code>#!/usr/bin/python</code>、 <code>#!/user/bin/perl</code></p>
<p><code>execve()</code> 读取了 128 个字节的文件头部后，会调用
<code>search_binary_handle()</code>
去搜索和匹配合适的可执行文件装载处理过程，不同类型的可执行文件格式都有相应的装载处理过程，如
elf 可执行的装载处理过程叫 <code>load_elf_binary()</code>,
装载可执行脚本程序的处理过程叫 <code>load_scrip()</code> ,
这里主要描述<strong><code>load_elf_binary()</code>的基本过程</strong></p>
<ol type="1">
<li>检查 elf 可执行文件的有效性，比如说 magic number，program header 中
segment 的数量</li>
<li>寻找动态链接的 .interp
段，设置动态链接的路径（后面会有一篇文章专门描述动态链接）</li>
<li>根据 elf 可执行文件的 program header 描述，对 elf
文件进行映射，比如代码、数据、只读数据等</li>
<li>初始化 elf 进程环境</li>
<li>将系统调用的返回地址改成 elf
文件可执行文件的入口点，这个<strong>入口点取决于程序的链接方式</strong>，如对于静态链接的
ELF 文件，这个入口就是 ELF 文件的文件头中 <code>e_entry</code>
所指的地址;对于动态链接的 ELF 文件，这个入口就是动态链接器</li>
</ol>
<p>当 <code>load_elf_binary()</code> 执行完后，第五步会<strong>令 EIP
寄存器直接跳转到 ELF 程序的入口地址，于是程序就开始执行，ELF
可执行文件装载完成。</strong></p>
<h2 id="总结">总结</h2>
<p>这一章主要描述了程序运行时是如何使用内存空间的，即程序如何被装载到内存中（页映射模式）；然后详细介绍了进程虚拟地址空间的分布，即操作系统如何为程序的代码、数据、堆和栈在进程中分配虚拟地址空间(VMA),
最后介绍了 Linux 系统下是如何装载 ELF
可执行文件的，且这一章中描述的都是在都是静态链接，即只有一个可执行文件，后面会描述动态链接，即一个可执行文件会被拆成若干个模块。</p>
]]></content>
      <categories>
        <category>链接、装载与库</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>读书</tag>
        <tag>链接、装载与库</tag>
      </tags>
  </entry>
  <entry>
    <title>《链接、装载与库》 阅读笔记(1)-基本概念与静态链接</title>
    <url>/2020/05/31/%E3%80%8A%E9%93%BE%E6%8E%A5%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%8E%E5%BA%93%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(1)-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5/</url>
    <content><![CDATA[<p>一直对以 C/C++
为代表的的编译型语言的编译、运行的原理了解不多，最近正好看到这本由国人写的书
<a
href="https://book.douban.com/subject/3652388/">链接、装载与库</a>，书名已经比较言简意赅的介绍了书里相关内容，而且写得挺通俗的，值得一看。这里是书里第一、二部分内容的一些笔记，主要讲了操作系统的一些基本概念，编译生成的目标文件格式和静态链接的过程；由于笔者只摘录一些不太了解的内容，因此总体内容可能不是非常成体系，建议读原书。</p>
<span id="more"></span>
<h2 id="操作系统基本概念">操作系统基本概念</h2>
<p>这部分主要讲了一些与操作系统相关的基本概念，了解这些基本概念是了解书中后面内容的基础</p>
<ul>
<li>增加中间层解决问题
<ul>
<li>避免直接访问磁盘，增加中间层: 文件系统
<ul>
<li>磁盘以扇区作为基本单位，一个文件会被存储在多个扇区上，文件系统保存了这些数据结构</li>
</ul></li>
<li>避免直接访问物理地址的方法，增加中间层：虚拟地址
<ul>
<li>操作系统保留了从物理地址到虚拟地址的映射(MMU)</li>
<li>segmentation：把一段物理地址映射到一段虚拟地址，解决了物理地址不隔离的问题</li>
<li>paging：将物理/虚拟地址切成小块(page)再分配，避免程序占据了整块连续物理地址;
某些小块可能当前用不着，先存到磁盘中，需要用的时候再取出来，这就是虚拟内存</li>
</ul></li>
</ul></li>
<li>多线程
<ul>
<li>线程共享代码段，进程数据，打开的文件等资源。但是有自己的私有空间：即寄存器和栈</li>
<li>进程内部默认有一个主线程</li>
<li>可抢占式线程(preemption)与不可抢占线程,
即是否能强行中断当前线程分配资源给其他线程</li>
<li>对Linux 来说，线程不是一个通用概念
<ul>
<li>所有执行实体都被称为一个task，task间可共享内存空间；如fork就是创建了一个任务（COW机制，copy
on write，即只有在新的 task 改动内存时才为新的 task 创建内存</li>
</ul></li>
<li><strong>线程不安全的原因：代码的一个操作在被编译成汇编指令后不止一条，因此可能还行一半就被打断，不会被打断的指令也称为原子（atomic）指令</strong>，为了达到线程安全，需要同步与锁
<ul>
<li>信号量-semaphore: 允许 N 个线程并发访问一个资源</li>
<li>互斥锁-mutex：仅允许一个进程访问，与 semaphore 不同点在于 mutex
可由不同的线程来 release lock，但是 semaphore 只能由原来的线程释放</li>
</ul></li>
<li>编译器优化时可能会造成多线程的加了锁也有问题</li>
<li>用户态 v.s
内核态：用户实际使用的线程是用户态的，真正执行的线程是内核态的，这种情况下有几种模式（1）一对一（2）一对多（线程内可能会阻塞）
（3）多对多</li>
</ul></li>
<li><strong>堆栈内存区域</strong>（C中还有静态区域，用来存储 static
变量和全局变量)
<ul>
<li>堆可以理解为当前可以使用的空闲内存，但是其申请和释放都要程序员自己写代码管理。如果只申请不释放就会造成内存泄露</li>
<li>栈是程序运行时自动拥有的一小块内存，大小在编译期时由编译器参数决定，用于<strong>局部变量的存放或者函数调用栈的保存</strong></li>
<li>栈的另一个作用则是保存函数调用栈，这时和数据结构的栈就有关系了。在函数调用过程中，常常会多层甚至递归调用。每一个函数调用都有各自的局部变量值和返回值，每一次函数调用其实是先将当前函数的状态压栈，然后在栈顶开辟新空间用于保存新的函数状态，接下来才是函数执行。当函数执行完毕之后，栈先进后出的特性使得后调用的函数先返回，这样可以保证返回值的有序传递，也保证函数现场可以按顺序恢复</li>
<li><strong>操作系统的栈在内存中高地址向低地址增长，也即低地址为栈顶，高地址为栈底。这就导致了栈的空间有限制，一旦局部变量申请过多（例如开个超大数组），或者函数调用太深（例如递归太多次），那么就会导致栈溢出（Stack
Overflow），操作系统这时候就会直接把你的程序杀掉</strong>。</li>
</ul></li>
</ul>
<h2 id="编译与链接概述">编译与链接概述</h2>
<p>编译的过程(预编译-&gt;编译-&gt;汇编-&gt;链接) - 预编译（生成
<code>.i</code> 文件）：主要是处理 <code>#</code>
开头的语句，如进行宏展开、将被 include
的文件插入到对应的地方（递归执行） - 编译（生成 <code>.s</code>
文件）：将代码编译成汇编代码，包括词法分析、语法分析、语义分析和生成汇编代码的优化；虽然不同语言都可通过
gcc 来统一编译，但是 gcc
对于对于不同的语言调用了不同的编译程序（如c是cc1，c++是cclplus，java是jc1）
-
汇编（生成<code>.o</code>文件）：将汇编代码逐条转换成机器指令（有查找表）
- 链接（生成可执行文件）：静态链接与动态链接</p>
<p>其中编译这个步骤常常涉及到以下几个过程 -
词法分析：将源码分割成一系列的token，利用
lex，编译器开发者只需要定义词法规则 - 语法分析：生成语法树，利用
yacc，编译器开发者只需要定义语法规则 -
语义分析：确定语句是否合法（编译器只能分析静态语义），为语法树中的每个节点标记出其类型</p>
<p>编译器的前端和后端 -
前端：生成与机器无关的中间代码（即前面的词法和语法分析步骤） -
后端：将中间代码转换成目标机器代码 -
跨平台编译器，使用同一个前端和不同后端</p>
<p>关于编译器的架构可参考这篇文章：<a
href="https://zhuanlan.zhihu.com/p/102250532">LLVM概述——基础架构</a></p>
<p>链接基本概念 -
处理各模块间的相互引用（如引用了其他模块的函数，需要在运行时知道这个函数的地址）
-
<strong>从原理上来说，链接就是把一些指令对于其他符号的地址的引用加以修正</strong>
- 库是一些常用代码被编译成目标文件后打包存放</p>
<h2 id="目标文件的格式">目标文件的格式</h2>
<ul>
<li>目标文件就是源代码编译后但是未进行链接的那些中间文件（windows 的
<code>.obj</code> 和 linux 下的 <code>.o</code>,
它跟可执行文件的内容基本一样，所以两类文件使用同一种格式存储（windows
下的 PE-COFF 和 Linux 下的 ELF）</li>
<li><strong>除了目标文件,动态库(windows 的 <code>.dll</code> 和 linux
下的<code>.so</code>)和静态库(windows 的 <code>.lib</code> 和 linux
下的<code>.a</code>)</strong>都是按照可执行文件格式存储</li>
<li>ELF
文件格式可归为如下四类（linux下可通过file格式来显示文件格式）</li>
</ul>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>ELF 文件类型</th>
<th>说明</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>可重定位文件(Relocatable File)</td>
<td>包含代码和数据，可用来被链接为可执行文件或共享目标文件，静态链接库也可归为这一类</td>
<td>Linux 的 <code>.o</code>, Windows 的 <code>.obj</code></td>
</tr>
<tr class="even">
<td>可执行文件(Executable File)</td>
<td>包含了可以直接执行的文件，在Linux下一般都没有拓展名</td>
<td>Linux 的 /bin/bash, windows下的 <code>.exe</code></td>
</tr>
<tr class="odd">
<td>共享目标文件(shared object file)</td>
<td>包含代码和数据，可以（1）被链接器将其与可重定位文件和共享目标文件进行链接,产生新的目标文件
（2）<strong>动态链接器可将几个共享目标文件与可执行文件结合</strong>，作为进程映像的一部分来运行</td>
<td>Linux 的 <code>.so</code>, Windows 的 <code>.dll</code></td>
</tr>
<tr class="even">
<td>核心存储文件(Core Dump File)</td>
<td>进程意外终止是，系统将进程的地址空间和终止时的一些其他信息转储到核心存储文件下</td>
<td>Linux 下的 core dump文件</td>
</tr>
</tbody>
</table>
<ul>
<li><p>目标文件组成主要分为两部分：<strong>程序指令和程序数据</strong>；顾名思义，程度指令就是存放代码，程序数据用来存放代码中的数据，分局数据中的类型又可分为几种段</p></li>
<li><p>数据和指令代码分开存放的好处</p>
<ul>
<li>数据是可以读写的，但是代码指令是只读的</li>
<li><strong>系统中运行着该程序的多个副本运行时（多进程，多线程），只需要保存一份指令代码/只读数据即可，可节省大量内存</strong></li>
<li>可提高缓存命中率</li>
</ul></li>
<li><p><code>objdump</code>
可被用来分析目标文件中所包含的各个段（代码段，数据段，bss段）的一些信息(如下图所示），<code>size</code>
则可被用来查看对应的各个段的大小</p></li>
</ul>
<figure>
<img src="https://wulc.me/imgs/objdump_result.jpg" alt="objdump" />
<figcaption aria-hidden="true">objdump</figcaption>
</figure>
<p>从上图可知,
目标文件中有好几个类型的数据段，但是其中某些段是不占空间如<code>.bss</code>
段，用于表示未初始化的全局变量和局部静态变量(更准确地说是为这些变量预留了空间)，已初始化的保存在
<code>.data</code>；因此在内存中的占位如下所示</p>
<figure>
<img src="https://wulc.me/imgs/ObjectFile.jpg" alt="obj file" />
<figcaption aria-hidden="true">obj file</figcaption>
</figure>
<p>各个段的含义如下</p>
<ul>
<li><code>.text</code>: 存储汇编后的机器指令，通过
<code>objdump -d</code>
反汇编可看到代码段的机器指令机器和对应的汇编代码</li>
<li><code>.data</code>:
存储<strong>已经初始化的全局变量和局部静态变量</strong></li>
<li><code>.bss</code>:
存储<strong>未初始化的局部变量和局部静态变量</strong></li>
<li><code>.rodata</code>: 存储只读数据段，一般用来存储 <strong>const
常量和字符常量</strong></li>
</ul>
<p>可将一个二进制的文件通过 <code>objcopy</code> copy 到目标文件中</p>
<p>除了上面介绍的各个段，ELF 文件还有下面几个比较重要的结构</p>
<ul>
<li>文件头：描述整个文件属性（如文件版本、目标机器型号、程序入口地址等）</li>
<li>段表：描述上面提到的各个段的基本属性，编译器，链接器和装载器都是依赖段表来定位和访问各个段的属性</li>
<li>符号表：管理代码中的符号（函数名和变量名），用于进行链接，因为链接的接口就是符号名</li>
</ul>
<p><strong>实际上，无论是可执行文件、目标文件或库，实际上都是一样基于段的
ELF
文件或者是这种文件的集合；源代码经过编译后，按照代码和数据分别存放到相应的段中；除此之外，编译器还会将一些辅助性的信息（符号表，重定位表等）放到目标文件中。下面就是怎么把这些目标文件组装起来了，这就是链接要解决的事情。</strong></p>
<h2 id="静态链接的过程">静态链接的过程</h2>
<p>问题：合并目标文件时，对于多个目标文件中的多个段，链接器如何将它们各个段合并到输出文件；或者说<strong>链接器怎么为目标文件分配地址和空间</strong></p>
<p>先说结论，链接可简单地分为两步（two-pass linking)</p>
<ol type="1">
<li><strong>空间地址与分配</strong>：扫描输入文件，合并相同类型的段，输出合并后的段的长度与位置</li>
<li><strong>符号解析与重定位</strong>：利用第一步搜集到的信息，进行符号解析与重定位、调整代码中的地址等；这一步是链接过程的核心，尤其是重定位部分</li>
</ol>
<p>上面提到的“链接器怎么为目标文件分配地址和空间”中的“地址和空间”实际包括两方面:
(1)输出的可执行文件中的空间 (2)装载后的虚拟地址中的虚拟地址空间;
对于目标文件中像 <code>.text</code> 和 <code>.data</code>
的段这两方面都要考虑，但是对于 <code>.bss</code>
的段只需要考虑虚拟地址空间，因为 <code>.bss</code>
不在可执行文件中占用空间，<strong>后面说的分配也着重于虚拟地址空间的分配</strong></p>
<p>这里以下面两个源文件 <code>a.c</code> 和 <code>b.c</code> 说明</p>
<figure>
<img src="https://wulc.me/imgs/SourceCode.jpg" alt="source code" />
<figcaption aria-hidden="true">source code</figcaption>
</figure>
<h3 id="空间地址与分配">空间地址与分配</h3>
<p>链接前后使用的虚拟地址（VMA，Virtual Memory Address）
已经是程序在进程中的虚拟地址（通过 objdump 可看到目标文件中各个段的
VMA）；如下图所示是将两个目标文件 <code>a.o</code> 和 <code>b.o</code>
链接成一个可执行文件 <code>ab</code>（通过命令
<code>ld a.o b.o -e main -o ab</code> 可生成可执行文件 <code>ab</code>,
其入口为函数 <code>main</code>【通过 -e 参数指定，ld 链接器默认的入口为
<code>_start</code>】）</p>
<p>通过 <code>objdump</code> 可分析出目标文件与可执行文件中 VMA
的变化</p>
<figure>
<img src="https://wulc.me/imgs/link_objdump.jpg" alt="link_ojbdump" />
<figcaption aria-hidden="true">link_ojbdump</figcaption>
</figure>
<p>从上面可以看到，<strong>链接前目标文件的 VMA
都是0，因为虚拟空间还没有被分配，等链接后，可执行文件中的各个段都被分配到了相应的虚拟地址</strong></p>
<p>下图展示了将两个目标文件 <code>a.o</code> 和 <code>b.o</code>
链接成可执行文件 <code>ab</code>
后<strong>目标文件与可执行文件各个段的映射关系，以及可执行文件与虚拟地址的映射关系</strong></p>
<figure>
<img src="https://wulc.me/imgs/link_rearrange.jpg"
alt="link_rearrange" />
<figcaption aria-hidden="true">link_rearrange</figcaption>
</figure>
<p>在确定了各个段的地址后，由于<strong>符号地址在本来段内就是确定的</strong>（从前面的
objdump
命令输出结构可知），因此可以根据各个段的地址偏移确定各个符号的地址</p>
<h3 id="符号解析与重定位">符号解析与重定位</h3>
<p>完成空间地址分配后,进入到了符号的解析与重定位,这也是静态编译的重点</p>
<p>首先,通过 <code>objdump -d</code> 可以看到 <code>a.o</code>
代码的反汇编结果如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/Disassembly.jpg" alt="obj Disassembly" />
<figcaption aria-hidden="true">obj Disassembly</figcaption>
</figure>
<p>从上图输出可知，目标文件 <code>a.o</code> 中定义了一个函数
<code>main</code>, 其起始地址是
0x00000000，这是因为<strong>在程序代码里使用的都是虚拟地址，且在空间地址与分配之前，目标文件中的起始地址是
0x00000000</strong>，等到空间分配完成后，各个函数才会确定自己在虚拟地址空间的地址。</p>
<p>此外，上图中命令的输出中的 main 函数下面每行都是一条指令,
从左到右依次是指令的偏移量、指令的机器码, 右边是指令对应的汇编代码。</p>
<p>因此，上图中的 main 函数共占了 0x33 个字节， 17 条指令，其中 0x18
的指令占了两行，<strong>加粗的两条指令分别对应于 <code>a.c</code>
中引用的 shared 和 swap</strong>,</p>
<p>对于 shared 的引用是偏移为 0x18 的 mov 指令，这条指令共 8 个字节，前
4 个字节是指令吗，后面 4 个字节是 shared 的地址, 从图中看到这个地址为全
0，这是因为 <code>a.c</code> 被编译成目标文件时，并不知道 shared 和 swap
的地址，因此暂时用全 0 来表示</p>
<p>对于 swap 的引用则是偏移为 0x26 的 call 指令，这条指令共 5
个字节，其作用就是调用另一条指令，后面四个字节就是要调用的下一条指令的偏移量（地址），同样地，在链接前这个地址是一个
mock 的地址。</p>
<p>由上面描述可知，目标文件中的地址都是临时的 mock
地址，<strong>真实地址的分配与调整是由链接器来完成的</strong>，因为经过第一步的“空间地址与分配”
后，链接器已经能够确定所有符号的地址了。同样地通过
<code>objdump -d</code> 我们可以看到可执行文件 ab 的反汇编的结果如下</p>
<figure>
<img src="https://wulc.me/imgs/Disassembly1.jpg"
alt="exec Disassembly" />
<figcaption aria-hidden="true">exec Disassembly</figcaption>
</figure>
<p>从上图可知，main 函数地址确定了下来，同时 shared 和 swap
的地址也确定了，</p>
<p><strong>链接器是怎么知道哪些指令是要被调整的？</strong>在 ELF
文件中有一个叫<strong>重定位表（Relocation
Table</strong>）的结构来专门保存与重定位相关信息，重定位表实际上也是一个
ELF 文件中的一个段（重定位段），通过 <code>objdump -r</code>
可以看到目标文件中的重定位段，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/RelocationTable.jpg"
alt="RelocationTable" />
<figcaption aria-hidden="true">RelocationTable</figcaption>
</figure>
<p>上图展示了 <code>a.o</code> 里面要重定位的地方，即 <code>a.o</code>
所有引用到外部符号的地址，对照前面 <code>objdump -d a.o</code>
的结果可知，上图中的偏移的值就是 shared 和 swap
在目标文件中的机器指令的后四个字节所在地址</p>
<p>那<strong>在上面重定位的过程中，链接器怎么知道 a.o
里面需要的符号在哪去查找</strong>？这就涉及到链接器是如何进行符号解析的了，实际中，链接器会查找<strong>所有输入目标文件的符号表组成的全局符号表</strong>，找到相应的符号然后重定位。我们在编译过程中常碰到的找不到符号，或者符号冲突，其实都是发生在这个过程中</p>
<p>通过 <code>readelf -s</code> 可以看到目标文件中的符号表，如下是
<code>a.o</code> 的符号表，可以看到 shared 和 swap 都是
UND(undefined）的</p>
<figure>
<img src="https://wulc.me/imgs/charTable.jpg" alt="charTable" />
<figcaption aria-hidden="true">charTable</figcaption>
</figure>
<h3 id="commom-块">COMMOM 块</h3>
<p><strong>强符号与弱符号</strong>：在 C
语言中，函数和初始化的全局变量是强符号，未初始化的全局变量是弱符号</p>
<p>在链接<strong>中一个符号可能会出现在多个目标文件</strong>中，因此可能会出现下面几种情况</p>
<ol type="1">
<li>两个或两个以上的强符号，类型不一致</li>
<li>两个或两个以上弱符号，类型不一致</li>
<li>有一个强符号，其他都是弱符号，类型不一致</li>
</ol>
<p>第一种情况是非法的，因为<strong>不能定义多个强符号，链接器会报多重定义错误</strong>，链接器要处理的就是后两种情况，处理的方式就是下面提到的
COMMON 块(Commom block)机制，简单来说，COMMON
块记录了对应的符号的空间大小</p>
<p>对于第二种情况，会从多个弱符号中选择一个空间最大的，比如说两个弱符号，一个是
int 型，一个是 double 类型，则最终会选择 double 类型的</p>
<p>对于第三种情况，会选择强符号，但是如果有弱符号的空间大于强符号的，最终会报如下的
warning:</p>
<p><code>ld: warning: alignment 4 of symbol global in a.o is smaller than 8 in b.o</code></p>
<p>因此，使 COMMOM
模块的原因是因为编译器和链接器允许不同类型的弱符号存在，同时链接器不支持符号类型，即连机器无法判断各个符号类型是否一致。</p>
<h3 id="静态库">静态库</h3>
<p>一种语言的开发环境往往会带有语言库（Language
Library），这些库就是对操作系统的 API
的包装；<strong>一个静态库可以看做是一组目标文件的集合</strong></p>
<p>通过 <code>ar</code> 可以看到一个静态库中有哪些目标文件</p>
<figure>
<img src="https://wulc.me/imgs/staticLibrary.jpg" alt="library" />
<figcaption aria-hidden="true">library</figcaption>
</figure>
<p>值得注意的是，<strong>静态库里的一个目标文件只包含一个函数</strong>，这是是为了是的在链接过程中只链接那些使用到的函数对应的目标文件，如果很多函数都放在同一个目标文件中，会导致很多没用的函数都被遗弃链接进了输出结果中。</p>
<h2 id="小结">小结</h2>
<p>综上，本文主要介绍了操作系统的一些基本概念，以及静态链接的基本过程，主要关注一下几个方面</p>
<ul>
<li>目标文件由各种段组成，基本可分为代码段和数据段两大类</li>
<li>目标文件被链接成最终的可执行文件时，输入的目标文件中的各个段是如何被合并到输出文件中的</li>
<li>链接器如何为合并后的段分配在空间和地址（包含输出文件和进程虚拟地址空间）</li>
<li>地址确定后如何进行符号的解析与重定位，使得每个段中的指令和数据都指向正确的位置</li>
</ul>
]]></content>
      <categories>
        <category>链接、装载与库</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>读书</tag>
        <tag>链接、装载与库</tag>
      </tags>
  </entry>
  <entry>
    <title>一些有意思的题目</title>
    <url>/2016/05/28/%E4%B8%80%E4%BA%9B%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E9%A2%98%E7%9B%AE/</url>
    <content><![CDATA[<p>从互联网搜集的一些比较有趣的题目，通过python实现，换成其他语言大多也能实现。题目会尽量保持更新,如果您有好的项目推荐，欢迎在评论区留言。</p>
<p>github地址:https://github.com/WuLC/show-me-the-code</p>
<blockquote>
<p>Talk is cheap. Show me the code.--Linus Torvalds</p>
</blockquote>
<span id="more"></span>
<hr />
<p><strong>第 0000 题：</strong>将你的 QQ
头像（或者微博头像）右上角加上红色的数字，类似于微信未读信息数量那种提示效果。
类似于图中效果</p>
<figure>
<img src="https://wulc.me/imgs/result1.jpg" alt="头像" />
<figcaption aria-hidden="true">头像</figcaption>
</figure>
<p><strong>第 0001 题：</strong>做为 Apple Store App
独立开发者，你要搞限时促销，为你的应用<strong>生成激活码</strong>（或者优惠券），使用
Python 如何生成 200 个激活码（或者优惠券）？</p>
<p><strong>第 0002 题</strong>：将 0001 题生成的 200
个激活码（或者优惠券）保存到 <strong>MySQL</strong> 关系型数据库中。</p>
<p><strong>第 0003 题：</strong>将 0001 题生成的 200
个激活码（或者优惠券）保存到 <strong>Redis</strong>
非关系型数据库中。</p>
<p><strong>第 0004
题：</strong>任一个英文的纯文本文件，统计其中的单词出现的个数。</p>
<p><strong>第 0005
题：</strong>你有一个目录，装了很多照片，把它们的尺寸变成都不大于
iPhone5 分辨率的大小。</p>
<p><strong>第 0006 题：</strong>你有一个目录，放了你一个月的日记，都是
txt，为了避免分词的问题，假设内容都是英文，请统计出你认为每篇日记最重要的词。</p>
<p><strong>第 0007
题：</strong>有个目录，里面是你自己写过的程序，统计一下你写过多少行代码。包括空行和注释，但是要分别列出来。</p>
<p><strong>第 0008
题：</strong>一个HTML文件，找出里面的<strong>正文</strong>。</p>
<p><strong>第 0009
题：</strong>一个HTML文件，找出里面的<strong>链接</strong>。</p>
<p><strong>第 0010 题：</strong>使用 Python
生成类似于下图中的<strong>字母验证码图片</strong>,同时写出识别验证码的程序。</p>
<figure>
<img src="https://wulc.me/imgs/aVhbegV.jpg" alt="字母验证码" />
<figcaption aria-hidden="true">字母验证码</figcaption>
</figure>
<ul>
<li><a
href="http://stackoverflow.com/questions/2823316/generate-a-random-letter-in-python">阅读资料</a></li>
</ul>
<p><strong>第 0011 题：</strong> 敏感词文本文件
filtered_words.txt，里面的内容为以下内容，当用户输入敏感词语时，则打印出
Freedom，否则打印出 Human Rights。</p>
<pre><code>北京
程序员
公务员
领导
牛比
牛逼
你娘
你妈
love
sex
jiangge</code></pre>
<p><strong>第 0012 题：</strong> 敏感词文本文件
filtered_words.txt，里面的内容 和 0011题一样，当用户输入敏感词语，则用
星号 *
替换，例如当用户输入「北京是个好城市」，则变成「**是个好城市」。</p>
<p><strong>第 0013 题：</strong> 用 Python 写一个爬图片的程序,爬<a
href="https://www.zhihu.com/question/24340705">这个链接</a>的壁纸</p>
<p><strong>第 0014 题：</strong> 纯文本文件 student.txt为学生信息,
里面的内容（包括花括号）如下所示：</p>
<pre><code>&#123;
    &quot;1&quot;:[&quot;张三&quot;,150,120,100],
    &quot;2&quot;:[&quot;李四&quot;,90,99,95],
    &quot;3&quot;:[&quot;王五&quot;,60,66,68]
&#125;</code></pre>
<p>请将上述内容写到 student.xls 文件中，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/nPDlpme.jpg" alt="student.xls" />
<figcaption aria-hidden="true">student.xls</figcaption>
</figure>
<ul>
<li><a
href="http://www.cnblogs.com/skynet/archive/2013/05/06/3063245.html">阅读资料</a>
腾讯游戏开发 XML 和 Excel 内容相互转换</li>
</ul>
<p><strong>第 0015 题：</strong> 纯文本文件 city.txt为城市信息,
里面的内容（包括花括号）如下所示：</p>
<pre><code>&#123;
    &quot;1&quot; : &quot;上海&quot;,
    &quot;2&quot; : &quot;北京&quot;,
    &quot;3&quot; : &quot;成都&quot;
&#125;</code></pre>
<p>请将上述内容写到 city.xls 文件中，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/rOHbUzg.png" alt="city.xls" />
<figcaption aria-hidden="true">city.xls</figcaption>
</figure>
<p><strong>第 0016 题：</strong> 纯文本文件 numbers.txt,
里面的内容（包括方括号）如下所示：</p>
<pre><code>[
    [1, 82, 65535], 
    [20, 90, 13],
    [26, 809, 1024]
]</code></pre>
<p>请将上述内容写到 numbers.xls 文件中，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/iuz0Pbv.png" alt="numbers.xls" />
<figcaption aria-hidden="true">numbers.xls</figcaption>
</figure>
<p><strong>第 0017 题：</strong> 将第 0014 题中的 student.xls
文件中的内容写到 student.xml 文件中，如</p>
<p>下所示：</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;root&gt;
&lt;students&gt;
&lt;!-- 
    学生信息表
    &quot;id&quot; : [名字, 数学, 语文, 英文]
--&gt;
&#123;
    &quot;1&quot; : [&quot;张三&quot;, 150, 120, 100],
    &quot;2&quot; : [&quot;李四&quot;, 90, 99, 95],
    &quot;3&quot; : [&quot;王五&quot;, 60, 66, 68]
&#125;
&lt;/students&gt;
&lt;/root&gt;</code></pre>
<p><strong>第 0018 题：</strong> 将 第 0015 题中的 city.xls
文件中的内容写到 city.xml 文件中，如下所示：</p>
<pre><code>&lt;?xmlversion=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;root&gt;
&lt;citys&gt;
&lt;!-- 
    城市信息
--&gt;
&#123;
    &quot;1&quot; : &quot;上海&quot;,
    &quot;2&quot; : &quot;北京&quot;,
    &quot;3&quot; : &quot;成都&quot;
&#125;
&lt;/citys&gt;
&lt;/root&gt;</code></pre>
<p><strong>第 0019 题：</strong> 将 第 0016 题中的 numbers.xls
文件中的内容写到 numbers.xml 文件中，如下</p>
<p>所示：</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;root&gt;
&lt;numbers&gt;
&lt;!-- 
    数字信息
--&gt;

[
    [1, 82, 65535],
    [20, 90, 13],
    [26, 809, 1024]
]

&lt;/numbers&gt;
&lt;/root&gt;</code></pre>
<p><strong>第 0020 题：</strong> 使用 Python
语言开发服务器端口扫描器，用来检测目标服务器上有哪些端口开放。</p>
<p><strong>第 0021 题：</strong> 通常，登陆某个网站或者
APP，需要使用用户名和密码。密码是如何加密后存储起来的呢？请使用 Python
对密码加密。</p>
<ul>
<li><p>阅读资料 <a
href="http://zhuoqiang.me/password-storage-and-python-example.html">用户密码的存储与
Python 示例</a></p></li>
<li><p>阅读资料 <a
href="http://www.pythoncentral.io/hashing-strings-with-python/">Hashing
Strings with Python</a></p></li>
<li><p>阅读资料 <a
href="http://stackoverflow.com/questions/2572099/pythons-safest-method-to-store-and-retrieve-passwords-from-a-database">Python's
safest method to store and retrieve passwords from a
database</a></p></li>
</ul>
<p><strong>第 0022 题：</strong> 使用 Python 的 Web 框架，做一个 Web
版本 留言簿 应用。</p>
<p><a href="http://v2ex.com/t/151643#reply53">阅读资料：Python 有哪些
Web 框架</a></p>
<ul>
<li><figure>
<img src="https://wulc.me/imgs/image_1aoqu2cj46e018hhp4g27d1fs19.png"
alt="留言簿参考" />
<figcaption aria-hidden="true">留言簿参考</figcaption>
</figure></li>
</ul>
<p><strong>第 0023 题：</strong>
通过有道翻译提供的API写一个支持命令行翻译单词的工具，效果如下图：</p>
<p><img
src="https://wulc.me/imgs/image_1atfr8u7f180e1lm61ns91321qsr9.png" /></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>中文维基百科语料库词向量的训练</title>
    <url>/2016/10/12/%E4%B8%AD%E6%96%87%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E7%9A%84%E8%AF%8D%E5%90%91%E9%87%8F%E7%9A%84%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<p>要通过计算机进行自然语言处理，首先就需要将这些文本数字化。目前用得最广泛的方法是词向量，根据训练使用算法的不同，目前主要有
<a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a> 和 <a
href="http://nlp.stanford.edu/projects/glove/">GloVe</a>
两大方法，本文主要讲述通过这两个方法分别训练中文维基百科语料库的词向量。</p>
<span id="more"></span>
<h2 id="获取并处理中文维基百科语料库">获取并处理中文维基百科语料库</h2>
<h3 id="下载">下载</h3>
<p>中文维基百科语料库的下载链接为：https://dumps.wikimedia.org/zhwiki/,
本试验下载的是最新的<a
href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2">zhwiki-latest-pages-articles.xml.bz2</a>。这个压缩包里面存的是标题、正文部分，该目录下还包括了其他类型的语料库，如仅包含标题，摘要等。</p>
<h3 id="抽取内容">抽取内容</h3>
<p>Wikipedia Extractor
是一个开源的用于抽取维基百科语料库的工具，由python写成，通过这个工具可以很容易地从语料库中抽取出相关内容。使用方法如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/attardi/wikiextractor.git wikiextractor</span><br><span class="line">$ wikiextractor/WikiExtractor.py  -b 2000M -o zhwiki_extracted zhwiki-latest-pages-articles.xml.bz2</span><br></pre></td></tr></table></figure>
<p>由于这个工具就是一个python脚本，因此无需安装，<code>-b</code>
参数指对提取出来的内容进行切片后每个文件的大小，如果要将所有内容保存在同一个文件，那么就需要把这个参数设得大一下，<code>-o</code>
的参数指提取出来的文件放置的目录，抽取出来的文件的路径为<code>zhwiki_extract/AA/wiki_00</code>。更多参数可参考其github主页的说明。</p>
<p>抽取后的内容格式为每篇文章被一对<code>&lt;doc&gt; &lt;/doc&gt;</code>包起来，而<code>&lt;doc&gt;</code>中的包含了属性有文章的id、url和title属性，如<code>&lt;doc id="13" url="https://zh.wikipedia.org/wiki?curid=13" title="数学"&gt;</code>。</p>
<h3 id="繁简转换">繁简转换</h3>
<p>由上一步提取出来的中文维基百科中的语料中既有繁体字也有简体字，这里需要将其统一变为简体字，采用的工具也是开源的
<a href="https://github.com/BYVoid/OpenCC">OpenCC</a>
转换器。使用方法如下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/BYVoid/OpenCC.git</span><br><span class="line">$ <span class="built_in">cd</span> OpenCC &amp;&amp; make &amp;&amp; make install</span><br><span class="line">$ opencc -i zhwiki_extract/AA/wiki_00 -o zhwiki_extract/zhs_wiki -c /home/nlp/OpenCC/data/config/t2s.json</span><br></pre></td></tr></table></figure>
<p>我使用的是
centos，yum源中找不到这个软件，因此通过编译安装最新的版本，需要注意的是编译OpenCC
要求gcc的版本最低为 4.6 。其中 <code>-i</code>表示输入文件路径，
<code>-o</code>表示输出的文件
，<code>-c</code>表示转换的配置文件，这里使用的繁体转简体的配置文件，OpenCC自带了一系列的转换配置文件，可参考其github主页的说明。</p>
<h3 id="去除标点符号">去除标点符号</h3>
<p>去除标点符号有两个问题需要解决，一是像下面这种为了解决各地术语名称不同的问题
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">他的主要成就包括Emacs及後來的GNU Emacs，GNU C 編譯器及-&#123;zh-hant:GNU 除錯器;zh-hans:GDB 调试器&#125;-。</span><br></pre></td></tr></table></figure></p>
<p>另外一个就是将所有标点符号替换成空字符，通过正则表达式均可解决这两个问题，下面是具体实现的python代码。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*- </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pre_process</span>(<span class="params">input_file, output_file</span>):</span><br><span class="line">    multi_version = re.<span class="built_in">compile</span>(u<span class="string">r&#x27;-\&#123;.*?(zh-hans|zh-cn):([^;]*?)(;.*?)?\&#125;-&#x27;</span>)</span><br><span class="line">    punctuation = re.<span class="built_in">compile</span>(<span class="string">u&quot;[-~!@#$%^&amp;*()_+`=\[\]\\\&#123;\&#125;\&quot;|;&#x27;:,./&lt;&gt;?·！@#￥%……&amp;*（）——+【】、；‘：“”，。、《》？「『」』]&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> io.<span class="built_in">open</span>(output_file, mode = <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">        <span class="keyword">with</span> io.<span class="built_in">open</span>(input_file, mode = <span class="string">&#x27;r&#x27;</span>, encoding =<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> infile:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> infile:</span><br><span class="line">                line = multi_version.sub(u<span class="string">r&#x27;\2&#x27;</span>, line)</span><br><span class="line">                line = punctuation.sub(<span class="string">&#x27;&#x27;</span>, line.decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">                outfile.write(line)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) != <span class="number">3</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Usage: python script.py input_file output_file&quot;</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    input_file, output_file = sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>]</span><br><span class="line">    pre_process(input_file, output_file)</span><br></pre></td></tr></table></figure>
<h3 id="分词">分词</h3>
<p>经过上面的步骤基本得到了都是简体中文的纯净文本，下面需要对其进行分词并且整理成每行一篇文本的格式，从而方便后续的处理。</p>
<p>分词采用 python 的分词工具 <a
href="https://github.com/fxsjy/jieba">jieba</a>，通过
<code>pip install jieba</code>
安装即可。且将一篇文章分词后的结果存储在一行，由前面可知，每篇文章存储在一对<code>&lt;doc&gt;&lt;/doc&gt;</code>标签中，由于前面去掉了标点，所以现在变成了<code>doc doc</code>,所以只要判断当前行为<code>doc</code>时即可认为文章结束，从而开始在新的一行记录下一篇文章的分词结果。实现的python代码如下:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cut_words</span>(<span class="params">input_file, output_file</span>):</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> io.<span class="built_in">open</span>(output_file, mode = <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">        <span class="keyword">with</span> io.<span class="built_in">open</span>(input_file, mode = <span class="string">&#x27;r&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> infile:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> infile:</span><br><span class="line">                line = line.strip()</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(line) &lt; <span class="number">1</span>:  <span class="comment"># empty line</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> line.startswith(<span class="string">&#x27;doc&#x27;</span>): <span class="comment"># start or end of a passage</span></span><br><span class="line">                    <span class="keyword">if</span> line == <span class="string">&#x27;doc&#x27;</span>: <span class="comment"># end of a passage</span></span><br><span class="line">                        outfile.write(<span class="string">u&#x27;\n&#x27;</span>)</span><br><span class="line">                        count = count + <span class="number">1</span></span><br><span class="line">                        <span class="keyword">if</span>(count % <span class="number">1000</span> == <span class="number">0</span>):</span><br><span class="line">                            <span class="built_in">print</span>(<span class="string">&#x27;%s articles were finished.......&#x27;</span> %count)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> jieba.cut(line):</span><br><span class="line">                    outfile.write(word + <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%s articles were finished.......&#x27;</span> %count)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &lt; <span class="number">3</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Usage: python script.py input_file output_file&quot;</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    input_file, output_file = sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>]</span><br><span class="line">    cut_words(input_file, output_file)</span><br></pre></td></tr></table></figure>
<h2 id="通过-word2vec-训练词向量">通过 Word2Vec 训练词向量</h2>
<p>Word2vec中包含了两种训练词向量的方法：Continuous Bag of
Words(CBOW)和Skip-gram。CBOW的目标是根据上下文来预测当前词语的概率。Skip-gram刚好相反，根据当前词语来预测上下文的概率。这两种方法都利用人工神经网络作为它们的分类算法。起初，每个单词都是一个随机N维向量。训练时，该算法利用CBOW或者Skip-gram的方法获得了每个单词的最优向量。</p>
<p>最初 Google 开源的 Word2Vec 是用C来写的，后面陆续有了Python ，Java
等语言的版本，这里采用的是 Python 版本的 <a
href="http://radimrehurek.com/gensim/models/word2vec.html">gensim</a>。通过
gensim 提供的 API
可以比较容易地进行词向量的训练。gensim的建议通过conda安装，步骤如下:</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">$ wget https://repo.continuum.io/archive/Anaconda2-<span class="number">4.1</span><span class="number">.1</span>-Linux-x86_64.sh</span><br><span class="line">$ bash Anaconda2-<span class="number">4.1</span><span class="number">.1</span>-Linux-x86_64.sh</span><br><span class="line">$ conda update conda</span><br><span class="line">$ conda install gensim</span><br></pre></td></tr></table></figure>
<p>Linux 系统一般原来会带有 python，直接执行 python
命令可能会调用系统内置的 python 解释器，因此如果要使用conda安装的
python， 执行 python 命令的时候需要输入指定其通过 conda
安装的完整目录，或者将这个路径添加在环境变量<code>$PATH</code>之前。</p>
<p>下面是对上面处理后的语料库进行训练的一个简单例子。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> gensim  </span><br><span class="line"></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">word2vec_train</span>(<span class="params">input_file, output_file</span>):</span><br><span class="line">    sentences = gensim.models.word2vec.LineSentence(input_file)</span><br><span class="line">    model = gensim.models.Word2Vec(sentences, size=<span class="number">300</span>, min_count=<span class="number">10</span>, sg=<span class="number">0</span>, workers=multiprocessing.cpu_count())</span><br><span class="line">    model.save(output_file)</span><br><span class="line">    model.save_word2vec_format(output_file + <span class="string">&#x27;.vector&#x27;</span>, binary=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) &lt; <span class="number">3</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;Usage: python script.py infile outfile&quot;</span></span><br><span class="line">        sys.exit()</span><br><span class="line">    input_file, output_file = sys.argv[<span class="number">1</span>], sys.argv[<span class="number">2</span>]</span><br><span class="line">    word2vec_train(input_file, output_file)</span><br></pre></td></tr></table></figure>
<p>上面的训练过程首先将输入的文件转为 gensim 内部的 LineSentence
对象，<strong>要求输入的文件的格式为每行一篇文章，每篇文章的词语以空格隔开</strong>。</p>
<p>然后通过 <code>gensim.models.Word2Vec</code> 初始化一个 Word2Vec
模型，<code>size</code>参数表示训练的向量的维数；<code>min_count</code>表示忽略那些出现次数小于这个数值的词语，认为他们是没有意义的词语，一般的取值范围为（0，100）；<code>sg</code>表示采用何种算法进行训练，取0时表示采用CBOW模型，取1表示采用skip-gram模型；<code>workers</code>表示开多少个进程进行训练，采用多进程训练可以加快训练过程，这里开的进程数与CPU的核数相等。</p>
<p>最后将训练后的得到的词向量存储在文件中，存储的格式可以是 gensim
提供的默认格式(<code>save</code>方法)，也可以与原始c版本word2vec的
vector 相同的格式(<code>save_word2vec_format</code>方法)，加载时分别采用
<code>load</code> 方法和 <code>load_word2vec_format</code>
方法即可。更详细的API可参考
https://rare-technologies.com/word2vec-tutorial/ 和
http://radimrehurek.com/gensim/models/word2vec.html。</p>
<p>假设我们训练好了一个语料库的词向量，当一些新的文章加入这个语料库时，如何训练这些新增的文章从而更新我们的语料库？将全部文章再进行一次训练显然是费时费力的，gensim提供了一种类似于“增量训练”的方法。即可在原来的model基础上仅对新增的文章进行训练。如下所示为一个简单的例子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">model = gensim.models.Word2Vec.load(exist_model)</span><br><span class="line">model.train(new_sentences)</span><br></pre></td></tr></table></figure>
<p>上面的代码先加载了一个已经训练好的词向量模型，然后再添加新的文章进行训练，同样新增的文章的格式也要满足每行一篇文章，每篇文章的词语通过空格分开的格式。<strong>这里需要注意的是加载的模型只能
是通过<code>model.save()</code>存储的模型，从<code>model.save_word2vec_format()</code>恢复过来的模型只能用于查询.</strong></p>
<h2 id="通过-glove-训练词向量">通过 Glove 训练词向量</h2>
<p>除了上面的 Word2Vec ，通过 Glove
也可以训练出词向量，只是这种方法并没有 Word2Vec
用得那么广泛。这里简单提及，也算是为训练词向量提供多一个选择。</p>
<p>首先需要下载并编译 Glove，步骤如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wget http://www-nlp.stanford.edu/software/GloVe-1.2.zip</span><br><span class="line">$ unzip Glove-1.2.zip </span><br><span class="line">$ cd Glove-1.2 &amp;&amp; make</span><br></pre></td></tr></table></figure></p>
<p>编译后会在 <code>Glove-1.2</code> 目录下生成一个 <code>build</code>
目录，里面包含了训练需要用到的工具。目录结构如下所示： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">build/</span><br><span class="line">|-- cooccur</span><br><span class="line">|-- glove</span><br><span class="line">|-- shuffle</span><br><span class="line">`-- vocab_count</span><br></pre></td></tr></table></figure></p>
<p>训练过程总共分为四步，对应上面的四个工具，顺序依次为<code>vocab_count --&gt; cooccur --&gt; shuffle --&gt; glove</code>，下面是具体的训练过程</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ build/vocab_count -min-count 5 -verbose 2 &lt; zhs_wiki_cutwords &gt; zhs_wiki_vocab</span><br><span class="line"></span><br><span class="line">$ build/cooccur -memory 4.0 -vocab-file zhs_wiki_vocab  -verbose 2 -window-size 5 &lt; zhs_wiki_cutwords &gt; zhs_wiki_cooccurence.bin</span><br><span class="line"></span><br><span class="line">$ build/shuffle  -memory 4.0 -verbose 2 &lt; zhs_wiki_cooccurence.bin &gt;zhs_wiki_shuff.bin</span><br><span class="line"></span><br><span class="line">$ build/glove -save-file zhs_wiki_glove.vectors -threads 8 -input-file zhs_wiki_shuff.bin -vocab-file zhs_wiki_vocab -x-max 10 -iter 5 -vector-size 300 -binary 2 -verbose 2 </span><br></pre></td></tr></table></figure>
<p>上面四条命令分别对应于训练的四个步骤，每个步骤含义如下</p>
<ol type="1">
<li><p><code>vocab_count</code>从语料库(<code>zhs_wiki_cutwords</code>是上面第一步处理好的语料库)中统计词频，输出文件
<code>zhs_wiki_vocab</code>，每行为<code>词语 词频</code>；<code>-min-count 5</code>指示词频低于5的词舍弃，<code>-verbose 2</code>控制屏幕打印信息的，设为0表示不输出</p></li>
<li><p><code>cooccur</code> 从语料库中统计词共现，输出文件
<code>zhs_wiki_cooccurence.bin</code>，格式为非文本的二进制；<code>-memory 4.0</code>指示<code>bigram_table</code>缓冲器，<code>-vocab-file</code>指上一步得到的文件，<code>-verbose 2</code>同上，<code>-window-size 5</code>指示词窗口大小。</p></li>
<li><p><code>shuffle</code> 对 <code>zhs_wiki_cooccurence.bin</code>
重新整理，输出文件<code>zhs_wiki_shuff.bin</code></p></li>
<li><p><code>glove</code>
训练模型，输出词向量文件。<code>-save-file</code>
、<code>-threads</code> 、<code>-input-file</code>
和<code>-vocab-file</code>
直接按照字面应该就可以理解了，<code>-iter</code>
表示迭代次数，<code>-vector-size</code>
表示向量维度大小，<code>-binary</code>
控制输出格式<code>0: save as text files; 1: save as binary; 2: both</code></p></li>
</ol>
<p>训练后得到的二进制词向量模型格式与原始c版本word2vec的 vector
格式也相同，可以通过下面的方法统一加载使用。</p>
<h2 id="使用词向量模型">使用词向量模型</h2>
<p>训练好的词向量可以供后续的多项自然语言处理工作使用，下面是通过 gensim
加载训练好的词向量模型并进行查询的例子</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = Word2Vec.load_word2vec_format(<span class="string">&#x27;/home/nlp/zhs_wiki_trained.vector&#x27;</span>,binary = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 词向量维度</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(model[<span class="string">u&#x27;男人&#x27;</span>])</span><br><span class="line"><span class="number">300</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 具体词向量的值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model[<span class="string">u&#x27;男人&#x27;</span>]</span><br><span class="line">array([ <span class="number">0.56559366</span>, -<span class="number">1.96017861</span>, -<span class="number">1.57303607</span>,  <span class="number">1.2871722</span> , -<span class="number">1.38108838</span>.....</span><br><span class="line"></span><br><span class="line"><span class="comment"># 词语相似性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.similarity(<span class="string">u&#x27;男人&#x27;</span>,<span class="string">u&#x27;女人&#x27;</span>)</span><br><span class="line"><span class="number">0.86309866214314379</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找某个词的近义词，反义词</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words = model.most_similar(<span class="string">u&quot;男人&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> word[<span class="number">0</span>], word[<span class="number">1</span>]</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">女人 <span class="number">0.863098621368</span></span><br><span class="line">女孩 <span class="number">0.67369633913</span></span><br><span class="line">女孩子 <span class="number">0.658665597439</span></span><br><span class="line">陌生人 <span class="number">0.654322624207</span></span><br><span class="line">小女孩 <span class="number">0.637025117874</span></span><br><span class="line">小孩 <span class="number">0.630155563354</span></span><br><span class="line">男孩 <span class="number">0.625135600567</span></span><br><span class="line">男孩子 <span class="number">0.617452859879</span></span><br><span class="line">小孩子 <span class="number">0.613232254982</span></span><br><span class="line">老婆 <span class="number">0.584552764893</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words = model.most_similar(positive=[<span class="string">u&quot;女人&quot;</span>, <span class="string">u&quot;皇后&quot;</span>], negative=[<span class="string">u&quot;男人&quot;</span>], topn=<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span> word[<span class="number">0</span>], word[<span class="number">1</span>]</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">皇太后 <span class="number">0.630089104176</span></span><br><span class="line">太后 <span class="number">0.613425552845</span></span><br><span class="line">王妃 <span class="number">0.581929504871</span></span><br><span class="line">贵妃 <span class="number">0.581658065319</span></span><br><span class="line">王后 <span class="number">0.577878117561</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 若干个词中剔除与其他最不相关的</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>  model.doesnt_match(<span class="string">u&quot;早餐 晚餐 午餐 食堂&quot;</span>.split())</span><br><span class="line">食堂</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>  model.doesnt_match(<span class="string">u&quot;早餐 晚餐 午餐 食堂 教室&quot;</span>.split())</span><br><span class="line">教室</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多个词语的相似性</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>model.n_similarity([<span class="string">u&quot;女人&quot;</span>, <span class="string">u&quot;皇帝&quot;</span>], [<span class="string">u&quot;男人&quot;</span>, <span class="string">u&quot;皇后&quot;</span>])</span><br><span class="line"><span class="number">0.76359309631510597</span></span><br></pre></td></tr></table></figure>
<p>这里并没有对训练出来的词向量质量进行评估，虽然 Google
提供了一种测试集，约20000句法和语义的测试实例（<a
href="https://flystarhe.github.io/2016/09/04/word2vec-test/">questions-words.txt</a>），检查如<code>A对于B类似C对于D</code>这种线性平移关系。由于测试集是英文的，因此可以考虑翻译过来然后对中文的采用同样的评估方法，但是实际的效果还是要看具体应用中的效果。</p>
<hr />
<p>参考： https://flystarhe.github.io/2016/09/04/word2vec-test/
https://flystarhe.github.io/2016/08/31/wiki-corpus-zh/
http://radimrehurek.com/gensim/models/word2vec.html
https://rare-technologies.com/word2vec-tutorial/</p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么相爱容易,相守不易？</title>
    <url>/2015/12/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%9B%B8%E7%88%B1%E5%AE%B9%E6%98%93-%E7%9B%B8%E5%AE%88%E4%B8%8D%E6%98%93%EF%BC%9F/</url>
    <content><![CDATA[<blockquote>
<p>文章为转载，作者：淡水天</p>
</blockquote>
<p>该文从比较科学的角度阐述了一个不怎么科学的现象，值得一看。下面为原文</p>
<p>一桩桩分手或出轨的事件，像恼人的烟雾一样缠绕住心怀，更是让许多人直呼“再也不相信爱情了”。哎，为何世间好物如此不坚牢，开头美好，结局却潦倒？相爱容易，相守却很难？
<span id="more"></span></p>
<h2
id="哪里有什么爱情不过是生殖冲动">哪里有什么爱情？不过是生殖冲动</h2>
<p>爱是什么？大约谁也道不清。它是一道隐秘的风，没有轮廓，没有重量，吹过人们柔软的身体，也吹皱他们的心。初初相爱的男女为轻飘飘的快乐所托起，在云层间来回轻踱。</p>
<p>爱没有名字。若是非要给它找一个丈量的器具，那么怦然跃动的心，手掌里沁出的汗，面颊上映出的云霞....或可作为一种参照。在爱之开端，激情浇灌着两颗年轻的心。然而，也因了爱情模糊的面目，个体的紧张与唤醒状态也会被贴上“爱情”的标签。心理学家哈特菲尔德甚至认为，爱情就是生理唤醒和心理标签相互作用的结果。</p>
<p>阿瑟·阿伦（ArthurAron，1974）曾经做过一个经典的实验，他找来一位漂亮的女助手，由她去找男性被试完成一个简单的问卷，再让他们根据一张图片编一个小故事。参加实验的大学生被分为三组，分别在安静的公园、坚固而低矮的石桥，以及危险的吊桥上接受调查。最后，这位漂亮的女助手把自己的联系方式告诉了每一位参加实验的大学生，如果他们想进一步了解实验可以给她打电话。</p>
<p>猜一猜，最后的结果如何？没错，与其他两组相比，在危险的吊桥上参加实验的大学生给女调查者打电话的人数最多，而他们所编撰的故事中，也更多含有情爱的色彩。</p>
<p><strong>这就是著名的“吊桥效应”，其理论来源是沙赫特的“情绪三因素理论”，情绪=刺激×生理唤醒×认知标签。</strong>个体如何解释情境及生理反应，往往与外部的线索和“诱因”有关。大部分男性把横渡吊桥时因为紧张所致的口渴感，以及心跳加速等生理上的兴奋误认为性冲动，于是在心底埋下了一颗爱情的种子。</p>
<p>事实上，在加拿大温哥华北部的千山万壑之中确实存在着一座“爱情桥”——卡皮兰诺吊桥。它全长137米，悬挂在高达70米的河谷上。无数往来的男女在这座惊心动魄的吊桥上演绎了一段段爱情佳话。</p>
<p><img
src="http://static.zybuluo.com/WuLiangchao/310owivp6u40l4lyn13kpgmh/mp8712460_1427768399998_3.jpeg" /></p>
<p>爱情正是这样不靠谱的存在，无怪乎钱钟书先生在《围城》一书中借方鸿渐之口说出，“哪里有什么爱情？不过是生殖冲动。”<strong>爱情的产生就是一场索然无趣的化学反应，一段美好的爱情关系，通常是人体内几种不同的化学物质（如多巴胺、催产素等）相互作用的结果。大脑神经会经历很多不同的化学反应过程，当外界的刺激按照正确的顺序，刺激到正确的复合体时，人们就会相爱。</strong></p>
<h2 id="短暂的投射认同游戏">短暂的“投射—认同”游戏</h2>
<p>相爱是不难的，难的是相依相伴，相守终生。犹记得《笑傲江湖》里，苍茫大雪纷飞，林平之执剑在少室山的雪人身后刻下“海枯石烂，此情不渝”八个大字，那时的情浓意长，你焉能说他没有一点真心？却也还是敌不住日后的风霜刀剑严相逼啊。</p>
<p><strong>爱情也有生命，也会经历生老病死，种种的一切。爱意的萌生或许只是刹那间的电光火石，但维护爱情的生命却需付诸百倍的时间与耐性。</strong>作为最强烈的人际吸引形式，爱情也有其循序渐进的过程，在时日缓慢的雕琢中，从定向阶段，到情感探索阶段，再到情感交流阶段，最后才会步入稳定交往阶段。</p>
<p>所谓的“经营爱情”大多指的就是在“<strong>情感探索</strong>”和“<strong>情感交流</strong>”这两个阶段的相处与沟通之道。通常在情感探索阶段的初期，双方因为相当程度上的保留与节制，仍然<strong>通过“投射”与“认同”来维护关系，恋人小心翼翼地开放着自己的私人领域，也好奇地探索着关于对方的一切，他们修饰着自己也美化着对方，同时因为接触与了解的程度不深，也可以较少地受到对方自身特质的干扰，迅速地把自己的早期客体形象，投射到对方身上。而对方为了讨得恋人的欢心，也会迅速地认同这个投射，做出恋人理想中的样子来。</strong></p>
<p>这是最甜蜜的阶段，他们就像是两个小孩子，围着一个神秘的果酱罐，一点一点地尝它，看看里面有多少甜。</p>
<p>然而，爱情并不只是甜的。<strong>当那个果酱罐被一点点地打开之后，它的神秘感与新鲜感都将消失，那时呈现在眼前的或许只是一只平凡无奇的小罐头而已，不同于最初的想象。</strong></p>
<p>甚至，令你失望。</p>
<h2 id="我是流泪的洋葱你还爱我吗">我是流泪的洋葱，你还爱我吗？</h2>
<p>随着交往的加深，早期的“投射—认同”游戏已经无法再继续下去，恋人被压抑的真实自我在呼唤得到释放，他们无法再去扮演一个理想的恋人，而更想去做一个真实的恋人。</p>
<p>这也是亲密关系的真谛。<strong>人们之所以想组建亲密关系，之所以想爱与被爱，就是想获得一种亲密感。亲密需要把自我最深处的部分向他人也向自己呈现，卸除掉层层的伪装与防护，建立起真我与真我之间的连接感。</strong></p>
<p>在这个阶段，双方的信任感、依恋感开始建立，沟通的深度和广度也有所发展，开始牵涉到较深的情感卷入。<strong>这是心与心之间相知的契机，但同时也是一场充满风险的赌博。</strong></p>
<p>人们的内心常常由三层组成：<strong>最外面一层是保护层，接下来是伤痛，而最深处是真我</strong>。每个人的成长多多少少都会经历一些伤痛，或者来自于父母，或者来自重要他人，或者是一些创伤性的体验。<strong>因为这些伤痛的存在，所以人们发展出了保护层和种种防御机制，以守护脆弱的内核。</strong>当恋人鼓起勇气一层层地剥落掉充满防御机制的外壳时，也是在将自己的伤痛展示给对方看，这是痛苦的，必定会像剥洋葱皮一样，一边剥落一边掉泪。</p>
<p>如果对方的反应是积极的、接纳的，那么恋人即便落泪痛苦，也会因为感受到情感上的陪伴与支持，而坚定地一层层剥落掉那些保护壳，直到露出完整的内核。倘若双方都能如此坦然地接纳对方，那么爱情就会发展到稳定交往阶段，琴瑟和鸣，风雨同舟。</p>
<p>但很多时候，受限于自己的狭隘、缺陷，以及种种未处理完的情结，人们渴望亲密，又害怕亲密，宁愿相信坦露真实的自我只会招致他人的批判、拒绝和抛弃，也很难相信有人肯接纳自己内在的真实。于是，在关系发展到一定程度时，就会退缩、害怕、扮演角色，在操纵与受控之间游走，生出嫉妒与厌恶、逃离与背叛之心，将关系场演变成游乐场，上演出种种的闹剧与幻想。</p>
<h2 id="爱是一门艺术">爱是一门艺术</h2>
<p>归根结底，相爱容易，而相守不易，也是因为我们错误地理解了“爱”。</p>
<p><strong>人是孤独的，他与外物、与社会、与世界分离，这种孤独创造了一种无法忍受的监禁感，使得人们迫切地寻求与他人的连接。但也正因如此，人们才将爱情的重心放在“体验被爱”，而不是“体验爱”上。于是酿制出种种矛盾，衍生出种种失望。</strong></p>
<p>弗洛姆认为，爱不仅是情感，爱也是一种能力，更是一门艺术。如果说爱情始于生理唤醒，又在“你投射，我认同”的模式下发酵发展，那么能够相依相伴必定是因为习得了爱的能力，掌握了爱的艺术。</p>
<p>爱的四要素包括关心、尊重、责任和认识。只有当我们从整体上理解爱人，为对方投注以主动的关怀，尊重他的真实存在，为他的精神成长负起责任时，我们才能维持长久的关系。</p>
<p>这是一场<strong>相互的驯化，是两个个体之间“不完整的融合”，是在距离感与亲密感之间取得一个合理的平衡点。它需要很多的耐心与时间，又在耐心与时间中酿造出新的意义。</strong></p>
<p><strong>乱入图片一张</strong> <img
src="https://wulc.me/imgs/Screenshot_2015-02-13-21-10-07.jpg" /></p>
<p>做到这一切并不容易。爱有起点，也必有终点，以死亡为句读是爱最好的结局，也是最难的结局。但当你用心地去呵护爱情的生命时，你会发现，一切终将黯淡，唯有被爱的目光镀过金的日子依然在岁月的深谷里闪耀着永恒的光芒。</p>
<p>那是赠与你的礼物。即便爱情终将死亡，你也可以做那个延长它生命的人。即便你护卫不了对方的心，你也始终可以护卫自己的心，守住自己对爱的这份忠贞。</p>
<p>别再说什么不相信爱情了，我知道——你只是不愿去相信自己。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉树的遍历方法</title>
    <url>/2016/06/05/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>二叉树的遍历方法有三种，分别是前序遍历，中序遍历和后序遍历。其中的前、中、后分别表示根节点在遍历中被访问的次序。因此，各个遍历方式的访问顺序如下所示：</p>
<span id="more"></span>
<p><strong>前序遍历：根节点--&gt;左子树--&gt;右子树
中序遍历：左子树--&gt;根节点--&gt;右子树
后序遍历：左子树--&gt;右子树--&gt;根节点</strong></p>
<p>下面通过 python
分别实现这三种遍历的递归方法和非递归方法，首先定义每个节点如下所示</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TreeNode</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x</span>):</span><br><span class="line">        self.val = x</span><br><span class="line">        self.left = <span class="literal">None</span></span><br><span class="line">        self.right = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h2 id="前序遍历">前序遍历</h2>
<h3 id="递归实现">递归实现</h3>
<p>递归实现的方法非常简单，就是先访问根节点，然后访问左子树，最后访问右子树即可。实现代码如下所示：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preorderTraversal</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :type root: TreeNode</span></span><br><span class="line"><span class="string">    :rtype: List[int]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    result.append(root.val)</span><br><span class="line">    result += preorderTraversal(root.left)</span><br><span class="line">    result += preorderTraversal(root.right)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<h3 id="非递归实现">非递归实现</h3>
<p>非递归的方法通过栈来实现，流程如下 （1）将根节点设为当前节点
（2）记录当前节点C的值，然后将C入栈，将当前节点设为C的左子节点
（3）重复步骤（2）直到访问到空叶子节点，然后从栈中弹出一个元素D，并将当前节点设为D的右子节点,重复步骤（2）
（4)重复步骤（2）~（3）直到栈为空</p>
<p>实现代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preorderTraversal</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :type root: TreeNode</span></span><br><span class="line"><span class="string">    :rtype: List[int]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    stack, result = [], []</span><br><span class="line">    curr_node = root</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(stack) != <span class="number">0</span> <span class="keyword">or</span> curr_node!= <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> curr_node != <span class="literal">None</span>:</span><br><span class="line">            result.append(curr_node.val)</span><br><span class="line">            stack.append(curr_node)</span><br><span class="line">            curr_node = curr_node.left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tmp = stack.pop()</span><br><span class="line">            curr_node = tmp.right</span><br><span class="line">    <span class="keyword">return</span> result  </span><br></pre></td></tr></table></figure></p>
<h2 id="中序遍历">中序遍历</h2>
<h3 id="递归实现-1">递归实现</h3>
<p>递归实现也非常简单，按照顺序访问即可，实现代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inorderTraversal</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :type root: TreeNode</span></span><br><span class="line"><span class="string">    :rtype: List[int]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    result += inorderTraversal(root.left)</span><br><span class="line">    result.append(root.val)</span><br><span class="line">    result += inorderTraversal(root.right)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
### 非递归实现</p>
<p>非递归实现的过程类似于前序遍历的非递归实现，只是在记录节点的时间不同，中序周游记录是在元素从栈里弹出的时候才记录元素的值。实现的步骤如下：</p>
<p>（1）将根节点设为当前节点
（2）将当前节点C入栈，然后将当前节点设为C的左子节点
（3）重复步骤（2）直到访问到空叶子节点，然后从栈中弹出一个元素D，记录元素D的值，并将当前节点设为D的右子节点,重复步骤（2）
（4)重复步骤（2）~（3）直到栈为空</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inorderTraversal</span>(<span class="params"> root</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :type root: TreeNode</span></span><br><span class="line"><span class="string">    :rtype: List[int]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    stack, result= [], []</span><br><span class="line">    curr_node = root</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(stack) != <span class="number">0</span> <span class="keyword">or</span> curr_node != <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> curr_node != <span class="literal">None</span>:</span><br><span class="line">            stack.append(curr_node)</span><br><span class="line">            curr_node = curr_node.left</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tmp = stack.pop()</span><br><span class="line">            result.append(tmp.val)</span><br><span class="line">            curr_node = tmp.right</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="后序遍历">后序遍历</h2>
<h3 id="递归实现-2">递归实现</h3>
<p>后序遍历的实现也非常简单，只需要按照顺序访问即可，实现代码如下所示：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">postorderTraversal</span>(<span class="params">root</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :type root: TreeNode</span></span><br><span class="line"><span class="string">    :rtype: List[int]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    result += postorderTraversal(root.left)</span><br><span class="line">    result += postorderTraversal(root.right)</span><br><span class="line">    result.append(root.val)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
<h3 id="非递归实现-1">非递归实现</h3>
<p>后续遍历的非递归实现利用了一点小技巧，就是先进行<code>根节点--&gt;右子树--&gt;左子树</code>的遍历,然后将得到的结果进行反转（reverse）即可。这是因为当根节点最后访问时无法确定何时该记录这个值。</p>
<p>实现的过程也类似于前序遍历，具体过程如下： （1）将根节点设为当前节点
（2）记录当前节点C的值，然后将C入栈，将当前节点设为C的右子节点
（3）重复步骤（2）直到访问到空叶子节点，然后从栈中弹出一个元素D，并将当前节点设为D的左子节点,重复步骤（2）
（4)重复步骤（2）~（3）直到栈为空</p>
<p>实现代码如下所示： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">postorderTraversal</span>(<span class="params">self, root</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    :type root: TreeNode</span></span><br><span class="line"><span class="string">    :rtype: List[int]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    stack, result = [], []</span><br><span class="line">    curr_node = root</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(stack)!=<span class="number">0</span> <span class="keyword">or</span> curr_node != <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> curr_node != <span class="literal">None</span>:</span><br><span class="line">            result.append(curr_node.val)</span><br><span class="line">            stack.append(curr_node)</span><br><span class="line">            curr_node = curr_node.right</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tmp = stack.pop()</span><br><span class="line">            curr_node = tmp.left</span><br><span class="line">    result.reverse() </span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title>《认知红利》阅读笔记(2)-大脑升级</title>
    <url>/2021/10/05/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(2)-%E5%A4%A7%E8%84%91%E5%8D%87%E7%BA%A7/</url>
    <content><![CDATA[<p>本文是《<a
href="https://book.douban.com/subject/34793488/">认知红利</a>》下半部分内容的笔记(书里的上半部分的内容可参考<a
href="https://wulc.me/2021/08/22/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E6%A6%82%E5%BF%B5%E9%87%8D%E5%A1%91/">《认知红利》阅读笔记(1)-概念重塑</a>)，这里的“大脑升级”采用的是原书的大标题，简单来说就是这部分内容侧重方法论，主要介绍了一些分析问题、解决问题的思维方式，具备一定的实践意义，本文记录了对笔者而言印象比较深刻的观点，推荐读一下原书。</p>
<span id="more"></span>
<h2 id="解开大脑的封印">解开大脑的封印</h2>
<h3 id="大脑的封印">大脑的封印</h3>
<h4 id="两道封印">两道封印</h4>
<p>书里认为大脑的两道封印是：<strong>负面词语和负面情绪</strong>；主要观点是这些负面的词语和情绪会影响到人的思维方式，进而影响人的具体行动</p>
<p>什么是负面词语?
比如我不行、我做不到、我没有办法、这样行不通......在这些语句中的“不、没有”就是负面词语，书里的观点是“<strong>当我们使用“负面词语”来思考问题的时候，我们大脑状态就是停滞的</strong>”，这个观点其实在《得意忘形》播客里的第11期有更详细的介绍和延伸：<a
href="https://www.ximalaya.com/yule/6688726/34642375">不如我们停止自我攻击，看看会发生什么？</a></p>
<p>书里给出的方法路是：找到这些限制你思考的负面词语，并把它们从你的语言中删除，并用正面词语代替，笔者理解就是从思维上需要进行
“<strong>描述-&gt;行动</strong>”的转换，因为抱怨、愤懑是无法解决问题的，如下是一些例子</p>
<blockquote>
<p>我没有朋友 →我要多参加一些社交活动 这个没办法 →我要换个新角度思考一下
我不想那么穷 →我要想办法增加收入</p>
</blockquote>
<p>负面情绪则更常见的，通常是由外部引起的，如同书里提到的“既然是外围世界导致了你的情绪，那么你要么改变世界，要么控制自己”；所以大多数人在面对负面情绪的时候，往往会选择如下几种方式处理：发泄、隐忍、转移...</p>
<p>但核心问题是，如果负面情绪是由外部变化造成且这些外部变化是长期存在的，那么上面这些处理方法都是治标不治本的，那该如何做?书里从给了如下例子分析负面情绪产生的根本原因</p>
<blockquote>
<p>你正参加一场培训，很认真地在听讲，突然老师冲下讲台，抢走了你的手机，然后对你大吼一声:“你爸妈小时候怎么教你的?!上课玩
手机，你懂不懂尊重人啊!你是不是有病啊!” 然后当着众人的面，越骂越凶......
请问，你心里是什么感受?
一定是怒火中烧吧，是不是会立刻站起来怼回去?甚至握紧了双拳，随时准备挥舞?
可是，如果你在上课之前，收到了这样一条消息:“今天给你们分享的这位老师，有点精神失常，今早出门的时候忘记吃药了，你要小心一点......”
再面对刚才的一幕，请问你心里又会是什么感受?
也许不是愤怒而是害怕了吧，不是想怼回去，而是想赶紧躲得远远的吧......</p>
<p>为什么同样的场景，同样的人，做同样的事情，你会表现出截然不同的情绪反应?
这里有两个原因:
1.你对外围世界的理解发生了变化。原来你觉得老师是个正常人，现在变成神经病了!正常人做出这种行为是不可理喻的，而神经病做出这种行为就是情理之中的......
2.你对眼前问题失去了掌控力。老师原来是个正常人，你这样羞辱我，我是有办法处理这种情况的，我要么怼回去，要么把你打趴下;可如果面对的是一个神经病，那我真不敢保证搞得过他，谁知道他会干嘛，吓死人了，还是走为上计</p>
</blockquote>
<p>上面的 2 个原因，可更抽象一层，记为如下两个原因</p>
<p><strong>1.信念不匹配</strong>。即外在世界与内在的 BVR
信念系统(参考上书里第一部分内容)冲突，与自己预期不符
<strong>2.能力不足够</strong>。类似常说的无能狂怒，负面情绪的出现，往往是有事情阻碍了我们，当我们无法很好解决时，负面情绪标会一直都在</p>
<h4 id="解开封印">解开封印</h4>
<p>怎么解开封印？或者说怎么避免负面情绪？书里给出了<strong>长期和短期</strong>的两个方法</p>
<p>长期方法是指在没有情绪的时候，好好调养自己的身心，让负面情绪的状态根本没有机会出现，书里主要提到了一下两点</p>
<p><strong>1.提升解决问题的能力</strong>，这一点针对的是上面的“能力不足够”的原因，比较好理解，如果一个人的大部分问题都能够被很好处理，那自然不会有过多的负面情绪</p>
<p><strong>2.建立正面的信念系统</strong>，这一点针对的是上面的“信念不匹配”的原因，书里给了
12 条供参考的信念，其实就是给了我们另一种看待世界的方式</p>
<blockquote>
<p><strong>1.没有两个人是一样的</strong>
每一个人都在不同的环境里长大，形成了不同的价值观和信念系统，因此对待同一个问题，自然会有不同的看法，你要学会接受这一事实</p>
<p><strong>2.一个人不能控制另外一个人</strong>
每个人的信念、价值观、行为习惯等，只对自己有效，不应该强加给另外一个人</p>
<p><strong>3.有效果比有道理更重要</strong>
听上去再有道理的道理，如果实际应用的时候没效果，那就是没道理。在不伤害其他人的基础之上，有利于目标的达成，就是好方法。</p>
<p><strong>4.只有由感官经验塑造出来的世界，没有绝对的真实世界</strong>
你永远不可能看完世界上所有的角落，了解每个人遇到的每件事，过程中也会缺失很多信息。就算是进入了大脑的信息，也会被你的信念系统给重新编码，被赋予新的意义。你遇到的所有事情，本身其实都是没有意义的，所有的意义都是我们根据自己的信念系统，人为给加上去的。</p>
<p><strong>5.沟通的意义在于对方的回应</strong>
在和对方沟通的时候，你不应该只关注自己说了什么，而是要关注对方听到了什么，理解的程度到哪里。对方的回应，才是你这次沟通的效果。</p>
<p><strong>6.重复旧的做法，只会得到旧的结果</strong>
你如果想要得到从未得到过的东西，就要去做从未做过的事情。</p>
<p><strong>7.凡事必有至少三个解决方法</strong>
当你感到无计可施的时候，只能说你已知的办法都行不通而已，并不能说问题无法解决。因此，你只要相信一定还有未知的、更好的方法存在，那么总有一天，问题会被你解决</p>
<p><strong>8.每一个人都选择给自己最佳利益的行为</strong>
每个人的行为背后，一定有他的正面动机。如果你了解和接受了他的正面动机，他就会觉得你
接受他这个人，你就更容易引导他做出有效的改善</p>
<p><strong>9.每个人都已经具备使自己成功快乐的资源</strong>
你的快乐取决于怎么看待眼前发生的事情，而不是眼前的这件事决定你快不快乐。你遇到的每一件事里，正面和负面的意义都是同时存在的，至于你想看到事物的哪一面，赋予它什么意义，由你自己决定。</p>
<p><strong>10.在任何一个系统里，最灵活的部分便是最能影响大局的部分</strong>
能有一个以上的选择，便是灵活;能容纳别人的不同意见，便是灵活;灵活并不代表放弃自己的立场，而是寻求双赢、多赢的可能性;灵活也代表你足够地自信，自信度越低，越容易在某个角落认死理，态度强硬;而强硬的态度会让周围的人感到紧张，灵活却能让人放松</p>
<p><strong>11.没有失败，只有反馈</strong>
失败只有在事情画上句号的时候才能使用，失败只是一种反馈信号，告诉我们之前的尝试没有用而已</p>
<p><strong>12.动机和情绪总不会错，只是行为没有效果而已</strong>
接受自己的动机和情绪，同时改变自己的行为方式</p>
</blockquote>
<p>短期方法则是在情绪来袭的时候使用的方法，主要有三步</p>
<p><strong>1.自觉</strong></p>
<p>察觉到自己出在情绪状态中，因为当你知道自己“正在生气”，你的怒火便会减少一大半，这部分笔者觉得就是书里上半部分说的元认知</p>
<p><strong>2.理解</strong></p>
<p>找到自己发火的动机，问一下自己这几个问题，“我为什么会发火?我的动机是什么?我想通过发火得到什么?有没有更好的方式来获得?”</p>
<p><strong>3.转化</strong></p>
<p>实际的处理，如找到情绪表达里的负面词语并试着转为正面词语；前面提到的
12
条信念有没有哪一条可以解释当下状况；是不是自身能力不足导致了这个问题，有没有谁能帮你解决这个问题</p>
<p>在这一章的小结里，作者写了如下的话，笔者也比较认可</p>
<blockquote>
<p>本章说的这些都是治本的方式，而<strong>治本的方式都有一个通病，就是耗时特别长。你不要期望读完本课就能马上不一样了，这是不可能的</strong>。</p>
<p>删除负面词语，替换信念系统，提高解决问题的能力，这每一项都需要你反复训练、长期坚持，才能逐渐收效。</p>
<p>有些人喜欢快，喜欢药到病除，喜欢掌握一套武功秘籍，然后马上小人物逆袭，而忘了真正重要的是强身健体和修炼内功。
正因为那么多人喜欢快，喜欢疲于解决表面问题，才给我们这些喜欢慢，喜欢解决根本问题的人以机会。坚持练习，持续打磨，日拱一卒，做时间的朋友，期待一年后一个不一样的自己!</p>
</blockquote>
<h3 id="知识的获取与应用">知识的获取与应用</h3>
<p>这部分主要介绍了该控制什么信息进入大脑的信息，以及如何对进入大脑后的信息进行分类和整理</p>
<h4 id="三个过滤器">三个过滤器</h4>
<p>过滤器是什么？其实就是要对输入大脑的东西有所警觉，而不是来者不拒，因为请神容易送神难，进入大脑的信息，是极难被清理干净的，特别是那些含有说服技巧、有煽动性的话语，会长期霸占你的大脑，影响你的思维方式，而你可能还不自知......</p>
<p>书里提供了 3
个过滤器：<strong>区分信息与知识、区分经验与规律和区分优质与劣质</strong></p>
<p><strong>1.区分信息与知识</strong></p>
<p>对于信息与知识，书里给的定义如下</p>
<blockquote>
<p>信息: 一切听到的、看到的、闻到的、感觉到的都可以称之为信息;
如马路上的大妈骂街、电视里的新闻联播、抖音上的美女热舞、微信里的表情斗图</p>
<p>知识:
那些被验证过的、正确的，被人们相信的<strong>概念、规律、方法论</strong>。如“复利”“元认知”“注意力”这些本书上篇所讲的内容就是概念;规律是事物背后的运行法则，比如用户需求不变，产品的供应量降低，价格就会升高，这就是规律;而方法论，就是我们俗称的“套路”，是一套被验证过的，解决某一特定问题最有效率的执行流程。</p>
</blockquote>
<p>书里的观点是：信息有真假，有时效;而知识有积累,有迭代。你<strong>要学习的是知识，而不是信息</strong>。</p>
<p>虽然这部分强调的是改学习什么内容，同时书里为了强调不被无用信息干扰，在上面阐述信息是给的例子基本都是负面的，但笔者认为在生活中一些有用的信息是必不可少的，尤其是在做决策的时候，比如说择业、成家等。</p>
<p><strong>2.区分经验与规律</strong></p>
<p>一些成功人士的分享，往往会说他们如何通过艰难困苦最后创业成功的，这是经验；中间可能存在幸存者偏差，存在当时的环境红利，同样的事情重复做一遍，哪怕是他自己也不一定能再次成功。因此，我们<strong>要学习的是规律，而不是经验</strong>。</p>
<p>而规律简单来说就是<strong>能够导致重复成功的因果关系</strong>，具体的方法是归纳与推演，从成功经验中推导出原因，而且只有在多次的推演下这个因果关系成立才是规律。</p>
<p><strong>3.区分优质与劣质</strong></p>
<p>海量书籍、互联网资讯容易带来信息过载，让人无所适从，不知道从哪里学起，或者说分不清哪些该学，哪些不该学</p>
<p>书里将这个原因归结为<strong>个人知道得太少了</strong>,就是个人的知识量还不足以拥有分辨内容优劣的能力，而如果要做到这一点关键是“见真识假”，即好的看多了，自然就能分辨什么是差的了。书里给出了如下两个例子：</p>
<p>（1）如果你想学习某个领域里的内容，那就先去找这个领域里最出名的经典书去阅读，可以从各类图书的畅销榜里去挑选，也可以看看业内牛人们的推荐，这样找到的书你会发现来来回回说的就是那几本，这些就是好书。</p>
<p>（2）如果你是刚刚进入一个新的领域，建议先从经典入门级的书开始读，这有助于你快速掌握这个领域内的基础概念，基础概念的夯实对后期的学习帮助巨大。</p>
<h4 id="放入知识">放入知识</h4>
<p>在过滤器辨别了哪些知识值得学习后，下一步就要把知识放入大脑了，书里在这里给出了四个步骤(这里在第
2、3 点上笔者的理解跟原书不太一样，所以这里按照笔者的理解来写)</p>
<p><strong>1.给大脑外接一个硬盘</strong></p>
<p>就是借助一些工具来记录这些知识，如各种云笔记软件；对于笔者，这个 blog
的内容也是一个外接的硬盘</p>
<p><strong>2.把知识分类归档</strong></p>
<p>就是设置一个分类体系，将凌乱的知识分门别类，比如笔者会对每篇文章打上标签；</p>
<p>分类的体系怎么建立？书里给出 2 中方法(书里将这部分放在了第 3
点即结构化的部分，但是笔者觉得放在这里更合适)</p>
<ol type="1">
<li>MECE 法则: 就是遵循“不遗漏，不重复”的原则建立分类体系，详细可参考<a
href="https://zhuanlan.zhihu.com/p/144052435">这篇文章</a></li>
<li>站在巨人的肩膀上：有些领域知识的结构化已经非常成熟了，你可以直接拿来使用</li>
</ol>
<p><strong>3.把知识结构化</strong></p>
<p>当某一个类别超过20篇知识点文章，你就可以试着把它们“结构化”；这样知识就成了一个体系，比如笔者前不久写的
<a
href="https://wulc.me/2021/05/05/An%20Overview%20Of%20Ad%20System/">An
Overview Of An Ad System</a>,
里面就是笔者看过或写过的与“计算广告”这一类别相关的内容的一个结构化的过程</p>
<p><strong>4.建立知识之间的链接</strong></p>
<p>这里想表达的观点是：每一次新知识的加入，都需要与原有知识做一次链接，也可以认为是重做步骤
3；而大多数人的情况是收藏后就不再看了；</p>
<p>这个过程也可以想象成你当前了解的知识点组成了一张
DAG(有向无环图)，当有新知识到来时，应该把这个点拼到哪里？</p>
<h4 id="应用知识">应用知识</h4>
<p>学习知识不是目的，解决问题才是；<strong>学习知识只是为了能更高效地解决问题</strong></p>
<p>书里认为应用知识去高效解决问题的关键点在于<strong>提高思考质量</strong>；因为“知识”并不能直接解决问题的，而是提高了你解决这个问题的“思考质量”，因此这部分的重点是如何提升思考质量</p>
<p>思考的过程可以总结为2
步：<strong>链接背景知识、梳理背景知识</strong></p>
<p>1.链接背景知识</p>
<p>即在自己的知识库中搜索相关的背景知识，可以是概念、方法论或者别人的经验，或者是自己所见所闻的信息，也可以是其他行业的知识......</p>
<p>当你掌握的背景知识越多，可用于思考的要素就越多，最终给出的方案也会越全面。当别人还在理解问题的时候，你可能已经链接到一个方法论，并开始侃侃而谈了</p>
<p>2.梳理背景知识</p>
<p>背景知识可能会很零碎，你需要结合问题，把它们重新排列组合一下，梳理成一条完整的信息，形成最终的结论。这个过程包括筛选、整理、重组、缩放等</p>
<p>针对上面这两点，书里给出的提升思考质量的方法论有如下 4 点</p>
<p><strong>1.增加背景知识量</strong></p>
<p>思考问题中的大部分时间其实是在回忆；如果你掌握的背景知识量太少，你的思考就会比较片面，以偏概全;
或者所有问题，都链接到一个方法论，比如用供需理论解释一切，这就像拿着一把锤子，眼里都是钉子..</p>
<p><strong>2.提高链接强度</strong></p>
<p>链接强度指的是熟悉程度，那如何提高与背景知识的链接强度，这部分跟上面放入知识中的链接内容有点相似，书里给了如下
2 步</p>
<ol type="1">
<li>建立初次链接</li>
</ol>
<blockquote>
<p>学习的过程是链接，而不是记忆;
每次学习了一个新概念、新方法，并不是把它背出来，或者
存入收藏夹，而是让它<strong>和你的旧知识发生链接</strong>，用旧的知识来理解这个新概念，让这个新概念从你的原有知识里“长”出来。</p>
<p>不要死记硬背定义，那样很快就会忘记，因为没有发生链接。你可以用其他熟悉的知识来理解它，比如电脑里的硬盘和内存:“背景知识”就相当于“硬盘”里储存的信息，平时一般不用，等有个程序需要用
到这个信息的时候，这个信息就会从“硬盘”进到“内存”里进行工作，这个内存就是“思考区域”</p>
</blockquote>
<ol start="2" type="1">
<li>重复再重复，形成条件反射级的链接</li>
</ol>
<p>其实就是要不断应用这些知识，只有当强度到达一定程度后，才会呈现出条件反射级的链接。</p>
<p><strong>3.增强知识的结构性</strong></p>
<p>增加知识的结构性的好处是当你联想到某个背景知识的时候，不是一个个想到的，而是一整片一整片的，甚至是一整套完整的方案；书里给了如下例子</p>
<blockquote>
<p>产品卖不出去怎么办?</p>
<p>别人能链接到的背景知识是:激励销售员，降价促销，增加广告投放渠道这些零碎的点;而你就可以直接链接到“企业能量模型”这个结构化的知识，然后分别从“产品、营销、渠道”这三个方向，九个常用解决方案里挑选几个适合的，几乎在瞬间给出一套完整的优化方案......</p>
</blockquote>
<p><strong>4.提高对背景知识的梳理能力</strong></p>
<p>这部分要解决的是从大脑搜索出了背景知识后，该如何做筛选、整理、重组、缩放等操作，梳理给了
2 个方法</p>
<p>(1)随意搭配: 没有什么规则，根据自己的喜好来搭配 (2)按套路搭配:
就是一些公开的套路,如整理背景知识的使用MECE法则;提升沟通效果的使用SCQA结构化表达;
策略选择使用SWOT分析; 正向演绎推理的使用三段论....</p>
<h3 id="提高效率">提高效率</h3>
<p>专注才能提高效率，因为在一段时间内，输入同类信息,
就可以同一套背景知识去理解，不需要来回切换，即思考就省去了不断寻找背景知识的过程，只剩下梳理了，思考的效率自然会提高不少；不知不觉便会进入所谓的“心流”状态</p>
<p>无法专注的原因，主要可分为 2 个：外在的和内在的</p>
<p>1.外在原因：总结为“他人需要你、他事勾引你”，即不断有人来找你，各类app
不断吸引你的注意力</p>
<p>2.内在原因：人类天生容易分心，从进化论的角度来解释就是：时刻关注身边所有的信息是刻在我们基因里的习惯</p>
<p>获得专注的具体方法，书里列了三点</p>
<p><strong>1.破除内部干扰:选择能专注的事情</strong></p>
<p>如果说天生爱分心、爱主动去捕获各类信息，同时
内心又如万马奔腾是我们的天性使然，我们无法改变的，那么要解决天性的问题，我们只能用另一种天性去对抗</p>
<p>而有两类事情，当它们出现时，我们的天性就会自然切换到专注的状态</p>
<p>(1)对恐惧的逃避：即时间紧迫，不得不做 (2)对愉悦的追求:
即做能让自己感到愉悦的事情</p>
<p>第二点告诉我们我们要找到我们自己的天赋，自己感兴趣，能给自己带来成就感和满足感的事情，并将这些事情作为自己的事业</p>
<p>第一点则是应用在哪些重要但你不感兴趣的事情上，就是要给事情一个威胁对象和时间期限；这其实也是笔者比较有感触的一点：<a
href="https://www.xinli001.com/info/100012010">恐惧让人成长</a>，但在《得意忘形》第
10 期 <a
href="https://www.ximalaya.com/yule/6688726/33817975">「快乐」到底是个什么东西？</a>中，提到了人的三种驱动模式：欲望驱动、恐惧驱动与创造驱动，而恐惧驱动具备一定的缺陷，可以去听一下。</p>
<p><strong>2.阻断外部干扰:创造纯净的环境</strong></p>
<p>这部分应该绝大多数人都懂，就是要营造一个有利于让自己进入专注状态的整体环境，具体是如下
3 点：<strong>隔离噪声、调控信道、摒除杂念</strong></p>
<p>(1)隔离噪声</p>
<p>当你需要专注工作的时候，找一个相对独立或者周围都是陌生人的环境，然后关闭各种App的提醒功能，最后，如果环境声音对你有影响，带上降噪耳机</p>
<p>(2)调控信道</p>
<p>为什么你在电影院能非常专心地看完一部电影?因为电影霸占了你两个“信道”:视觉信道和听觉信道</p>
<p>为什么电子游戏比电影更容易让人专注?因为它霸占了你三个“信道”:视觉、听觉还有触觉。</p>
<p>那当你想要<strong>专注一件事情的时候，能否调用多个信道来一起完成它</strong>?
比如说晨读，其实就是听觉、视觉、触觉都围绕一件事情展开，理解和记忆的效果就会明显提升</p>
<p>那假如某些工作用不到所有的信道?剩余没用到的信道最好用一些信息量小的内容填充，如写作的时候，一般只用到视觉和触觉，听觉是用不到的，这个时候可以用白噪声去填充；但笔者觉得这条成立的前提是这些没用到的信道受到了干扰，否则在一个安静的环境没必要这么做</p>
<p>(3)摒除杂念</p>
<p>针对摒除杂念给了三点建议:
主动进入受拘束的环境、少看不相关的内容、不轻易中断思维</p>
<p><strong>a.主动进入受拘束的环境</strong></p>
<p>在家很容易分心，因为在家我们可以想干嘛就干嘛，这是一个极度自由的环境。而<strong>太自由的环境，会让想法和行动离得太近，你可以任性而为</strong>，这不利于专心，你需要主动进入办公室、咖啡厅等公共场合，从一定程度上限制自己的自由。（笔者对这一点深有体会，所以周末如果需要学习写文章之类的，都会回公司）</p>
<p><strong>b.少看不相关的内容</strong></p>
<p>任何信息进入你的大脑，都会留下记忆的灰烬。看到的内容，都会留存在大脑中，时不时地冒出来，叨扰你一下。因此最好的方法就是不看;
和自我成长没有关系的内容，对知识增长没有帮助的信息，尽量远离</p>
<p><strong>c.不轻易中断思维</strong></p>
<p>在做事情的时候，大脑很容易会冒出一个不相关的想法，如果是无益的想法可以直接摈弃，而好的想法可以先临时记录一下，然后回过头再来思考，就是不要轻易中断自己当前的思维，可以利用番茄工作法帮助自己达到这一目标</p>
<p><strong>3.注意休息</strong></p>
<p>专注需要生理上的良好状态，所以要休息好，书里给出三类的休息和一些参考方法如下</p>
<blockquote>
<p>(1)短休息
专注了一段时间后，我们需要让大脑进行一次短暂的放松，休息5~10分钟，可以<strong>闭目养神，或者站起来随意走动一下</strong></p>
<p>(2)中度休息
每天午饭后半小时，人会感觉昏昏欲睡，如果你强行工作，效率就会很低。你可以在这个时候进行一次<strong>20分钟左右的冥想</strong>，既能达到休息的目的，又能锻炼元认知
开始之前，你可以先喝一杯咖啡，15~20分钟的时间正好可以让咖啡因进入血液，等睁开双眼的时候，你就会感到精神饱满，思维清晰，充满活力，比脉动还管用。</p>
<p>(3)夜晚睡眠质量的保证
每天至少需要7小时的充足睡眠时间，晚上尽量不要超过12点入睡，同时给自己配个好枕头、好床垫，投资自己的睡眠质量</p>
</blockquote>
<p>关于最后的睡眠，《<a
href="https://book.douban.com/subject/27023900/">睡眠革命</a>》里提出的
R90 睡眠法值得去实践一下，大致的意思就是每个睡眠周期是 1.5h, 每晚需要睡
4-5 个完整周期</p>
<h2 id="思维力的提升">思维力的提升</h2>
<h3 id="找到本质问题">找到本质问题</h3>
<h4 id="描述问题">描述问题</h4>
<p>“问题”是什么?
书里给出的定义是<strong>期望与现状的落差部分</strong></p>
<p>为什么常说“没有问题，就是最大的问题”?
因为没有问题，就意味着你<strong>不知道目标在哪里，也不知道现状是什么，自然就不知道有什么问题</strong>，只是当一天和尚撞一天钟，随波逐流，一脸迷茫，书里举了如下例子</p>
<blockquote>
<p>比如你刚对一群人讲完一大段话，然后问:“大家还有没有问题?”
大家回答你:“没有问题......”
你千万别天真地以为大家都听懂了，更大的可能是:他不知道什么算真正听懂了，以及为什么要听你说这一大段，他没有一个期望值;也不知道自己听懂了什么，没听懂什么，处在游离状态，找不到自己的现状
因此，不是他完全听懂了，没有问题，而是他不知道自己有没有听懂，不知道什么算完全听懂，因而找不到这个“落差”在哪里，没有发现落差也就没有发现问题，所以只能回答:“没有问题......”</p>
</blockquote>
<p>将期望记为 B, 现状记为 B', 则解决问题的办法都应该围绕 B'→B
来展开思考的, 但大部分人的的做法是是还没有理清 B 和 B'
的实际情况，就急于给出自己的建议，那该如何描述一个问题，书里给出了如下三步法</p>
<p><strong>1.明确期望值(B)</strong></p>
<ul>
<li>你的目标是什么?</li>
<li>目标是否现实，或者说正常的情况应该是怎样的?</li>
<li>这个目标可衡量吗?</li>
</ul>
<p><strong>2.精准定位现状(B')</strong></p>
<p>清晰地描述目前所处的位置，并不是一件容易的事。因为现状往往不是单一维度的，需要牵涉到许多方面，在这个过程中需要注意的一点是要区分事实与观点,其实就是要给出量化的指标，用数据说话</p>
<p><strong>3.用B'→B这个落差，精准描述问题</strong></p>
<p>不要问模糊的问题，而是要用数字描述问题，书里举了如下的例子</p>
<blockquote>
<p>下一次，请记得不要再问出类似于“你的业绩那么差，打算怎么办”这样模糊的问题，因为你认为的差，和他认为的差，也许并不一样。在他眼里20%的下跌，也许算正常波动，而你却已忧心忡忡。所以，你想让他给出方案，而听到的却感觉他在不断寻找借口......
你们在讨论的，其实并不是该如何提升业绩的方法，而是到底什么
才算“差”...... 那应该怎么问?
你应该问:“你之前三个月的业绩分别是100万元、110万元、105万元，而这个月变成了80万元,我们来讨论一下，下个月如何能做到120万元?”</p>
</blockquote>
<h4 id="解决问题">解决问题</h4>
<p>怎么找到本质问题，而不是头痛医头、脚痛医脚？书里针对这部分，给出了一个叫“<strong>透析三棱镜</strong>”的方法，这个方法认为问题并不会平白无故地出现，它是由“目标、方法、变量”这三个因素共同影响产生的，而所谓的三棱镜也对应着这三个要素。书里举了如下例子</p>
<blockquote>
<p>比如我们设定，公司本月业绩的期望值B=100万元。</p>
<p>然后怎么办?每月的业绩又不会自己完成。所以，我们要同时制定一个实现它的方法，我们假定这个方法是(A)。那么，理想的状态应该是:做了A就能完成B(见图17-5)。
可现在做了A之后，并没有达到预期结果B，而是达到了B′，这就产生了B′→B的这个落差。也就是我们看到的表面问题，或者称之为症状(见图17-6)。</p>
<p>然后我们就开始分析，B′为什么会产生?
结果发现有一家讨厌的竞争对手降价了!
这个因素，在我们当时制定A的时候，没有考虑进去，是一个在过程中突发的变量，我们称之为C。现状B′的出现，它脱不了干系(见图
17-7) 总体如下图所示
<img src="https://wulc.me/imgs/real_problem.jpg" height="35%" width="35%"></p>
</blockquote>
<p>因此，现状B′并不是凭空出现的，而是在三个因素的共同影响下导致的</p>
<ul>
<li>A:
为了实现B的结果所使用的方法。如果方法是错误的，目标自然无法达到</li>
<li>B:
期望值。目标设置不当，或者目标设定过高，那么即便完美做到了A，这个目标也是无法达成的</li>
<li>C:
过程中出现的变量。方法和目标都没有问题，可是出现了意料之外的事，也有可能导致目标无法达成</li>
</ul>
<p>因此，<strong>要解决问题，不能盯着B'→B看，而是要透过B'去看ABC，即透析三棱镜</strong>,
具体就是如下的三步：<strong>校准目标、重构方法、消除变量</strong></p>
<p><strong>(1) 校准目标 B</strong></p>
<p>目标要符合 SMART 原则，SMART 含义如下</p>
<ul>
<li>S: Specific，明确的，具体的</li>
<li>M: Measurable，可衡量的</li>
<li>A: Achievable，可独力完成的</li>
<li>R: Rewarding，完成后有满足感的</li>
<li>T: Time-bou，有时间限制的</li>
</ul>
<p>Specific
指的是目标要明确，不能太过虚无，如“幸福”这个目标定义就不明确，需要把这个<strong>目标用清晰明确的行动指引来替代</strong>，如““我的目标是有一份稳定的工作，有一个爱自己的老公，每周能一起去看次电影，每年去旅行一次”</p>
<p>Measurable
指的是目标是否达成，需要可衡量的标准，比如“我们的目标就是让客户满意”就没有可衡量的标准，而是要改成说“用户好评分，在9.5分以上”</p>
<p>Achievable
指的是可独力完成的，即<strong>目标的达成，一定是自己的力量可以控制的过程，而不能把目标达成与否寄托在他人或者你不可控的事情上</strong>。比如，目标定为“下半年能够升职”，或者是“他能更喜欢我”，这些你不能控制，因为决定权在对方，你可以改成“连续三个月业绩达到100万元”、“提升自己知识量和气质，增加自己的魅力”等</p>
<p>Rewarding
指的是完成后有满足感的，即当你完成这个目标的时候，是否能满足你的存在感知层?<strong>太近、太容易的目标，即便完成，你也不会有愉悦感和满足感</strong></p>
<p>Time-bound 指的是有时间限制即 deadline，否则任何目标都没有意义</p>
<p>制定目标除了要遵循“SMART原则”外，还得注意<strong>区分目标和手段</strong>，即在使用方法A来达成目标B时，不要把
A 本身当成了目标，书里给了如下例子</p>
<blockquote>
<p>就比如读书这件事，你定了一个目标:一年要读50本书
然后呢，具体要看什么书?历史、商业还是文学?找不到方向......
年中的时候，发现才读了10本书，下半年就开始奋起直追
到了年底，终于读完了50本书了，然后呢?
好像也没学到什么，读完这50本书能干嘛呢? 还是一脸迷茫...... 为什么会这样?
那是因为，读书是手段，并不是目的。
你不应该问:“读书是为了什么?”而是要问:“为了什么，我需要读书?”
<strong>读书是让你达成某个目标的手段，但我们却常常把它当成了目标本身</strong></p>
</blockquote>
<p><strong>(2) 重构方法 A</strong></p>
<p>A 是你为了实现 B 所用的方法,
当出现了现状B'时，我们会习惯性地再找一条从 B' 到 B
的途径，但这其实是治标不治本的方法，结果常常让同样的问题重复出现，书里举了如下例子</p>
<blockquote>
<p>王小锤的团队离开了两名重要伙伴，不应该马上给出解决方案:再补两名销售，而是要回过头，去看看王小锤平时是用什么方式经营团队的，也就是原来的A是怎么样的。
管理方法是什么?责权利有没有对等?是否应用了情境管理?
团队结构是怎么样的?合适的人有没有放到合适的位置?
激励机制能否激励到所有人?是资源分配不公平，还是保健因素没给到? ......
是其中的哪个原因导致了员工的离开?
如果这些“导致员工离开的原有系统”不改变，只是单纯地再补两个新人，那么依然还会有新的员工继续离职。</p>
</blockquote>
<p>调整A需要大量的背景知识和正确的思维方式，才能找到适合的解决办法。每个问题都有其独特性和不同的时空背景，需要具体问题具体分析。这一部分书里也没给出相应的方法论，你平时看的大量方法论书籍都是在讲各种A，这些就像是不同的药丸，当你能够快速抓住问题本质，就能在这些药丸中找到适合的来对症下药了</p>
<p>所以这部分主要是强调了这点:
<strong>现状是由原来的方法导致的，因此想要改变现状，不是从现状出发，添加一个新的解决方案，而是要回过头，重构原来的方法系统</strong>。</p>
<p><strong>(3) 消除变量C</strong></p>
<p>如果 A 和 B 都没有问题，问题依然存在，那一定存在着变量
C，书里给出了“象、数、理”这个框架来寻找 C，意思是:
<strong>任何一个“现象”背后一定有“数据”，任何“数据”的变动，背后一定有“道理”</strong></p>
<p>面对一个客观问题，要避免使用“我感觉......”这样的表述方式，这样的反馈没有任何意义，因为这只是你的“观点”，不是“事实”，你要用“数据”来说明，数据就是事实。书里举了如下例子</p>
<blockquote>
<p>比如，上个月我们的销量是1000单，共接到2个投诉电话，投诉率为2%;这个月我们卖了3000单，却接到了20次投诉电话，投诉率为6.7‰，比上个月足足提高了3倍多，这个问题需要引起我们的重视!
但有了这个数据够不够，你要继续挖掘更细的数据，比如这20个投诉电话，分别投
诉了哪些内容。然后你发现，其中有19个投诉了产品质量问题，有1个投诉了物流问题。
当然，你还可以继续追问下去，比如具体是哪些部位的质量问题，占比各是多少?这些产品分别是什么时间生产的?等等。
有了数据后，通过不断问“为什么”来找到问题的根源</p>
</blockquote>
<h3 id="线性思维">线性思维</h3>
<p>在讲线性思维前，书里介绍了一个概念：点状思维，就是知识点并没有发生“链接”，而是像一个一个孤岛一样，单独地存在大脑之中；反之，线性思维就是将两件事、两个概念建立链接，像一条线一样串联起成，由A推导出B，由B联想到C；</p>
<p>关于建立链接书里给了三种方法：演绎法、归纳法、类比法</p>
<h4 id="演绎法">演绎法</h4>
<p>演绎法，就是由“因”推导出“果”，由一般推导出特殊的思维方式，其核心是<strong>三段论</strong>，一种“<strong>大前提→小前提→结论</strong>”式的推理过程，如著名的“苏格拉底三段论”:</p>
<p>大前提: 所有的人都是要死的 小前提: 苏格拉底是人 结论:
所以苏格拉底是要死的</p>
<p>演绎法在生活中能被应用到逻辑推理、逻辑验证中，比如说要<strong>验证自己/他人的结论的合理性</strong>，
这里需要注意的是：在实际应用中，演绎法并不是那样标准的三段形态，或者是隐去了大前提，或者是隐去了小前提，或者是隐去了结论，需要显式地用三段论分析才行，如下是书里的一个例子</p>
<blockquote>
<p>我们再来看另外一句:“她穿得那么暴露，活该被色狼盯上......”
这句话可能隐藏了什么大前提?
我猜，他脑海中的大前提可能是:“受害者必有罪过。” (大前提)受害者必有罪过。
(小前提)她是受害者(被色狼盯上)。 (结论)她一定有罪过(穿着暴露)。
所以，他得出了这样的结论:“她穿得那么暴露，活该被色狼盯上......”</p>
</blockquote>
<h4 id="归纳法">归纳法</h4>
<p>归纳法，就是由“结果”出发，寻找“原因”;
这个方法非常常见，上一节讲的“象、数、理”的分析方法其实就是归纳法</p>
<p>从“结果找原因”这句话过于笼统，实际操作中归纳法有 5 个具体的方法, 即<a
href="https://wiki.mbalib.com/wiki/%E7%A9%86%E5%8B%92%E4%BA%94%E6%B3%95">穆勒五法</a>，这里的方法其实在现实中大多数人都会用到，只是不知道这些方法的具体名字而已</p>
<p><strong>1.求同法</strong></p>
<p>通俗来说就是让相同的对象同时出现在不同场合下，然后研究这个对象是否是造成不同场合下相同结果的原因，求同法的一般模式如下所示</p>
<p><img src="https://wulc.me/imgs/MillMethods1.jpg" height="50%" width="50%"></p>
<p><strong>2.求异法</strong>:</p>
<p>通俗来说就是让两个场合下只有一个变量,
研究这个变量里的对象是否是造成不同结果的原因,常见的 AB
实验就是这种模式； 求异法的一般模式如下所示</p>
<p><img src="https://wulc.me/imgs/MillMethods2.jpg" height="50%" width="50%"></p>
<p><strong>3.并用法</strong>:</p>
<p>就是同时利用求同法和求异法，更加明确地确定某个研究对象是导致结果的原因，并用法的一般模式如下</p>
<p><img src="https://wulc.me/imgs/MillMethods3.jpg" height="50%" width="50%"></p>
<p><strong>4.共变法</strong>:</p>
<p>通俗来说就是研究 2 个因素是否的相关性,
通过改变其中的一个因素的特性(比如说浓度，强度等不改变本质的特性)，研究结果是否会有相同的变化趋势，比如说冰箱温度和食物存储时长的关系，如下是共变法的一些模式</p>
<p><img src="https://wulc.me/imgs/MillMethods4.jpg" height="50%" width="50%"></p>
<p><strong>5.剩余法</strong>:</p>
<p>通俗来说就是结果里的部分现象可由已知的原因解释，那剩下的还不可被解释的现象理论上也是由类似的原因造成的。书里举了如下例子</p>
<blockquote>
<p>1846年，天文学家在观测天王星的时候，发现它有四次偏离了预定轨道。经过分析，发现其中有三次偏移是因为分别受到了已知行星的引力影响，还有一次原因不明。
于是，科学家就推测，一定存在着另外一颗还没有被我们发现的行星，导致了这次天王星的偏离。
根据这一猜想，天文学家们运用天体力学的理论，计算出了这颗未知行星的轨道，并且最终在1846年9月18日，用望远镜在与计算相差不到1度的地方，发现了这颗神秘的行星:海王星。</p>
</blockquote>
<h4 id="类比法">类比法</h4>
<p>类比法比较好理解，就是拿一件事来理解另一件事，笔者觉得这个方法在跟沟通、演讲过程中非常有用，选择你的听众熟悉的事情来类比，往往会让你的观点更容易被人理解</p>
<p>书里举了小米的例子，素有“杂货铺”之称的小米为什么除了手机，连毛巾、牙刷的都要卖？</p>
<blockquote>
<p>小米科技的副总裁刘德说:“这类生意对小米来说，是‘烤红薯生意’”</p>
<p>“小米发展到今天，已经有3亿用户了，其中2.5亿是活跃用户。他们除了需要小米手机、充电宝、手环等科技产品，也需要毛巾、床垫等高品质的日用品。所以，与其让这些流量白白耗散掉，不如利用这些流量
来转化一些营业额。就像一个火热的炉子，它的热气散就散了，不如借助余热顺便来烤一些红薯，这就是‘烤红薯生意’”</p>
</blockquote>
<h4 id="知行合一">知行合一</h4>
<p>只知道这三种链接的方式是没有用的；因为不会有人来问你，什么叫归纳法，什么叫演绎法。那在生活中应该怎么应用这几种方法</p>
<p><strong>1.学习新知识后的链接练习</strong></p>
<p>比如：</p>
<ul>
<li>刚学到一个新规律，就可以试着找到一个现象，然后用“演绎法”做出一番预测</li>
<li>刚学到一个新概念，可以试着找到生活中的哪些现象，也能“归纳”出这个结论</li>
<li>刚学会的是一个比较复杂的理论，可以试着用类比法，寻找一个简单、形象的物体来给它做一次封装，让它变得更简单易懂</li>
<li>...</li>
</ul>
<p><strong>2.练习写作和演讲</strong></p>
<p>核心在于通过输出的手段，强迫着你把学习到的知识点建立起结构严密的逻辑链接</p>
<p>最后，虽然介绍了线性思维中的三种方法，但是线性思维的问题是会让你的思维变得单向而局限，会让你看不到事物之间更多方向、更复杂、更曲折的因果关系，有时候让你只关注到局部，而忽略整体。因此，书里在线性思维后又介绍了结构化思维和系统性思维</p>
<h3 id="结构化思维">结构化思维</h3>
<p>不少人可能会遇到这种情况：有人口若悬河地和你讲了半天，他说的每个字你都听得懂，然而组合在一起，你并不知道他想说什么，内容没有逻辑，语句没有重点</p>
<p>这是因为大脑处理信息有两个规律：1.太多的信息记不住
2.喜欢有规律的信息；而杂乱无章地表达自己的观点，哪怕自己很懂，其他人也会云里雾里；而<strong>语言没有逻辑是因为思维没有结构</strong>，书里举了如下例子</p>
<blockquote>
<p>当有人问你，你能说说你有哪些衣服吗?
“嗯......我有很多衣服(想法)......” 能说得详细点吗?
“我有一条蓝裤子，一条橘黄色裙子，一件白衬衫，还有件灰白条纹衬衫，一条牛仔裤，一条蓝色竖条纹的裤子，还有顶黑色的帽子，哦
对了，还有一条蓝色裤子(这个刚才好像说过了)......”</p>
</blockquote>
<p>而所谓结构化思维，就像是把衣橱里的这些衣服，分门别类地整理好，如下是书里给的例子</p>
<blockquote>
<p>比如按季节分类，按穿着场合分类，按服装风格分类，等等。
这时候，如果别人再问你:“你有些什么衣服呢?”
你可以这样回答:我一共有208件装备，分为: 夏季、春秋季、冬季三大类;
每个季节的衣服又分为工作装、休闲装、宴会装、运动装四大系列;
其中，休闲装里有田园、淑女、简约三种风格;
每种风格的衣服，拥有深色、浅色各3套搭配;
另外配了4双运动鞋、5双皮鞋、6双休闲鞋、7个包包、8顶帽子来应对不同需要......</p>
</blockquote>
<p>笔者觉得这部分其实跟前面“解开大脑封印”中说的增强知识的结构性很像，要解决的核心问题还是怎么分门别类，只是前面的是知识，这里则是更广义的东西，比如说问题拆解，演讲、会议、日常沟通中要输出的内容等。而且这部分也给了比较详细的方法论</p>
<h4 id="金字塔结构">金字塔结构</h4>
<p><strong>1.明确目的，找到分解角度</strong></p>
<p>将一个“整体”拆成一个个独立的“要素”，再将一个个要素组合成结构，其实可以有很多种组合方式。因此，<strong>结构化思维并不是简单地做个分类汇总，而是要思考，分解后以什么方式组合，要达成什么目的</strong>。因为同样的要素，组合成不同的结构，就能实现不同的功能和目的。书里举了如下例子</p>
<blockquote>
<p>我们得在问题分解之前，先弄清楚分解的目的是什么，然后根据目的进行拆解与结构化。比如说，对于一个项目:
如果目标是分析进度:那就按时间进度，过程阶段来分解;
如果目标是分析成本:那就按工作项来分解;
如果目标是分析客户:那就按性别、年龄、学历、职业、收入等 来分解。</p>
</blockquote>
<p><strong>2.按MECE原则，组成结构</strong></p>
<p>前面在讲知识结构话时，也讲了 MECE 原则，这是《<a
href="https://book.douban.com/subject/1020644/">金字塔原理</a>》里面一个核心概念，意思是：相互独立、完全穷尽</p>
<p>《金字塔原理》中提出了金字塔结构，其实就是思维导图，即从上而下逐层分解，形成金字塔结构，而相互独立、完全穷尽意味着<strong>金字塔的每一层，内容不能有重复的部分，也不能有遗漏的部分</strong>。以上面的衣服分类为例，如果把衣服分类为春秋季服饰和职业套装，那其实是有重复也有遗漏的；而分为春秋季服饰、夏季服饰和冬季服饰就符合
MECE 原则。</p>
<p>书里以三个月完成 100
万元的销售业绩作为问题，通过以下两种方式来构建金字塔结构</p>
<p><strong>(1)自上而下“使用演绎法”设计结构</strong></p>
<blockquote>
<p>要完成100万元的业绩，关键是客户，因此我们可以根据客户的类
别进行划分，对不同客户类别采取不同的营销策略来完成业绩。
根据MECE原则我们发现，客户无非来源于三类: 1.陌生的新客户;
2.正在跟进中的准客户; 3.已经购买过的老客户
因此，可以在金字塔的第一层，划分为新客户、跟进中客户、 老客户这三类
<img src="https://wulc.me/imgs/MECE1.jpg" height="50%" width="50%"></p>
<p>这样一划分，大致的思路就清楚了: 1.开拓更多获取新客户的渠道;
2.提高跟进中客户的付款率; 3.促进老客户的复购。
根据这个策略，我们再继续往每个子分类中添加要素
在这个过程中，<strong>第一层的分类最重要</strong>，它决定了你整个结构的整体功能</p>
</blockquote>
<p><strong>(2)自下而上“使用归纳法”提炼结构</strong></p>
<p>自上而下演绎法的好处是效率高，可以很快速地就把问题结构化。可是，这种方式有个前提，就是你得对问题的解决方法有深刻的理解，能够快速找到恰当的分解角度，或者大脑中已经有了现成的结构可以直接使用，比如:销售额=流量×转化率×客单价。</p>
<p>当没有现成的结构或找不到分解的角度时，可以尝试自下而上的归纳法，大致的步骤是：头脑风暴，枚举所有可能的想法-&gt;梳理形成结构化内容；书里还是以上面的问题为例描述了这种方法</p>
<blockquote>
<p>我们还是回到前面的问题:如何在未来三个月完成100万元销售业绩?
你需要开始头脑风暴，把能想到的所有相关信息都列出来，完全穷尽，也可以找来一些帮手，把大伙儿关在会议室里一起讨论，运用群体智慧，通过各种唇枪舌剑，各种奇思妙想，将想法、建议、点子铺满整个白板,
如下图所示
<img src="https://wulc.me/imgs/MECE2.jpg" height="50%" width="50%"></p>
<p>看着上面凌乱的信息很是让人头大，下一步需要<strong>用归纳法中的“求同、求异、剩余法”对内容进行分组</strong>,
同时需要对内容进行一些增减修补
经过一番调整，凌乱的内容很快被分成了五个大组:渠道、获客方法、产品活动、客户分类、沟通方式，这里的分组名称不要求太精确，
因为后期可能还需要调整; 如下图所示
<img src="https://wulc.me/imgs/MECE3.jpg" height="50%" width="50%"></p>
<p>到这里稍微清晰了一些，但是这五类之间的逻辑，看上去还是比较混乱，内容之间也不
MECE，而且也不是金字塔结构;
因此，你需要进一步梳理这五组的逻辑关系。我们发现“客户分类”这个组和其他几组明显不同，渠道、获客方式、沟通方式应该是根据不同的客户采取的不同的拉新、促销的手段
在调整的过程中，继续修改归类错误，结构不MECE的部分，比如:
“客户分类”中目前的内容是:新客户、准客户、老客户、机构客户。而机构客户和其他三类有重叠部分，不符合MECE原则，应剔除;
之前的类别命名不精确，其实应该分为“渠道、营销”这两部分，不同的用户对应不同的渠道，不同的渠道对应不同的营销方式;
头脑风暴时只考虑了新客户的渠道，没有考虑准客户和老客户的渠道，要补上，图下入所示
<img src="https://wulc.me/imgs/MECE4.jpg" height="50%" width="50%"></p>
<p>“产品活动”去哪了?不管是新客户、准客户还是老客户，我们采取的产品活动都是同一个，因此可以把产品活动放在它们的上方，作为金字塔的顶端，这也因此成了本次三个月业绩冲刺的核心活动,最终的金字塔结构如下所示
<img src="https://wulc.me/imgs/MECE5.jpg" height="50%" width="50%"></p>
</blockquote>
<h4 id="平面切割">平面切割</h4>
<p>平面切割就是在一张纸上通过线条切割出不同的部分，由于本来是一个整体，所以是无遗漏的;用线条把彼此分开，一定是相互独立不重叠的，即符合了
MECE
原则，比如说决定录用员工的标准，往往考核的是能力和态度，那么可以画出如下的平面切割图</p>
<p><img src="https://wulc.me/imgs/ability_attitude.jpg" height="50%" width="50%"></p>
<p>值得注意的是<strong>结构化思考是帮助我们分析问题的，至于分析完之后又应该如何给出更有效的解决方案，还得看你的背景知识量</strong>，上面这个案例省略了具体策略的制定过程</p>
<p>而遇到问题时，不用每次都自己去分析和切割，因为已经有了一些成熟的模式，如下是一些可参考的切割模型</p>
<p><img src="https://wulc.me/imgs/classical_model.jpg" height="50%" width="50%"></p>
<p>上面基本都是两分法，其前提是任何事物都是一对矛盾的统一体，彼此对立，加在一
起又是一个整体；而在二分法的中间添加一个“过渡”的状态，让分类变得更加细致，就是三分法；同时结合这两种画线技巧，可以设计出更复杂的结构模型（笔者觉得这些数字并不一定要是
2 或 3 这么死板，要根据实际情况来）</p>
<p>书里还是以未来三个月完成100万元销售业绩作为问题，阐述了平面切割这个方法的过程</p>
<blockquote>
<p>1.用两分法，找到第一条切割线 客户?产品?活动方案?营销?渠道?
好像这些都不太适合，要么范围太小，无法包含所有相关的信息;要么无法切分成一个对立统一的整体。那应该怎么切?
无论是从哪个角度思考，无非就分为公司的外部因素和公司的内部因素，这既包含了所有的相关要素，又对立统一。
因此，我们第一条线可以先把结构分为“内部因素、外部因素”这两部分</p>
<p>2.第二条线怎么画
要完成100万元的销售，无非就两个环节:(1)把产品生产出来;(2)把产品卖掉。因此，第二条线可以是“生产与销售”这对矛盾统一体。
因此可画出如下的平面切割图
<img src="https://wulc.me/imgs/Cut1.jpg" height="50%" width="50%"></p>
<p>然后再看一下每个部分是否还可以继续切割，如
在“营销/渠道”这个分类中，不同的用户类别适用于不同的渠道和营销方式,可切成新客户、准客户、老客户三类
在“销售团队”这个分类中，使用X-Y结构，设置业绩目标，施加外部压力;设置业务奖励，提供内在激励
在“市场需求”这个分类中，用两分法切分为用户需求和市场热点,协助设计部门做出更受欢迎的产品或者活动
在“产品设计/供应”这个分类中，用两分法切分为产品设计和供应链管理，针对用户的需求和未来这三个月可能出现的销售高峰，调整产品设计，对供应链进行优化等
最终可画出如下切割图
<img src="https://wulc.me/imgs/Cut2.jpg" height="50%" width="50%"></p>
<p>当方案开始执行，根据实际的销售情况、市场反馈，视图中右下角的“用户需求”部分的信息就会被更新;这将进一步帮助你优化产品设计，提供更受市场欢迎的产品，优化供应链的管理，以满足市场的增长;紧接着，调整团队业绩目标，优化激励方案;然后，继续改善渠道的营销方式......整个方案动起来了
<img src="https://wulc.me/imgs/Cut3.jpg" height="50%" width="50%"></p>
</blockquote>
<h3 id="系统性思维">系统性思维</h3>
<p>上面讲平面切割的最后部分，提到整个方案的不同部分之间相互影响，其实这也是系统性思维的核心，就是要看到各个要素之间的关系</p>
<h4 id="定义">定义</h4>
<p>书里从如下 3 点阐述了系统性思维的特点</p>
<p>1.系统性思维是一种“基于要素之间关系”的思维方式
2.系统性思维是一项“看见整体”的修炼 3.系统性思维是一种“动态化”的视角</p>
<p><strong>1.系统性思维是一种“基于要素之间关系”的思维方式</strong></p>
<p>主要观点是：系统是由要素组成的，比要素更重要的是要素之间的关系，要学会看见要素之间的关系，而非盯着要素本身</p>
<p>书里以管理为例子</p>
<blockquote>
<p>一群聪明人，如果不经管理，就无法组合成一个目标一致、互相配合的系统，他们就会你争我夺，各怀鬼胎，谁都不服谁，各自打着小算盘，最后公司成为一盘散沙，什么事也推进不了。</p>
<p>管理的目的，就是把一群人组合成一个有效的系统，他们才能成为一支团队。看不见的关系，比看得见的要素要重要得多。<strong>系统性思维的第一步，就是要将你的视角从要素转移到关系</strong></p>
</blockquote>
<p><strong>2.系统性思维是一项“看见整体”的修炼</strong></p>
<p>主要观点是：需要关注系统结构、并以系统整体功能和系统目标为导向，来优化内部结构和要素，同时需要关注当前系统所在的大系统</p>
<p>怎么看到整体？书里列了三点</p>
<ol type="1">
<li>要看到系统的内部结构</li>
</ol>
<p>任何一个要素的变动，影响的不是一条直线上的因果关系，而是会牵一发而动全身，按了葫芦起了瓢。只有看清了所有的关系和结构，才能找出系统中的<strong>杠杆解</strong></p>
<ol start="2" type="1">
<li>要看到系统的整体特性</li>
</ol>
<p>在分析问题的时候，除了要看到整体之下的要素、关系、结构，还要看到整个系统涌现出的特性和功能，以<strong>整体功能和系统目标</strong>为导向，优化系统内部的结构和要素</p>
<ol start="3" type="1">
<li>要看到系统的外部结构</li>
</ol>
<p>一个系统，往往是一个更大的系统中的要素。因此不仅要考虑某个要素在系统内的互动关系，还要考虑系统作为一个要素，与外部系统之间的互动关系。</p>
<p><strong>3.系统性思维是一种“动态化”的视角</strong></p>
<p>这里可以通过“<a
href="https://zh.wikipedia.org/wiki/%E8%9D%B4%E8%9D%B6%E6%95%88%E5%BA%94">蝴蝶效应</a>”比较形象地解释，我们所处的是一个持续演化的混沌世界，现实的世界中往往没有绝对的因果关系，各个要素之间相互影响。</p>
<h4 id="反馈与回路">反馈与回路</h4>
<p>系统中最常见的两个概念是反馈与回路。</p>
<p>书里将反馈分为三种，其定义如下，比较好理解</p>
<ul>
<li>正反馈: 代表两个要素之间是正比例关系，A增强，B增强</li>
<li>负反馈: 代表两个要素之间是反比例关系，A增强，B减少</li>
<li>延迟反馈:
代表两个要素之间的互动关系不是即刻发生的，A发生，一段时间之后，B才会有反应</li>
</ul>
<p>通过反馈可以构成 2 种回路: 增强回路和调节回路</p>
<ul>
<li>增强回路: 可以简单理解为马太效应</li>
<li>调节回路: 由1个负反馈加上若干个正反馈所组成的环路</li>
</ul>
<p>增强回路比较好理解，关于调节回路，书里举了下面的例子</p>
<blockquote>
<p>再比如，为了保持公司持续拥有竞争力，你需要保证公司内部有一定的人员流失率。
比例太高，意味着招聘成本的增加以及业绩的损失;而太低意味着人员臃肿，考核过于宽松，你的团队会越来越没有战斗力。怎么办?
经过统计，10%的末尾淘汰率，是一个比较健康的流失率。因此，你需要设计一个调节回路，通过调节考核指标来控制人员流失比例</p>
</blockquote>
<h4 id="两种模型">两种模型</h4>
<p>如果把要素比作电子元器件，反馈方式比作电线，通过把电子元器件用电线一步步连接成一个系统的方式只适用于简单的系统，对于复杂的系统无能为力</p>
<p>实际上一些常见的系统结构，也能被封装成像主板、显卡那样的一个个模块，可以直接拿来使用，就可以大大提高构建一个系统的效率。书里在这部分介绍了两种最常见的基本结构，生活中很多复杂的系统都可以由它们通过简单的变形、拆分、组合而成</p>
<p><strong>结构一:增长上限</strong></p>
<p>增强回路可能不会永远增强下去，因为<strong>系统在增强的过程中，会产生一些抑制增强的副作用</strong>，
而副作用的不断累积，就会反过来制约增强回路，最终导致增强的停止，甚至会让它急转直下，即增长上限的结构模型，如下如所示（这个概念也叫做<a
href="https://wiki.mbalib.com/wiki/%E6%88%90%E9%95%BF%E4%B8%8A%E9%99%90%E6%A8%A1%E5%BC%8F">成长上限模式</a>）</p>
<p><img src="https://wulc.me/imgs/LimitsToGrowth.jpg" height="50%" width="50%"></p>
<p>书里以养鸡为例</p>
<blockquote>
<p>比如说鸡生蛋，蛋生鸡，看似很美好，但是随着鸡的数量不断增加，规模带来的养殖复杂度，也呈几何级上升，这就对你的管理能力提出了严峻的考验</p>
<p>瘟疫、污染、水电等等因素，会因为你的管理能力不足而频频发生，大量的鸡会因为种种意外、管理不当开始死亡，一场瘟疫、两小时的停电等突发事件就有可能让整个养鸡场毁于一旦。</p>
<p>而造成的影响，比如恶性瘟疫的发生，甚至会持续发酵，让你面临巨额的赔款，导致你倾家荡产
如下图所示
<img src="https://wulc.me/imgs/LimitsToGrowthExample1.jpg" height="50%" width="50%"></p>
</blockquote>
<p>那当发现自己进入了一个“增长上限”的系统结构，应该怎么办？大多数的人会选择继续上图左圈的循环，因为这个方法曾经有效，并带来过指数级的增长，如今停滞了，那么我就应该更加努力；但这是不对的，书里给了如下的例子</p>
<blockquote>
<p>你们公司推出了一款新的产品，通过投放大量的广告，让产品的销售量暴增。钱多了，于是你们开始投放更多的广告，产品越卖越多，销售额呈指数级增长，这是一个增强回路......
但是，产品卖得多了，产量就得跟着提升;产量提高了，你可能就得加人手，管理的复杂度就提升了;管理复杂度提升，就会带来次品率的上升，次品率会影响用户的口碑，用户的差评变多了,就会影响你产品的销量......
而这个时候，如果你选择继续走左侧，增加广告投放量，你就会发现，广告对产品的销量拉动开始变得乏力，甚至由于市面上你的负面信息过多，这个时候的广告反而会带来反效果，引起大量的嘲讽和退货，造成销量的快速下跌，变成了一个逆向的增强回路......
如下图所示
<img src="https://wulc.me/imgs/LimitsToGrowthExample2.jpg" height="50%" width="50%"></p>
</blockquote>
<p>实际上，发现自己身处一个“增长上限”的系统结构中，你应该<strong>找到右侧循环中的“限制因素”</strong>，比如养鸡场案例里的“管理能力”，新产品销售案例里的“品控能力”，它们才是<strong>杠杆解，用心解决限制因素就能打开上限，让左侧的增强回路继续良性运转</strong>。</p>
<p>当然，并不是所有的限制因素最终都会被消除，比如市场容量，它会让你的增长最终迎来极限。</p>
<p><strong>结构二:舍本逐末</strong></p>
<p>这个结构指的是只解决表面问题，没有找到本质问题去解决。也可参考<a
href="https://wiki.mbalib.com/wiki/%E8%88%8D%E6%9C%AC%E9%80%90%E6%9C%AB%E6%A8%A1%E5%BC%8F">舍本逐末模式</a>，其特点是</p>
<p>(1)由两个“调节回路”组成，两个回路都想解决问题，上面一个回路代表能够快速解决问题的“症状解”，但是效果只是暂时的;下面一个回路是能够从根本上解决问题的“根本解”，但是存在时间延迟、见效慢、成本高、难度大等问题，但可以持久有效
(2)使用症状解的过程中，还会产生<strong>副作用</strong>，并隐含了一个增强回路，让问题症状在未来变得更难解决</p>
<p>其结构如下图所示</p>
<p><img src="https://wulc.me/imgs/ShiftTheBurden.jpg" height="50%" width="50%"></p>
<p>书里还是以上面养鸡为例子</p>
<blockquote>
<p>回到养鸡场的案例，现在养殖复杂度变得越来越高，鸡群的风险变得越来越大，你应该怎么办?
增加人手?提高打扫卫生的频次?在饲料里添加抗生素?
这些行为，确实可以在短时间内快速解决出现的问题，却会在长期的过程中，产生新的更严重的问题(比如说长期食用抗生素，将带来的副作用是药物残留，产生抗药性，普通细菌会演化成超级病菌，这将进一步危害鸡群和人类的健康);或者这些问题会一再地出现，你需要不断地去解决，成为救火队员。
真正有效的解决办法，是引入一整套科学的现代养鸡体系，从硬件设施到软件管理，全部规范化、流程化......
听到这里，你可能已经头大了，这得花多少钱，花多少时间啊，我现在的这些设施怎么办?人员怎么办?再搬个场地?开玩笑......现在已经出现问题了，你告诉我怎么解决?
嗯，你说的没错，所以你只能是个救火队员......
比起救火，更重要的工作是防火。如果觉得防火的工作麻烦而不去做，你就只能天天去做救火的事情。</p>
</blockquote>
<p>舍本逐末的结构，在生活中非常常见，比如说</p>
<ul>
<li>生病是“症状”，去医院看病是“症状解”，去医院能很快地缓解病情，而“根本解”是健康饮食和锻炼身体，耗时长，见效慢</li>
<li>收入低是“症状”，下班后去做兼职是“症状解”，做兼职能够很快地增加收入，而“根本解”是提高自己的能力，耗时长，见效慢</li>
<li>...</li>
</ul>
<p>如何逃离舍本逐末的死循环？书里没有给出很详细的方法论，只提了“选择进入下面的回路，而避免走上面的回路了”；但笔者觉得这个现实指导意义有限，更合理做法是<strong>两个回路都要走，但逐步减弱上面的回路，增强下面的回路</strong>；</p>
<p>比如说上面的低收入的例子，对于一些人不做这些低收入的工作可能生活都成问题；再比如说一些互联网公司里的架构问题，在当前架构修修补补是“症状解”，但症状解都不做，可能公司就完了</p>
<p>这部分内容跟前面思维能力的提升中“找到本质问题”有相似之处，可以</p>
<h4 id="案例">案例</h4>
<p>书里还是以前面“如何在未来三个月完成100万元的销售业绩”为例，将系统性思维里面的概念和方法论串了起来。</p>
<p>这里值得注意的是，<strong>使用系统性思维并不是说就要抛弃结构化思维，结构化思维能够让我们把事情想得很完整，这是基础。而系统性思维则是在这个基础之上，帮助我们找到要素之间的关系，发现整个事件的内部结构，同时拉高视角让我们看到事情的全貌，建立起一个整体的概念；并加上动态的时间轴，让我们能看到事情未来的演化方向。</strong></p>
<p><img src="https://wulc.me/imgs/Cut2.jpg" height="50%" width="50%"></p>
<p><strong>第一步，从调节回路开始，描述系统</strong></p>
<p>从系统的角度来看，系统的目标应该<strong>拉长时间</strong>，比如三年要实现一个什么目标;
或者<strong>状态化</strong>，比如每天、每月要实现什么样的效果。</p>
<p>因此，我们可以把系统的目标调整为:每月销售额达到50万元，这就是一个状态化的目标</p>
<p>根据这个目标，可以画出调节回路中的“现状、目标差距”这两个要素(见图20-24)；那当今的销量是如何产生的?销量是经由你目前的“销售系统”产生的，销售系统的效率越高，当今的销量越高(见图20-25)</p>
<p>PS：下面图中笔者不太理解的是为什么目标对业绩差距有正反馈作用，因为这只是个目标而不是动作，难道是指目标订得越高，与当前的业绩差距就越大？</p>
<p><img src="https://wulc.me/imgs/SystemThoughExample1.jpg" height="50%" width="50%"></p>
<p>有了上面的拓扑图，下一个问题就是：业绩的差距如何能提高销售系统的效率？可以试着在业绩没达到之前，给团队设定KPI，用压力工具，推动销售系统的运转</p>
<p><img src="https://wulc.me/imgs/SystemThoughExample2.jpg" height="50%" width="50%"></p>
<p><strong>第二步，优化结构，完成系统图，找到杠杆解</strong></p>
<p>当前的系统结构中，只有当
团队业绩不达标的情况下，KPI才会发挥作用，用压力推动销售系统，而业绩一旦达标，团队就没有了继续销售的动力，甚至会把当月的业绩藏到下个月用，怎么办?</p>
<p>一个系统，增长的动力来自于“增强回路”，因此要想办法在系统中构建一个增强回路，让系统不断地增强。比如可以试着用新增业绩的一部分作为激励，推动销售系统的继续运转，形成增强回路</p>
<p><img src="https://wulc.me/imgs/SystemThoughExample3.jpg" height="50%" width="50%"></p>
<p><strong>增强回路出现后，我们就要马上想到，会不会存在“增长上限”的结构</strong>?也就是产品卖得越多，会不会产生其他的副作用?
这个当然会，产品卖得越多，产品供应端的压力肯定就增大，产品质量、服务品质可能都会因此下降，如下图所示，而应对方法就是上面提到的“保证左侧回路的正常运行,去除右侧回路的限制因素”</p>
<p><img src="https://wulc.me/imgs/SystemThoughExample4.jpg" height="50%" width="50%"></p>
<p><strong>第三步，抬头看天，放入大系统</strong></p>
<p>目前这个系统只是某一个业务层面的系统图，我们可以将这个系统放到整个公司的运营系统中:
用公司中能带来大量现金流的业务，来给案例中的业务提供弹药，给人、给钱、给资源，帮助该业务更快地成长为明星业务</p>
<p><img src="https://wulc.me/imgs/SystemThoughExample5.jpg" height="50%" width="50%"></p>
<p>同时可以将视角再往上拉一个维度；即把整个公司的业务，看作是一个要素，把它放在整个市场环境中去分析；这样就能从能从更宏观的层面，从上到下，系统性地逐层分析，找到更适合公司的发展策略、产品策略、营销策略</p>
<p><img src="https://wulc.me/imgs/SystemThoughExample6.jpg" height="50%" width="50%"></p>
<p>这里也要注意，在分析任何问题时，都需要把全世界的每个角落都看一遍才能做决定，把与问题相关性最大的系统结构拿来分析即可</p>
<h2 id="解决所有问题">解决所有问题</h2>
<h3 id="做选择">做选择</h3>
<p>如果说“选择&gt;努力”，那就应该在“选择”这件事情上花更多的精力</p>
<h4 id="克服非理性">克服非理性</h4>
<p>人是非理性的，比如<a
href="https://wiki.mbalib.com/wiki/%E5%8F%8D%E5%B0%84%E6%95%88%E5%BA%94">反射效应</a>、<a
href="https://wiki.mbalib.com/wiki/%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%95%88%E5%BA%94">确定效应</a>、<a
href="https://wiki.mbalib.com/wiki/%E9%94%9A%E5%AE%9A%E6%95%88%E5%BA%94">锚定效应</a>、<a
href="https://www.jianshu.com/p/57f3d4720099">迷恋小概率事件</a>等，</p>
<p>在《<a
href="https://book.douban.com/subject/10785583/">思考，快与慢</a>》这本书中，把人脑分成了2个思考模式来解释上面的非理性现象，分别是<strong>“系统1——快思考”和“系统2——慢思考”</strong>，其含义如下</p>
<p>系统1：就是我们日常说的直觉思考，凭感觉行事，甚至是一种本能反应
系统2：理性思考，是逻辑推理，是量化分析；把问题拆开了、揉碎了、铺在面前，按照一定的步骤，开始分析各种利弊、因果关系、逻辑推理</p>
<p>由于系统1是自动运行的，不需要调用大量的注意力，很节能。所以大脑本能的选择，都是凭感觉行事，速度很快但也很容易出错；看到这部分，笔者想起之前看到的一句话
<strong>“毁掉一个人最快的方式，就是让他忙到没时间成长”</strong>，本质上就是在让人一直通过系统
1 来思考和执行。</p>
<p>因此，做决策首先需要克服非理性，其实就是要启动系统
2，具体的方法是</p>
<p><strong>1.启动元认知，开启系统2</strong></p>
<p>即要意识到这是个重要的决策，需要做仔细的分析</p>
<p><strong>2.让思考离开大脑，强制限速</strong></p>
<p>即要借助外部的媒介来记录思考的结果:
比如拿出一张白纸，打开Excel表，或者使用Xmind等脑图软件，将自己思考分析的过程可视化，把自己变成第三人视角...</p>
<p>除了上面提到的技巧，笔者还有一个经验就是尽量在一个安静的环境下进行上面的操作，过于吵杂比较难让大脑进入系统2</p>
<p><strong>3.设置外部提醒</strong></p>
<p>即通过外部因素来避免上面 1、2
点没法很好被执行；比如遇到问题时多去问一下别人的意见，或者召开一次会议，让自己的想法接受别人的批评与挑战......通过这些外部的力量激活系统2</p>
<p><strong>4.识别认知偏误</strong></p>
<p>除了开头提到的几种非理性的效应，还有类似于损失规避、心理账户、禀赋效应、可得性偏差、比例偏见、结果偏见、鸡蛋理论等一系列人们非理性的行为特征，这些要去学习了解，以防踩坑；要认识到很多公司的营销策略，都在让用户的大脑只运行系统1，让他不断买买买...</p>
<p>启动系统 2
后，分析各个选项也有套路，总结来说就是<strong>列标准+量化选项</strong>，列出什么是自己关注的，<a
href="https://www.zhihu.com/question/55195858/answer/2113793467">什么是自己不能接受的</a>等等，然后基于这些标准给每个选项分配权重，打分，然后算出最后的分数</p>
<p>笔者觉得这个过程中的量化虽然往往不是那么准确（正是由于不确定性才会让人产生选择困难），但关键是在你量化的这个过程中，你能更清楚自己更想要什么，能够舍弃什么，这比起最终不准确的量化结果更为重要。当然，这个过程中也可以借鉴其他人的意见，但最清楚你的情况的还是你自己。</p>
<h4 id="第三选择">第三选择</h4>
<p><strong>面对选择题，首先不要只看选项本身，而是要还原目标</strong>:你要问自己，做这个题到底是为了什么?你最想要达到的结果是什么?</p>
<p>而一旦问题有了目标，选择题变成了简答题，也就不局限于已有的选择，而是有“第三选择”；有了这个思维习惯，当你再遇到“选A还是选B”这样纠结的情况，你首先应该问自己的是:“目标是什么?还有更好的选择吗?”
书里举了如下例子</p>
<blockquote>
<p>比如在谈判中，对方觉得你们的产品太贵了，希望可以降价。怎么办?
你不要在降不降价的问题上纠结，你应该说:“通过与贵公司的合作，增加彼此的整体利润是我们共同的目标。降价是可以的，不过这样会对我们的利润造成很大的影响，我们对贵公司的C业务也很感兴趣，是否可以在C业务上给我们一个位置更好的广告位作为交换?”
这就是跳出了原有的选择框架，找到了更好的第三选择，得到双赢的结果。</p>
</blockquote>
<h4 id="小事不纠结">小事不纠结</h4>
<p>上面提到了做选择需要准备的工作，既要慢思考避免认知偏误，又要量化分析做理性决策，还不能局限于现有的选项，要找到问题背后的目标，把它转化为简答题，再扩充选项，如果每一个选择都是这样，那会非常麻烦。</p>
<p>因此，我们不需要在所有事情上都这么做，而是要紧盯核心目标，过滤大多数问题，不在小事上纠缠；那什么是核心目标？就是书的前半部分说的精神层次、身份层次里的那些事;
就是5年、10年、30年之后，再回过头来看也依然觉得很重要，影响重大的那些事</p>
<h3 id="做计划">做计划</h3>
<p>计划=目标+实现路径，缺一不可；如果只有目标那只是愿望清单，而如果只有实现路径那是
TODO List</p>
<p>而对于不同难度的目标，做计划的方式也不同，书里把根据目标难度分为
Easy、Normal 和 Hard
三种模式，在不同模式下的具体策略也不同，如下图所示</p>
<p><img src="https://wulc.me/imgs/PlanClassification.jpg" height="50%" width="50%"></p>
<h4 id="easy-模式">Easy 模式</h4>
<p>这种任务有两个特点</p>
<p>1.任务可以独立完成，你无须其他人帮助;
2.你什么都不缺，就缺行动力和时间，只要你想，就能把它轻松完 成。</p>
<p>在这个场景下的任务虽然简单，但是多而杂乱，因此，你的应对策略，就是<strong>有效管理好这些待办任务，让它们变得有序且不遗漏，提高你的处理效率</strong>。</p>
<p>书里提到了一个叫 GTD(<a
href="https://en.wikipedia.org/wiki/Getting_Things_Done">Getting Things
Done</a>) 的方法，主要分为以下4 步</p>
<p><strong>1.收集</strong>：把任务从你的大脑中清空, 记录到各种清单软件上
<strong>2.整理</strong>：删除一时兴起记下的、委托可给他人的、剩下的移入建立好的任务分类里，比如工作、家庭、健康、
某某项目等 <strong>3.执行</strong>：保持专注，一次只做一件事
<strong>4.回顾</strong>：定期对所有任务进行一次回顾，看看收件箱里有没有未处理的任务</p>
<h4 id="normal-模式">Normal 模式</h4>
<p>Normal
难度级别下的任务，光有执行力和能力已经不够了，还得每一步都正确，你不能走一步算一步，你需要提前规划好每一步。因为<strong>一旦中间某个环节你做错了，很可能整个任务都得推倒重来</strong>。</p>
<p>书里给出了在 Normal 模式下完成目标的 4 步</p>
<p><strong>1.设定一个目标</strong></p>
<p>即根据前面提到的 SMART
原则设定一个大目标，目标一般可分为主动目标和被动目标两种</p>
<p>(1)被动目标: 别人安排给你的任务，比如公司要求你达成的业绩 目标。
(2)主动目标: 是你自己想去完成的事情，是选择的结果</p>
<p>同时值得注意的是，所有的结果都需要你用注意力和时间去交换，而你的时间和注意力是有限的，如果你什么都想要，最后就什么也得不到</p>
<p><strong>2.把大目标拆解成小目标</strong></p>
<p>通过加法或乘法的方式将大目标拆成若干小目标</p>
<p>（1）加法分解：按照时间或空间分解，比如说未来一年要赚多少钱是目标，可以按照时间分解到每个季度；也可按空间把收入分成多个组成部分，如工资收入、业绩奖金、期权折现等
（2）乘法分解：需要找到与目标对应的数学公式，如销售额=流量×转化率×客单价</p>
<p><strong>3.将目标拆解成任务</strong></p>
<p>这一步就是把“结果”翻译成实现结果的“过程”，书里给了2 中具体的方法
（1）正向规划：有成熟的步骤、参考资料、历史的经验可以借鉴
（2）逆向规划：即以终为始，从结果倒推；同时可借助一种“事前验尸”的方法来列举出所有的失败可能，然后尽量避开这些失败可能</p>
<p><strong>4.执行</strong></p>
<p>有了具体的规划和任务，下一步就可以把这些任务放入你的 GTD
系统，开始逐项执行了</p>
<h4 id="hard-模式">Hard 模式</h4>
<p>事情到了这个级别，想靠一己之力去完成目标已经不可能了，你得调动几十人、几百人甚至上千人协同作战才行</p>
<p>这里借助了书的前半部分提到的
“NLP理解层次”，来设计一套能够调动一群人行动的计划方案，并称之为“N
计划”，其步骤如下</p>
<p><strong>1.为目标赋予意义，统一共识</strong></p>
<p>为整个团队设定目标，不仅要符合SMART原则，还需要为目标赋予重大的意义；一个有意义的目标自带影响力，它能够吸引斗士、凝聚人心。那意义是什么？书里给的答案是</p>
<blockquote>
<p>意义就是你为什么要制定这个目标，而不是其他目标。完成这个目标我们团队能获得什么?对我们团队的长远发展能起到什么样的关键作用?客户能因此获得什么?整个社会能获得什么?你们每个人能获得什么?对成长的帮助，对收入的贡献......</p>
</blockquote>
<p><strong>2.确认领袖，组建核心班底</strong></p>
<p>就是选出项目的 <a
href="https://en.wikipedia.org/wiki/Point_of_contact">POC</a>,
可以从过去、当下和未来三个方面去考虑</p>
<p>(1)过去: 在这件事情上曾经有哪些成功的经验; (2)当下:
是否拥有领导的品质，比如领导力、格局、智慧、性格等等; (3)未来:
对这个目标如何达成的战术思路是否靠谱，信心是否足够，意愿是否强烈等等</p>
<p>这里值得注意的是，<strong>千万不能抓壮丁</strong>，即有意愿去做但能力还不足的人；这样最终可能带来的是也许只有挫败感，打击的却是全团队的士气</p>
<p><strong>3.制定团队的行事原则</strong></p>
<p>即<a
href="https://wulc.me/2021/08/22/%E3%80%8A%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E6%A6%82%E5%BF%B5%E9%87%8D%E5%A1%91/">上篇文章</a>中提到的
BVR 概念，通俗来说就是原则</p>
<p>(1)B(Believe):信念</p>
<p><strong>信念即认为事情应该是怎么样的?世界是怎么运行的?你们的行动应该遵循哪个法则?整个计划应该遵循什么因果逻辑?</strong></p>
<p>信念也可以是某套理论体系或概念，比如行为经济学、长尾理论、网络效应等等。当你相信某套理论，相信未来会按它说的那样发展，那么你就可以以它为基础，开始设计你的规则，安排你的计划，建立你的行为和之后结果之间的因果关系。</p>
<p>(2)V(Value):价值观</p>
<p><strong>价值观即认为什么是对的，什么是错的;什么是重要的，什么不重要;什么是我们要的，什么是我们应该该坚决说NO</strong>的。</p>
<p>每个人都有自己的观点和喜好，没有绝对的正确与错误，但如果身处一个团队之中，所谓正确的事，就是符合团队价值观的事</p>
<p>(3)R(Rule):规条</p>
<p>信念和价值观略显抽象，<strong>规条把它们具象为具体的行为要求</strong>，比如对国家来说就是宪法和各种条例，对企业来说是制度，对团队来说是规则，对学生来说是行为规范</p>
<p><strong>4.配置人力、财力、物力</strong>
<strong>5.计划、分工、执行</strong></p>
<p>这两部分有重叠内容，书里放在一块讲了，总共有 6
不，而且很多内容跟前面有重合，这里也不详细展开了 (1) 分解目标 (2)
将目标分解成任务 (3) 分配资源:
有多少资源就干多大的事，实在需要就想办法去借，或者调低目标，步步为营，把雪球滚起来了再干大事
(4) 专业化分工: 保证每个人只专注于一件事，让专注产生个体效率 (5)
开始执行：通过 GTD 方法来执行 (6) 执行力保障：保证各个任务进度</p>
<p><strong>6.找势能高地借力</strong></p>
<p>即寻找部找资源，让团队站上有势能的高地，顺势而为，关于势能可以可参考上一篇文章</p>
<p>因此，结合 NLP 理解层次可画出下图</p>
<p><img src="https://wulc.me/imgs/HardPlan.jpg" height="50%" width="50%"></p>
<h3 id="计划还是演化">“计划”还是“演化”</h3>
<p>计划的有效性依赖 2 个前提</p>
<p>1.计划有正确的目标：“正确”指的是计划能经得起时间的考验，即现在笃信的一个目标，在未来是否会是一个靠谱的目标
2.计划靠谱：“靠谱”指的是在执行过程中能够能够克服“不确定”和“复杂性”两个问题，不确定指的是过程中可能有其他未曾设想的因素出现，复杂性则是指为了解决这些因素导致了总体方案膨胀，难以执行</p>
<p>我们常听到的“<strong>计划赶不上变化</strong>”，其实就是这 2
个前提中的部分不成立了；因此，书里还提出了一种“演化”的思维方式，这种方式基本就是自然进化的思想：遗传变异和自然选择，进而提出构建自我演化能力的方法，可分为如下
4 步</p>
<p><strong>1.开启初始状态</strong></p>
<p>不管是产品也好、团队也好，都需要从0到1，先开启一个初始状态，作为演化的起点。</p>
<p>对于产品而言，这一步不要去憋大招，一上来就想去设计一个包罗万象，改变世界的产品；而是要开启一个演化循环，让你的产品或者团队快速进入并适应眼前的市场，好产品、好团队、好结果都是演化出来的。这一点比较好理解，软件开发中的过度设计说的也是这个问题</p>
<p>对于团队而言，初始就是就是我们上节课讲到的创始团队+使命、愿景、价值观</p>
<p><strong>2.自然选择</strong></p>
<p>这里可分为外部和内部两部分的选择</p>
<p>外部指的是把自己的产品、服务投放到市场上去，接受用户的点赞或者吐槽，把用户的喜好当成一把自然剪刀，对自己进行一番修剪</p>
<p>内部指的是在团队内部设计一个竞争环境，让员工、团队、产品在内部进行各种厮杀，互相PK，优胜劣汰，完成企业整体的自我演化，比如腾讯著名的“赛马”机制，末尾淘汰机制等(优劣这里就不讨论了，本文只是客观陈述这一现象)</p>
<p><strong>3.变异</strong></p>
<p>变异在这里就是创新，变异可分为基因重组和基因变异，这里也对应着创新的两大类：<strong>重组式创新和突变式创新</strong></p>
<p>基因重组就是把原来就有的各种要素，用新的方式组合起来，形成一个新的个体；类比到重组式创新，一般优秀的要素越多，组合方式就越多，创新的空间也就越大；从产品层面具体来说，重组式创新要素包括：</p>
<ul>
<li>初代产品：特别是在上一步自然选择过程中体现出“生存优势”的部分</li>
<li>外部多样性：可以是在内部赛马制中输掉的团队，虽然输了赛马，但是否也有亮点，被用户特别喜欢的部分;或者是同行的产品中，是否有那些已经被市场认可的功能和设计(注意，是借鉴或者购买，不是抄袭)</li>
<li>内部多样性：团队中的人彼此擅长的部分、所属的领域等差异越大，越容易产生新的创意</li>
<li>....</li>
</ul>
<p>基因突变指的是某个特性，在某一代的身上突然出现了；类比到突变式创新，就是“主动试错”，书里举了如下例子</p>
<blockquote>
<p>如谷歌有个神秘部门叫“Google
X”，专门研发一些天马行空的项目，比如太空电梯，冷聚变，在海面上盖房子，利用磁悬浮技术开发悬
浮滑板，从海水中提取价格低廉的燃料，对抗衰老和死亡，当然也包括著名的Google
Glass...... 这些想法听着就很荒诞，很不靠谱......
而事实上，它们也确实基本都失败了......
但又有什么关系，就像是那些复制错误的基因，消亡就消亡吧，只要其中有一个项目能完成实质性的突破，能带来新的生存优势，也许就
能再造一个Google，甚至变成一个更厉害的物种。</p>
</blockquote>
<p><strong>4.遗传</strong></p>
<p>遗传这一步比较好懂，就是把经验和找到的生存优势遗传给下一代，让下一代站在巨人的肩膀上</p>
<p>说完了演化的特点，你可能会问，应该选择计划还是演化？其实这两者不是非此即彼，而是可以配合使用，计划的缺点是抗风险能力差，但好处是效率高，可以在短时间内高效地完成任务;而演化的优点是抗风险能力强，不需要具体的目标就能越变越好，但缺点是效率低、耗时长!</p>
<h3 id="创新">创新</h3>
<p>前面讲演化的时候简单提过了创新，这里则是给出了更详细的分析和方法论</p>
<h4 id="创新三要素">创新三要素</h4>
<p>创新要满足三个要素：<strong>新元素、价值增量和可实现</strong></p>
<ul>
<li>新元素：必须得有新的元素，可以是新技术、新创意、新材料，也可以是新的定位、新的应用、新的解决方案</li>
<li>价值增量：要能满足市场上的某些需求。没有价值的创新，只能称之为创意</li>
<li>可实现：想法能落地；创新理论的鼻祖熊彼特说过:“所谓的创新，就是发明的第一次商业化应用。”</li>
</ul>
<h4 id="重组式创新">重组式创新</h4>
<p>如同前面提到的，重组式创新就是把原来就有的各种元素，用新的方式组合起来，形成一个新的个体。书里给出重组式创新的三个操作步骤</p>
<p><strong>1.创造适合的环境</strong></p>
<p>合适的环境需要包含 2 个条件：<strong>(1)具有足够的多样性
(2)元素间能发生高效的连接</strong></p>
<ol type="1">
<li>具有足够的多样性</li>
</ol>
<p>简单来说就是要提高个人知识量，书里举了如下例子</p>
<blockquote>
<p>重组式创新就好像是玩乐高积木，积木的种类和数量越多，你能拼接出的作品就越多。因此，你想要创新，第一步就是要增加积木的数量和种类</p>
<p>什么是积木的数量?
就是你个人的背景知识量，你拥有的背景知识量越大，能用来组成创意的元素也就越多。因此，为了提高你的背景知识量，你需要阅读，大量地阅读，不停地阅读，这是创新的基础。</p>
<p>什么是积木的种类?
一个人看再多书也是有限的，而且大多会集中在你感兴趣的领域上，因此你在某个方面越专业，了解得越深入，可能就越缺乏其他领域的知识。所以，你需要找不同领域的人来和你一起碰撞想法，增加你们的背景知识总量。一个由五个不同领域的人组成的团队，比五个都是同行的团队，能碰撞出更多的创意火花</p>
</blockquote>
<ol start="2" type="1">
<li>元素之间能发生高效的连接</li>
</ol>
<p>这部分讲的更多是如何有效进行团队的沟通与协作, 主要包含三部分：从 “No”
到 “Yes...And...”、设置规则保证充分链接、创造彼此链接的办公环境</p>
<p>首先，不管是你一个人在思考，还是很多人在一起讨论，记得都<strong>不要说“No”，而是要说:“Yes...And...”</strong>，书里举了如下例子</p>
<blockquote>
<p>No 是否定想法;
好比在积木堆中出现了一块看上去很丑的积木，觉得没用准备把它扔了；但看上去很丑的积木，也许就是一个新品种出现了，目前看上去没有什么用，但是一旦积木越来越多了之后，你也许就会突然发现它大有用处。</p>
<p>因此，你需要用“Yes...And...”来先肯定这个怪想法，然后基于这个怪想法接着思考:“如果加上了这个想法，接下来可能还会发生什么呢?”这样就很容易跳出固有的思维框架，来到一片新大陆，产生意想不到的结果。</p>
</blockquote>
<p>其次，如果是多人讨论，你们就需要<strong>设置一些规则，来保证彼此能充分链接，让想法不断涌现</strong>。比如说书里提到的头脑风暴往往没有发挥很好的作用，如下例子所示</p>
<blockquote>
<p>会议刚开始不久，还没等几个新想法出现，有些在公司略有地位的人，就开始跳出来指点江山，接着，这些大佬们就开始试图彼此说服，急于证明自己的想法特别厉害，分分钟为别人的智商感到担忧。
然后，一言不合就开启辩论模式，头脑风暴眼看就要变成一场辩论大会，场中央的领导实在看不下去了，一拍桌子举手表决!看着大佬们唇枪舌剑杀红了眼，明明有了新想法的小透明们也不敢多插一嘴，只得默默地把票投给了自己的上司......
与其说这是头脑风暴，不如说是舞台选秀，谁的嗓门大，谁的地位高，谁的人缘好，谁就能赢取最终的胜利!请问，这样的方式之下会有创新吗?
答案自然是否定的
其实，大多数团队用错了这个工具。其实，<strong>头脑风暴就是群体版的“Yes...And...”，是靠点子来激发点子的沟通方式</strong>，任何一个新想法的出现，都需要被鼓励，甚至是夸张的鼓掌支持，然后由这个不靠谱的想法展开，链接到越来越多不靠谱的想法，就像水中的涟漪，层层裹挟，不断散开，最终踏入一片未曾想象到的领域，进而迸发出真正的创新火花。</p>
</blockquote>
<p>最后，你还得创造一个能促进<strong>彼此链接的办公环境</strong>。即创造出成员之间更频繁、更平等的交流环境。书里举了如下例子</p>
<blockquote>
<p>比如，曾经创造了《玩具总动员》《怪物电力公司》《飞屋环游记》《寻梦环游记》等无数票房神话的皮克斯动画，为了在公司里营造更好的创新环境，他们撤掉了全公司的长会议桌和座次牌，因为老板觉得这些会造成成员之间的层级感，影响链接的效率，比如坐在长桌子中间的人，总是更有权威感，让其他位置上的人不敢畅所欲言，而全部换成圆桌之后，沟通效率大大提升。</p>
</blockquote>
<p><strong>2.收集创新元素</strong></p>
<p>有了激发创造力的环境后，下一步就是要去看创新是如何被产生的。书里通过下图来描述这个过程，图中横轴代表离创新本体的距离，纵轴代表元素属性的虚实，然后以“创新本体”为轴心(以产品创新为例)，由近及远地把寻宝图分成5个层级(同行、异业、原型、环境、时空)，共10个板块，</p>
<p><img src="https://wulc.me/imgs/Innovation.jpg" height="50%" width="50%"></p>
<ol type="1">
<li>同行层</li>
</ol>
<p>同行层是离创新本体最近的一层，是指你在<strong>同行中寻找那些可以借鉴的部分</strong>，然后把它们拿过来和自己的产品重组，从而让自己变成一个更好的创新产品，</p>
<p>同行层中的元素包含两个部分，看得见<strong>实体的部分:产品</strong>，比如同行产品中某处优秀的界面设计，某个让人着迷的互动玩法，又或者是某项对用户帮助极大的功能和技术等;另一半是看不见的、<strong>虚的部分:模式</strong>，比如同行的战略定位、商业模式、组织运营等。</p>
<p>这个过程需要的不是灵感，而是是<strong>大量的信息收集和配对测试</strong>；同时书里也强调了不是要去“抄袭”同行，而是在不侵害他人专利的情况下，善于借鉴、学习他人优秀的部分，对有专利保护的部分要舍得购买，然后引入自己的产品中</p>
<ol start="2" type="1">
<li>异业层</li>
</ol>
<p><strong>异业层和同行层一样，只不过对象换成了其他行业</strong>，拥有了更大的范围。比如你是做手机的，除了向同行学习借鉴之外，你还可以跑到汽车业、家具业甚至娱乐业等其他行业中去找寻创新元素。书里举了如下例子</p>
<blockquote>
<p>19世纪末期，当时新生儿的死亡率奇高，一直得不到有效的解决。一个名叫斯蒂芬·塔尼的妇产科医生，在一次逛动物园的时候，偶然看到了园内的一个小鸡孵化器，刚出生的小鸡在这个小温室里
活蹦乱跳，这给他带来了启发。之后，他便与奥迪尔·马丁一起借鉴了小鸡孵化器的模式，制造出了人类婴儿用的恒温箱，挽救了数以亿计的生命。</p>
</blockquote>
<ol start="3" type="1">
<li>原型层</li>
</ol>
<p>“原型层”离大众视野就比较远，这一层的实体部分是可能还<strong>停留在实验室阶段的技术和原型</strong>，它们或找不到应用场景，或无法量产，或还没普及.书里给了如下的方法和例子</p>
<blockquote>
<p>在这一层寻找创新元素的时候，你得去全世界各地搜寻那些还未被广泛使用的黑科技，它不一定完全在实验室里，也可能在其他行业中已偶有尝试，只是效率可能还不高，或者使用的方法不对。你把它们找出来，并试着与你的产品重组，看看能否产生新的化学反应，提升现有价值，实现量产。一旦适配，这通常都是颠覆性的创新</p>
<p>这其中特别要留意“<strong>提高能量使用效率</strong>”和“<strong>提高信息传播效率</strong>”方面的技术突破，这两方面一旦出现了可商用的技术突破，随之带来的可能就会是全行业的整体革命。你如果能够率先应用，将能取得划时代级别的领先优势，比如蒸汽机、内燃机、电力等提高能量使用效率的发明推动了第一次和第二次工业革命;纸张、印刷术、电话、无线通信、互联网等提高信息传播效率方面的技术突破，带来了人与人协作效率的大幅提升，催生出了很多全新的行业。</p>
</blockquote>
<ol start="4" type="1">
<li>环境层</li>
</ol>
<p>创新元素不仅可以是已经成型的技术、模式或者产品，还可以到“自然界”和“人生经历”中去寻找。书里给了如下的例子</p>
<blockquote>
<p>比如，第一次世界大战期间，德国第一次大规模地使用了毒气战，导致英法联军伤亡惨重。为了避免悲剧再次发生，英法联军开始投入研发防毒面具。经过一番调查，他们发现战场上大多数的
动物都因中毒而亡，唯独野猪没有死。原来，当毒气来袭时，野猪们会把鼻子拱进泥土里，松软的土壤既保证了呼吸又过滤了毒气，这才让它们幸免于难。科学家就根据这个原理，发明了世界上第一批防毒面具。</p>
</blockquote>
<ol start="5" type="1">
<li>时空层</li>
</ol>
<p>时空层，就是脱离当下的束缚，跨越时空，回到过去，走进文化，甚至到并不存在的虚拟故事中去提取创新元素，书里举了如下例子</p>
<blockquote>
<p>创新元素可以是故事和传说，它们本身就是创新的结果，是虚拟创造出来的东西，你可以直接将它们变换形式，做二次、三次的创新。
比如，你可以把虚拟的形象产品化:蜘蛛人的衣服、海贼王的手办、忍者神龟的背包、流氓兔的抱枕、蓝精灵的茶杯......
你还可以把这些虚拟的形象现实化，比如迪士尼乐园、丹麦童话之城蒂沃利公园、日本环球影城、环球冒险岛乐园......
你还可以把这些不同故事里的虚拟形象集合在一起，比如聚在一起拍部电影，叫作《复仇者联盟》;聚在一起制作个游戏，叫作《英雄联盟》......</p>
</blockquote>
<p><strong>3.重组并验证可行性</strong></p>
<p>当我们填完这10个模块内的信息，基本上就能在其中找到适合自己的创新元素并开始重组。如果还找不到，那就是收集的信息还不够多</p>
<h4 id="突变式创新">突变式创新</h4>
<p>重组式创新是向外寻找的创新方法，与优秀为伍；而突变式创新是向内探求的创新方法，在一次次自我“破坏”中，找到创新的方向。书里给的操作方法是<strong>拆解、修改和验证可行性</strong>，且主要在阐述修改部分(对应着基因变异)</p>
<p>1.拆解: 即要清楚自己产品是由哪些元素组合起来的
2.修改：书里给出了如下四种修改，这里值得注意的是现在是，并不是每一种突变都要去尝试，因为失败的成本太高，你需要在沙盘上先不断地推演，只有<strong>凑齐了全部的三个创新要素才能开始实践</strong></p>
<p><strong>(1)减去一个元素</strong></p>
<p>对应生物的基因在进行遗传复制时，有可能会丢失部分遗传信息；但这里<strong>最好减去的是比较重要的部分，因为如果是无关紧要的部分，那么变化将不会很大</strong>。书里举了如下的例子</p>
<blockquote>
<p>比如风扇的例子中，你可以试试把风扇叶给减掉!
什么!没有风扇叶的风扇?还真异想天开啊......
没关系，假设要大胆，先别急着说“No”，而是试着说“Yes... And...”
好，现在新元素肯定是有了，那是否能给它补齐创新三要素里的另外两条边——“价值增量”和“可实现”呢?
先思考:如果没有风扇叶，会有哪些好处? - 小孩子会更安全; -
噪音应该也能小很多; - 外表酷炫到没有朋友，很有未来感!</p>
<p>看来价值增量还不少，应该是很有市场的，现在只差“实现”这一步 了......
英国人詹姆士·戴森根据干手器的原理，于2009年10月12日真的就发明了一款没有风扇叶的风扇,也就是我们后来熟悉的戴森的品牌了</p>
</blockquote>
<p><strong>(2)复制一个元素</strong></p>
<p>对应生物的基因在进行遗传复制时，可能会把某个碱基复制多次而发生变异；书里举了如下例子</p>
<blockquote>
<p>智能手机的组成部分有屏幕、主板、电池、按键、摄像头、SIM卡槽、外壳等等。
我们从中挑选一个元素进行复制，比如原来是一个摄像头，现在复制成两个，背面的用来拍别人，正面的用来拍自己;复制成三个，背面两个，正面一个，背面两个摄像头可以拍出更高质量的照片，或者拍出
3D 效果。
你还可以把一个屏幕复制成两个屏幕，正面一个液晶屏用来玩游戏、刷微博，背面一个墨水屏用来看书。
你还可以把SIM卡槽进行复制，双卡双待，三卡三待，天啊，现在竟然都已经有四卡四待了......可四卡有什么价值?自己和自己打麻将吗?
不是，在中国可能用处不大，但如果放在非洲就不一样了，由于非洲有多个通信运营商，不同运营商的电话互打资费很高，所以一个人办理多个卡，用同卡通话来减低通信费，变成了当地的刚需，就像我们国内用中国移动和中国移动的卡通话有优惠套餐一样。有一家来自中国的著名手机公司“传音”就生产了很多款四卡四待的手机，在非洲成了爆款，销量远超iPhone、三星等，是非洲人心目中的手机第一品牌......</p>
</blockquote>
<p><strong>(3)重新组合元素</strong></p>
<p>对应生物的基因在进行遗传复制时，可能会出现碱基顺序的变动而发生变异；因此可以尝试将产品原本的结构打乱，将功能或者硬件“重新组合”成另一种形态来实现创新，书里举了如下例子</p>
<blockquote>
<p>比如把产品的某个部件抽离出来，放到其他位置上:在20世纪60年代之前，对电视机进行操作都是在电视机主体上进行的，后来在1950年由美国的一家叫Zenith的电器公司，将控制的部分从电视机主体上分离了出来，就变成了如今你熟悉的遥控器，大大方便了我们的日常使用</p>
<p>上面是把原本一体的事物分离开，也可以试着把原本分离的事物整合在一起；比如，每次上完洗手间你都要去洗手，而马桶每次冲完也需要在蓄水箱里加水，这两件事一直是关联发生的，因此是否可以把这两件事放在一个框架内去思考?
日本的TOTO卫浴就将这两件事结合在了一起，他们在马桶的蓄水池上装了个水龙头，每次冲完水，水龙头就会自动出水，可用于洗手，洗完手的水会进入蓄水池以备二次使用，这样既方便，还能节约空间，节约水资源</p>
</blockquote>
<p><strong>(4)改变元素的特性</strong></p>
<p>即通过放大、缩小、逆转等操作，改变某个元素的特性来实现创新;书里举了如下例子</p>
<blockquote>
<p>可以放大某个元素的功能来实现创新。你环顾四周，就能发现许多产品都是通过这种方式来实现创新的，比如更高的运行速度，更大的显示屏幕，更快的上网带宽，更强的输出动力......放大的好处自不必多说，这类创新更重要的是考虑可实现性</p>
<p>同样可以通过缩小某个元素，让产品获得一种新的特性。比如，将硬盘的尺寸缩小，于是有了U盘;将博客的字数缩短,
于是有了微博; 将视频的长度缩短，于是有了抖音......</p>
<p>还可以逆转某个元素的状态或者功能等来实现创新。比如，原来电吹风是将风吹向物体，现在反过来，将空气往机器里吸，于是有了吸尘器;原来是人走楼梯，现在反过来，人不动楼梯动，于是有了自动扶梯;原来电动机是电产生磁场，磁场移动物体，现在反过来，让移动产生磁场，磁场再产生电，于是有了发电机</p>
</blockquote>
<p>最后就是验证可行性了，按照上面的想法创意也许会来得很快，但是先别急着去实践，得先反复确认它是否满足创新三要素，<strong>只有创新三要素的三条边完全闭合了才能动手实践</strong>，并在初期仅做小范围的测试，获得真实的积极反馈后，再开始大量生产。</p>
<h2 id="小结">小结</h2>
<p>书中后半部分主要内容如下</p>
<p><strong>1.解开大脑的封印</strong></p>
<ul>
<li>负面词语和负面情绪是大脑的两道封印</li>
<li>解开封印需要提升解决问题能力，建立正确信念系统</li>
<li>学习知识不是目的，解决问题才是，需要里利用知识提升解决问题时的思考能力</li>
<li>知识获取前需要经过三个过滤器，善于利用工具对知识进行存储，并让知识链接起来</li>
<li>提升效率，从内因和外因入手</li>
</ul>
<p><strong>2.思维能力的提升</strong></p>
<ul>
<li>问题是现状和预期的落差，需要精准描述</li>
<li>分析问题的“透析三棱镜”: 校准目标(SMART
原则)、重构方法(治本)、消除变量(象、数、理)</li>
<li>线性思维：重视因果性；三段论的演绎法，归纳法(穆勒五法)与类比法，要刻意练习</li>
<li>结构化思维：描述问题/方案要全面；金字塔结构(自上而下、自下而上)、平面切割法</li>
<li>系统性思维：动态地看事情，厘清要素之间的相互作用；增长上限、舍本逐末是两种常见结构</li>
</ul>
<p><strong>3.解决所有问题</strong></p>
<ul>
<li>选择大于努力，因此得更多时间在选择上，但是小事不要纠结</li>
<li>人是非理性的，要启动慢思考克服这个问题</li>
<li>盯着问题而不是选择，将选择题变为简答题，找到第三选择</li>
<li>把目标分为 easy、normal 和 hard：easy 注重“执行(”GTD方法)，normal
注重“执行+计划”，hard 注重“执行+计划+协作”</li>
<li>构建自我演化能力，应对不确定的世界</li>
<li>满足创新三要素才去执行，否则只是创意</li>
<li>重组式创新要创造合适的创新环境, 并通过五个层来收集创新元素</li>
<li>突变式传创新要拆解和修改，4 种修改方式</li>
</ul>
<p>因为概念较多，所以这里也做了思维导图，连同书的前半部分如下图所示，原始的
<a
href="https://github.com/WuLC/resources/blob/master/%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9.xmind">xmind
文件</a>也可以从 github 下载</p>
<p><img src="https://wulc.me/imgs/%E8%AE%A4%E7%9F%A5%E7%BA%A2%E5%88%A9.png"></p>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>什么才算是真正的编程能力？</title>
    <url>/2016/01/04/%E4%BB%80%E4%B9%88%E6%89%8D%E7%AE%97%E6%98%AF%E7%9C%9F%E6%AD%A3%E7%9A%84%E7%BC%96%E7%A8%8B%E8%83%BD%E5%8A%9B%EF%BC%9F/</url>
    <content><![CDATA[<p>本文综合整理自知乎同名问答帖
链接：https://www.zhihu.com/question/31034164/</p>
<hr />
<p>题主问题：
&gt;还在读书，也在实验室帮忙做了些东西，自己也搭过几个网站。在周围人看来似乎好像我很厉害，做了那么多东西，但是我发现这些东西虽然是我做的，但是实际上我手把手自己写的代码却并没有多少，很多都是用开源的东西，我写的代码无非是把别人的东西整合下，类似于胶水一样的工作。
<span id="more"></span>
&gt;我之前所认为的编程是全手动一行一行敲代码，但是现在我发现哪怕是工程上，也有很多人是复制黏贴来解决问题的，并且提倡不要重复造轮子。</p>
<blockquote>
<p>但是靠谷歌和复制别人的轮子，虽然我做出了很多东西，可是我并不觉得自己能力上有提升，倒是利用搜索引擎的能力的确提升了不少。而学校里另外一部分在搞ACM的人，他们每天都在刷题练算法，但单凭我个人的感受感觉他们似乎对工程上有些东西并不了解，或许算法的能力才算是实打实的编程能力？那”胶水”的能力和整合轮子的能力算不算编程能力呢?</p>
</blockquote>
<blockquote>
<p>所以我现在就很困惑，所谓的编程能力到底是什么，我该如何提升自己的编程能力？</p>
</blockquote>
<p>下面是两个人的回答：</p>
<p>下面是刘贺的回复,专栏：http://zhuanlan.zhihu.com/shanhu
链接：https://www.zhihu.com/question/31034164/answer/50423838</p>
<blockquote>
<p>非常好的一个问题。这可能是我在知乎见到过的问编程有关的问题中问得最好的一个了。我非常喜欢这个问题。</p>
</blockquote>
<blockquote>
<p>计算机科学有两类根本问题。一类是理论：算法，数据结构，复杂度，机器学习，模式识别，等等等。一类是系统：操作系统，网络系统，分布式系统，存储系统，游戏引擎，等等等等。</p>
</blockquote>
<blockquote>
<p>理论走的是深度，是在追问<strong>在给定的计算能力约束下如何把一个问题解决得更快更好</strong>。而系统走的是广度，是在追问<strong>对于一个现实的需求如何在众多的技术中设计出最多快好省的技术组合</strong>。</p>
</blockquote>
<blockquote>
<p>搞ACM的人，只练第一类。像你这样的更偏向于第二类。其实挺难得的，但很可惜的是第二类能力没有简单高效的测量考察方法，不像算法和数据结构有ACM竞赛，所以很多系统的苗子都因为缺少激励和正确引导慢慢就消隐了。</p>
</blockquote>
<blockquote>
<p>所以比尔盖茨才会说，看到现在学编程的人经常都把编程看作解各种脑筋急转弯的问题，他觉得很遗憾。</p>
</blockquote>
<blockquote>
<p>做系统，确实不提倡“重复发明轮子”。但注意，是不提倡“重复发明”，不是不提倡“重新制造”。恰恰相反的，我以为，<strong>系统的编程能力正体现在“重新制造”的能力。</strong></p>
</blockquote>
<blockquote>
<p><strong>能把已有的部件接起来，这很好。但当你恰好缺一种关键的胶水的时候，你能写出来吗？当一个已有的部件不完全符合你的需求的时候，你能改进它吗？如果你用的部件中有bug，你能把它修好吗？在网上繁多的类似功能的部件中，谁好谁坏？为什么？差别本质吗？一个开源代码库，你能把它从一个语言翻译到另一个语言吗？从一个平台移植到另一个平台吗？能准确估计自己翻译和移植的过程需要多少时间吗？能准确估计翻译和移植之后性能是会有提升还是会有所下降吗？</strong></p>
</blockquote>
<blockquote>
<p><strong>系统编程能力体现在把已有的代码拿来并变成更好的代码，体现在把没用的代码拿来并变成有用的代码，体现在把一个做好的轮子拿来能画出来轮子的设计蓝图，并用道理解释出设计蓝图中哪些地方是关键的，哪些地方是次要的，哪些地方是不容触碰的，哪些地方是还可以改进的。</strong></p>
</blockquote>
<blockquote>
<p>如果你一点不懂理论，还是应该学点的。对于<strong>系统性能的设计上，算法和数据结构就像在自己手头的钱一样，它们不是万能的，但不懂是万万不行</strong>的。</p>
</blockquote>
<blockquote>
<p><strong>怎么提高系统编程能力呢？土办法：多造轮子。就像学画画要画鸡蛋一样，不是这世界上没有人会画鸡蛋，但画鸡蛋能驯服手指，感受阴影线条和笔触。所以，自己多写点东西吧。写个编译器？渲染器？操作系统？web服务器？web浏览器？部件都一个个换成自己手写的，然后和已有的现成部件比一比，看看谁的性能好，谁的易用性好？好在哪儿？差在哪儿？为什么？</strong></p>
</blockquote>
<blockquote>
<p>更聪明一点的办法：<strong>多拆轮子</strong>。多研究别人的代码是怎么写的。然而这个实践起来经常很难。原因：大部分工业上用的轮子可能设计上的思想和技术是好的，都设计和制造过程都很烂，里面乱成一团，让人乍一看毫无头绪，导致其对新手来说非常难拆。这种状况其实非常糟糕。所以，此办法一般只对比较简单的轮子好使，对于复杂的轮子，请量力而行。</p>
</blockquote>
<blockquote>
<p>轮子不好拆，其实是一个非常严重的问题。重复发明轮子固然是时间的浪费，但当轮子复杂而又不好拆的时候，尤其是原来造轮子的人已经不在场的时候，重新发明和建造轮子往往会成为无奈之下最好的选择。这是为什么工业界在明知道重复发明/制造轮子非常不好的情况下还在不断重复发明/制造轮子的根本原因。</p>
</blockquote>
<blockquote>
<p><strong>程序本质是逻辑演绎的形式化表达，记载的是人类对这个世界的数字化理解。不能拆的轮子就像那一篇篇丢了曲谱的宋词一样，能读，却不能唱。</strong></p>
</blockquote>
<blockquote>
<p>鄙人不才，正在自己研究怎么设计建造一种既好用又好拆的轮子。您没那么幸运，恐怕是等不到鄙人的技术做出来并发扬光大了。在那之前，多造轮子，多拆好拆的小轮子，应该是提高编程能力最好的办法了。</p>
</blockquote>
<blockquote>
<p>以上。嗯。</p>
</blockquote>
<blockquote>
<p>（文章属个人观点，与本人工作雇主无关。）</p>
</blockquote>
<p>下面是疯坦克的回答
链接：https://www.zhihu.com/question/31034164/answer/74716106</p>
<blockquote>
<p>真正的编程能力其实并不是对语法细节的理解，也不在于手写或者复制粘贴，更不在于对什么操作系统的使用，或者常用库的api的记忆。而是<strong>找出解决方法的能力，把现实问题转换为代码逻辑的能力。这个是最重要的。语法很好学，只要看一看，再不行网上搜一搜都有，但是解决问题的能力，在网上搜不到，找不来，谁也帮不了。只能在长期的分析问题解决问题的过程中得到。</strong></p>
</blockquote>
<blockquote>
<p>在工作中，见过太多面试的时候打高分，把什么<code>const char*</code>,
<code>char const*</code>,
<code>char*const i+++++i</code>这种奇技淫巧玩的烂熟，解决问题的时候一筹莫展的。只能你清晰明了的告诉他流程他才能实现。这样的人，要是不思进取，沉浸在这种很多公司禁用的语法技巧里沾沾自喜，可能永远只能是个代码流水线工人。也有很多人面试的时候各种语法都模棱两可，提起做过的项目和程序，却能够条理清楚，头头是道。给他一个问题，他几分钟就给出还不错的解决方案。这样的人，<strong>随便什么语言，什么语法，什么库，对他来说都是工具。他知道与否，都能最终解决问题。</strong>其实不管是复制黏贴也好，自己手写也好，关键的是解决问题。编程最终还是个生产工具，目的是解决问题，不能解决问题的，一切都是空中楼阁，毫无价值。</p>
</blockquote>
]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>从焦虑谈起，聊聊生活的可能性与随机性</title>
    <url>/2022/07/31/%E4%BB%8E%E7%84%A6%E8%99%91%E8%B0%88%E8%B5%B7%EF%BC%8C%E8%81%8A%E8%81%8A%E7%94%9F%E6%B4%BB%E7%9A%84%E5%8F%AF%E8%83%BD%E6%80%A7%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%80%A7/</url>
    <content><![CDATA[<p>35
岁这个槛，似乎是悬在互联网人头上的达摩克利斯之剑，一直在各大媒体上被鼓吹放大，虽不明真假，但也让人不寒而栗；而持续了三年的疫情加上
2022 随之而来互联网裁员潮，王兴那句开玩笑似的 “2019
可能会是过去十年里最差的一年，但却是未来十年里最好的一年”
似乎一语成谶。</p>
<p>走在奔三的路上，凝望这前面那个迷雾般的 35
岁路口，焦虑就一直萦绕在心头；伴随着的是一系列的疑问：大厂为什么要裁员？所谓的
35 岁危机从何而来？只有互联网才有这个危机么？普通人只能眼巴巴地等待着 35
岁到来然后被裁掉？我们能做些什么？</p>
<p>当我最开始问出自己这一串问题时，焦虑中带着点绝望，因为前方的路虽然处于迷雾，却又似乎一眼能望到头；但是准备写这篇文章，心里又平静了很多，也许是经过这一个多月的调研和自我教育，看到了生活的可能性和随机性，接受了与焦虑为伴这个事实。本文算是写给自己的心理按摩，文章可能会有点发散，祝开卷有益。</p>
<p><img src="https://wulc.me/imgs/fog.jpg" height="70%" width="70%"></p>
<span id="more"></span>
<h2 id="裁员危机与焦虑">裁员、危机与焦虑</h2>
<h3 id="裁员原因">裁员原因</h3>
<p>先说大厂裁员，大厂裁员本质上是在停止增长后的断臂求生；你会发现，首先裁员的部门基本是那些还没有实现盈利、具备较大不确定性的部门，而经济下行时，企业更多地会追求稳定性而放弃未来不确定的可能性；在这种前提下，往往会存在整条业务线被优化掉的情况，有时候哪怕你是一个高职级的员工、或者是应届生，也难逃被裁的结果</p>
<p>上面很关键的一个词是是“停止增长”，从微观层面的角度来看，停止增长指的是公司的
DAU
可能已经见顶，广告等收入也见顶，而能够带来新的现金流的业务还没出现；从宏观层面来看，则是<strong>整个互联网行业面临着没有新要素的困境</strong>(新要素指的是之前的移动互联网、移动支付)，目前很难去找到一个所谓风口，或者说蓝海。无人驾驶，元宇宙，web3
等等，都还无法没看到变现的迹象，大厂基本的现金流还是传统的广告、游戏和电商</p>
<p>PS：其实这三年反复的疫情，各行各业都不好过，也并非只有互联网大厂在裁员，只是刚好这个人群在互联网上的声音比较大，裁员其实是从传统行业一直蔓延到互联网大厂的，因为疫情最先影响的就是实体的生意，然后才是互联网，实体生意都没了，还需要啥营销和广告呢</p>
<p>裁员现象其实跟资本二级市场里的一些现象有点类似，比如说裁员存在恐慌情绪的蔓延，大厂开始裁完了，中厂也会跟着裁；举个可能不是很恰当的例子，裁员就是公司看空未来的经济发展，跟二级市场大家看空某个股票疯狂抛售并无二样，且抛售的股票无人接盘</p>
<p>裁员另一个很重要的原因是人员冗余，因为在经济好、资本充足时，一切看起来欣欣向荣；在这个时候大厂招人并不理性，会疯狂招人，而且大的组织做很多事情都有惯性，招人会一直招到非常冗余，这个惯性就有点像钟摆效应，如同在大牛市顶端进去接盘的人们，大家都是怀揣着上证指数要上
1 万点的心态进场的</p>
<p>疯狂招人背后，边际收益的递减是必然存在的，乱翻书在 54
期播客聊到这个话题时(相关链接会放在最后)，里面有句话特别传神：“<strong>飞驰的火车上，每个人都觉得自己在开火车，其实大家都在车厢里做布朗运动</strong>”</p>
<p>所以，大家会发现裁员后，对公司业务的影响可能是很小的，工作业绩影响微乎其微，但是财报会立马更好看，其实这个也可以用二八法则来解释(最近越来越发现，几乎一切皆可二八法则)，这就好比在一个广告系统里，把那些无跑量素材或计划砍掉，你会看到对整个大盘的几乎是无损的，但是所谓的生态会好很多，但从另一个角度来看，这牺牲了长尾计划/素材的探索空间，回到公司上，则是牺牲了未来的可能性。</p>
<h3 id="裁员迹象">裁员迹象</h3>
<p>裁员一般会有什么迹象？在乱翻书的播客里提到了，裁员一般有 2 种情况</p>
<p>（1）中小公司，突然遭受资金上的问题，然后急于去控制成本，会迅速的在所有层面，包括连行政费用都会裁掉，比如说员工的福利等
（2）大厂，经济性的裁员，提前预示到了未来会有什么风险，会有什么趋势的变化，前置的进行成本优化。整个成本结构被拉出来，人力成本的优化只是其中的一部分</p>
<p>定下了裁员目标后，会盘点业务，然后决定部门需要裁员的比例，这个时候可能会出现<strong>频繁的汇报</strong>，写
PPT 描述你在做什么，产出了什么价值等</p>
<p>另外，裁员的决策往往没有一个很长周期的准备和测试，有时候就只是上面突然把这个指令传达到
hr
的一句话，然后立马开始了“约谈-&gt;赔偿-&gt;走人”等一系列流程；所以可能会出现前脚刚给五星，后脚就立马裁人；前面还在疯狂招人，后面就开始冻结
hc 并开始优化</p>
<h3 id="被裁了怎么办">被裁了怎么办</h3>
<p>首先要对大环境有一个判断，就是自己所处的专业的人才<strong>供需情况</strong>，裁员初始阶段会存在大量的人不愿意激降身价的情况，趁着这个时候市场上的供给端还比较充足，需要从你有经验的这个细分领域里边找到一个比较优质的岗位迅速地嵌进去</p>
<p>说到底了还是供需关系，这也是为什么在知乎上相关的回答有很多建议，如果公司大趋势就是要裁员，且你所在的业务线有较大的风险,
就争取做第一批被裁的</p>
<p>那怎么市面上的工作的好坏？基本上，只要业务能够有<strong>良好的现金流，业务看上去比较靠谱</strong>，这些岗位普遍就好。像那种还依靠着融资的钱生存，还没有正向现金流的业务，并且在你可预期的未来，都不太可能有稳定的现金流,
这种预判非常考验个人的判断力，同时也有运气成分在里面。</p>
<p>比如说自动驾驶、新能源车这些它未来是趋势吗？一定是趋势，但是你不知道它什么时候能到那个节点。万一它是十年，而假如你在一个行业等十年，那这十年你是不是真的能积累下来一些经验？</p>
<h3 id="岁危机中年危机">35岁危机/中年危机</h3>
<p>为什么媒体一直把 35 岁锚定为中年危机的年龄？其实定 35
这个坎是为了方便大众的认知和媒体的传播，真相是这个年龄段上下的都算是这个范围</p>
<p>而这个年龄段会有的一些共性：上有老下有小，需要照看的东西更多了，放到工作上的精力会更少，同时学习能力和学习意愿普遍的会偏弱化一些(尤其面对一些创新业务的时候)；
当然，这是普遍意义，但不是绝对意义上的。因此，在面对一些经验价值没那么高的业务类型上，找一个年轻的更有冲劲的精力更充沛的，性价比会更高；而互联网又有多少经验价值高的业务呢？</p>
<p>说白了就是只要你不是不可替代的，找到了更便宜好用的螺丝钉，就会把老的生锈螺丝钉摘掉，这么说可能会比较残酷，但目前看来事实就是如此</p>
<p>如果说的更残酷一点，所谓的中年危机，就是钱不够，不够满足当前的需求和欲望，无法如预期水平地去照看你关注的那些人和事；面对收入的断崖式下跌，心理和生活上都难免会受到冲击</p>
<h3 id="被规训的大厂人">被规训的大厂人</h3>
<p>规训这个词，从播客里听到的时候就觉得非常的妙，一般来说每个厂都有自己的一些文化，入乡就要随俗，而很多人从毕业开始就在一个大厂环境里面，里里外外地被规训，他认识世界的方式和做事的方式全部是依赖这个大厂形成的规则，但他意识不到是被规训的</p>
<p>这种规训最大的问题在于，他<strong>内心的秩序和意义是来自于这个大厂的</strong>，你如果问他喜欢什么，做什么事情能沉浸有热忱，他突然会发现卡壳</p>
<p>这样的人一旦离开，要面对的问题还是挺多的，尤其是心理上的；有个很好的比喻就是“这就像在一个鱼缸里边圈养了
50
年的一个鲸鱼放归大海”，我们认为是自由，但是对他来说不是他认识世界的方式。这跟
ze ran 在 “程序员的悲哀是什么” 这个问题写下的<a
href="https://www.zhihu.com/question/399148081/answer/1289671821">回答</a>：“大学毕业了很多年，还有种初入社会的疏离感”，感觉很相似</p>
<p><a
href="https://m.jellow.club/users/1c582789-2b28-4fc2-9712-ab3032e3dabe">戴某demo</a>
在播客里更是一针见血的指出了这种现象的问题</p>
<blockquote>
<p>你在一个厂里边没有升到高管，又能做十几年，这本身代表着一些事情。其实那个脑子比较开放性的意愿比较多的，比较强的，普遍的会有很多想法，要么在大厂里边自己管一块业务，要么就蹦出来，可能成、可能不成，那是命运的问题；但是不会在一个大厂里面像做一辈子一样去做十几年，但是公司不开我，我可能做
20
年对吧，最终这个漏斗本身筛下来能做那么久的又不是高管的，是同一类人，<strong>相对追求确定性，安稳，开放性没那么足</strong>。专业上垂直，因为待得久，有一定的专业能力，但这个<strong>专业能力要依附于某个大平台</strong></p>
</blockquote>
<p>在所谓的大厂裁员和中年危机双重 debuff
的加持下，焦虑自然是难免的了，我们不禁会问，我们能做什么？如果离开大厂，是否就能消解掉这两个
debuff？</p>
<h2 id="不止一种叙事方式">不止一种叙事方式</h2>
<p>这部分不少案例来自<a
href="https://m.jellow.club/users/BB769515-C724-4652-8838-6AA32EC1A8DF">刘飞</a>的“<a
href="https://www.xiaoyuzhoufm.com/collection/episode/623afb37d79419001097242c">非大厂叙事</a>”系列播客，主要讲了生活更多的可能性，即除了在各个大厂反复横跳，或者是融资烧钱、做具备规模效应的创业以外，还存在的一些其他可能性，笼统地概括就是自己找到一个现金流比较好、不追求多大规模的生意，把眼前的事情做好，用内容支撑品牌，用播客里的话来说就是“浙商思维”。</p>
<p>而刘飞也提到了很多人不做这件事的原因，那就是信息差：“很多老同事老朋友他们非常缺乏安全感和有
35
岁焦虑，就是因为不知道。我觉得他们的能力他们的喜好想法其实挺适合做一些别的事情的，但是就是单纯不知道。因为他们看到的例子、我们在大厂里接触到例子，都是这种互联网大厂的玩法，和创业的拿融资烧钱创业的这种玩法，我觉得知道之后，可能真的是有很多可选的机会”</p>
<p>那为什么大家眼里只能看到那种高举高打的创业？因为接收到的信息有偏。我们看很多商业分析，或者是自媒体的文章，很容易产生一个错觉：就是你创业你做互联网只能做大，你不做行业第一，DAU
上亿，你不做市值十亿一百亿，你就根本下不去这个手；久而久之，我们看到的创业成功的模式似乎都是那种具备规模效应的模式，我们以为创业只有这一种模式</p>
<p>与之相反的是，也有不少人从大厂出来，选择了一个自己比较清晰(就是他知道这个事情的商业逻辑是什么样)，然后同时又有一个比较好的现金流的事情，这就是一个比较好的生意；这个生意如果从互联网视角看，好像没那么性感，但是这个生意它会让你觉得好像更踏实一些，更有积累一些</p>
<p>而本质上，<strong>创业也是做生意，只不过创业打上了一个理想主义的标签</strong>，最后你追求的还是一个能不能转起来的生意，而不是说只是把
DAU 烧起来，剩下的什么都不管了</p>
<p>下面主要摘录自刘飞在非大厂叙事里提到了几个小生意，里面有基于轻量级开发团队做的效率工具，小工具
app，也有涉及实体的二手店和淘宝店，总之就是像我们展示了更多的可能性，这里引用刘飞的一段话</p>
<blockquote>
<p>之前我们做互联网很多时候做的，我理解它更多的是<strong>效率平台，效率平台做的很多事情都是撮合</strong>，都是我把供需匹配好。然后我在这个过程中有的是用人力，有的是用运营，有的是用算法把这个效率最大化。但是现在消费市场变化了之后，会有很多垂直的领域，小众的领域大家追求的是<strong>内容产品或者内容品牌</strong>，就这些是面向垂直的用户，小众群体。</p>
<p>就比如说某些是消费品，包括刚才我提到的像 flomo，你很难说 flomo
它是一个可以对标备忘录、对标印象笔记、或者对标飞书的一个协作工具。它就是一个很小众的工具，它是做知识管理。<strong>它不是一个大众的产品，它有自己的用户群体，它自己的用户群体有非常好的复购率，这个用户群体有非常强的粘性，而且非常认同这个产品</strong>。就类似这样的产品，还有像那个多抓鱼，还有像那个三顿半，这些产品其实它们都是类似的这种属性的。就我有自己的目标用户垂直领域，然后它们有比较好的复购，然后我持续地深耕做这些用户</p>
</blockquote>
<p>下面的几个故事，会言简意赅地摘录一些笔者关注的重点，推荐去听一下原播客，也许每个人能听到的重点都不一样</p>
<h3 id="flomo">flomo</h3>
<p><a href="https://flomoapp.com/">flomo</a>
是一个快速记录想法的笔记软件，创始人是<a
href="https://m.okjike.com/originalPosts/6256b4f58a498500101ba0e1">少楠</a>和<a
href="https://web.okjike.com/u/1D8ADFAD-5785-469A-903B-E2AB5B5426C4">Lightory</a>，与其他工具简单的说明书不同，flomo
提供了一个 <a href="https://help.flomoapp.com/">flomo
101</a>，详细的讲了这个工具背后所代表的理念，其实就是在通过内容讲一个品牌故事。</p>
<p>少楠在刘飞的三五环做客了非常多次，下面的一些内容也是两人的播客里聊到的,
相关的一些播客链接也会放到最后</p>
<p><strong>为什么做 flomo</strong></p>
<p>少楠在提到离职创业时，辞去提供一大笔年薪的工作，的确会比较恐惧，尤其是上有老下有小的情况下;
但是转念一想，如果这个事情等到 40
多岁再来做，成本又会变得特别高；而相比于这个，在相当长的时间里都在用五年前或七年前的知识来解决问题让他更恐惧，因为这相当于他的知识体系不更新了，而他的知识是最值钱的东西</p>
<p>《<a
href="https://book.douban.com/subject/3025921/">黑天鹅</a>》这本书提到：“毒品，碳水化合物，月薪，是三种最有害的瘾”，<strong>月薪之所以有害，是因为无论做的好坏，月薪还是那么多，最多绩效会差一点;
长期下来，会让人有一种麻痹感和错觉，就是我不用怎么努力，更新自己的知识体系，也能持续拿到这样的薪水</strong></p>
<p>虽然做 flomo
后拿到的钱变少了，但播客里有个观点是这样的，就是“<strong>每一笔钱是不平等的</strong>”：大厂里拿到的钱，跟创业拿到的钱，即使是等额的，但是背后代表的东西是不一样的；大厂那笔钱的背后是你的交换出去的时间和价值；而创业那笔钱背后是你创造的资产，能够持续创造现金流；而如果按照创业公司
PE 来算的话，从创业拿到的工资折算回去，资产的价值还是比较高的</p>
<p>但是，我觉得大厂积累下来的经验和履历也是一种资产，虽然大厂履历带来的光环越来越暗淡,
需要警惕的是在边缘部门做一些边缘事情，积累不下任何经验</p>
<p><strong>焦虑</strong></p>
<p>收入焦虑，某种程度上也是知识焦虑，要多问下自己的知识资产是在消耗还是积累，有没有变现手段？比如说自己的知识体系是否已经非常老旧了，或者垂直性非常强，只有在某个领域或某个公司才适用</p>
<p><strong>做 flomo 的一些经验</strong></p>
<p>效率产品，背后都需要有一些被验证过有效的理念，且这些理念要传递给用户(通过内容创作构造出品牌)</p>
<p>用户增长，往往同时需要考虑 2
个方面，一是<strong>讲好品牌故事</strong>(烧钱投广告增长不可持续)，二是<strong>做好投放渠道</strong>(内容渠道和广告渠道，酒香也怕巷子深)</p>
<p>虽然 ab
实验是一种比较科学的决策方法，但是很多决策没法拿短期的数据来衡量，比如说把品牌种在更多的用户心里；打造品牌往往需要做一个长期贪婪的事情，少楠做这件事的方式就是写很多文章和内容，教用户怎么使用，甚至是改变思维方式</p>
<h3 id="谜底科技">谜底科技</h3>
<p>开发 flomo 的是一个轻量级的团队(初期只有 2
个人，现在应该也是个位数)，而<a
href="https://www.miidii.tech/">谜底科技</a>则是另一个这样的团队，创始人之一
<a
href="https://m.okjike.com/users/7A97B0F5-9674-4DD7-82AD-43E7C62B975A">61</a>
在很早就看到了很多国外的的独立开发者：一个设计师，一个开发去搭档，很多
Mac/IOS 上优秀的 App 其实都是这样一个人或两个人的作品,
那时候心里的目标就是成为一个这样的团队</p>
<p>一直想做一个中国版的 product hunt，但是效果一直不达预期；反倒是一些
site project，在数据上的表现很不错，改变了 61 只想做 big
的想法，更专注在一些 small but effective
的东西上；这个过程的关键是<strong>看数据，数据是不会骗人的，所以这个过程一定要有一套评估的系统，能直观看到数据</strong></p>
<p>两个小工具类产品，offscreen 和谜底时钟，都是打磨了一年后，随着 IOS
上线带来的小组件特性而火了起来，具有一定的运气成分，但同时也是为这次运气做了一年的默默耕耘后，才能在机会来的时候快速抓住</p>
<p>小团队做增长的一些路径：找到各种媒体上的 KOL，如果东西是好的，KOL
也是会愿意去推荐的（follower
会喜欢），同时海外市场也是一个有潜力的市场；提到了增长，在这一期的播客里也
cue
到了少楠之前的一些感悟：<strong>第一次创业关注的是体验，第二次创业关注的是增长</strong></p>
<p>flomo
和谜底科技的几款产品都有一个共同特点，就是<strong>为了控制成本，不会把事情搞得很复杂，无论是团队规模或者是产品功能</strong>；谜底科技的
App
基本都没有服务端，选型目的是想让团队比较轻量级，<strong>重运营和重服务端的都不做</strong>；即使不做这些，依然可以挑出很多有商业价值、有前景的项目，写这篇文章也发现谜底科技的另一款小工具谜底黑胶又在
app store 登顶了</p>
<p>所以，不要特别瞧不起小的东西，不一定就要做一个特别大的公司，<strong>比较好地解决垂直领域的一个问题，也只很值得去做的</strong>，比如说小宇宙；古典产品也许在慢慢回归</p>
<h3 id="山茶子">山茶子</h3>
<p>上面两个案例都是偏互联网工具类的产品，后面的两个例子则是涉及到了实体类的小生意。山茶子是<a
href="https://m.jellow.club/users/835b6850-ccf8-4f02-b6d5-74666d4d5047">牙刷味</a>做的一个茶叶小品牌，在这一期能够看到牙刷味一个人怎么把整个茶叶品牌搭起来，以及除了打工和创业以之外的第三条路</p>
<p>在牙刷味<strong>持续工作过程中，也在持续地想自己想要做什么，工作只是单纯地为了生活</strong>；决定做做茶叶时，开始做的时候也没有想得很清楚；因为有时候如果充分调研，可能就不会去做了，会觉得这个事情太大了。</p>
<p>与前面的提到的两个互联网产品不同，互联网产品的边际成本基本为
0，但是涉及到实体的生意还是存在实打实的原材料成本的，因此也需要考虑供应链，以这个茶叶生意为例，基本的供应链就是，<strong>茶叶原料
-&gt; 代加工 -&gt; 包装 -&gt; 推广 -&gt; 发货</strong></p>
<p>具体搭建茶叶品牌的流程就是先去做了竞品调研，买了市场上这个领域所有的产品，只要相同价格下品质做的更好就可以，但是利润空间会更小；原材料在杭州龙井茶村找，代加工厂在
1688
上找，但是前期规模小，不一定能找到很好的工厂；这一系列事情其实牵涉了在播客里反复被提及的浙商思维：<strong>先去做眼前的事情，尝试把眼前的事情做好</strong></p>
<p>虽然如此，实际中也存在很多不充分调研，考虑不周全而倒下的创业者，只是大家没有看到，这里面感觉还是有一定的运气成分</p>
<p>这里有一个理念跟前面的两个案例很相似，那就是也<strong>不会一开始就考虑很大的团队，除非招一个人能赚出他自己的工资</strong></p>
<p>做生意不像在公司，这家不行就换下一家，但是在公司不行，对接的研发/产品不行，很难换一个</p>
<p>谈到了更多可能性，<strong>警惕自己给自己贴标签，如果因为你比较成功地做过一些事情，其他人给你贴上了你擅长这件事的标签，不要误认为自己只能做这件事，需要接触和尝试，不一定每种可能性都要尝试，但是要从接触开始</strong></p>
<p>环境对人的影响是很大的，<strong>人的生活状态，价值观和叙事方式都是由环境塑</strong>造的，在环境里很容易被周围的人影响,
举了一个比较极端的例子：比如说这公司都快倒了。但是只要这公司里比如说公司租的楼够好，公司里面的员工大家每天还是按时上班，甚至还在加班。还是比较有昂扬斗志的。开会大家还是在
argue 加在这争来争去的。那你就会觉得这个公司好像没啥问题</p>
<p>最后，还提到了一种很有趣生活态度：<strong>把生活当做游戏，自己是主角，其他人都是
NPC</strong>；不同 NPC
可能会给你带来不同的线索，体验不同的支线任务；但是<strong>能奖励你的那个事情才是主线，找到能给你正反馈的主线和
NPC</strong></p>
<h3 id="多抓鱼">多抓鱼</h3>
<p><a
href="https://www.duozhuayu.com/book">多抓鱼</a>是一家二手书店，创始人之一<a
href="https://m.okjike.com/users/86891A68-1D76-4291-B317-83EF8BBE804F">猫助</a>在三五环也做客过，里面聊到创办多抓鱼的经历以及多抓鱼的一些基本模式</p>
<p>猫助最早想开二手店，可以追溯到大学的时候；当时没有去大厂，而是去了刚成立的知乎，因为<strong>觉得去了创业公司，至少能看到一个企业是怎么做起来的，将来就可以去做自己的企业了</strong></p>
<p>最早多抓鱼的 MVP
版本是：“我们找了一些可能有意愿卖二手书的朋友，然后说如果你想卖书你就@群主，群主会给你约快递，最后群主会单独把钱打给你。群主收到书之后会把书名写在Excel表上面，然后再发到群里说，我们今天上新了，快来挑挑都有什么你喜欢的书。这就是最早的多抓鱼”</p>
<p>选择实体店 or
线上？当前多抓鱼两个模式都有，实体店偏本地，租金贵但没有邮费，退货率也非常低，就基本没有退货了；线上是全国的匹配，调用了物流；非标的东西(没有明确规格和型号的商品)只在线下售卖，但是偏标准品的东西还是说偏线上全国消化(当前主要是书，衣服和小数码)</p>
<p>世界上很多很多的生存方式和路径，不要只看到一种路径：从 p4
到p6，p6到p8</p>
<p>c2b2c(多抓鱼)相比于c2c(闲鱼),
能够<strong>提高卖家的效率，保证买家的质量</strong>，而这两个原因也是猫助选择了多抓鱼现有的模式</p>
<p>在多抓鱼，没有什么纯粹的管理工作，上到 CEO
下到一个实习生，全都是要搬砖的</p>
<p>跳出社会预期：老耿(70后)以前是豆瓣的 VP,
对自己的预期特别低，而他就活的状态像个少年，什么事情都能做；其实也是我们常说的
ego 小的一种体现</p>
<h2 id="围城外的巨人">围城外的巨人</h2>
<p>现实中，很多事情都是一座围城，城外的人想进去，城里的人想出去</p>
<p>如果说大厂是一座围城，那上面都是围城里的人出去并且活得还不错的故事，但是城外都是毫无风险的吗？围城外是否会存在让人回想起被支配的恐惧的“巨人”？</p>
<p>当然存在，上面看到的都是成功的或者说目前公司还存在的案例，必然存在一个幸存者偏差，死掉的项目是没人关注的。而看到很多成功项目时，我们很容易幻想：这些事情自己好像也有能力做，做成也不难，却忽略了媒体报导的偏差性、人和人的差异性，以及生活的随机性，很容易会因为当前手上或烦人或无聊工作，而脑子一热冲出围城，然后就会面临着现实生活这个“巨人”的一顿毒打</p>
<p>在三五环的一期播客里也提到了这一现象：很多大厂离职出去的员工会面临着“返贫”的现象，原因是不懂得打理资产；资产最终会回流到会管理他们的人身上；而<strong>打理资产的能力，无论是上学或者上班，都没有人教我们；上学是在学教科书里的知识，上班更多学习的是专业能力和管理能力</strong></p>
<p>什么是打理资产的能力？无论是投资金融类资产，投资其他人的项目，还是创业做个小生意，大致含义就是能够看到完整的商业逻辑，看到钱从哪里来,
怎么保证现金流</p>
<p>对于普通人来说，要<strong>意识到自己在公司学习到的能力的局限性</strong>，绝大部分人都是一个可弃用的螺丝钉，对于全貌未必看得比较准确；哪怕看到了全貌，历史经验也是具备局限性的，因为很多事情会受到经济周期的影响，在经济上行时总结的经验，未必就适用于所有的时期</p>
<p>我们常常说，大学是一座象牙塔；其实大厂也算是一座象牙塔(尤其是离一线销售岗位较远的岗位)，大部分人工作中每天接触到的清一色的都是相同的人和事，不需要关注公司的现金流情况(大多数情况也没有这样的机会)，只知道广告能有收入，却不知道广告里的每个细分行业的生意是如何运转的，广告主为什么愿意花钱投广告；只知道商家的
roi&gt;1
看起来好像就是正的，却不知道刨除商品、人工、场地、营销等成本，可能就是个赔钱生意；这些东西，围城里没有人会教我们。</p>
<p>即刻上<a
href="https://m.jellow.club/users/855232d3-0779-4cef-8e25-e56288d4cf1c">刘玮冬</a>发的不少动态，能更真实地反映出一个普通生意人在实际创业时面临的问题和烦恼，能让我们更清楚看到城外巨人的狰狞面目。其中提到的一个<a
href="https://m.okjike.com/originalPosts/62d26811917bdd85e7e03e88?s=eyJ1IjoiNWM1YmZiMmU3ZjYyNTEwMDE1MTk2Mzk3IiwiZCI6MX0=&amp;utm_source=wechat_session">现象</a>，也是很多从大厂出去创业的人面临的典型问题：<strong>想通过互联网思维去改变一切，却发现成本控制不了，现金流转不起来</strong>;
其实互联网改造传统行业并没有那么容易</p>
<blockquote>
<p>做电商这几年，也见过很多“精英人士”入局做电商，可能是我段位不行，接触的都是精英人士做电商失败或者被毒打的案例。这些失败案例的步骤也比较一致</p>
<p>第一步：精英人士泛指：名牌大学海龟精英/互联网大厂精英/外企500强白领精英/有钱的用过好东西的富二代/有点审美天赋的艺术精英
第二步：锚定一个品类，可能是宠物/护肤/美妆/服装/电子产品/运动/食品/母婴产品
等等
第三步：做这些品类的产品调研，用了该品类TOP10的产品之后，发出各种吐槽：这是人吃的么？人用的么？质量那么差？这么丑的衣服是人穿的么？狗都不会用的东西........
第四步：由此认为该品类机会大有可为，认为自己进去一定能颠覆品类，成为该品类第一，并且认为自己将是国货崛起的代言人，自己有着巨大的使命，一定要让中国人都用上好东西
第五步：自诩为乔布斯化身，开始非常极致的产品开发，选最好的材料/面料/食材，各个环节都用最好的工艺，各种版本，包材，样本打了几十个版本，一次又一次推翻，跑遍了全国各种代工厂
第六步：在产品设计上罗永浩附体，字体大小，颜色，VI，排版，行间距，字间距，深浅调了几十版，学习张小龙，每一个像素都抠的非常细
第七步：半年或一年后，产品正式上线，由于产品各种选取最优质的材料，那个成本也高出天际，然后那个产品售价超出主流市场价格带一大截。
第八步：产品好是好，但因为太贵，老百姓买不起，所以销量寥寥无几，非常讽刺，目标是希望国人用上好东西，但结果国人用不起。
第九步：东西太贵，只能抓精准富裕中产精英群体，但又没有特别渠道，手段，抓不到这群用户，花钱做了很多广告，转化率极差。
第十步：找各个主播，渠道去推，主播渠道都表示东西很好，但太贵了，推不动，能不能售价降50%，咬咬牙同意了，爆了几波销量后发现卖一个亏一个，别人都说你家直播卖了好多钱，只有你知道，算上税，退货，邮费，主播分成，产品成本，你甚至还赔钱。
第十一步：销量上不去，也没法融资，公司财务开始恶化，资金不断消耗，推广费用捉襟见肘，没钱开发二代，三代产品，开始各种暴躁，骂员工，员工合伙人纷纷离职
第十二步：库存堆成山，卖不出去，各种供应商找上门来，找家里要钱/拿出工资储蓄/卖了房子之后终于把欠债还完了。
第十三步：出来逢人就总结，自己的产品非常优秀，非常好，可惜中国老百姓不识货啊！</p>
</blockquote>
<h2 id="接受焦虑享受随机性">接受焦虑，享受随机性</h2>
<p>读到这里，你会发现，长期呆在大厂里会里里外外被规训，也面临着所谓的中年危机；出去外面，面对着的是更加复杂的人和事，看到的都是成功的案例，具备较强的随机性和不可复制性，真正去做的时候可能一不小心就返贫，把过去十多年的积累一次清空。那我们能怎么办，似乎没有一个一劳永逸的方法？</p>
<p>是的，生活本来就没有一个一劳永逸的答案。在大厂可能会被裁员，难道开公司当老板，就会永远盈利不倒闭么？我们看到上面的还算成功的非大厂的各种叙事，能活多长时间，可能连创始人也没法告诉你。生活本来就是混沌的，充满随机性的，无法预测的，过分追求安稳与确定性，有时候会很痛苦。</p>
<p>《<a
href="https://wulc.me/2015/11/20/%E6%88%91%E4%BB%AC%E8%BF%99%E4%B8%80%E4%BB%A3%E4%BA%BA%E7%9A%84%E5%9B%B0%E6%83%91/">我们这一代人的困惑</a>》是这么说的</p>
<blockquote>
<p>仔细想想，我们的一生好像都是在实现目标中挣扎着度过的。上初中的时候，老师告诉你，中考的淘汰率是最高的，只要闯过去，上了高中一切就好了。但上了高中的时候发现不是那么回事嘛，高中老师又说了啊，考上大学就进了天堂。于是你考上了大学，依然空虚迷茫各种草样年华，父母老师又告诉你，找到工作就好了。工作之后发现烦恼和忧虑依然都在，女朋友给你看马云的故事，告诉你等你事业有成就好了……</p>
<p>你发现了吗，其实人这一辈子的每一个阶段都有新的痛苦和顾虑，周而复始，生生不息。绝对不会因为你考上大学，事业有成，迎娶了女神就从此
happily ever
after。但每一个阶段也有每一个阶段的快乐，无法替代。生活不是安徒生童话也不是好莱坞电影，从出生的那一刻起直到生命的尽头，都不存在什么节点，过去了之后一切幸福美满无忧无虑。</p>
</blockquote>
<p>接受人这一生都要与焦虑为伴的事实，不要与焦虑对抗、尝试解决或者抹除焦虑，也许会是更自然与平和的状态，因为
<strong>what you resist
persists</strong>，往往越抵抗，反噬可能会越严重；所以需要<strong>学会接受焦虑，学会与焦虑相处</strong>，因为很多事情，你接受了，就不会痛苦，或者说有了预期，当事情发生时就不会那么痛苦（人的快乐和痛苦往往都是来源于发生了预期以外的事情）</p>
<p>但接受焦虑，并不意味着要躺平，因为<strong>焦虑往往就是有一些需要做的事情但是没有做，那件事在你的心底大声地发出嘲讽，让你愈发恐慌</strong>；所以往往什么都不做，会让你更加焦虑，因此焦虑时合理的手段也几乎只有一种：<strong>进一步做好你当前的事（工作、学习），并选择一个“至少不是错的”的方向去努力</strong></p>
<p>对于还在大厂的人，就是好好把手上的事情做好，提升自己的能力；至于升职这类事情，能力和运气都是必要条件，我们无法左右运气，但至少在能力上，我们还是具备主观能动性的</p>
<p>而在本职工作以外，又有什么是值得我们去追求的呢？</p>
<h3 id="找到内生的信念">找到内生的信念</h3>
<p>无论是继续留在大厂或者是决定是否从大厂离开，都要想清楚，自己是为了什么去做这个事情的，或者说要找到内生的信念</p>
<p>内生的信念，指的是你真的有你想要去做的事情；这种情况下，无论你是辞职还是创业，无论结果是好还是坏，普遍感知上会更好一些；因为这种情况下<strong>收到的正向的反馈是大于你获得的外在工资</strong>的。这个正反馈可以是你在外面做内容做得好，受到读者的好评；也可以是你在外面做一个品牌，你感受的一些成就感等等</p>
<p>如果说你还没有找到这些东西，只在对比工作的状态和收到的工资的话，那确实在大厂整体肯定还是对比起来更舒适的，因为从大厂那种有一定的基建保障的环境中出来之后，会面对一个更混沌的外部系统，它资源整合调度做事的难度其实并没有比之前降低，只是对体感上你的好像自由决策，没人能管得了</p>
<p>反之，如果没找到自己喜欢做的事情，被外部诱惑从某个大厂离开的人，经常会有落差，最后的情况都不会那么好</p>
<p>因为如果你是被诱惑出来的，可能是觉得现在工作特别不开心，特别累，出来可能更开心一点；或者说外面有一个机会，这个机会给你承诺的很多，但是你没有看到这个风险。这种情况出来的话，很容易就会感觉到心力支撑不住，因为没有原来这种确定性和安全感了，在外面自己又没有特别想做的事情，那就确实会比较痛苦；所以有很多人就回去了，但是也有很多人回不去了</p>
<h3 id="差异化竞争">差异化竞争</h3>
<p>很多情况下，我们应该摆脱竞争，竞争就必然会内卷，<strong>只要你跟别人做一样的事情，就一定会产生这种消耗性的竞争</strong>。你要想办法为自己找到一个差异的点，然后去做跟别人不一样的事情。我们常说的“找到自己的那条赛道，在那条赛道上我们就是第一”，其实也是这么一回事</p>
<p>如何找到自己的赛道？对不起，这也没有一个明确的答案，但是比较明确的是，<strong>我们需要看到更多的可能性，收集足够全的信息，然后自己做判断，而不是直接收集的是别人的结论</strong>，因为个人的差异性和生活的随机性决定了适合每个人的赛道是不一样的</p>
<p>工作之余，可以尽量多地做低成本的尝试，万一哪个尝试成了，就可以比较从容地应对所谓的裁员和中年危机；以戴某demo为例，之前在业余做投资的事情，做顾问的事情已经做了好多年了，在离开公司的时候其实并不是一个很突兀的要转型，而是一个很自然的过程</p>
<p>对于更多的人来说，可行的方案之一，也许是<strong>真诚的有品质的表达</strong>，因为这是一个高效的社交活动。当你把你的思考放出来去寻求回应的时候，很多看到并与你共频的人会给你那个回响(念念不忘，必有回响),
这比你挨个自己去找人这容易的太多了，而这些表达说不定会给你吸引来更多的可能性和机会；所以我一直认为有品质的写作、播客、视频等，都是一个高效的社交</p>
<h3 id="把自己当做资产">把自己当做资产</h3>
<p>这里其实是套用了孟岩写的文章的标题：<a
href="https://zhuanlan.zhihu.com/p/511430949">把自己当作资产</a>，
里面提到了比较核心的一个概念：人力资本，简单来说，就是把人当做资产，这个资产未来会不断释放现金流；这一点在作客组织进化论的播客中也有提及</p>
<blockquote>
<p>我们把人力资本释放的现金流，不断通过金融市场，转换为金融资本。随着时间的流逝，我们的金融投资获得不错的回报，金融资本也慢慢增长成为我们总财富的主要部分。</p>
<p>年轻时，尽管我们完全没有意识到，我们可能远比自己想象的有钱。只是在这个时候，财富更多以人力资本的形式存在。</p>
<p>因为拥有相对安全的人力资本资产，这就意味着年轻人可以比年长者把更多的金融资产投资于更高风险的资产，比如股票，甚至可以包括少量的杠杆和债务。原因很简单，这时候的损失，无论是
5 % 还是
30%，尽管当下看起来很多，但在我们总资产（包含人力资本）的盘子里，实在微不足道。</p>
</blockquote>
<p>在谈工作的时候，大家很容易会把着眼点放在收入上，这无可厚非。但它带来的副作用是你过于集中在这个点上，你就会忽略你整个职业生涯里，真正应该积累的可能是<strong>视野、知识能力、品格、人脉、口碑</strong>等。你如果真正真是并积累它，钱会找到你</p>
<p>另外，无论你所在的企业如何，都要记住，企业愿意聘用你，他们花钱购买的是你的专业能力，这是一切的前提；而你把着眼点反过来放在那个纯收益上，有可能忽视了真正要积累的东西，反而不一定会有一个很好的结果，因为这样下来竞争力可能会越来越低，同时有可能失去了你自己的自我认同</p>
<p>很多大厂里的员工，其实并没有在大厂里边真正<strong>把自己当成一个产品或者一个资产去创造什么东西</strong>，更多的是把焦点盯在工资和收益上，但把焦点盯在你的经济收益和盯在创造上，你的过程和结果可能都会不一样，尤其是你的体感。而飞书建议大家写的<a
href="https://www.feishu.cn/hc/zh-CN/articles/360048137813">个人使用说明书</a>，本质上也是在建议大家把自己当做一个产品或者说资产，这里我觉得可以用《<a
href="https://www.navalmanack.com/">The Almanack of
Naval</a>》里的一句话经常反问自己</p>
<blockquote>
<p>Am I productizing it? Am I scaling it? Am I scaling with labor or
with capital or with code or with media? ### 享受随机性</p>
</blockquote>
<p>放眼互联网公司的发展或者个人的成长，我们会发现，一个绕不多去的话题就是运气，或者说生活的随机性；什么“我的成功你也能复制”，都是在扯犊子，忽略了时代的不同和生活的随机性</p>
<p>我们生活中遇到的事情基本可以分为三类，第一类基本由能力决定，比如说考试；第二类纯粹由随机性决定，比如布朗运动；第三类，也是我们最常遇到的，由能力和随机性共同决定，比如创业、投资、恋爱或是梦想。</p>
<p>我们最大的问题是，面临生活中大部分的事情时，往往会自动地归为第一类，而忽略了随机性对结果的影响。大到互联网的发展，小到一个个体去选择自己的职业生涯，其实很多都是随机性决定的；<strong>有的时候我们事后因为人性的原因，各喜欢各种归因，总是在这找原因，其实没啥可归纳的，也没什么指导意义，因为时代在变，大环境在变</strong></p>
<p>当你意识到世界很多事情都有随机性，甚至是被随机性主导的；当你深知这件事情的随机性也许永远不会青睐你，你是选择继续坚持下去，还是选择躺平呢？</p>
<p>而一个人最宝贵的财富，也许就是在做一件事情时，能够清楚地意识到随机性和运气在其中的占比，并心平气和地接受这个事实</p>
<p>需要意识到的另一个事实是：随机性会带来坏的事情，但也可能会带来好的事情，而在我们努力没达到一定程度前，我们连面对好的随机性的资格都没有，也可能会随时被坏运气冲垮；这也意味着需要做好
2 个准备</p>
<p><strong>（1）抓住好运气的能力</strong>
<strong>（2）对冲坏运气带来的风险</strong></p>
<p>抓住好运气的能力，意味着我们要不断地提高自己的各项能力，即使现阶段不能给你带来即刻的回报；比如说现在要提拔你，你觉得你的管理能力是否能够
hold
住现有的团队？你的专业能力是否能带领整个团队攻克当前遇到的问题？比如说
web3
现在如火如荼，这里面是否真的有好的项目，你是否有能力去分辨其中各个项目的价值，而不是去当绿油油的韭菜？</p>
<p>对冲坏运气的能力，意味着我们要能够尽量识别出未来可能发生的风险，比如说工作上的风险，身体健康的风险，经济上的风险等发生时，你有做好兜底的方案吗？</p>
<p>面对随机性，有时候会让人绝望，因为即使你做了准备，对最终的结果可能也是毫无意义的；但面对随机性，我们唯一能做的也是好好地<strong>活在当下</strong>(虽然被说烂了，但的确是真理)，放下一些不必要的执念和无意义的比较，与身边的人愉快相处，认真安排好每一天的活动，用心去感受每一天的心境</p>
<p>因为一直瞻前顾后，容易陷入对过去的后悔和对未来的担忧中，这种焦虑带来的是所有非工作状态的生活都被填满；尤其当你做的是一个寻求机会的事情时，准确地规划是很难的，当你试图用理性来假设和分析时，很多时候回过头再看，这些假设跟真实的差异会很大，但这样的分析往往会令人陷入悲观主义，因为往往假设会越做越谨慎，似乎一定要万无一失才能开始行动</p>
<p><strong>既然随机性不可避免，而过分追求确定性可能会让我们瞻前顾后、步步惊心，还不如学着接受并享受生活的随机性；既然预定要飞向意大利的航班，最终有可能让你降落在荷兰，还不如好好享受荷兰的风光，对自己说一句：<a
href="https://zhuanlan.zhihu.com/p/435160088">欢迎来到荷兰</a></strong></p>
<p>最后，借用《<a
href="https://book.douban.com/subject/5366382/">夜航西飞</a>》里的一段话来回答开头的问题，虽然前方的
35 岁路口被迷雾遮挡，但是相信走进去，就会云开雾散~</p>
<blockquote>
<p>我学会了如果你必须离开一个地方，一个你曾经住过、爱过、深埋着你所有过往的地方，无论以何种方式离开，都不要慢慢离开，要尽你所能决绝地离开，永远不要回头，也永远不要相信过去的时光才是更好的，因为它们已经消亡。过去的岁月看来安全无害，被轻易跨越，而未来藏在迷雾之中，隔着距离，叫人看来胆怯。但当你踏足其中，就会云开雾散。我学会了这一点，但就像所有人一样，待到学会，为时太晚</p>
</blockquote>
<hr />
<p>文中相关的一些播客</p>
<p><a
href="https://www.xiaoyuzhoufm.com/episode/6267c0d7bf39836fd02b7718">大厂裁员的原因、方案和连锁反应</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/629c936ad02ea2b34ca8868e">离开大厂的中年人，何去何从</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/60f51c310023d1e387ddac77">跟少楠聊聊大厂和创业，以及如今的独立开发者生活</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/61af575182cdf82712002fb7">跟少楠聊聊做
flomo 的新体会，以及什么是 indie</a> <a
href="https://www.xiaoyuzhoufm.com/episode/61f0165d21c23a45ed5d65e5">跟
61 聊聊他曲折又坦然的创业故事</a> <a
href="https://www.xiaoyuzhoufm.com/episode/619e0da61adca419b5f8f2a5">跟牙刷味聊聊打工和创业之外的第三条路</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/5f15bf9b6d76607427c80341">跟多抓鱼的猫助聊聊二手生意和创业态度</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/6268efd6bf39836fd02b778a">跟浩翔聊聊离开大厂的「返贫」现象和背后的思考</a>
<a
href="https://afdian.net/p/a270675253ac11eb90c452540025c377">识别运气，并享受生活的随机性</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/61b87b96c308e3900b9bdc02">愿我们都做一条脱钩的鱼</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/628d64070e30c626186839c2">孟岩：最好的投资，是投资自己</a></p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>以太网中的MTU与MSS</title>
    <url>/2015/12/08/%E4%BB%A5%E5%A4%AA%E7%BD%91%E4%B8%AD%E7%9A%84MTU%E4%B8%8EMSS/</url>
    <content><![CDATA[<p>以太网（Ethernet）最大的数据帧是1518字节。以太网帧的帧头的14字节和帧尾CRC校验4字节共占了18字节，剩下的<strong>承载上层协议的地方也就是Data域最大就只剩1500字节.这个值我们就把它称之为MTU</strong>。MTU的全称是maximum
transmission
unit（最大传输单元）。<strong>MTU可以认为是网络层能够传输的最大IP包。</strong></p>
<span id="more"></span>
<p><strong>而MSS（Maximum segment
size）可以认为是传输层的概念，也就是TCP数据包每次能够传输的最大量</strong>。为了达到最佳的传输效能，TCP协议在建立连接的时候通常要协商双方的MSS值，这个值TCP协议在实现的时候往往用MTU值代替（需要减去IP数据包包头的大小20Bytes和TCP数据段的包头20Bytes）所以<strong>往往MSS为1460</strong>。通讯双方会根据双方提供的MSS值得最小值确定为这次连接的最大MSS值。
　　
MSS为1460是由1500-20（IP头）-20（TCP头）计算出的。但是在实际场景下，TCP包头中会带有12字节的选项--时间戳（用户在发送每一个TCP报文的时候都放置一个时间戳，接受方在确认中返回这个时间戳值。<strong>发送方就可以根据这个时间戳来计算RTT</strong>（往返传输时间--发送端从发送TCP包开始到接收到它的立即响应所耗费的传输时间.）。从而使得RTT更加精确，减少不必要的重传。减低网络的负载。)
　　
这样，单个TCP包实际传输的最大量就缩减为1448字节。1448=1500-20（IP头）-32（20字节TCP头和12字节TCP选项时间戳）。</p>
<p><strong>问题来了：“每个TCP包在理论上应该能打包更多数据才对，但是实际场景下TCP传输为什么会以这个1448作为打包单位呢？”</strong></p>
<p>理论上，<strong>单个TCP包能打包的数据量远远多于1448字节，现在为了适应MTU，只要在以太网上跑TCP，系统就默认最大以1448字节打包TCP。</strong>
　　 <strong>假如我们用更大的数据量来打包会有什么结果呢？
答案是降低了传输效率。</strong></p>
<p>超过MTU的大包反而降低效率的原因如下：</p>
<p><strong>IP层非常关心MTU，因为IP层会根据MTU来决定是否把上层传下来的数据进行分片。</strong>就像一条运输线路的承载能力是有限的，碰到大东西要运输，只能把大东西拆开成为散件，分开运输，到达目的地之后还必须能再次组装起来。</p>
<p>当两台远程PC互联的时候，它们的数据需要穿过很多的路由器和各种各样的网络媒介才能到达对端，网络中不同媒介的MTU各不相同，就好比一长段的水管，由不同粗细的水管组成（MTU不同
:)）通过这段水管最大水量就要由中间最细的水管决定。
对于网络层的上层协议而言（我们以TCP/IP协议族为例）它们对水管粗细不在意，它们认为这个是网络层的事情。网络层IP协议会检查每个从上层协议下来的数据包的大小，并根据本机MTU的大小决定是否作“分片”处理。分片最大的坏处就是降低了传输性能，本来一次可以搞定的事情，分成多次搞定，所以在网络层更高一层（就是传输层）的实现中往往会对此加以注意！</p>
<p>这个就是在以太网上，TCP不发大包，反而发送1448小包的原因。只要这个值TCP才能对链路进行效能最高的利用。</p>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Screen管理Linux远程会话</title>
    <url>/2015/12/10/%E4%BD%BF%E7%94%A8Screen%E7%AE%A1%E7%90%86Linux%E8%BF%9C%E7%A8%8B%E4%BC%9A%E8%AF%9D/</url>
    <content><![CDATA[<p>通过 SSH 或者 telent 远程登录到
Linux服务器执行一些长时间运行的任务，比如系统备份、ftp
传输等等。因为他们执行的时间太长了。必须等待它执行完毕，在此期间可不能关掉窗口或者断开连接，否则这个任务就会被杀掉，一切半途而废了。
本文分析了这个问题的原因以及解决方法。 <span id="more"></span></p>
<h2
id="为什么关掉窗口断开连接会使得正在运行的程序死掉">为什么关掉窗口/断开连接会使得正在运行的程序死掉？</h2>
<p><strong>元凶：SIGHUP 信号</strong>
在Linux/Unix中，有这样几个概念：</p>
<ul>
<li><p><strong>进程组（process
group）</strong>：一个或多个进程的集合，每一个进程组有唯一一个<strong>进程组ID</strong>，即<strong>组长进程的ID</strong>。</p></li>
<li><p><strong>会话（session）</strong>：一个或多个进程组的集合，开始于用户登录，终止与用户退出，此期间所有进程都属于这个会话。一个会话一般包含一个<strong>会话首进程、一个前台进程组和一个后台进程组</strong>。</p></li>
<li><p><strong>守护进程（daemon）</strong>：Linux大多数服务都是通过守护进程实现的，完成许多系统任务如0号进程为调度进程，是内核一部分；1号进程为init进程,负责内核启动后启动Linux系统。守护进程不因为用户、终端或者其他的变化而受到影响。</p></li>
</ul>
<p>当<strong>终端接口检测到网络连接断开，将挂断信号（SIGHUP）发送给控制进程（会话期首进程）</strong>。而挂断信号默认的动作是终止程序。如果会话期首进程终止，则该信号发送到<strong>该会话期前台进程组</strong>。</p>
<p>也就是说：ssh打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有<strong>前台进程</strong>杀掉。（<strong>后台进程和守护进程不会被关闭</strong>！！！）
　　 ## 测试案例 ### 测试例一
打开两个SSH终端窗口，在其中一个运行了一个循环打印的python脚本。执行命令如下：
<code>[root@localhost ~]# python test.py</code>
<code>test.py</code>内容如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while True:</span><br><span class="line">    print &quot;hehe&quot;</span><br></pre></td></tr></table></figure>
另外一个终端用<code>pstree -p</code>查看当前的进程树。显示如下
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# pstree -p</span><br><span class="line">（省略）</span><br><span class="line">├─sshd(958)─┬─sshd(1282)───bash(1286)───pstree(1436)</span><br><span class="line">│           └─sshd(1410)───bash(1414)───python(1433)</span><br></pre></td></tr></table></figure>
可以看到2个bash进程代表了2个终端，pstree是当前进程正在运行的程序，而python进程则是另外一个终端正在运行的程序。</p>
<p>关掉启动python的终端，在刚刚执行pstree的终端上查找pid为1433的进程（也就是原来的python进程），发现没有这个pid的进程，说明python随着终端的关闭而终止了，此时输入<code>pstree -p</code>变为了下面这样：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# pstree -p</span><br><span class="line">（省略）</span><br><span class="line">├─sshd(958)──sshd(1282)───bash(1286)───pstree(1436)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="测试例二">测试例二</h3>
<p>步骤同例一，只是在执行python脚本时将其放到后台执行，执行命令如下：
<code>[root@localhost ~]# python test.py &amp;</code>
这样在关闭执行python的中断后，<strong>python进程并没有被中断</strong>，通过<code>pstree -p</code>查看到进程数类似于下面的情况：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(省略)</span><br><span class="line">├─python(1493)</span><br><span class="line">├─sshd(958)───sshd(1282)───bash(1286)───pstree(1497)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
因为python执行的是个后台进程，而SIGHup信号只会发送给前台进程组，当父进程结束后，其原来子进程中的后台进程会成为孤儿进程被init进程收养。详见<a
href="http://wulc.me/2015/12/05/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/">孤儿进程和僵尸进程</a></p>
<p>注：网上一些资料显示执行某些复杂程序的时候，只加<code>&amp;</code>也会终止，但是博主还没遇到过这种情况，因为我不会这样去执行一个执行时间较长的程序。</p>
<p>同样,nohup命令可以达到这个目的，值得注意的是nohup命令只是使得程序忽略SIGHUP信号，还需要使用标记&amp;把它放在后台运行。这种情况能够保证程序不会被终止。
<code>nohup &lt;command&gt; [argument…] &amp;</code></p>
<h2 id="使用screen管理远程会话">使用screen管理远程会话</h2>
<p>虽然nohup和后台进程很容易使用，但还是比较“简陋”的，对于简单的命令能够应付过来，对于复杂的需要人机交互的任务就麻烦了。</p>
<p>其实我们可以使用一个更为强大的实用程序screen。</p>
<p>简单来说，Screen是一个可以在多个进程之间多路复用一个<strong>物理终端</strong>的窗口管理器。Screen中有会话的概念，用户可以在一个screen会话中创建多个screen窗口。</p>
<h3 id="创建新的会话">创建新的会话</h3>
<p>在screen中创建一个新的会话有2种方式</p>
<p><strong>1．直接在命令行键入screen命令</strong>
<code>[root@localhost ~]# screen</code>
Screen将创建一个执行shell的全屏窗口。你可以执行任意shell程序，就像在ssh窗口中那样。在该窗口中键入exit退出该窗口，如果这是该screen会话的唯一窗口，该screen会话退出，否则screen自动切换到前一个窗口。
也可通过<code>screen -S name</code> 来为启动的session取名字。
<strong>2．Screen命令后跟你要执行的程序</strong> [root@localhost ~]#
python test.py Screen创建一个执行python
test.py的单窗口会话，终止进程将退出该窗口/会话。</p>
<h3 id="进入已创建会话">进入已创建会话</h3>
<p>即使关闭了启动所有终端，在screen会话中启动的进程也不会终止，再次连接时可通过<code>screen -ls</code>查看已经启动的screen会话(detached状态)，用<code>screen -r name</code>恢复指定会话，也可在会话中通过exit退出screen会话。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# screen -ls</span><br><span class="line">There is a screen on:</span><br><span class="line">	1518.lc	(Detached)</span><br><span class="line">1 Socket in /var/run/screen/S-root.</span><br><span class="line">重新连接会话</span><br><span class="line">[root@localhost ~]# screen -r lc或screen -r 1518</span><br><span class="line">退出当前screen会话</span><br><span class="line">[root@localhost ~]#exit</span><br></pre></td></tr></table></figure></p>
<h3 id="screen的一些常用参数如下所示">screen的一些常用参数如下所示</h3>
<ul>
<li><strong>分享操作</strong></li>
</ul>
<p><code>screen -x name</code>进入一个还在连接着（attached）的screen，然后所有操作能够被另外所有正在连着的screen看到</p>
<ul>
<li><strong>分屏</strong></li>
<li>创建一个新的窗口：ctrl+a+S
（注意是大写的s）,此时新的窗口还没启动bash</li>
<li>启动新窗口的bash：ctrl+a+c</li>
<li>切换窗口：ctrl+a+tab</li>
<li>关掉当前窗口:ctrl+a+X（注意是大写的x）</li>
</ul>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>使用sklearn优雅地进行数据挖掘</title>
    <url>/2017/01/16/%E4%BD%BF%E7%94%A8sklearn%E4%BC%98%E9%9B%85%E5%9C%B0%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</url>
    <content><![CDATA[<p>本文转载自 http://www.cnblogs.com/jasonfreak/p/5448462.html，
主要讲述如何通过 sklearn 完成数据挖掘中的一个完整的流程。</p>
<span id="more"></span>
<h2 id="数据挖掘的步骤">数据挖掘的步骤</h2>
<p>数据挖掘通常包括数据采集，数据分析，特征工程，训练模型，模型评估等步骤。使用sklearn工具可以方便地进行特征工程和模型训练工作，在《使用sklearn做单机特征工程》中，我们最后留下了一些疑问：特征处理类都有三个方法
<code>fit</code>、<code>transform</code>和<code>fit_transform</code>，而
fit 方法居然和模型训练方法 fit
同名（不光同名，参数列表都一样），这难道都是巧合？</p>
<p>显然，这不是巧合，这正是sklearn的设计风格。我们能够更加优雅地使用sklearn进行特征工程和模型训练工作。此时，不妨从一个基本的数据挖掘场景入手：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b9cq73pg19f71ajf2e41u8r1d5n9.png"
alt="基本数据挖掘场景" />
<figcaption aria-hidden="true">基本数据挖掘场景</figcaption>
</figure>
<p>我们使用 sklearn
进行虚线框内的工作（sklearn也可以进行文本特征提取）。通过分析 sklearn
源码，我们可以看到除训练，预测和评估以外，处理其他工作的类都实现了3个方法：<code>fit</code>、<code>transform</code>和<code>fit_transform</code>。<strong>从命名中可以看到，<code>fit_transform</code>方法是先调用<code>fit</code>然后调用<code>transform</code>，我们只需要关注
fit 方法和 transform 方法即可。</strong></p>
<p><code>transform</code>
方法主要用来对特征进行转换。<strong>从可利用信息的角度来说，转换分为无信息转换和有信息转换。无信息转换是指不利用任何其他信息进行转换，比如指数、对数函数转换等。有信息转换从是否利用目标值向量又可分为无监督转换和有监督转换。无监督转换指只利用特征的统计信息的转换，统计信息包括均值、标准差、边界等等，比如标准化、PCA法降维等。有监督转换指既利用了特征信息又利用了目标值信息的转换，比如通过模型选择特征、LDA法降维等</strong>。通过总结常用的转换类，我们得到下表：</p>
<table style="width:100%;">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="header">
<th>包</th>
<th>类</th>
<th>参数列表</th>
<th>类别</th>
<th>fit方法有用</th>
<th>说明</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>sklearn.preprocessing</td>
<td>StandardScaler</td>
<td>特征</td>
<td>无监督</td>
<td>Y</td>
<td>标准化</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.preprocessing</td>
<td>MinMaxScaler</td>
<td>特征</td>
<td>无监督</td>
<td>Y</td>
<td>区间缩放</td>
<td></td>
</tr>
<tr class="odd">
<td>sklearn.preprocessing</td>
<td>Binarizer</td>
<td>特征</td>
<td>无信息</td>
<td>N</td>
<td>定量特征二值化</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.preprocessing</td>
<td>OneHotEncoder</td>
<td>特征</td>
<td>无监督</td>
<td>Y</td>
<td>定性特征编码</td>
<td></td>
</tr>
<tr class="odd">
<td>sklearn.preprocessing</td>
<td>Imputer</td>
<td>特征</td>
<td>无监督</td>
<td>Y</td>
<td>缺失值计算</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.preprocessing</td>
<td>PolynomialFeatures</td>
<td>特征</td>
<td>无信息</td>
<td>N</td>
<td>多项式变换（fit方法仅仅生成了多项式的表达式）</td>
<td></td>
</tr>
<tr class="odd">
<td>sklearn.preprocessing</td>
<td>FunctionTransformer</td>
<td>特征</td>
<td>无信息</td>
<td>N</td>
<td>自定义函数变换（自定义函数在transform方法中调用）</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.feature_selection</td>
<td>VarianceThreshold</td>
<td>特征</td>
<td>无监督</td>
<td>Y</td>
<td>方差选择法</td>
<td></td>
</tr>
<tr class="odd">
<td>sklearn.feature_selection</td>
<td>SelectKBest</td>
<td>特征/特征+目标值</td>
<td>无监督/有监督</td>
<td>Y</td>
<td>自定义特征评分选择法</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.feature_selection</td>
<td>SelectKBest+chi2</td>
<td>特征+目标值</td>
<td>有监督</td>
<td>Y</td>
<td>卡方检验选择法</td>
<td></td>
</tr>
<tr class="odd">
<td>sklearn.feature_selection</td>
<td>RFE</td>
<td>特征+目标值</td>
<td>有监督</td>
<td>Y</td>
<td>递归特征消除法</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.feature_selection</td>
<td>SelectFromModel</td>
<td>特征+目标值</td>
<td>有监督</td>
<td>Y</td>
<td>自定义模型训练选择法</td>
<td></td>
</tr>
<tr class="odd">
<td>sklearn.decomposition</td>
<td>PCA</td>
<td>特征</td>
<td>无监督</td>
<td>Y</td>
<td>PCA降维</td>
<td></td>
</tr>
<tr class="even">
<td>sklearn.lda</td>
<td>LDA</td>
<td>特征+目标值</td>
<td>有监督</td>
<td>Y</td>
<td>LDA降维</td>
<td></td>
</tr>
</tbody>
</table>
<p>不难看到，<strong>只有有信息的转换类的<code>fit</code>方法才实际有用，显然<code>fit</code>方法的主要工作是获取特征信息和目标值信息</strong>，在这点上，<code>fit</code>方法和模型训练时的<code>fit</code>方法就能够联系在一起了：<strong>都是通过分析特征和目标值，提取有价值的信息</strong>，对于转换类来说是某些统计量，对于模型来说可能是特征的权值系数等。另外，<strong>只有有监督的转换类的fit和transform方法才需要特征和目标值两个参数</strong>。fit方法无用不代表其没实现，而是除合法性校验以外，其并没有对特征和目标值进行任何处理，<code>Normalizer</code>的<code>fit</code>方法实现如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Do nothing and return the estimator unchanged</span></span><br><span class="line"><span class="string">        This method is just there to implement the usual API and hence</span></span><br><span class="line"><span class="string">        work in pipelines.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        X = check_array(X, accept_sparse=<span class="string">&#x27;csr&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure>
<p>基于这些特征处理工作都有共同的方法，那么试想可不可以将他们组合在一起？在本文假设的场景中，我们可以看到这些工作的组合形式有两种：流水线式和并行式。基于流水线组合的工作需要依次进行，前一个工作的输出是后一个工作的输入；基于并行式的工作可以同时进行，其使用同样的输入，所有工作完成后将各自的输出合并之后输出。sklearn提供了包<code>pipeline</code>来完成流水线式和并行式的工作。</p>
<h2 id="数据初貌">数据初貌</h2>
<p>在此，我们仍然使用IRIS数据集来进行说明。为了适应提出的场景，对原数据集需要稍微加工：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> hstack, vstack, array, median, nan</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> choice</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment">#特征矩阵加工</span></span><br><span class="line"><span class="comment">#使用vstack增加一行含缺失值的样本(nan, nan, nan, nan)</span></span><br><span class="line"><span class="comment">#使用hstack增加一列表示花的颜色（0-白、1-黄、2-红），花的颜色是随机的，意味着颜色并不影响花的分类</span></span><br><span class="line">iris.data = hstack((choice([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], size=iris.data.shape[<span class="number">0</span>]+<span class="number">1</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>), vstack((iris.data, array([nan, nan, nan, nan]).reshape(<span class="number">1</span>,-<span class="number">1</span>)))))</span><br><span class="line"><span class="comment">#目标值向量加工</span></span><br><span class="line"><span class="comment">#增加一个目标值，对应含缺失值的样本，值为众数</span></span><br><span class="line">iris.target = hstack((iris.target, array([median(iris.target)])))</span><br></pre></td></tr></table></figure>
<h2 id="关键技术">关键技术</h2>
<p><strong>并行处理，流水线处理，自动化调参，持久化是使用sklearn优雅地进行数据挖掘的核心</strong>。并行处理和流水线处理将多个特征处理工作，甚至包括模型训练工作组合成一个工作（从代码的角度来说，即将多个对象组合成了一个对象）。在组合的前提下，自动化调参技术帮我们省去了人工调参的反锁。训练好的模型是贮存在内存中的数据，持久化能够将这些数据保存在文件系统中，之后使用时无需再进行训练，直接从文件系统中加载即可。</p>
<h3 id="并行技术">并行技术</h3>
<p>并行处理使得多个特征处理工作能够并行地进行。根据对特征矩阵的读取方式不同，可分为整体并行处理和部分并行处理。整体并行处理，即并行处理的每个工作的输入都是特征矩阵的整体；部分并行处理，即可定义每个工作需要输入的特征矩阵的列。
#### 整体并行处理
<code>pipeline</code>包提供了<code>FeatureUnion</code>类来进行整体并行处理：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建将整体特征矩阵进行对数函数转换的对象</span></span><br><span class="line">step2_1 = (<span class="string">&#x27;ToLog&#x27;</span>, FunctionTransformer(log1p))</span><br><span class="line"><span class="comment">#新建将整体特征矩阵进行二值化类的对象</span></span><br><span class="line">step2_2 = (<span class="string">&#x27;ToBinary&#x27;</span>, Binarizer())</span><br><span class="line"><span class="comment">#新建整体并行处理对象</span></span><br><span class="line"><span class="comment">#该对象也有fit和transform方法，fit和transform方法均是并行地调用需要并行处理的对象的fit和transform方法</span></span><br><span class="line"><span class="comment">#参数transformer_list为需要并行处理的对象列表，该列表为二元组列表，第一元为对象的名称，第二元为对象</span></span><br><span class="line">step2 = (<span class="string">&#x27;FeatureUnion&#x27;</span>, FeatureUnion(transformer_list=[step2_1, step2_2, step2_3]))</span><br></pre></td></tr></table></figure></p>
<h4 id="部分并行处理">部分并行处理</h4>
<p>整体并行处理有其缺陷，在一些场景下，我们只需要对特征矩阵的某些列进行转换，而不是所有列。<code>pipeline</code>并没有提供相应的类（仅<code>OneHotEncoder</code>类实现了该功能），需要我们在<code>FeatureUnion</code>的基础上进行优化：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion, _fit_one_transformer, _fit_transform_one, _transform_one </span><br><span class="line"><span class="keyword">from</span> sklearn.externals.joblib <span class="keyword">import</span> Parallel, delayed</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#部分并行处理，继承FeatureUnion</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeatureUnionExt</span>(<span class="title class_ inherited__">FeatureUnion</span>):</span><br><span class="line">    <span class="comment">#相比FeatureUnion，多了idx_list参数，其表示每个并行工作需要读取的特征矩阵的列</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, transformer_list, idx_list, n_jobs=<span class="number">1</span>, transformer_weights=<span class="literal">None</span></span>):</span><br><span class="line">        self.idx_list = idx_list</span><br><span class="line">        FeatureUnion.__init__(self, transformer_list=<span class="built_in">map</span>(<span class="keyword">lambda</span> trans:(trans[<span class="number">0</span>], trans[<span class="number">1</span>]), transformer_list), n_jobs=n_jobs, transformer_weights=transformer_weights)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#由于只部分读取特征矩阵，方法fit需要重构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span><br><span class="line">        transformer_idx_list = <span class="built_in">map</span>(<span class="keyword">lambda</span> trans, idx:(trans[<span class="number">0</span>], trans[<span class="number">1</span>], idx), self.transformer_list, self.idx_list)</span><br><span class="line">        transformers = Parallel(n_jobs=self.n_jobs)(</span><br><span class="line">            <span class="comment">#从特征矩阵中提取部分输入fit方法</span></span><br><span class="line">            delayed(_fit_one_transformer)(trans, X[:,idx], y)</span><br><span class="line">            <span class="keyword">for</span> name, trans, idx <span class="keyword">in</span> transformer_idx_list)</span><br><span class="line">        self._update_transformer_list(transformers)</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="comment">#由于只部分读取特征矩阵，方法fit_transform需要重构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self, X, y=<span class="literal">None</span>, **fit_params</span>):</span><br><span class="line">        transformer_idx_list = <span class="built_in">map</span>(<span class="keyword">lambda</span> trans, idx:(trans[<span class="number">0</span>], trans[<span class="number">1</span>], idx), self.transformer_list, self.idx_list)</span><br><span class="line">        result = Parallel(n_jobs=self.n_jobs)(</span><br><span class="line">            <span class="comment">#从特征矩阵中提取部分输入fit_transform方法</span></span><br><span class="line">            delayed(_fit_transform_one)(trans, name, X[:,idx], y,</span><br><span class="line">                                        self.transformer_weights, **fit_params)</span><br><span class="line">            <span class="keyword">for</span> name, trans, idx <span class="keyword">in</span> transformer_idx_list)</span><br><span class="line"></span><br><span class="line">        Xs, transformers = <span class="built_in">zip</span>(*result)</span><br><span class="line">        self._update_transformer_list(transformers)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">any</span>(sparse.issparse(f) <span class="keyword">for</span> f <span class="keyword">in</span> Xs):</span><br><span class="line">            Xs = sparse.hstack(Xs).tocsr()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            Xs = np.hstack(Xs)</span><br><span class="line">        <span class="keyword">return</span> Xs</span><br><span class="line"></span><br><span class="line">    <span class="comment">#由于只部分读取特征矩阵，方法transform需要重构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line">        transformer_idx_list = <span class="built_in">map</span>(<span class="keyword">lambda</span> trans, idx:(trans[<span class="number">0</span>], trans[<span class="number">1</span>], idx), self.transformer_list, self.idx_list)</span><br><span class="line">        Xs = Parallel(n_jobs=self.n_jobs)(</span><br><span class="line">            <span class="comment">#从特征矩阵中提取部分输入transform方法</span></span><br><span class="line">            delayed(_transform_one)(trans, name, X[:,idx], self.transformer_weights)</span><br><span class="line">            <span class="keyword">for</span> name, trans, idx <span class="keyword">in</span> transformer_idx_list)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">any</span>(sparse.issparse(f) <span class="keyword">for</span> f <span class="keyword">in</span> Xs):</span><br><span class="line">            Xs = sparse.hstack(Xs).tocsr()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            Xs = np.hstack(Xs)</span><br><span class="line">        <span class="keyword">return</span> Xs</span><br></pre></td></tr></table></figure>
<p>在本文提出的场景中，我们对特征矩阵的第1列（花的颜色）进行定性特征编码，对第2、3、4列进行对数函数转换，对第5列进行定量特征二值化处理。使用<code>FeatureUnionExt</code>类进行部分并行处理的代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建将部分特征矩阵进行定性特征编码的对象</span></span><br><span class="line">step2_1 = (<span class="string">&#x27;OneHotEncoder&#x27;</span>, OneHotEncoder(sparse=<span class="literal">False</span>))</span><br><span class="line"><span class="comment">#新建将部分特征矩阵进行对数函数转换的对象</span></span><br><span class="line">step2_2 = (<span class="string">&#x27;ToLog&#x27;</span>, FunctionTransformer(log1p))</span><br><span class="line"><span class="comment">#新建将部分特征矩阵进行二值化类的对象</span></span><br><span class="line">step2_3 = (<span class="string">&#x27;ToBinary&#x27;</span>, Binarizer())</span><br><span class="line"><span class="comment">#新建部分并行处理对象</span></span><br><span class="line"><span class="comment">#参数transformer_list为需要并行处理的对象列表，该列表为二元组列表，第一元为对象的名称，第二元为对象</span></span><br><span class="line"><span class="comment">#参数idx_list为相应的需要读取的特征矩阵的列</span></span><br><span class="line">step2 = (<span class="string">&#x27;FeatureUnionExt&#x27;</span>, FeatureUnionExt(transformer_list=[step2_1, step2_2, step2_3], idx_list=[[<span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>]]))</span><br></pre></td></tr></table></figure></p>
<h3 id="流水线处理">流水线处理</h3>
<p><code>pipeline</code>包提供了<code>Pipeline</code>类来进行流水线处理。流水线上除最后一个工作以外，其他都要执行<code>fit_transform</code>方法，且上一个工作输出作为下一个工作的输入。最后一个工作必须实现fit方法，输入为上一个工作的输出；但是不限定一定有<code>transform</code>方法，因为流水线的最后一个工作可能是训练！</p>
<p>根据本文提出的场景，结合并行处理，构建完整的流水线的代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建计算缺失值的对象</span></span><br><span class="line">step1 = (<span class="string">&#x27;Imputer&#x27;</span>, Imputer())</span><br><span class="line"><span class="comment">#新建将部分特征矩阵进行定性特征编码的对象</span></span><br><span class="line">step2_1 = (<span class="string">&#x27;OneHotEncoder&#x27;</span>, OneHotEncoder(sparse=<span class="literal">False</span>))</span><br><span class="line"><span class="comment">#新建将部分特征矩阵进行对数函数转换的对象</span></span><br><span class="line">step2_2 = (<span class="string">&#x27;ToLog&#x27;</span>, FunctionTransformer(log1p))</span><br><span class="line"><span class="comment">#新建将部分特征矩阵进行二值化类的对象</span></span><br><span class="line">step2_3 = (<span class="string">&#x27;ToBinary&#x27;</span>, Binarizer())</span><br><span class="line"><span class="comment">#新建部分并行处理对象，返回值为每个并行工作的输出的合并</span></span><br><span class="line">step2 = (<span class="string">&#x27;FeatureUnionExt&#x27;</span>, FeatureUnionExt(transformer_list=[step2_1, step2_2, step2_3], idx_list=[[<span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>]]))</span><br><span class="line"><span class="comment">#新建无量纲化对象</span></span><br><span class="line">step3 = (<span class="string">&#x27;MinMaxScaler&#x27;</span>, MinMaxScaler())</span><br><span class="line"><span class="comment">#新建卡方校验选择特征的对象</span></span><br><span class="line">step4 = (<span class="string">&#x27;SelectKBest&#x27;</span>, SelectKBest(chi2, k=<span class="number">3</span>))</span><br><span class="line"><span class="comment">#新建PCA降维的对象</span></span><br><span class="line">step5 = (<span class="string">&#x27;PCA&#x27;</span>, PCA(n_components=<span class="number">2</span>))</span><br><span class="line"><span class="comment">#新建逻辑回归的对象，其为待训练的模型作为流水线的最后一步</span></span><br><span class="line">step6 = (<span class="string">&#x27;LogisticRegression&#x27;</span>, LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>))</span><br><span class="line"><span class="comment">#新建流水线处理对象</span></span><br><span class="line"><span class="comment">#参数steps为需要流水线处理的对象列表，该列表为二元组列表，第一元为对象的名称，第二元为对象</span></span><br><span class="line">pipeline = Pipeline(steps=[step1, step2, step3, step4, step5, step6])</span><br></pre></td></tr></table></figure></p>
<h3 id="自动化调参">自动化调参</h3>
<p><strong>网格搜索为自动化调参的常见技术之一</strong>，<code>grid_search</code>包提供了自动化调参的工具，包括<code>GridSearchCV</code>类。对组合好的对象进行训练以及调参的代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建网格搜索对象</span></span><br><span class="line"><span class="comment">#第一参数为待训练的模型</span></span><br><span class="line"> <span class="comment">#param_grid为待调参数组成的网格，字典格式，键为参数名称（格式“对象名称__子对象名称__参数名称”），值为可取的参数值列表</span></span><br><span class="line"> grid_search = GridSearchCV(pipeline, param_grid=&#123;<span class="string">&#x27;FeatureUnionExt__ToBinary__threshold&#x27;</span>:[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>], <span class="string">&#x27;LogisticRegression__C&#x27;</span>:[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.8</span>]&#125;)</span><br><span class="line"><span class="comment">#训练以及调参</span></span><br><span class="line">grid_search.fit(iris.data, iris.target)</span><br></pre></td></tr></table></figure></p>
<h3 id="持久化">持久化</h3>
<p><code>externals.joblib</code>包提供了<code>dump</code>和<code>load</code>方法来持久化和加载内存数据：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#持久化数据</span></span><br><span class="line"><span class="comment">#第一个参数为内存中的对象</span></span><br><span class="line"><span class="comment">#第二个参数为保存在文件系统中的名称</span></span><br><span class="line"><span class="comment">#第三个参数为压缩级别，0为不压缩，3为合适的压缩级别</span></span><br><span class="line">dump(grid_search, <span class="string">&#x27;grid_search.dmp&#x27;</span>, compress=<span class="number">3</span>)</span><br><span class="line"><span class="comment">#从文件系统中加载数据到内存中</span></span><br><span class="line">grid_search = load(<span class="string">&#x27;grid_search.dmp&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="小结">小结</h3>
<table>
<thead>
<tr class="header">
<th>包</th>
<th>类或方法</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>sklearn.pipeline</td>
<td>Pipeline</td>
<td>流水线处理</td>
</tr>
<tr class="even">
<td>sklearn.pipeline</td>
<td>FeatureUnion</td>
<td>并行处理</td>
</tr>
<tr class="odd">
<td>sklearn.grid_search</td>
<td>GridSearchCV</td>
<td>网格搜索调参</td>
</tr>
<tr class="even">
<td>externals.joblib</td>
<td>dump</td>
<td>数据持久化</td>
</tr>
<tr class="odd">
<td>externals.joblib</td>
<td>load</td>
<td>从文件系统中加载数据至内存</td>
</tr>
</tbody>
</table>
<p>组合和持久化都会涉及pickle技术，在sklearn的技术文档中有说明，<strong>将lambda定义的函数作为<code>FunctionTransformer</code>的自定义转换函数将不能pickle化。</strong></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>使用sklearn做单机特征工程</title>
    <url>/2017/01/03/%E4%BD%BF%E7%94%A8sklearn%E5%81%9A%E5%8D%95%E6%9C%BA%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<p>本文转载自 http://www.cnblogs.com/jasonfreak/p/5448385.html
,在某些部分会拓展补充一些内容，全文主要讲述有关特征工程中通常使用的方法以及在sklearn中的相关实现。</p>
<span id="more"></span>
<h2 id="特征工程是什么"><strong>特征工程是什么</strong></h2>
<p>有这么一句话在业界广泛流传：<strong>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</strong>那特征工程到底是什么呢？顾名思义，其本质是一项工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用。通过总结和归纳，人们认为特征工程包括以下方面：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b99tlsf81c6n5iicv3otetoa9.png"
alt="特征工程思维导图" />
<figcaption aria-hidden="true">特征工程思维导图</figcaption>
</figure>
<p>特征处理是特征工程的核心部分，sklearn提供了较为完整的特征处理方法，包括数据预处理，特征选择，降维等。首次接触到sklearn，通常会被其丰富且方便的算法模型库吸引，但是这里介绍的特征处理库也十分强大！</p>
<p>本文中使用sklearn中的<a
href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris">IRIS（鸢尾花）数据集</a>来对特征处理功能进行说明。IRIS数据集由Fisher在1936年整理，包含4个特征（Sepal.Length（花萼长度）、Sepal.Width（花萼宽度）、Petal.Length（花瓣长度）、Petal.Width（花瓣宽度）），特征值都为正浮点数，单位为厘米。目标值为鸢尾花的分类（Iris
Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），Iris
Virginica（维吉尼亚鸢尾））。导入IRIS数据集的代码如下：
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入IRIS数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment">#特征矩阵</span></span><br><span class="line">iris.data</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标向量</span></span><br><span class="line">iris.target</span><br></pre></td></tr></table></figure></p>
<h2 id="数据预处理"><strong>数据预处理</strong></h2>
<p>通过特征提取，我们能得到未经处理的特征，这时的特征可能有以下问题：</p>
<ul>
<li>不属于同一量纲：即特征的规格不一样，不能够放在一起比较。<strong>无量纲化</strong>可以解决这一问题。</li>
<li>信息冗余：对于某些定量特征，其包含的有效信息为区间划分，例如学习成绩，假若只关心“及格”或不“及格”，那么需要将定量的考分，转换成“1”和“0”表示及格和未及格。<strong>二值化</strong>可以解决这一问题。</li>
<li>定性特征不能直接使用：某些机器学习算法和模型只能接受定量特征的输入，那么需要将定性特征转换为定量特征。最简单的方式是为每一种定性值指定一个定量值，但是这种方式过于灵活，增加了调参的工作。通常使用<strong>哑编码</strong>的方式将定性特征转换为定量特征：假设有N种定性值，则将这一个特征扩展为N种特征，当原始特征值为第i种定性值时，第i个扩展特征赋值为1，其他扩展特征赋值为0。<strong>哑编码的方式相比直接指定的方式，不用增加调参的工作，对于线性模型来说，使用哑编码后的特征可达到非线性的效果。</strong></li>
<li>存在缺失值：缺失值需要补充。</li>
<li>信息利用率低：不同的机器学习算法和模型对数据中信息的利用是不同的，之前提到在线性模型中，使用对定性特征哑编码可以达到非线性的效果。类似地，<strong>对定量变量多项式化，或者进行其他的转换，都能达到非线性的效果。</strong></li>
</ul>
<p>我们使用sklearn中的 <code>preproccessing</code>
库来进行数据预处理，可以覆盖以上问题的解决方案。</p>
<h3 id="无量纲化"><strong>无量纲化</strong></h3>
<p>　
无量纲化使不同规格的数据转换到同一规格。常见的无量纲化方法有<strong>标准化和归一化。</strong></p>
<p><strong>标准化一般指的是0均值标准化(zero-mean
normalization)也叫z-score标准化。z-score标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布，即均值为0，标准差为1。</strong></p>
<p><strong>归一化一般指的是区间缩放法，利用了边界值信息，将特征的取值区间缩放到某个特点的范围，例如[0,
1]等。</strong></p>
<h4 id="标准化"><strong>标准化</strong></h4>
<p>0均值标准化需要计算特征的均值和标准差，公式表达为：<span
class="math display">\[x&#39; = \frac{x - \mu}{\sigma}\]</span> 公式中的
<span class="math inline">\(\mu\)</span> 为原始数据的期望， <span
class="math inline">\(\sigma\)</span>为原始数据的标准差。</p>
<p>使用 <code>preproccessing</code> 库的 <code>StandardScaler</code>
类对数据进行标准化的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment">#标准化，返回值为标准化后的数据</span></span><br><span class="line">StandardScaler().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<p>标准化的原理比较复杂，它表示的是原始值与均值之间差多少个标准差，是一个相对值，所以也有去除量纲的功效。同时，它还带来两个附加的好处：均值为0，标准差为1。关于这两个属性的具体好处参考
http://www.zhaokv.com/2016/01/normalization-and-standardization.html
如下</p>
<blockquote>
<p>均值为0有什么好处呢？它可以使数据以0为中心左右分布（这不是废话嘛），而数据以0为中心左右分布会带来很多便利。比如在去中心化的数据上做SVD分解等价于在原始数据上做PCA；机器学习中很多函数如Sigmoid、Tanh、Softmax等都以0为中心左右分布（不一定对称）。</p>
<p>标准差为1有什么好处呢？这个更复杂一些。对于<span
class="math inline">\(x\_i, x\_{i&#39;}\)</span>两点间距离，往往表示为
<span
class="math display">\[D(x\_i,x\_{i&#39;})=\sum\limits\_{j=1}^pw\_j\cdot
d\_j(x\_{ij},x\_{i&#39;j})(\sum\limits\_{j=1}^pw\_j=1)\]</span> 其中
<span class="math inline">\(d\_j(x\_{ij},x\_{i&#39;j})\)</span>是属性
<span class="math inline">\(j\)</span> 两个点之间的距离, <span
class="math inline">\(w\_j\)</span> 是该属性间距离在总距离中的权重
注意设 <span class="math inline">\(w\_j=1,\forall
j\)</span>并不能实现每个属性对最后的结果贡献度相同。对于给定的数据集，所有点对间距离的平均值是个定值，即
<span
class="math display">\[\bar{D}=\frac{1}{N^2}\sum\limits\_{i=1}^N\sum\limits\_{i&#39;=1}^ND(x\_i,x\_{i&#39;})=\sum\limits\_{j=1}^pw\_j\cdot
\bar{d}\_j\]</span> 是个常数，其中 <span
class="math inline">\(\bar{d}\_j=\frac{1}{N^2}\sum\limits\_{i=1}^N\sum\limits\_{i&#39;=1}^Nd\_j(x\_{ij},
x\_{x&#39;j})\)</span>, 可见第 <span class="math inline">\(j\)</span>
个变量对最终整体平均距离的影响是 <span class="math inline">\(w\_j\cdot
\bar{d}\_j\)</span>,所以设 <span class="math inline">\(w\_j\sim
1/\bar{d}\_j\)</span>
可以使所有属性对全体数据集平均距离的贡献相同。现在设 <span
class="math inline">\(d\_j\)</span>
为欧氏距离的平方，它是最常用的距离衡量方法之一，则有<span
class="math display">\[\bar{d\_j}=\frac{1}{N^2}\sum\limits\_{i=1}^N\sum\limits\_{i&#39;=1}^N(x\_{ij}-x\_{i&#39;j})^2=2\cdot
var\_j\]</span>其中 <span class="math inline">\(var\_j\)</span> 是 <span
class="math inline">\(Var(X\_j)\)</span>
样本估计，也就是说每个变量的重要程度正比于这个变量在这个数据集上的方差<strong>。如果我们让每一维变量的标准差都为1（即方差都为1），每维变量在计算距离的时候重要程度相同。</strong></p>
</blockquote>
<p>因此在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，往往采用标准化方法。</p>
<h4 id="归一化"><strong>归一化</strong></h4>
<p>区间缩放法的思路有多种，常见的一种为利用两个最值进行缩放，公式表达为：<span
class="math display">\[x&#39; = \frac{x - Min}{Max - Min}\]</span> 使用
<code>preproccessing</code> 库的 <code>MinMaxScaler</code>
类对数据进行区间缩放的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment">#区间缩放，返回值为缩放到[0, 1]区间的数据</span></span><br><span class="line">MinMaxScaler().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<p>归一化的依据非常简单，不同变量往往量纲不同，归一化可以消除量纲对最终结果的影响，使不同变量具有可比性。比如两个人体重差10KG，身高差0.02M，在衡量两个人的差别时体重的差距会把身高的差距完全掩盖，归一化之后就不会有这样的问题。</p>
<p>除此之外，<strong>归一化后能够加快梯度下降求最优解的速度</strong>，如下图所示，蓝色的圈圈图代表的是两个特征的等高线。其中左图两个特征
<span class="math inline">\(X1\)</span> 和 <span
class="math inline">\(X2\)</span> 的区间相差非常大，<span
class="math inline">\(X1\)</span> 区间是[0,2000]，<span
class="math inline">\(X2\)</span>区间是[1,5]，其所形成的等高线非常尖。当使用梯度下降法寻求最优解时，很有可能走“之字型”路线（垂直等高线走），从而导致需要迭代很多次才能收敛；而右图对两个原始特征进行了归一化，其对应的等高线显得很圆，在梯度下降进行求解时能较快的收敛。<strong>因此如果机器学习模型使用梯度下降法求最优解时，归一化往往非常有必要，否则很难收敛甚至不能收敛。</strong></p>
<figure>
<img src="https://wulc.me/imgs/image_1b99vqj1v1cffks1m321n8k1lalm.png"
alt="归一化对收敛的影响" />
<figcaption aria-hidden="true">归一化对收敛的影响</figcaption>
</figure>
<p>因此。在涉及到计算点与点之间的距离时，使用归一化或标准化都会对最后的结果有所提升，甚至会有质的区别。那在归一化与标准化之间应该如何选择呢？根据上面论述我们看到，<strong>如果把所有维度的变量一视同仁，在最后计算距离中发挥相同的作用应该选择标准化，如果想保留原始数据中由标准差所反映的潜在权重关系应该选择归一化。另外，标准化更适合现代嘈杂大数据场景。</strong></p>
<h3 id="对定量特征二值化"><strong>对定量特征二值化</strong></h3>
<p>定量特征二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0。使用
<code>preproccessing</code> 库的 <code>Binarizer</code>
类对数据进行二值化的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Binarizer</span><br><span class="line"></span><br><span class="line"><span class="comment">#二值化，阈值设置为3，返回值为二值化后的数据</span></span><br><span class="line">Binarizer(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h3 id="对定性特征哑编码"><strong>对定性特征哑编码</strong></h3>
<p>由于IRIS数据集的特征皆为定量特征，故使用其目标值进行哑编码（实际上是不需要的）。使用
<code>preproccessing</code> 库的 <code>OneHotEncoder</code>
类对数据进行哑编码的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment">#哑编码，对IRIS数据集的目标值，返回值为哑编码后的数据</span></span><br><span class="line">OneHotEncoder().fit_transform(iris.target.reshape((-<span class="number">1</span>,<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<h3 id="缺失值计算"><strong>缺失值计算</strong></h3>
<p>由于IRIS数据集没有缺失值，故对数据集新增一个样本，4个特征均赋值为NaN，表示数据缺失。使用
<code>preproccessing</code> 库的 <code>Imputer</code>
类对数据进行缺失值计算的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> vstack, array, nan</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"></span><br><span class="line"><span class="comment">#缺失值计算，返回值为计算缺失值后的数据</span></span><br><span class="line"><span class="comment">#参数missing_value为缺失值的表示形式，默认为NaN</span></span><br><span class="line"><span class="comment">#参数strategy为缺失值填充方式，默认为mean（均值）</span></span><br><span class="line">Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data)))</span><br></pre></td></tr></table></figure>
<h3 id="数据变换"><strong>数据变换</strong></h3>
<p>数据变换就是通过组合或变换方式将原来的特征转换为新的特征，常见的数据变换有基于多项式的、基于指数函数的、基于对数函数的。</p>
<p>例如，输入的一个二维特征为 <span class="math inline">\([a,
b]\)</span>,则度为2的多项式特征为 $ [1, a, b, a^2, ab, b^2]$</p>
<p>使用 <code>preproccessing</code> 库的 <code>PolynomialFeatures</code>
类对数据进行多项式转换的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"></span><br><span class="line"><span class="comment">#多项式转换</span></span><br><span class="line"><span class="comment">#参数degree为度，默认值为2</span></span><br><span class="line">PolynomialFeatures().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<p>基于单变元函数的数据变换可以使用一个统一的方式完成，使用
<code>preproccessing</code> 库的 <code>FunctionTransformer</code>
对数据进行对数函数转换的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> log1p</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> FunctionTransformer</span><br><span class="line"></span><br><span class="line"><span class="comment">#自定义转换函数为对数函数的数据变换</span></span><br><span class="line"><span class="comment">#第一个参数是单变元函数</span></span><br><span class="line">FunctionTransformer(log1p).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h3 id="小结"><strong>小结</strong></h3>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>类</th>
<th>功能</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>StandardScaler</td>
<td>无量纲化</td>
<td>标准化，基于特征矩阵的列，将特征值转换至服从标准正态分布</td>
</tr>
<tr class="even">
<td>MinMaxScaler</td>
<td>无量纲化</td>
<td>区间缩放，基于最大最小值，将特征值转换到[0, 1]区间上</td>
</tr>
<tr class="odd">
<td>Normalizer</td>
<td>归一化</td>
<td>基于特征矩阵的行，将样本向量转换为“单位向量”</td>
</tr>
<tr class="even">
<td>Binarizer</td>
<td>二值化</td>
<td>基于给定阈值，将定量特征按阈值划分</td>
</tr>
<tr class="odd">
<td>OneHotEncoder</td>
<td>哑编码</td>
<td>将定性数据编码为定量数据</td>
</tr>
<tr class="even">
<td>Imputer</td>
<td>缺失值计算</td>
<td>计算缺失值，缺失值可填充为均值等</td>
</tr>
<tr class="odd">
<td>PolynomialFeatures</td>
<td>多项式数据转换</td>
<td>多项式数据转换</td>
</tr>
<tr class="even">
<td>FunctionTransformer</td>
<td>自定义单元数据转换</td>
<td>使用单变元的函数来转换数据</td>
</tr>
</tbody>
</table>
<h2 id="特征选择"><strong>特征选择</strong></h2>
<p>当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：</p>
<ul>
<li><strong>特征是否发散</strong>：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。</li>
<li><strong>特征与目标的相关性</strong>：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，本文介绍的其他方法均从相关性考虑。</li>
</ul>
<p>根据特征选择的形式又可以将特征选择方法分为3种：</p>
<ul>
<li><strong>Filter：过滤法</strong>，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。</li>
<li><strong>Wrapper：包装法</strong>，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</li>
<li><strong>Embedded：嵌入法</strong>，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。</li>
</ul>
<p>我们使用sklearn中的feature_selection库来进行特征选择。</p>
<h3 id="filter"><strong>Filter</strong></h3>
<h4 id="方差选择法"><strong>方差选择法</strong></h4>
<p>使用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。使用
<code>feature_selection</code> 库的 <code>VarianceThreshold</code>
类来选择特征的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line"><span class="comment">#方差选择法，返回值为特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数threshold为方差的阈值</span></span><br><span class="line">VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure></p>
<h4 id="相关系数法"><strong>相关系数法</strong></h4>
<p>使用相关系数法，先要计算各个特征对目标值的相关系数以及相关系数的P值。用
<code>feature_selection</code> 库的 <code>SelectKBest</code>
类结合相关系数来选择特征的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line"><span class="comment">#第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数</span></span><br><span class="line"><span class="comment">#参数k为选择的特征个数</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h4 id="卡方检验"><strong>卡方检验</strong></h4>
<p>经典的卡方检验是<strong>检验定性自变量对定性因变量的相关性</strong>。具体的意义可参考这篇文章<a
href="http://guoze.me/2015/09/07/chi-square/">卡方检验原理及应用</a>。用
<code>feature_selection</code> 库的 <code>SelectKBest</code>
类结合卡方检验来选择特征的代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h4 id="互信息法"><strong>互信息法</strong></h4>
<p>经典的互信息也是变量间相互依赖性的量度，互信息计算公式如下： <span
class="math display">\[I(X,Y) = \sum\_{x \in X}\sum\_{y \in
Y}p(x,y)log\frac{p(x,y)}{p(x)p(y)}\]</span>
为了处理定量数据，最大信息系数法被提出，使用
<code>feature_selection</code> 库的 <code>SelectKBest</code>
类结合最大信息系数法来选择特征的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line"></span><br><span class="line"><span class="comment">#由于MINE的设计不是函数式的，定义mic方法将其为函数式的，返回一个二元组，二元组的第2项设置成固定的P值0.5</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mic</span>(<span class="params">x, y</span>):</span><br><span class="line">    m = MINE()</span><br><span class="line">    m.compute_score(x, y)</span><br><span class="line">    <span class="keyword">return</span> (m.mic(), <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择K个最好的特征，返回特征选择后的数据</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:mic(x, Y), X.T)).T, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h3 id="wrapper"><strong>Wrapper</strong></h3>
<h4 id="递归特征消除法"><strong>递归特征消除法</strong></h4>
<p>递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。使用feature_selection库的RFE类来选择特征的代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment">#递归特征消除法，返回特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数estimator为基模型</span></span><br><span class="line"><span class="comment">#参数n_features_to_select为选择的特征个数</span></span><br><span class="line">RFE(estimator=LogisticRegression(), n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure> ----</p>
<h3 id="embedded"><strong>Embedded</strong></h3>
<h4
id="基于惩罚项的特征选择法"><strong>基于惩罚项的特征选择法</strong></h4>
<p>使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。使用<code>feature_selection</code>库的<code>SelectFromModel</code>类结合带L1惩罚项的逻辑回归模型，来选择特征的代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(LogisticRegression(penalty=<span class="string">&quot;l1&quot;</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<p>L1惩罚项降维的原理在于保留多个对目标值具有同等相关性的特征中的一个，所以没选到的特征不代表不重要。故，可结合L2惩罚项来优化。具体操作为：若一个特征在L1中的权值为1，选择在L2中权值差别不大且在L1中权值为0的特征构成同类集合，将这一集合中的特征平分L1中的权值，故需要构建一个新的逻辑回归模型：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LR</span>(<span class="title class_ inherited__">LogisticRegression</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, threshold=<span class="number">0.01</span>, dual=<span class="literal">False</span>, tol=<span class="number">1e-4</span>, C=<span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">                 fit_intercept=<span class="literal">True</span>, intercept_scaling=<span class="number">1</span>, class_weight=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 random_state=<span class="literal">None</span>, solver=<span class="string">&#x27;liblinear&#x27;</span>, max_iter=<span class="number">100</span>,</span></span><br><span class="line"><span class="params">                 multi_class=<span class="string">&#x27;ovr&#x27;</span>, verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>, n_jobs=<span class="number">1</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment">#权值相近的阈值</span></span><br><span class="line">        self.threshold = threshold</span><br><span class="line">        LogisticRegression.__init__(self, penalty=<span class="string">&#x27;l1&#x27;</span>, dual=dual, tol=tol, C=C,</span><br><span class="line">                 fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight=class_weight,</span><br><span class="line">                 random_state=random_state, solver=solver, max_iter=max_iter,</span><br><span class="line">                 multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs)</span><br><span class="line">        <span class="comment">#使用同样的参数创建L2逻辑回归</span></span><br><span class="line">        self.l2 = LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, intercept_scaling=intercept_scaling, class_weight = class_weight, random_state=random_state, solver=solver, max_iter=max_iter, multi_class=multi_class, verbose=verbose, warm_start=warm_start, n_jobs=n_jobs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y, sample_weight=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment">#训练L1逻辑回归</span></span><br><span class="line">        <span class="built_in">super</span>(LR, self).fit(X, y, sample_weight=sample_weight)</span><br><span class="line">        self.coef_old_ = self.coef_.copy()</span><br><span class="line">        <span class="comment">#训练L2逻辑回归</span></span><br><span class="line">        self.l2.fit(X, y, sample_weight=sample_weight)</span><br><span class="line"></span><br><span class="line">        cntOfRow, cntOfCol = self.coef_.shape</span><br><span class="line">        <span class="comment">#权值系数矩阵的行数对应目标值的种类数目</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cntOfRow):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cntOfCol):</span><br><span class="line">                coef = self.coef_[i][j]</span><br><span class="line">                <span class="comment">#L1逻辑回归的权值系数不为0</span></span><br><span class="line">                <span class="keyword">if</span> coef != <span class="number">0</span>:</span><br><span class="line">                    idx = [j]</span><br><span class="line">                    <span class="comment">#对应在L2逻辑回归中的权值系数</span></span><br><span class="line">                    coef1 = self.l2.coef_[i][j]</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(cntOfCol):</span><br><span class="line">                        coef2 = self.l2.coef_[i][k]</span><br><span class="line">                        <span class="comment">#在L2逻辑回归中，权值系数之差小于设定的阈值，且在L1中对应的权值为0</span></span><br><span class="line">                        <span class="keyword">if</span> <span class="built_in">abs</span>(coef1-coef2) &lt; self.threshold <span class="keyword">and</span> j != k <span class="keyword">and</span> self.coef_[i][k] == <span class="number">0</span>:</span><br><span class="line">                            idx.append(k)</span><br><span class="line">                    <span class="comment">#计算这一类特征的权值系数均值</span></span><br><span class="line">                    mean = coef / <span class="built_in">len</span>(idx)</span><br><span class="line">                    self.coef_[i][idx] = mean</span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure>
<p>使用<code>feature_selection</code>库的<code>SelectFromModel</code>类结合带L1以及L2惩罚项的逻辑回归模型，来选择特征的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"></span><br><span class="line"><span class="comment">#带L1和L2惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line"><span class="comment">#参数threshold为权值系数之差的阈值</span></span><br><span class="line">SelectFromModel(LR(threshold=<span class="number">0.5</span>, C=<span class="number">0.1</span>)).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h4
id="基于树模型的特征选择法"><strong>基于树模型的特征选择法</strong></h4>
<p>树模型中GBDT也可用来作为基模型进行特征选择，使用
<code>feature_selection</code> 库的 <code>SelectFromModel</code> 类结合
GBDT 模型，来选择特征的代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment">#GBDT作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h4 id="小结-1"><strong>小结</strong></h4>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>类</th>
<th>所属方式</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>VarianceThreshold</td>
<td>Filter</td>
<td>方差选择法</td>
</tr>
<tr class="even">
<td>SelectKBest</td>
<td>Filter</td>
<td>可选关联系数、卡方校验、最大信息系数作为得分计算的方法</td>
</tr>
<tr class="odd">
<td>RFE</td>
<td>Wrapper</td>
<td>递归地训练基模型，将权值系数较小的特征从特征集合中消除</td>
</tr>
<tr class="even">
<td>SelectFromModel</td>
<td>Embedded</td>
<td>训练基模型，选择权值系数较高的特征</td>
</tr>
</tbody>
</table>
<h2 id="降维"><strong>降维</strong></h2>
<p>当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。<strong>PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。</strong></p>
<h3 id="主成分分析法pca"><strong>主成分分析法（PCA）</strong></h3>
<p>使用 <code>decomposition</code> 库的PCA类选择特征的代码如下：
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="comment">#主成分分析法，返回降维后的数据</span></span><br><span class="line"><span class="comment">#参数n_components为主成分数目</span></span><br><span class="line">PCA(n_components=<span class="number">2</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure></p>
<h3 id="线性判别分析法lda"><strong>线性判别分析法（LDA）</strong></h3>
<p>使用lda库的LDA类选择特征的代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.lda <span class="keyword">import</span> LDA</span><br><span class="line"></span><br><span class="line"><span class="comment">#线性判别分析法，返回降维后的数据</span></span><br><span class="line"><span class="comment">#参数n_components为降维后的维数</span></span><br><span class="line">LDA(n_components=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure></p>
<h3 id="小结-2">小结</h3>
<table>
<thead>
<tr class="header">
<th>库</th>
<th>类</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>decomposition</td>
<td>PCA</td>
<td>主成分分析法</td>
</tr>
<tr class="even">
<td>lda</td>
<td>LDA</td>
<td>线性判别分析法</td>
</tr>
</tbody>
</table>
<h2 id="总结">总结</h2>
<p>再让我们回归一下本文开始的特征工程的思维导图，我们可以使用sklearn完成几乎所有特征处理的工作，而且不管是数据预处理，还是特征选择，抑或降维，它们都是通过某个类的方法<code>fit_transform</code>完成的，<code>fit_transform</code>要不只带一个参数：特征矩阵，要不带两个参数：特征矩阵加目标向量。这些难道都是巧合吗？还是故意设计成这样？方法<code>fit_transform</code>中有fit这一单词，它和训练模型的fit方法有关联吗？接下来，在《<a
href="http://www.cnblogs.com/jasonfreak/p/5448462.html">使用sklearn优雅地进行数据挖掘</a>》中将会阐述其中的奥妙！</p>
<hr />
<p>参考： <a
href="http://www.zhaokv.com/2016/01/normalization-and-standardization.html">归一化与标准化</a>
<a
href="https://uqer.io/community/share/56c3e9c6228e5b0fe6b17d95">研究｜数据预处理｜归一化
（标准化）</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>修改Linux下bash的命令提示符</title>
    <url>/2015/10/11/%E4%BF%AE%E6%94%B9Linux%E4%B8%8Bbash%E7%9A%84%E5%91%BD%E4%BB%A4%E6%8F%90%E7%A4%BA%E7%AC%A6/</url>
    <content><![CDATA[<p>Linux终端的命令提示符能够显示诸如当前用户，主机名，时间等信息，根据自己实际需要配置自己的命令提示符能够使得工作更为便利。下面介绍一下修改命令提示符的方法。
<span id="more"></span></p>
<p>根据用户的不同，可以为系统所有用户修改命令提示符，也可以为单一用户修改命令提示符。两者的区别仅仅是修改的配置文件不同，前者需要修改<code>/etc/profile</code>文件，后者则只需要修改用户主目录下的
<code>.bashrc</code>文件。</p>
<p>修改的内容就是<code>PS1</code>这个环境变量，一种修改方法如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PS1=&#x27;[\u@\H: \d \t \w \$]&#x27;</span><br></pre></td></tr></table></figure>
<p>将上面的内容添加到当前用户的<code>~/.bashrc</code>文件中，各个参数的具体含义后面会讲。</p>
<p>但是此时配置还没生效，需要运行下面的命令让该文件配置立即生效。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure> 生效后可以看到命令提示符变成了下面的形式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@memcached1: Sat Jan 23 03:03:13 /etc/sysconfig #]</span><br></pre></td></tr></table></figure>
<p>此时便可以明白了上面修改的PS1的各个参数的含义了，<code>\u</code>表示当前用户，<code>\H</code>表示主机名，<code>\d</code>表示当前日期，而且格式是“<strong>weekday
month
date</strong>”<code>\t</code>表示当前时间，24小时制，格式是"<strong>HH:MM:SS</strong>",<code>\w</code>表示用完整路径表示当前的目录，<code>\$</code>表示提示字符，root用户用<code>#</code>,一般用户用<code>$</code>。</p>
<p>除了上面提到的几个比较常用的参数外，还有下面一些参数及其含义：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">参数</th>
<th style="text-align: center;">含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td
style="text-align: center;">显示当前路径的相对路径，小写的w是完整路径</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td
style="text-align: center;">表示当前时间，12小时制，格式是"<strong>HH:MM:SS</strong>"</td>
</tr>
<tr class="odd">
<td style="text-align: center;">\#</td>
<td style="text-align: center;">执行的第几个命令</td>
</tr>
<tr class="even">
<td style="text-align: center;">BASH的版本信息</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>做一个清醒的傻瓜</title>
    <url>/2023/02/05/%E5%81%9A%E4%B8%80%E4%B8%AA%E6%B8%85%E9%86%92%E7%9A%84%E5%82%BB%E7%93%9C/</url>
    <content><![CDATA[<p>随机性，如同带刺的玫瑰，危险而又迷人；随机性可能会给你带来生活中的惊喜，但也有可能会降临足以毁灭生活的灾难</p>
<p>在去年的<a
href="https://wulc.me/2023/01/01/2022%20%E5%B0%8F%E7%BB%93/">年度小结</a>提到，22
年最大的感悟，是生活存在非常多的随机性，正是这些随机性导致了无法预测和无人知晓的未来；1
月份在查资料过程中看到了塔勒布的<a
href="https://book.douban.com/series/45353">“不确定性”四部曲</a>：《随机漫步的傻瓜》、《黑天鹅》、《反脆弱》和《非对称风险》，相比于笔者简单的感悟，这几本书花了很大功夫来描述随机性这件事情</p>
<p>如果单纯看随机性，很容易让我们陷入虚无主义中，因为没什么是确定的，或者说没什么是能够坚信的，因为随机性几乎主导了一切。幸运的是，书里给出了还给出了一些也许可供参考的方法论，虽然作者行文有时候较为晦涩，但总体还是值得一读的。本文主要是
《随机漫步的傻瓜》和《黑天鹅》两本书的一些笔记以及拓展，祝开卷有益。</p>
<span id="more"></span>
<h2 id="我们都是随机漫步的傻瓜">我们都是随机漫步的傻瓜</h2>
<p>生活往往被随机性左右，你的成功或失败不见得是因为比其他人高明或愚蠢，很可能只是单纯的运气的结果</p>
<p>上面这句话，也许是《随机漫步的傻瓜》最想给我们揭示的道理</p>
<p>《<a
href="https://book.douban.com/subject/3688489/">异类</a>》一书中也提到以下现象</p>
<blockquote>
<p>英超联赛大部分球员都在9月至11月出生；
比尔·盖茨和史蒂夫·乔布斯都出生在1955年；
纽约很多著名律师事务所的开创者竟然都是犹太人后裔，并且他们的祖辈大多是在纽约的服装行业谋生。
为什么对那些成功人士进行的统计结果会这样一致“意外”？这是因为：
英超球员注册时间是9月。在同龄的球员中，9月份出生的人实际上比8月份出生的人几乎大了一岁，一岁的差距对他们的职业生涯有着不可低估的影响；
1955年前后正是计算机革命的时期，如果你出生太早，就无法拥有个人电脑，如果出生太晚，计算机革命的好机会又被别人占去了；
犹太人律师事务所的成长，是因为他们正赶上企业重组的法律诉讼出现革新的时候，而他们移民到美国的祖辈们的经历又让他们出色地掌握了抓住机遇的能力。</p>
</blockquote>
<p>很多时候，大的成功往往靠的是天时地利人和，而且天时地利可能是主导因素。看人物自传往往会让我们热血澎湃，似乎遵循着成功者的路线，他的成功我也可以复制，但事实往往是他们在那个时代提供了那个时代最需要的东西，然后在合适的时机，时代给予了他们足够大的正向的反馈，不同时代的人压根无法复制。我们看到的往往都是幸存者偏差，因为无论概率多小，只要尝试的基数足够大，每个时代最终都能选出那一批为人所熟知的幸存者</p>
<p>这里并不是说人物自传一无是处，也不是说那些名人的成功是纯粹由机遇和随机性指导，他们的思考方式、他们付出的努力，都是无法粗暴地被“机遇”二字淹没的</p>
<p>但我们需要清楚地意识到，影响一件事情的成功或失败的因素往往是错综复杂，这其中有多少是运气成分，有多少又是努力的成分，往往无法给出一个明确的量化标准；而当我们面临一个选择时，如果能够清楚地意识到随机性在其中的影响，并心平气和的接收这个事实及其可能带来的后果，也许能让我们活得更加轻松和豁达</p>
<p>在股市上，我们往往也都是一个随机漫步的傻瓜，市场总体上升时，几乎每个人都觉得是自己英明的抉择选择才让自己赚得盆满钵满的，但其中是
alpha 收益主导，还是 beta
收益主导，可能大多数人都说不清楚；因为在短的时间内，市场很多所谓表现都是波动;各类新闻报纸每天都要点评股市，试图为今天的涨跌说出个理由，因为媒体总会想说点什么来明他们有存在的价值；但实际上没有什么理由，每天的股价变动由随机性决定更多</p>
<p>关于这本书，知乎上有个比较精彩的回答，<a
href="https://www.zhihu.com/question/20951240/answer/16699613">《随机漫步的傻瓜》是怎样的一本书？</a>；笔者把核心观点提炼如下,
这里其实也提到了《黑天鹅》中的叙述谬误的现象，因为《随机漫步的傻瓜》出版得比《黑天鹅》更早，两者的观点会有些许重合</p>
<blockquote>
<p><strong>我们万事都需要一个解释，以获得内心的宁静。没有解释的事情会让人茶饭不思、寝卧难安</strong></p>
<p><strong>因此我们急于去总结成功的经验和失败的教训，其结果就是我们常常顾不得去分析这个成功或失败的原因是否存在</strong></p>
<p>但常常我么也会找不到确定的因果，于是我们只好迷信；这完全是我们从先古部落首领那里传承下来的习惯，比如他们采用了某种祭拜姿势就可以求得龙王降雨</p>
<p>这本书多少有一点虚无主义色彩。你没有什么可以相信的，如果有人因为努力而获得了巨大成就，要相信，事情没有那么复杂——大部分时候，都是运气使然。虚无主义的意思是，没有什么是确定的，或者说，没有什么会找到确定的原因，一切都是不确定的。</p>
<p>可以把它当成《心灵鸡汤》一类的读物。<strong>它让你接受现实——当然，前提是你足够理性，同时足够努力和聪明。准确地说，这不过是一本写给迷失在财富追求的过程之中的人们，换言之，是写给有点钱、有点追求、但是钱又不太多的人们看的</strong>。很重要的一个提示是：不要老看着多少人比你强，要看到多少人比你差</p>
</blockquote>
<h2 id="黑天鹅从何而来">黑天鹅从何而来</h2>
<p>不要忽视那些概率低、但是有极大的冲击性的事情，这些事情无法预测，但是在行动时要考虑到</p>
<p>上面这句话，也许是《黑天鹅》最想给我们揭示的道理</p>
<p>书里还给了很多由于惯性思维、人性等原因带来的问题，意识到这些点，也许能让我们能够更好地认知到很多事情或结论的局限性</p>
<h3 id="叙述谬误">叙述谬误</h3>
<p>很多时候，在黑天鹅发生后，人的本性促使我们在事后为它的发生编造理由，并且或多或少认为它是可解释和可预测的；而这其实也是黑天鹅发生的原因之一</p>
<p>书中将这一现象称作“叙述谬误”，叙述谬误指的是我们无法在不编造理由或者强加一种逻辑关系的情况下观察一系列事实。换句话说，我们在观察一组事实的时候，一定编造相应的理由或者逻辑关系，让我们觉得这组事实是可以解释的，符合逻辑的；如果不这样，我们就无法观察和表达。造成叙述谬误有以下几个原因</p>
<p>1）解释习惯；我们习惯对观察到的事实梳理因果关系，让事情变得可解释，这个过程虽然好，但是也会可能导致<strong>一些看起来无关的事实就会被我们忽视掉。而那些被忽略的事实往往会成为导致黑天鹅现象的原因，并且在黑天鹅事件发生后，被人们重新翻查出来，并加以解释</strong>
2）模式辨识习惯：《<a
href="https://book.douban.com/subject/20507212/">习惯的力量</a>》指出，习惯之所以出现，是因为大脑一直在寻找可以省力的方式。模式就是大脑的省力方式，为了高效处理信息，作出反应，我们不得不训练自己形成各种习惯，但是这些<strong>习惯也会阻碍我们接受新的观念</strong>
3）简化习惯：信息理论核心问题：1.信息获得是有代价的；2.信息的存储也是有代价的；3.信息的处理和提取也是有代价的正是这些代价，让我们简化了很多东西，倾向于讲故事而不是注重事实。而我们的简化行为使得我们以为世界的随机性要比实际的小</p>
<p>而如果进一步深究上面几个原因，我们会发现这都是人性导致的</p>
<ul>
<li>解释习惯是因为我们天生喜欢有条理的东西，为了让因果关系看起来更加可解释；而常常忽略了一些所谓的
outlier，如同在机器学习中去除 outlier
一样，有时候其实样本并不异常，只是我们的模型不足以学习到这些所谓的
outlier，而人为地把这些样本过滤掉</li>
<li>模式辨识习惯和简化习惯，都是我们为了更省力地去做事情而发展出来的，毕竟如果每件事情都从头去想和做，是在是太费时费力了</li>
</ul>
<p>在书里的“自我欺骗的人类”一章中，则提到了人类的思想有三重迷雾：
1）假想的理解，也就是在一个超出人们想象之外的复杂或随机的世界，人们都以为自己知道其中正在发生什么；很多发生过的事情本来应该被认为是完全不可思议的，但在事情发生之后，看上去却没那么不可思议了。这种事后合理性在表面上降低了事件的稀有性，并使事件看上去可以理解
2）反省的误差，也就是我们只能在事后评价事物，就像只能以后视镜里看东西，<strong>历史在历史书中比在经验现实中显得更加清晰和有条理</strong>；在一个历史事件发生之前存在无数个事实，其中只有相当少的一部分会在后来你对历史事件的理解中有帮助，而这些有条理的时间会被记入史书中
3）对事实性信息价值的高估</p>
<p>在生活中，当我们作出一些判断和决定前，如果能够清楚意识到叙述谬误这一现象的存在，以及上面提到的由人性的局限性，也许就是这本书能够给我们带来的价值之一</p>
<h3 id="极端斯坦平均斯坦与择业">极端斯坦、平均斯坦与择业</h3>
<p>这是《黑天鹅》中提到的两个概念，基本含义如下</p>
<p>平均斯坦：当样本数量最够大，任何个例都不会对整体产生重大影响（正态分布）
极端斯坦：不平均性现象，个体能够对整体产生不成比例的影响（长尾分布）</p>
<p>如果从分布上来说，极端斯坦有点像方差较大的一个正态分布，极端的个体较少；而极端斯坦则是一个长尾分布，头部的一些个体会影响全局，跟二八法则有点像</p>
<p>这个概念往往会被应用在择业上</p>
<p>有些技术性的职业，比如牙医、咨询师、按摩师的收入是不可能具有突破性的，他们受到既定的时间内服务的病人或客户的最大数量的限制。在这些职业中，不论报酬多高，收入总是受到限制，他们不可能一夜致富，财富总是来自于持续的积累。并且这种工作在很大程度上是可预测的：他的收入可以增长，但不可能达到一天的收入超过余生的收入总和的程度，也就是说这种职业不会受到黑天鹅的驱使,
假如你是一名会计师或外科医生，你不可能一夜之间成为超级英雄，也不太可能成为一名失败者。</p>
<p>而另外还有一些职业如果干得好，收入可以十倍、百倍地增长，同时几乎不需要增加额外的努力。比如股票交易员，买100股股票与买100万股股票的工作量是一样的，要打同样的电话，做同样的计算，对交易的正确性做同样的确认，收入却截然不同。同样，演员、录音师、作家对于同一作品，他们的工作量也是一样的，但这类职业可以不必增加劳动量就可能十倍、百倍地增加收入，一部发行量大的影片、一本畅销的书籍都能带来突破性的收入</p>
<p>一般<strong>智力，科学和艺术行为</strong>等属于极端斯坦，在这里成功是高度集中的，少量赢者得到蛋糕的大部分。其实极端斯坦基本上适用于所有“有意思”的职业，但<strong>从事他们并不是好主意，因为收入具有突破性的职业，只有在你成功的时候才对你有利，这样的职业竞争激烈，导致了更大的不平均和不确定性，在努力和回报之间存在巨大差异，可能会出现赢家通吃的现象，普通人或许什么也得不到；挨饿的演员比挨饿的会计师要多</strong></p>
<h3 id="无法预测的未来">无法预测的未来</h3>
<p>很多事情不能只靠过去的经验来判断，某件事情1000天的历史不会告诉你弟1001天的任何信息；我们从过去获得的实际上顶多是无关痛痒和虚假的信息，甚至是危险的信号</p>
<p>其实这个观点《随机漫步的傻瓜》中就有了，只是这里做了进一步的说明和延伸，同时提出了以下有趣的观点</p>
<ul>
<li><strong>信息会妨碍知识</strong></li>
</ul>
<p>因为人们对于经验现实的细节知识了解的越多，看到的噪点就越多，就可能把它们错当成真实信息。同时，<strong>一旦你的思维被某种世界观占据，你会习惯于只关注证明你正确的事例。吊诡之处在于，你拥有越多的信息，你就越认为自己正确</strong></p>
<p>因此，我们在接收信息时一定要谨慎过滤，不要轻易全盘接受，这里有 2
个也许可供参考的方法</p>
<p>（1）<strong>注重事实而不是故事</strong>；我们天生喜欢故事，喜欢总结，喜欢简化，也就是减少事情的影响因素。没有人愿意去听某个无聊的抽象统计学讲座，我们喜欢听故事，这没有错，我们只是<strong>要去更加彻底的审视，故事是否对事实做了严重扭曲</strong></p>
<p>（2）<strong>控制接收信息的频率</strong>；从机器学习角度来讲，人其实是一个持续流式更行的
online
model，对近期收到的信息和样本会更加敏感，每小时收听广播比阅读周刊之所以要糟糕，是我们会被短时间的很多
noise
干扰了想法和思绪，而较长的时间间隔能够过滤掉一些无关重要信息；这里不得不提以下当前软件流行的信息流模式，很容易让人建立多巴胺回路，让人一刷接着一刷欲罢不能，说到底，还是要保护好我们自己的注意力</p>
<ul>
<li><strong>认知自大</strong></li>
</ul>
<p>我们在自以为拥有的知识方面非常自大，我们有一种内在的倾向，以为我们比实际上知道得多一些，这一点常常招致严重的麻烦。认知自大有双重影响：我们<strong>高估我们的知识，低估不确定性，也就是低估未知事物的范围</strong></p>
<p>“<a
href="https://www.zhihu.com/question/49805566">淹死的都是水性好的</a>”，说得也是这个道理，过度的自信容易让我们忽略未知的风险，从而做出错误的判断和预测</p>
<h2 id="如果黑天鹅无法避免">如果黑天鹅无法避免</h2>
<p>《随机漫步的傻瓜》告诉了我们生活中存在着种种随机性，需要清楚地意识到成功或失败中的运气成分，《黑天鹅》则是告诉了我们那些概率极低但破坏极大的事情的诱因，那回到最终要的方法论上，也就是面对这些随机性，我们能做些什么？</p>
<p>黑天鹅的序里写了这段话：如果把塔勒布和巴菲特的共同经验总结，可以得到应对黑天鹅事件的5个基本原则：<strong>1.不要预测；2.谨慎预防；3.危中取机；4.最重要的一点，保持充足冗余；5.不要负债</strong></p>
<p>下面针对这 5 点进行一些拓展和讨论</p>
<h3 id="不预测只应对">不预测，只应对</h3>
<p>黑天鹅事件往往无法预测、无法解释，很多事后的归因往往也是无效的；所以才有了我们前面提到的
2 条原则：不要预测和谨慎预防</p>
<p>这里的小标题套用了孟岩的文章《<a
href="https://zhuanlan.zhihu.com/p/143362092">不预测，只应对</a>》</p>
<p>我们往往面临的三个主要问题：<strong>（1）总结出来的规律并不靠谱（2）用于预测的信息也不客观（3）未来充满不可预期的「随机事件」</strong></p>
<p>（1）总结出来的规律并不靠谱；指的是我们总结出来的规律往往是从过去发生的事件中归纳出来的,
而已发生的事情，往往是<strong>因果规律和随机性共同作用的结果</strong>，但我们的大脑回路天生并不习惯于捕捉「随机事件」，往往都希望根据因果规律解释已发生的事情，而随机性可能会导致相同的事情总结出不同的规律（想象有一个平行世界发生了相同的事情，但是结果不同，那么总结出来的规律也会不一样），这也是《黑天鹅》中提到的“叙述谬误”的现象</p>
<p>（2）用于预测的信息也不客观；作出预测需要信息，信息本身是客观的，但是每个人接收信息的方式并不客观，亦即“一千个人眼里就有一千个哈姆雷特”；我们听到的信息都是经过我们大脑加工的，往往会带上我们的个人偏好和特性</p>
<p>（3）未来充满不可预期的随机事件；这个比较好理解，不确定性四部曲以及整篇文章就是在阐述这种现象</p>
<p>针对上面的三个问题，文章也分别给了一些方法</p>
<p>（1）总结出来的规律并不靠谱-&gt;
<strong>运用尽量少的规律，并且这些规律最好是普世的、第一性的、经过长时间考验的；</strong>
（2）用于预测的信息也不客观-&gt;去除
Ego，尽可能客观地去收集和看待信息，排除人为干扰；这个跟纳瓦尔宝典里提到的
“<strong>Shed your Identity to see reality</strong>”说的是同一件事
（3）未来充满不可预期的随机事件-&gt;有足够的容错性，对各种随机事件的发生做好准备</p>
<p>这里着重讲一下第 1 点，也是笔者认为比较重要的一样，这里提到的方法跟
<a href="https://en.wikipedia.org/wiki/First_principle">First
principle</a>
很相似，其思想都是从事情的本质上去思考，仅从一些最简单的规律(“cannot be
deduced from any other proposition or assumption”)去推导，这里有一个关于
Frist Principle 的例子，<a
href="https://zhuanlan.zhihu.com/p/80699627">首要原则（First Principles
Thinkings）：埃隆·马斯克谈为自己思考的力量</a></p>
<p>而回到投资里的不确定性，文章给出的方法论跟上面提到的基本原理是一样的
&gt;
从最基本的一些普世规律和常识出发，打造一套自己的「投资系统」，并且对未来各种「随机事件」做好充分的准备，不会死。用系统去根据市场的信息做出「应对」，不断迭代升级,循环往复</p>
<h3 id="祸福相依">祸福相依</h3>
<p>祸兮福之所倚，福兮祸之所伏；很多事情都是祸福相依的；往往黑天鹅事件是以危机形式展现，但危中有机，危后出机，最大的危机会出现最大的暴跌，也就会形成最好的投资良机，黑天鹅的序中提到了：<strong>正确的策略应该是尽可能多地尝试和尽可能多地把握黑天鹅机会</strong></p>
<p>当然，这个事情说起来是这么个道理，但实践起来会很难，就拿投资来说，你永远无法预估到绝对的底在哪里，且往往这种黑天鹅事件出现时，意味着我们相信的很多法则都会消失，这个时候根据历史经验做判断可能是行不通的；更重要的是，在黑天鹅事件发生后，人和市场都是很容易出现恐慌的，这种情况下无法预估到底加上恐慌，很容易让我们成为割肉逃跑而不是逢低加仓的人</p>
<p>比如说 08
年的次贷危机，虽然惨烈，但的确有人从中获利了，这也正是电影《大空头》讲到的故事；但需要意识到，《大空头》中也存在着幸存者偏差，我们看到的是成功做空获利的几个例子，但其中做了同样的事情却最终失败了的，不会有人感兴趣，因为我们都喜欢听成功的故事，都崇拜以一己之力获胜的英雄主义；关于这部分可参考：<a
href="https://www.zhihu.com/question/39528631/answer/95594954">如何评价电影《大空头》（The
Big Short）？</a></p>
<p>除了在黑天鹅中看到机会，日常还可以尽量做一些<strong>高杠杆</strong>的事情，即一些成本很低，但是成功了能够给你带来较大回报的事情；比如说<a
href="https://www.zhihu.com/topic/20014871/hot">无风险套利</a>，当然这种事情都是可遇不可求的</p>
<p>往往风险和收益是正相关的，为什么能捕获风险低但收益高的事情？《<a
href="https://zhuanlan.zhihu.com/p/148518267">在黑天鹅频发的年代，重读塔勒布的四本书</a>》给了一个可供参考的解释，即也风险和收益的正相关只是在期望上成立，<strong>现实世界中每次事件的风险和收益都是在期望上线波动，如果能够找到风险低于期望，但收益高于期望的事情</strong>；但这种事情往往发生的概率会很低</p>
<p>上面其实是一个期望与概率的例子，关于这点可以延伸说说，上面提到的观点是要<strong>捕获概率低但收益高的事情</strong>；而在后面的《反脆弱》的策略更多的提到了要关注期望而不是概率：<strong>买卖不应取决于股票上涨概率，而应取决于上涨期望</strong>。比如有90%的可能上涨1元，有10%的可能下跌100元，那么期望是下跌1元，应该卖空，而非买入。这里提到的<a
href="https://zhuanlan.zhihu.com/p/349095824">例子</a>跟反脆弱中的观点也是类似</p>
<blockquote>
<p>如果人生会重复一万次，牙医在每次“人生”中都很有可能过上富裕的生活，而靠中彩票大奖过上富裕生活的流浪汉，却很难再中一次大奖。因此，不能纯以是否富有的结果导向来对人进行评价。可以将人生的种种可能看作是一种分布，现在当下发生的只是这个分布的一个抽样。牙医人生的整体分布更优于流浪汉，即使流浪汉偶尔中了一次超级大奖，但对人生的整体分布影响不大</p>
</blockquote>
<p>两个观点看似矛盾，但实则不是，笔者认为其中<strong>差异在于这些事件发生的次数</strong>；期望是经过多次
IID
的试验得到的一个值，或者说买卖次数要足够多，这条定理才成立；而黑天鹅时间往往是稀有的，期望在其中也许并不成立，但交易是会发生多次的；所以结论也就很明显了，</p>
<h3 id="保持冗余">保持冗余</h3>
<p>这部分也很好理解，也是我们常说的鲁棒性或健壮性（robustness），比如说在工程上留出足够的
buffer，预防低概率事件发生，以及永远不要 all
in，无论是在投资还是生活，都要尽量给自己留一条后路</p>
<p>这部分涉及到反脆弱中的一些观点的，其中最令人深思的是：“<strong>系统的反脆弱性是通过牺牲个体为代价取得的</strong>”，这句话可以解释很多现象</p>
<p>回到与所有人都息息相关的日常工作中，这篇文章提出了一些比较有趣的观点，<a
href="https://zhuanlan.zhihu.com/p/79042586">反脆弱：为什么稳定的工作，只是一种人生的幻觉</a></p>
<blockquote>
<p>一个国家是如何渡过经济衰退期的呢？是靠死掉一大批没有竞争力的企业，让坚持下来的公司减少竞争对手
“人力资源市场”的“反脆弱性”也是如此：经济衰退期，淘汰一批没有竞争力的人，让留下来的人更容易找到工作；经济过热期，淘汰掉一批给不起高薪的企业，让给得起高薪的企业更容易找人。
<strong>“反脆弱性”会牺牲一部分最脆弱的人的利益，来提高整个系统的生存资源的利用效率，而这正是“35岁现象”的本质，因为某些凭借年龄获得优势的行业与职业，一过35岁，脆弱性会大大增加</strong></p>
</blockquote>
<p>那大公司的稳定性从何而来？</p>
<p>系统的反脆弱性是通过牺牲个体为代价取得的，大公司之所以稳定，是因为“体系至上、公司文化至上、业务至上”，任何一个员工的利益都无足轻重，随时可以被牺牲掉，在巨大的危机面前，就算是CEO也可以牺牲</p>
<p>对个人来说，致命的是“大公司稳定幻觉”，让你陷入舒适，从而忽视了为自己建立“反脆弱结构”；这种工作造成的稳定性的幻觉，就像火鸡，它们活的时间越长，就越“确信”农场主的仁慈，直到感恩节来临的那一天</p>
<p>保持冗余，本质也是反脆弱，不要 all in
一件事情，多为自己留一些后路，至于具体的方法和途径真的是因人而异了，毕竟这些也都是比较耗心力的事情，但本质还是要
productize yourself</p>
<h3 id="不要负债">不要负债</h3>
<p>套用塔勒布的原话是这么说的，“有一条是对于个人和机构非常重要的戒律：我们可以降低经济生活中90%的黑天鹅风险……我们所做的只是取消投机性的债务。”</p>
<p>这里的<strong>投机性的债务</strong>没有一个明确的定义，笔者猜测这里指的是类似
08 年次贷危机的那种炒房式的负债</p>
<p>房子在各个国家好像都会被当做金融工具，也的确其中有人会赚得盆满钵满，但需要清楚，你进去的时候是否会是最终的接盘侠</p>
<h2 id="小结">小结</h2>
<p>说实话，看完这两本总感觉比较反人性，因为人性就是希望事情都是可总结可解释的，包括笔者在写这篇文章，做的事情就是总结塔勒布这几本书的内容，期待从中获取一些可指导生活的规律和原理</p>
<p>但无论是《随机漫步的傻瓜》还是《黑天鹅》，都在告诉我们很多事情都是无法预测的，我们从历史获取的是无关痛痒，甚至是危险的信号；我们看到的很多成功也都是幸存者偏差，是运气和因果性共同主导的结果，且往往运气占了大头</p>
<p>如同开头所说，仅仅看到未来无法预测这一面，有时候会让人更绝望，很容易陷入虚无主义中，因为没什么是确定的，或者说没什么是能够坚信的，因为随机性几乎主导了一切；而我们，就是在其中随机漫步的傻瓜</p>
<p>既然生活的随机性的影响可能要远远大于努力，为什么还要努力？</p>
<p>因为在努力还没达到一定程度前，我们连面对随机性的机会都没有，或者说幸存者偏差也是有门槛的，当你的能力不足时，进入决赛圈的资格都没有</p>
<p>而面对随机性，书里这 5
条原则也许值得我们参考与实践：1.不要预测；2.谨慎预防；3.危中取机；4.保持充足冗余；5.不要负债</p>
<p>写到这里，好像隐约读懂了罗曼罗兰的那句“世上只有一种真正英雄主义，那就是在认清生活的真相后仍然热爱它”；虽然“生活的真相”有很多种，生活充满了随机性或许也是其中一种，在了解这个真相后仍然能够“尽人事，听天命”，认认真真把手上的每件事情做好，也许就是一个清醒的傻瓜</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>修改Linux主机名</title>
    <url>/2015/10/23/%E4%BF%AE%E6%94%B9Linux%E4%B8%BB%E6%9C%BA%E5%90%8D/</url>
    <content><![CDATA[<p>修改Linux主机可分为临时修改和永久修改</p>
<span id="more"></span>
<ul>
<li><p>临时修改：通过<code>hostname NewHostName</code>命令临时修改，修改后通过<code>exit</code>注销后重新登录就可以在命令提示符看到新的主机名称，但是重启后会失效</p></li>
<li><p>永久修改：修改配置文件<code>/etc/sysconfig/network</code>中的<code>HOSTNAME</code>项，<strong>修改后需要重启才能生效</strong>。</p></li>
</ul>
<p>另外一个与主机名相关的配置文件是<code>/etc/hosts</code>,但是这个文件与本机的主机名无关，一般是用来记录网络上<strong>其他主机的ip和主机名的对应关系</strong>，其作用有点像本地的DNS服务器。</p>
<p>比如说本机没有配置DNS服务器，与本机在同一个局域网的一台名为<code>memcached</code>的主机的ip是192.168.0.23，那么此时本机输入命令<code>ping  192.168.0.23</code>能够ping通这个ip，但是如果<code>ping memcached</code>则ping不通了，因为本机不知道<code>memcached</code>这台主机的ip是多少，同时也无法向DNS查询。这时可以在本机的<code>/etc/hosts</code>文件中添加这样一行
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.0.23  memcached</span><br></pre></td></tr></table></figure>
表示这个ip和这个主机名的对应关系。然后再ping主机memcached就可以ping通了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>先验概率，后验概率，共轭分布与共轭先验</title>
    <url>/2017/01/08/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%EF%BC%8C%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%EF%BC%8C%E5%85%B1%E8%BD%AD%E5%88%86%E5%B8%83%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/</url>
    <content><![CDATA[<p>本文主要讲述先验概率，后验概率，共轭分布和共轭先验这几个概念。</p>
<span id="more"></span>
<p>众所周知，概率论中有两大学派：频率学派和贝叶斯学派。<strong>先验概率，后验概率，共轭分布和共轭先验是贝叶斯学派中的几个概念。原因是贝叶斯学派认为分布存在先验分布和后验分布的不同，而频率学派则认为一个事件的概率只有一个</strong>。</p>
<p>下面先以一个直观的例子来说明先验概率和后验概率的概念</p>
<p>比如说，你来到一个山洞,这个山洞里可能有熊也可能没有熊,
记你觉得山洞有熊的为事件 <span class="math inline">\(Y\)</span>.
然后,你也许听到山洞里传来熊的吼声, 记听到熊吼声为事件 <span
class="math inline">\(X\)</span>. 你一开始认为山洞有熊的概率是 <span
class="math inline">\(P(Y)\)</span>; 听到熊的吼声之后,你认为有熊的概率是
<span class="math inline">\(P(Y|X)\)</span>。在这里，<span
class="math inline">\(P(Y)\)</span>就是先验概率,<span
class="math inline">\(P(Y|X)\)</span>是后验概率.</p>
<p>回到概率论中一个经典的例子:抛硬币。抛硬币时抛出正面的概率为多大？假如事前关于这枚硬币没有任何额外信息，那么一般都会认为是
1/2，这时候的 1/2 就是正面朝上的先验概率
。但是在经过一系列实验确认后再得到的正面朝上的概率很可能就不是1/2了(受到到硬币的质地，重量分布等因素的影响)，这个概率便是后验概率。</p>
<p>简单理解就是<strong>在事件发生之前，根据以往的经验推测的与该事件相关的概率就是先验概率，而在事件(试验)真正发生后，通过事件(试验)的结果可以修正先验概率，从而得到后验概率。</strong></p>
<p>那么对于抛硬币这个事件来说，<strong>抛出正面硬币的概率就应该是一个概率的概率，也就是说它的结果不是一个单一的值
1/2，而是一个概率分布，可能有很高的概率是1/2，但是也有一定的概率是100%（比如抛100次结果还真都100次都是正面）</strong>。那么在这里<strong>这个概率的分布用函数来表示就是一个似然函数</strong>，所以似然函数也被称为“分布的分布”。用公式来表示就是：</p>
<p>**后验概率（posterior probability）∝ 似然函数（likelyhood
function）*先验概率（prior probability）**</p>
<p>即：</p>
<p><span class="math inline">\(P(X|D) ∝ P(μ|D)*P(X)\)</span></p>
<p>这里 <span class="math inline">\(D\)</span>
表示一组观测实验(比如我扔了五次硬币得到5次正反面的结果)，<span
class="math inline">\(X\)</span>
表示随机变量（在这里是硬币的正反面），表示随机函数里面的参数（在这里就是硬币掷为正面的概率）。</p>
<p>注意这里是正比于而不是等于，这个是理解似然函数的一个关键，右侧直接的乘积其实是不满足概率分布归一化的条件的（就是右侧的积分最后不会等于1）那么这个正比符号怎样才能变成等号呢？其实只要再除以一个系数进行归一化就可以了：</p>
<p><span class="math inline">\(P(X|D) =P(μ|D)*P(X)/P(D)\)</span></p>
<p>这个归一化的系数是怎么来的呢？让我们回忆一下贝叶斯公式：</p>
<p><span class="math inline">\(P(X|D)*P(D)=P(XD)\)</span></p>
<p>而<span
class="math inline">\(P(μ|D)=P(D|X)\)</span>(似然函数在计算时的做法就是将D的观察结果代入P(X)的分布式子中去得到的)</p>
<p>于是</p>
<p><span
class="math inline">\((P(μ|D)/P(D))\*P(X)=P(D|X)\*P(X)/P(D)=P(XD)/P(D)=P(X|D)\)</span></p>
<p><strong>似然函数的形式是依赖于观测值的</strong>，它在贝叶斯学派与频率学派都有很大的作用，不过在两家的用法并不相同。</p>
<p><strong>频率学派认为每个事件的概率是一个客观存在的常数值，只是我们不知道而已</strong>。比如抛硬币，在实验估计之前我们不知道它是多少，频率学派也不会管之前大家说抛硬币出现正面的概率是1/2还是多少，所谓“眼见为实，耳听为虚”，他们的<strong>最终结论只和在实验中观测到的数据有关系</strong>。但是它肯定是一个确定的常数，然后我们通过观察实验，获得一组样本值
<span class="math inline">\(D\)</span>，再将这组样本值代入似然函数 <span
class="math inline">\(P(D|X)\)</span>
，求解使得似然函数最大的值就是估计出来的（当然由于实验的结果不同，这个估计出来的也很可能不是1/2，实验不同得到的结果也不同，但是根据大数定律，理论上实验次数足够多以后，求出来的是会越来越接近真实的概率的）。也就是说<strong>频率学派认为答案只有一个，我们不断地通过各种估计法来猜测这个值。</strong></p>
<p>而贝叶斯学派并不会完全拒绝大家之前所说的“硬币扔出正面的概率是1/2”的说法，只是<strong>贝叶斯学派认为最终硬币扔出正面反面的概率并不是一个常数值，不是一个有唯一答案的真理，这个值本身应该也是一个随机变量</strong>，是在不断变化的一个数值，如何得到这个值，<strong>贝叶斯学派认为也需要通过实验在“硬币扔出正面的概率是1/2”的说法（先验概率）的基础上通过实验数据（似然函数）不断去预估这个扔出正面概率的实际分布（后验分布）。</strong></p>
<p>举个例子：假如我扔了5次硬币，先出现了3次正面，后出现了两次反面，那么这时的似然函数就应该是
<span
class="math inline">\(P(μ|D)=P(D|X)=L(μ)=μ\*μ\*μ\*（1-μ）\*（1-μ）\)</span>
(<span class="math inline">\(\mu\)</span>
是硬币抛正面的概率，在似然函数里就相当于概率分布函数里的随机变量一样变成一个随机变化的值了）</p>
<p>如果用我们以前统计课本上的频率学派的最大似然估计法，对<span
class="math inline">\(L(μ)\)</span>求导求最大值，得到 <span
class="math inline">\(μ=3/5\)</span>，
那么得出结论就是最后抛硬币为正面的概率就是
3/5，当然还要附上一个参数估计的置信度，表示这个结论自然不是100%准确的</p>
<p>但是如果采用贝叶斯学派的后验概率<span class="math inline">\(P(X|D) =
P(D|X)\*P(X)/P(D)=L(μ)\*P(X)/P(D)\)</span>，</p>
<p>其中 <span class="math inline">\(P(D)\)</span>
可以简单地由古典概型算出来：<span
class="math inline">\(P(D)=1/=1/32=0.03125\)</span>。如果 <span
class="math inline">\(μ\)</span> 取了
3/5，代入上式那么抛硬币为正面的概率就是
0.55296，而不是1/2，当然<strong>贝叶斯学派最终得到的后验概率是一个随
<span class="math inline">\(μ\)</span>
变化的分布，只不过在这种情况这个分布取到 0.55296
这个值的概率最大而已</strong></p>
<p>清楚似然函数、先验概率、后验概率的几个贝叶斯学派的基本概念，要明白共轭分布和共轭先验就很简单了，所谓<strong>共轭分布就是先验概率和后验概率具有一样函数形式的分布形式</strong>，举个例子就是假如先验分布函数是形如
<span class="math inline">\(C_1\mu^a (1-\mu)^b\)</span>
的形式（比如二项分布就是这种形式）而后验分布是 <span
class="math inline">\(C_2\mu^m (1-\mu)^n\)</span>
这样的形式，两者只是具体参数值不同，或者先验分布和后验分布都是高斯分布等等的情形就可为认为先验分布和后验分布具有同样的形式。</p>
<p><strong>这种形式不变的好处是，我们能够在先验分布中赋予参数很明确的物理意义，这个物理意义可以延续到后验分布中进行解释，同时从先验变换到后验的过程中从数据中补充的知识也容易有物理解释。同时能够后验分布和先验分布共轭的情况下是可以大大简化计算量。</strong></p>
<p>那么共轭先验又是什么概念呢？因为在现实建模问题中，往往我们<strong>先得到和固定的反而是似然函数</strong>（其实也很好理解，客观的实验观察数据才是第一手最solid的材料），这时先验函数（可以理解为先验知识或者是对后验分布的一种假设和猜测）是可以选择的。这时如果我选的先验分布最后乘上这个似然函数，使得后验分布与先验分布共轭，那么我们就称这个<strong>先验函数为似然函数的共轭先验</strong>。基于上面说到的共轭分布的好处，往往选择先验函数时都会让先验概率分布和后验概率分布共轭。</p>
<p><a href="http://blog.huanghao.me/?p=250">共轭分布与共轭先验</a> <a
href="https://www.zhihu.com/question/22905989/answer/25679831">条件概率和后验概率有什么不同？</a></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>共享键鼠神器 Synergy</title>
    <url>/2018/03/31/%E5%85%B1%E4%BA%AB%E9%94%AE%E9%BC%A0%E7%A5%9E%E5%99%A8%20Synergy/</url>
    <content><![CDATA[<p>最近需要频繁切换使用台式机和笔记本，但是我的小桌子上实在没法同时放得下一个键盘和笔记本
（≧0≦）。哪怕凑合挤下，还得不停在两台电脑之间切换键鼠，因此就想着有没有共享键鼠的方案，结果在网上找到了
<a
href="https://symless.com/synergy">Synergy</a>，试了几天后发现这真的是一个共享键鼠的神器。</p>
<span id="more"></span>
<h2 id="安装与配置">安装与配置</h2>
<p>这个软件在2.0版本前支持自己编译的免费模式的，核心源码见<a
href="https://github.com/symless/synergy-core">github</a>，官方还贴心地提供了各种操作系统下编译的文档:)，这里编译出来的是
stable 版本，如果还需要更高级功能，可以去官网上购买 pro
版本支持一下。网上已经有雷锋帮我们编译了若干个 stable
version，详见下面链接</p>
<blockquote>
<p>https://www.brahma.world/synergy-stable-builds/</p>
</blockquote>
<p>这个软件的工作模式采用 Client-Server 模式，只允许有一台
Server，但是可有多台client，且只需要在 Server
端配键鼠就行了。我这里以笔记本为server，台式机为client，注意 Server 和
Client 应该在同一局域网内</p>
<h3 id="server">Server</h3>
<p>Server 端的配置过程如下</p>
<p>首先在下图点击<code>设置服务器</code></p>
<figure>
<img src="https://wulc.me/imgs/server_stat.png"
alt="server_stat.png-87.8kB" />
<figcaption aria-hidden="true">server_stat.png-87.8kB</figcaption>
</figure>
<p>出现下图后从右上角将电脑图标拖入网格内，有几台clinet就拖几台，然后进行命名（下图我拖了一台client
并命名为 435LC）这里的命名保持和客户端一致即可。</p>
<figure>
<img src="https://wulc.me/imgs/server.png" alt="server.png-53.7kB" />
<figcaption aria-hidden="true">server.png-53.7kB</figcaption>
</figure>
<h3 id="client">Client</h3>
<p>首先要勾选 client 的选项，并输入上图的 Server
的IP，然后需要在编辑中设置屏幕名与 Server
中的屏幕名一致，接着点击启动即可，下面的console 会输出相应的 log
信息</p>
<figure>
<img src="https://wulc.me/imgs/image_1c9tm4g7acg5k0pph1fdt16061p.png"
alt="client" />
<figcaption aria-hidden="true">client</figcaption>
</figure>
<p>通过这种方式就能够愉快地通过笔记本的键盘和触摸板来控制其他电脑了。</p>
<h2 id="修改快捷键">修改快捷键</h2>
<p>由于笔记本是 mbp，所以复制粘贴用的是 command+c/v, 跟 Windows
的ctrl+c/v 不一样，切换的时候经常搞错，因此这里将 mbp 复制粘贴也改成
ctrl+c/v</p>
<p>如下是打开系统偏好设置-&gt;键盘后的界面，通过 +
号添加相应的快捷键即可</p>
<figure>
<img src="https://wulc.me/imgs/key_binding.png" alt="key binding" />
<figcaption aria-hidden="true">key binding</figcaption>
</figure>
<p>需要注意的是上面的<strong>快捷键的名称需要与你系统保持一致</strong>，具体可通过任意窗口的菜单中的编辑项查询，如下就是我所用的
mbp 的一个快捷键的名称，比如撤消不能写成撤销，否则快捷键不生效。</p>
<figure>
<img src="https://wulc.me/imgs/keyname.png" alt="key name" />
<figcaption aria-hidden="true">key name</figcaption>
</figure>
<h2 id="文件传输">文件传输</h2>
<p>有时候还需要在两台主机上传输一些文件，Synergy
的普通版本不支持这种粘贴复制的传输，但是 pro
版本支持。我这边找不到pro版。。。。。。但是因为我经常要用到 FTP
传输文件， windows 装了 FileZilla 这个FTP 客户端，所以我直接在 windows
上通过 FTP 连到 mbp 上进行传输，在大文件的传输上速度也有保证。</p>
<p>最后祭上一张我的工作台的图片，不得不说 mbp
的触摸板就是好用，有效预防鼠标手 ～(￣▽￣～)(～￣▽￣)～</p>
<figure>
<img src="https://wulc.me/imgs/image_1c9tnc61g13g21jab9dpvp1lau26.png"
alt="work desk" />
<figcaption aria-hidden="true">work desk</figcaption>
</figure>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>关键词抽取算法的研究</title>
    <url>/2016/05/28/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<p>关键词抽取的一般步骤为：</p>
<p><strong>分词--&gt;过滤停止词,得到候选关键词--&gt;从候选关键词中选出文章的关键词</strong></p>
<p>从候选关键词中选出文章的关键词需要通过关键词抽取算法实现，而关键词抽取算法可以根据是否需要人工标注的语料进行训练而分为有监督的提取和无监督的提取。
<span id="more"></span>
有监督的提取需要人工标注的语料进行训练，人工预处理的代价较高。而无监督的抽取算法直接利用需要提取关键词的文本即可进行关键词的提取，因此适用性较强。</p>
<p>关键词抽取中无监督的抽取算法可分为三大类：
1）基于统计特征的，如TF-IDF 2）基于词图模型的，如TextRank
3）基于主题模型的，如LDA</p>
<p><strong>本文主要讲述TF-IDF算法、TextRank算法、以及通过组合两者得到的三种新方法，然后通过Java实现这几种方法并比较这几种方法在特定语料库上进行关键词抽取的效果。</strong></p>
<h2 id="tf-idf算法">TF-IDF算法</h2>
<p>TF-IDF（Term Frequency-Inverse Document
Frequency）算法是一种基于统计特征的非常经典的算法，通过计算一个词的TF值和IDF值的乘积作为该值的得分，然后根据得分从大到小对词语排序，选择分数高的词语作为关键词。</p>
<p>TF值指词语在文本中出现的频率，如某篇文章分词并过滤停止词后的词语的数量为n，而其中的某个词语w出现的个数为m,则词w的TF值为
<!--$$TF(w)=\frac{m}{n}$$--></p>
<p><img src="https://wulc.me/imgs/TF.png" /></p>
<p>IDF值则指词语在整个语料库中的出现的频率大小。这里首先要指出的是TF-IDF算法是针对一个语料库（也就是多篇文档进行）进行关键词提取的算法。假如语料库中共有N篇文档，而出现了词语w的文档数为M。则词w的IDF值为
<!--$$IDF(w)=log_2\frac{N}{M}$$--></p>
<p><img src="https://wulc.me/imgs/IDF.png" /></p>
<p><span
class="math inline">\(TF(w)*IDF(w)\)</span>则为词w的TF-IDF值，根据这个值对候选词从大到小排序，选择前n个作为候选关键词即可。</p>
<p>通过Java的实现并不难，主要是利用Java的集合框架Map、List等存储词语的中间得分、以及候选关键词等。</p>
<p>实现的完整代码见:
https://github.com/WuLC/KeywordExtraction/blob/master/src/com/lc/nlp/keyword/algorithm/TFIDF.java</p>
<h2 id="textrank算法">TextRank算法</h2>
<p>TextRank算法是借鉴PageRank算法在语言处理中的一个算法，关于PageRank算法可参考<a
href="http://blog.csdn.net/hewei0241/article/details/8276029">这篇文章</a>。无论是PageRank还是TextRank，其关键思想都是<strong>重要性传递</strong>。</p>
<p>以PageRank为例，假如一个大型网站有一个超链接指向了某个小网站，那么小网站的重要性会上升，而上升的量则依据指向它的大网站的重要性。下图所示的就是一个例子：</p>
<p><img src="https://wulc.me/imgs/pagerank.png" /></p>
<p>假设网页A,B原来的重要性为100和9，那么根据他们指向的网页，传递给C、D的重要性分别为53和50。</p>
<p><strong>在TextRank中将上图的网页替换成词语，将网页间的超链接换成词语间的语义关系；假如两个词的距离小于预设的距离，那么就认为这两个词间存在语义关系，否则不存在。这个预设的距离在TextRank算法中被称为同现窗口（co-occurance
window）。这样便可构建出一个词的图模型。</strong></p>
<p>但是在实际中应用时我们是无法预先知道网页A、B的重要性的，又或者说假如我们已经知道了网页的重要性，那么也不需要通过算法计算出网页的重要性了。这就成了一个先有鸡还是先有蛋的问题。</p>
<p>PageRank的原始论文提出了解决这个问题的方法，<a
href="http://blog.csdn.net/hewei0241/article/details/8276029">这篇文章</a>中通过具体的例子提到了相关的理论依据，就是<strong>幂法求特征向量与初始值无关</strong>。具体做法就是，先给每个网页随机附一个初值，然后通过迭代计算直至收敛，理论证明了收敛的值与初始值无关。</p>
<p>同样的，TextRank也采取了相同的方法，就是先随机赋初值，然后通过迭代计算得到每个
词的重要性的得分。词语<span
class="math inline">\(V_i\)</span>的得分计算公式如下所示：</p>
<p><img src="https://wulc.me/imgs/TextRank.png" /></p>
<p>上式中各符号表示如下</p>
<p><img
src="https://wulc.me/imgs/image_1ajqme4gn17a515dg1oqhgja1h0m1f.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1ajqm7ppj1bu51s0m191s10i2tvol.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1ajqmcc9o13pkdiktru1momi2j12.png" /></p>
<p><strong>实现的一个关键点在于构建词的图模型</strong>，在Java中通过队列实现，队列大小即为同现窗口的大小，移动队列的过程中将队列内部的词语互相连接。连接的形式通过java的<code>Map&lt;String,Set&lt;String&gt;&gt;</code>类型实现，表示指向词语（第一个String）的所有其他词语（<code>Set&lt;String&gt;</code>）的实现的关键代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, Set&lt;String&gt;&gt; words = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, Set&lt;String&gt;&gt;();</span><br><span class="line">Queue&lt;String&gt; que = <span class="keyword">new</span> <span class="title class_">LinkedList</span>&lt;String&gt;();</span><br><span class="line"><span class="keyword">for</span> (String w : wordList) <span class="comment">//wordList为候选关键词</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="keyword">if</span> (!words.containsKey(w))</span><br><span class="line"> &#123;</span><br><span class="line">     words.put(w, <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;String&gt;());</span><br><span class="line"> &#125;</span><br><span class="line"> que.offer(w);    <span class="comment">// 入队</span></span><br><span class="line"> <span class="keyword">if</span> (que.size() &gt; coOccuranceWindow)</span><br><span class="line"> &#123;</span><br><span class="line">     que.poll();  <span class="comment">// 出队</span></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span> (String w1 : que)</span><br><span class="line"> &#123;</span><br><span class="line">     <span class="keyword">for</span> (String w2 : que)</span><br><span class="line">     &#123;</span><br><span class="line">         <span class="keyword">if</span> (w1.equals(w2))</span><br><span class="line">         &#123;</span><br><span class="line">             <span class="keyword">continue</span>;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         words.get(w1).add(w2);</span><br><span class="line">         words.get(w2).add(w1);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>另外一个实现关键点就是判断算法是否收敛</strong>，可以认为前后两次计算出来的值小于指定的阈值（一般取值较小，如0.000001）时算法收敛，或者超过设定的最大迭代次数时停止。实现的关键代码如下所示：
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">min_diff = <span class="number">0.000001</span></span><br><span class="line">Map&lt;String, Float&gt; score = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, Float&gt;();</span><br><span class="line"> <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; max_iter; ++i)</span><br><span class="line"> &#123;</span><br><span class="line">     Map&lt;String, Float&gt; m = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, Float&gt;();</span><br><span class="line">     <span class="type">float</span> <span class="variable">max_diff</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">     <span class="keyword">for</span> (Map.Entry&lt;String, Set&lt;String&gt;&gt; entry : words.entrySet())</span><br><span class="line">     &#123;</span><br><span class="line">         <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> entry.getKey();</span><br><span class="line">         Set&lt;String&gt; value = entry.getValue();</span><br><span class="line">         m.put(key, <span class="number">1</span> - d);</span><br><span class="line">         <span class="keyword">for</span> (String other : value)</span><br><span class="line">         &#123;</span><br><span class="line">             <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> words.get(other).size();</span><br><span class="line">             <span class="keyword">if</span> (key.equals(other) || size == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">             m.put(key, m.get(key) + d / size * (score.get(other) == <span class="literal">null</span> ? <span class="number">0</span> : score.get(other))); </span><br><span class="line">         &#125;</span><br><span class="line">         </span><br><span class="line">         max_diff = Math.max(max_diff, Math.abs(m.get(key) - (score.get(key) == <span class="literal">null</span> ? <span class="number">1</span> : score.get(key))));</span><br><span class="line">     &#125;</span><br><span class="line">     score = m;</span><br><span class="line">     </span><br><span class="line">     <span class="comment">//exit once recurse</span></span><br><span class="line">     <span class="keyword">if</span> (max_diff &lt;= min_diff) </span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>完整的实现代码见：
https://github.com/WuLC/KeywordExtraction/blob/master/src/com/lc/nlp/keyword/algorithm/TextRank.java</p>
<h2 id="综合textrank-多同现窗口">综合TextRank 多同现窗口</h2>
<p>由于TextRank的同现窗口的大小会影响提取的效果，如下图是同现窗口为2~10的时候评估值为F1值的变化情况。（<a
href="https://github.com/iamxiatian/data/tree/master/sohu-dataset">测试语料</a>）</p>
<p><img
src="https://wulc.me/imgs/%E5%90%8C%E7%8E%B0%E7%AA%97%E5%8F%A3%E5%8F%98%E5%8C%96%E5%9B%BE.png" /></p>
<p>而原始的TextRank算法仅仅是建议该值设为2~10，无法知道对于一篇文章的最优同现窗口，因此本方法会综合TextRank多同现窗口的结果，将一个词语在不同大小的窗口下的得分相加，作为该词的总得分，然后根据总得分对词语排序，选择得分较高的前n个词作为候选关键词
。</p>
<p>该算法的效果与原始的TextRank算法的效果对比如下（<a
href="https://github.com/iamxiatian/data/tree/master/sohu-dataset">测试语料</a>）</p>
<p><img
src="https://wulc.me/imgs/%E5%90%8C%E7%8E%B0%E7%AA%97%E5%8F%A3%E5%8F%98%E5%8C%96%E5%9B%BE%28point%29.png" /></p>
<p>图中的<code>textrank</code>表示原始的TextRank算法的效果，而<code>multi_window_textrank</code>表示综合了大小为2~10的同现窗口的结果的效果。从图中可知，在提取关键词个数大于4个的时候，该方法的效果要优于原始的TextRank算法，但是F1值的提升幅度不大，并且实际运行的时候，综合多同现窗口的方法花费的时间是原始TextRank算法的14倍左右。</p>
<p>代码的具体实现见：
https://github.com/WuLC/KeywordExtraction/blob/master/src/com/lc/nlp/keyword/algorithm/TextRankWithMultiWin.java</p>
<h2 id="textrank-与-tf-idf-综合">TextRank 与 TF-IDF 综合</h2>
<h3 id="考虑词语的idf值">考虑词语的IDF值</h3>
<p>由于TextRank算法仅考虑文档内部的结构信息，导致一些在各个文档的出现频率均较高且不属于停止词的词语最总的得分较高。原因是没有考虑词语在整个语料库中的权重。因此在TextRank算法得到的每个词的得分基础上，乘上这个词在整个语料库的IDF值，IDF值是TF-IDF算法中的一个概念，该值越大，表示这个词在语料库中出现的次数越少，越能代表该文档。</p>
<p>将词语的TextRank得分乘上这个词的IDF值后作为该词的新得分，然后根据得分从大到小排序，选择得分高的前n个词作为关键词即可。</p>
<p>下面是考虑了词语的IDF值的方法与原始的TextRank算法的效果对比图（<a
href="https://github.com/iamxiatian/data/tree/master/sohu-dataset">测试语料</a>）</p>
<p><img src="https://wulc.me/imgs/textrank_idf%28point%29.png" /></p>
<p>从图中可知，考虑了词语的IDF值后的方法的效果要优于原始的TextRank算法，运行时间约为TextRank算法的两倍。</p>
<p>完整的代码实现见：
https://github.com/WuLC/KeywordExtraction/blob/master/src/com/lc/nlp/keyword/algorithm/TextRankWithTFIDF.java</p>
<h3 id="textrank与tf-idf投票">TextRank与TF-IDF投票</h3>
<p>这种方法也是针对TextRank算法仅考虑文档内部的信息而忽略了文档外部的信息，综合TextRank算法和TF-IDF算法提取出来的结果。</p>
<p>具体的流程为：确定要抽取的关键词个数n,通过TextRank算法和TF-IDF算法对语料库分别提取2n个关键词,选择同时在两个算法得到的结果中出现的词语作为关键词，假如同时出现的词语不足n个，那么剩下的词语从TextRank的结果或TF-IDF的结果中补。</p>
<p>下面是TextRank和TF-IDF投票方法的结果与原始的TextRank算法的结果的对比图（<a
href="https://github.com/iamxiatian/data/tree/master/sohu-dataset">测试语料</a>）</p>
<p><img src="https://wulc.me/imgs/textrank_tfidf%28point%29.png" /></p>
<p>从结果可知，两个算法综合投票的方法的效果要优于原始的TextRank算法。运行的时间约为原始的TextRank的两倍。</p>
<p>完整的代码实现见：
https://github.com/WuLC/KeywordExtraction/blob/master/src/com/lc/nlp/keyword/algorithm/TextRankWithTFIDF.java</p>
<h2 id="总结">总结</h2>
<p>本文主要讲述了TextRank算法以及对其进行简单改进的三种方法：综合多同现窗口的结果、考虑词语的IDF值、TF-IDF与TextRank共同投票。通过Java实现并比较其效果（评判指标为F1值）。下图是这几个算法的总效果对比图。（<a
href="https://github.com/iamxiatian/data/tree/master/sohu-dataset">测试语料</a>）</p>
<p><img src="https://wulc.me/imgs/summary%28points%29.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1ajqtflb2jjc10ihej11fs7133v9.png" /></p>
<p>综合多同现窗口的改进方案后的效果虽然要略优于原始的 TextRank
算法，但是消耗的时间是原始 TextRank 算法的 14 倍左右；综合 TextRank
算法和 TF-IDF 算法后的结果是改进算法后最优的，其次是考虑 TextRank
提取出的关键词的 IDF 值的改进方案，两者的效果均要优于原始的 TextRank
算法， 消耗的时间也比原始的 TextRank 算法要多。</p>
<p>因此，若需要<strong>对单篇文档提取的关键词时</strong>，可采用原始的TextRank算法或综合多同现窗口的方法，
假如对提取效果的要求较高且对时间要求不高时，可以采用综合多同现窗口的方法，
反之直接采用原始的TextRank算法。如果需要<strong>对多文档进行关键词抽取时</strong>，四种方法都可以采用，但是考虑提取的效果以及消耗的时间，
建议使用 TextRank 算法和 TF-IDF 算法综合投票的方法或 TextRank
结合IDF值的方法，并且根据着重点是时间还是提取的精度，选择 TF-IDF
算法综合投票的方法或 TextRank 结合 IDF 值的方法。</p>
<p>上文提到的所有代码的地址为：https://github.com/WuLC/KeywordExtraction
除了算法的实现，还包括了语料库的导入、F1值的计算方法的实现等。</p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>凸优化总结</title>
    <url>/2017/05/20/%E5%87%B8%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>之前曾写过一篇<a
href="http://wulc.me/2017/02/01/%E6%9C%80%E4%BC%98%E5%8C%96%E8%AE%A1%E7%AE%97%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/">最优化课程总结</a>，
涉及到的内容较多也较细。而在最优化中，凸优化是最为常见而又最为重要的，因为凸优化有一个良好的性质：<strong>局部最优是全局最优</strong>，这个性质使得我们不需要去证明解是否会收敛到全局最优，或者如何避免局部最优。因此凸优化有广泛应用，在优化问题不是凸的时候，往往也会尝试将其变为凸问题便于求解。本文着重讲凸优化，算是对之前写的文章的一个拓展和补充。</p>
<p>本文主要讲述下面内容，凸优化的概念以及凸优化中的三类常见解法：<strong>梯度类方法，对偶方法和ADMM方法</strong>。</p>
<span id="more"></span>
<h2 id="凸集凸函数与凸优化">凸集，凸函数与凸优化</h2>
<h3 id="凸集">凸集</h3>
<p>凸集的定义非常清楚</p>
<blockquote>
<p>对于集合 <span class="math inline">\(K\)</span> ，<span
class="math inline">\(\forall x\_1,x\_2 \in K\)</span>,若 <span
class="math inline">\(\alpha x\_1 + (1-\alpha)x\_2 \in
K\)</span>,其中<span class="math inline">\(\alpha \in [0,1])\)</span>,则
<span class="math inline">\(K\)</span> 为凸集</p>
</blockquote>
<p>即集合中任意两点的连线均在凸集中，如在下图中左边的是凸集而右边的不是</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgff3run1u5f8ivpt6tb19it9.png"
alt="凸集概念" />
<figcaption aria-hidden="true">凸集概念</figcaption>
</figure>
<p>有时候需要对某个凸集进行放缩转换等操作，对凸集进行以下操作后，得到的集合依然是凸集</p>
<ol type="1">
<li>凸集的重叠（intersection）部分任然为凸集</li>
<li>若 <span class="math inline">\(C\)</span> 为凸集，则 <span
class="math display">\[aC+b = \lbrace ax+b , x \in C, \forall a,
b\rbrace\]</span> 也为凸集</li>
<li>对于函数 <span class="math inline">\(f(x) = Ax+b\)</span>, 若 <span
class="math inline">\(C\)</span>
为凸集，则下面得到的转换也为凸集，注意这里的 <span
class="math inline">\(A\)</span> 是矩阵<span class="math display">\[f(C)
= \lbrace f(x):x\in C\rbrace\]</span> 而当 <span
class="math inline">\(D\)</span>
是一个凸集的时候，下面得到的转换也是凸集<span
class="math display">\[f^{-1}(D) = \lbrace x: f(x)\in
D\rbrace\]</span>这两个转换互为逆反关系</li>
</ol>
<p>常见的凸集有下面这些(下式中 <span class="math inline">\(a, x,
b\)</span> 均为向量, <span class="math inline">\(A\)</span> 为矩阵)</p>
<ul>
<li>点（point）、线（line）、面（plane）</li>
<li>norm ball: <span class="math inline">\(\lbrace x: ||x|| \le
r\rbrace\)</span></li>
<li>hyperplane: <span class="math inline">\(\lbrace x:
a^Tx=b\rbrace\)</span></li>
<li>halfspace: <span class="math inline">\(\lbrace x: a^Tx \le
b\rbrace\)</span></li>
<li>affine space: <span class="math inline">\(\lbrace x: Ax =
b\rbrace\)</span></li>
<li>polyhedron: <span class="math inline">\(\lbrace x: Ax &lt;
b\rbrace\)</span></li>
</ul>
<blockquote>
<p>polyheron 的图像为 <img
src="https://wulc.me/imgs/image_1bgfffffmlao1ka2l241maffrm.png"
alt="polhedron" /></p>
</blockquote>
<h3 id="凸函数">凸函数</h3>
<p>凸函数的定义如下</p>
<blockquote>
<p>设<span
class="math inline">\(f(x)\)</span>为定义在n维欧氏空间中某个凸集S上的函数，若对于任何实数<span
class="math inline">\(\alpha(0&lt;\alpha&lt;1)\)</span>以及S中的任意不同两点
<span class="math inline">\(x\)</span> 和 <span
class="math inline">\(y\)</span>，均有<span
class="math display">\[f(\alpha x+ (1-\alpha)y) \le \alpha f(x) +
(1-\alpha)f(y)\]</span>则称<span
class="math inline">\(f(x)\)</span>为定义在凸集 S 上的凸函数</p>
</blockquote>
<p>凸函数的定义也很好理解，任意两点的连线必然在函数的上方，如下是一个典型的凸函数</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgfgj5e31lhe1ti15q81t5fig613.png"
alt="凸函数" />
<figcaption aria-hidden="true">凸函数</figcaption>
</figure>
<p><strong>严格凸(strictly convex)与強凸(strongly convex)</strong></p>
<ul>
<li>严格凸指的是假如将上面不等式中的 <span
class="math inline">\(\le\)</span> 改为 <span
class="math inline">\(\lt\)</span>， 则称该函数为严格凸函数。</li>
<li>严格凸指的是<span class="math inline">\(\forall m &gt; 0, f -
\frac{m}{2}||x||\_2^2\)</span>
也是凸的，其含义就是该凸函数的“凸性”比二次函数还要强，即使减去一个二次函数还是凸函数</li>
</ul>
<p>凸函数有几个非常重要的性质，对于一个凸函数 <span
class="math inline">\(f\)</span>, 其重要性质 1.
<strong>一阶特性（First-order characterization）</strong>： <span
class="math display">\[f(y) \ge f(x) + \nabla f(x)(y - x)\]</span> 2.
<strong>二阶特性（Second-order characterization）</strong>： <span
class="math display">\[\nabla^2f(x) \succeq 0\]</span>这里的 <span
class="math inline">\(\succeq 0\)</span> 表示 Hessian 矩阵是半正定的。
3. <strong>Jensen不等式（<a
href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s
inequality</a>）</strong>：<span class="math display">\[f(E(x)) \le
E(f(x))\]</span>这里的 <span class="math inline">\(E\)</span>
表示的是期望，这是从凸函数拓展到概率论的一个推论，这里不详细展开。 4.
<strong>sublevel sets</strong>，即集合 <span
class="math inline">\(\lbrace x:f(x) \le t\rbrace\)</span>
是一个凸集</p>
<p>其中，<strong>一阶特性或二阶特性是一个函数为凸函数的充要条件，通常用来证明一个函数是凸函数。</strong></p>
<p>常见的凸函数有下面这些</p>
<ul>
<li>仿射函数( Affine function ): <span class="math inline">\(a^Tx +
b\)</span></li>
<li>二次函数( quadratic function),注意这里的 <span
class="math inline">\(Q\)</span> 必须为半正定矩阵: <span
class="math inline">\(\frac{1}{2}x^TQx + b^Tx+c(Q \succeq
0)\)</span></li>
<li>最小平方误差( Least squares loss ): <span
class="math inline">\(||y-Ax||\_2^2\)</span> (总是凸的，因为 <span
class="math inline">\(A^TA\)</span> 总是半正定的)</li>
<li>示性函数（Indicator function）：<span class="math display">\[I\_C(X)
= \begin{cases} 0&amp;x \in C\\\
\infty &amp; x \notin C\end{cases}\]</span></li>
<li>max function: <span class="math inline">\(f(x) = max \lbrace
x\_1,...x\_n \rbrace\)</span></li>
<li>范数（Norm）：范数分为向量范数和矩阵范数，任意范数均为凸的，各种范数的定义如下</li>
</ul>
<p><strong>向量范数</strong></p>
<blockquote>
<p>0范数：$||x||_0 $= 向量中非零元素的个数 1范数： <span
class="math inline">\(||x||\_1 = \sum\_{i=1}^n |x\_i|\)</span> <span
class="math inline">\(p\)</span> 范数：<span
class="math inline">\(||x||\_p = (\sum\_{i=1}^nx\_i^p)^{1/p}~~(p &gt;
1)\)</span> 无穷范数: <span class="math inline">\(||x||\_{\infty} =
max\_{i=1,...n} |x\_i|\)</span></p>
</blockquote>
<p><strong>矩阵范数</strong> &gt;核(nuclear)范数: <span
class="math inline">\(||X||\_{tr} = \sum\_{i=1}^{r}\sigma\_i(X)\)</span>
, (<span
class="math inline">\(\sigma\_i(X)\)</span>是矩阵分解后的奇异值,核范数即为矩阵所有奇异值之和)
&gt;谱（spectral）范数：<span class="math inline">\(||X||\_{op} =
max\_{i=1,...r}\sigma\_i(X)\)</span>, 即为最大的奇异值</p>
<h3 id="凸优化">凸优化</h3>
<p>对于下面的优化问题</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad f(x)\\\
&amp;\begin{array}\\\
s.t.&amp;g\_i(x) \le 0,~i=1,\ldots,m\\\
&amp;h\_j(x)=0,~j=1,\ldots,r
\end{array}
\end{align\*}
\]</span></p>
<p>当 <span class="math inline">\(f(x), g\_i(x)\)</span> 均为凸函数，
而<span class="math inline">\(h\_j(x)\)</span> 为仿射函数（affine
function）时，该优化称为凸优化,注意上面的 <span
class="math inline">\(\min\)</span> 以及约束条件的符号均要符合规定。</p>
<p>凸优化也可以解释为目标函数 <span class="math inline">\(f(x)\)</span>
为凸函数而起约束围成的可行域为一个凸集。</p>
<p>常见的一些凸优化问题有：<strong>线性规划（linear
programs），二次规划（quadratic programs），半正定规划（semidefinite
programs）</strong>，且 <span class="math inline">\(LP \in QP \in
SDP\)</span>, 即后者是包含前者的关系。</p>
<p>线性规划问题一般原型如下(<span
class="math inline">\(c\)</span>为向量，<span
class="math inline">\(D,A\)</span>为矩阵)</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad c^Tx\\\
&amp;\begin{array}\\\
s.t.&amp;Dx \le d\\\
&amp;Ax=b
\end{array}
\end{align\*}
\]</span></p>
<p>二次规划问题一般原型如下（要求矩阵 <span
class="math inline">\(Q\)</span> 半正定）</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad \frac{1}{2}x^TQx+c^Tx\\\
&amp;\begin{array}\\\
s.t.&amp;Dx \le d\\\
&amp;Ax=b
\end{array}
\end{align\*}
\]</span></p>
<p>而半正定规划问题一般原型如下(<span class="math inline">\(X\)</span>
在这里表示矩阵) <span class="math display">\[
\begin{align\*}
&amp;\min\_X\quad CX\\\
&amp;\begin{array}\\\
s.t.&amp;A\_iX \le b\_i, i=1,...m\\\
&amp;X \succeq 0
\end{array}
\end{align\*}
\]</span></p>
<h2 id="梯度类方法">梯度类方法</h2>
<p>梯度类方法是无约束优化中非常常用的方法，其依据的最根本的事实就是梯度的负方向是函数值下降最快的方向。但是常用的
<code>gradient descent</code>
必须要求函数的连续可导，而对于某些连续不可导的问题（如lasso
regression），<code>gradient descent</code>
无能为力，这是需要用到<code>subgradient descent</code>和<code>proximal gradient descent</code>.</p>
<h3 id="gradient-descent">gradient descent</h3>
<p>梯度下降法的迭代公式为 <span class="math display">\[x^{(k)} =
x^{(k-1)} - t\_k\nabla f(x^{(k-1)} )\]</span></p>
<p>上式中上标 <span class="math inline">\((k)\)</span> 表示第 <span
class="math inline">\(k\)</span> 次迭代, 而 <span
class="math inline">\(t\_k\)</span>表示步长，<span
class="math inline">\(\nabla f(x^{(k-1)} )\)</span>表示在点 <span
class="math inline">\(x^{(k-1)}\)</span> 的梯度。</p>
<p>这里对于梯度下降主要讨论其步长选择的问题，
最简单直接的方式是固定每次的步长为一个恒定值，但是如果步长过大或过小时，可能会导致结果难以收敛或者收敛速度很慢。因此提出了可变长步长的方法，可变长步长的方法指的是根据每次迭代依照一定的规则改变步长，下面介绍两种：<code>backtracking line search</code>
和 <code>exact line serach</code>。</p>
<p><strong>backtracking line search</strong></p>
<p>backtracking line search 需要先选择两个固定的参数 <span
class="math inline">\(\alpha, \beta\)</span>, 要求 <span
class="math inline">\(0 &lt; \beta &lt; 1,
0&lt;\alpha&lt;1/2\)</span></p>
<p>每次迭代的时候，假如下式成立</p>
<p><span class="math display">\[f(x - t\nabla f(x)) &gt; f(x) - \alpha
t||\nabla f(x)||\_2^2\]</span></p>
<p>则改变步长为 <span class="math inline">\(t = \beta t\)</span>,
否则步长不变。</p>
<p>这种方法的思想是当步长过大的时候(即跨过了最优点)，减小步长，否则保持步长不变，如下式是一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgidgkp7h8p1cg71gji1qfl9i9.png"
alt="backtracking line search" />
<figcaption aria-hidden="true">backtracking line search</figcaption>
</figure>
<p><strong>exact line serach</strong></p>
<p>exact line serach 则是得到先计算出梯度 <span
class="math inline">\(\nabla f(x^{(k-1)}
)\)</span>,然后代入下面的函数中，此时只有步长 <span
class="math inline">\(t\_k\)</span> 是未知，因此可对 <span
class="math inline">\(t\_k\)</span> 进行求导并令其为0，求得的 <span
class="math inline">\(t\_k\)</span>
即为当前的最优的步长，因为这个步长令当前迭代下降的距离最大。</p>
<p><span class="math display">\[f(x^{(k-1)} - t\_k\nabla f(x^{(k-1)}
))\]</span></p>
<p>这种方法也被称为最速下降法。</p>
<h3 id="subgradient-descent">subgradient descent</h3>
<p><strong>subgradient 可以说是 gradient
的升级版，用于解决求导时某些连续不可导的函数梯度不存在的问题</strong>，我们知道，对于可微的凸函数有一阶特性，即</p>
<p><span class="math display">\[f(y) \ge f(x) + \nabla^T f(x)(y -
x)\]</span></p>
<p>加入将上面的 <span class="math inline">\(\nabla^T f(x)\)</span> 换成
<span class="math inline">\(g^T\)</span> 且不等式恒成立，则 <span
class="math inline">\(g\)</span> 被称为 subgradient，当函数可微时，<span
class="math inline">\(\nabla f(x) = g\)</span>
，但是若函数不可微，subgradient
不一定存在，下面是几个特殊函数的subgradient例子。</p>
<p>对于函数 <span class="math inline">\(f(x) =
|x|\)</span>,其图像如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgii8g37ine1569fr97gd12881g.png"
alt="sub1" />
<figcaption aria-hidden="true">sub1</figcaption>
</figure>
<p>其subgradient为 <span class="math display">\[g = \begin{cases}sign(x)
&amp;x \neq 0\\\
[-1,1] &amp; x=0\end{cases}\]</span></p>
<p>对于函数 <span class="math inline">\(f(x) =
||x||\_2\)</span>,其图像如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgiiehmc19eb1j631gejubdc191t.png"
alt="sub2" />
<figcaption aria-hidden="true">sub2</figcaption>
</figure>
<p>其subgradient为 <span class="math display">\[g = \begin{cases}
x/||x||\_2&amp;x \neq 0\\\
\lbrace z: ||z||\_2 \le 1\rbrace &amp; x=0\end{cases}\]</span></p>
<p>对于函数 <span class="math inline">\(f(x) =
||x||\_1\)</span>,其图像如下</p>
<figure>
<img
src="https://wulc.me/imgs/image_1bgiiioee1oir157n1ij714db14982a.png"
alt="sub3" />
<figcaption aria-hidden="true">sub3</figcaption>
</figure>
<p>其subgradient为 <span class="math display">\[g = \begin{cases}
sign(x\_i) &amp;x\_i \neq 0\\\
[-1,1] &amp; x\_i=0\end{cases}\]</span></p>
<p>对于两个相交的函数 <span class="math inline">\(f(x) = \max \lbrace
f(x\_1), f(x\_2)\rbrace\)</span>,设其函数图像如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgiinl7i1ejimgncpdp0v13b62n.png"
alt="sub4" />
<figcaption aria-hidden="true">sub4</figcaption>
</figure>
<p>则其subgradient为<span class="math display">\[g = \begin{cases}
\nabla f(x\_1) &amp;f(x\_1) &gt; f(x\_2) \\\
\nabla f(x\_2) &amp;f(x\_1) &lt; f(x\_2) \\\
[\min \lbrace \nabla f(x\_1),\nabla f(x\_2)\rbrace, \max \lbrace \nabla
f(x\_1), \nabla f(x\_2)\rbrace] &amp;f(x\_1) = f(x\_2)\end{cases}
\]</span></p>
<p>而 subgradient descent 与 gradient descent
的不同地方就是当函数不可微的时候，将 gradient descent 中更新公式中的
gradient 换成 subgradient。下面看一个经典的
<code>lasso regression</code> 问题。</p>
<p><span class="math display">\[\min\_{\beta \in \mathbb {R}^n}
\frac{1}{2} ||y-\beta||\_2^2 + \lambda ||\beta||\_1~~(\lambda \ge
0)\]</span></p>
<p>对目标函数求导并令其为0，其中 <span
class="math inline">\(||\beta||\_1\)</span>
项不可导，用前面提到的subgradient代替，则有以下等式</p>
<p><span class="math display">\[\begin{cases} y\_i - \beta\_i = \lambda
sign(\beta\_i) &amp;\beta\_i \neq 0\\\
|y\_i - \beta\_i| \le \lambda &amp;\beta\_i = 0
\end{cases}\]</span></p>
<p>则解可表示成</p>
<p><span class="math display">\[\beta\_i = \begin{cases} y\_i - \lambda
&amp; y\_i &gt; \lambda\\\
0 &amp;-\lambda \le y\_i \le \lambda \\\
y\_i + \lambda &amp; y\_i &lt; -\lambda\end{cases}\]</span></p>
<p>上面实际上是简化了的 <code>lasso regression</code>，
因为更一般的lasso 问题表示如下</p>
<p><span class="math display">\[\min\_{\beta \in \mathbb {R}^n}
\frac{1}{2} ||y-X\beta||\_2^2 + \lambda ||\beta||\_1~~(\lambda \ge
0)\]</span></p>
<p>这时如果采用上面的解法，那么会得到</p>
<p><span class="math display">\[\begin{cases} X\_i^T(y - X\beta) =
\lambda sign(\beta\_i) &amp;\beta\_i \neq 0\\\
|X\_i^T(y - X\beta)| \le \lambda &amp;\beta\_i = 0
\end{cases}\]</span></p>
<p>上式并没有为这个 lasso
问题提供一个明确的解，这个问题可以通过下面要提到的 proximal gradient
进行求解，但是上面的式子一定程度上解释了<code>L1 regularization</code>的导致的参数的稀疏性的特点，从上面的表达式可知，只有当
<span class="math inline">\(X\_i^T(y - X\beta) = \lambda
sign(\beta\_i)\)</span> 时，对应的 <span
class="math inline">\(\beta\_i\)</span> 才不为0，而其他大多数的情况下
<span class="math inline">\(\beta\_i\)</span> 为0.</p>
<h3 id="proximal-gradient-descent">proximal gradient descent</h3>
<p>proximal gradient descent 也可以说是 subgradient
的升级版，<strong>proximal 通过对原问题的拆分并利用 proximal
mapping，能够解决 subgradient descent 无法解决的问题（如上面的一般化
lasso 问题）。</strong></p>
<p>一般来说，这类方法将目标函数描述成以下形式</p>
<p><span class="math display">\[f(X) = g(x) + h(x)\]</span></p>
<p>上面的 <span class="math inline">\(g(x)\)</span> 是凸且可微的， 而
<span class="math inline">\(h(x)\)</span> 也是凸的，但是不一定可微。则
proximal gradient descent 的迭代公式为</p>
<p><span class="math display">\[x^{(k)} = x^{(k-1)} -
t\_kG\_{t\_k}(x^{(k-1)})\\\
G\_{t}(x) = \frac{x - prox\_{th}(x-t\nabla g(x))}{t}\\\
prox\_{th}(x) = argmin\_{z\in \mathbb {R}^n}
\frac{1}{2t}||x-z||\_2^2+h(z)\]</span></p>
<p>上面 <span class="math inline">\(prox\_{th}(x)\)</span> 表示对函数
<span class="math inline">\(h\)</span> proximal
mapping。这里仅给出结论，证明过程略，接下来以上面没有解决的一般化的
lasso 问题为例讲述这种方法的应用。</p>
<p><span class="math display">\[\min\_{\beta \in \mathbb {R}^n}
\frac{1}{2} ||y-X\beta||\_2^2 + \lambda ||\beta||\_1~~(\lambda \ge
0)\]</span></p>
<p>记 <span class="math inline">\(g(\beta) = \frac{1}{2}
||y-X\beta||\_2^2, h(\beta) = \lambda ||\beta||\_1\)</span></p>
<p>则有 <span class="math display">\[prox\_{th}(\beta) = argmin\_{z \in
\mathbb {R}^n} \frac{1}{2t}||\beta - z||\_2^2+h(z) \]</span></p>
<p>这个问题通过前面的 subgradient 方法已经解出来，结果为</p>
<p><span class="math display">\[z\_i = \begin{cases} y\_i - \lambda t
&amp; y\_i &gt; \lambda t\\\
0 &amp;-\lambda t \le y\_i \le \lambda t\\\
y\_i + \lambda t &amp; y\_i &lt; -\lambda t\end{cases}\]</span></p>
<p>将上面的解记为 <span class="math inline">\(S\_{\lambda
t}(y)\)</span>, 同时 <span class="math inline">\(\nabla g(\beta) = -
X^T(y-X\beta)\)</span></p>
<p>代取上面列出的 proximal gradient descent 列出的迭代公式，则 <span
class="math inline">\(\beta\)</span> 的迭代公式如下</p>
<p><span class="math display">\[\beta^{(k)} = S\_{\lambda
t}(\beta^{(k-1)} + t\_kX^T(y-X\beta^{(k-1)}))\]</span></p>
<p>其中 <span class="math inline">\(t\_k\)</span> 为步长。</p>
<p>这种方法之所以比 subgradient 方法更加一般化，是因为 <span
class="math inline">\(prox\_{th}(x)\)</span> 对于绝大部分的 <span
class="math inline">\(h\)</span> 是易求的。</p>
<h2 id="对偶方法与kkt条件">对偶方法与KKT条件</h2>
<p>对偶理论在最优化中非常重要，其中具有代表性的两条定理是弱对偶定理和强对偶定理，<strong>弱对偶定理告诉了我们最优化的目标的上界(
max 问题)或下界(min 问题)，而强对偶定理告诉了当 KKT
条件满足的时候，可以通过对偶问题的解推出原问题的解。</strong></p>
<p>弱对偶条件总是成立，而强对偶需要在 <code>Slater's condition</code>
成立时才成立，该条件描述如下</p>
<p>对于优化问题</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad f(x)\\\
&amp;\begin{array}\\\
s.t.&amp;g\_i(x) \le 0,~i=1,\ldots,m\\\
&amp;h\_j(x)=0,~j=1,\ldots,r
\end{array}
\end{align\*}
\]</span></p>
<p>假如存在可行解 <span class="math inline">\(x&#39;\)</span> 使得 <span
class="math inline">\(g\_i(x&#39;) &lt; 0(i=1,...m)\)</span>,
即不等式约束严格成立（注意同时等式约束也要成立，否则就不是可行解了），那么称<code>Slater's condition</code>
成立，同时强对偶也成立。</p>
<h3 id="线性规划对偶">线性规划对偶</h3>
<p>对于形如下面的线性规划问题</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad c^Tx\\\
&amp;\begin{array}\\\
s.t.&amp;Ax = b\\\
&amp;Gx \le h
\end{array}
\end{align\*}
\]</span></p>
<p>其对偶问题为</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_{u,v}\quad -b^Tu - h^Tv\\\
&amp;\begin{array}\\\
s.t.&amp;-A^Tu - G^Tv = c\\\
&amp; v \ge 0
\end{array}
\end{align\*}
\]</span></p>
<p>对于 LP 问题，其对偶的特殊性在于只要存在原问题存在可行解，那么
<code>Slater's condition</code> 一定成立，因此强对偶也成立.</p>
<p>LP 对偶问题的一个经典的例子是最大流(max flow)问题和最小割(min
cut)问题.</p>
<h3 id="拉格朗日对偶">拉格朗日对偶</h3>
<p>对于更一般的非 LP
问题的对偶问题，需要用到拉格朗日对偶理论得到，并称该问题为拉格朗日对偶问题。</p>
<p>这个方法可以说是对求解等式约束的<a
href="https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0">拉格朗日乘子法</a>的一个推广。</p>
<p>对于下面的优化问题</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad f(x)\\\
&amp;\begin{array}\\\
s.t.&amp;g\_i(x) \le 0,~i=1,\ldots,m\\\
&amp;h\_j(x)=0,~j=1,\ldots,r
\end{array}
\end{align\*}
\]</span></p>
<p>其増广拉格朗日函数为</p>
<p><span class="math display">\[L(x,u,v) = f(x) + \sum\_{i=1}^m
u\_ig\_i(x) + \sum\_{j=1}^r v\_jh\_j(x)~~(u\_i \ge 0)\]</span></p>
<p>则原问题的拉格朗日对偶函数为</p>
<p><span class="math display">\[ g(u,v) = \min\_x L(x,u,v)\]</span></p>
<p>且原问题的对偶问题为</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\max\_{u,v}\quad g(u,v)\\\
&amp;\begin{array}\\\
s.t.&amp;u\_i \ge 0,~i=1,\ldots,m
\end{array}
\end{align\*}
\]</span></p>
<p>上面得到对偶问题的简单推导流程如下：</p>
<p>首先原问题的目标函数<strong>加上约束</strong>可以表示为</p>
<p><span class="math display">\[f(x) = \max\_{u,v} L(x,u,v)\]</span></p>
<p>原因是在增广拉格朗日函数中，假如 <span
class="math inline">\(x\)</span> 违反了约束条件(即 $ g(x) &gt; 0 $
)，那么 <span class="math inline">\(f(x)\)</span>
会趋向无穷大；而不违反约束条件时，<span class="math inline">\(u\)</span>
必须取0才能使得目标最小。</p>
<p>进一步，原问题可以表示为 <span class="math display">\[\min\_x
\max\_{u,v} L(x,u,v) \]</span></p>
<p>而由于下式恒成立（弱对偶定理）</p>
<p><span class="math display">\[\min\_x \max\_{u,v} L(x,u,v) \ge
\max\_{u,v} \min\_xL(x,u,v) \]</span></p>
<p>因此将 <span class="math inline">\(\min\_xL(x,u,v)\)</span>
作为对偶函数， $_{u,v} _xL(x,u,v) $ 作为对偶问题。</p>
<p>假设现在找到了对偶问题，并且对偶问题比原问题要容易求解得多，也求出了对偶问题的解，那么该转化去求原问题的解，这里就要用到下面的KKT条件。</p>
<h3 id="kkt-条件">KKT 条件</h3>
<p>KKT
条件是非线性规划领域中最重要的理论成果之一，是确定某点是最优点的一阶必要条件，只要是最优点就一定满足这个条件，但是一般来说不是充分条件，因此满足这个点的不一定是最优点。但<strong>对于凸优化而言，KKT条件是最优点的充要条件</strong>。</p>
<p>同样地</p>
<p>对于下面的优化问题</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad f(x)\\\
&amp;\begin{array}\\\
s.t.&amp;g\_i(x) \le 0,~i=1,\ldots,m\\\
&amp;h\_j(x)=0,~j=1,\ldots,r
\end{array}
\end{align\*}
\]</span></p>
<p>其増广拉格朗日函数为</p>
<p><span class="math display">\[L(x,u,v) = f(x) + \sum\_{i=1}^m
u\_ig\_i(x) + \sum\_{j=1}^r v\_jh\_j(x)~~(u\_i \ge 0)\]</span></p>
<p>则 KKT 条件为</p>
<p><span class="math display">\[\begin{cases} \nabla\_x L(x,u,v) = 0\\\
u\_ig(x) = 0\\\
u\_i \ge 0\\\
g\_i(x) \le 0, h\_j(x)=0
\end{cases}\]</span></p>
<p>因此其实只要能够求解出上面的联立方程组，得到的解就是最优解（对于凸优化而言，非凸的问题一般用KKT来验证最优解）。</p>
<p>但是上面的方程组往往很难求解，一些特殊情况下解是有限的，可以分类讨论；但是更一般的情况下可能的解是无限的，因此无法求解。这里要结合上面的拉格朗日对偶问题得到的解进行求解。</p>
<p>求解之前，首先要知道下面的定理 &gt;假如一个问题满足强对偶，那么 <span
class="math inline">\(x&#39;,u&#39;,v&#39;\)</span>
是原问题和对偶问题的最优解 <span
class="math inline">\(\longleftrightarrow\)</span> <span
class="math inline">\(x&#39;,u&#39;,v&#39;\)</span> 满足KKT条件。</p>
<p>因此通过对偶问题求得 <span
class="math inline">\(u&#39;,v&#39;\)</span> 后，带入上面的 KKT
条件即可求出 <span class="math inline">\(x&#39;\)</span> 。</p>
<p>svm
是利用拉格朗日对偶和KKT条件进行求解的经典问题，这里不详细展开，有兴趣的可以参考
<a
href="http://open.163.com/special/opencourse/machinelearning.html">Andrew
Ng 公开课</a>中关于 svm 的那章或<a
href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982684.html">这篇文章</a>。</p>
<h2 id="admm">ADMM</h2>
<p>ADMM(Alternating Direction Method of Multipliers)
是解决带约束的凸优化问题的一种迭代解法，当初提出这个算法最主要的目的是为了在分布式环境(Hadoop,
MPI 等)中迭代求解这个问题，关于这方面的资料可参考<a
href="http://stanford.edu/~boyd/admm.html">这里</a></p>
<p>ADMM 将要解决的问题描述成以下形式</p>
<p><span class="math display">\[
\begin{align\*}
&amp;\min\_x\quad f\_1(x\_1) + f\_2(x\_2)\\\
&amp;\begin{array}\\\
s.t.&amp; A\_1x\_1+A\_2x\_2 = b
\end{array}
\end{align\*}
\]</span></p>
<p>这里省略证明过程，直接给出 ADMM 的迭代公式</p>
<p><span class="math display">\[\begin{align\*}
&amp;x\_1^{(k)} = argmin\_{x\_1} f\_1(x\_1) +
\frac{\rho}{2}||A\_1x\_1+A\_2x\_2^{(k-1)} - b + w^{(k-1)}||\_2^2\\\
&amp;x\_2^{(k)} = argmin\_{x\_2} f\_2(x\_2) +
\frac{\rho}{2}||A\_1x\_1^{(k)} + A\_2x\_2 - b + w^{(k-1)}||\_2^2\\\
&amp;w^{(k)} = w^{(k-1)} + A\_1x\_1^{(k)} + A\_2x\_2^{(k)} - b
\end{align\*}
\]</span></p>
<p>上式中的 <span class="math inline">\(\rho\)</span>
是事先选择的参数，可以选择定值，选择定值的时候会遇到跟梯度下降固定步长的类似问题，因此也可以根据每次迭代情况改变
<span class="math inline">\(\rho\)</span> 的值，具体可参考<a
href="http://stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf">这篇文献</a>。</p>
<p>实际中，<strong>难点在于把一个问题变为 ADMM
求解的形式</strong>，即上面列出的优化问题的形式。下面给出一个例子说明这个问题，这个例子是一个更一般的
lasso regression 问题，称为 <code>fused lasso regression</code>.</p>
<p><span class="math display">\[\min\_{\beta \in \mathbb {R}^n}
\frac{1}{2} ||y-X\beta||\_2^2 + \lambda ||D\beta||\_1~~(\lambda \ge
0)\]</span></p>
<p>一般的 lasso regression 问题中 <span class="math inline">\(D =
I\)</span>.下面用 ADMM 的形式表示上面的问题</p>
<p><span class="math display">\[\min\_{\beta \in \mathbb {R}^n，\alpha
\in \mathbb {R}^n} \frac{1}{2} ||y-X\beta||\_2^2 + \lambda
||\alpha||\_1~~(\lambda \ge 0)\\\
s.t. D\beta - \alpha = 0\]</span></p>
<p>将这个问题映射到上面的优化问题的模式有</p>
<p><span class="math display">\[\frac{1}{2} ||y-X\beta||\_2^2\rightarrow
f\_1(x1) \\\
\lambda ||\alpha||\_1 \rightarrow f\_2(x\_2)\\\
D\beta - \alpha = 0 \rightarrow A\_1x\_1+A\_2x\_2 = b\]</span></p>
<p>则根据上面的迭代公式计算（对问题变量求导且令结果为0）可得到下面的迭代公式</p>
<p><span class="math display">\[\begin{align\*}
&amp;\beta^{(k)} = (X^TX+\rho D^TD)^{-1}(X^Ty+\rho
D^T(\alpha^{(k-1)}-w^{(k-1)})\\\
&amp;\alpha^{(k)} = S\_{\lambda/\rho}(D\beta^{(k)}+w^{(k-1)})\\\
&amp;w^{(k)} = w^{(k-1)} + D\beta^{(k)} - \alpha^{(k)}
\end{align\*}
\]</span></p>
<p>而对于无约束的优化也可以通过 ADMM 求解，例如对于下面的问题</p>
<p><span class="math display">\[\min\_x \sum\_{i=1}^B
f\_i(x)\]</span></p>
<p>将其表示为ADMM的形式如下</p>
<p><span class="math display">\[\min\_{x\_1,..x\_B,x} \sum\_{i=1}^B
f\_i(x\_i)\\\
s.t. x\_i = x,~~i=1,..B\]</span></p>
<p>则ADMM的迭代规则如下</p>
<p><span class="math display">\[\begin{align\*}
&amp;x\_i^{(k)} = argmin\_{x\_i}
f\_i(x\_i)+\frac{\rho}{2}||x\_i-x^{(k-1)}+w\_i^{(k-1)}||~(i=1,..B)\\\
&amp;x^{(k)} = \frac{1}{B} \sum\_{i=1}^B (x\_i^{(k)} + w\_i^{(k-1)})\\\
&amp;w\_i^{(k)} = w\_i^{(k-1)} + x\_i^{(k)} - x^{(k)}~(i=1,..B)
\end{align\*}
\]</span></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>写给大四</title>
    <url>/2015/11/18/%E5%86%99%E7%BB%99%E5%A4%A7%E5%9B%9B/</url>
    <content><![CDATA[<blockquote>
<p>文章为转载，作者不详</p>
</blockquote>
<p>无论你是找工作了，还是保研了，我们或多或少对未来的不确定性感到彷徨和焦虑，看完希望对你有用。</p>
<p>昨天有个同学来找我，谈毕业选择的事情。谈完以后她突然过来拥抱了我一下。为此我深受鼓舞，决定给你们写一点东西。你们正处在一个艰难的阶段。我想以下面这段文字，争取给你们提供点正能量。虽然写了很长，但不会谈如何申学校、找什么工作、要不要保研这种具体的问题。我想谈的是，如何排解你心中的恐慌。</p>
<span id="more"></span>
<h2 id="焦虑的本质">焦虑的本质</h2>
<p>大四是一个焦虑的时期。你们的烦恼有时候是具体问题带来的压力，有时候却是无端的、莫名其妙的，有时候还极易受到外界的影响，别人一句话就会激起内心难以遏制的波澜。所有这些焦虑、恐慌、敏感，在我看来，其实归根结底是源于三件事：</p>
<ol type="1">
<li>人生的有限性</li>
<li>未来的不确定性</li>
<li>过去的不可更改性。</li>
</ol>
<p>这三件事是人生不可回避的三道阴影。每当想到它们我就想写诗。</p>
<ul>
<li>“我要如何准备才能胜出？”“我会失败吗？”这是未来的不确定性在你的内心敲打。</li>
<li>“我走这条路是不是多浪费一两年的时间？”“我会不会走弯路？”这是人生的有限性在摆弄你。</li>
<li>“我的选择是不是错了？”“这么大的投入最后回报得来吗？”，你们患得患失，因为没有后悔药可以吃。</li>
</ul>
<p>怎么样？其实每天让你感到痛苦的，不是那些具体的事，而是上面这些萦绕不去的疑问。我开宗明义地拔高到人生的高度来剖析，不只是因为我一以贯之的文艺与深沉，更是因为我觉得下面这个前提非常重要：<strong>如果你感到的恐惧，是人生某些不可改变的特性带来的，那么你拼命地想抓住什么、甚至你终于完成了一个目标、得到了一块暂时的喘息之地，你仍然解决不了你内心的痛苦。</strong></p>
<p>这就是为什么你们没拿到Offer的时候很煎熬，拿到了offer的又患得患失；等到6月份还没出路的痛苦无比，早在9月份就保研的同样不开心。痛苦最多可以缓解，永远得不到解决。这次痛苦比较小的人，下次痛苦没准会很大。</p>
<p>由于人生的规律没法改变，所以要想解决内心的痛苦，外面如何挣扎和抓取都没用，最终只能靠内心的成长。</p>
<h2 id="怎么破">怎么破？</h2>
<p>如果现在要打的是人生的终极大boss——所谓人最大的敌人就是自己。那么我这个水平，当然不知道怎么破。不过我已经感觉到了人内心成长的历程，可以跟你们分享。</p>
<p>首先你们要重视自己的理性。<strong>人有一个不断强大的头脑，和一颗充满恐惧、贪欲和脆弱的玻璃心。人的大多数行为仿佛更倾向于受到情绪的驱动，而不是头脑的指示。你的头脑作为弱势群体，要学会和内心对话，了解你内心深藏的力量和驱动，并争取引导它，逐渐达到心智的合一。</strong></p>
<p>这是一个漫长的成长过程，一些人最终变得更有智慧，大气、从容、坚定，能够更好地把握自己的人生。但绝大多数人终此一生也无法主宰自己，像浮萍一样地随风浪摇摆。这其中可能包括你的父母。</p>
<p>但我常常感觉到，情绪的力量非常强大，理性的作用一开始往往有限。你可以很容易明白很好的道理，但是你控制不了自己，尤其在受到外界干扰的时候。你内心成长的心智就像一颗小树苗，在它尚还柔弱的时候，恐怕经不起太严酷的风吹雨打。外部的环境太恶劣了，再强大的内心都有可能被压倒。</p>
<p>所以，我的经验是：内外双修。</p>
<h2 id="跟自己的内心对话">跟自己的内心对话</h2>
<p>深感艰难的阶段，我们要多跟自己讲讲道理。听别人讲也行，自己跟自己讲也行。<strong>其实被情绪所操纵的心灵很傻的，说的多了，它就会慢慢相信。</strong>这就是为什么要多跟女人说我爱你的原因。你们可以经常给自己说说这些道理：</p>
<h3 id="相信命运"><strong>相信命运</strong></h3>
<p>我这么说不是要你们去算命。而是说作为受过大学教育的人，你们要明白事物的不可操控性。我们高中学习的知识和成长的经历，容易给我们塑造一种观念，就是万事是因果相连的。有了条件，就可以推算出答案。这个世界由根本的、简明的自然规律和公理推动运转，一切都可以预测和解释。好好学习，一般来说就可以考上好大学。能不能达到预设的结果，全在于能不能满足一定的条件，比如说有没有努力。</p>
<p>可惜由于我们的大学教育整体比较失败，所以前面形成的观念基本得不到修正和挑战。如果你大学继续学习数理化，你就知道你高中的那些定理和公理都是17世纪牛顿时代的东西。20世纪出现的相对论、量子理论、混沌理论，说明连自然界都不是那么确定无疑的。微观来看，因果关系固然牢靠，但是一旦到了宏观，变量可能太过复杂，复杂到超越人在有限时空里可以理解或掌握的程度。</p>
<p>自然是这样，人生也是这样。有的事情变量更简单，可把握性更强；有的事情变量更复杂，可把握性更小。高考就算可把握性比较强的事情，虽然也有个别点背的。但是学习这种事情，绝对是社会现象中的特例。你一生里遇到的其他事，其可把握性都远远低于在学校里的生活。</p>
<p>现在你们即将踏入社会，<strong>社会给你们上的第一课，就是全然不同于学校学习的“低把握性逻辑”。你想要找一条好的出路，只能尽量为之准备，但结果如何，非常地“混沌”。</strong>我给你们讲过很多我身边的故事。我大学同班，学习最好没有留在北京，最像共产党员的去了外企，最不上课的当了公务员，最北京味儿的出了国，最学术的之一当了导演，最不像搞学术的一个如今在大学当老师，就是我。</p>
<p>我不是想告诉你们世事无常，躺下来等着天上掉铁饼就好了。我有一个同学进了外交部，她一直想进外交部；还有一个同学也在当大学老师，他当年确实是一个学霸。但这两个同学当时并不比别的同学更努力，他们现在也并不比别的同学更成功。</p>
<p><strong>你们必须学会理解和接受人生的偶然性。未知当然让人恐惧，但这是你心灵的自然反应。你的头脑可以相信：每个人都有一条路。这条路有很多错综复杂的因素促成，但一定由一个人在当时当地能够做的最好的选择组成。所以你提前恐慌或者不恐慌，并不能改变什么。走上去以后，就好好地走，才能精彩。</strong></p>
<h3 id="没有弯路"><strong>没有弯路</strong></h3>
<p>踏上社会之前的恐慌，很大程度上来自于“输在起跑线”上的幻想。真正的人生不是一场竞赛；至少也不是一场跑向同一终点的竞赛。这也是高考养成的逻辑。从进大学开始就已经不管用。</p>
<p>我也给你们讲过很多故事。习近平青年时候被下放到农村种了七年地，22岁才回城读大学。胡锦涛大学毕业以后到西北修水坝去了。奥巴马和克林顿都是穷小子，好不容易考上了个东部的常青藤，结果一个回老家干社区工作，一个回老家在名不见经传的大学教书。按照前面的逻辑，他们都输在了起跑线上。</p>
<p>如果你们真要有志向当个人生的赢家，可以多看看那些有成就的人。大多数伟人的人生都充满了波折，有的还几起几落。可是从后往前看，哪里又有什么弯路？你当过村支书，别人没有当过村支书，几十年后，竞争国家主席你就有优势。</p>
<p>你可能不想当伟人，只不过不想吃苦。但前面已经说过，你们的人生总有一条路，有时候会是弯的，有时候是直的。不要只想走直路。直路开的太快，便无心欣赏风景，难有宽广的眼界和丰富的心灵，于是你缺少快乐的潜质。总之所有的努力都不会白费。在哪儿努力都行。</p>
<h3 id="我自己定"><strong>我自己定</strong></h3>
<p>大四这种时候，你们每天最好给自己打打气：凡事我做主。</p>
<p>我不知道你们会有一个什么样的爸妈，总之他们很有可能会很烦。有的平时很开明，到了这种时候，也偶尔冒出一两句不懂事的话，让你平添无意义的难受。七大姑八大姨都会打电话。放个假回家就会不停地问。哥们闺蜜死党什么的纷纷提建议。同班同学这呀那的，你努力从每一个传闻中获得给自己的启示。</p>
<p><strong>最后，你接收了很多信息，询问了很多建议，却迷失了自己。其实你的事情只有你最懂，别人都不行。从今天开始，你要立足于自己。你希望别人帮你，其实是害怕对可能的失败负全责。可是，你的前途，谁能替你负责？真正的自信，就从自负其责开始；真正的自由，也是从自负其责开始。</strong></p>
<h2 id="改变外围环境">改变外围环境</h2>
<p>除了常常与自己的内心对话，你们还要争取为这种对话营造一个好的外在环境，靠近阳光雨露，远离风吹雨打。
### <strong>不要来烦我</strong></p>
<p>我好像试图挑拨你们与父母的关系。其实我的意思是：到了这个年龄，你们必须开始重塑你们与父母之间的关系。在这个特殊的阶段，最关心你们前途的是你们的父母；最影响你们心情往往也是他们。你们需要父母的关心。但如果他们跟你一样被情绪所驱动，缺乏坚定与理性，时常而来的关心不过是一种情绪发作后的排解。那你就要明确告诉他们：请克制自己的恐慌，多给我传递正能量。</p>
<p>父母的建议可能有用。但多半用处不大。如果生活在农业时代，你基本上只需要按照父母说的做就行了，因为你们两代人的人生没有什么大的区别。可是现如今，你在外地的父母怎么知道北京的事？又怎么能知道美国的事？如果要沟通，让父母多给你分享一些人生感悟，而不是具体建议。</p>
<p>同样的的道理，远离负能量的种种议论，除非你们能相互鼓励。远离打扰你内心平静的环境，为内心的对话保留空间。如果可能的话，尽量地给周围的人一些正能量。如果你确定你知道什么是正能量的话。</p>
<h3 id="不要拖沓"><strong>不要拖沓</strong></h3>
<p>这个时候你们都在为了各种事做准备。不管在追求什么，制定好计划，有规律地生活，该做的事不要拖沓。<strong>当你感到愈发恐慌的时候，往往是有该做的事却没做的时候。那件事在你的心底大声地发出嘲讽，让你越发地焦虑和没有自信。如果你所努力的事情按部就班、取得进展，你的情绪化的心灵会驯服很多，讲的道理它才会耐心去听。</strong></p>
<h3 id="完成小心愿"><strong>完成小心愿</strong></h3>
<p>一个年轻的心灵，最需要灌溉的泉水，就是自信。做一些能够让你提升自信的事情。这些事情可能都很小，但是短期能看到效果，取得进步，或者得到结果。你们如果排除无谓的焦虑，其实有相当的时间可以做这些事情。</p>
<ul>
<li>出去短途旅游。独自计划、独自出行、独自完成，回来后你会觉得自己成长了。</li>
<li>读一些书，讲给没读过的人听。那人最好不是大四。</li>
<li>练习一项体育运动，看到自己的进步。</li>
<li>做任何你想做、靠相对简单的努力能够做成的事情。</li>
</ul>
<h2 id="希望有用">希望有用</h2>
<p>我花了两天的时间来构思，又用一整天的时间把这些话写出来，中间鼓起了很多次的勇气，要自己坚持下去。一方面我很不愿意说教，虽然我经常说教。我对你们说教，实际上我自己和内心对话的一个形式，所以无比真诚。你们叫我人生导师，可我的人生也亟需引导。目前只能进行</p>
<p><strong>人生有的阶段不可逾越，有的痛苦必须体验。身处其中的人很难解脱。评论的人常常是站着说话不腰疼。</strong>比如现在如果有个老同志对我说：“你年轻人不要为买不起房、排不上车号、每个月存不下钱而焦虑。这些都是虚妄的。”我一方面觉得他说的有道理，另一方面心底有一个强大的声音在呼喊：“把你的给我嘛”。
　　许多道理，只有走过了，回转来才能真正体会。上学期我在毕业典礼上做的发言，在社会上有不少媒体刊登和转载，光各种稿费单子就收了一堆。可是在学校里的同学们，感受就隔了一层。他们找到了一个黑我的新办法。一度我只要问“为什么”，他们就会说“因为我们来自山顶”。</p>
<p>所以，接下来我再问为什么，你们可以说：“请先跟你的内心对话。”</p>
<p>我现在内心里的想法，就是希望你们接下来这一年不被虚度。这是你们人生中最美好时代中的一年，它不是拿来过渡、等待或者牺牲的。现在这一年才刚刚开始。</p>
<p>大四加油！</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式机器学习(1)-A New Era</title>
    <url>/2018/02/08/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(1)-A%20New%20Era/</url>
    <content><![CDATA[<p>这个分布式机器学习系列是由<a
href="https://www.zhihu.com/people/wang-yi-21/activities">王益</a>分享的，讲的是分布式机器学习。正如作者在分享中所说，分布式机器学习与我们今天常听到的机器学习存在比较大的差异，因此分享中的很多观点跟我们从教课书上学到的机器学习是背道而驰的。作者在这方面具有丰富的经验，虽然是三年前的分享，或许分享中提到的部分技术改变了，但是其中的一些观点还是具有一定参考价值的。</p>
<p>笔者对于分享中的一些观点也是存在疑惑的，这里还是按照分享中作者表达的意思记录下来,
也许等到笔者工作后，才有机会去验证这些观点的正误。</p>
<p>本文主要介绍了分布式机器学习中的一些重要概念，如互联网的真实数据是长尾分布的、大比快要重要、不能盲目套用一个框架等，本文对应的视频在<a
href="https://www.youtube.com/watch?v=dqE50moCwno&amp;list=PLFze15KrfxbH2rGxJqcpFAgKp-iZv5uW0&amp;index=1">这里</a>，需要自备梯子。</p>
<span id="more"></span>
<h2 id="机器学习与分布式机器学习">机器学习与分布式机器学习</h2>
<p>机器学习最重要的是数学知识，而这里的分布式机器学习更关注的是工程技法。且一般的机器学习模型假设数据是指数簇分布，而实际的数据是长尾分布的，分布式机器学习需要去对长尾的数据进行建模，对于这点，后面会有详细的描述。</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5pmmntgsgd1a1k1p1516kp1i7g16.png"
alt="ml and distributed ml" />
<figcaption aria-hidden="true">ml and distributed ml</figcaption>
</figure>
<h2 id="长尾效应">长尾效应</h2>
<p>根据<a
href="https://zh.wikipedia.org/wiki/%E9%95%BF%E5%B0%BE">维基百科</a>，<strong>长尾指的是指那些原来不受到重视的销量小但种类多的产品或服务由于总量巨大，累积起来的总收益超过主流产品的现象</strong>。在互联网领域，长尾效应尤为显著。下图所示黄色的部分就是长尾部分，之所以要关注长尾的数据，是因为长尾的数据的量并不小，蕴含着重要的价值</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5q3h20158g1ftjllk1t421uh349.png"
alt="长尾" />
<figcaption aria-hidden="true">长尾</figcaption>
</figure>
<p>以互联网广告为例，长尾现象指的是有大量频次低的搜索词，这些搜索词并非为大多数人所了解。如搜索“红酒木瓜汤”时不应该出红酒、木瓜或者汤的广告，因为这个是一个丰胸健美类的产品，这就是一个长尾的搜索词。</p>
<p>另外一个例子如下所示，下图是从 <a
href="https://zh.wikipedia.org/wiki/Delicious">Delicious</a>
的网页中挖掘出的一些频繁项集，最左边便是这个频繁项集，最右边表示这个频繁项集在所有网页（数亿）中出现的次数，可以看到这些频繁项集是长尾的数据了，然而，这些数据都是有具体意义的。</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5pn2u281gq6u811g4k17qg12aq2v.png"
alt="long tail" />
<figcaption aria-hidden="true">long tail</figcaption>
</figure>
<h2 id="大比快重要">大比快重要</h2>
<p>并行计算关注的是更快，而分布式机器学习关注的则是更大，因为数据是长尾的，要涵盖这些数据中的长尾数据，首要的处理的是首先是大量的数据。</p>
<p>在讲述下文前，需要先说明几个概念，Message Passing 和 MapReduce
是两个有名的并行程序编程<strong>范式</strong>（paradigm），也就是说，并行程序应该怎么写都有规范了——只需要在预先提供的<strong>框架</strong>（framework）程序里插入一些代码，就能得到自己的并行程序。Message
Passing范式的一个框架叫做MPI。MapReduce范式的框架也叫MapReduce。而MPICH2和Apache
Hadoop分别是这MPI和MapReduce两个框架的<strong>实现</strong>（implementations）。</p>
<p>对于框架而言，其中重要的一点是要支持 <a
href="https://www.ibm.com/support/knowledgecenter/en/SSKTMJ_9.0.1/admin/admn_faultrecovery_c.html">Fault
Recovery</a>，简单来说就是要支持失败的任务的回滚。MPI 无法实现 Fault
Recovery，这是因为MPI允许进程之间在任何时刻互相通信。如果一个进程挂了，我们确实可以请分布式操作系统重启之。但是如果要让这个“新生”获取它“前世”的状态，我们就需要让它从初始状态开始执行，接收到其前世曾经收到的所有消息。这就要求所有给“前世”发过消息的进程都被重启。而这些进程都需要接收到他们的“前世”接收到过的所有消息。这种数据依赖的结果就是：所有进程都得重启，那么这个job就得重头做。</p>
<p>虽然很难让MPI框架做到fault
recovery，我们可否让基于MPI的应用系统支持fault
recovery呢？原则上是可以的——最简易的做法是做
<strong>checkpoint</strong>——时不常的把有所进程接收到过的所有消息写入一个分布式文件系统（比如HDFS）。或者更直接一点：进程状态和job状态写入HDFS。</p>
<p>与 MPI 相反的框架是
MapReduce，MPI容许进程间在任意时刻互相通信，MapReduce则只允许 进程在 Map
和 Reduce 间的 shuffle 进行通信，MPI
几乎能够将所有的机器学习算法并行化，而部分复杂的算法无法通过 MapReduce
实现。</p>
<h2 id="一些坑">一些坑</h2>
<p>这里是作者认为一些需要避开的坑， 下面选择几个展开说明</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5pm0hpjvv41gru1ne1h5l11plp.png"
alt="坑" />
<figcaption aria-hidden="true">坑</figcaption>
</figure>
<h3 id="de-noise-data">De-noise data</h3>
<p>这里的noise data
指的是将数据中出现频率不高的数据，将这些数据去掉，根据前面讲的长尾，这相当于是将长尾的尾巴截掉了，因此会丢失大部分有用的数据。</p>
<p>为什么不能将长尾的尾巴割掉，作者在 <a
href="https://zhuanlan.zhihu.com/p/19901994">描述长尾数据的数学模型</a>
这篇文章是这么说的</p>
<blockquote>
<p>那条长尾巴覆盖的多种多样的数据类型，就是Internet上的人生百态。理解这样的百态是很重要的。比如百度和Google为什么能如此赚钱？因为互联网广告收益。传统广告行业，只有有钱的大企业才有财力联系广告代理公司，一帮西装革履的高富帅聚在一起讨论，竞争电视或者纸媒体上的广告机会。互联网广告里，任何人都可以登录到一个网站上去投放广告，即使每日广告预算只有几十块人民币。这样一来，刘备这样织席贩屡的小业主，也能推销自己做的席子和鞋子。而搜索引擎用户的兴趣也是百花齐放的——从人人爱戴的陈老师苍老师到各种小众需求包括“红酒木瓜汤”（一种丰胸秘方，应该出丰胸广告）或者“苹果大尺度”（在搜索范冰冰主演的《苹果》电影呢）。把各种需求和各种广告通过智能技术匹配起来，就酝酿了互联网广告的革命性力量。这其中，理解各种小众需求、长尾意图就非常重要了。</p>
</blockquote>
<h3 id="parallelize-models-in-papers-and-textbooks">Parallelize models
in papers and textbooks</h3>
<p>教科书或paper中的模型无法应用到大数据环境下，原因是教科书上的模型假设数据是指数簇分布（<a
href="https://en.wikipedia.org/wiki/Exponential_family#Definition">Exponential
family</a>）的，而真实的数据是长尾分布（<a
href="https://en.wikipedia.org/wiki/Long_tail">Long tail</a>）的。</p>
<p><strong>用指数簇分布的模型去拟合长尾分布的数据，会有什么后果？答案就是会将长尾数据的尾巴给割掉了</strong>。比如说对于pLSA和LDA这两个Topic
model，如果大家尝试着把训练语料中的低频词去掉，会发现训练得到的语义和用全量数据训练得到的差不多。换句话说，pLSA和LDA模型的训练算法没有在意低频数据。</p>
<p>目前大部分的数学模型都假设数据是指数簇分布的，如 Topic model 中的 LDA
和 PLSA 其先验分布和后验分布均是指数簇分布，像 SVD
这种矩阵分解的方法也做了高斯分布的假设，而像Linear Regression
这类方法，从损失函数可以看到也倾向于优化数量多的样本。</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5pnprn71fnbjj73m87s26fd3f.png"
alt="model pitfall" />
<figcaption aria-hidden="true">model pitfall</figcaption>
</figure>
<p><strong>既然如此，为什么这类模型还要假设数据是指数族分布的呢？</strong>，作者在
<a
href="https://zhuanlan.zhihu.com/p/19901994">描述长尾数据的数学模型</a>
中是这么说的
&gt;这么做实在是不得已。指数族分布是一种数值计算上非常方便的数学元素。拿LDA来说，它利用了Dirichlet和multinomial两种分布的共轭性，使得其计算过程中，模型的参数都被积分给积掉了（integrated
out）。这是AD-LDA这样的ad
hoc并行算法——在其他模型上都不好使的做法——在LDA上好用的原因之一。换句话说<strong>，这是为了计算方便，掩耳盗铃地假设数据是指数族分布的。</strong></p>
<p>因此，要对长尾建模，作者提到，<a
href="https://en.wikipedia.org/wiki/Dirichlet_process">Dirichlet
process</a> 和 <a
href="https://en.wikipedia.org/wiki/Pitman%E2%80%93Yor_process">Pitman-Yor
process</a> 是一个可能的新方向。</p>
<h3 id="use-existing-frameworks">Use existing frameworks</h3>
<p>MPI 和 MapReduce 是两个极端，介于两者之间的是Pregel（google），spark
等框架，这些主要思想就是在磁盘上做 checkpooint
从而实现灵活的通信和有效的Recovery。</p>
<p>像 PageRank 这种算法在这些框架上能work，但是像 LDA
这种通信量大的算法，做checkpoint 时需要写入磁盘，会导致 buffer
过大，进而出现 out of memeory
的情况。<strong>因此，并不能通过一个通用的计算框架来解决所有问题。</strong></p>
<figure>
<img src="https://wulc.me/imgs/image_1c5po2i6f1e341p1i7930k1f563s.png"
alt="existing model" />
<figcaption aria-hidden="true">existing model</figcaption>
</figure>
<p>下面是一些被广泛使用的开源框架，需要注意的是，在设计机器学习系统时，需要权衡效果与代价，选择甚至是开发合适的框架</p>
<ul>
<li><a href="http://mpi-forum.org/docs/">MPI</a></li>
<li><a
href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">MapReduce</a></li>
<li><a
href="https://kowshik.github.io/JPregel/pregel_paper.pdf">Pregel</a></li>
<li><a href="https://turi.com/products/create/">GraphLab</a></li>
<li><a
href="http://spark.apache.org/docs/latest/ml-guide.html">Spark</a></li>
</ul>
<p>另外一个需要注意的问题就是<strong>不要将计算框架和分布式操作系统混在一起</strong>，如
Hadoop 1.0
设计中将集群管理系统和分布式计算框架混合在一起就显得非常混乱，因此在 2.0
中出现了 Yarn 这个分布式操作系统专门负责任务的调度。</p>
<h2 id="分布式机器学习技术栈">分布式机器学习技术栈</h2>
<p>最后这张图是分布式技术栈，从下到上依次涵盖了分布式文件系统，分布式操作系统，一些中间件，分布式计算框架，以及构构建在这套分布式系统上的应用。由于是15年的视频了，因此相应的技术也会有所改变，至少我所知的
DNN 的 framework 已经是 tensorflow，pytorch，caffe，mxnet
等占主流了。</p>
<p><img
src="https://wulc.me/imgs/image_1b34t45e61kv71g1hdaq1fcb1i6km.png" /></p>
<hr />
<p>参考</p>
<p><a
href="https://www.youtube.com/watch?v=dqE50moCwno&amp;list=PLFze15KrfxbH2rGxJqcpFAgKp-iZv5uW0&amp;index=1">分布式机器学习系列讲座
- 00 A New Era</a> <a
href="https://zhuanlan.zhihu.com/p/19901976">分布式机器学习的故事：评价标准</a>
<a
href="https://zhuanlan.zhihu.com/p/19901986">分布式机器学习的故事：pLSA和MPI</a>
<a
href="https://zhuanlan.zhihu.com/p/19901994">描述长尾数据的数学模型</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式机器学习(2)-Infrequent Pattern Mining using MapReduce</title>
    <url>/2018/02/11/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(2)-Infrequent%20Pattern%20Mining%20using%20MapReduce/</url>
    <content><![CDATA[<p>这一讲主要介绍了挖掘频繁项集中的经典方法 <a
href="https://dl.acm.org/citation.cfm?doid=335191.335372">FP-growth</a>，以及如何通过
MapReduce 实现这个算法，通过MapReduce实现的 FP-growth 也称为 <a
href="https://dl.acm.org/citation.cfm?doid=1454008.1454027">PFP</a>，这个方法不仅能够挖掘频繁项集，还能够挖掘非频繁项集。原视频在<a
href="https://www.youtube.com/watch?v=eCrhaUCqiiE&amp;t=4400s">这里</a>，需要自备梯子。</p>
<span id="more"></span>
<h2 id="频繁项挖掘">频繁项挖掘</h2>
<p>频繁项集挖掘（Frequent Itemset
Mining）指的是将那些共同出现较为频繁的项集找出来，其中一个经典的例子就是啤酒和尿布。下图展示了频繁项挖掘中的一些基本概念</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5s43rc91en7uks12ji49518fs9.png"
alt="基本概念" />
<figcaption aria-hidden="true">基本概念</figcaption>
</figure>
<ul>
<li>Transaction：每一行就是一个 Transaction，表示一个订单</li>
<li>Item &amp; ItemSet：每个 Transaction 包含了若干个
Item，表示订单中的商品，任意数量的 Item 可组成一个 ItemSet</li>
<li>Support：表示某个 ItemSet 出现的次数</li>
</ul>
<p>挖掘频繁项集有两个基本方法：Apriori 和 FP-growth，其中 Apriori
需要对原始数据进行多次的扫描，导致速度很慢。这里不展开讲述，具体可参考<a
href="http://www.cnblogs.com/fengfenggirl/p/associate_apriori.html">这篇文章</a>。</p>
<p>这里讲述的是 FP-growth 算法，该算法通过构建一棵 prefix
tree，使得只需要遍历两次原始的数据，下面先介绍这个算法的流程，再介绍如何通过
MapReduce 实现。</p>
<h2 id="fp-growth-算法">FP-growth 算法</h2>
<p>FP-growth 算法首先需要构建一棵 FP-tree ，FP-tree 是一棵 prefix
tree，构造的方法跟一般的 prefix tree 一样，但是在构造前需要对每个
transaction 中的 items
按照统一的规则排序（可以按照item出现的频率，也可以按照item的名称，总之各个transaction保持一致即可）</p>
<p>由于原始的 items 已经按照items名称排序，因此这里直接按照构建prefix
tree 的方法构建 FP-tree 即可，如下图所示是读入前两条记录的构建结果</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6h1582b13lr1h1f14v46fhd1u13.png"
alt="prefix tree 1" />
<figcaption aria-hidden="true">prefix tree 1</figcaption>
</figure>
<p>按照这种方法可以构建出整棵 FP-tree 如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6h170i0v2jhn6v871v7g1dvj1g.png"
alt="prefix tree 2" />
<figcaption aria-hidden="true">prefix tree 2</figcaption>
</figure>
<p><strong>这里需要注意的是上述的过程忽略了一步，就是在构造 FP-tree
前还还需要设定一个 min-support 值，这个值表示某个 item 至少要出现
min-support 次，如果小于 min-support 次，则将这个 item 从所有的
transaction 中剔除，再按照上面的方法构造 prefix tree。</strong></p>
<p>这么做的原因一是出现频率不高的 itemset
中的item被认为是相关度较低的，二是当输入很大的时候，构造出来的树也会很大，因此可通过设定阈值，去掉
infrequent
item。但是从我们前面讲的内容可知，这样做其实已经去掉了部分长尾数据。</p>
<p><strong>构造完 FP-tree 后，挖掘频繁项集时需要先指定一个
item，再挖掘与这个 item
相关的频繁项集</strong>，挖掘与这个item相关的频繁项集需要构造
Conditional FP-tree，所谓的 Conditional FP-Tree，就是与该 item
相关的所有 transaction 所组成的 FP-tree。如要挖掘与 e 这个 item
相关的频繁项集，则构造 Conditional FP-tree 过程如下</p>
<p>首先需要找到以 e 为叶子节点的所有 branch 组成的 tree，如下图 (a)
所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6hdlsfq1hvc126tsvlfarno11t.png"
alt="conditional FP-tree 1" />
<figcaption aria-hidden="true">conditional FP-tree 1</figcaption>
</figure>
<p>接着更新父节点的计数为子节点的计数之和，并且去掉 e
这个叶子节点，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6hds4av12hr1j421m2gk8h1dmg2a.png"
alt="conditional FP-tree 2" />
<figcaption aria-hidden="true">conditional FP-tree 2</figcaption>
</figure>
<p>在这个过程中需要去掉那些 support 数不满足 min-support 的item，这里令
min-support 为2，,则由于上图中的 b 的support 数只有 1，需要去掉 b 这个
item，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6he1m4fk03eo412dro4m1ain2n.png"
alt="conditional FP-tree 3" />
<figcaption aria-hidden="true">conditional FP-tree 3</figcaption>
</figure>
<p>构造出 e 的 conditional FP-tree 后，只需要挖掘出 conditional FP-tree
中的频繁项集，并在所有的频繁项集后加上 e 即可，如从 conditional FP-tree
中挖掘出的频繁项集为 <code>&#123;a:2, d:2&#125;</code> 和 <code>&#123;c:2&#125;</code>,
则关于 e 的频繁项集为 <code>&#123;a:2, d:2, e:2&#125;</code> 和
<code>&#123;c:2, e:2&#125;</code>。这样实际上是在解决一个递归问题了。</p>
<h2 id="mapreduce-实现-fp-growth">MapReduce 实现 FP-growth</h2>
<p>一般来说，挖掘频繁项集的原始数据都相当庞大，因此构造出来的 FP-tree
也会很大，当内存无法存储 FP-tree 时，一种解决方法就是通过提高
min-support 的值，从而将 FP-tree
的大小降低，但是根据之前讲的长尾效应，这样做会将长尾数据切掉。</p>
<p>另外一种方法就是通过分布式的方式实现该算法，通过分布式使得能够 构建
FP-tree 时支持更小的
min-support，从而能够挖掘非频繁项集。这里采用的分布式框架就是
MapReduce，下面讲述的是这个方法实现的细节。</p>
<p>下面首先介绍一下MapReduce 的编程范式，输入、中间结果和输出均是
key-value pairs, 中间的 shuffling 过程目的就是要将 key 相同的 pairs
交给同一个 worker 处理。</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5saqi2j1is3156872reg9rdam.png"
alt="mapreduce" />
<figcaption aria-hidden="true">mapreduce</figcaption>
</figure>
<p>在具体的实现上，shuffling 过程可通过对 key 做 hash 后，再取模（worker
的数量）决定这个 kv 对由哪个 worker 来负责。</p>
<p>另外数据的传输是通过分布式文件系统实现的，也就是需要通过反复写磁盘来进行数据的传输，这导致了
MapReduce 的速度无法快起来。</p>
<p>从上面可知，找到 item A 和 item B
的频繁项集这两个任务是不相关的，只需要分别找出 item A 和 item B 的
conditional FP-tree 即可，因此可以分别交给两个 worker 进行处理。</p>
<p>通过 MapReduce 实现的 FP-growth，<strong>每一次的 map + reduce
过程能够输出 item 对应的 conditional FP-tree</strong>，下图所示的是 map
过程，能够从 transaction 中输出各个 item 对应的 conditional
transaction</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6hmpeev1f601ocpg0o17me1q4j34.png"
alt="PFP map" />
<figcaption aria-hidden="true">PFP map</figcaption>
</figure>
<p>上图中最左边的 map input 是最开始的 transactions,
经过排序和过滤掉非频繁项后能够得到各个 item 对应的conditional
transaction，作为 map output 输入到 reduce 过程中，reduce
过程如下图所示，reduce 能够将相同的 key(item) 的conditional transactions
聚合在一起，进而构建出这个 item 对应的conditional FP-tree。</p>
<figure>
<img src="https://wulc.me/imgs/image_1c6hn2fhsikv18ok1pccnbj1m4g3h.png"
alt="PFP reduce" />
<figcaption aria-hidden="true">PFP reduce</figcaption>
</figure>
<p>得到这个 item 的 conditional FP-tree 后，可对这棵 conditional FP-tree
进行相同的 MapReduce 操作，因此，<strong>原始的 FP-growth
算法递归一次在这里就是一个 MapReduce Job。</strong></p>
<p>上面的实现方法实际上就是 <a
href="https://dl.acm.org/citation.cfm?doid=1454008.1454027">PFP(Parallel
FP-growth)</a> 算法，目前在 spark 框架中有<a
href="https://spark.apache.org/docs/2.1.0/mllib-frequent-pattern-mining.html">相应的实现</a>，可以直接调用。</p>
<p>最后需要注意的一点是，PFP
虽然能够挖掘出非频繁项集，也就是长尾数据的尾巴部分，但是却无法判断出这些非频繁项集中那些项集是有效的，那些是噪声。</p>
<p>综上，本文主要介绍了频繁项挖掘中的 FP-growth 算法以及如何通过
MapReduce 实现这个算法，通过 MapReduce 实现的版本能够支持更小的
min-support，因此能够挖掘出非频繁项集，也就是长尾数据中的尾巴部分，但是这个方法不能判断出那些非频繁项集是有效的。</p>
<hr />
<p>参考</p>
<p><a
href="https://www.youtube.com/watch?v=eCrhaUCqiiE&amp;t=4400s">分布式机器学习系列讲座
- 01 Infrequent Pattern Mining using MapReduce</a> <a
href="http://www.cnblogs.com/pinard/p/6307064.html">FP
Tree算法原理总结</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式机器学习(3)-Application Driven</title>
    <url>/2018/02/18/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(3)-Application%20Driven/</url>
    <content><![CDATA[<p>本文主要介绍了互联网几项重要业务（在线广告，推荐系统，搜索引擎）背后所需的一项共同技术：语义理解(semantic
understanding)，同时介绍了实现语义理解的若干种方法：包括矩阵分解，主题模型(Topic
Models)等。原视频见<a
href="https://www.youtube.com/watch?v=C7k0YSLAyX4&amp;index=3&amp;list=PLFze15KrfxbH2rGxJqcpFAgKp-iZv5uW0">这里</a>，需要自备梯子。</p>
<span id="more"></span>
<h2 id="semantic-understanding-支持的业务">semantic understanding
支持的业务</h2>
<h3 id="在线广告">在线广告</h3>
<p>作者以其在腾讯参与开发的 Peacock
系统为例介绍了在线广告所需的语义理解技术，如下是 peacock 系统对
“红酒木瓜汤” 这个查询关键词返回的语义理解的结果</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76cur5t9ho1kmq11kt1vrn1ekn9.png"
alt="online advertising" />
<figcaption aria-hidden="true">online advertising</figcaption>
</figure>
<p>最下面的 topics 是从 query 中推断出来的主题，每行为一个 topic，weight
是 query 属于这个 topic 的概率，topic_words 则是这个 topic
中的词语，且按照与query的相关度从高到低进行了排序。</p>
<p>如果将广告主的广告描述生成同样的 topics 分布，则可以将 query
和广告对应起来。Peacock 系统是基于 <a
href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">LDA(Latent
Dirichlet allocation)</a> 开发的，发表的具体论文是 <a
href="https://dl.acm.org/citation.cfm?id=2700497">Peacock: Learning
Long-Tail Topic Features for Industrial Applications</a>.</p>
<p>除了用户的 query，同样可得出用户浏览的内容的 topic
分布，进而根据用户的浏览内容为其推荐关联的广告。</p>
<h3 id="推荐系统">推荐系统</h3>
<p>推荐系统中最耳熟能详的算法是协同过滤，通过 users-items 矩阵中的 user
向量衡量 users 之间的相似性，通过 item 向量衡量 items
之间的相似性，具体可参考<a
href="http://wulc.me/2016/02/22/%E3%80%8AProgramming%20Collective%20Intelligence%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%282%29--%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/">这篇文章</a>。但是遇到下面这种情况时，协同过滤是无能为力的</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76fe1ok1oi74fs1o481tef1f959.png"
alt="recommendation system" />
<figcaption aria-hidden="true">recommendation system</figcaption>
</figure>
<p>上图所示的状况是不同 user 向量之间没有共同出现的 item，这样无法计算
user 向量间的近似性；而实际中的数据往往是非常稀疏的，不同用户间相交的
items 很少，因此协同过滤在推荐系统中几乎不再被使用。</p>
<p>那么，如何将上面提到的 semantic understanding
应用到推荐系统中呢？如下图所示，假如将原来的 users-items
矩阵划分为两个大的 topics，则每个 user 和每个 items 都可以被映射成一个
topic 向量，这样通过比较 topic 向量即可比较两个 user 或 item
的相似性</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76fpgg11k3t4gt1ruhv9n6csm.png"
alt="recommendation system 2" />
<figcaption aria-hidden="true">recommendation system 2</figcaption>
</figure>
<p>在实际中用得更多的是矩阵分解这一类方法，即无须事先对 users-items
矩阵进行划分，而是通过矩阵分解的方式得到每个 user 和每个 item 的 topic
向量。常见的 SVD、NMF 等都是这一类方法。</p>
<h3 id="搜索引擎">搜索引擎</h3>
<p>搜索引擎跟在线广告有点类似，都会根据用户的 query
返回关联的内容，下图中的 text
可以理解为用户的搜索关键词和页面的关键词</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76grvnn1n23qjh9clafd2913.png"
alt="search engine 1" />
<figcaption aria-hidden="true">search engine 1</figcaption>
</figure>
<p>图中有几个 topic，最简单的是两个，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76ijipd1ujj13bc14afc6p1gd51g.png"
alt="search engine 2" />
<figcaption aria-hidden="true">search engine 2</figcaption>
</figure>
<p>但是也可以认为有四个，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76ikob013gr1bro18omhtq1mm92d.png"
alt="search engine 2" />
<figcaption aria-hidden="true">search engine 2</figcaption>
</figure>
<p>所以这里有个重要问题，就是应该<strong>学习什么样粒度的 topic</strong>
？作者的观点是学习更小粒度的语义的好处更多。比如说按照第一种大粒度的语义分法时，第一行和第三行是有关联的；而按照第二种小粒度的语义分法时，第一行和第三行直观上没有联系，但可通过第二行联系起来。即更小粒度的语义能够完成大粒度的语义所完成的事情，但是大粒度的语义未必能完成小粒度语义所完成的事情，如从搜索的精确性考虑，肯定是小粒度的语义比大粒度的语义搜索要来得精准。</p>
<h2 id="实现-semantic-understanding-的方法">实现 semantic understanding
的方法</h2>
<p>实现 semantic understanding 的方法可以分为 unsupervised 和 supervised
两大类，supervised 其实就是分类（即将上面的 user 或 item 分类），但是
supervised
不仅需要人工标注的数据，而且还难以确定准确的类别数；因此实际中往往是采用
unsupervised 的方法，如下所示是一些 unsupervised 方法</p>
<figure>
<img src="https://wulc.me/imgs/image_1c76k8ff41pkbqmskflklc193j2q.png"
alt="unsupervised method" />
<figcaption aria-hidden="true">unsupervised method</figcaption>
</figure>
<p>Frequent itemset mining 在<a
href="http://wulc.me/2018/02/11/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%282%29-Infrequent%20Pattern%20Mining%20using%20MapReduce/">上一讲</a>中已经讲过，实际中，Frequent
itemset mining 和 collaborative filtering 使用得并不多</p>
<p>LSA(<a
href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">Latent
semantic analysis</a>)
实际上是对文本矩阵(每行是一篇文本，每列是一个单词) 进行 SVD
分解，且得到的 U 矩阵 和 V 矩阵中分别含有每篇文本或每个单词的 topic
向量。其他矩阵分解类的方法也都是遵循着这个思路。</p>
<p>NMF(<a
href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization">Non-negative
matrix factorization</a>) 是受限的
SVD，原因是这种方法分解后的矩阵中的元素必须要为正数。</p>
<p>pLSA(<a
href="https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis">Probabilistic
latent semantic analysis</a>)
在LSA的基础上加入了概率，使得结果有可解释性</p>
<p>LDA(<a
href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent
Dirichlet allocation</a>) pLSA
只能解释输入的数据，对于新来的数据无能为力，因此无法做到实时；因此有了
LDA 的出现，LDA 能够推断出新来的数据的 topic 分布，而smoothed pLSA
指的是 LDA 在 pLSA 基础上加入了先验概率，具体为狄利赫里先验分布。</p>
<p>HDP(<a
href="https://en.wikipedia.org/wiki/Hierarchical_Dirichlet_process">Hierarchical
Dirichlet process</a>) 与 LDA 效果类似，好处就是训练前不需要指定的
topics 的数量</p>
<p>作者认为，上面虽然列出了很多模型，但是不少模型之间是等价的，如 NFM 和
pLSA 的等价性可参考<a
href="http://users.cis.fiu.edu/~taoli/pub/NMFpLSIequiv.pdf">这篇文章</a>，pLSA
和 LDA 之间的等价性可参考<a
href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.6893">这篇文章</a>；</p>
<p>最后 semantic understanding
应用在上面所述三个互联网业务(在线广告，推荐系统，搜索引擎)时，基本的步骤是一致的，均为</p>
<ol type="1">
<li>Relevance: information retrieval</li>
<li>Ranking: click-through rate prediction</li>
</ol>
<p>第一步就是借助 semantic understanding 找到与 query
相关的结果，第二步要根据点击率等于具体业务相关的指标对这些相关结果排序。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式机器学习(4)-Implement Your MapReduce</title>
    <url>/2018/02/24/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(4)-Implement%20Your%20MapReduce/</url>
    <content><![CDATA[<p>提到 MapReduce，很自然想到的是 Hadoop MapReduce ，但是 MapReduce
只是一个编程范式，而 Hadoop MapReduce
则是这个编程范式的一个比较出名的实现。实际上，可以通过多种方式实现
MapReduce，本文要介绍的就是如何在 Linux 的 bash 下实现一个 MapReduce
程序，并且分别实现了单机版本和多机器版本。原视频见<a
href="https://www.youtube.com/watch?v=kZuJA5B2FtU&amp;index=4&amp;list=PLFze15KrfxbH2rGxJqcpFAgKp-iZv5uW0">这里</a>，需要自备梯子。</p>
<span id="more"></span>
<p>下面以 MapReduce 中的经典例子 WordCount 为例进行讲述,
先实现单机版本，再实现多机版本</p>
<h2 id="单机版-mapreduce">单机版 MapReduce</h2>
<p>下面是在 bash 下通过 MapReduce 范式实现的单机版本的 WordCount
程序</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">text=$(<span class="built_in">cat</span> &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">This is my Cup</span></span><br><span class="line"><span class="string">It is not your cup</span></span><br><span class="line"><span class="string">My cup is white</span></span><br><span class="line"><span class="string">Your cup is blue</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$text</span>\</span><br><span class="line">| awk <span class="string">&#x27;&#123;for (i=0; i&lt;=NF; i++) print $i, 1&#125;&#x27;</span> \</span><br><span class="line">| <span class="built_in">sort</span> \</span><br><span class="line">| awk <span class="string">&#x27;&#123;if ($1 != prev) &#123;print prev, c; c=0; prev=$1&#125; c+=$2&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>上面的 bash 脚本有几个需要了解的语法细节</p>
<p><code>cat &lt;&lt;EOF</code> 命令在 bash
中主要用于处理与实时多行string相关的任务，实时指的是多行string要在命令执行的时候输入（遇到
EOF 结束），这个命令一般可用于以下几个任务</p>
<p><strong>1. 将变量的值赋为多行 string</strong> <strong>2. 将多行
string 写入文件</strong> <strong>3. 将多行 string
传入管道命令</strong></p>
<p>上面的代码中就是将多行的 string赋值给变量
text，这三个任务的例子可参考<a
href="https://stackoverflow.com/questions/2500436/how-does-cat-eof-work-in-bash">这里</a></p>
<p><a href="https://en.wikipedia.org/wiki/AWK">awk</a> 是一门语言，也是
Linux 下一个常用工具，用于处理文本相关的数据，尤其是表格类的数据。awk
会逐行处理文本直至遍历完整个输入流（可以是标准输入流，也可以是文件流，上面的代码是标准输入流），每一行默认根据空格或tab分割文本为若干的
fields，从下标 1 开始，<code>$1</code> 表示第一个 field
的值，其他同理；NF 则是 awk 中特殊变量，表示这一行共有几个 field。 awk
对每行的操作是包含在 <code>&#123;&#125;</code> 中的命令。</p>
<p>因此，上面的代码中第一个 awk 实现了 map 过程，sort 实现了 shuffling
的过程，而第二个 awk 实现了 reduce 过程。</p>
<h2 id="多机器版本-mapreduce">多机器版本 MapReduce</h2>
<p>上面是一个单机版本的 MapReduce，然而 MapReduce
在多台机器上更能显示其威力。多机器版本的 MapReduce
首先要考虑的是不同机器间的通信问题，这里采用的是 ssh 通信方式。</p>
<p>ssh 除了可以开一个远程机器的 shell
外，还可以通过命令直接在远程机器起一个进程来运行指定程序。如运行下面的代码会在本地机器上显示
<code>hello world</code></p>
<p><code>echo "hello world" | ssh 192.168.1.10 'cat'</code></p>
<p>其通信过程首先是本机通过 ssh 连接到远程机器上，同时将
<code>hello world</code> 作为输入流传到远程机器，远程机器上的 sshd
进程截获了输入流，同时启动 cat
进程读取输入流，并将输出流返回给本地机器，本地机器的 sshd
进程同样会截获输出流，然后在本地机器输出。</p>
<p>这种分布式通信的模式在各个分布式系统中（yarn，mesos，k8s）都非常常见，每个节点都要有一个
deamon 与其他节点进行通信并进行资源管理，在这里 sshd 就相当于
daemon，只是没有资源管理功能，但是基本原理是一样的。</p>
<p>因此，利用这种方式，可将map过程放到其他机器上，如下代码所示就是将
<code>awk '&#123;for (i=0; i&lt;=NF; i++) print $i, 1&#125;'</code> 这段程序放到了
192.168.1.10 这台机器上执行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">text=$(<span class="built_in">cat</span> &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">This is my Cup</span></span><br><span class="line"><span class="string">It is not your cup</span></span><br><span class="line"><span class="string">My cup is white</span></span><br><span class="line"><span class="string">Your cup is blue</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$text</span>\</span><br><span class="line">| ssh 192.168.1.10 <span class="string">&#x27;awk &#x27;</span>&#123;<span class="keyword">for</span> (i=0; i&lt;=NF; i++) <span class="built_in">print</span> <span class="variable">$i</span>, 1&#125;<span class="string">&#x27;&#x27;</span> \</span><br><span class="line">| <span class="built_in">sort</span> \</span><br><span class="line">| awk <span class="string">&#x27;&#123;if ($1 != prev) &#123;print prev, c; c=0; prev=$1&#125; c+=$2&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>因此可将 map
过程放到其他机器上执行，并将结果存储在其他机器上，因为<strong>默认一台机器无法存储所有的数据</strong>，而输入的数据也是分布在各台机器上，这个过程具体代码如下所示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Map = <span class="string">&#x27;&#123;for (i=0; i&lt;=NF; i++) print $i, 1&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">ssh worker1 <span class="string">&#x27;awk $Map /input*.txt &gt; /tmp/o1 &amp;&amp; echo worker1 ok&#x27;</span></span><br><span class="line">ssh worker2 <span class="string">&#x27;awk $Map /input*.txt &gt; /tmp/o1 &amp;&amp; echo worker2 ok&#x27;</span></span><br><span class="line">ssh worker3 <span class="string">&#x27;awk $Map /input*.txt &gt; /tmp/o1 &amp;&amp; echo worker3 ok&#x27;</span></span><br></pre></td></tr></table></figure>
<p>上面的代码分别令三个 worker
处理它们本地的文件并将处理后的文件存储在本地，在处理完后返回消息。注意
<code>awk $Map /input*.txt &gt; /tmp/o1 &amp;&amp; echo worker1 ok</code>
需要用分号括起来，表示整条命令都在远程机器执行。</p>
<p>上面通过 ssh
启动远程程序时，一般会配置密钥访问，从而避免每次都要输入密码。</p>
<p>除了 map 过程，shuffling
过程也需要分布式执行，原因是数据无法容纳在一台机器上。之前shuffling
操作是对所有的数据进行 sort 操作，现在这种方案显然行不通，实际上
shuffling 的一个目的是将相同的 key
交给相同的worker进行处理。因此可以采取下面的方法进行分布式 shuffling</p>
<p>假设有 n 个 reduce worker，则每个 map worker 对其所处理的数据的每条
key,value 记录进行 hash(key)%n 操作，记取模后的值为 i (0&lt;=i &lt;
n),并将记录写入到本地第 i 个文件中，则最多会在本地生成 n
个文件，然后分别将这 n 个文件远程复制(scp 等)到 n 个reduce
worker的机器上。这样就会令相同的 key 被同一个 worker 处理。reduce worker
只需要对复制到其机器上的若干个文件进行 sort 和 reduce 操作即可，reduce
后的结果也是存储在各台机器上的（也可以考虑存放在一台机器，如果经过
MapReduce 后的数据量能够存放在一台机器上）。</p>
<p>上面的过程需要注意以下两点</p>
<ol type="1">
<li><p>map 和 shuffle 可以重叠，但是 map 和 reduce 不能重叠。map 和
shuffling 的重叠方法有很多，其中的一种是每个 map worker
通过上面的方法生成 n 个文件时，不是一次性将所有的 record 传送给 reduce
worker，而是达到一定数量后就复制，reduce worker 端则通过插入排序进行
sort 操作，每次接收到 map worker
传过来的文件时，就在已排序的序列上进行插入排序</p></li>
<li><p>某个 worker 的可能会被比其他的要慢很多，可能原因 load balance
问题，也就是分到这个 worker 的 record 数量太多，可以对这些 record
进行进一步的切分，但是要保证同一个 key 需要被同一个 reduce worker
处理。</p></li>
</ol>
<p>Github 上有个 <a
href="https://github.com/erikfrey/bashreduce.git">bashreduce</a>
的项目就是在 bash 上实现了
MapReduce，思路与我们前面讲的差不多，只是还考虑了很多其他细节。</p>
<p>作者本人也实现了一个 C++ 版本的 <a
href="https://github.com/wangkuiyi/mapreduce-lite">mapreduce-lite</a>，没有考虑存储问题，速度较快，感兴趣可参考。</p>
<p>另外，Hadoop 项目中也有 <a
href="https://hadoop.apache.org/docs/r1.2.1/streaming.html">Hadoop
Streaming</a>，允许用于用其他语言实现 MapReduce 操作，只要指定好 mapper
和 reducer 即可。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统笔记(1)-MapReduce</title>
    <url>/2019/01/14/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(1)-MapReduce/</url>
    <content><![CDATA[<p>一直都想系统性地学习一下分布式系统的一些理论，所以打算开个坑学习一下
MIT 的课程 <a href="https://pdos.csail.mit.edu/6.824/">6.824:
Distributed Systems</a> 。本文主要是 LEC 1
中的内容，简单介绍了分布式系统的几个核心问题，以及经典的分布式计算框架-MapReduce,
虽然这是耳熟能详的一个框架（或者说是编程范式）了，但是其设计思想至今还是非常值得参考的。</p>
<span id="more"></span>
<h2 id="分布式系统概述">分布式系统概述</h2>
<p>简单来说，分布式的目的就是通过多台机器进行协作来提供一台机器所无法提供的运算能力和存储能力。除了通过增加机器来拓展运算能力和存储能力的伸缩性，分布式会额外带来机器隔离后的安全性、多份数据副本的错误容忍性等。</p>
<p><strong>性能(performance)，一致性(consistency), 容错(fault tolerance)
是分布式系统中比较关注的问题。</strong></p>
<p>如何让总体的运算能力随着机器数量的增长而线性增长？这是 performance
所关心的，各台机器的负载差别大吗(load balance)?
网络能承受得住随着机器数量增加而增加的通信吗(共享资源的瓶颈)?所有的代码都能够被并行化吗？</p>
<p>如何让多台机器上的同一份数据副本被多个进程读写后仍然保持一致？这是
consistency
所关心的，这个过程需要考虑的问题就太多了，因此也产生了很多一致性协议(Paxos,
Raft等)专门处理这个问题。比如说当 client 或 server
在写数据的不同阶段时宕机该怎么办？网络的抖动导致了
server的假死(脑裂)怎么办？<strong>性能(performance)与一致性(consistency)总是相悖的</strong>，也就是说强一致性往往会导致比较慢的系统，高性能的系统通常会以牺牲强一致性为代价，需要根据具体场景进行
trade-off。</p>
<p>如何让不可避免的宕机不影响总体的服务？这是 fault tolerance
所关心的，在一台机器宕掉后，其执行过的 tasks
该怎么办？其他与这台机器发生过的 communication
的机器的依赖性该怎么解决？</p>
<p>可以说任意的分布式系统都会涉及到这三个问题，只是会各有侧重；目前常见的分布式系统从功能上可分为分布式计算框架(MPI,
MapReduce, Spark等)、分布式文件系统(GFS, HDFS等)、分布式调度系统(Mesos,
Yarn等)。</p>
<h2 id="mapreduce">MapReduce</h2>
<p>很久之前写过一篇关于 MapReduce 使用的文章：<a
href="http://wulc.me/2018/02/24/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%284%29-Implement%20Your%20MapReduce/">分布式机器学习(4)-Implement
Your MapReduce</a>，这里则主要是根据 MapReduce 论文着重讲述 MapReduce
的一些原理。</p>
<p>下图是从 MapReduce 的论文 <a
href="https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf">MapReduce:
Simplified Data Processing on Large Clusters</a> 中摘取的</p>
<figure>
<img src="https://wulc.me/imgs/image_1d17mcpgj1l74h1p88g19t4bvu9.png"
alt="Excutation" />
<figcaption aria-hidden="true">Excutation</figcaption>
</figure>
<p>通常 MapReduce 被人所了解的是上图中 (3)(4)(5)(6)
的过程，也就是输入文件被分成 M 个小文件，每个小文件分别在 Map phase 被
Map 函数处理后输出一系列的（key,valu) 对，然后对 key
进行哈希取模找到除了这个 key 的 reducer worker，reduce worker 在 Reduce
phase 会对通过 reduce 函数处理相同的key，两个函数的输入输出如下所示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Map: (k1,v1) → list(k2,v2)</span><br><span class="line">Reduce: (k2,list(v2)) → list(v2)</span><br></pre></td></tr></table></figure>
<p>这个过程理解起来很简单，框架使用起来也不麻烦，这是因为 MapReduce
框架隐藏了上图中通过 master 追踪各个 task 是否顺利完成、以及如何进行
fault tolerance，而这也是论文最值得关注的点之一。</p>
<h3 id="execution-overview">Execution Overview</h3>
<p>上面讲的 MapReduce
过程可以说是一个编程范式，下面主要根据原始论文讲述整体的执行流程，各个步骤的编号跟上图保持一致</p>
<ol type="1">
<li>User Program 中的 MapReduce 库会将输入分成 M 个小文件（通常是 16MB
到 64MB），然后 fork 出多个子进程</li>
<li>子进程中有一个作为 master，其他作为 worker。假设有 M 个 map task 和
R 个 reduce task（<strong>M 和 R 都远大于机器数量</strong>），master
会分配挑选处于 idle 的 worker 分配 task</li>
<li>被分配了 map task 的 worker 读入对应的输入文件，从输入文件中解析出
key/value pairs，并将每个 pair 输入用户自定义的 Map 函数，Map 函数输出的
intermediate key/value pairs 被缓存在内存中</li>
<li><strong>缓存在内存中的 intermediate key/value pairs 会被周期性地写入
map worker 本地的磁盘</strong>，根据 key 的不同分别写入到 R
个本地文件中，然后<strong>这些文件在本地的路径会传输给 master，从而
master 可以告知 reducer worker 到哪里读取数据</strong></li>
<li><strong>直到所有的 Map 过程完成，Reduce 过程才能开始</strong>；当
reduce worker 被 master 告知要读取的文件的位置时，会通过 RPC 从 map
worker 的磁盘读取这些数据；reduce worker 读取完所有的 intermediate
key/value pairs 后会针对 key 进行排序**，从而让所有相同的 key
汇聚在一块</li>
<li>reduce worker 遍历排序后的 pairs，并将每个独立的 key 及其对应的
value 集合传输给 Reduce 函数，Reduce
函数则会将输出添加至最终的文件中。</li>
</ol>
<p>在完成一个 MapReduce 计算过程后会产生 R
个文件，但是<strong>一般不需要对这 R
个文件进行合并</strong>，因为这些文件可能会被作为下一个 MapReduce
计算的输入，或者被另外的分布式引用处理，而分布式应用往往能够处理这样被分隔后的小文件。另外，这里的
MapReduce 配合了 GFS 的使用，所以从磁盘读写直接使用的是 GFS
文件系统。</p>
<h3 id="master-与-fault-tolerance">Master 与 Fault Tolerance</h3>
<p>master 会记录每个 map task 和 reduce task 的状态(idle, in-progress
或者 completed), 对于那些不是 idle 的task，master 还会记录执行这个 task
的机器。</p>
<p>从上面描述的 MapReduce 流程可知，master 是 map worker 和 reduce
worker 的桥梁，每个 map task 完成后都会将其产生的 M
个文件的路径和大小传输给 master，master 则会将这些信息 push 给那些有处于
in-progress task 的 reduce worker。</p>
<p>Fault Tolerance 可分为两大类：worker 的 Fault Tolerance 和 master 的
Fault Tolerance；而 worker 又可分为 map worker 和 reduce worker
两种，下面分别介绍针对这三种角色的 Fault Tolerance 的策略。</p>
<p>首先，master 会周期性地 ping 各个 worker，并根据是否收到回复来判断
worker 是否发生了宕机。</p>
<p><strong>当一个 map worker 被 master 判为宕机后，这个 worker 所有的
task(包括 in-progress 和 completed 的)都会被重置为 idle
状态</strong>，从而让这些 task 能够被重新分配给其他的 map worker
来重新执行。而发生这种重新执行的情况时，所有的 reduce worker
都会被告知重新执行的这个 task 的是哪个 map worker，从而让 reduce worker
从新的 map worker 那里读取数据（针对那些还没从已经宕机的 map worker
读取数据的 reduce worker，原来那些已经读了数据的 reduce worker
不需要）</p>
<p><strong>当一个 reduce worker 被 master 判为宕机后，这个 worker
那些未完成的 task(也就是处于 in-progress 状态的)会被置为 idle
状态，而已完成的 task 不会。</strong>这是因为 reduce worker 将输出写入
GFS，worker 宕机后数据仍然可以被读取，而 map worker
则是将输出结果写入到本地的磁盘，宕机后数据无法被读取</p>
<p>这里有两个问题值得思考：</p>
<ol type="1">
<li>map worker 宕机后，reduce worker 从新的 map worker
读取的结果与从原来宕机的 map worker 读取的结果是否一致？</li>
<li>如果 reduce worker
在数据写入一半的时候宕机了，已经写入的数据怎么办？</li>
</ol>
<p>第一个问题的答案是肯定的，因为 map
函数不记录状态，也就是对固定的输入有固定的输出，此外，<strong>reduce
task 会在所有的 map task 完成后才开始执行</strong>，因此也保证了 reduce
worker 总能读到 map worker 完整的输出文件。</p>
<p>第二个问题与 <strong>GFS 提供的 atomic rename
特性</strong>有关，reduce worker
会先将结果写入到临时文件中，直到所有的结果都完成后才将临时文件重命名为最终文件并写入
GFS 中；这个特性也让多个 reduce worker
重复执行一项任务时最终只产生一个文件。</p>
<p><strong>针对 master 宕机的情况，论文的做法是令 master
周期性地往磁盘写入 checkpoint</strong>，重启 master 后从上次的
checkpoint 重新执行。</p>
<h3 id="load-balancebackup-task-与-locality">Load Balance，Backup Task
与 Locality</h3>
<p>load balance 指的是某个 worker 执行 task 时间过长，导致其他已完成
task 的 worker 都在等待这个 worker
完成（因为任务之间有依赖性），这一执行时间过长的 worker 也被称为</p>
<p>文章针对这一问题的做法是<strong>把每个 task 分得尽量小，即 M(map task
的数量) 和 R(reduce task 的数量)
的值要远远大于机器数量</strong>。这样就不会出现某个 task
执行过的时间过长，不仅解决了上面的问题，还加速了 fault tolerance 后的
recovery。</p>
<p>除了 task 过大，出现 straggler 的原因也可能是机器本身的硬件问题，哪怕
task 已经分得很小了。文章解决这一问题的做法是<strong>当 straggler
出现的时候，master 会把 straggler 在做的 task 分给另外一个 worker
做，谁先做完就汇报给 master，而 master
也只会接收其中一个的完成的消息</strong>，这在文中称为 Backup Task。</p>
<p>在任意分布式系统中，当 worker
数量增多，网络通信的负载都会变大。文章利用了 MapReduce 和 GFS
架设在同一组机器上的特性，从而<strong>让 Map 过程从 GFS
读取文件时尽可能读取处于本地磁盘的的 copy</strong>（GFS
为每份数据创建了三份 copies），在本地磁盘找不到时才读取其他 worker
磁盘的数据，这样就大大减少了网络的开销，而文中又称这一特性为
Locality。</p>
<h2 id="小结">小结</h2>
<p>回到文章开头提到的分布式系统中三个比较关注的问题，MapReduce
这篇论文中主要是关注其中的 performance 和 fault tolerance。</p>
<p>为了提升 performance，通过把 task 分得更小来获得更好的 load
balance，通过 backup task 来降低 straggler 对整个系统的影响，通过
locality 来减少网络的负载。</p>
<p>针对 fault tolerance，则通过为 task 设定状态，失败的 worker 的 task
被重置为 idle 状态，从而找到新的 worker 重新执行这些 task。</p>
<p>每种框架都有其适用场景，而对于
MapReduce，首先就是<strong>任务要能够表达成一个或多个 MapReduce
过程</strong>，文中提到的一些任务包括: Distributed Grep、Distributed
Sort、Count of URL Access Frequency、ReverseWeb-Link Graph、Inverted
Index等；其次<strong>数据量要足够大</strong>才能显示出 MapReduce
的效率(其实对于任意分布式系统基本都是这样,
否则整个系统调度的开销比计算的开销还要大)；还有就是<strong>涉及到多次
shuffle (也即是多个 MapReduce
过程)时，由于要与磁盘多次交互，因此虽然能够实现，但是效率很低，</strong>这时候就要考虑其他更灵活的框架了。不要局限于一定要把算法表达成
MapReduce 过程，而是可以考虑更加灵活的框架，如 spark 等。</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统笔记(2)-RPC and threads</title>
    <url>/2019/01/16/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(2)-RPC%20and%20threads/</url>
    <content><![CDATA[<p>本系列文章是学习课程 <a
href="https://pdos.csail.mit.edu/6.824/">6.824: Distributed Systems</a>
时的一些学习笔记，整个课程的相关材料已整理至 <a
href="https://github.com/WuLC/DistributedSystemInGo">DistributedSystemInGo</a>。本文是
LEC2 的内容，主要介绍了 RPC 的概念并通过 RPC 实现了一个简单的 c/s 架构的
kv 数据库；同时介绍了多线程编程并通过两种方式实现了一个多线程爬虫。</p>
<span id="more"></span>
<p>这门课程采用的语言是 go，原因是 go 对 concurrency、RPC 和 gc
等有较好的支持，且上手较快，可以把问题集中在分布式系统而不是由于对语言不熟悉而带来的
bug。因此，上面提到的两个 demo 也是采用 go 实现。</p>
<h2 id="rpc">RPC</h2>
<h3 id="rpc-基本概念">RPC 基本概念</h3>
<p>RPC(Remote Procedure Call)
的概念很好理解，类比函数调用，只是两个函数不在一个内存空间，不能直接调用，需要通过网络进行远程调用。RPC
的调用过程如下，图片摘自 <a
href="https://www.cs.rutgers.edu/~pxk/417/notes/03-rpc.html">Remote
Procedure Calls</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1d1aklohvnmj16md1b1cbbtbs219.png"
alt="RPC" />
<figcaption aria-hidden="true">RPC</figcaption>
</figure>
<p>需要明确的一点是 RPC
只是一个概念，因此广义上任意实现远程调用的方法都可称为 RPC（如
http），而<strong>区别于各个 RPC 的实现(RPC
框架)在于其实现的协议的不同</strong>，而最基本的协议包含编码协议和传输协议。</p>
<p>编码协议表明了该如何将要传递的参数等信息打包好；常见的有基于文本编码的
xml、 json，也有二进制编码的 protobuf、binpack，也可自定义协议。</p>
<p>而传输协议则表明如何将打包好的数据传输到远端；如著名的 <a
href="https://grpc.io/">gRPC</a> 使用的 http2 协议，也有如 <a
href="https://dubbo.incubator.apache.org/en-us/">dubbo</a>
一类的自定义报文的tcp协议(精简了传输内容)等。</p>
<p>类似于计算机网络中的各种协议一样，这些协议是比较繁琐的且通用的，因此产生了很多
RPC
框架来完成这些协议层面的东西，而除了上面提到的最基本的编码协议和传输协议，成熟的
rpc 框架还会实现额外的策略,
如<strong>服务注册发现、错误重试、服务升级的灰度策略，服务调用的负载均衡</strong>等。上面提到的
gRPC 和 dubbo 就是两个比较有名的 RPC 框架，通过 RPC
框架，在编码时能够像本地调用一样使用 RPC。</p>
<p>对于一个 RPC 框架，实现中最关注以下三点 (1) <strong>Call
ID映射</strong>：即告诉远程服务器要调用的是哪个函数或应用 (2)
<strong>序列化和反序列化</strong>：即上面的编码协议 (3)
<strong>网络传输</strong>：即上面的传输协议
更详细的解析可参考这个回答，<a
href="https://www.zhihu.com/question/25536695/answer/221638079">谁能用通俗的语言解释一下什么是
RPC 框架？ - 洪春涛的回答</a>，</p>
<h3 id="rpc-in-go">RPC in go</h3>
<p>go 提供了自己的 <a href="https://golang.org/pkg/net/rpc/">rpc
库</a>，这里通过这个库来实现一个简单的 c/s 架构的 kv 数据库</p>
<p>server 端的核心代码如下，KV 这个 struct 提供了 Put 和 Get
这两个存取方法，且存取时通过 <code>sysc.Mutex</code>
进行加锁来保证一致性。通过 go 内置的 rpc 框架启动一个 server 且将 KV
注册在 1234 端口，网络传输采用的是 tcp 协议；每当 server 与一个 client
建立一个连接时，server 会启动一个线程(goroutine)
去处理这个连接对应的请求</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> KV <span class="keyword">struct</span> &#123;</span><br><span class="line">	mu       sync.Mutex</span><br><span class="line">	keyvalue <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *KV)</span></span> Get(args *GetArgs, reply *GetReply) <span class="type">error</span> &#123;</span><br><span class="line">	kv.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> kv.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	reply.Err = <span class="string">&quot;OK&quot;</span></span><br><span class="line">	val, ok := kv.keyvalue[args.Key]</span><br><span class="line">	<span class="keyword">if</span> ok &#123;</span><br><span class="line">		reply.Err = OK</span><br><span class="line">		reply.Value = val</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		reply.Err = ErrNoKey</span><br><span class="line">		reply.Value = <span class="string">&quot;&quot;</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(kv *KV)</span></span> Put(args *PutArgs, reply *PutReply) <span class="type">error</span> &#123;</span><br><span class="line">	kv.mu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> kv.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	kv.keyvalue[args.Key] = args.Value</span><br><span class="line">	reply.Err = OK</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">server</span><span class="params">()</span></span> &#123;</span><br><span class="line">	kv := <span class="built_in">new</span>(KV)</span><br><span class="line">	kv.keyvalue = <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">string</span>&#123;&#125;</span><br><span class="line">	rpcs := rpc.NewServer()</span><br><span class="line">	rpcs.Register(kv)</span><br><span class="line">	l, e := net.Listen(<span class="string">&quot;tcp&quot;</span>, <span class="string">&quot;ServerIP:1234&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> e != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(<span class="string">&quot;listen error:&quot;</span>, e)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> &#123;</span><br><span class="line">			conn, err := l.Accept()</span><br><span class="line">			<span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">				<span class="keyword">go</span> rpcs.ServeConn(conn)</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				<span class="keyword">break</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		l.Close()</span><br><span class="line">		fmt.Printf(<span class="string">&quot;Server done\n&quot;</span>)</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>client 端的程序如下，client 首先通过 Dial 函数 与 server
建立连接，Get 和 Put 则分别调用了 server 端对应的 Get 函数和 Put
函数（在 rpc.Call 中声明), 可以看到，进行 RPC 就如同本地调用一样
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Dial</span><span class="params">()</span></span> *rpc.Client &#123;</span><br><span class="line">	client, err := rpc.Dial(<span class="string">&quot;tcp&quot;</span>, <span class="string">&quot;ServerIP:1234&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(<span class="string">&quot;dialing:&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> client</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Get</span><span class="params">(key <span class="type">string</span>)</span></span> <span class="type">string</span> &#123;</span><br><span class="line">	client := Dial()</span><br><span class="line">	args := &amp;GetArgs&#123;<span class="string">&quot;subject&quot;</span>&#125;</span><br><span class="line">	reply := GetReply&#123;<span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">	err := client.Call(<span class="string">&quot;KV.Get&quot;</span>, args, &amp;reply)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(<span class="string">&quot;error:&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	client.Close()</span><br><span class="line">	<span class="keyword">return</span> reply.Value</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Put</span><span class="params">(key <span class="type">string</span>, val <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">	client := Dial()</span><br><span class="line">	args := &amp;PutArgs&#123;<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;6.824&quot;</span>&#125;</span><br><span class="line">	reply := PutReply&#123;<span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">	err := client.Call(<span class="string">&quot;KV.Put&quot;</span>, args, &amp;reply)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatal(<span class="string">&quot;error:&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	client.Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>完整的代码可参考<a
href="https://github.com/WuLC/DistributedSystemInGo/blob/master/src/LECTURE02/kv.go?1547621819033">这里</a></p>
<h3 id="failure-in-rpc">failure in RPC</h3>
<p>上面只是一个简单的 RPC
例子，没有考虑到这个过程中可能出现的异常情况。而最常见的异常个情况就是
client 发出 request 后收到不 server 的
response，引起这种问题的原因有很多：网络断了、server
宕机了等。针对这个问题有什么解决方法呢？</p>
<p>最直观也是最简单的方法是让 client 等待一段时间收不到回复后的重新发送
request，且设置重复发送的次数的上限，如果超过这个上限，则先调用的应用程序返回
error 异常信息。</p>
<p>但是，当 client 重复发送请求时，server 有可能已经收到了 client
的前一个请求，只是网络的延迟使得 client 还没收到 response，那这时候
server 就会收到重复的 request。如果 client
发出的是读请求，那么问题不大；但是如果是写操作，server
端就需要处理这些重复的写请求从而使得最终只有一个被执行。</p>
<p>这里可针对 server 端采取 <strong>at most once</strong>
的策略，即同一个 request 最多只能在 server
端被执行一次，如果收到了重复的
request，那么就将之前的结果返回。这样需要解决的问题就是为每个 request
生成一个 unique id，生成 unique id 也有很多方法，比如说可以利用 client
的 ID 及其 request 编号的组合等方法。</p>
<p>go 的 RPC 库采用的就是 at most once
的策略，库已经在传输层进行了过滤重复 request
的操作，因此在代码中无需体现这一操作。</p>
<h2 id="threads">threads</h2>
<p>多线程是 concurrency 的重要手段，在 golang 中的 thread 也被称为
goroutine，一般多线程都能够充分利用 CPU 的多个核(Python 的 Cpython
解析器除外，GIL 的限制)</p>
<p>进行多线程编程时有以下几点值得注意：</p>
<p>（1）同一个进程内的线程是共享地址空间的，因此在<strong>对共享数据进行写操作时需要加锁</strong>
（2）当任务间有依赖性，一项任务拆分给多个线程去完成时，线程间往往需要先共完成任务
A 才能开始任务 B
（3）要确定线程并行的粒度，比如说多线程爬虫，每个线程是负责一个站点？还是站点下的一个目录？一般粗粒度的实现会很简单，但是并行性不高；而细粒度的并行化程度会更高，但是会更容易出现死锁等问题。</p>
<p>下面会通过 golang
实现一个多线程爬虫，分别采用了两种方式，第一种是通过经典的队列方法（<code>channel</code>)，这种防范没有加锁；第二种则通过加锁(<code>mutex</code>)和设定任务完成的
threshold(<code>waitgroup</code>)；在这个例子中两种方式的并行化粒度均是网页</p>
<h3 id="channel">channel</h3>
<p>队列是很常见的多线程编程采用的方式，将需要执行的任务送入队列，然后线程从队列中取出任务执行，并将新的任务入列(在这个例子中就是当前网页所含有的其他网页的链接)，这里还需要额外检查网页是否已经被抓取过原因有两个</p>
<p>（1）网页间的指向有可能形成闭环，不判断会导致死循环
（2）效率问题，不希望执行重复工作</p>
<p>因此，golang 通过 channel 完成的多线程爬虫如下所示, master
从队列头读出一个网页并判断其是否已经被执行，如果没有执行，就启动一个
goroutine 来执行 dofetch 任务，dofetch
会将其当前网页所指向的其他网页入列</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">dofetch</span><span class="params">(url1 <span class="type">string</span>, ch <span class="keyword">chan</span> []<span class="type">string</span>, fetcher Fetcher)</span></span> &#123;</span><br><span class="line">    <span class="comment">// body is content of url1, urls are those to which url1 refer</span></span><br><span class="line">	body, urls, err := fetcher.Fetch(url1)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Println(err)</span><br><span class="line">		ch &lt;- []<span class="type">string</span>&#123;&#125;</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		fmt.Printf(<span class="string">&quot;found: %s %q\n&quot;</span>, url1, body)</span><br><span class="line">		ch &lt;- urls</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">master</span><span class="params">(ch <span class="keyword">chan</span> []<span class="type">string</span>, fetcher Fetcher)</span></span> &#123;</span><br><span class="line">	n := <span class="number">1</span></span><br><span class="line">	fetched := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">bool</span>)</span><br><span class="line">	<span class="keyword">for</span> urls := <span class="keyword">range</span> ch &#123;</span><br><span class="line">		<span class="keyword">for</span> _, u := <span class="keyword">range</span> urls &#123;</span><br><span class="line">			<span class="keyword">if</span> _, ok := fetched[u]; ok == <span class="literal">false</span> &#123;</span><br><span class="line">				fetched[u] = <span class="literal">true</span></span><br><span class="line">				n += <span class="number">1</span></span><br><span class="line">				<span class="keyword">go</span> dofetch(u, ch, fetcher)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		n -= <span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> n == <span class="number">0</span> &#123;</span><br><span class="line">			<span class="keyword">break</span> <span class="comment">// or close(ch)</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CrawlConcurrentChannel</span><span class="params">(url <span class="type">string</span>, fetcher Fetcher)</span></span> &#123;</span><br><span class="line">	ch := <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="type">string</span>)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		ch &lt;- []<span class="type">string</span>&#123;url&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">	master(ch, fetcher)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那终止的条件是什么呢？队列为空, 但是在 golang 中没有显示判断 channel
为空的方法，且<strong>通过 for 遍历 channel 时，只有关闭了 channel
后循环才能正常退出</strong>，否则会出现 deadlock
的错误，但是显然无法随意关闭 channel，因为每一个 goroutine
都不知道是否还有其他的 goroutine 要写入这个
channel；上面的解决方法是通过 n 来记录当前队列的长度，如果 n == 0 就关闭
channel 或退出</p>
<h3 id="mutex-与-waitgroup">mutex 与 waitgroup</h3>
<p>上面只是在 master 中判断某个 url
是否已经被访问过了，那么<strong>每个独立的 goroutine 能否自行判断某个
url 是否别访问过了呢？答案是肯定的，只是需要对存储 url 是否被访问的
hashmap 进行加锁</strong>，在 golang 中可通过 <code>sys.Mutex</code>
对某个数据进行加锁和解锁操作</p>
<p>同样，我们需要设定终止条件。该如何衡量所有任务都完成，这里我们可以<strong>想像一颗多叉树的结构，每个节点表示一个网页，而每个节点的子节点是其网页中指向的其他网页，那么一个节点被判为完成当且仅当其所有的子节点都完成</strong>，这就涉及到了上面提到的任务间的依赖性问题，实际上就是要等待
goroutines 共同完成当前节点的所有子节点，这要用到
<code>sys.Waitgroup</code> 实现的具体代码如下</p>
<figure class="highlight golang"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> fetchState <span class="keyword">struct</span> &#123;</span><br><span class="line">	mu      sync.Mutex</span><br><span class="line">	fetched <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *fetchState)</span></span> CheckAndMark(url <span class="type">string</span>) <span class="type">bool</span> &#123;</span><br><span class="line">	<span class="keyword">defer</span> f.mu.Unlock()</span><br><span class="line"></span><br><span class="line">	f.mu.Lock()</span><br><span class="line">	<span class="keyword">if</span> f.fetched[url] &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">	&#125;</span><br><span class="line">	f.fetched[url] = <span class="literal">true</span></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mkFetchState</span><span class="params">()</span></span> *fetchState &#123;</span><br><span class="line">	f := &amp;fetchState&#123;&#125;</span><br><span class="line">	f.fetched = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">bool</span>)</span><br><span class="line">	<span class="keyword">return</span> f</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CrawlConcurrentMutex</span><span class="params">(url <span class="type">string</span>, fetcher Fetcher, f *fetchState)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> f.CheckAndMark(url) &#123;</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	body, urls, err := fetcher.Fetch(url)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		fmt.Println(err)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Printf(<span class="string">&quot;found: %s %q\n&quot;</span>, url, body)</span><br><span class="line">	<span class="keyword">var</span> done sync.WaitGroup</span><br><span class="line">	<span class="keyword">for</span> _, u := <span class="keyword">range</span> urls &#123;</span><br><span class="line">		done.Add(<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(u <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">			<span class="keyword">defer</span> done.Done()</span><br><span class="line">			CrawlConcurrentMutex(u, fetcher, f)</span><br><span class="line">		&#125;(u) <span class="comment">// Without the u argument there is a race</span></span><br><span class="line">	&#125;</span><br><span class="line">	done.Wait()</span><br><span class="line">	<span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面可以说是 <code>sync.WaitGroup</code>
的经典用法，在为每个线程分配任务时通过 <code>done.Add(1)</code>
增加未完成任务， 在线程完成任务时通过 <code>done.Done()</code>
表示当前子任务已完成, 通过 <code>done.Wait()</code>
阻塞直到所有的子任务都完成。</p>
<h2 id="小结">小结</h2>
<p>这一课介绍了 RPC 和多线程编程的基本概念，并分别用 go
语言实现了一个简单的例子，主要是为后面的几个实验做准备。</p>
<p>RPC 是个广义的概念，RPC
需要解决最基本的通信协议和编码协议；除此之外，一些高级的 RPC
框架还帮我们处理了、服务注册发现、错误重试等细节，让远程调用如同本地调用一样。</p>
<p>关于多线程编程，给出的爬虫例子实现了两种形式的多线程编程，一种是
Mutex + WaitGroup 的方式，一种则是 Channel
的方式；需要注意的是，这两种方式不是非此即彼，而是可以混用的，可以参考
<a
href="https://github.com/golang/go/wiki/MutexOrChannel">MutexOrChannel</a>
的介绍，比如说通过 Mutex 来让每个单独的线程判断某个 url
是否被访问过，通过 Channel 来将未完成的队列入列，通过 WaitGroup
来分类下载资源（其实这也涉及到了并行的粒度的划分，即并行地下载某一类的资源）。回想起来，很久之前写的一个爬取几个输入法的词库的程序
<a href="https://github.com/WuLC/ThesaurusSpider">ThesaurusSpider</a>
就是这么做的，只是通过 python 实现而已，有兴趣可参考。</p>
<hr />
<p>参考：</p>
<ul>
<li><a href="https://www.zhihu.com/question/41609070">既然有 HTTP
请求，为什么还要用 RPC 调用？</a></li>
<li><a
href="https://www.zhihu.com/question/25536695">谁能用通俗的语言解释一下什么是
RPC 框架？</a></li>
</ul>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统笔记(3)-GFS</title>
    <url>/2019/01/20/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0(3)-GFS/</url>
    <content><![CDATA[<p>本系列文章是学习课程 <a
href="https://pdos.csail.mit.edu/6.824/">6.824: Distributed Systems</a>
时的一些学习笔记，整个课程的相关材料已整理至 <a
href="https://github.com/WuLC/DistributedSystemInGo">DistributedSystemInGo</a>。本文是
LEC3 的内容，介绍了分布式文件系统 GFS，GFS 为 MapReduce
提供了存储，同样是出自
Google，同样是年代久远，但是其中的一些设计思想同样值得我们参考。</p>
<span id="more"></span>
<h2 id="设计理念">设计理念</h2>
<p>GFS 的设计理念也可以理解为其适用场景</p>
<ul>
<li>整个分布式系统是由普通的商用机器构成的，因此<strong>故障会比较频繁</strong></li>
<li>系统存储着数百万级的<strong>大文件</strong>，每个文件的大小基本都大于
100MB；小文件也存在，但是不是优化的目标</li>
<li>文件系统读操作主要有两种：large streaming read 和 small random
read，且前者占主导; 区别在于 large streaming read
是<strong>顺序访问，读取量大</strong>；small random read 则刚好相反</li>
<li>文件系统的写操作主要是对文件进行追加(append)操作, 追加的数据是
large、 sequencial
的；且<strong>写入后文件就很少会被修改</strong>；同样的 small random
write 也支持，但是不是优化的目标</li>
<li>系统需要支持多个 client 同时写一个文件</li>
<li>相比低延迟，更看重<strong>高吞吐量</strong></li>
</ul>
<h2 id="系统结构">系统结构</h2>
<p>GFS 总体的系统结构如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/GFS_Architecture.png" alt="GFS" />
<figcaption aria-hidden="true">GFS</figcaption>
</figure>
<p>整个系统包括一个 master 和若干个 chunkservers，master
存储着文件系统的 metadata，chunkservers 则存储着真正的文件内容，client
会先从 master 获取文件存储在哪一个的 chunkserver，然后从这个 chunkserver
直接读取。该过程有以下几点需要注意:</p>
<h3 id="metadata">metadata</h3>
<p>master 存储的 metadata 主要包括文件系统的
namespace、文件与chunk的映射、chunk 的位置等。</p>
<p>文件系统的 namespace
在GFS中存储为B+树。树上的每个叶子节点代表普通文件，而中间节点则代表目录文件。根节点是文件系统的根目录。</p>
<p>master
启动时会将所有元数据加载至内存中，优点是元数据操作速度很快，但是由于采用的是
single master，master 的内存会限制了文件系统的可扩展性，由于每个 64MB 的
chunk 会占据 64B 的metadata，则 64GB 内存的服务器最多可支持的 chunk
的数量约为 64GB/64B =
10亿。但由于GFS应用场景是大文件，所以这个问题并不是严峻</p>
<h3 id="chunk">chunk</h3>
<p>每个大文都件被划分为若干个固定大小的 chunk，每个 chunk
在创建的时候都会被 master 赋予一个唯一的 ID，称为 chunk handle</p>
<p>chunk 的大小理论上可为任意值，GFS 中为 64MB)，大的 chunk size
有以下优点与不足</p>
<ul>
<li>减少了 client 与 master 的通信次数，从而减少了 master 和 network
的负载；对于 sequential read，chunk size 越大，数据在同一个 chunk
上的概率就越大，因此避免了读取多个 chunk</li>
<li>减少 master 存储的 metadata 的大小，因为 chunk size 越大，chunk
的数量就越小</li>
<li>可能会浪费空间，如一个 65MB 的文件会被分成两个 chunk，但是第二个
chunk 只有 1MB 的数据却占了 64MB 的大小</li>
<li>可能会导致 load imbalance，如一个小文件只有一个 chunk，因此存储这些
chunk 的 chunkserver 会成为 hot spot；但是在文章提到的应用中，hot spot
并不是一个大问题，因为文章内的应用应用场景是 read large multi-chunk
files sequentially</li>
</ul>
<p>此外，在每个 chunk
都会有另外的两个副本，分别存储在三台机器上，其作用有两个：high
availability 和 load
balancing；在这个机制中，<strong>副本位置的选取</strong>是一个比较关键的问题，一个好的副本位置定义算法满足下面特性：</p>
<ol type="1">
<li>保证足够的<strong>可靠性</strong>，例如，不能将所有副本存放在同一个磁盘或者物理机器上；</li>
<li>保证写入<strong>高效性</strong>，多副本位置尽量靠近，降低写入延迟，提高读写性能</li>
</ol>
<p>论文中创建chunk时副本位置的选择方法如下：</p>
<p>（1）选择存储空间利用率最低的节点和磁盘 （2）选择最近一段时间内新建
chunk 数量较少的节点和磁盘； （3）将多个副本分散在不同的机架上</p>
<p>1和3比较容易理解，2是为了保证一个节点/磁盘不会被频繁新建chunk（新建完接下来就是数据写入了），否则很容易沦为
hot spot，导致磁盘IO和网络带宽被占满，影响效率。</p>
<h3 id="operation-log">operation log</h3>
<p>由于 metadata 存储着 GFS 的核心信息，因此 GFS 还设置了日志记录
metadata 的变更信息，这个日志就是 operation log</p>
<p>operation log 中一个关键信息是时间信息，包括 chunk
的版本、创建时间等，从而能够处理 concurrent opration</p>
<p>client 请求的 operation 首先会被 master 接受，然后 <strong>master
会先写日志，在修改内存中的
metadata</strong>，这样即使出现断电等异常，也不会丢失更新，因为可以在重启时通过
operation log 重新构造内存的 metadata</p>
<p>如果 operation log 记录着 GFS 自使用以来的所有 operation，那么 log
会非常大且重启时构建耗时会非常长，GFS采用的机制是<strong>当 log
达到一定大小时，将当前内存的 metadata 持久化到硬盘上，称为
checkpoint；则 operation log 只需要存储创建 checkpoint 的时刻后的所有
operation，恢复时根据 latest checkpoint 恢复最新状态，且重新执行一遍
opration log 里面的操作即可</strong></p>
<h3 id="single-master">single master</h3>
<p>single master
的设计显然存在着单点故障的问题，但是论文表明这么做两个理由</p>
<ul>
<li>(1)这样大大减化了设计和实现</li>
<li>(2)实际数据直接在 client 和 chunkserver 间交流，所以 single master
不会成为 bottleneck</li>
</ul>
<p>master 与 chunkserver 通过周期性的 HeartBeat 通信，用于动态搜集
chunkserver 的状态：如 chunkserver 上有哪些 chunk，从而 master
能够及时更新而无需长期存储这些信息</p>
<h2 id="读写操作">读写操作</h2>
<p>下面主要讨论 GFS 中的读写操作</p>
<h3 id="读">读</h3>
<p>读操作比较简单，上面的系统架构图也显示了这一过程，其步骤如下</p>
<ol type="1">
<li>client 告诉 master 需要读取的具体文件及其位置(chunk index)</li>
<li>master 返回这部分文件所在的 chunservers 以及 chunk 的 version</li>
<li>client 缓存这些信息(信息有一个过期时间，client
会等到这个信息过期后才会再次向 master 请求, 从而缓解了频繁读写时，向
master 请求次数过多从而导致 master 负载过大)</li>
<li>client 请求最近的 chunkserver，然后检查 chunkserver 上 chunk 的
version 是否与从 master 获取的相同；如果相同则读取数据，否则重新向
master 请求这些信息</li>
</ol>
<h3 id="写">写</h3>
<p><strong>写操作主要分为两种：write 和 append</strong>，write
是修改数据，append 则是在文件末尾添加数据</p>
<p>首先是 write 的过程，为了让同一个 chunk 多个副本数据保持一致，
<strong>master 将存储 chunk 的其中一个 chunkserver 作为 primary，其他是
secondary，primary 用于确定数据写入这个 chunk 的顺序，secondary 则复制
primary 的写入顺序即可</strong>，下图是一个写操作的流程</p>
<figure>
<img src="https://wulc.me/imgs/gfs_write_operation.png"
alt="gfs_write" />
<figcaption aria-hidden="true">gfs_write</figcaption>
</figure>
<p>各个步骤的具体操作如下</p>
<ol type="1">
<li>client 询问 master 要写入的 chunk 所对应的 primary 和 secondary
位置（如果这时没有 primary，master就会指定一个</li>
<li>master 返回相关信息(chunk locatioin，chunk version
等)，client会把信息存入cache，以后就不再重复询问 master
以节省开销，直到该 primary 的身份失效</li>
<li>客户端把数据发给所有 replicas (包括 primary 和 secondary)，replicas
们会把数据暂存在 LRU buffer cache
中，但是<strong>此时还并没有真的写入磁盘</strong></li>
<li>当所有 replica 都确认收到数据后，client 发写入指令给
primary；<strong>primary 会给这个指令定一个序列号(当同时收到多个 client
的请求时，在 primary 这里确定顺序)</strong>，primary
依序列号修改本地的数据</li>
<li>primary 把写入指令和序列号发给
secondary，secondary都依同样序列号修改自己的数据</li>
<li>当 primary 收到 secondary 的回复时，返回成功信息给客户端</li>
<li>如果有 secondary 失败了，primary
会返回失败信息给客户端。此时数据就是不一致的。客户端会发起重试。</li>
</ol>
<p>另外一个写操作是 record append，其过程与上面相似，但是在这里
<strong>client 不会指定 offset，而是只提供数据，GFS 会把数据 append
进去后再返回 offset 给 client</strong>。</p>
<p>record append 还在 primary 添加了以下逻辑：</p>
<ul>
<li>每次 append 时会针对待写文件的最后一个 chunk; 如果发现该 chunk
剩余空间不足以写入，则把当前 chunk
用空白补齐（padding)，然后把数据写入新的chunk</li>
<li>数据的写入是at-least-once，如果写失败了（即只在部分secondary上写成功），则会在新的末尾重新写一次，这样就会导致上次已经写成功的
replica
上数据出现两次，而上次写失败的replica上会有一段空白。返回给客户端的是成功写入的offset位置</li>
<li>客户端程序需要能正确处理这些情况：对于不正确的数据，可以在每个记录开头加一个magic
number，或者加一个checksum之类；对于重复的数据，需要客户端判重，比如在记录里加一个unique
id。</li>
</ul>
<h3 id="其他策略">其他策略</h3>
<ul>
<li><strong>chunk version</strong>
<ul>
<li>上面提到读写过程中，master 均会告诉 client 对应的 chunk 目前的
version，从而保证 clinet 读取的是最新的数据</li>
<li>chunk version 会在 master 为这个 chunk 选择新的 primary
时增加，并通知包含这个 chunk 的所有 chunkservers 更新这个 version</li>
<li>如果 client 在某个 chunkserver 读到的 chunk 的 version 与从 master
读取的不同，说明这个 chunkserver 的数据不是最新的</li>
</ul></li>
<li><strong>snapshot</strong>
<ul>
<li>snapshot是对系统当前状态进行的一次拍照。用户可以在任意时刻回滚到快照的状态</li>
<li>采用 <strong>COW</strong>(<a
href="https://en.wikipedia.org/wiki/Copy-on-write">copy-on-wirte</a>)
机制实现 snapshot，即如果被 snapshot
的文件有更新操作时，就将文件的要被更新的chunk复制一份，然后对复制的chunk进行更新，而原来的chunk作为快照数据被保留，以后要恢复到该快照时，直接将该chunk读出即可</li>
<li>当GFS的Master节点收到Snapshot请求时，其处理逻辑如下</li>
</ul></li>
</ul>
<ol type="1">
<li>回收 snapshot 请求覆盖的文件的 chunks 上的租约(即<strong>撤销
primary</strong>)，这样的话接下来客户端要对文件修改时，就必须向 master
申请，而此时 master 就可以对 chunk 进行复制</li>
<li>master 在日志中记录本次 snapshot 操作，然后在内存中执行 snapshot
动作，具体是将被 snapshot
的文件或目录的元数据复制一份，<strong>被复制出的文件与原始文件指向相同的
chunk</strong>；</li>
<li>假如客户端申请更新被 snapshot 的文件内容，那么找到需要更新的
chunk，向其多个副本发送拷贝命令，在其<strong>本地创建出 chunk
的副本</strong>
，之所以本地创建是因为可以避免跨节点之间的数据拷贝，节省网络带宽；</li>
<li>客户端收到 master 的响应后，表示该 chunk 已经 COW
结束，接下来客户端的更新流程与正常的没有区别。</li>
</ol>
<ul>
<li>checksum</li>
<li>checksum
解决的是数据完整性问题，即磁盘损坏从而导致数据损坏的问题</li>
<li>每个 chunk 会被划分为大小为 64KB 的block，每个 block 有一个 32 位的
checksum</li>
<li>client 从某个 chunkserver 读取数时，chunkserver
首先会验证要读取的数据的 checksum，如果 checksum
不符合已知记录(写入时的记录)，会返回错误，从而让 client 去读取其他
chunkserver 上的 chunk</li>
</ul>
<h2 id="一致性">一致性</h2>
<p>由于 GFS 中的 metadata 只在 master 可写，因此通过加锁保证修改的
atomicity；而对于修改 metadata 的 concurrent operation，operation log
中定义了这些 operation 的顺序， <strong>metadata
的一致性能够得到保证</strong>。</p>
<p>因此这里的一致性着重讨论的是文件的一致性，GFS
针对文件定义了以下的一致性状态</p>
<figure>
<img src="https://wulc.me/imgs/gfs_consistent_state.png"
alt="consistent state" />
<figcaption aria-hidden="true">consistent state</figcaption>
</figure>
<p>上图中的四种状态含义如下</p>
<ul>
<li>defined：从客户端角度来看，客户端完全了解已写入集群的数据的
offset，例如，客户端串行写入且成功（serial
success），此时的状态是defined</li>
<li>consistent：客户端角度来看，chunk 多副本的数据完全一致，但不一定
defined(defined 包含了 consistent)</li>
<li>inconsistent：多副本数据不一致</li>
<li>undefined：数据未定义</li>
</ul>
<p>下面分别以几个案例介绍上面的状态，这部分内容主要摘自<a
href="https://zhuanlan.zhihu.com/p/28155582">这里</a></p>
<p><strong>serial write</strong></p>
<p>当 client
串行更新时时，客户端自己知道写入文件范围以及写入数据内容，且本次写入在数据服务器的多副本上均执行成功。因此，本次写结果对于客户端来说就是明确的，且多副本上数据一致，故而结果是
<strong>defined</strong>。如下图：</p>
<figure>
<img src="https://wulc.me/imgs/gfs_defined_write.png"
alt="gfs-defined" />
<figcaption aria-hidden="true">gfs-defined</figcaption>
</figure>
<p><strong>concurrent write</strong></p>
<p>多个 client 同时写入时,
由于多个客户端由于<strong>写入范围可能交叉而形成交织写</strong>。这时候，由于单个客户端无法决定写入顺序（只有
primary
才能决定谁先写谁后写），因此，即使写入成功，客户端仍无法确定在并发写入时交叉部分最终写入结果，但是因为写入成功，所以多副本数据必然一致，
如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/gfs_consistent_undefined_write.png"
alt="consistent_undefined" />
<figcaption aria-hidden="true">consistent_undefined</figcaption>
</figure>
<p>图中红色部分代表并发追加的部分，这部分数据由于无法确定谁先谁后执行，因此结果不确定；但由于跟新成功，因此，副本间数据是一致的，这就是<strong>consistent
but undefined</strong>。需要注意的是，consistent but undefined
只会出现在<strong>原始的write操作被划分为几个子操作时</strong>，原文解析如下</p>
<blockquote>
<p>If a write by the application is large or straddles a chunk boundary,
GFS client code breaks it down into multiple write operations. They all
follow the control flow described above but may be interleaved with and
overwritten by concurrent operations from other clients. Therefore, the
shared file region may end up containing fragments from different
clients, although the replicas will be identical because the individual
operations are completed successfully in the same order on all replicas.
This leaves the file region in consistent but undefined state as noted
in Section 2.7.</p>
</blockquote>
<p>而无论是 serial write 还是并行 concurrent write，一旦失败，多个 chunk
副本上的数据可能都不一致了，因此便是
inconsistent，必然也是undefined。</p>
<p><strong>append</strong></p>
<p>上面提到，client 的 append 操作无需指定offset，由 chunk 的 primary
根据当前文件大小决定写入offset，在写入成功后将该offset返回给客户端。因此，<strong>客户端能够根据offset
确切知道写入结果，无论是串行写入还是并发写入，其行为是defined</strong>。如下所示</p>
<figure>
<img src="https://wulc.me/imgs/gfs_defined_append.png"
alt="defined append" />
<figcaption aria-hidden="true">defined append</figcaption>
</figure>
<p>假设上面的append经历了一次重试，那可能实际chunk的布局如下</p>
<figure>
<img src="https://wulc.me/imgs/gfs_inconsistent_append.png"
alt="inconsistent append" />
<figcaption aria-hidden="true">inconsistent append</figcaption>
</figure>
<p>由于第一次写失败（错误可能发生在任意一个副本），导致了多副本之间从50至80的数据可能不一致。但接下来重试成功，从80至110之间的数据一致，因此，其状态是
<strong>interspersed with inconsistent</strong>。</p>
<h2 id="小结">小结</h2>
<p>本文主要介绍了 GFS 的适用场景、系统架构、读写过程以及
一致性的保证，GFS 可以说是为 MapReduce 量身定做的文件系统:
大文件、文件写入后基本不修改、更着重吞吐量等，也<a
href="https://zhuanlan.zhihu.com/p/36752400">有人说</a>认为 GFS 也就没有
MapReduce 了，其实与其说 MapReduce 多么牛，不如说是GFS牛，因为 MapReduce
模型早就是数据库领域几十年前玩剩下的了, 但是只有 Google
做出了那种廉价高效的分布式系，主要是因为 Google 的下层的支持系统也就是
GFS 做得好。</p>
<hr />
<p>参考</p>
<ul>
<li><a
href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/035fc972c796d33122033a0614bc94cff1527999.pdf">The
Google File System</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28155582">Google File
System</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/36752400">Paper Reading:
GFS</a></li>
</ul>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分批训练过大的数据集</title>
    <url>/2017/11/18/%E5%88%86%E6%89%B9%E8%AE%AD%E7%BB%83%E8%BF%87%E5%A4%A7%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    <content><![CDATA[<p>在深度学习中训练网络时，往往会出现训练数据过于庞大从而无法全部加载到内存中的情况，这里讲述的就是如何分批训练一个庞大的数据集，下面会以Keras
中的训练为例进行讲述。</p>
<span id="more"></span>
<p>分批处理的思路就是先将那个较大的数据处理成若干个较小的数据文件（如共1000000
条记录，处理成 1000 个小文件，每个小文件 1000
条记录），然后依次读取各个小的数据文件到内存中进行训练，这里的利用了
python 的 generator 特性来依次读取各个文件的内容。</p>
<p>如下代码所示,就是每次读取 <code>num_files</code> 个文件并合并成
<code>X_train</code> 和 <code>Y_train</code>
并返回，直到整个目录下的文件都被遍历一遍。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_batch_generator</span>(<span class="params">train_data_dir = <span class="string">&#x27;./processed_data/train/&#x27;</span>, num_files = <span class="number">1</span></span>):</span><br><span class="line">    files = <span class="built_in">sorted</span>(os.listdir(train_data_dir))</span><br><span class="line">    count = num_files</span><br><span class="line">    embeddings, labels = [], []</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Reading file &#123;0&#125;...........&#x27;</span>.<span class="built_in">format</span>(file))</span><br><span class="line">        gc.collect()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(train_data_dir + file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> rf:</span><br><span class="line">            data = pickle.load(rf)</span><br><span class="line">        embeddings.append(data[<span class="string">&#x27;embedding&#x27;</span>])</span><br><span class="line">        labels.append(data[<span class="string">&#x27;label&#x27;</span>])</span><br><span class="line">        count -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> count == <span class="number">0</span>: </span><br><span class="line">            X_train, Y_train = np.concatenate(embeddings), np.concatenate(labels)</span><br><span class="line">            gc.collect()</span><br><span class="line">            count = num_files</span><br><span class="line">            embeddings, labels = [], []</span><br><span class="line">            <span class="keyword">yield</span> (X_train, Y_train)</span><br></pre></td></tr></table></figure>
<p>这样读取文件对应的训练方法如下（以Keras中的模型训练为例进行说明）</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;################&#123;0&#125; epochs#############&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> x_train, y_train <span class="keyword">in</span> train_batch_generator(num_files = <span class="number">3</span>):</span><br><span class="line">        <span class="built_in">print</span>(x_train.shape, y_train.shape)</span><br><span class="line">        gc.collect()</span><br><span class="line">        model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = <span class="number">100</span>, validation_data = (x_test, y_test))</span><br></pre></td></tr></table></figure>
<p>另一种方法不需要将大文件分成若干个小文件，而是直接打开整个大文件逐行读取，然后读取了一定数目的行后通过
<code>yield</code> 返回,
这种方法的一个问题就是训练过程中必须要保持整个文件为打开状态，此时如果发生系统故障等异常可能会损坏文件，而将大文件分为若干的小文件则能够很大程度上避免这个问题。</p>
<p>这种方法的另外一个问题就是不能对训练样本进行的
shuffle，由于这深度神经网络的训练都是基于 SGD
模式的，因此需要对其训练样本进行 shuffle，具体可参考<a
href="https://www.quora.com/Does-the-order-of-training-data-matter-when-training-neural-networks">这个问题</a>。但是当训练样本很大时，显然无法读取整个文件后在内存进行
shuffle，但是如果将大文件分成小文件后，可在系统内存能够承受的范围内对几个小文件进行shuffle(如相邻的三个小文件)，虽然这种shuffle是一种局部的shuffle，但是可以通过改变进行shuffle的小文件的间隔并进行多次的shuffle（如间隔分别从0递增），从而近似全局的shuffle。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>听说你觉得生活很无聊</title>
    <url>/2015/11/18/%E5%90%AC%E8%AF%B4%E4%BD%A0%E8%A7%89%E5%BE%97%E7%94%9F%E6%B4%BB%E5%BE%88%E6%97%A0%E8%81%8A/</url>
    <content><![CDATA[<blockquote>
<p>文章为转载，作者：马德，作家，已出版《当我放过自己的时候》、《允许自己虚度时光》等。</p>
</blockquote>
<p>（一）
一辈子活下来，常常是，在最有意思的时候，没有有意思地过，在最没意思的时候，想要有意思地过结果却再也过不出意思。</p>
<p>或者，换一种表述就是，在看不透的时候，好看的人生过得不好看；看透了，想过得好看，可是人生已经没法看了。</p>
<p>这句话说得并不绕。其实，人生比这个绕多了。</p>
<p>人生就是这样的一场游戏：在欲望浮沉中，把生命扔到很远很远，最后，只为了找到很近很近的那个简单的自己。</p>
<span id="more"></span>
<p>（二）</p>
<p>有一年，到大连旅游，参观旅顺日俄监狱。印象中，地牢般的监狱，只有很窄的一方窗户开在地上，可以看到人世的阳光。</p>
<p>在一孔窗户周围，看到一茎绿草，小小的，嫩嫩的，在风中摇曳。我想，这应是在那里苦难度日的囚犯们，所能见到的全部蓬勃和生机了吧。但是，那么多的监牢，每一孔窗户前，会恰好有一粒草的种子落在那里吗？会有生命的绿意，落在绝望的人生里吗？</p>
<p>那得多么幸运啊！</p>
<p>而我们的窗外，就有蓝天白云，我们的身边，就有鲜花绿草，没有谁囚禁我们，但我们却囚禁了自己。</p>
<p>常常是，在追不上的时候，才去追；在味道尽去的时候，才想品；在不得已时候，才珍惜得已；在人生的大片美好过到支离破碎后，才去捡拾一些碎片，拼凑美好。</p>
<p>（三） <strong>生活就是一个七天接着一个七天。</strong></p>
<p>不是日子重复导致了枯燥和无聊，而是你枯燥无聊，把气撒在了日子的重复上。</p>
<p>其实，都在重复。位高权重的，富可敌国的，没有谁的日子不是一个七天接着另一个七天。只不过，当你仰慕谁，就会美化对方的重复，认为人家重复得有趣味有意义。其实，这一切，都是仰慕的光环散发出的五彩。</p>
<p>重复，赋予每个人的本质和意义都是一样的。</p>
<p>多重复才算重复呢？你看那些一天到晚打麻将的人，每天面对的就是那一百多张牌，然后，洗牌，码牌，打牌，和牌。论理说，该盯得头晕眼花，坐得腰酸腿疼，琢磨得心力交瘁了吧，但嗜打的人从来乐此不疲，没有一个喊累的，也没有一个喊重复的。</p>
<p>为什么呢？上瘾。</p>
<p>其实，有瘾，才是快乐生活的关键。瘾，就是情趣，它会让每一个日子，像绽开的花朵，一寸一寸阳光踩过的花瓣，无论多重复，都会美得各不相同。</p>
<p>（四）</p>
<p>活得没滋味的时候，去坐坐北京地铁，从1号线到15号线，在上班的早高峰。</p>
<p>你一下子就释然了。当然了，一下子也更崩溃了。</p>
<p>密密麻麻的人，如雨前的蚁，簇拥着，没有喧闹，没有声响，是令人压抑的寂静。几乎不用走，“哗”被推上车，“哗”又被挤下车。就这样，每天，还未曾上班呢，两三个小时，先折耗在了路上。无论你蓄了多少激情和活力，也会被日复一日地磨蚀殆尽。关键是，还有下班呢，还有一个晚高峰等着呢。</p>
<p>谁比谁活得更容易？</p>
<p>但，即便这样，一定也有活得幸福的“北漂”。幸福的人生活里不是没有不堪和琐碎，不是没有疲惫和失望，而是不管生活给了多大的泥淖，也要让生命拔腿出来，临清流，吹惠风，也要在心中修篱种菊，怡养内在的优雅和高贵。</p>
<p><strong>幸福是一种自我剥离的能力，以及自我生成的能力。生活中，没有多少幸福是现成的，有幸福的人，只是会幸福罢了。</strong></p>
<p>（五）</p>
<p>一个整宿睡得很好的人，会嫉妒一个睡眠质量不怎么好、甚至半宿还会醒一会儿的人。乍听，简直不可思议。再解释，你就明白了。原来，那个睡得很“好”的人，是靠安定这种镇静药片睡过一个晚上又一个晚上的。</p>
<p>如果不说透，从表面上看，应该是后者羡慕甚至嫉妒前者才是。因为，前者太好了，好得简直无与伦比。</p>
<p>生活，有多少是我们看透了本质的。你羡慕的权贵，前呼后拥，看起来那么风光，可是风光背后有多少痛苦，对方不说，你不会知道；你羡慕的富有，宝马香车，锦衣玉食，看起来，是那么荣华，这荣华背后有多少痛苦，对方不说，你不会知道。</p>
<p>也就是说，即便失点眠，你依然是那个睡得很好的人。即便过得平凡而宁静，你也会赢得别人羡慕。甚至，这里边，那些你羡慕着的人也在羡慕你。</p>
<p>只是，你要知道，这个世界没有一个人愿把这种羡慕轻易告诉你。</p>
<hr />
<p>转载
作者：马德，作家，已出版《当我放过自己的时候》、《允许自己虚度时光》等。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>命令行编译Java源文件</title>
    <url>/2016/01/13/%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%AF%91Java%E6%BA%90%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<p>众所周知，Java是一门编译型语言，需要编译成字节码才能在JVM上运行。常用的IDE如Eclipse等将编译、运行等步骤结合起来一起执行，只需要按下Run即可完成编译和运行的工作。但是实际上编译java程序的核心是JDK。本文主要讲述了只安装jdk通过命令行来编译运行Java程序。</p>
<span id="more"></span>
<h2 id="jdk-与-jre">JDK 与 JRE</h2>
<p>说到JDK和JRE的关系。可以简单认为<strong>JDK是用来编译java文件的，而jre是用来运行编译生成的class文件。JDK中包含JRE</strong>，在JDK的安装目录下有一个名为jre的目录，里面有两个文件夹bin和lib，在这里可以认为bin里的就是jvm，lib中则是jvm工作所需要的类库，而jvm和
lib和起来就称为jre。</p>
<p>另外在windows下安装jdk是会有选择是否安装单独的jre，如果选择安装，那么就会安装了两套jre，一套包含在jdk安装目录中，另外一套则是独立安装的jre。那么<strong>这两套jre有区别吗</strong>？</p>
<p>答案是有的，因为jdk是作为开发使用的，而jre仅仅是作为运行java程序的环境。因此<strong>具备开发功能的jdk自己的jre下会同时有client性质的jvm和server性质的
jvm，而仅仅作为运行环境的jre下只需要client性质的jvm.dll就够了。</strong></p>
<p>可根据需要编译的源文件的数目和位置将通过命令行编译运行java程序分成两大类。一类是只有单一的源文件，另外一种是有多个源文件。</p>
<h2 id="单个源文件">单个源文件</h2>
<p>单个原文件是最简单的了，编译命令为： <code>javac  source.java</code>
运行的命令为 <code>java source</code>
上面没有考虑单个源文件中引入的jar包，假如引入了不在classpath环境变量中的jar包时，需要在编译时加上<code>-classpath</code>参数。即命令为：
<code>javac -classpath  *.jar  source.java</code></p>
<h2 id="多个源文件">多个源文件</h2>
<p>编译多个源文件是指其中一个源文件引用了另外一个源文件里面的类。这里可以根据源文件是否在同一个包进行以下分类。</p>
<h3 id="源文件在同一个包">源文件在同一个包</h3>
<p>这时候只需要编译“最顶层”的类的源文件即可，比如说有以下三个类：</p>
<p>类E源文件如下 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">E</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">E</span><span class="params">()</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">&quot;this is E&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>类C源文件如下 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span>  <span class="keyword">class</span> <span class="title class_">C</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="title function_">C</span><span class="params">()</span>&#123;</span><br><span class="line">		E e=<span class="keyword">new</span> <span class="title class_">E</span>();</span><br><span class="line">		System.out.println(<span class="string">&quot;this is C&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>类D源文件如下 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">D</span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String [] args)</span>&#123;</span><br><span class="line">		C c=<span class="keyword">new</span> <span class="title class_">C</span>();</span><br><span class="line">		System.out.println(<span class="string">&quot;this is D&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
现在这三个源文件在同一个包，也就是同一个文件夹下，此时<strong>只需要编译类D的源文件即可</strong>，执行时也只需要执行类D的class文件。即依次执行下面命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">javac D.java</span><br><span class="line">java D</span><br></pre></td></tr></table></figure>
<p>得到的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">this is E</span><br><span class="line">this is C</span><br><span class="line">this is D</span><br></pre></td></tr></table></figure>
<h3 id="源文件不在同一个包">源文件不在同一个包</h3>
<p>这种情况下又可分为两种情况，详见下面例子</p>
<h4 id="第一种情况">第一种情况：</h4>
<p>类B的源文件如下： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> tcp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="title function_">B</span><span class="params">()</span>&#123;</span><br><span class="line">	System.out.println(<span class="string">&quot;this is B&quot;</span>);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>类A的源文件如下： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tcp.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String [] args)</span>&#123;</span><br><span class="line">		B b=<span class="keyword">new</span> <span class="title class_">B</span>();</span><br><span class="line">		System.out.println(<span class="string">&quot;this is A&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
这时候需要建立一个名为<code>tcp</code>的目录,将类B的源文件放到tcp目录中，然后类A的源文件与tcp目录在同一个目录下，这时候只需要进入到类A所在目录下执行<code>javac A.java</code>即可生成<code>A.class</code>和<code>B.class</code>两个类文件，且<code>B.class</code>在tcp目录下生成。再执行命令<code>java A</code>便可得到以下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">this is B</span><br><span class="line">this is A</span><br></pre></td></tr></table></figure>
<h4 id="第二种情况">第二种情况</h4>
<p>在第一种情况下类A并没有在任何包中，那么假如类A也在一个包中该怎么编译运行呢？</p>
<p>在类A的源文件的开头添加多一行<code>pacakge udp;</code>即类A在包udp中，这时候通过命令行该怎么编译？</p>
<p>首先建立<code>tcp</code>和<code>udp</code>两个文件夹且将他们放在同一目录，tcp目录中放置<code>B.java</code>,udp目录中放置<code>A.java</code>,编译的方法有两种：</p>
<p>第一种：进入到udp目录，执行命令<code>javac -classpath .. A.java</code>
第二种：不进入tcp或udp，在tcp和udp所在的目录执行命令<code>javac udp\A.java</code></p>
<p>第一种方法的-classpath参数指出了tcp包所在目录，<code>..</code>表示上一层目录，这里采用了相对路径，也可采用绝对路径。</p>
<p>第二种方法利用了jdk编译时遇到import的包时会先在当前目录寻找的特性。</p>
<p>执行A程序的步骤则只有一种方法，就是在tcp和udp目录下执行命令
<code>java udp.A</code></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据是否能够改造你的行业</title>
    <url>/2017/06/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E8%83%BD%E5%A4%9F%E6%94%B9%E9%80%A0%E4%BD%A0%E7%9A%84%E8%A1%8C%E4%B8%9A/</url>
    <content><![CDATA[<p>本文内容主要来源于<a
href="https://www.zhihu.com/lives/778738193250942976">该知乎
live</a>，主要介绍了深度学习为什么能在大数据的环境下有效，并描述了大数据的三个特点：<strong>行为数据、全量加工和自动化应用</strong>。</p>
<span id="more"></span>
<h2 id="深度学习为何有效">深度学习为何有效</h2>
<figure>
<img src="https://wulc.me/imgs/image_1bibon900cpa18bnft25jm1v1l9.png"
alt="机器学习的发展" />
<figcaption aria-hidden="true">机器学习的发展</figcaption>
</figure>
<p>深度学习属于表示表示学习的一种，将特征提取和模型训练放到一起，消除了领域知识(特征工程)的影响</p>
<p>深度学习有效的原因</p>
<p>1）深度学习的表达能力更强，模型能够容纳更多的数据
2）深度学习的模型很早就提出了，但是一直缺乏有效的优化方法（求解方法），无法将桶灌满，直到
GPU 的出现，相当于图中的水管的出现
3）能够获取的数据量变得更大（水源）</p>
<figure>
<img src="https://wulc.me/imgs/image_1biboqno31et14vufm3jqanogm.png"
alt="深度学习模型" />
<figcaption aria-hidden="true">深度学习模型</figcaption>
</figure>
<h2 id="行为数据全量加工自动化应用">行为数据、全量加工、自动化应用</h2>
<p>能够利用大数据改造的产业必须要有以下三个特点</p>
<p>1）具有行为数据 2）需要进行全量加工 3）能够部署自动化应用</p>
<h3 id="行为数据-v.s-交易数据"><strong>行为数据 v.s
交易数据</strong></h3>
<figure>
<img src="https://wulc.me/imgs/image_1bibpk6le148m1kbm1cobs68lpi1g.png"
alt="交易数据和行为数据" />
<figcaption aria-hidden="true">交易数据和行为数据</figcaption>
</figure>
<p>由于两者的特点不同，交易数据和行为数据的加工方式差别很大</p>
<h3 id="全量加工-v.s-采样加工"><strong>全量加工 v.s
采样加工</strong></h3>
<p>问题属性决定采用哪种加工</p>
<figure>
<img src="https://wulc.me/imgs/image_1bibq50b31boak2s1ntfktrmf41t.png"
alt="采样分析和全量加工" />
<figcaption aria-hidden="true">采样分析和全量加工</figcaption>
</figure>
<p>全量加工是大数据的一个根本特点</p>
<p>CTR
预估是一个全量加工的问题，但是实际中往往要对负样本抽样以解决正负样本不平衡问题</p>
<h3 id="洞察应用-v.s-全自动化应用"><strong>洞察应用 v.s
全自动化应用</strong></h3>
<p>洞察指的是根据大量数据生成报表，然后通过人观察这些报表并作出决策</p>
<p>全自动化指的是数据的产生，加工，交易形成闭环</p>
<figure>
<img src="https://wulc.me/imgs/image_1bibqfpl114vp1h9s15nak9t1ftq2a.png"
alt="全自动化应用" />
<figcaption aria-hidden="true">全自动化应用</figcaption>
</figure>
<p>因此，要将大数据应用到业务中，需要回答这三个问题</p>
<p>1）行为数据从哪里来？ 2）要全量加工的问题是什么？
3）如何做到自动化</p>
<p>下面是根据大数据的三个特点介绍的三个应用场景，其中广告行业是已经发展的比较成熟的了，而保险行业和医疗行业则是未来有这种发展趋势的</p>
<figure>
<img src="https://wulc.me/imgs/image_1bibr8ek9gd7cecftn1fm3mqg2n.png"
alt="广告行业" />
<figcaption aria-hidden="true">广告行业</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1bibreoiq1c3cm561ausnqpvc534.png"
alt="保险行业" />
<figcaption aria-hidden="true">保险行业</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1bibsfvk3100ns471bdd3abq023h.png"
alt="大数据医疗行业" />
<figcaption aria-hidden="true">大数据医疗行业</figcaption>
</figure>
<h2 id="自动化系统一般框架">自动化系统一般框架</h2>
<p>上面提到了在大数据的环境下需要将处理自动化，下面以发展得较为成熟的计算广告为例讲述自动化系统的一般框架</p>
<p>这个系统的分解以及各部分的作用如下所示，更详细的可参考<a
href="http://wulc.me/2017/04/20/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0%281%29--%E5%B9%BF%E5%91%8A%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/">这里</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1bibuiuc31d6h77k188415gs16m23u.png"
alt="自动化系统一般框架" />
<figcaption aria-hidden="true">自动化系统一般框架</figcaption>
</figure>
<p>由于开源软件的发展，搭建这样的系统难度不大，开源软件的几个优势和顾虑如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bibusqjp1ud23h118qaqdes0t4b.png"
alt="搭建系统" />
<figcaption aria-hidden="true">搭建系统</figcaption>
</figure>
<p>核心业务的迭代应该是非常快而且非常重要的，不能被开源软件的开发进度控制。</p>
<p>最后，在具体的业务中应用到数据时，一定要遵循以下准则：<strong>数据高于经验，让数据来决策，不能只是先入为主做假设</strong>，有些现象是想不到的</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>大规模机器学习框架的四重境界</title>
    <url>/2018/03/10/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E7%9A%84%E5%9B%9B%E9%87%8D%E5%A2%83%E7%95%8C/</url>
    <content><![CDATA[<p>文章为转载，原文链接见<a
href="https://zhuanlan.zhihu.com/p/29968773">这里</a>，作者是 <a
href="https://www.zhihu.com/people/carbon-zhang/activities">carbon
zhang</a>。这篇文章主要介绍了分布式机器学习中的若干重点概念和经典论文，包括数据并行和模型并行、分布式框架的流派、参数服务器以及同步协议的演进等，非常值得一看。</p>
<span id="more"></span>
<h2 id="背景">背景</h2>
<p>自从google发表著名的 GFS、MapReduce、BigTable
三篇paper以后，互联网正式迎来了大数据时代。大数据的显著特点是大，哪里都大的大。本篇主要针对volume大的数据时，使用机器学习来进行数据处理过程中遇到的架构方面的问题做一个系统的梳理。</p>
<p>有了GFS我们有能力积累海量的数据样本，比如在线广告的曝光和点击数据，天然具有正负样本的特性，累积一两个月往往就能轻松获得百亿、千亿级的训练样本。这样海量的样本如何存储？用什么样的模型可以学习海量样本中有用的pattern？这些问题不止是工程问题，也值得每个做算法的同学去深入思考。</p>
<h3 id="简单模型or复杂模型">简单模型or复杂模型</h3>
<p>在深度学习概念提出之前，算法工程师手头能用的工具其实并不多，就LR、SVM、感知机等寥寥可数、相对固定的若干个模型和算法；那时候要解决一个实际的问题，算法工程师更多的工作主要是在<strong>特征工程</strong>方面。而特征工程本身并没有很系统化的指导理论（至少目前没有看到系统介绍特征工程的书籍），所以很多时候特征的构造技法显得光怪陆离，是否有用也取决于问题本身、数据样本、模型以及<strong>运气</strong>。</p>
<p>在特征工程作为算法工程师主要工作内容的时候，构造新特征的尝试往往很大部分都不能在实际工作中work。据我了解，国内几家大公司在特征构造方面的成功率在后期一般不会超过20%。也就是80%的新构造特征往往并没什么正向提升效果。如果给这种方式起一个名字的话，大概是<strong>简单模型+复杂特征</strong>；简单模型说的是算法比如LR、SVM本身并不服务，参数和表达能力基本呈现一种线性关系，易于理解。复杂特征则是指特征工程方面不断尝试使用各种奇技淫巧构造的可能有用、可能没用的特征，这部分特征的构造方式可能会有<strong>各种trick，比如窗口滑动、离散化、归一化、开方、平方、笛卡尔积、多重笛卡尔积等等</strong>；顺便提一句，因为<strong>特征工程本身并没有特别系统的理论和总结，所以初入行的同学想要构造特征就需要多读paper，特别是和自己业务场景一样或类似的场景的paper，从里面学习作者分析、理解数据的方法以及对应的构造特征的技法；久而久之，有望形成自己的知识体系。</strong></p>
<p>深度学习概念提出以后，人们发现通过深度神经网络可以进行一定程度的表示学习（representation
learning），例如在图像领域，通过CNN提取图像feature并在此基础上进行分类的方法，一举打破了之前算法的天花板，而且是以极大的差距打破。这给所有算法工程师带来了新的思路，既然深度学习本身有提取特征的能力，干嘛还要苦哈哈的自己去做人工特征设计呢？</p>
<p>深度学习虽然一定程度上缓解了特征工程的压力，但这里要强调两点：</p>
<ol type="1">
<li>缓解并不等于彻底解决，除了图像这种特定领域，在个性化推荐等领域，深度学习目前还没有完全取得绝对的优势；究其原因，可能还是数据自身内在结构的问题，使得在其他领域目前还没有发现类似图像+CNN这样的完美CP。</li>
<li>深度学习在缓解特征工程的同时，也带来了模型复杂、不可解释的问题。算法工程师在网络结构设计方面一样要花很多心思来提升效果。概括起来，深度学习代表的<strong>简单特征+复杂模型</strong>是解决实际问题的另一种方式。</li>
</ol>
<p>两种模式孰优孰劣还难有定论，以点击率预测为例，在计算广告领域往往以海量特征+LR为主流，根据VC维理论，LR的表达能力和特征个数成正比，因此海量的feature也完全可以使LR拥有足够的描述能力。而在个性化推荐领域，深度学习刚刚萌芽，目前google
play采用了WDL的结构<a
href="https://dl.acm.org/citation.cfm?id=2988454">[1]</a>，youtube采用了双重DNN的结构<a
href="https://dl.acm.org/citation.cfm?id=2959190">[2]</a>。</p>
<p>不管是那种模式，当模型足够庞大的时候，都会出现模型参数一台机器无法存放的情况。比如百亿级
feature
的LR对应的权重w有好几十个G，这在很多单机上存储都是困难的，大规模神经网络则更复杂，不仅难以单机存储，而且参数和参数之间还有逻辑上的强依赖；要对超大规模的模型进行训练势必要借用分布式系统的技法，本文主要是系统总结这方面的一些思路。</p>
<h3 id="数据并行vs模型并行">数据并行vs模型并行</h3>
<p>数据并行和模型并行是理解大规模机器学习框架的基础概念，其缘起未深究，第一次看到是在姐夫（Jeff
Dean）的blog里，当时匆匆一瞥，以为自己懂了。多年以后，再次开始调研这个问题的时候才想起长者的教训，年轻人啊，还是图样图森破。如果你和我一样曾经忽略过这个概念，今天不放复习一下。</p>
<p>这两个概念在<a
href="https://www.zhihu.com/question/53851014">这个问题</a>中沐帅曾经给出了一个非常直观而经典的解释，可惜不知道什么原因，当我想引用时却发现已经被删除了。我在这里简单介绍下这个比喻：如果要修两栋楼，有一个工程队，怎么操作？第一个方案是将人分成两组，分别盖楼，改好了就装修；第二种做法是一组人盖楼，等第一栋楼盖好，另一组装修第一栋，然后第一组继续盖第二栋楼，改完以后等装修队装修第二栋楼。咋一看，第二种方法似乎并行度并不高，但第一种方案需要每个工程人员都拥有“盖楼”和“装修”两种能力，而第二个方案只需要每个人拥有其中一种能力即可。第一个方案和数据并行类似，第二个方案则道出了模型并行的精髓。</p>
<p>数据并行理解起来比较简单，当样本比较多的时候，为了使用所有样本来训练模型，我们不妨把数据分布到不同的机器上，然后每台机器都来对模型参数进行迭代，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cl0d5u1emv1j8v5p9ogc1dfl9.png"
alt="data parallel" />
<figcaption aria-hidden="true">data parallel</figcaption>
</figure>
<p>图片取材于TensorFlow的paper<a
href="https://arxiv.org/abs/1603.04467">[3]</a>，图中ABC代表三台不同的机器，上面存储着不同的样本，模型
P
在各台机器上计算对应的增量，然后在参数存储的机器上进行汇总和更新，这就是数据并行。先忽略synchronous，这是同步机制相关的概念，在第三节会有专门介绍。</p>
<p><strong>数据并行概念简单，而且不依赖于具体的模型，因此数据并行机制可以作为框架的一种基础功能，对所有算法都生效。</strong>与之不同的是，模型并行因为参数间存在依赖关系（其实数据并行参数更新也可能会依赖所有的参数，但区别在于往往是依赖于上一个迭代的全量参数。而模型并行往往是同一个迭代内的参数之间有强依赖关系，比如DNN网络的不同层之间的参数依照BP算法形成的先后依赖），无法类比数据并行这样直接将模型参数分片而破坏其依赖关系，所以<strong>模型并行不仅要对模型分片，同时需要调度器来控制参数间的依赖关系</strong>。而每个模型的依赖关系往往并不同，所以模型并行的调度器因模型而异，较难做到完全通用。关于这个问题，CMU的Erix
Xing在<a
href="https://www.jianshu.com/p/00736aa21dc8">这里</a>有所介绍，感兴趣的可以参考。</p>
<p>模型并行的问题定义可以参考姐夫的<a
href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks">[4]</a>，这篇paper也是tensorflow的前身相关的总结，其中图</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cm9l72otn1vu6r7f1dbt13grm.png"
alt="model parallel" />
<figcaption aria-hidden="true">model parallel</figcaption>
</figure>
<p>解释了模型并行的物理图景，当一个超大神经网络无法存储在一台机器上时，我们可以切割网络存到不同的机器上，但是为了保持不同参数分片之间的依赖，如图中粗黑线的部分，则需要在不同的机器之间进行concurrent控制；同一个机器内部的参数依赖，即途中细黑线部分在机器内即可完成控制。</p>
<p>黑线部分如何有效控制呢？如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cmb1p01bq8jrq1u8ijg61dc813.png"
alt="parameter rely" />
<figcaption aria-hidden="true">parameter rely</figcaption>
</figure>
<p>在将模型切分到不同机器以后，我们<strong>将参数和样本一起在不同机器间流转</strong>，途中
ABC
代表模型的不同部分的参数；假设C依赖B，B依赖A，机器1上得到A的一个迭代后，将A和必要的样本信息一起传到机器2，机器2根据A和样本对P2更新得到，以此类推；当机器2计算B的时候，机器1可以展开A的第二个迭代的计算。了解<strong>CPU流水线</strong>操作的同学一定感到熟悉，是的，模型并行是通过数据流水线来实现并行的。想想那个盖楼的第二种方案，就能理解模型并行的精髓了。</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cmdj2u20adgtc5c6b1pkt2g.png"
alt="parameter rely controller" />
<figcaption aria-hidden="true">parameter rely controller</figcaption>
</figure>
<p>上图则是对控制模型参数依赖的调度器的一个示意图，实际框架中一般都会用DAG（有向无环图）调度技术来实现类似功能，未深入研究，以后有机会再补充说明。</p>
<p>理解了数据并行和模型并行对后面参数服务器的理解至关重要，但现在让我先荡开一笔，简单介绍下并行计算框架的一些背景信息。</p>
<h2 id="并行算法演进">并行算法演进</h2>
<h3 id="mapreduce路线">MapReduce路线</h3>
<p>从函数式编程中的受到启发，google发布了MapReduce<a
href="https://dl.acm.org/citation.cfm?id=1327492">[5]</a>的分布式计算方式；通过将任务切分成多个叠加的Map+Reduce任务，来完成复杂的计算任务，示意图如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cmk8hj1k1518k91j4eb19pv43t.png"
alt="MapReduce" />
<figcaption aria-hidden="true">MapReduce</figcaption>
</figure>
<p>MapReduce的主要问题有两个，一是原语的语义过于低级，直接使用其来写复杂算法，开发量比较大；另一个问题是依赖于磁盘进行数据传递，性能跟不上业务需求。</p>
<p>为了解决MapReduce的两个问题，Matei在<a
href="https://dl.acm.org/citation.cfm?id=2228301">[6]</a>中提出了一种新的数据结构RDD，并构建了Spark框架。Spark框架在MR语义之上封装了DAG调度器，极大降低了算法使用的门槛。较长时间内spark几乎可以说是大规模机器学习的代表，直至后来沐帅的参数服务器进一步开拓了大规模机器学习的领域以后，spark才暴露出一点点不足。如下图</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cmp3c8682rsf42j1l2r9cn4a.png"
alt="spark" />
<figcaption aria-hidden="true">spark</figcaption>
</figure>
<p>从图中可以看出，<strong>Spark框架以Driver为核心，任务调度和参数汇总都在driver，而driver是单机结构，所以spark的瓶颈非常明显，就在Driver这里</strong>。当模型规模大到一台机器存不下的时候，Spark就无法正常运行了。所以从今天的眼光来看，Spark只能称为一个中等规模的机器学习框架。剧透一句，公司开源的
<a href="https://github.com/Tencent/angel">Angel</a>
通过修改Driver的底层协议将Spark扩展到了一个高一层的境界。后面还会再详细介绍这部分。</p>
<p>MapReduce不仅是一个框架，还是一种思想，google开创性的工作为我们找到了大数据分析的一个可行方向，时至今日，仍不过时。只是逐渐从业务层下沉到底层语义应该处于的框架下层。</p>
<h3 id="mpi技术">MPI技术</h3>
<p>沐帅在<a
href="https://www.zhihu.com/question/55119470">这个问题</a>中对MPI的前景做了简要介绍；和Spark不同，MPI是类似socket的一种系统通信API，只是支持了消息广播等功能。因为对MPI研究不深入，这里简单介绍下优点和缺点吧；优点是系统级支持，性能杠杠的；缺点也比较多，一是和MR一样因为原语过于低级，用MPI写算法，往往代码量比较大。另一方面是基于MPI的集群，如果某个任务失败，往往需要重启整个集群，而MPI集群的任务成功率并不高。阿里在<a
href="https://dl.acm.org/citation.cfm?id=3098029">[7]</a>中给出了下图：</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cn0o8l6q65bh90f17io8tr4n.png"
alt="MPI" />
<figcaption aria-hidden="true">MPI</figcaption>
</figure>
<p>从图中可以看出，MPI作业失败的几率接近五成。MPI也并不是完全没有可取之处，正如沐帅所说，在超算集群上还是有场景的。对于工业届依赖于云计算、依赖于commodity计算机来说，则显得性价比不够高。当然如果在参数服务器的框架下，对单组worker再使用MPI未尝不是个好的尝试，[7]中的鲲鹏系统正式这么设计的。</p>
<h2 id="参数服务器">参数服务器</h2>
<h3 id="历史演进">历史演进</h3>
<p>沐帅在<a
href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-li_mu.pdf">[8]</a>中将参数服务器的历史划分为三个阶段，第一代参数服务器萌芽于沐帅的导师Smola的
<a href="http://vldb.org/pvldb/vldb2010/papers/R63.pdf">[9]</a>
，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cs9n1qgj71ohp8pgv6t7l454.png"
alt="parallel topic model" />
<figcaption aria-hidden="true">parallel topic model</figcaption>
</figure>
<p>这个工作中仅仅引入memcached来存放key-value数据，不同的处理进程并行对其进行处理。<a
href="http://static.usenix.org/event/osdi10/tech/full_papers/Power.pdf">[10]</a>中也有类似的想法，第二代参数服务器叫application-specific参数服务器，主要针对特定应用而开发，其中最典型的代表应该是tensorflow的前身<a
href="https://dl.acm.org/citation.cfm?id=2959190">4</a>。</p>
<p>第三代参数服务器，也即是通用参数服务器框架是由百度少帅李沐正式提出的，和前两代不同，第三代参数服务器从设计上就是作为一个通用大规模机器学习框架来定位的。要摆脱具体应用、算法的束缚，做一个通用的大规模机器学习框架，首先就要定义好框架的功能；而所谓框架，往往就是把大量重复的、琐碎的、做了一次就不想再来第二次的脏活、累活进行良好而优雅的封装，让使用框架的人可以只关注与自己的核心逻辑。第三代参数服务器要对那些功能进行封装呢？沐帅总结了这几点，我照搬如下：</p>
<p>1）<strong>高效的网络通信</strong>：因为不管是模型还是样本都十分巨大，因此对网络通信的高效支持以及高配的网络设备都是大规模机器学习系统不可缺少的；</p>
<p>2）<strong>灵活的一致性模型</strong>：不同的一致性模型其实是在模型收敛速度和集群计算量之间做tradeoff；要理解这个概念需要对模型性能的评价做些分析，暂且留到下节再介绍。</p>
<p>3）<strong>弹性可扩展</strong>：显而易见</p>
<p>4）<strong>容灾容错</strong>：大规模集群协作进行计算任务的时候，出现Straggler或者机器故障是非常常见的事，因此系统设计本身就要考虑到应对；没有故障的时候，也可能因为对任务时效性要求的变化而随时更改集群的机器配置。这也需要框架能在不影响任务的情况下能做到机器的热插拔。</p>
<p>5）<strong>易用性</strong>：主要针对使用框架进行算法调优的工程师而言，显然，一个难用的框架是没有生命力的。</p>
<p>在正式介绍第三代参数服务器的主要技术之前，先从另一个角度来看下大规模机器学习框架的演进</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8csill81sv91pbo1songrh8rf5h.png"
alt="框架演进" />
<figcaption aria-hidden="true">框架演进</figcaption>
</figure>
<p>这张图可以看出，在参数服务器出来之前，人们已经做了多方面的并行尝试，不过往往只是针对某个特定算法或特定领域，比如
YahooLDA
是针对LDA算法的。当模型参数突破十亿以后，则可以看出参数服务器一统江湖，再无敌手。</p>
<p>首先我们看看第三代参数服务器的基本架构</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cskcg2r9olg5shi1l956du5u.png"
alt="parameter server" />
<figcaption aria-hidden="true">parameter server</figcaption>
</figure>
<p>上图的 resource manager
可以先放一放，因为实际系统中这部分往往是复用现有的资源管理系统，比如yarn、mesos或者k8s；底下的training
data毋庸置疑的需要类似GFS的分布式文件系统的支持；剩下的部分就是参数服务器的核心组件了。</p>
<p>图中画了一个 <strong>server group</strong> 和三个<strong>worker
group</strong>；实际应用中往往也是类似，server group 用一个，而worker
group按需配置；server manager 是server
group中的管理节点，一般不会有什么逻辑，只有当有server
node加入或退出的时候，为了维持一致性哈希而做一些调整。</p>
<p>Worker group中的task
schedule则是一个简单的任务协调器，一个具体任务运行的时候，task
schedule负责通知每个worker加载自己对应的数据，然后去server
node上拉取一个要更新的参数分片，用本地数据样本计算参数分片对应的变化量，然后同步给server
node；server
node在收到本机负责的参数分片对应的所有worker的更新后，对参数分片做一次update。</p>
<p>这里存在的一个问题就是不同的worker同时并行运算的时候，可能因为网络、机器配置等外界原因，导致不同的worker的进度是不一样的，如何控制worker的同步机制是一个比较重要的课题。详见下节分解。</p>
<h3 id="同步协议">同步协议</h3>
<p>本节假设读者已经对随机梯度优化算法比较熟悉，如果不熟悉的同学请参考吴恩达经典课程机器学习中对SGD的介绍，或者我之前多次推荐过的书籍《最优化导论》。</p>
<p>我们先看一个单机算法的运行过程，<strong>假设一个模型的参数切分成三个分片k1，k2，k3；比如你可以假设是一个逻辑回归算法的权重向量被分成三段。我们将训练样本集合也切分成三个分片s1，s2，s3；在单机运行的情况下，我们假设运行的序列是（k1，s1）、（k2，s1）、（k3、s1）、（k1、s2）、（k2、s2）、（k3、s2）</strong>。。。看明白了吗？就是假设先用s1中的样本一次对参数分片k1、k2、k3进行训练，然后换s2；这就是典型的单机运行的情况，而我们知道这样的运行序列最后算法会收敛。</p>
<p>现在我们开始并行化，假设k1、k2、k3分布在三个server
node上，s1、s2、s3分布在三个worker上，这时候如果我们还要保持之前的计算顺序，则会变成怎样？work1计算的时候，work2和worker3只能等待，同样worker2计算的时候，worker1和work3都得等待，以此类推；可以看出这样的并行化并没有提升性能；但是也算简单解决了超大规模模型的存储问题。</p>
<p>为了解决性能的问题，业界开始探索这里的一致性模型，最先出来的版本是前面提到的<a
href="http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks">9</a>中的<strong>ASP模式，就是完全不顾worker之间的顺序，每个worker按照自己的节奏走，跑完一个迭代就update</strong>，然后继续，这应该是大规模机器学习中的freestyle了，如图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8ct5p651d7816sh1tk0n1p1g5s6b.png"
alt="ASP" />
<figcaption aria-hidden="true">ASP</figcaption>
</figure>
<p>ASP的优势是最大限度利用了集群的计算能力，所有的worker所在的机器都不用等待，但缺点也显而易见，除了少数几个模型，比如LDA，<strong>ASP协议可能导致模型无法收敛</strong>。也就是SGD彻底跑飞了，梯度不知道飞到哪里去了。</p>
<p>在ASP之后提出了另一种相对极端的同步协议BSP，Spark用的就是这种方式，如图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8ct7b2p1ps16ju7kfpfii6i6o.png"
alt="BSP" />
<figcaption aria-hidden="true">BSP</figcaption>
</figure>
<p><strong>每个worker都必须在同一个迭代运行，只有一个迭代任务所有的worker都完成了，才会进行一次worker和server之间的同步和分片更</strong>新。这个算法和严格一致的算法非常类似，区别仅仅在于单机版本的batch
size在BSP的时候变成了有所有worker的单个batch size求和得到的总的butch
size替换。毫无疑问，BSP的模式和单机串行因为仅仅是batch
size的区别，所以在模型收敛性上是完全一样的。同时，因为每个worker在一个周期内是可以并行计算的，所以有了一定的并行能力。</p>
<p>以此协议为基础的spark在很长时间内成为机器学习领域实际的霸主，不是没有理由的。此种协议的缺陷之处在于，<strong>整个worker
group的性能由其中最慢的worker决定，这个worker一般称为straggler。</strong>读过GFS文章的同学应该都知道straggler的存在是非常普遍的现象。</p>
<p>能否将ASP和BSP做一下折中呢？答案当然是可以的，这就是目前我认为最好的同步协议SSP；<strong>SSP的思路其实很简单，既然ASP是允许不同worker之间的迭代次数间隔任意大，而BSP则只允许为0，那我是否可以取一个常数s</strong>？如图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8cta3iv13eb1o6istc1ue1v9e75.png"
alt="SSP" />
<figcaption aria-hidden="true">SSP</figcaption>
</figure>
<p>不同的worker之间允许有迭代的间隔，但这个间隔数不允许超出一个指定的数值s，图中s=3.</p>
<p>SSP协议的详细介绍参见<a
href="http://papers.nips.cc/paper/4894-more-effective-distributed-ml-via-as">[11]</a>，CMU的大拿Eric
Xing在其中详细介绍了SSP的定义，以及其收敛性的保证。理论推导证明常数s不等于无穷大的情况下，算法一定可以在若干次迭代以后进入收敛状态。其实在Eric提出理论证明之前，工业界已经这么尝试过了</p>
<p>顺便提一句，考察分布式算法的性能，一般会分为 <strong>statistical
performance 和 hard performance 来看,
前者指不同的同步协议导致算法收敛需要的迭代次数的多少，后者是单次迭代所对应的耗时。</strong>两者的关系和precision，就不赘述了。有了SSP，BSP就可以通过指定s=0而得到。而ASP同样可以通过制定s=无穷大来达到。</p>
<h3 id="核心技术">核心技术</h3>
<p>除了参数服务器的架构、同步协议之外，本节再对其他技术做一个简要的介绍，详细的了解请直接阅读沐帅的博士论文和相关发表的论文。</p>
<p><strong>热备、冷备技术</strong>：为了防止server
node挂掉，导致任务中断，可以采用两个技术，一个是对参数分片进行热备，每个分片存储在三个不同的server
node中，以master-slave的形式存活。如果master挂掉，可以快速从slave获取并重启相关task。</p>
<p>除了热备，还可以定时写入checkpoint文件到分布式文件系统来对参数分片及其状态进行备份。进一步保证其安全性。</p>
<p><strong>Server node管理</strong>：可以使用一致性哈希技术来解决server
node的加入和退出问题，如图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c8ctft67143lni21uk71s2tgag7i.png"
alt="一致性哈希" />
<figcaption aria-hidden="true">一致性哈希</figcaption>
</figure>
<p><strong>当有server node加入或退出的时候，server
manager负责对参数进行重新分片或者合并。</strong>注意在对参数进行分片管理的情况下，一个分片只需要一把锁，这大大提升了系统的性能，也是参数服务器可以实用的一个关键点。</p>
<h2 id="大规模机器学习的四重境界">大规模机器学习的四重境界</h2>
<p>到这里可以回到我们的标题了，大规模机器学习的四重境界到底是什么呢？</p>
<p>这四重境界的划分是作者个人阅读总结的一种想法，并不是业界标准，仅供大家参考。</p>
<h3 id="境界1参数可单机存储和更新">境界1：参数可单机存储和更新</h3>
<p>此种境界较为简单，但仍可以使用参数服务器，通过数据并行来加速模型的训练。</p>
<h3
id="境界2参数不可单机存储可以单机更新">境界2：参数不可单机存储，可以单机更新</h3>
<p>此种情况对应的是一些简单模型，比如 sparse logistic
regression；当feature的数量突破百亿的时候，LR的权重参数不太可能在一台机器上完全存下，此时必须使用参数服务器架构对模型参数进行分片。但是注意一点，SGD的更新公式可以分开到单个维度进行计算，但是单个维度也是需要使用到上一轮迭代的所有参数(即计算预测值<span
class="math inline">\(f(w)\)</span>)。而我们之所以对参数进行分片就是因为我们无法将所有参数存放到一台机器，现在单个worker有需要使用所有的参数才能计算某个参数分片的梯度，这不是矛盾吗？可能吗？</p>
<p>答案是可能的，因为<strong>单个样本的feature具有很高的稀疏性（sparseness）</strong>。例如一个百亿feature的模型，单个训练样本往往只在其中很小一部分feature上有取值，其他都为0（假设feature取值都已经离散化了）。</p>
<p>因此<strong>计算<span
class="math inline">\(f(w)\)</span>的时候可以只拉取不为0的feature对应的那部分w即可</strong>。有文章统计一般这个级别的系统，稀疏性往往在0.1%（or
0.01%，记得不是很准，大致这样）以下。这样的稀疏性，可以让单机没有任何阻碍的计算<span
class="math inline">\(f(w)\)</span>。</p>
<p>目前公司开源的angel和AILab正在做的系统都处于这个境界。而原生spark还没有达到这个境界，只能在中小规模的圈子里厮混。Angel改造的基于Angel的Spark则达到了这个境界。</p>
<h3
id="境界3参数不可单机存储不可单机更新但无需模型并行">境界3：参数不可单机存储，不可单机更新，但无需模型并行</h3>
<p>境界3顺延境界2二来，当百亿级feature且feature比较稠密的时候，就需要计算框架进入到这层境界了，此时<strong>单个worker的能力有限，无法完整加载一个样本，也无法完整计算<span
class="math inline">\(f(w)\)</span></strong>。怎么办呢？其实很简单，学过线性代数的都知道，矩阵可以分块。<strong>向量是最简单的矩阵，自然可以切成一段一段的来计算。只是调度器需要支持算符分段而已了。</strong></p>
<h3
id="境界4参数不可单机存储不可单机更新需要模型并行">境界4：参数不可单机存储，不可单机更新，需要模型并行</h3>
<p>进入到这个层次的计算框架，可以算是世界一流了。可以处理超大规模的神经网络。这也是最典型的应用场景。此时不仅模型的参数不能单机存储，而且同一个迭代内，模型参数之间还有强的依赖关系，可以参见姐夫对
distbelief 的介绍里的模型切分。</p>
<p>此时首先需要增加一个coordinator组件来进行模型并行的concurrent控制。同时参数服务器框架需要支持namespace切分，coordinator将依赖关系通过namespace来进行表示。</p>
<p>一般参数间的依赖关系因模型而已，所以较难抽象出通用的coordinator来，而必须以某种形式通过脚本parser来生产整个计算任务的DAG图，然后通过DAG调度器来完成。对这个问题的介绍可以参考<a
href="https://www.jianshu.com/p/00736aa21dc8">Erix Xing的分享</a>。</p>
<h3 id="tensorflow">Tensorflow</h3>
<p>目前业界比较知名的深度学习框架有Caffee、MXNet、Torch、Keras、Theano等，但目前最炙手可热的应该是google发布的Tensorflow。这里单独拿出来稍微分解下。</p>
<p>前面不少图片引自此文，从TF的论文来看，TF框架本身是支持模型并行和数据并行的，内置了一个参数服务器模块，但从开源版本所曝光的API来看，TF无法用来10B级别feature的稀疏LR模型。原因是已经曝光的API只支持在神经网络的不同层和层间进行参数切分，而超大规模LR可以看做一个神经单元，TF不支持单个神经单元参数切分到多个参数服务器node上。</p>
<p>当然，以google的实力，绝对是可以做到第四重境界的，之所以没有曝光，可能是基于其他商业目的的考量，比如使用他们的云计算服务。</p>
<p>综上，个人认为如果能做到第四重境界，目前可以说的上是世界一流的大规模机器学习框架。仅从沐帅的ppt里看他曾经达到过，google内部应该也是没有问题的。第三重境界应该是国内一流，第二充应该是国内前列吧。</p>
<h2 id="其他">其他</h2>
<h3 id="资源管理">资源管理</h3>
<p>本文没有涉及到的部分是资源管理，大规模机器学习框架部署的集群往往资源消耗也比较大，需要专门的资源管理工具来维护。这方面yarn和mesos都是佼佼者，细节这里也就不介绍了。</p>
<h3 id="设备">设备</h3>
<p>除了资源管理工具，本身部署大规模机器学习集群本身对硬件也还是有些要求的，虽然理论上来说，所有commodity机器都可以用来搭建这类集群，但是考虑到性能，我们建议尽量用高内存的机器+万兆及以上的网卡。没有超快速的网卡，玩参数传递和样本加载估计会比较苦逼。</p>
<h2 id="参考文献">参考文献</h2>
<p>[1] Cheng H T, Koc L, Harmsen J, et al. Wide &amp; deep learning for
recommender systems[C]//Proceedings of the 1st Workshop on Deep Learning
for Recommender Systems. ACM, 2016: 7-10.</p>
<p>[2] Covington P, Adams J, Sargin E. Deep neural networks for youtube
recommendations[C]//Proceedings of the 10th ACM Conference on
Recommender Systems. ACM, 2016: 191-198.</p>
<p>[3] Abadi M, Agarwal A, Barham P, et al. Tensorflow: Large-scale
machine learning on heterogeneous distributed systems[J]. arXiv preprint
arXiv:1603.04467, 2016.</p>
<p>[4] Dean J, Corrado G, Monga R, et al. Large scale distributed deep
networks[C]//Advances in neural information processing systems. 2012:
1223-1231.</p>
<p>[5] Dean J, Ghemawat S. MapReduce: simplified data processing on
large clusters[J]. Communications of the ACM, 2008, 51(1): 107-113.</p>
<p>[6] Zaharia M, Chowdhury M, Das T, et al. Resilient distributed
datasets: A fault-tolerant abstraction for in-memory cluster
computing[C]//Proceedings of the 9th USENIX conference on Networked
Systems Design and Implementation. USENIX Association, 2012: 2-2.</p>
<p>[7] Zhou J, Li X, Zhao P, et al. KunPeng: Parameter Server based
Distributed Learning Systems and Its Applications in Alibaba and Ant
Financial[C]//Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. ACM, 2017:
1693-1702.</p>
<p>[8] Li M, Andersen D G, Park J W, et al. Scaling Distributed Machine
Learning with the Parameter Server[C]//OSDI. 2014, 14: 583-598.</p>
<p>[9] Smola A, Narayanamurthy S. An architecture for parallel topic
models[J]. Proceedings of the VLDB Endowment, 2010, 3(1-2): 703-710.</p>
<p>[10] Power R, Li J. Piccolo: Building Fast, Distributed Programs with
Partitioned Tables[C]//OSDI. 2010, 10: 1-14.</p>
<p>[11] Ho Q, Cipar J, Cui H, et al. More effective distributed ml via a
stale synchronous parallel parameter server[C]//Advances in neural
information processing systems. 2013: 1223-1231.</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>转载</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>如何用数据来挣钱</title>
    <url>/2017/06/05/%E5%A6%82%E4%BD%95%E7%94%A8%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%8C%A3%E9%92%B1/</url>
    <content><![CDATA[<p>本文内容主要来源于 <a
href="https://www.zhihu.com/lives/778738943326695424">该知乎
live</a>，主要简单介绍了互联网中免费的商业模式所带来的资产（数据），以及如何通过这些资产进行变现。</p>
<span id="more"></span>
<h2 id="免费模式与变现资产">免费模式与变现资产</h2>
<figure>
<img src="https://wulc.me/imgs/image_1bidaji0gba61s3u786nlt1ccv9.png"
alt="免费模式" />
<figcaption aria-hidden="true">免费模式</figcaption>
</figure>
<p>免费模式带来的后向变现资产包括</p>
<figure>
<img src="https://wulc.me/imgs/image_1bidauj3048eofg1eeg65v3pg13.png"
alt="可变现资产" />
<figcaption aria-hidden="true">可变现资产</figcaption>
</figure>
<p>其中<strong>数据依附于流量进行变现，数据提高了流量变现的价值，</strong>如下图通过数据进行人群划分后再进行广告的投放能够提高收益</p>
<figure>
<img src="https://wulc.me/imgs/image_1bide3qav17pc1s8cjav1gch1psm1g.png"
alt="数据的利用带来的效益" />
<figcaption aria-hidden="true">数据的利用带来的效益</figcaption>
</figure>
<h2 id="数据变现产品的发展历程">数据变现产品的发展历程</h2>
<p>数据变现可以说是经历四个发展阶段，由于广告在这方面的发展历程较为完备，因此以计算广告中的数据变现的发展历程来介绍，但是拓展到其他领域也是大同小异</p>
<p>1）变现人口属性数据 2）变现行为数据
3）变现第一方和第三方数据：在此阶段前只利用了广告平台提供的数据，这个阶段用了广告主自身的数据（第一方数据）
4）变现场景数据</p>
<figure>
<img src="https://wulc.me/imgs/image_1bidesbt11cnk1ji4qjjq195772a.png"
alt="广告商业产品发展历程" />
<figcaption aria-hidden="true">广告商业产品发展历程</figcaption>
</figure>
<h3 id="变现人口属性数据合约广告">变现人口属性数据（合约广告）</h3>
<p>这个阶段对应于计算广告中的合约广告，即广告主要求在符合某些人口属性的人群中投放一定量的广告，并与提供广告位方达成一定的合约。如下图中的需求节点所展示的是一些广告主的具体需求，供给节点则是一些媒体网站等的流量信息，所展示的整个系统称为担保式投放系统（Guarantee
Delivery，GD）。在这个过程中要解决在线分配（Online
delivery）的问题。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bidf8use1c5s1i4b1966rlek0o2n.png"
alt="合约分配交易模式" />
<figcaption aria-hidden="true">合约分配交易模式</figcaption>
</figure>
<p>上述这种方法在粗略定向中有效，对更精细数据的定向力不从心，因此有了竞价广告的出现</p>
<h3 id="变现行为数据竞价广告">变现行为数据（竞价广告）</h3>
<p>上面提到的精细数据（行为数据）其实代表的就是<strong>长尾数据，也就是频次很低但是数量很多的数据</strong>。实际中无法去掉长尾流量，因为长尾所占的总体比例还是很大的，在广告中的通过竞价交易模式来变现这一部分数据</p>
<p>以搜索广告为例， A 个广告主在争取 S 个广告位</p>
<figure>
<img src="https://wulc.me/imgs/image_1bidfmge212sh19hsgkrbimvq734.png"
alt="竞价的交易模式" />
<figcaption aria-hidden="true">竞价的交易模式</figcaption>
</figure>
<p>在这个过程中有个需要注意的点就是竞价是要采用<strong>广义第二高价</strong>的原则，就是广告位拍卖最终收的钱是出价中排第二的那个价格，这是由经济学博弈论得到的一个结论。</p>
<h3
id="变现第一方和第三方数据程序化交易">变现第一方和第三方数据（程序化交易）</h3>
<p>产生的原因是广告主的定制化的需求，因为竞价广告中提供的定向还不能满足广告主的个性需求，需要更精细化的定向。如广告主（称为第一方）要向其流失用户投放优惠广告，这时候流失的用户的数据只存在于第一方数据中，像
Google、百度这些是不可能为广告主找出其流失用户的。</p>
<p>程序化交易则是将用户数据展示给广告主，让广告主自己决定是否要这个广告，大大提高了中小广告主的参与度
。这种方式使得第一方的数据得到应用，同时也让第一方（广告主）有动力去购买其他渠道的用户数据（第三方数据），也就是促进了数据交易。</p>
<p>下图展示的是一个程序化交易的过程</p>
<p>2.1 用户访问媒体 2.2 媒体网站上有 ADX 的代码，将请求发送给 ADX 2.3
ADX 将该用户信息和询价请求发送给 DSP，DSP 进行竞价</p>
<p>在这个过程中，DSP 需要根据广告主提供的数据来判断 ADX
所发送的用户是否符合广告主的需求，这样广告主的数据（第一方数据）便得到了应用</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5slvh22r8a1ham1cr01jvnnf99.png"
alt="程序化交易" />
<figcaption aria-hidden="true">程序化交易</figcaption>
</figure>
<p>下如所示是第一方（广告主）数据的使用的一个具体例子：重定向，也就是找到访问过广告主网站的用户并投放广告</p>
<figure>
<img src="https://wulc.me/imgs/image_1bidk71ef18jjsmm2551t3t11444b.png"
alt="重定向" />
<figcaption aria-hidden="true">重定向</figcaption>
</figure>
<p>上面的例子仅仅是使用第一方数据，下面的例子联合使用了第一方（广告主）和第三方（媒体）的数据。</p>
<p>Look-alike
指的是本来广告主的用户基数人群就不多，需要借助广告平台的数据找到可能的新的用户，该过程也被称为新客推荐。这个过程需要广告主提供一部分的种子用户，DSP
分析这些用户的共同特点，并结合媒体网站上其他用户的数据为广告主推荐与种子用户相似的用户。</p>
<figure>
<img
src="https://wulc.me/imgs/image_1bidkbdf214os1ol41aat1e5t111r4o.png"
alt="look-alike" />
<figcaption aria-hidden="true">look-alike</figcaption>
</figure>
<h3 id="变现场景数据移动广告">变现场景数据(移动广告)</h3>
<p>主要是与移动端广告有关，通过手机可以了解到人当前所处的场景</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii4o71papfrti1v6afvku332a.png"
alt="场景" />
<figcaption aria-hidden="true">场景</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1bii4rbq6tri12528jn1h96qht2n.png"
alt="检测场景" />
<figcaption aria-hidden="true">检测场景</figcaption>
</figure>
<p>比如说每天 9
点进行地点采样一次，那么一个月下来便可知道其工作地点，便可向其推送附近商家的广告。</p>
<p>有比如说早上上班时间检测到手机从高速移动的状态变为低速移动的状态，那么就是从地铁出来了，这是便可向其推荐附件早餐店的广告。</p>
<p>这个方向比较前沿，目前还没有成熟的方案</p>
<h2 id="从电商角度看数据利用的方法">从电商角度看数据利用的方法</h2>
<p>下面以电商为例，讲述电商将其数据变现的几种途径</p>
<ol type="1">
<li>站内推荐</li>
<li>站外推荐：重定向</li>
<li>新客推荐：Look-alike</li>
</ol>
<figure>
<img src="https://wulc.me/imgs/image_1bidla39acv5a161ckqat540955.png"
alt="从电商看数据利用" />
<figcaption aria-hidden="true">从电商看数据利用</figcaption>
</figure>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>如何用数据武装运营工作</title>
    <url>/2017/06/18/%E5%A6%82%E4%BD%95%E7%94%A8%E6%95%B0%E6%8D%AE%E6%AD%A6%E8%A3%85%E8%BF%90%E8%90%A5%E5%B7%A5%E4%BD%9C/</url>
    <content><![CDATA[<p>这篇文章的内容主要来源于 <a
href="https://www.zhihu.com/lives/778742419016400896">该知乎live</a>，主要介绍了利用数据获取了用户后如何运营，从而能够尽可能长时间地留存用户，介绍了这方面的三个具体方法：建立用户转化漏斗、通过多维报表找到问题和建立实验框架。</p>
<span id="more"></span>
<p>本文主要关注下图左半部分，利用了别人的数据和流量获取了用户后该怎么运营以留存用户。</p>
<figure>
<img src="https://wulc.me/imgs/image_1biqbrl8q1lqd1q2q1t2kuji31k9.png"
alt="商业闭环" />
<figcaption aria-hidden="true">商业闭环</figcaption>
</figure>
<p>为了达到这个目标，有三个重要的方法</p>
<ol type="1">
<li>建立用户转化漏斗：总体的数据发生变化时，到底是哪个环节起了作用。</li>
<li>通过多维报表找到问题：经过上一步确定某个环节出现问题后，对这一个环节需要更细致的分解，这是需要从各个维度去分析这个环节中出现问题的原因。</li>
<li>建立灵活的实验框架：上面两步是被动地发现问题，实际中更要主动的探索新方案，新的实验框架有利于测试的快速迭代</li>
</ol>
<h2 id="建立用户转化漏斗">建立用户转化漏斗</h2>
<p>把商业目标转化为用户转化的一系列步骤，下面是两个具体例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1biqd74p4ege1ulu20ata85p6m.png"
alt="用户转化漏斗" />
<figcaption aria-hidden="true">用户转化漏斗</figcaption>
</figure>
<p>每一步都有一定的损失，且需要关注的点是前后两步的用户的比率，因为通过比率更容易看到具体的变化</p>
<p><strong>漏斗设计的原则与作用：整个漏斗过程用于优化一个唯一的目标，并将该目标分解为若干比率的乘积，便于发现问题并优化</strong>，下面是一个优化总用户时长的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1biqdjogq1b941ie019kfab1us113.png"
alt="总用户时长漏斗设计" />
<figcaption aria-hidden="true">总用户时长漏斗设计</figcaption>
</figure>
<p>设计用户漏斗需要涉及到具体的度量指标，下面是<strong>移动应用</strong>中一些常见的度量指标</p>
<p><strong>转化率/激活率</strong>：激活数和点击数的比
<strong>留存率</strong>：某日激活的用户中，经过一段时间还活跃的用户所长比例；根据设定的时间不同可分为次日留存、七日留存、月留存等
<strong>活跃用户</strong>：活跃的独立用户数，根据时间的不同可分为日活跃用户（DAU）、月活跃用户（MAU）
<strong>用户时长</strong>：每个活跃用户平均消耗的时间</p>
<p>对于网站分析，其优化目标本质上跟移动的应用一样，就是尽可能吸引并留存更多的用户，但是由于两者具体提供服务的不同，两者的度量指标也有不同的叫法，下面是网站分析中常见的度量</p>
<p><strong>UV (User View)</strong>：独立访客数 <strong>PV (Page
View)</strong>：所有浏览量 <strong>页面停留时长</strong>：页面浏览时间
<strong>跳出率 (Bounce
Rate)</strong>：指单页会话（用户打开了网站上的一个网页，然后就退出了网站）次数在所有会话次数中所占的比例，也就是用户在您网站上仅查看一个网页的会话次数所占的百分比
网站热力图：热力图是指以特殊高亮的形式显示访客热衷的页面区域和访客所在的地理区域的图示，简单来说就是分析出一个页面内各个部位的点击情况，如下是一个热力点击图</p>
<figure>
<img src="https://wulc.me/imgs/image_1biqfc1gtrti4991d2p1m7l1bqh2a.png"
alt="热力点击图" />
<figcaption aria-hidden="true">热力点击图</figcaption>
</figure>
<p>关于跳出率，高跳出率有时是网站本身的属性决定的，这时候就没必要做更多的优化，
<a
href="https://support.google.com/analytics/answer/1009409?hl=zh-Hans">Google
Analytics</a> 描述如下：</p>
<blockquote>
<p>高跳出率不是件好事？</p>
<p>这需要视情况而定。</p>
<p>如果您网站的成功取决于用户是否查看多个网页，那么高跳出率就不是一件好事。例如，如果您的首页是通往您网站的其他部分（例如新闻报道、产品页、结帐流程）的入口，而大部分用户仅查看您的首页，那么您一定不希望跳出率处于较高的水平。</p>
<p>另一方面，如果您拥有类似博客那样的单页网站，或提供预计会产生单页会话的其他类型的内容，则高跳出率完全属于正常现象。</p>
</blockquote>
<p><strong>分析工具</strong></p>
<p>网站分析工具：Google Analytics、百度统计、CNZZ
应用分析工具：TalkingData、友盟+、Flurry、Google Analytics
应用归因工具：Appsflyer、Tune、Adjust、TalkingData</p>
<p>分析工具是用于分析已有用户的行为，而归因工具是用于分析用户的来源。</p>
<p>因此，总结上面的过程为：<strong>建立漏斗并利用分析工具将漏斗的每一步的数据找出来</strong></p>
<p>下面是一个通过漏斗分析的页游的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1biqfsg2sj8um1b1edgi2f1no82n.png"
alt="转化漏斗" />
<figcaption aria-hidden="true">转化漏斗</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1biqftdj9h8dlrs1m5k1cumj0034.png"
alt="多维度报表" />
<figcaption aria-hidden="true">多维度报表</figcaption>
</figure>
<p>通过这样的步骤可以有目的地去排查具体的问题，如上面的例子中可能是程序在
chrome 浏览器上的不兼容导致了注册率的较低。</p>
<h2 id="通过多维报表找到问题">通过多维报表找到问题</h2>
<p>上面的例子中统计各个浏览器的注册率时已经涉及到了多维报表查询的问题，因为除了从浏览器，还可能从地域、时间段、时间段和浏览器组合等其他维度去统计，这时候就需要一个灵活的查询统计工具来提供这样的多维度报表，这个工具就是<strong>数据仓库（Data
Warehouse）</strong></p>
<figure>
<img src="https://wulc.me/imgs/image_1biqh4tkk1narkvt10crs121p5h3h.png"
alt="数据仓库" />
<figcaption aria-hidden="true">数据仓库</figcaption>
</figure>
<p>OLAP (Online Analytical Processing) 和 OLTP(Online Transaction
Processing)</p>
<figure>
<img src="https://wulc.me/imgs/image_1biqhflcf1rllu3lfi8p01m283u.png"
alt="OLAP v.s OLTP" />
<figcaption aria-hidden="true">OLAP v.s OLTP</figcaption>
</figure>
<p>软件：Saiku、Tableau</p>
<p>上面的流程：</p>
<p>一个商业目标 -&gt; 建立一个转化漏斗 -&gt; 用分析工具在应用或网站埋点
-&gt; 分析工具得到的数据建立数据仓库 -&gt; 用数据仓库做精细查询</p>
<h2 id="建立灵活的实验框架">建立灵活的实验框架</h2>
<p>实验框架其实就是常听说的 A/B
测试，就是把用户分成两部分（两部分的量不一定相等），然后对这两部分的用户分别采用不同的方案，比较哪种的效果好，从而采取效果好的那个方案。这里的不同方案的不同点就是我们需要验证的产品的特性，且往往是单变量的，也就是验证某个新的特性与旧特性哪个好时需要保持其他环境一样，而仅仅改变这个特性。在这个过程中需要注意划分的用户要有代表性，也就是两部分用户的分布情况应该一致（如年龄等）</p>
<p><strong>A/B
测试中的一个重要方法是分层实验框架，其目的是为了能够在同样的流量情况下容纳更多的
A/B 测试</strong>，下面以一个简单的例子讲解</p>
<figure>
<img src="https://wulc.me/imgs/image_1c5d1791udab13dogtp1ljq1nbq9.png"
alt="分层实验框架" />
<figcaption aria-hidden="true">分层实验框架</figcaption>
</figure>
<p>上图所示的实验层中，在UI层，广告检索层和广告排序层均有 A/B
测试的需求，假如要测试UI层的一个新特征，同时也要测试广告检索层的一个新特征，当需要同时进行这两个测试时，必须要确保UI层的流量划分不会影响到广告检索层的测试，也就是说在广告检索层中划分的两部分流量中，只存在着广告检索层的特征的差异。因此如果同时在两个层进行AB测试，需要将流量划分为四份，分别是
UI层原特征+广告检索层原特征、UI层原特征+广告检索层新特征、UI层新特征+广告检索层原特征、UI层新特征+广告检索层新特征。即需要测试的特征数为
<span class="math inline">\(n\)</span> 时，需要划分的流量数为 <span
class="math inline">\(2^n\)</span>,
显然这样的增长级数带来了流量分割的困难。分层实验框架就是解决这个问题的。</p>
<p>具体的做法就是<strong>采用正交的哈希函数来为每一层进行流量划分，正交的哈希函数避免了不同层间的干扰问题</strong>。如对于上面的问题，采用两个相互正交的哈希函数，分别在UI层和广告检索层将流量划分为两部分，因为两个哈希函数是正交的，因此在UI层所划分的两部分流量U1和U2中，U1所包含的广告检索层的原特征流量和U2所包含的广告检索层的原特征流量比例相等，同时新特征的比例也相等，这样就避免了上面的指数级增长的划分方式。更详细的信息可参考这篇文章
<a href="https://dl.acm.org/citation.cfm?id=1835810">Overlapping
experiment infrastructure: more, better, faster experimentation</a></p>
<p>上图中的非重叠测试域指的是测试的特性贯穿了三个层，就是同时测试三个层的特性组合带来的效果，这时候就用不上分层实验框架了。</p>
<p>上面这种采用正交的哈希函数来为每一层进行流量划分思路同样可用在灰度发布中，进行分层的灰度发布测试。</p>
<p>通过 A/B 测试能够将目前的产品的特性调到最优，但是需要注意的是 A/B
测试并不是万能的，因为过度依赖于数据会丧失对关键创新的把握，这里有一句很形象的话：汽车无法从跑得更快的马进化而来，也就是无论我们利用
A/B
测试把马（现有的产品）训练成跑得更快，依然是没法比得过汽车（更有创意的产品）。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>如何成为快速阅读高手</title>
    <url>/2021/07/25/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB%E9%AB%98%E6%89%8B/</url>
    <content><![CDATA[<p>最近在找资料的时候意外发现一个与快速阅读相关的干货, 就是在得到这个
app 上的一门课《<a
href="https://www.igetget.com/course/%E6%80%8E%E6%A0%B7%E6%88%90%E4%B8%BA%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB%E7%9A%84%E9%AB%98%E6%89%8B?param=rk7i8Nh7f6x&amp;token=MqBr4kj5gLNYKNPfvJdemExy36GaAZ">怎样成为快速阅读的高手</a>》，里面介绍了快速阅读的一个比较系统的方法论，总结来说就是阅读三步法：<strong>评测、速读和精读</strong>。笔者对其中的不少观点有共鸣，因此在本文摘录一些印象深刻的地方，推荐去听原始的课程，也许会有更大收获，也算是支持一下课程的作者。</p>
<span id="more"></span>
<h2 id="为什么要快速阅读">为什么要快速阅读</h2>
<ul>
<li><p>“阅读是一件很享受的事”仅限于读小说，读散文，读一些虚构类的作品，共同特征就是没有什么目的性</p></li>
<li><p>阅读大多数非虚构类书籍的时候并不享受，因为需要耗费大量脑力，<strong>不应该把阅读的时间拖得过长</strong></p></li>
<li><p>比起一本书的价格，<strong>读书时间是最大的花销</strong>；我们需要将读书的收益最大化，即降低读书时间，获取书中的有用价值</p></li>
<li><p>快速阅读的好处不限于读书，在工作、生活中也是大有用途</p></li>
</ul>
<h2 id="摆正阅读的三个心态">摆正阅读的三个心态</h2>
<p>提升阅读速度和效率，除了技巧，心态的调整也是重要的环节。课程中主要讲了三个：(1)丢掉对书本的敬畏感
(2)有的书只需要你速读 （3）即便是你要精读一本书，也要先速读一遍。</p>
<h3 id="丢掉对书的敬畏感">丢掉对书的敬畏感</h3>
<p>这一点是笔者觉得最重要的一点</p>
<p>我们从小被灌输着一些这样的思想：读书可以陶冶情操，可以修身养性，能获得知识，能塑造价值观，总之读书就是千好万好，书里的知识就是珍宝。</p>
<p>这自然没错，但这就容易让你对书本产生敬畏感，会让你觉得，<strong>如果我不逐字逐句地读完，那我就有可能不理解作者的思想，就有可能丢掉一些很宝贵的东西；让你觉得凡是写进书里的内容就是有价值的，就是名言警句，要是我看不懂，那是我水平不够，和作者没啥关系</strong>。</p>
<p>但事实并非如此，如果你觉得一本书死活看不进去，不一定是你的问题。这其中有很多原因，包括但不限于</p>
<ul>
<li>翻译的问题，其他文字转化成汉语，总有一些语意的丢失。</li>
<li>作者在当时的社会背景下提出了一个当时的问题，现在这个问题已经不存在了</li>
<li>作者就为了凑字数，就一个事情翻来覆去地说，故意营造一种重要感。</li>
<li>作者连自己想说啥自己都不知道，不顾读者的感受在那自顾自地表达，东一句西一句让人不知所云</li>
<li>....</li>
</ul>
<p>根据作者读书的经验,</p>
<blockquote>
<p>一本非虚构类的畅销书，有可能80%的内容都是在堆积材料，20%的内容是作者自己的观点和思考，这其中，可能只有1%的内容对你有所启发，不过话说回来，你能有这1%的收获就已经赚了。</p>
</blockquote>
<p>因此，你要认识到，读书是不用跪在书的面前，而是<strong>应该用很轻松的心态，就像和一个比你年纪稍微大那么一点点的老朋友聊天那样，化繁为简</strong>，听他怎么说就好。觉得好的地方就收下；觉得不好的就果断扔掉</p>
<h3 id="有的书只需要你快速的读完">有的书只需要你快速的读完</h3>
<p>笔者觉得这里也可以翻译为读书需要<strong>有目的性</strong>，即要意识到读这本书的对自己实际用作是什么，对那些实际作用不大的书可以快速读完，比如</p>
<ul>
<li>一些包装得特别好的书，作者的背景、网友的评论好像都不错，结果一看满书都是一些<strong>大而无当</strong>的话，要么就是一句话能说清楚的事情说了500多页，遇到这种书当然就快速翻完就完了。</li>
<li>一些老的经典书，书的名气非常大，写得也好，但是作者<strong>讨论的问题现在已经不存在</strong>了；再比如一些概念前些年提出来可能会很牛，但是现在提出来明显就已经过时了。</li>
<li>于一些可能名气大，但由于各种原因，营养有限或现实意义不大的书，你为了<strong>满足自己的好奇心</strong>，可以去看看它，但没必要花太多时间投入。很多书你是需要绕过去的。</li>
<li>...</li>
</ul>
<h3
id="即使需要精读一本书也先要速读一遍">即使需要精读一本书，也先要速读一遍</h3>
<p>精读前的速读的必要性(针对非虚构类作品)</p>
<ul>
<li>先预览一遍可以帮你<strong>建立一个地图</strong>，能降低你理解这本书的难度</li>
<li>快速浏览一遍能<strong>激发出你的问题和好奇心</strong>，带着问题和好奇心去书里找答案，效率更高</li>
</ul>
<p>作者理解的<strong>速读不是单位时间内你能看更多的字，而是单位时间内看的字更少，但是抓要点地去看</strong>。所以，一本书是可以像看电影一样快进看完的，就像以前你阅读是<strong>撒网捕鱼</strong>，你可能想的是怎么把网做得越来越大，怎么一网撒下去能捞到更多的鱼，现在你知道会速读的人都不是用这个方法，他们都是用<strong>鱼枪捕鱼</strong>，一次就瞄一条，但是瞄的那条一定是最大的。</p>
<p>很多人拿到一本新书就准备一遍把它读完，其实最有效的方式是读三遍。用一句话总结就是：<strong>读书读三遍，从大往小看</strong>。</p>
<p>第一遍看主题，看口碑，确定自己是不是要花时间在上面。这是从一本书的价值角度来看，视野要放大，离书的距离要远一些。</p>
<p>第二遍看结构，看脉络，用快进的方式整体浏览一遍，看看作者是如何设置这本书的结构，哪里是铺垫，哪里是重点。这是从内部的整体结构来看，走的就离书近了一些。</p>
<p>第三遍，挑自己感兴趣的部分反复看，仔细琢磨，最后输出成自己的东西，这就是进入书中，从小处着手来阅读。</p>
<p>总结起来就是<strong>阅读三步法：评测、速读和精读</strong>，也分别对应着下面要说的三个部分的内容。</p>
<h2 id="评测是为阅读蓄力">评测是为阅读蓄力</h2>
<p>这是阅读三步法的第一步：评测和预判；即选择“对”的书</p>
<p>评测的过程其实也是看书，目的是确定这本书值不值得看。你可能通过个人兴趣、或者别人推荐、媒体推荐等，对一本书有了兴趣，那么怎么判断这本书值不值得花时间打开呢？</p>
<p>这其实包含两个层面，(1) 这本书本身是不是有价值,是不是一本好书
(2)这本书是不是适合你</p>
<p>如何去判断呢？作者提供了以下几种方法</p>
<ol type="1">
<li>看主题。很多人觉的序言里基本都是推荐的话，不值得一看，其实不是。<strong>序言部分通常是作者请自己一些有点名气的朋友写或是作者本人自己写，等于是一本书的门面，他们通常都会很认真，在里面他们会对这本书的主要内容和重要观点做一个综述</strong>，把你看完能得到的收获写进去，这些东西都可以很好的帮你了解这本书。</li>
<li>看出版社的宣传文案。虽然很多宣传文案都会过度吹捧，不过也可能会把书中提出的主要问题列出来，你可以对照一下是不是自己正感兴趣的，这里面当然也会包括作者的信息，看看作者有什么样的背景，他是不是这个领域里资深研究者，这个通过介绍也很容易了解到，作者靠谱了，书自然也不会差。</li>
<li>看目录。通过目录可以直观地看到作者要讨论的内容和结构，这也是你后面阅读的时候需要反复看的地方。它就像你穿过一片丛林时不能丢掉的地图。</li>
<li>看评论。上网搜一搜关于这本书的相关信息，看看别人是怎么评价这本书的。</li>
</ol>
<p>在以上四点中，作者重点介绍了如何<strong>正确参考书评，或者如何判断书评是否有价值</strong></p>
<p>没价值的是啥样的呢？就是<strong>单纯的给出判断</strong>，比如</p>
<ul>
<li>这本书很好，但是就不说哪里好 &gt;
这种情况，要么是读者很懒或是水平有限，他确实总结不出哪里是亮点；要么就是读者压根没看懂，<strong>很多人会对自己看不懂的，觉得很厉害的东西说好，这是很常见的一种心理现象</strong>；要么就是读者已经花了时间在里面，这时候如果承认自己看了一本烂书并且一无所获，这是一件不舒服的事，所以就安慰自己这本书其实很好。</li>
<li>这本书很烂，但就是不说哪里烂，还有的负面评价是发泄式的</li>
</ul>
<p>那什么是有价值的呢？就是会<strong>提供关于这本书的额外信息，给出哪里好或是哪里不好的论证</strong>，比如</p>
<ul>
<li>书是在怎么样的大背景下写出的，在同类书目中的地位是怎么样的</li>
<li>书里的观点有没有和他对立的存在，关于这本书的延伸阅读，等等</li>
</ul>
<p>另外，作者也提到的观点笔者非常赞同，而这其实也不限于读书，生活其实都是“小马过河”
&gt;
在你亲自认真的读完一本书之后，你会有一个自己的判断，很可能你会发现很多人说的好，其实没那么好，水平很一般，也可能别人说的烂也没那么烂，很多观点是对你有启发的。</p>
<p>总之，评测过程可以让你对这本书有一个大致的预先判断，还能激发出你的问题和好奇心，让你带着问题去书里探寻答案。这有点<strong>像一个蓄力的过程，蓄到一定程度后，你会发觉你对这本书充满了好奇，有一种一探究竟的冲动</strong>，那在后面进入书本的时候，你就是带着解密的心态在读，会增加很多趣味性。有了这根筋后，你就不至于漫无目的地看书了，看书打瞌睡，看一会就困的问题就解决了。</p>
<h2 id="速读就是找关键信息">速读就是找关键信息</h2>
<p>这是阅读三步法的第二步：速读；这个过程需要用到速读技巧，作者这里提供了三个技巧：（1）用视觉输入代替线性输入（2）以语义单元推进阅读（3）通过概念找重点</p>
<h3 id="用视觉输入代替线性输入">用视觉输入代替线性输入</h3>
<p>很多人的阅读习惯是一开始就从左往右、从上往下，一个字一个字，一行一行地开始读，这其实是最原始的读书方式，刚拿到一本书，不能这么开始，不然你会发现自己好像在完成一个艰巨的任务。</p>
<p>那应该怎么办呢，应该要先浏览一遍，目的迅速了解一本书的主题和框架，包括作者的写作意图，背景，搞清楚重点在哪里。你可能会说，了解一本书的框架我知道，但是我的速度就是起不来，其实这是<strong>因为你总是会忘掉快速浏览的目的，总想在快速浏览的时候追求理解</strong>。</p>
<p>我们通常是把看书这个动作称做阅读是吧，它分为<strong>阅和读</strong>，这其实是两个动作。这两个动作有啥区别呢？</p>
<p><strong>看是视觉输入</strong>，就像你看一幅画一样，你不会从上往下从左往右按着顺序来看，你一眼瞄过去就能知道这是幅肖像画还是风景画。</p>
<p><strong>读是听觉输入，听觉输入是线性输入</strong>。你得按照一定的顺序描述才能把它还原成一幅画，就像我们听一些课程，你放个3倍的速度，那你几乎就听不清说的啥了。</p>
<p>既然看一段文字就像看一幅画，你一眼瞄过去就应该能找到这一大幅图的特征，就应该能知道他画的是什么东西。可能你不知道里面的细节，但是没关系，做到这一步就够了。就像你去超市逛了一圈，让你想零食的种类你可能想不起来，但是零食区在哪你肯定知道。</p>
<p>理解这一点很重要。因为所谓的快速阅读，就是指快速地找出一段话的关键信息，抓的快、准、稳，直接跳过和忽略那些不重要的辅助信息。</p>
<h3 id="以语意单元推进阅读">以语意单元推进阅读</h3>
<p>那怎么用快进的方式看书呢？作者分享的方法是“<strong>语意单元推进法</strong>”</p>
<p>熟悉写作的朋友都知道，在写非虚构类的文章时，总要先列个大纲，一个大纲包含很多条想要说的事和想要表达的观点，<strong>每一件想说的事，每一个想要表达的观点，其实就构成了一个语意单元</strong>。</p>
<p>既然是这样，那我们在开始快速阅读的时候，也按照语意单元来理解就好了，有时候一段话就构成一个语意单元，有时候十几页构成了一个语意单元，这都不重要。重要的是你能以这个为单位进行快速地推进，而不要一开始就陷入到细节中去。</p>
<p>举个书中经常遇到的例子，比如，一个故事一开始作者总要烘托一下气氛，引出他想要说的观点，要说说自己是怎么发现这个事情的，他做了哪些工作，对他产生了什么影响，总之最后的目的就是要烘托他发现的这个道理很重要。那这些所有烘托气氛的描述就是一个语意单元。</p>
<p>那语意单元要怎么找呢，在找的时候注意两点。</p>
<p><strong>（1）注意关键词的位置</strong></p>
<p>比如一段话的第一句话或是最后一句话，大多数段落的中心句就是放在第一句。有很少一部分放在最后一句。</p>
<p>还要注意那些表示转折的<strong>关联词</strong>，比如“但是”、“然而”、“不过”等等，这些词的后面经常会跟着一段话的中心句。</p>
<p>还要养成一个习惯，就是<strong>对名词和动词要格外的敏感</strong>，因为把这些词抓住了，一个中心句的主语和谓语经常就能一把抓住了，一段话的中心意思也就常常一目了然了。</p>
<p>至于小标题，作者重点标出的黑体字等，也是重点要看的地方。不过大多数的书里作者是不给这样的提示性信息的，还是得靠你自己去发现。</p>
<p><strong>（2）阅读过程中要在脑海中勾勒作者的写作思路和意图</strong></p>
<p>想想作者为什么这么写？他想证明什么？想要表达什么？在看的过程中脑海中要同时有两个声音在运作，一个是作者的，一个是你的，<strong>这些问题要一直问，这样就不至于陷入杂乱无章的细节论述里去了</strong>。</p>
<p>这个过程就像你坐着直升机飞过一片丛林，看过去之后，大的地貌特征你已经清楚了，手里有了一张地图，以后再走起来就方便多了。</p>
<p>在快速浏览的时候你可能会遇到一些问题。</p>
<ul>
<li>一些观点的论证过程非常长，看到后面你基本上就已经忘了当初那个问题是什么，这时候你需要经常的跳回去看看作者最初的写作目的。<strong>浏览的时候你完全可以来回翻</strong>，不一定就是按照顺序从前往后看，</li>
<li>遇到了一些难点，快速浏览的时候完全看不懂，这时候很多人就容易停下来开始死磕，其实不用。<strong>遇到这种情况先把难点放一放，继续往下推进</strong>，说不定从后面的解释中你一下就明白前面那段话的意思了。实在不行，那就等到下个阶段，精读的时候再重点攻克</li>
</ul>
<h3 id="通过概念找重点">通过概念找重点</h3>
<p>以语意为单位为快速推进的目的其实就是在找东西，找啥呢？找重点。</p>
<p>那什么算重点呢？例子算重点吗？不算，因为例子通常是为论点服务的。那论点算重点吗？也不一定，因为作者的论点很可能是大家都知道的常识，可能没啥特别的，你已经知道了，这样的信息就可以直接过。很多人习惯只要看到作者列出个123就开始划线，觉得那就是重点，其实那是作者的逻辑，你不需要按照作者的逻辑走，要按照自己的逻辑走，迅速把握一本书里对你来说最重要的那些知识点。</p>
<p>作者提出在速读的时候，需要注意寻找这三类重点：</p>
<p>第一类：
<strong>你不认识的新概念</strong>。比如作者用了一个新的词解释了一种大家经常见到但是叫不出名字的现象，你第一次见到，在书中作者围绕这个概念给出了一个解释，这就属于重点之一。</p>
<p>方法论也可以划分到新概念里，比如在这门课里分享的一个快速阅读的技巧，你以前不会，那快速阅读对你来说也属于新概念。但是注意有些概念通常是换了一个包装而已，如果你有点经验，通常可以一眼就辨识出来，不一定作者给出的新词你就要用，你能用自己熟悉的东西解释清楚这个概念当然更好。</p>
<p>第二类：<strong>你不够重视的旧概念</strong>。作者把一个你认识的概念的重要性提升了一个高度。之前你可能经常遇见这个概念，但是没有重视，重视起来后可以带来很多好处。</p>
<p>比如“自我辩护”，大家觉得自我辩护是人之常情，平时都不怎么关注它，犯错了谁都会替自己找借口，把自己的行为合理化一些，这样能减少自己的痛苦。但是在《错不在我》那本书里，作者提出的点是，自我辩护这个行为，不是我们平时以为的那么没有危害，他几乎是一切矛盾和冲突的本源。如果把自我辩护这个很常见的行为重视起来，在平时我们就能减少很多冲突。</p>
<p>第三类：<strong>等待替换的概念</strong>。就是作者试图用自己的论证来说服你，让你了解自己以前的观念是错的，是具有片面性的，是可以重新解释的。</p>
<p>比如“取悦”，大家可能觉得只要取悦别人就能让别人喜欢，实际上《取悦症》这本书告诉我们，一味取悦别人会带来相反的结果，喜欢取悦别人的人容易遭人讨厌，是不是很反常识？比如说“智商”，平时我们都以为智商是一个固定的值，天生的，谁也改变不了。但是《绝非天赋》这本书中告诉我们，智商是一个相对值，他之所以被普遍接受，是美国政府刻意推广的结果。</p>
<p>这三种类别分好之后，我们在浏览的时候<strong>把这三类信息找出来</strong>就可以了。有了这个找三类信息的目标之后，你至少就不会打瞌睡了。接下来干嘛呢，你可能觉得应该精读了吧？不是，这时候你最好<strong>把书放一边去，干点别的事情，让大脑休息一会，给自己一段缓冲的时间，大脑有一个特性，会自动过滤不重要的信息</strong>。休息一段时间回来再翻开书的时候，你会感觉这本书里的内容已经一目了然了，这本书会变得很薄，你会发现自己应该在哪里用力。</p>
<h2 id="能输出才是有效精读">能输出才是有效精读</h2>
<p>这是阅读三步法的第二步：精读；<strong>速读完一本书后需要判断这本书是不是需要精读，不是所有的书都需要或者值得精读</strong></p>
<p>如果一本书是在你的专业领域范围之外，你只是路过，特别好奇地想要朝里面望一眼，如果没有意外，你可能永远不会翻开这本书，那其实就不需要精读</p>
<p>如果一本书真是对你有很大的帮助，你希望去亲自阅读、去挖掘更多的东西，你想把书本中的东西变成自己的见识、谈资，内化成自己的表达能力，那你就要做更多的工作了。</p>
<p>很多人在这就会遇到一个问题了，那就是看完书脑子里只留下一团模模糊糊的概念，要是别人问你看的书讲的是啥，你说不出来，或者不能漂亮利落地说出来。其实这不是因为你表达能力不行，这是因为你没有学会正确的有效阅读。</p>
<p>什么是有效阅读？作者给有效阅读的定义就是<strong>能记住、能输出</strong>，因为只有这样，你读过的东西才真正变成你的东西。</p>
<p>因此，在精读细读的过程中，你要建立一个目标感，你既然是以输出为目的的阅读，你就不能像看小说一样任由作者牵着你走，<strong>你要假设待会就要给别人讲讲这本书里写了些啥，哪些东西对你是有帮助的，哪些东西对你是有启发的，哪些东西特别有意思</strong>。这样带有目的阅读就是有效阅读。</p>
<p><strong>有效阅读的这个过程大致分两个步骤，第一个是理解和互动。第二个是把内容记住和输出。</strong></p>
<h3 id="理解和互动">理解和互动</h3>
<p>先说第一个，怎样进行深入的理解和互动。</p>
<p>最简单的方法就是看完你认为好的部分之后，<strong>做笔记，写感想</strong>。</p>
<p>你可能会问，我没感想怎么办，不可能的，你一定有感想，比如读完一段话后，你单纯地觉得“好”，这个“好”就是感想。至于哪好你可能还说不出来，不过没关系，只要有这个感受就行了，这很重要，这说明你和这段信息做了一次轻微的互动，说明你对这段信息有感觉了。</p>
<p>那怎么进行深一点互动呢？你可以写写这段信息哪里好，哪里引发你的兴趣了。比如你在其它书里看到了类似的观点；比如这段信息可能很新鲜；可能是一个比喻用得很贴切；可能是很走心；可能帮你把一个平时觉得很模糊的概念定义清楚了；可能纠正了你一些错误的观念；也许就是单纯地给了你一个实用的方法论或思想工具。</p>
<p>这其实就是让新知识和你脑海中已经有的东西来一次互动，把原来的东西看得更清楚一点，经过这个过程，以后再遇到类似的信息，你会一下就想起来以前在哪里看过的。用这个方法积累下去，它会慢慢地变成一种习惯，新知识和旧知识的连接和互动速度可能越来越快，长期积累，你就会变成别人眼中那种特别有想法的人了。</p>
<h3 id="记住和输出">记住和输出</h3>
<p>笔者对这部分的很多观点都是深有体会的</p>
<p><strong>输出的方式大致分两种，一种是写作，一种是口语表达</strong>。写作要求的整合信息的能力强一点，逻辑思维能力高一点。而口语表达要求故事性、画面感高一点。</p>
<p>如果你能持续地做笔记，那你会发现自己会对信息变得很敏感，什么样的信息你似乎都会本能的来一次互动，从这段信息中看出一点别的什么东西出来。这时候不让你输出都很难，你会有一种想给别人表达的冲动，你会发现随便一写就好几千字。</p>
<p>把自己平时觉得有价值的文章、有价值的段落标记出来，和它互动，记一些想法，然后定期整理它们，这就是你的素材库。</p>
<p>上面说的是记住，如果有自己平时的积累和搜索引擎的帮助，你会发现，输出一段内容会变成一件能给你带来巨大帮助的事。比如你本来可能对一个问题的看法是很模糊的，但是现在你要写这个主题的东西，做一次分享，这种强制性的输出会让你思路变得很清晰。在做分享的时候，你自己能理解得更加透彻，<strong>以教为学是最有效的学习方式，没有之一</strong>。</p>
<p>作者认为，锻炼输出能力要学会的第一件事、也是最难的一件事就是写稿：把自己想表达的东西语言流畅、逻辑清晰地呈现出来。</p>
<p><strong>写稿的作用不单单是把你知道的呈现出来，写作这个动作本身也是一个帮助你思考的过程，可能你在敲打键盘前，对自己想要表达的东西感觉都是模模糊糊的，感觉都是云山雾罩的，没关系，开始写，一旦开始，你会发现你的思路会越来越清晰，逻辑也会越来越严谨，因为写作这个动作和口语表达不一样，本来就慢，它会启动你大脑的第二系统，第二系统就是所谓的慢思考，你是有意识地、有逻辑地在调动大脑中的资源，这时候你的想法自然会更深，输出的东西自然会更有料，这就是写稿带来的好处</strong>。</p>
<p>你动手前可能想要写一篇完美的无可挑剔的稿子，脑袋里抱着这样的想法自然是动不了手的，因为你脑袋里负责创造的声音和负责评价的声音是同时开启的，就像你开车的时候一边踩着油门，一边踩着刹车，你能跑快吗？</p>
<p>所以在<strong>第一遍写稿的时候，你要有意识的把评价的声音关掉</strong>，等到第一遍完成了，这时候你大脑中评价的声音就可以开启，你可以用挑剔的眼光看待自己的稿子，进行修改和补充，这个过程也是提升你写作能力和思考能力的过程。等多修改几遍后，再回头一看，你会发现也没那么烂，挺好的，是值得和别人分享的。这个过程不断重复，你的输出能力会越来越强。</p>
<p>接下来就是反复练习了，这个过程没有什么技巧可言，就是下功夫，如果你能坚持，时间会带给你回报</p>
<h2 id="小结">小结</h2>
<p>笔者从这门课中获取的最大的两个收获是：<strong>摆正阅读的三个心态和阅读三步法(评测、速读、精读)</strong></p>
<p>摆正阅读的三个心态分别是</p>
<ol type="1">
<li>丢掉对书本的敬畏感，要带着批判的眼光看书</li>
<li>认识到有些书就是要速读的</li>
<li>精读前需要速读</li>
</ol>
<p>而阅读三步法中每一步都有一些技巧</p>
<p>（1）评测</p>
<ul>
<li>不要遗漏那些有用的信息，比如序言、目录、宣传文案等，序言和宣传文案可能有过度吹捧的嫌疑，但通常也能帮你了解这本书所讨论的问题</li>
<li>要带着怀疑的眼光去看各种信息，鉴别书评是否有价值</li>
</ul>
<p>（2）速读</p>
<ul>
<li><strong>用视觉输入代替线性的听觉输入</strong>：快速浏览的目的是了解一本书的主题和框架，包括作者的写作意图和背景。细节在这个过程中不是最需要关注的，你需要关注的是这本书的结构、脉络。</li>
<li><strong>以语意为单元推进</strong>：在找语意单元的时候，注意关键词的位置，还要注意作者的写作框架。遇到不懂的地方先略过，不要停下来，可以从前往后看，也可以从后往前看。</li>
<li><strong>通过概念找重点</strong>：作者有可能是提出一个新概念，可能审视一个旧概念，也有可能在替换概念</li>
</ul>
<p>（3）精读</p>
<ul>
<li>建立一个<strong>有效阅读的概念</strong>:
能记住、能输出，我们应该带着这个目的去精读，而这可分两个步骤：(1)理解和互动
(2)记忆和输出</li>
<li><strong>理解和互动</strong>:
把你有感觉的段落和句子记下来，仔细想一想为什么好，哪里好</li>
<li><strong>记忆和输出</strong>:
以教为学，输入时需要避免完美主义，关键是要动手开始做，然后逐步完善</li>
</ul>
<p>最后引用课程作者的一段话收尾</p>
<blockquote>
<p>快速阅读，并不是让你抱着不求甚解的态度博览群书，它是读书的一个环节，是你对一本书作出价值判断和寻找要点的必要步骤，而且，快速阅读和有效的精读是不冲突的，它是精读前的一个步骤。掌握了这套方法，它在以后带给你的效益是超乎想象的。</p>
</blockquote>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>孤儿进程和僵尸进程</title>
    <url>/2015/12/05/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="基本概念">基本概念</h2>
<p>正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个<strong>异步过程</strong>,即父进程永远无法预测子进程
到底什么时候结束。
孤儿进程和僵尸进程就是由于这个异步过程没有正确执行而引起的问题。下面先看看这两类进程的一些概念。</p>
<span id="more"></span>
<p><strong>孤儿进程</strong>：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。<strong>孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</strong></p>
<p><strong>僵尸进程</strong>：一个进程使用fork创建子进程。如果<strong>子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息</strong>，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</p>
<h2 id="问题及危害">问题及危害</h2>
<p>unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息，
就可以得到。这种机制就是:
在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。
但是<strong>仍然为其保留一定的信息</strong>,包括</p>
<ul>
<li>进程号(the process ID)</li>
<li>退出状态(the termination status of the process)</li>
<li>运行时间(the amount of CPU time taken by the process)等</li>
</ul>
<p>僵尸进程危害：直到父进程通过wait/waitpid来取时才释放。但这样就导致了问题，<strong>如果进程不调用wait/waitpid的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程.
此即为僵尸进程的危害，应当避免。</strong></p>
<p>孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤
儿进程的父进程设置为init，而<strong>init进程会循环地wait()它的已经退出的子进程。</strong>这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此<strong>孤儿进程并不会有什么危害。</strong></p>
<h2 id="寻找并杀掉僵尸进程">寻找并杀掉僵尸进程</h2>
<p>僵尸进程危害场景： 例如有个进程，它定期的产
生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程
退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。</p>
<p><strong>严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。</strong>因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大
量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。<strong>枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进
程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源</strong>，这样，这些已经僵死的孤儿进程
就能瞑目而去了。 　　 上面是具体的思路，下面是实际的操作：</p>
<p><strong>查找僵尸进程：</strong>
可通过top命令查看当前是否有僵尸进程，如下图0 zombie表示没有僵尸进程 <img
src="https://wulc.me/imgs/2016-01-06_120845.png"
alt="top查看僵尸进程" /></p>
<p>假如该值不为0，可以通过<code>ps</code>和<code>grep</code>命令查找僵尸进程,如:
<code>ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]'</code> 命令注解： -A
参数列出所有进程 -o 自定义输出字段 我们设定显示字段为 stat（状态）,
ppid（进程父id）, pid(进程id)，cmd（命令）这四个参数 因为状态为
z或者Z的进程为僵尸进程，所以我们使用grep抓取stat状态为zZ进程。</p>
<p>找到这些进程后，可以直接kill掉僵尸进程，如果僵尸进程的数量比较多，也可以kill掉其父进程的pid让init经常回收这些僵尸进程的资源。</p>
<p>参考资料： [1] http://www.cnblogs.com/Anker/p/3271773.html [2]
http://be-evil.org/linux-find-and-kill-zombie-process.html</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>常用数学符号的 LaTeX 表示方法</title>
    <url>/2016/09/18/%E5%B8%B8%E7%94%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E7%9A%84%20LaTeX%20%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>在 Markdown 中编辑数学公式一般是使用LaTeX
来渲染和排版的，但是一些数学符号的 LaTeX
比较特殊，常常会忘掉，因此在这里特意记录这些数学符号用LaTeX
的表示方法。</p>
<span id="more"></span>
<h2 id="指数和下标">指数和下标</h2>
<p>指数和下标可以用 <code>^</code> 和 <code>_</code>
后加相应字符来实现,如果指数或下边多于一个字符， 那么需要用
<code>&#123;&#125;</code> 将其括起来</p>
<p><img
src="https://wulc.me/imgs/image_1at3q8nd52jj1sd9lfarrmg2m9.png" /></p>
<h2 id="平方根">平方根</h2>
<p>平方根（square root）的输入命令为：，n 次方根相应地为:
。方根符号的大小由LATEX自动加以调整。也可用仅给出 符号。比如：</p>
<p><img
src="https://wulc.me/imgs/image_1at3qbmm1due1ell3ce1mj219elm.png" /></p>
<h2 id="分数">分数</h2>
<p>分数（fraction）使用 排版。</p>
<p><img
src="https://wulc.me/imgs/image_1at3qnj0o12k01g781g1n7921bu2a.png" /></p>
<h2 id="积分求和连乘">积分、求和、连乘</h2>
<p>积分运算符用来生成。求和运算符由生成。乘积运算符由生成。上限和下限用^
和_来生成，类似于上标和下标</p>
<p><img
src="https://wulc.me/imgs/image_1at3qqa7v3fsll1asue8g50n2n.png" /></p>
<h2 id="表达式的上下方画出水平线">表达式的上、下方画出水平线</h2>
<p>命令和表达式的上、下方画出水平线。比如</p>
<p><img
src="https://wulc.me/imgs/image_1at3qdatu1bn41qj21chpqnofg613.png" /></p>
<h2
id="表达式的上下方给出一水平的大括号">表达式的上、下方给出一水平的大括号</h2>
<p>命令和在表达式的上、下方给出一水平的大括号。 比如：</p>
<p><img
src="https://wulc.me/imgs/image_1at3qf3eo1nclfgrjkgcnlfqh1g.png" /></p>
<h2 id="向量上方的箭头">向量上方的箭头</h2>
<p>向量通常用上方有小箭头（arrow
symbols）的变量表示。这可由得到。另两个命令和到B 的向量时非常有用。</p>
<p><img
src="https://wulc.me/imgs/image_1at3qjq312bei3q10o4tt8vhr1t.png" /></p>
<h2 id="其他一些数学符号">其他一些数学符号</h2>
<p><img
src="https://wulc.me/imgs/image_1at3qrvfr176k1bsc9trp561bi134.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1at3qstl4g24f1deo411252ig3h.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1at3qtjlp1qvb1tidqjbfttbjt3u.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1at3qua6tplk11dl3g75eb1ool4b.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1at3qvdas1am1cop1udn1aou1vsm4o.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1at3r0srlh7b1qtl7p91mjmsdj55.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1at3r1mhh1qnpug31his1is6154k5i.png" /></p>
<hr />
<p>参考：http://mohu.org/info/symbols/symbols.htm</p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>年轻的时候，做什么才不会浪费</title>
    <url>/2017/03/25/%E5%B9%B4%E8%BD%BB%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%81%9A%E4%BB%80%E4%B9%88%E6%89%8D%E4%B8%8D%E4%BC%9A%E6%B5%AA%E8%B4%B9/</url>
    <content><![CDATA[<p>文章有点标题党的意思，但是里面的内容却很很值得一读，本文为转载，作者是<a
href="https://zhuanlan.zhihu.com/iquanwai">孙圈圈</a>,侵删。</p>
<span id="more"></span>
<p>最近去各个城市做读者见面会，见到很多年轻人，跟他们交流，无一例外地：焦虑，迷茫，没方向，一无所有，着急……</p>
<p>但，这些 “月经式”问题，谁年轻的时候没痛过？</p>
<h2 id="从学校到公司这条路有多长">从学校到公司，这条路有多长</h2>
<p>刚工作的时候，我比现在有个性多了：我老板是区域总监，在她下面的一位大区经理（我非常不喜欢的一个人）让我做一份数据表格。</p>
<p>实际上，每个大区经理都有自己的助理，但他说自己助理太辛苦，让我做。</p>
<p>结果我不服，直接发了一封邮件给他，抄送我老板，把我的岗位说明书发给那位大区经理，跟他说：在我的工作职责里面，没有一条是需要服务你的。</p>
<p>现在想想，当时老板真的挺宽容我的，因为这样一来，她会处于很尴尬的境地，那位大区经理会以为，我的行为是我老板指使的。</p>
<p>反正，换做是我现在，遇到当年的自己，肯定火冒三丈。</p>
<p>那时候，还经常跟同事一起抱怨：公司培训机制不行、学不到东西；老板不民主、一意孤行；上层不体察民情、听不到员工的声音；公司太看重短期利益、不考虑长期发展……</p>
<p><strong>等到后来，自己做管理者，才知道，一个团队的管理、一个公司的经营，远远不是我作为一个初级员工所想象的那样</strong>。</p>
<p>有很多文章，批评年轻员工不负责、不会站在老板角度考虑问题。但要我说，这些都没说到点子上，即：从学校到公司，到底有什么不同？</p>
<p>最大的区别就是：<strong>你给学校付钱，但公司给你付钱</strong>。</p>
<p><strong>所以在学校里，老师为你服务，有义务帮助你学习；但在公司，你是为老板服务，有义务帮他解决问题。</strong></p>
<p>对这个概念的模糊不清，是导致我们在职场屡屡受挫的最大障碍。</p>
<p>因为如果不意识到这一点，我们就不会知道：应该站在老板的角度，去了解他需要什么，而不是要他站在我们的角度，来关心我们要什么；不应该像在学校跟老师相处那样，向老板寻求答案，而是要主动学习，帮老板找到答案。</p>
<p>在中国教育体制下浸润了20年、习惯了向老师寻求标准答案的我们，在进入公司之后，能够多快地抛弃这种惯性，从而在没有标准答案的问题面前，去主动学习和思考、摸索解决方案，基本上决定了我们最初5年的职场上升速度。</p>
<h2 id="焦虑感什么时候才会消失">焦虑感什么时候才会消失</h2>
<p>科比说他见过洛杉矶凌晨4点的样子，我没见过，但我见过上海凌晨4点的样子，因为那时候我还没睡。</p>
<p>不是因为在工作，而是因为我焦虑，睡不着。</p>
<p>毕业那年，在没有任何实习经历的情况下找工作，所以第一份工作找得不好。</p>
<p>工作三个月后，就发现这个职位几乎不可能有什么发展。</p>
<p>从此就一直想要逃离，但毕业半年，谁会要你呢？于是经常焦虑、自我怀疑，总会想：我这辈子是不是就这样了？是不是就要困在这儿了？</p>
<p>还好，一直都在关注外部机会，最后幸运地进了咨询公司。但马上又开始焦虑，因为进公司之后1个月，全球经济危机就开始了，公司在全球范围内冻薪，甚至在传有可能会裁员。</p>
<p>如果被裁，那就意味着，我毕业1年，得第三次换工作了。</p>
<p>还好，又幸运地留在了公司。但公司冻薪了两年，不能加薪不能升职。</p>
<p>而且，公司还在那年取消了分析师级别，应届生一进来就是高级分析师了。这意味着，我毕业快3年了，还跟应届生的工资一样、职位也一样。</p>
<p>知道消息的那天，躺在床上焦虑得睡不着：毕业快3年了，事业还停留在起点，还没了男朋友，刚到上海所以也没有好朋友，租房子一年搬了6次家，这样的人生还有什么希望？</p>
<p>但后来，毕竟还是走出来了，经济危机终究过去了。</p>
<p>人生也终于开挂了，9个月完成别人3年达到的晋升、成为大中华区晋升最快的顾问、几次在1年内薪资翻倍、带着团队拿比赛冠军、转换到我喜欢的咨询业务线、买房子把家人接到身边、买东西开始不关注价格、遇到对的人……</p>
<p>当年焦虑的那些问题，如今都一一解决了。</p>
<p>其实，现在随便去问一个年轻人，都会发现，我的经历没有任何特别之处，这些问题都是大多数人年轻时候的必经之路。</p>
<p>只是，回头再看年轻时候那些焦虑的经历，我唯一想分享的经验是：<strong>在我们应对焦虑的时候，需要学会一次只解决一个问题。</strong></p>
<p>比如，意识到工作没发展，就把一切精力放在寻找转行机会上；经济危机的时候，反正也没法找到工作，就干脆埋头苦干，等到危机一过，就得到了自己想要的；工作顺利之后，才开始考虑感情问题，之前都先放一边；再次遇到天花板的时候，就尽全力转换业务线。</p>
<p>这些问题，几乎没有哪一个是我同一时间花时间去解决的。</p>
<p>没钱、没男/女朋友、没地位、工作不顺、人际关系受挫……这些都是我们大多数人年轻时候躲不开的问题。</p>
<p>但是，<strong>当我们把所有问题混为一谈的时候，就会疲于奔命、无从下手，脑子里只有“焦虑”二字，一团浆糊。</strong></p>
<p><strong>只有当我们把问题掰开，逐个分析的时候，才会看到问题的本质，看到我们想要的“解决方案”，逐个击破。</strong></p>
<p>现在，我经常会对那些看职场鸡汤的人嗤之以鼻，但倒回很多年前，那时候的自己，面对诸多问题、急于一下子解决、又没有头绪的时候，不也曾诉诸鸡汤、试图寻求一个简单粗暴的答案、慰藉自己的焦虑情绪吗？</p>
<p>等我们对鸡汤的粗暴答案嗤之以鼻、开始主动思考的时候，才是我们真正认识世界、开始解决问题的时候。</p>
<h2 id="年轻的时候做什么才不会浪费">年轻的时候，做什么才不会浪费</h2>
<p>线下签售的时候，有读者问我一个问题：我现在还年轻，现在的职业未必是以后要从事的，而且时代变化这么快，现在的工作也随时可能被淘汰。那我现在学的东西，是不是都白费了？我要怎么预测一下，未来10年的情况呢？</p>
<p>这个问题，几乎没人可以回答。凯文凯利在《失控》里面有句话：所有对未来的长期预测都是错的。</p>
<p>但是，虽然长期无法预测，有些东西是不太会变的。</p>
<p>《人类简史》里面提到，根据史学家的考证，只有智人能够表达出从来没看过、碰过、听过的事物，这种能力让他们得以聚集大批人力，灵活合作，从而战胜比智人更加强大的其它人种。</p>
<p>说白了，就是讲故事的能力。</p>
<p>而我们看今天，<strong>人类进化到这个阶段，讲故事的能力依然重要，不管你说服客户、说服老板还是说服投资人，甚至做自媒体，都很需要</strong>。</p>
<p><strong>所以，不管行业、职业被颠覆成什么样子，有些核心的底层能力是任何时代、任何职业都用得上的。那么，只要我们掌握这些能力，就能够以不变应万变了。</strong></p>
<p>我们现在做的事情，都未必是将来想做的，也未必是适合自己的，从功利的角度讲，确实有些事情是会白费的。但我们做以下这些事情，是永远不会浪费时间的：</p>
<h3 id="核心能力提升">核心能力提升</h3>
<p>就像上面说的，核心能力是能够让我们以不变应万变的能力。</p>
<p><strong>这些核心能力，除了上面说的讲故事能力之外，还包括：快速学习能力、分析与解决问题能力、创新能力等等。</strong></p>
<p><strong>如果一份工作只能够给你知识和技能，却无法让你提升这些能力，那么就会是一份高风险的工作，因为当某种知识和技能不再稀缺的时候，你就很难有什么立足之本，瞬间回归起点。</strong></p>
<p>而当你的工作能够帮助你提升这些核心能力的时候，即便转换职业，也只是一时下滑，很快就能够反弹上去。</p>
<h3 id="认识自己的优劣势">认识自己的优劣势</h3>
<p>过去给企业做咨询的时候，接触了很多人才研究，这些研究都试图发现：究竟是什么因素，让一些人可以脱颖而出，更容易成功？</p>
<p>最终会发现，<strong>知识和技能这些，都不关键，而能力，有不小的影响，但最终起决定作用的，却是我们的天性：性格特质、动机、价值观这些。</strong></p>
<p><strong>似乎这是个悲观的发现，因为我们在成年之后，除非遭遇重大的人生变故，否则这些因素几乎是不可改变的。</strong></p>
<p>既然如此，我们还需要白费力气去做什么努力呢？</p>
<p>但实际并非如此，因为<strong>这些天性，几乎没有什么好坏之分</strong>，比如在我们的社会，似乎外向的人更有优势，因为可以更加快速地跟人熟络起来。</p>
<p>然而，内向的人也有自己的优势，他们很少直接发表自己的看法，更加倾向于深思熟虑，所以往往在思考方面有自己的优势。</p>
<p>由此看来，任何天性，都可以找到适合自己的成功道路。</p>
<p>年轻的时候，我们不了解自己、不满意自己、不想成为自己，跟自己的天性对抗，但没有关系，这些对抗最终会让我们发现自己的特点、边界和意义。</p>
<p>等到了一定年龄，就会知道，<strong>不应该再对抗自己的天性，而是发现并顺应天性，找到适合自己的定位，最大化自己的优势，成就自己</strong>。</p>
<p>接受无法改变的，改变可以改变的，这才是我们得以向前的高性价比方式。</p>
<h3 id="广结善缘">广结善缘</h3>
<p>年轻的时候，要成就一件事情，靠自己苦干就行，因为那时候，我们的工作主要是“对事”，比如写好一份报告、解决一个问题、克服一个技术障碍等等。</p>
<p>而随着年龄增长、地位提升，要成就一件事情，靠苦干远远不够，因为我们的工作变得主要是“对人”，比如管理团队、说服客户、拿到投资等等。</p>
<p><strong>所以，越往上发展，你越需要与人交往，越需要更多的资源，越需要他人的帮助。个人英雄主义，往往会成为一个人未来发展的最大天花板。</strong></p>
<p>但人际交往这样的事情，不会是一次性的利益交换，而是基于长久积累的信任。</p>
<p><strong>如果我们能够在自己力所能及的情况下，不计回报地给别人提供一些帮助，你将会在后面几年的人生中，收获意外惊喜。</strong></p>
<p>我自己在几个月前开始创业，现在圈外的课程设计负责人，是我的前同事，一位非常资深的项目经理。</p>
<p>她本身对创业不感兴趣，在做自由顾问，但因为我们课程设计的要求很高，初创阶段又没有足够的钱，所以很难找到适合的人。</p>
<p>她就拿了相当于自己做自由顾问1/10的工资，帮我设计课程、培养我们的课程教练、带团队，丝毫没有犹豫。我几次觉得不好意思，想要多给她一些回报，她跟我说：“等你做大了再说，我现在还不缺钱。”</p>
<p>然后，最近因为我们产品内测，需要更多的课程迅速上线，她甚至推了报酬丰厚的咨询项目，投入了更多时间在圈外。</p>
<p>我从前极少麻烦朋友帮忙，但这段时间，得到了太多人的帮助，感觉自己消耗了前10年积攒的人品。</p>
<p>所以人际交往这个事情，真的是个长期投入，如果在你想用的时候才去培育，是来不及的。</p>
<p>年轻的时候，能多帮别人就多帮，别去计较一时得失，过几年自会发现，“帮助别人”是你在年轻时候做的最有价值的投资。</p>
<p>读完这篇文章，年轻的你就能接受并照做吗？未必。</p>
<p>你们可能会说我是在倚老卖老、讲大道理。然而，这大概就是人生的有趣之处，总要自己痛过，才会愿意领悟。</p>
<p><strong>年轻的时候，有的是资本去试错，也应该去试错，唯有如此，才能够从中吸取教训，通过与现实的碰撞不断探索自己的意义，最终走向心智成熟。</strong></p>
<p>还是那句话，<strong>只要还年轻，对未来的恐慌、对成功的渴望、对未知的不安、对想要而不得的不甘……这些弯路，该经历的都一定会经历，该焦虑的也一样都不会少，无处可逃。</strong></p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>张潇雨的个人投资课(1)-市场规律</title>
    <url>/2021/11/14/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE(1)-%E5%B8%82%E5%9C%BA%E8%A7%84%E5%BE%8B/</url>
    <content><![CDATA[<p>因《得意忘形》播客认识张潇雨老师，从中听到了不少令人耳目一新的观点，后来发现张老师还是一名对冲基金经理，在得到上有一门课:
<a
href="https://www.igetget.com/course/%E5%BC%A0%E6%BD%87%E9%9B%A8%C2%B7%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE?param=XDGhXPc6fL6&amp;token=YPZNRwQ0qL1MVEpfwzK3lmz4kgWEnx">个人投资课</a>，总体听下来，将笔者断断续续学习过的一些投资方面的知识串了起来，值得写一篇文章记录一下。</p>
<p>内容总体可分为两大部分：基本投资原则和具体的方法论，课程在讲解过程中将其划分为如下四个部分：<strong>市场规律、投资工具、自我局限和投资组合构建</strong>，前三个部分主要讲一些投资过程中最容易犯的错误，最后一部分则是讲一些具体的投资方法。本文主要是市场规律部分相关内容，同时简单介绍了个人投资者现对于专业投资者的一些优势与劣势。</p>
<span id="more"></span>
<h2 id="个人投资者的优势与劣势">个人投资者的优势与劣势</h2>
<p>课程里的内容主要针对的是普通投资者的投资，而普通的个人投资者的特点是</p>
<p>（1）投资不是你的全职工作，你还有其他的事业和职业去做
（2）除了自己或者最多照顾到亲密的家人朋友以外，不会管理其他外部人士的资金</p>
<p>个人投资者相对于专业投资的优势是：<strong>不需要像专业投资人那样舍近求远，舍易求难</strong>；即专业投资人面对着同行和背后投资人的压力，总得干些什么事情来证明自己，往往需要做一些身不由己的事情;
但是作为个人投资者则没有这种压力</p>
<p>课程里举了几个例子来说明这个观点，第一个例子是《彼得·林奇的成功投资》里第二章的例子<a
href="https://www.gupiaoxuexi.top/gpsj/468.html">专业投资者的劣势</a>；第二个例子则是
2000 年<a
href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%AF%E7%B6%B2%E6%B3%A1%E6%B2%AB">互联网泡沫</a>；</p>
<blockquote>
<p>在 2000
年的互联网泡沫里，作为一个基金经理，如果不买互联网的股票基本就要被市场抛弃了，甚至不光是你的同行，连把钱交给你的人，他们都会督促你赶紧买互联网股票，否则他们就要把钱抽走去别的地方投资了，那这个时候你买还是不买？在那个疯狂的年代，能耐得住寂寞，抵抗住压力，不参与这种全民狂欢的专业投资人是非常少的。有没有人确实做到了？</p>
<p>有，那就是我们熟知的股神巴菲特，但是代价就是1999年它大幅跑输大盘，受到了无数人的嘲笑与质疑，当时间转到2000年初，整个市场开始崩盘，网络概念股价格直线跳水，完全跌到退市的公司也屡见不鲜，无数的基金价值被毁灭，投资人的血本无归，基金经理们也一夜之间没有了工作。
所以经常有人问，美国几次市场泡沫都那么明显，普通人都能看出来，那些专业人士就看不出来吗？其实不是看不出来，而是这个时候你要不杀进去，别人就会认为你是个笨蛋，你的职业生涯可能也要提前终止了。</p>
</blockquote>
<p>而个人投资者的劣势则是接触到的资源非常有限，比如说一些收益较为可观的基金(如<a
href="https://zh.wikipedia.org/wiki/%E6%A9%8B%E6%B0%B4%E5%9F%BA%E9%87%91">桥水基金</a>)对投资的金额都有一定的门槛，因此，<strong>课程里认为对于个人投资者而言，花时间研究那些奇技淫巧的东西，其实是得不偿失的；反倒是掌握一些最朴素的投资方法，避免那些最明显的投资错误，才是走向投资成功的正途</strong>。</p>
<h2 id="房子还会不会是最好的资产">房子还会不会是最好的资产</h2>
<p>对于中国人甚至整个亚洲人民来说，最喜欢的投资方式之一是买房，而在过去的好几年，房价的走势也的确很给力，很多人都将购买房子作为一种投资方式，课程里针对这种现象提出了一个有趣的观点：<strong>一个人的投资偏好往往会受到年少记忆的影响</strong>，就是在十几岁二十几岁相对年轻的时候，对整个投资市场和各种投资产品的印象和体验，很大部分就构成了一个人的投资偏好。</p>
<p>课程里举了两个例子，第一个是美国的股票</p>
<blockquote>
<p>美国的80年代是股票市场历史上投资回报率非常好的一个黄金10年，但在这10年里，美国家庭财产投资在股票上的比例居然是下降的，而且之后的90年代市场继续走强，走出了一个很不错的大牛市，大家投资在股票市场的资金继续减少，比例从60年代的40%到80年代的25%，再到90年代只剩17%了。而且不只是股票投资美国家庭的投资比例也在持续减少，曾经这个比例超过70%，但到了90年代就只剩40%了。在这个阶段，美国整个股票市场翻了三四倍，但一大批投资者却把钱从股市上抽走了，完全没有享受到国家财富增长的成果，这到底是为什么呢？</p>
<p>答案就是美国整个70年代的经济实在太惨了，在上世纪70年代，由于越战升级，中东石油危机，国家不合理的福利政策导致财政赤字急剧扩大等等一系列原因。美国国内大幅通货膨胀，同时经济停滞，失业率也非常高，这段时间美国股市的表现非常惨淡。从1969年末到1979年末这整整10年时间，美国的道琼斯指数和标普500指数几乎纹丝不动，10年呢没有任何增长，算上通货膨胀甚至是亏损的。而且中间还有几次莫名其妙的大跌，让整个市场都处于一种担惊受怕的状态。</p>
<p><strong>你想想如果你出生在60年代，20岁左右的时候呢发现谁投资股票谁倒霉，那么等你到了三四十岁的壮年期，家庭情况好了，收入也上来了，你会放心大胆的买股票吗？绝大部分人都不会这么做，因为小时候的记忆实在是太深了，但这样显然带来了一个很惨痛的后果，很多的普通投资者和勤勤恳恳的家庭错过了美国历史上最好的一段牛市，而钱都被敢于在熊市逆向投资的专业机构转走了</strong></p>
</blockquote>
<p>另一个例子则是日本的楼市，这部分更多的参考资料见<a
href="https://www.zhihu.com/question/36643095">日本楼市的兴衰史，是怎样的一个过程？</a></p>
<blockquote>
<p>二战之后日本大力发展制造业，从六七十年代开始，日本经济开始崛起，以索尼和丰田为代表的优秀企业，把自己的产品卖到了全世界。到了80年代日本经济达到顶峰，全国从企业到个人都陷入了疯狂的买买买的状态。</p>
<p>最著名的就是地产开发商三菱地所去美国买下了洛克菲勒大厦，还在大楼的最高处插上日本国旗。由于广场协议让日元大幅贬值，日元开始回流到国内市场，加上日本政府大幅降息扩大贷款，造成国内一时间产生了大量的钱，都流向了股票市场和房地产市场。结果就是当时东京市中心银座广场的地价达到了25万美元一平米，而且这可是在1989年，那个时候只要在东京或者大阪有房子的日本人都可以说是千万富翁。</p>
<p>那么当时拼命在买房的人都是谁呢？正是经历了六七十年代日本经济起飞对未来无限乐观的那批人，他们在十几岁赶上好时候，到了三四十岁有了购买力自然就要买房，让财富增值。但后来的故事呢我们都知道了，日本经济泡沫破裂，很多家庭的倾家荡产，那些使用高额贷款买房的人瞬间负债累累，欠的钱可能一辈子都还不清。日本整个国家和民众迎来了一个失落的20年</p>
</blockquote>
<p>曾经的美国人由于股市10年惨淡，再也不敢买股票，错过了之后的大牛市;
当年的日本人由于国家经济迅速发展，房价节节高升，结果无数人买到了最高点上之后一路崩盘。这个例子告诉我们一个被忽视，但非常简单的道理，那就是要一个被很多人忽视，但非常简单的道理，那就是要<strong>尽量忘掉你的投资偏好，多元配置你的投资组合</strong>。</p>
<p>因为各类资产（股票、房子、债券、石油、黄金等）都有一个轮换周期，可能一下就是10年、15年、甚至20年，这对于整个市场只是一个很小的时间段，但对于我们每个人来说，可能就是人生中最黄金的一段时光。同时市场很难预测，没人能准确说出来接下来10年20年投资什么最好。因此，如果我们做到足够的多元分散，你就可以提高自己压中宝的概率，不错过人生中重要的财富增值的机会。而想做到这样，最重要的就是不要根据过去几年甚至十几年的经验，简单的认为接下来同样的事情还会重复发生，因为市场总在变化，也许在下个周期里真正大涨的东西你想也想不到</p>
<p>因此，这部分有以下 3 个结论值得重点关注</p>
<ol type="1">
<li><strong>我们很容易因为自己过去的经历就对某一种资产有特殊偏好，这样很容易让你错过增长最快的那个资产品类</strong></li>
<li><strong>不管是短期还是长期，你都很难预测哪类资产在未来表现会最好</strong></li>
<li><strong>因此作为投资者不要对资产有明显的偏好，多元分散投资不只是规避风险，更是抓住赚钱的机会</strong></li>
</ol>
<h2 id="择时陷阱">择时陷阱</h2>
<p>择时就是选择时机，英文叫做 <a
href="https://en.wikipedia.org/wiki/Market_timing">market
timing</a>，本质就是我们对市场对接下来各种资产的表现一个短期走势的预测，然后决定是否要买入或卖出；课程里的建议是不要择时。</p>
<p>以股票为例，单个交易日的大涨大跌会比较难，那有没有可能成功预测比较长时间段的趋势呢？比如有没有可能提前预测到2008年的金融危机？答案是可以的，但这件事最难的地方在于即使你真能预测金融危机会到来，但你怎么知道它恰好会发生在2008年，而不是2007年或者2009年？</p>
<p>在以 08 年次贷危机为原型的电影<a
href="https://movie.douban.com/subject/26303622/">大空头</a>里，主角之一的原型迈克尔巴黎，其实从2005年就开始做空刺激贷款了，结果是他硬扛了两年多，直到2007年才赚到钱，中间也遭受了无数的质疑。在知乎上的这个回答也提到了这一点，<a
href="https://www.zhihu.com/question/39528631/answer/95594954">如何评价电影《大空头》（The
Big Short）？ - Z Abigail的回答 - 知乎</a>,
这部分其实也侧面佐证了上面提到的个人投资者相对于专业投资者的优势</p>
<blockquote>
<p>如凯恩斯所言，“market can stay irrational longer than you can remain
solvent”假设存在一个平行的宇宙，美国在05/06年改变移民策略——买一套价值xx元以上的房产就可以自动获得永久居留权，由此推迟了次贷危机，使之在2012年而不是2008年爆发。请问电影中的那些fund
mangers真的有足够的钱满足margin call 和 AUM
撑到2012年吗？在投资行业越来越机构化的今天，短时间的 underperformance
（一年）都可能导致大量投资者撤资，更不要说连续几年了。举个例子，很多在2014年底大量买E&amp;P公司股票/债券的funds在2015年年底因为投资人大量撤资，被迫关门</p>
</blockquote>
<p>课程里另一个例子就是<a
href="https://baike.baidu.com/item/%E8%80%81%E8%99%8E%E5%9F%BA%E9%87%91/9120135">老虎基金</a>，这个例子其实也是上面这个知乎回答的一个佐证</p>
<blockquote>
<p>从98、99年开始，金融市场突然刮起了科技旋风，那个时候最热门的就是互联网股票，但那时候的互联网公司没有一个有盈利的，大多数呢都是噱头，光靠炒概念股价又能翻好几倍。
在这种环境下，作为价值投资者的罗伯逊显然认为市场的泡沫太大了，于是他开始做空科技股，但在当时那个市场环境,
再烂的公司股价也是非常整个市场呢毫无理性可言。结果由于做空这些股票，老虎基金损失惨重。
不仅如此，当时由于所有人都在疯狂的追涨科技公司，很多资金也从传统经济流向了互联网领域，所以传统的价值股也受到了很大的冲击。如老虎重仓持有的美国航空12个月里面跌了接近一半,等到了2000年2月底，老虎基金已经跌的不成样子了，而且基金越跌，投资者也越拼命的撤资，
于是仅仅一年多时间，老虎基金管理的资产就从巅峰的230亿美元狂跌到65亿美元，等到了3月罗伯逊彻底扛不住了，干脆决定关闭基金。
但最令人唏嘘的是什么呢？老虎基金是在2000年3月30日正式关闭的，20天前啊纳斯达克指数刚刚创下了历史新高，结果仅仅到4月，整个市场就开始暴跌，一个月就下跌了15%，接下来两年跌了快80%。想一想，如果罗伯逊是在这个时候做空的，他的回报是难以想象的，所以虽然他的判断是对的，但就是倒在了黎明之前，择时也正是这么一件非常难的事情。</p>
</blockquote>
<p>既然择时那么难，那具体的方法论是什么呢？这部分课程会在第四部分提，一句话来说就是根据
PE/PB
分位数定投宽基指数。其实哪怕定投了，还有一个问题需要考虑，就是何时止盈或止损的问题，这个问题比较
open，知乎上有个回答可以参考下<a
href="https://www.zhihu.com/question/28930738/answer/1334772730">如果做基金定投的话，什么时候应该卖出呢？
- TopView的回答 - 知乎</a>，课程则是从另一个角度来阐述了这个问题,
部分观点可能有争议，但是笔者觉得其中的“<strong>个人投资是一个无限游戏</strong>”说的很对</p>
<blockquote>
<p>我们如果想回答什么时候应该卖出的时候，不如来想一想什么时候不应该卖出，因为我们把主要的错误的卖出理由排除掉，剩下的答案可能就很接近正确了,我觉得有两个最常见的错误的卖出的理由，
第一个是仅仅因为价格跌了，所以我就得卖出。这句话的背后其实有这样一个假设，就是你有能力每次都能买到这个东西价格的最低点，因为这样你买完之后它才不会跌，但是你觉得这件事有可能吗？
第二个错误的卖出理由和第一条是对称的，那就是仅仅因为一个资产价格涨了多少，也不应该是你卖出他的理由。我知道这条可能有点争议。比如伟大的对冲基金保罗杜德琼斯就说过，当你买入的股票达到了目标价的时候，你就应该卖出，因为后面不论这个股票是涨是跌，都和你的认知范围和认知能力无关了。</p>
<p>所以我在这里说的并不是一个绝对真理，更多的是对你的一种提醒。那就是很多投资者有一个习惯就是买了一个股票或者什么基金，结果接下来一两个月正好涨了10%或15%，那么干脆卖出把挣的钱落袋为安好了。这是有问题的，原因有如下
2 点</p>
<p>第一点，你要意识到<strong>个人投资是一个无限游戏，就是除非这个钱你真的要拿出来消费掉，否则你的投资总是要继续回到市场，不断循环滚动生生不息的，就像一个没有终点的游戏</strong>，比如你卖出基金挣了15%，然后你就把钱存到银行了吗？其实呢大部分时间也不会，你会拿着这笔钱再去投资到新的地方，那这个新的投资标的就比之前那个一定好吗？如果真的这么好，那么当初你为什么没有投他？这些问题都是需要去诚实的思考的。一个比较合理的正当卖出理由是<strong>你发现了这笔钱更好的去处，发现了更好的投资标的</strong>，比如说你一直看好的一个股票，突然受短期情绪影响跌了很多，进入了你的射程范围，那么你去更换一下持仓，这是可以理解的。当然这一切的前提都是你真的能判断这些资产的价值，而不是看上了那一点蝇头小利才选择卖出的。</p>
<p>第二点，如果你因为账面盈利选择卖出，实际上相当于你下了一个判断，就是这个资产接下来会下跌，而且不会再涨回来了。你的这个判断最后会有两个结果，第一个是它下跌之后又涨回来了，那么这个时候你要不要买回来？(实际上这种想着我先卖出之后跌了再买回来的人，往往就是那些错过了腾讯茅台甚至比特币的那些人)。第二种则是你卖出之后价格下跌了，而且再也没涨回来，那么恭喜你，你可能做出了一个正确的决定。但这里还隐藏着一个问题，就是如果是这样的话，是不是意味着你当初买入的决定有一些问题呢？那么下一次你怎么防范类似的错误，而且最关键的是当你决定卖出的时候，你实际上在做一个判断和决策。而如果你的认知能力或者情绪管理能力不足的话，这种决策出错的概率是很大的。</p>
<p>说了这么多错误的卖出理由，<strong>一个好的卖出理由是什么呢？我觉得就是你的买入理由不再成立了</strong>，有时候这是因为公司的基本面变化了，有的时候呢是因为你觉得本来一个资产价格低估，但是呢现在高估了，有的时候呢就是因为一开始就买错了，总之从本质上来说，你<strong>买入一个东西的成本，不应该成为你是否卖出的理由</strong></p>
</blockquote>
<p>因此，这部分有以下 3 个结论值得重点关注</p>
<p>（1）<strong>从短期来看，我们很难通过择时获得超额回报</strong>。对于股市来说，一年中最好的那些交易日分布非常不均匀，且和牛市还是熊市无关，所以我们很难挑中这些好的交易日，而一旦错过，对于我们的投资回报率就是致命的打击。
（2）<strong>不仅短期来看，择时很难，就连准确判断牛市熊市的来临时间也非常难</strong>。即使是像老虎基金这样最著名的基金，也很难掌握择时这件事情，所以避免轻易的择时，避免压住短期的市场走势，我们就又能避免一种亏损
（3）<strong>个人投资是一个无限游戏，一个好的卖出理由是是你的买入理由不再成立了</strong></p>
<h2 id="宏观迷信">宏观迷信</h2>
<p>这部分内容是为了说明个人投资者不需要过于依赖<a
href="https://wiki.mbalib.com/wiki/%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E#:~:text=%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E6%98%AF%E6%8C%87%E6%80%BB,%E8%A7%84%E6%A8%A1%E5%8F%8A%E5%85%B6%E5%8F%98%E5%8A%A8%E7%AD%89%E3%80%82">宏观经济</a>来指导投资。</p>
<p>课程里举了<a
href="https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E6%A2%85%E7%BA%B3%E5%BE%B7%C2%B7%E5%87%AF%E6%81%A9%E6%96%AF">凯恩斯</a>的例子来说明这个观点</p>
<blockquote>
<p>凯恩斯可以说是历史上最伟大的经济学家之一，也是整个宏观经济学的奠基人，但很少有人知道的是，他其实也是一个很成功的实战派投资人，不过可能和你想的不一样，凯恩斯不是一个靠预测宏观经济周期赚钱的人，而是和巴菲特一样是个股票的价值投资者。</p>
<p>当时的故事这样的, 在 20 世纪 20 年代，凯恩斯 40
岁上下正在盛年，那时候他的宏观经济学理论也比较成熟了，所以在实战中经常依靠自己的理论进行投资操作。当时凯恩斯最喜欢的投资品类是外汇和期货，因为这两种资产和宏观经济的挂钩最为紧密，他觉得只要能弄懂宏观数据，把握好经济周期，赚钱简直是必然的。</p>
<p>但结果是那个阶段的凯恩斯大部分的时候都在亏钱。比如在1920年，凯恩斯根据自己的理论分析，压住，英镑升值，做空法郎、德国马克和意大利里拉，但市场走势和它预测的正好相反，几种货币全部对英镑升值，他直接被平仓出局，大亏了一笔。凯恩斯这种预测失败的情况还发生过很多次。根据统计，从1922年到1929年的
7 年里，凯恩斯有 5 年的投资收益都低于市场指数，成绩相当的惨淡。</p>
<p>但是到了30年代，凯恩斯改变了自己的投资哲学，那个时候他已经是自己母校剑桥大学国王学院的财务主管了，会帮助学校打理一部分资金，再想之前那么不靠谱可不行了。所以他开始不再预测经济形势，而是寻找被低估的股票，并且大量买入并长期持有，成为了一个彻头彻尾的价值投资信徒，结果这种投资方式给他带来了丰厚的回报。他之后的15年的投资记录上升到了年回报
9% 左右，而同期英国股市跌了
15%。凯恩斯为什么会做出这种转变？他后来在一封给朋友的信里是这么解释的，他<strong>说宏观经济当然很重要，但是影响宏观经济的因素实在是太多太复杂了，常人难以掌握，相比之下寻找价值被低估的好公司要容易得多</strong>。</p>
</blockquote>
<p>此外，巴菲特、芒格也有<a
href="https://xueqiu.com/1175857472/40995621">类似的观点</a>，认为宏观经济在投资中所起作用并非那么大。</p>
<p>那如果我们不去研究这些宏观大问题，应该去研究什么呢？另一位著名的投资者乔尔蒂林哈斯特的一本书应该是解答这个问题的好选择。他之前写了一本书叫做
big money thinks small(中文叫《<a
href="https://book.douban.com/subject/35033233/">大钱细思</a>》)，这个名字正好契合了这一讲的主题。蒂林哈斯特说<strong>如果你整天研究宏观经济形势，那你就是让自己陷入信息的汪洋大海了</strong>。作为极其专业的股票投资者，他说自己每天想的都是很具体的小问题，比如分析公司的时候，他问自己的都是消费者为什么会购买这家公司的产品或者服务？这家公司比起竞争对手来说，最大的不同是什么？什么东西会导致这家公司彻底失败等？</p>
<p>而如果借用巴菲特的说法，投资的时候最重要的是弄清<strong>什么是重要的、可知的，如果一件事是不重要的或者不可知的，那我们就别管了</strong>。比如宏观经济问题是很重要，但对于普通投资者是不可知的，而什么东西是可知的？比如</p>
<ul>
<li>自己的投资期限有多长</li>
<li>应该如何针对性的配置自己的资产</li>
<li>购买国内外指数基金的时候，哪家的费用或者成本比较低</li>
<li>如果自己在境外有一些存着的美元或者外币，如何更好的进行现金管理</li>
<li>....</li>
</ul>
<p>把精力花在这些可知的事情上，才对我们的长期回报更有益处。</p>
<p>因此，这部分有以下2个结论值得重点关注</p>
<p>（1）<strong>宏观经济是很重要，但影响宏观经济的因素太多太复杂</strong>，即使凯恩斯席勒这样的大师也没法根据宏观经济指标来赚钱
（2）<strong>与其把精力放在宏观经济这种重要但不可知的事情上，不如想的小一点，关注更可知的事情</strong>。比如我们怎样完成一个资产配置的方案，购买的产品呢有多大风险，成本怎么样等</p>
<h2 id="风险度量">风险度量</h2>
<p>风险是难以量化的。对于收益这个东西我们可以非常清晰的量化，比如一年收益是3%、10%、还是50%，都可以算得清清楚楚。但你说风险是
10%、30%，好像没有这个说法，甚至你再往前想一步，会觉得更加困惑。</p>
<p>比如有人说这个投资产品风险有点高，估计 80%
得亏钱。那这个80%是什么意思呢？是说这个产品如果投资 10 次会有 8
次失败，还是说这个产品卖出 10 份得有 8
个人亏损，还是历史上类似的项目10个里面有8个都倒闭了，好像都不是。另外这个亏钱是亏多少呢？是亏20%还是亏一半还是全都亏掉？</p>
<p>课程里举了<a
href="https://zh.wikipedia.org/wiki/%E9%95%BF%E6%9C%9F%E8%B5%84%E6%9C%AC%E7%AE%A1%E7%90%86%E5%85%AC%E5%8F%B8">长期资本管理公司</a>，简单来说就是这个公司曾通过复杂的数学模型在市场上获得可观的回报，但是因为一次黑天鹅事件(即1998年俄罗斯金融危机)而破产了；后来著名的投资者巴菲特和霍华德马克思都说过，用数学的方式计算和预测风险是很荒谬的，众多学者们这么做的主要原因是他们需要一个可计算的、客观的、能够查明来龙去脉的数字，否则研究就没法做了。</p>
<p>如果风险如此不可捉摸，我们应该怎么做呢？答案也很简单，就是<strong>不要去想象风险的概念，而是要直接去衡量风险的结果</strong>，即在买入任何金融投资产品之前，都可以问自己这么一个问题，如果接下来它的价格跌了一半，我能理解到底发生了什么情况吗？我有应对的方法吗？如果回答不了这个问题那，这笔投资最好就不要做了。</p>
<p>因此，这部分有以下三个结论值得重点关注</p>
<p>（1）很多时候我们<strong>买了高风险的产品，但我们并不理解什么是风险，总以为亏损不会发生在自己身上，这是很危险的</strong>
（2）<strong>风险很难被量化，不要衡量风险本身，而去衡量风险爆发之后的结果</strong>
（3）具体应该怎么做？一个简单的方法是在买入任何投资产品之前都问自己这么一个问题，如果接下来它的价格跌了一半，我能理解到底发生了什么状况吗？我应该怎么去应对，如果回答不了，这笔投资呢就暂时不要做了，直到你弄清楚了这个问题。</p>
<h2 id="海外配置">海外配置</h2>
<p>前面提到，由于我们很难预测在未来一段时间里到哪一个大类的资产会涨得最好，所以在投资的时候要尽量的多元分散，就是大家常听到的资产配置的概念。不过另一个值得关注的点是<strong>资产配置不只是在资产品类这个维度做就行了，在地理这个维度上也要进行</strong>。</p>
<p>课程里针对普通人做海外配置时常有的两个问题做了解答
(1)我们真的有必要去海外投资吗？毕竟我们的生活主要都在国内，花钱也在国内，为什么要把钱放在我们不熟悉的地方？
(2)海外资产配置是不是富人的专利?</p>
<p>针对第一个问题，课程里给了先锋领航基金呢之前发表过一篇学术研究，他们测算了从1900年到2009年长达100多年里16个主要国家股票市场的涨幅和人均真实GDP增速的关系，最终得出了一个结论就是两者没有关系，也就是说对于这些国家来说，<strong>股市回报和经济增长的速度并没有什么直接关联</strong>。课程里对这个结论归因为如下两个原因</p>
<ul>
<li><strong>资产的价格</strong>。一个地方经济发展的速度当然可以很快，但如果人们为这种快速发展的预期付出了过高的价格的话，回报就不会太好；比如说房价</li>
<li><strong>全球化</strong>。由于全世界各个国家的经济联系越来越紧密，我们已经很难知道总体经济增长的时候利益会落到哪个具体的国家了。比如说耐克在福建、广东甚至越南生产出一双鞋，这双鞋的价值会实实在在的计入当地的GDP，但鞋里面大部分的利润都被耐克一家美国公司赚走了；公司股价则是和公司的盈利能力是息息相关的，所以虽然新兴经济体增长快，但里面有很大一部分利润都被跨国公司拿走了</li>
</ul>
<p><strong>所以我们想象中的那种新兴市场经济发展快，所以投资会赚到更多的印象是不准确的。这会导致一个什么问题呢？就是虽然我们国家未来仍然可能是世界上经济发展最强劲的国家之一，但这不意味着中国的股市、房市各种投资品市场会持续上涨。</strong></p>
<p>除此之外，课程里还提到了一个行为金融学的概念：<a
href="https://wiki.mbalib.com/wiki/%E6%9C%AC%E5%9C%9F%E5%81%8F%E5%A5%BD"><strong>本土偏好</strong></a>，即人们偏向于投自己国家的资产，比如日本股市的整个市值占全球总体市场的7~8%左右，但是日本本地的投资者会把60%左右的资产配置在本土市场上，同样美国股市的市值可以占到全球的一半，但美国投资者在本土股票上配比更高，几乎有80%，那中国的投资者就更不用说了，毕竟大家都熟悉本国的投资品种，投资起来更让人安心。但是本土偏好的一个风险是我们没法用简单的方法判断出一个国家的资产是不是会升值，只投资任何一个国家其实都是有点冒险的，</p>
<p>针对第二个问题，个人投资者在投资的时候，可以选择一些涵盖世界上主要股票市场的基金进行投资，如
<a href="https://xueqiu.com/S/ACWI">acwi 指数ETF</a>,
还有一些其他的海外配置的方法课程里没有提及，只是提了“稍微做一点功课都能找到”</p>
<p>因此，这部分有以下三个结论值得重点关注
（1）<strong>海外资产配置很有必要</strong>，因为一个资产能不能升值，跟一个国家的经济增长没有必然联系，所以我们不能因为中国经济发展迅速就忽略了海外投资。
（2）<strong>做海外资产配置的时候，不能只挑我们熟悉的国家</strong>，因为全球股市表现最好的地方，很多时候我们都想不到。
（3）想要投资全球市场，有不少产品可以实现，很多主流的大基金都能让我们坐拥全世界主要的股票市场</p>
<h2 id="小结">小结</h2>
<p>这部分介绍的内容可总结如下</p>
<p><strong>1.个人投资者的优势与劣势</strong></p>
<ul>
<li>优势是不需像专业投资者那样舍近求远、舍易求难；劣势是可接触的资源有限</li>
<li>掌握一些最朴素的投资方法，避免最明显的投资错误，才是走向投资成功的正途</li>
</ul>
<p><strong>2.避免投资偏好</strong></p>
<ul>
<li>无论短期还是长期，都很难预测哪类资产在未来表现会最好</li>
<li>个人容易因为过去的经历就对某一种资产有特殊偏好，但投资者不要对资产有明显的偏好</li>
</ul>
<p><strong>3.择时陷阱</strong></p>
<ul>
<li>短期来看，我们很难通过择时获得超额回报；长期来看，准确判断牛市熊市的来临时间也非常难</li>
<li>个人投资是一个无限游戏，一个好的卖出理由是是你的买入理由不再成立了</li>
</ul>
<p><strong>4.宏观迷信</strong></p>
<ul>
<li>宏观经济是很重要，但影响宏观经济的因素太多太复杂</li>
<li>与其把精力放在宏观经济这种重要但不可知的事情上，不如想的小一点，关注更可知的事情</li>
</ul>
<p><strong>5.风险度量</strong></p>
<ul>
<li>买了高风险的产品，但并不理解什么是风险，总以为亏损不会发生在自己身上，这是很危险的</li>
<li>风险难以被量化，因此不要去想象风险的概念，而是要直接去衡量风险的结果</li>
</ul>
<p><strong>6.海外配置</strong></p>
<ul>
<li>一个资产能否升值，跟一个国家的经济增长没有必然联系</li>
<li>做海外资产配置的时候，不能只挑我们熟悉的国家</li>
<li>很多主流的大基金都能让我们坐拥全世界主要的股票市场</li>
</ul>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>张潇雨的个人投资课(3)-投资组合构建</title>
    <url>/2021/11/28/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE(3)-%E6%8A%95%E8%B5%84%E7%BB%84%E5%90%88%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<p>本文是听了 <a
href="https://www.igetget.com/course/%E5%BC%A0%E6%BD%87%E9%9B%A8%C2%B7%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE?param=XDGhXPc6fL6&amp;token=YPZNRwQ0qL1MVEpfwzK3lmz4kgWEnx">个人投资课</a>
后的一些笔记，课程主要内容可划分为如下四个部分：<strong>市场规律、投资工具、自我局限和投资组合构建</strong>，前三个部分主要讲一些投资过程中最容易犯的错误，最后一部分则是讲一些具体的投资方法。</p>
<p>本文是最后一部分的内容，介绍了资产配置的必要性、大类资产基本分类即特点、以及三种经典的资产配置方法。课程前面内容介绍可参考</p>
<ul>
<li><a
href="https://wulc.me/2021/11/14/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%281%29-%E5%B8%82%E5%9C%BA%E8%A7%84%E5%BE%8B/">张潇雨的个人投资课(1)-市场规律</a></li>
<li><a
href="https://wulc.me/2021/11/20/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%282%29-%E6%8A%95%E8%B5%84%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%87%AA%E6%88%91%E5%B1%80%E9%99%90/">张潇雨的个人投资课(2)-投资工具与自我局限</a></li>
</ul>
<span id="more"></span>
<h2 id="资产配置与大类资产">资产配置与大类资产</h2>
<p>这部分主要强调了资产配置的重要性，同时介绍了进行资产配置时有哪些候选，即大类资产的分类</p>
<p>资产配置的重要性体现在其能较好回报的波动性，或者说最大回撤；课程里给出了如下的例子</p>
<blockquote>
<p>著名的投资大师耶鲁捐赠基金的掌门大卫斯文森说过，我们在市场上不管做什么，本质上都是在做三件事情，<strong>资产配置，市场择时和产品选择</strong>，</p>
<p>在 1986 年，三位著名学者发表了一篇叫做投资组合业绩表现的决定因素(<a
href="https://www.cfainstitute.org/en/research/financial-analysts-journal/1995/determinants-of-portfolio-performance">Determinants
of Portfolio
Performance</a>）的论文，里面得出一个结论，<strong>投资组合回报的波动性有93.6%都是由资产配置决定的，而市场择时、产品选择的贡献可以忽略不计</strong>;
等到了 1991
年，另外三位学者对这项研究进行了后续的补充，在更换了一些研究对象和研究方法之后，他们得出的结论是投资组合回报的波动性有91.5%是被资产配置决定的，其他两项因素可以忽略不计,
说白了就是再次肯定了之前的研究结论</p>
</blockquote>
<p>这个结论听起来很反直觉，比如说现在上证指数还没回到 07
年的高峰，难道不能说明择时能力很重要吗？买到涨停股和跌停股，一天的差别就是20%，难道不能说明选择产品的能力很重要吗？笔者觉得
<a href="https://www.xintuoyi.com/study/21.html">这篇文章</a>
里给出了这个结论适用的几个前提比较合理</p>
<blockquote>
<p>1、时间分散。为了防止配置资产时建仓成本过高，建议逐步增加至目标仓位，在市场高峰时，尤其要谨慎。
2、不同产品间分散投资。<strong>投资组合的目的不是为了寻找涨停股，而是为了获取持续稳健的收益</strong>。分散投资可以降低单支股票选择所带来的影响。
3、长期策略。短期投资和长期投资的业绩决定因素不一样。<strong>当投资时间覆盖一个经济周期以上时，选择具体产品的能力和选时能力的作用就会很小</strong>。</p>
</blockquote>
<p>因此，这里提到的资产配置，核心目标<strong>是在管理最大回撤这个指标的前提下，获得长期收益</strong></p>
<p>那么，在构建资产配置时，有哪些候选可以选择，或者说有哪些大类资产可供选择呢？因为大类资产配置对最大回撤指标和组合的波动性具有决定性的影响。</p>
<p>大类资产的似乎没有严格的分类，具体可参考这个问题 <a
href="https://www.zhihu.com/question/36726039">大类资产有哪些类？以那些标准分类？</a>；而从普通人的视角来看，常见的可投资的大类资产有</p>
<ul>
<li>权益类：主要就是股票市场，如A股、美股、港股、其他国家股等</li>
<li>固定收益类：债券、银行理财投资等</li>
<li>大宗商品：基本可归为能源、金属和农产品三大类(如原油、黄金、小麦等)</li>
<li>房地产：<a
href="https://zh.wikipedia.org/zh-sg/%E4%B8%8D%E5%8B%95%E7%94%A2%E6%8A%95%E8%B3%87%E4%BF%A1%E8%A8%97">房地产信托投资基金</a></li>
<li>现金：货币基金或短期债券</li>
</ul>
<p>股票型基金前面都讲得比较多了，这里主要介绍债券和大宗商品(后面投资组合也会有部分相应介绍)</p>
<p>关于债券, 以下几点值得关注
(1)债券主要分为<strong>利率债和信用债</strong>；前者有国家背书(如国债、地方政府债、中央银行票据等)，后者则没有(如金融债、企业信用债)，发行人信用情况是影响债券收益率的重要因素。<strong>信用债的风险大于利率债</strong>
(2)债券的价格于利率是呈反比的，也就是说，当利率上升的时候，债券的价格是下降的；相反，利率下降的时候，债券的价格是上升的，关于利率如何影响债券、股票等价格可以参考
<a
href="https://www.zhihu.com/question/331071222/answer/730833529">利率是如何影响大类资产价格的?</a>
(3)债券同样有基金，关于债券基金的一些细节可以参考 <a
href="https://zhuanlan.zhihu.com/p/108781882">2021，终于有人把债券基金说清楚了</a>，里面给出的一些收益率的参考数字如下</p>
<blockquote>
<p>短债基金长期平均年化在3%-4%； 长债基金长期平均年化在5%-6%；
二级债基比较优秀的，长期平均年化在可以到7%-8%左右。</p>
</blockquote>
<p>关于大宗商品，以下几点值得关注
(1)比较严重的金融危机或者战争危机来临的时候，黄金可以起到一定的避险作用，但这不意味着它在危机时价格一定会涨(如2008年金融危机，金价同样跌到了30%之多)
(2)从1973年统计到2017年，黄金总体回报率在6.9%左右；能源和产品类的总体回报率在5~6%之间，比国债高，比股票低；但这两种资产的波动和回撤比股票和债券都要高一些，黄金的最大回撤曾经超过60%，而大宗商品整体曾下跌超过80%。</p>
<p>有了相应地原材料，接下来就是如何组合这些原材料了，下面阐述的三种资产配置的方法是按照<strong>预期收益从低到高，预期波动程度从低到高，涉及的资产种类复杂程度也从低到高来排列</strong>的。虽然世界上没有绝对正确的资产配置方案，这三个组合都是大师推荐并经过长期的时间验证过的，所以从他们开始学习是个不错的选择。</p>
<h2 id="永久组合">永久组合</h2>
<p>这个组合是<a
href="https://book.douban.com/subject/27111607/">哈利·布朗的永久投资组合</a>，是简单来说，就是25%的股票，25%的国债，25%的现金和25%的黄金</p>
<p>整体思想就是不追求高回报，但追求长期的稳定以及过程的顺利，<strong>25%的股票负责整体回报，25%的国债会带来稳定收益，而现金和黄金的部分会在极端的市场环境下提供保护</strong>；日常情况下永久组合无法跑赢偏重股票的组合，但如果遇上经济危机和金融海啸，在别人的投资都跌掉30%、40%的时候，如果你使用的是永久组合，那么你的损失会小很多，很容易保持很良好的心态，更容易把投资长期的坚持下去，这也是永久这个名字的意义所在。</p>
<p>那么怎么衡量这个永久组合的表现？课程里将其与一个通用的
60、40组合做了对比</p>
<blockquote>
<p>有个标准叫做60、40组合，其实就是60%股票，40%国债这样一个极其简单的组合，这个组合被公认为是最简单，历史上的收益和风险也最被广泛的接受的一个组合。可以说任何的资产配置方案，都是从60
40这个极简的配置方法出发的，所以它就变成了业界公认的比较基准之一。</p>
<p>那接下来我们就比较一下，我们用<strong>25%的美国标普500指数基金，25%的美国10年国债指数基金，25%的黄金指数和25%的短期货币市场基金(即现金)</strong>来实现永久组合的配置。从1973年计算到2017年，这45年的历史回报那么得出的结果是怎么样的呢？</p>
<p>永久组合的年化回报是8.15%，最大回撤12.42%，<a
href="https://zh.wikipedia.org/wiki/%E5%A4%8F%E6%99%AE%E6%AF%94%E7%8E%87">夏普比率</a>是0.5
60、40组合的指标是年化回报9.76%，最大回撤29.69%，夏普比率 0.52
而对于标普500指数为例，这组相关指标分别是年化回报10.52%，最大回撤50.21%，夏普比率是0.43</p>
<p>根据这组比较，可以很明显的看出几个规律
第一，永久组合的长期回报8.15%，的确跑输了60、40组合的9.76%，当然也跑输了整个股市10%以上的回报，落后的幅度基本在每年1~2%左右。
第二,
长期收益率的落后换来的是过程的极大平稳。如果单纯投资股市，你要面临自己资产曾经腰斩，跌到一半的可能性，哪怕是60、40组合，最大回撤也有30%，但是永久组合有有现金和黄金的保护，最大回撤只有12%左右
第三，不管是永久组合还是60、
40组合，都明显提高了投资的夏普比率，也就是投资者每承担一份风险，获得了更高的超额回报。
也就是说这个资产配置的确提高了我们投资的效率</p>
</blockquote>
<p>那具体要怎么配置呢？课程给了如下建议</p>
<p><strong>1.股票</strong> - 原则：不要轻易选股，要尽量降低成本 -
用市面上能找到的正规可靠低成本的股票指数基金来代表股票的部分 - 4
家美国目前最大最可靠的基金公司：安硕、先锋、到富和富达，他们提供的指数基金产品都非常全面，而且价格低廉，</p>
<p><strong>2.债券</strong> -
一般用美国或者中国的国债作为底层资产，由于国家信用背书，这两种产品都是非常安全的
-
债券的种类也非常多，在具有专业知识的情况下，可以用其他的一些债券品种来充当这个部分的底层资产，但是选择要非常谨慎；详细可参考前面列出的关于债券的链接</p>
<p><strong>3.黄金</strong> -
可以买入实体的黄金，更方便的方法是买入和黄金挂钩的基金</p>
<p><strong>4.现金</strong> -
在国内可以放入活期存款，或者买入期限比较短，比如3~6个月的货币基金而 -
如果是外币，可以买入各大基金公司提供的美国三个月短期债券基金或者国债货币市场基金</p>
<p>值得注意的是，这里的组合更多是一个框架，可以灵活地进行调整，如
(1)<strong>具体成分的选择</strong>。比如在选择中国的股票指数基金的时候，可以加入香港恒生指数，甚至中概股指数，这些都是可以的，没有绝对的谁优谁劣；更多的是自己的判断和偏好，甚至有些专业人士比较喜欢加入行业型的指数基金，比如说医疗行业，消费行业等等，但是前提是你得有专业级的判断
(2)<strong>地理位置的选择</strong>，之前也介绍过，很难判断一段时间内哪些国家和地区的股市涨得最好，所以在投资的地理维度上保持多元分散也是有意义的。在课程中常用中国和美国的产品来举例，这是我们相对最了解的两个国家，但如果对其他国家有投资偏好，也可以加进自己的选择。比如说很多基金经理喜欢投资所谓的新兴市场，因为这些地区的经济增长更快，或者有的人觉得在漫长的增长停滞之后，日本经济会迎来复苏，所以他们愿意配置一些日经225指数基金
(3)<strong>每类资产比例的大小</strong>。比如永久组合是股票、债券、黄金、现金4等分的一个中庸的组合，但如果你希望长期回报更高，同时愿意接受多一点的波动和回撤，那么自然就可以少投资一点国债和现金，多加一些在股票上</p>
<h2 id="全天候组合">全天候组合</h2>
<p>这个组合的提出者是<a
href="https://zh.wikipedia.org/wiki/%E9%9B%B7%C2%B7%E9%81%94%E5%88%A9%E5%A5%A7">雷·达利奥</a>，是桥水基金创始人之一，这个全天候策略产品当前也是桥水基金的主打产品之一，管理有几百亿美元之多，而且表现不俗，尤其在2008年和2018年，整体环境不好的时候，都取得了可观的正回报。</p>
<p>但这个策略的所有细节，是超过1500名桥水员工经过多年打磨和研究得出来的，而且是非常动态的。作为普通投资者，我们不可能也没有必要全盘复制他们的方法，而且也确实做不到。但我们可以按照他们的思路构建自己的组合，达里奥也在很多场合给普通投资者推荐过他全天候策略的简化版，普通人通过这个版本也能达到和桥水基金相近的风险和回报，并且能在不同的经济环境下取得收益。</p>
<p>具体的配置是：<strong>美国大盘股18%，美国小盘股3%，其他发达国家股票6%，新兴市场国家股票3%，10
年期美国债券15%, 30
年期美国债券40%，大宗商品和黄金各占7.5%</strong>这个配置有一下几个特点</p>
<ol type="1">
<li>全天候组合对 30% 的股票部分进行了细化,
把它们分配给了美国、其他发达国家和发展中国家(所谓新兴市场）三个部分，这个也是之前一直说的多元分散自己的投资组合。</li>
<li>比起永久组合，简化版的全天候组合增加了一个大宗商品类的资产。<strong>这类资产往往被认为和通货膨胀挂钩比较多，可以在通胀比较严重的时候给投资组合提供回报</strong>。换种角度也可以理解成，达利奥觉得单独投资黄金还不保险，还把一部分的额度分给了大宗商品来一起控制最大回撤</li>
<li>从资产大类来看，全天候组合其实就是30%股票，55%政府债券，7.5%的黄金和7.5%的大宗商品，也就是说这个配置方案比之前的永久组合更激进一些，因为股票占比是更高的</li>
</ol>
<p>那这个组合的具体表现如何</p>
<blockquote>
<p>从1973~2013年的历史来看,
全天候组合：年化回报9.5%，最大回撤14.59%，波动率8%左右，夏普比率是0.51。
60、40组合：年化回报9.76%，最大回撤29.69%，波动率10%左右，夏普比率是0.52。
永久组合：年化回报8.15%，最大回撤12.42%，波动率6.88%，夏普比率是0.5</p>
<p>在这组数据里我们很容易看到，全天候组合和60、40组合的回报基本相同，但不管是波动率、还是最大回撤，都要小得多，毕竟不到15%的回撤，比起30%来还是舒服很多的。当然了永久组合因为有25%现金的存在，所以波动和回撤都是最小的，但这也是用降低
1~1.5% 左右的长期收益率换来的。</p>
</blockquote>
<p>至于具体的产品选择，基本跟前面提到的一样，只是课程里重申了选择产品的主要原则：<strong>来自大基金公司，成本费用低廉，没有基金经理主动的干预，只是被动地跟踪市场</strong>。</p>
<p>另外这部分还提到了一个组合管理与资产配置中另一个重要的概念：<strong>再平衡(rebalance)</strong>；即当你组合里各种资产的比例，随着市场涨跌已经偏离了最初设定的时候，要通过操作把它恢复成一开始的比例，有点像把手机或者电脑一键恢复成出厂设置。</p>
<p>那么这里有两个问题需要回答，第一，我们为什么要再平衡？第二，我们什么时候应该做再平衡？这两个问题，投资学术界和实战界都有很多经验总结</p>
<p>针对第一个问题，在平衡背后有两个理论依据 (1)<strong><a
href="https://zh.wikipedia.org/wiki/%E5%9D%87%E5%80%BC%E5%9B%9E%E6%AD%B8">均值回归</a>理论</strong>，即一个资产的价格最终都会回归到它的平均水平。根据这个理论，如果一个资产涨得比较快，在组合里占比比较大，我们对它的预期就是接下来的回报会下降；而如果一个资产之前跌了很多，接下来很可能会上升。所以再平衡的过程就是卖出上涨的资产，买入下跌资产的过程，这样会带来一些超额收益
(2)行为金融学上的原理：<strong>大部分人都更喜欢追涨杀跌</strong>，所以再平衡实际上是在高点卖出，在低点买入，实际上是一个相反的举动，这样长期坚持下来也会有一些超额收益</p>
<p>针对第二个问题，学术界也做过很多研究，最后发现不论是1个月、3个月、6个月还是12个月再平衡一次，差距都不是很大。所以作为普通投资者，我们<strong>每12个月再平衡一次就基本足以，这样也能降低交易成本</strong>。</p>
<p>另外，课程里还提到可以<strong>给自己的再平衡设置一个幅度</strong>，比如说永久组合4个资产开始各占25%，可以设定一旦某个资产涨到35%的时候，就把它卖出，然后买入占比最低的资产，对于全天候组合也是一样的</p>
<p>最后，关于全天候组合的更多阅读资料可参考 <a
href="https://www.zhihu.com/question/22929725/answer/23105457%9E%E6%AD%B8">Ray
Dalio 的「全天候交易策略」是什么？如何理解？ - 师纪瑞的回答 -
知乎</a></p>
<h2 id="斯文森组合">斯文森组合</h2>
<p>这个组合是<a
href="https://zh.wikipedia.org/wiki/%E5%A4%A7%E5%8D%AB%C2%B7%E6%96%AF%E6%96%87%E6%A3%AE">大卫·斯文森</a>管理耶鲁捐赠基金时提出的一个组合，当时的斯文森发现了
2 个秘密</p>
<ol type="1">
<li>要想保证长期的回报高，整个投资组合一定要偏重于股权(也就是股票）。现在也是整个业界的共识，但是在80年代斯文森接管耶鲁基金的时候，绝大部分的大学捐赠基金都更喜欢债券、房地产、黄金这样的投资产品，不太敢下重注在股票这个品类上。
(2)多投股权会带来一个的问题，就是波动很大，那么有没有一些股权品类是相对比较稳定，不太随着市场上上下下波动剧烈的呢?斯文森就找到了这么一个品类，说出来你也很熟悉,
就是风险投资和私募股权投资，也就是我们常说的 <a
href="https://zh.wikipedia.org/wiki/%E9%A3%8E%E9%99%A9%E6%8A%95%E8%B5%84">VC</a>
和对冲基金。</li>
</ol>
<p>但是这里一个显著的问题是，普通投资者很难复制这个方法，因为 VCP
、对冲基金这样的机构一般是不会对普通投资者开放的；因此，斯文森提供了一个简化版的耶鲁投资法，<strong>对于个人投资者，有三个核心的原则和建议</strong></p>
<ol type="1">
<li>一个投资组合里应该有6种不完全相同的资产，但总体来说应该以股票为主，因为从长期来看，股票永远是回报最高的选择。</li>
<li>投资者应该按照自己设定的时间频率来给组合进行再平衡，一般来说一年一次就可以。</li>
<li>市场很难战胜，所以相对个股投资,
那些低成本的指数基金是很好的选择</li>
</ol>
<p>其实这三点基本原则跟前面 2
种组合大同小异，斯文森根据这个思路推荐了一个这样的资产配置方法：<strong>美国大盘股20%、其他发达国家股票20%、新兴市场国家股票10%、30年期的美国债券15%、通胀保护债券15%、房地产投资信托20%</strong>。</p>
<p>可以看出啊这个组合比我们之前介绍的组合要更偏重股票一点，整体分配给股权的部分达到了50%。另外斯文森也比较喜欢房地产信托基金，房地产信托长期收益和股票类似，所以这个组合虽然成分比较多，操作起来呢也复杂一些，但总体收益要比之前介绍的两个组合要高一些，当然波动也会更大</p>
<p>那这个组合的收益情况如何？还是以1973年到2013年这个区间为例，斯文森组合的年化回报10.16%，最大回撤41.6%，波动率是10.68%，夏普比率是0.46，与前面的一些组合相比，回报是最高的，但是最大回撤也是最大的，夏普比率也是最低的</p>
<h2 id="因子投资">因子投资</h2>
<p>因子投资(<a
href="https://en.wikipedia.org/wiki/Factor_investing">Factor
investing</a>)简单来说，就是尝试找到股票涨跌和表现的原因(即因子)，然后基于这些因子来找到更好的投资产品的方法</p>
<p>以大盘股/小盘股的概念为例，简单来说公司市值规模比较大的就叫大盘股，规模小的就叫小盘股。历史经验告诉我们，小盘股的长期收益通常要比大盘股更高，即规模是影响股票表现的一个因素，也就是这里说的因子。</p>
<p>学术界在二十几年前就已经开始研究因子了，这个领域的泰斗级人物<a
href="https://zh.wikipedia.org/wiki/%E5%B0%A4%E9%87%91%C2%B7%E6%B3%95%E9%A9%AC">尤金·法马</a>，与同事提出了<a
href="https://zh.wikipedia.org/wiki/%E4%B8%89%E5%9B%A0%E5%AD%90%E6%A8%A1%E5%9E%8B">三因子模型</a>，股票的回报至少可以从三个角度来解释：<strong>市场因子、规模因子和价值因子</strong>。</p>
<p>具体一点就是股票的回报至少可以分解为三个部分
(1)市场的整体回报，即每只股票随着大势上上下下来回波动带来的回报，
(2)规模，比如说小公司的长期回报比大公司更好
(3)价值因子，简单来说就是比较便宜的股票，长期收益会比贵的股票更好</p>
<p>值得注意的是，这里说的这三个因子只能解释股市的一部分表现，而不代表所有，因为市场的复杂性往往通过这几个因子无法完全解释得通；那这些因子有什么实际的指导意义么？课程给出了如下建议</p>
<blockquote>
<p>通过这些因子，可以大概解释很多明星投资人和基金经理带来的超额回报到底是从哪来的了
比如说我们之前课程中介绍过的股神彼得林奇，他就以偏爱高增长的小盘股而著称，他买的很多股票都带有这种性质，而我们都知道巴菲特非常在意股票的价格，所以他的超额回报就有一部分来自价值因子
虽然因子肯定没法解释他们的全部天才，但是也给我们提供了一个重要的思路，这时候一个想法就很自然的诞生了。假设我们按照股神彼得林奇或者巴菲特的方法，<strong>系统性的投资小盘股或者估值比较便宜的股票</strong>，不就相当于复制了他们一部分的能力了吗？
换个角度说，被动投资指数是我们最倡导的投资策略，而靠主动选股持续的打败市场非常难，但是<strong>因子投资给了我们这么一个机会，就是用一种介于主动和被动之间的投资方法，把我们的长期收益提高那么一点点，而且还不用有特别高深的专业知识</strong>。</p>
</blockquote>
<p>那现在业界公认最有效的因子都有哪些？总结下来主要有主要有这么6个</p>
<ul>
<li><strong>规模因子</strong>，认为小盘股长期比大盘股回报要高一些</li>
<li><strong>价值因子</strong>，认为价格便宜的股票长期要比贵的股票收益高一些</li>
<li><strong>低波动因子</strong>，认为总体波动程度比较小的股票，长期比波动大的股票回报要高一些</li>
<li><strong>红利因子</strong>，认为高分红的股票长期表现会更好</li>
<li><strong>质量因子</strong>，认为质地比较好的公司的股票长期回报会更高</li>
<li><strong>动量因子</strong>，认为过去一段时间股价表现比较好的股票，接下来表现会更好</li>
</ul>
<p>这六大因子就是目前投资界已经被学者和实战派们反复证明了长期有效的因子，不仅经受住了统计学上的考验，也是很符合商业逻辑的；在具体的操作上，因子投资最终也可以落到买基金上，比如之前提到过的各种指数基金公司，像安硕、先锋等等，旗下都有费率很低的因子投资指数基金；国内各大基金公司都推出了像各种红利基金、价值基金、低波动基金等等相关的产品，</p>
<p>但是有一点值得关注，<strong>和大类资产的表现一样，因子的表现也有周期性和轮动性</strong>。换句话说，如果随便看5年甚至10年，有可能某一类因子表现很好，但另一类就很差，如果你正好选到了比较差的因子，那么还不如直接投资最普通的指数基金；比如从2001年到2007年，动量因子、价值因子、低波动因子和规模因子表现都不错，但是质量因子反而跑输大盘，而从2007年之后质量因子开始表现不错，但是动量因子和价值因子就没有那么好了，应对手段还是之前提到的大原则：<strong>多元分散</strong>，之前我们说的是要在资产种类上分散，那么在因子上也是可以分散的</p>
<h2 id="定投指数基金">定投指数基金</h2>
<p>这部分主要介绍了指数基金的一些基础知识，包括指数基金的一些分类，市盈率和市净率的含义。同时建议定投宽基指数基金，但是<strong>在国内</strong>这个建议是否适用还需要进一步考究，这部分在
<a
href="https://wulc.me/2021/11/20/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%282%29-%E6%8A%95%E8%B5%84%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%87%AA%E6%88%91%E5%B1%80%E9%99%90/">张潇雨的个人投资课(2)-投资工具与自我局限</a>，这里不再赘述</p>
<p>根据指数投资标的涵盖的范围，可以大概将指数分为：宽基指数、行业指数、策略指数；</p>
<ul>
<li><strong>宽基指数</strong>：就是我们最常见的没有任何主观因素的，直接按照规则被动的复制市场表现的股票指数。比如沪深300指数、中证
500指数、创业板指数等</li>
<li><strong>行业指数</strong>：在各个行业里按照一定的标准来选取公司，方便那些对某个行业有偏好的投资者来投资，如所谓的消费行业指数，医药指数，军工指数或者养老指数，</li>
<li><strong>策略指数</strong>：这个策略性基金和我们之前说到的因子投资基本是一回事，如大成中证红利指数基金、景顺长城、中证500低波动指数基金，申万零信沪深300价值指数基金、嘉实基本面50指数基金。这些基金本质上就是在把因子投资的理念应用在中国股市上，上面提到的几个基金使用了红利因子，低波动因子，价值因子和质量因子的理念</li>
</ul>
<p>关于行业指数，课程里着重强调了如下观点</p>
<blockquote>
<p>以我个人的意见，我觉得你要想投资某个行业的行业指数，不妨先问自己一个问题，那就是你对这个行业有没有超出平均水准的判断力？比如说很多人都会说看好中国的医疗行业，看好中国的养老行业，所以想投资相关的指数基金
这个时候我总会反问一个这样的问题，<strong>你的这种看好有什么超出常人水平的依据吗</strong>？比如说我们都知道中国人口老龄化的问题，都知道随着生活水平的提高，未来医疗养老服务会不断升级,那么你知道的这些信息是不是已经被反映在指数基金的价格里了？
换个角度说，你有多确定医疗行业在未来你的投资期限之内，比如说2年3年5年之内能跑赢大盘，如果你只是在媒体上看了一些消息，在公众号里看了几篇文章，就对一个行业觉得看好的话，我是不建议你投资行业指数基金的,宽基指数可能更适合你，而如果你是某个行业的从业人员或者专家，又或者对某个行业的观察和积累很深，那么投资行业指数就会是不错的选择。
对于我自己来讲，我觉得我对绝大多数行业都没有判断能力，所以投资宽级指数获得市场平均回报就很知足了</p>
</blockquote>
<p>所以课程里的建议是<strong>投资最常见也最经典的宽基指数，至于行业指数和策略指数，可以作为你核心持仓的一种补充，在自己能理解和接受的范围之内做一些配置就可以了</strong></p>
<p>基金通常还会被分为场内基金与场外基金，两者的区别可参考这个回答，<a
href="https://www.zhihu.com/question/30150662/answer/1041651863">场内基金与场外基金各有什么优劣势？
- 简七的回答 - 知乎</a>，简单对比如下图(图片也摘自这个回答)</p>
<p><img src="https://wulc.me/imgs/fund_compare.jpeg" height="80%" width="80%"></p>
<p>关于基金的一些基础知识，还可参考这个专栏 <a
href="https://zhuanlan.zhihu.com/p/22866377?refer=fundslearning">从0开始学基金投资</a>，写得比较通俗，同时也比较全面了</p>
<p>另外，课程里还提到经典的 PE、PB及其百分位的概念，这部分内容可以参考
<a
href="https://zhuanlan.zhihu.com/p/345397436">一文带你搞懂市盈率、市净率、市销率</a>，笔者觉得以下几点可以参考</p>
<ul>
<li>在公司每年都能稳定盈利的条件下，市盈率(PE)越低，散户投资回本的速度越快</li>
<li>低市净率(PB)意味着投资风险小，万一上市公司倒闭，清偿的时候可以收回更多成本</li>
<li>根据市盈率百分位加仓或止盈，<strong>30%以下进入加仓区间，70%以上进入止盈区间</strong>，可采取分批止盈方法</li>
<li>市盈率的局限
<ul>
<li>市盈率只反映过去和当下的市场</li>
<li>金融相关行业不适合用，例如银行、保险、证券业</li>
<li>周期行业不适用，例如钢铁、有色金属、化工等</li>
<li>战略性亏损的企业不适用，例如京东、亚马逊、特斯拉等</li>
</ul></li>
<li>市净率弥补市盈率，即使因为行业周期出现盈利能力的波动，对于市净率也不会有过大的影响</li>
<li>牛市看市盈率，熊市看市净率</li>
</ul>
<h2 id="课程结束语">课程结束语</h2>
<p>结束语主要强调两点 1.
从头到尾学完了之后，应该觉得投资真的很难，真的挺有风险，市场很强大，我们能掌控的事情其实很少的；当你<strong>对市场、对投资这件事更有敬畏心</strong>之后，你赚钱的几率反而会提高很多。
2.
<strong>语言是个功能有很大局限性的沟通工具</strong>，它是有很大的模糊性和欺骗性的，而这种模糊性和欺骗性很容易就把我们的投资旅程引入歧途</p>
<p>第一点比较好理解，关于第二点，课程列举了如下例子</p>
<blockquote>
<p>很多散户投资者，甚至很多专业投资人在买股票的时候都喜欢大盘蓝筹股，那么你知道蓝筹股这个词是怎么来的吗？
实际上蓝筹的英文是blue
chips，来自于西方赌场，因为过去的赌场里通常有三种筹码，白色的、红色的和蓝色的，其中蓝色的是最值钱的，久而久之大家就使用蓝筹股来指代那些规模大的、发展稳定的、市场形象良好的、盈利高的大公司。比如美国著名的道琼斯工业指数，一度也被称为蓝筹股指数，它在1928年创立出来的时候，就是选取的30家最大型的工业企业来代表美国股市的走势。
正因为蓝筹股的这种特性，很多投资者尤其是散户型的投资者都很爱买蓝筹股的股票，因为他们觉得所谓的蓝筹股肯定是比较稳定，买起来很踏实，回报比较高的股票，更好玩的是这个概念，漂洋过海来到中国之后，大家又延伸出来了一个白马股的概念，指的基本也是那些长时间的，业绩不错，业务管理水平比较高，商业模式也比较靠得住的大公司。而由于大家都知道这些公司不错所以比起仍然在等待被挖掘的黑马，这种公司更像是人人都看得见的白马，于是白马股这个词也就传开了</p>
<p>那投资蓝筹股或者白马股的结果怎么样呢？ 在2012年, 研究机构 <a
href="https://www.researchaffiliates.com/home">research affiliates</a>
的创始人罗布阿诺特做了一项研究，他们发现有这么一个现象，如果选取每个行业内市值最大的公司的第一名，这应该够蓝筹够白马了吧,
然后跟踪他们接下来1年、3年、5年和10年期的股价表现，这些公司有比较大的概率是要跑输整个行业的其他公司的，准确说一年内跑出的概率是57%、三年是58%、五年60%、10年就是66%，跑输的收益率幅度平均在4%以上，而且这个现象横跨了世界上9个主要国家的12个行业。</p>
<p>另外一个统计是从1980年到2019年，每一个10年全世界市值排名前10的公司，如果你看2019年上面都是什么苹果、微软、亚马逊、谷歌、腾讯、阿里这样的公司，但你仅仅往前翻10年，这个榜单就变成了中石油、埃克森、美孚、沃尔玛、汇丰银行、碧和碧拓这样的公司。再看2000年，英特尔、朗讯、ge、德意志电信榜上有名，而1990年则是东京三菱银行、丰田、富士银行这些日本公司的天下</p>
<p>因此，这些所谓的大盘股蓝筹股，在每个时代不可一世，觉得怎么也不可能消失的庞大的公司，他们的位置真的有那么稳固吗？买这些公司的股票真的是稳赚不赔吗？大公司的表现就一定能超出市场平均水平，超出指数吗？</p>
<p>这里需要记住的一点是<strong>做投资，千万不要执着于概念，更不要靠感觉行事。白马股不代表公司股价永远不跌，绩优股不代表业绩永远优秀</strong>，</p>
</blockquote>
<p>所以我们能看到，语言和文字是很有欺骗性的，几句话能传达的信息量非常有限，如果你执着于这些说法的字面意思，很可能就会被带的越来越偏。而很多时候，语言的这种欺骗性对我们的伤害还不是最大的，因为错的东西，我们吃亏个几次可能也就长记性了，<strong>可怕的是那种说法，其实挺对，也没想骗你，但表达出来非常模糊，很容易让人误解的东西</strong>。关于这一点，课程举了如下例子</p>
<blockquote>
<p>巴菲特那句“要在别人恐惧的时候我贪婪，别人贪婪的时候我恐惧”，这句话有错吗？当然没错，可以说是一句金玉良言，但问题是这句话实在是太模糊了，模糊到每个人的理解都可能非常不同
比如，别人恐惧我贪婪，这里的别人是谁？是你的家人朋友，还是你认识的散户投资者？是市场的主力资金，还是各国的央行和政府？你有数据统计有百分之多少的别人正处在恐惧情绪里吗？这些东西我们很难说的清楚;同样，怎么就叫恐惧了，是市场跌了20%叫恐惧，还是跌了50%叫恐惧？是一个月连续下跌叫恐惧还是连跌三年叫恐惧？继续再说贪婪，怎么就叫贪婪，是把全部身家拿去买股票叫贪婪，还是你敢买所有人都觉得要完蛋了的公司叫贪婪，这些还是很模糊。所以巴菲特老人家也经常吐槽大家过于追求咬文嚼字的习惯，比如他都说过，我不知道什么叫价值投资，因为所有的投资都应该叫价值投资，一个投资没价值，你还要投资吗？</p>
<p>更有意思的是,很多时候你会发现，哪怕有些说法实际上毫无意义，人们也会选择去听取和相信，比如陈大老师在他写的那篇很有意思的，<a
href="https://zhuanlan.zhihu.com/p/343522691">如何做一个打脸无忧的股评</a>里，就提到过，股评家最爱用一些模棱两可的话来预测市场
比如他们来说，市场正在进行估值修复，什么叫估值修复？是高变成低叫修复还是低变成高叫修复，好像怎么说都行。还有比如市场情绪正在升温，怎么就叫升温了？是资金多了，还是价格涨了，还是恐惧情绪升温，大家都要逃跑了，还是怎么说都行。还有什么市场风险释放？陈老师说我就想问一问市场风险有憋着不释放的时候吗？市场风险不释放会怎么样？是原地爆炸吗？</p>
<p>所以在最后一节课里，我为什么要说这些？因为我知道一门我的个人投资课，不可能把世间投资的道理都覆盖到。<strong>在课程结束之后，你肯定还要去其他地方继续学习研究，不断提高自己的水平和认知，这是非常正确的。但是你不管学习什么投资知识，它的载体肯定都是语言和文字，这门课也不例外，而只要是语言就带有它的局限，就有覆盖不到的情况，具有模糊性和欺骗性。</strong></p>
<p>所以<strong>投资这门学科里没有金科玉律，也没有绝对真理，尽信书、
不如无书</strong>，只有时时刻刻保持独立思考，求真求实，相信理性，不根据感觉形式，不去相信和追求一劳永逸的必胜之法，而和常识概率以及时间站在一起才是最最重要的。</p>
</blockquote>
<p>关于语言的局限性，得意忘形有 2 期节目有过类似的观点，可以去听一下</p>
<ul>
<li><a
href="https://www.xiaoyuzhoufm.com/episode/5e74543a418a84a046c4e5bb">#03：《降临》与语言哲学、线性思维缺陷与「时间」可能不存在吗？</a></li>
<li><a
href="https://www.xiaoyuzhoufm.com/episode/5e74543a418a84a046c4e55b">#34：语言的陷阱、「财务自由」的
legitimacy 以及「你到底喜不喜欢我啊？」</a></li>
</ul>
<h2 id="小结">小结</h2>
<p>这部分内容可总结如下</p>
<p><strong>1.资产配置的必要性</strong></p>
<ul>
<li>投资组合回报的波动性有基本由资产配置决定的，而市场择时、产品选择的贡献可以忽略不计</li>
<li>资产配置的目的不是为了寻找涨停股，而是为了管理最大回撤这个指标的前提下，获得长期收益</li>
</ul>
<p><strong>2.大类资产</strong></p>
<ul>
<li>权益类：主要就是股票市场，如A股、美股、港股、其他国家股等</li>
<li>固定收益类：债券、银行理财投资等</li>
<li>大宗商品：基本可归为能源、金属和农产品三大类(如原油、黄金、小麦等)</li>
<li>房地产：房地产信托投资基金</li>
<li>现金：货币基金或短期债券</li>
</ul>
<p><strong>3.永久组合</strong></p>
<ul>
<li>25%的股票，25%的国债，25%的现金和25%的黄金</li>
<li>股票负责整体回报，国债会带来稳定收益，而现金和黄金的部分会在极端的市场环境下提供保护</li>
<li>可调整维度：具体成分、地理位置、每类资产比例</li>
</ul>
<p><strong>4.全天候组合</strong></p>
<ul>
<li>美国大盘股18%，美国小盘股3%，其他发达国家股票6%，新兴市场国家股票3%，10
年期美国债券15%, 30 年期美国债券40%，大宗商品和黄金各占7.5%</li>
<li>产品选择大原则：来自大基金公司，成本费用低廉，没有基金经理主动的干预，只是被动地跟踪市场</li>
<li>再平衡(rebalance)：均值回归与追涨杀跌，12 月调整一次即可</li>
</ul>
<p><strong>5.斯文森组合</strong></p>
<ul>
<li>美国大盘股20%、其他发达国家股票20%、新兴市场国家股票10%、30年期的美国债券15%、通胀保护债券15%、房地产投资信托20%。</li>
<li>基本原则同上，需要 rebalance</li>
</ul>
<p><strong>6.因子投资</strong></p>
<ul>
<li>规模因子，认为小盘股长期比大盘股回报要高一些</li>
<li>价值因子，认为价格便宜的股票长期要比贵的股票收益高一些</li>
<li>低波动因子，认为总体波动程度比较小的股票，长期比波动大的股票回报要高一些</li>
<li>红利因子，认为高分红的股票长期表现会更好</li>
<li>质量因子，认为质地比较好的公司的股票长期回报会更高</li>
<li>动量因子，认为过去一段时间股价表现比较好的股票，接下来表现会更好</li>
<li>和大类资产的表现一样，因子的表现也有周期性和轮动性</li>
</ul>
<p><strong>7.基金的基本概念与常识</strong></p>
<ul>
<li>投资行业指数时需要问一下自己，看好这个行业有什么超出常人水平的依据</li>
<li>PE/PB 及其分位数定义</li>
<li>根据市盈率百分位加仓或止盈，30%以下进入加仓区间，70%以上进入止盈区间</li>
</ul>
<p><strong>8.语言的局限性与陷阱</strong></p>
<ul>
<li>语言是个功能有很大局限性的沟通工具</li>
<li>做投资，千万不要执着于概念，更不要靠感觉行事。白马股不代表公司股价永远不跌，绩优股不代表业绩永远优秀</li>
<li>投资这门学科里没有金科玉律，也没有绝对真理，尽信书、 不如无书</li>
</ul>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>张潇雨的个人投资课(2)-投资工具与自我局限</title>
    <url>/2021/11/20/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE(2)-%E6%8A%95%E8%B5%84%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%87%AA%E6%88%91%E5%B1%80%E9%99%90/</url>
    <content><![CDATA[<p>本文是听了 <a
href="https://www.igetget.com/course/%E5%BC%A0%E6%BD%87%E9%9B%A8%C2%B7%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE?param=XDGhXPc6fL6&amp;token=YPZNRwQ0qL1MVEpfwzK3lmz4kgWEnx">个人投资课</a>
后的一些笔记，
课程主要内容可划分为如下四个部分：<strong>市场规律、投资工具、自我局限和投资组合构建</strong>，前三个部分主要讲一些投资过程中最容易犯的错误，最后一部分则是讲一些具体的投资方法。</p>
<p>本文是第二部分和第三部分的内容，主要介绍了在投资过程中对一些投资产品的误解，以及投资过程中的一些自我局限。课程第一部分的内容介绍可参考
<a
href="https://wulc.me/2021/11/14/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%281%29-%E5%B8%82%E5%9C%BA%E8%A7%84%E5%BE%8B/">张潇雨的个人投资课(1)-市场规律</a></p>
<span id="more"></span>
<h2 id="指数基金">指数基金</h2>
<p>投资最常见的方式之一是买股票，但课程的观点是作为一名普通投资者，想要靠购买个股赚钱是非常困难的，主要原因是选中好股票很难了</p>
<p>课程里列举了标普 500
指标的例子，这个指数基本涵盖了美国最大、最好、最有代表性的500家公司，但是根据学者的统计，从1957年到1998年之间，超过
40 年里标普 500
指数的变化，结果是在40年之后只有74家还存在于指数中，其他要么被收购，要么倒闭，要么衰退极大。而在这个
74 家里，只有 12
家跑赢了整体的指数，即你能压中超出市场平均回报的公司的概率只有区区的2.4%。</p>
<p>笔者附：虽然课程举的这个例子是为了推荐投资指数基金，而包括巴菲特等人也的确推荐普通人投资指数而不是个股，关于指数基金定投的教程网上也很多，但是笔者认为这里有
2 点需要注意</p>
<p>1.这里统计的跨度是 40
年，但是个人投资者往往会不会这么长期持有投资，而资产的涨跌都是有周期的，因此
40 年跨度的数据并不意味着在这个过程中投资个股收益超过指数的比例只有 2.4%
2.国内的市场跟美国不太一样，巴菲特建议的是在美国市场定投指数基金，但是在国内不一定适用，这部分内容更详细可参考
<a
href="https://zhuanlan.zhihu.com/p/260339255">千万不要再瞎买指数型基金了
- 米多多的文章 - 知乎</a> 和 <a
href="https://www.zhihu.com/question/267534527/answer/1337621519">基金定投这么好，为什么能坚持下来的人那么少？
- TopView的回答 -
知乎</a>，这两个回答，里面也介绍了指数基金一些其他知识</p>
<blockquote>
<p>A股长期来看稳定上涨，但几十年间波动极大。主要特点是牛短熊长，没有美股的走势给力。这就导致，巴菲特口中散户用指数，战胜专业投资机构的“神话”并不会发生</p>
<p>股神巴菲特已经总结过了，指数型基金最靠谱，无脑定投指数就行。但是但是！！！这是指美股，你看看纳斯达克，比很多主动性基金都厉害。A股的指数基金一般在牛市才能够比主动型基金强，但是A股牛短熊长。A股指数基金真的不适合无脑定投，尤其是上证50、沪深300这样的，要适当高位止盈做波段。</p>
</blockquote>
<p>其实看到这里，你也能发现，投资这个东西并没有一个一劳永逸的方法，因为这个事情受到的影响因素太多了，<strong>所有的投资资料或课程都只是提供了一个视角给你，包括这门课也是，对个人而言，需要的是不断地学习和思考，搜集更多的资料和数据，辩证地看待单一一门课程或文章提供的观点</strong>。</p>
<h2 id="安全边际">安全边际</h2>
<p>这部分主要强调了这个观点：<strong>好公司不等于好股票，买入价格的高低会严重影响投资收益</strong></p>
<p>大部分人在做股票投资的时，很容易陷入一个误区，认为一家好公司一定是一个值得投资的对象，比如说你用到了一个好产品，对这个公司产生了好感；发现周围很多人都对他家的东西评价很好；然后又看到这家公司的创始人的采访和报道，觉得人也非常靠谱；最后你在媒体上读到了一些对这家公司的分析，觉得特别有前途，顺应了时代的大趋势等。所有这些点点滴滴的信息最终都汇聚成了一个结论，这家公司不错，那么显然我们应该买点他的股票。</p>
<p>但实际上这是不对的，先不说上面这些分析和结论是不是严谨，光是对一个问题的忽略，就能导致我们这种投资方式失败了，那就是价格，<strong>一家公司再好，如果你购买它的价格过高，也是很难赚到钱的</strong>。课程里举了如下例子</p>
<blockquote>
<p>银行业在任何国家都是一个支柱型和垄断型的产业，在我们国家更是。过去二十几年里，银行都是我们国家最赚钱的行业之一，而其中的一个佼佼者就是招商银行，从2007年到2017年，招行的年利润从150亿增长到了700亿，翻了4倍，多年化的增长率有15%之多。衡量银行的另外一个指标，每股净资产招商银行同样增长接近4倍。简而言之,
在10年左右的时间里,
招商银行通过不懈的努力和发展变成了一家更大更好的公司。那你说你要是买到这样一家优质公司的股票，然后长期持有应该能赚大钱了.
可惜未必,在2007年末市场大牛市尾声的时候，招行的股价冲到了23块5左右,但之后股价一路走低，最低达到过5块多钱。直到接近10年之后，2017年7月招行的股价才又回到了24块钱左右的水平。换句话说，如果你在2007年末买到了这样一家优质公司的股票，恐怕要忍受长达10年的账面亏损，才可能迎来曙光。所以你很有可能在黎明之前就倒在了半路上。
这里的原因是什么？其实最大的问题就是你买入的价格太高了，07年末的时候，整个市场其实已经相当狂热，所有股票的股价都被炒得很高，招行也不例外，所以即使那个时候我们能预测到招行这家公司未来会发展迅猛，利润会越来越好，但它那个时候的价格已经过高了，高到了需要花10年时间来消化的程度。</p>
</blockquote>
<p>所以就像我们开头说的，<strong>再好的公司，如果你不管价格就随意买入，很可能也会让你亏钱</strong>。那有人可能想个股的大起大落实在太正常了？如果我们买指数基金呢？实际上价格这个因素不只对个股有作用，对于整个市场也是成立的。</p>
<blockquote>
<p>2000 年 3 月的时候，纳斯达克创下了 5048
点的历史最高点，等到整个市场再回到这个价格水平的时候，已经是2016年的7月，16
年的时间已经过去 同样对于标普500指数，2007 年的高峰等到 2013
年才再次初级 至于A股就更明显了, 2007 年沪深 300 的历史高点，直到 2019
年初还没有回去，曾经 2015
年的大牛市仿佛就要触到这个顶点了，但随之而来的又是一轮深深的下跌。而且你会发现不只是中美这两个大国，其他国家的股市都有类似的规律，只要你忽略价格问题，不假思索的追高，那么亏钱就是非常有可能的。</p>
</blockquote>
<p>那一个很自然的问题就是，怎么判断公司/指数当前的股价是否过高呢？课程里给出的答案是无法精确地判断出当前的价格是多少，但是可以做个大概的区间评估，用概率论的角度来说就是区间估计比点估计要更简单；用芒格的话来说就是，“<strong>预测一件事会不会发生，永远比预测一件事什么时候发生要简单的多</strong>”</p>
<p>更学术的来说就是安全边际这个概念了，安全边际通俗说就是，如果你觉得一个公司值10块钱，结果市场有一天突然给出了一个五六块钱的价格，那么这个打折的部分就是你的安全边际，具体的方法论就是<strong>不管你给这家公司估值多少，最好给你心目中那个价格打个五六折，再去考虑买这只股票</strong>，说白了就是便宜就买，如下图所示</p>
<p><img src="https://wulc.me/imgs/safety_margin.jpg" height="50%" width="50%"></p>
<p>更详细和通俗的解释可参考这个回答，上面的图其实也是来自这个回答，<a
href="https://www.zhihu.com/question/21076006/answer/147394714">如何用生动的例子来解释「安全边际」?
- 陈达的回答 -
知乎</a>，里面还介绍了严格的安全边际可能存在的一些局限性，值得一看。</p>
<p>因此，这部分有以下2个结论值得重点关注</p>
<p>(1)<strong>好公司是不等于好股票的，买入时你的价格一定是一个必须要考虑的因素</strong>。
(2)怎么判断一个公司的股价是不是过高呢？其实除非极端情况出现，否则我们就是很难判断的,最好的处理方式就是在买入的时候给留出足够的安全边际，才有更大的赚钱的概率。</p>
<h2 id="抄底哲学与专业光环">抄底哲学与专业光环</h2>
<p>这里其实是两讲的内容，只是因为笔者觉得内容都比较单薄，就放在一块了~</p>
<p>第一部分是强调了抄底需要谨慎，套用网上一张图就能很好表达这部分的内容了,
结合前面的安全边际部分，笔者觉得对于个人投资者的方法论是：尽量等价格跌到安全边际下才买入，同时做好继续下跌的准备~</p>
<p><img src="https://wulc.me/imgs/buy_at_bottom.jpg" height="50%" width="50%"></p>
<p>此外，课程的另一个观点是<strong>即使是抄底，也尽量要去抄市场的底，而不是个股的底</strong>，因为市场极端的下跌是不太可能，但是课程里没给出相应的方法论，这部分可以参考
<a
href="https://www.zhihu.com/question/447667710/answer/1769070778">基金大跌20%，现在适合抄底吗？
- 网叔的回答 - 知乎</a></p>
<p>第二部分强调了不要迷信专业光环，根据课程提供了数据表明，无论是从3年5年还是更长的时间维度来看，大多数主动型、基金和专业人士都跑不赢大盘</p>
<h2 id="交易成本">交易成本</h2>
<p>这部分主要为了说明在交易过程中，需要注意交易成本的高低，因为这对最终收益的高低影响较大</p>
<p>以基金为例，一般涉及到的费用有<strong>管理费、托管费、申购赎回费和销售服务费</strong>，，这几种费用的详细解释可参考这篇文章
<a
href="https://zhuanlan.zhihu.com/p/68515750">购买基金，不可不知的费用</a>,
一些值得关注的点列在了下面</p>
<blockquote>
<p>管理费 国内指数基金的平均管理费率在 <strong>0.69%</strong>
左右。部分规模大，运行时间长的基金，管理费率会降低到 0.5%
以下;<strong>主动型基金的管理费率一般是 1.5%</strong></p>
<p>托管费 国内指数基金的托管费率平均在 <strong>0.14%</strong>
左右，低的可以做到0.1%。
所有的基金，不管是场内还是场外，都会有管理费和托管费</p>
<p>申购赎回费
申购赎回费是场外基金的概念，对应场内基金的是买卖佣金，也就是在每次交易需要给的手续费
申购赎回费是不同的，一般在 <strong>1%-1.5%</strong>;
同的渠道申购，费用在不相同。比如在银行申购，费用一般不打折，在<strong>基金公司官网，部分网络平台申购，一般会有一定程度的折扣，有的时候甚至会打一折</strong>。</p>
<p>销售服务费
免申购赎回的基金，通常会在基金后面加个字母C，被称为C类基金。这类基金不收取申购费用，但会收取固定比例的销售费用，一般是每年收取0.4%-0.6%。<strong>投资指数基金，一般是长期持有，在申购费一折下，交易成本可以控制在
0.1% 左右，所以我们一般不选择 C 类基金</strong></p>
</blockquote>
<p>按照上面的计算，每年基本上会付出去3%左右的费用，那么这 3%
的费用到底高不高，听着好像也没多少，我们可以做个计算</p>
<blockquote>
<p>假设你投资的这个基金平均每年回报是
10%，这个成绩已经相当不错了，但是由于你支付了各种五花八门的费用，最终你真正拿到的收益应该是7%左右。那么我们假设一开始投资了100块，按照10%的每年的回报，10年之后你的100块钱会变成259块钱，20年之后你的100块钱会变成673块钱，分别翻了接近3倍和7倍，
但是经过基金公司的雁过拔毛，按照 7%
计算你的100块会变成多少？10年之后是197，20年之后是387，这是什么概念？即如果按照投资10年计算，由于费用的存在，你的利润被别人拿走了40%，如果按照20年计算，你的利润被别人拿走了50%，高达一半之多。
换句话说仅仅因为这些看起来好像没有多少的费用，你辛辛苦苦攒钱投资了20年，最后一半的收益都奉献给基金公司和基金经理了，这听起来是不是实在有点荒谬，原因也很简单，就是我们最熟悉的复利的作用</p>
</blockquote>
<p>那对于投资者来说，具体要怎么做呢？课程里并没提及这一点，雪球上的这篇文章
<a
href="https://xueqiu.com/2915047920/170605141">购买基金时不可忽视的手续费，如何降低手续费，提高基金收益</a>给出了一些具体的方法论</p>
<ol type="1">
<li>通过<strong>基金公司官网或第三方平台购买可以有1折的优惠，会比银行渠道购买更便宜</strong>，购买时可以多对比几个渠道</li>
<li>股票型基金都会有交易费用，如果没有申购费，要留意销售服务费用</li>
<li>指数基金费用相对更低，<strong>跟踪同一指数的基金收益差异不大，所以购买时可以多对比下同类型指数基金的运作费用和交易费用，特别是长期定投下，费用低的可以省下不少钱</strong></li>
<li>主动型基金手续费最高，但优秀的基金经理长期是可以大幅跑赢指数的，所以购买主动基金时，主要避免因频繁交易导致交易费用的上升</li>
<li>最重要的一点一定要记住<strong>，不要频繁买卖基金，基金的交易成本高，短期交易成本更高</strong></li>
</ol>
<h2 id="自我局限">自我局限</h2>
<p>这里主要分析了个人的自身的局限性是怎样阻碍我们投资成功的，主要分讲了以下几个因素：过度自信、反向复利、利益错位、场外因素，且总结得出最终的投资五大原则。</p>
<h3 id="过度自信">过度自信</h3>
<p>这部分主要想说明<strong>在投资过程中，要区分清楚赚到的前依赖的是运气还是实力，避免过度自信</strong>。因为如果是市场原因或者偶发的事件赚到了钱，却把原因归结成了自己的能力，那么在未来等待着你的往往就是灾难。</p>
<p>比如说在市场大牛市的时候，人人买股票都赚钱，人人都觉得自己是股神，但等到熊市以来，所有之前自认为正确的投资逻辑都失效了，很多人都会把之前赚的钱成倍的亏回去。</p>
<p>那该怎么避免这种问题呢？课程里提供了两个参考方法：<strong>一个事前使用，一个事后使用</strong></p>
<p>（1）事前使用的方法是：<strong>在进行投资之前，把自己的投资逻辑记录下来，列出你的诉条理由以及背后的逻辑</strong>。等投资有了结果，可以相对容易的看出是不是因为当时的判断正确赚到钱的，这会让你更好的认知自己的投资能力。</p>
<p>而且不管赚钱还是亏钱，这个习惯都能让你不断完善自己的认知体系和投资框架。长期来看你赚钱的概率就会慢慢提高了。我们为什么说巴菲特是股神？因为他投资已经六七十年、穿越了无数个周期，做对了无数多正确的决策，我们才认可了他的地位。对待他人是这样，对待自己也要一样，不要因为一两次的成功就沾沾自喜。</p>
<p>（2）事后采用的方法是及时止损，这里的止损不是说只要账面亏钱了就要立刻卖出，那就变成了追涨杀跌的赌博游戏。</p>
<p>这里说的止损是交易大师爱德华索普的方法，他说：“<strong>在我写下我的交易逻辑之后，我会放入一点钱，看看市场会不会验证我的逻辑。一旦我发现市场的表现和我预想的不一样，我就会先止损离场，给自己时间冷静下来，把问题想清楚再重新回去</strong>。这样虽然有时候会让我错过一些好的投资，但也能保证我不会犯下致命的错误，无法收场。”</p>
<p>因此，这部分有以下2个结论值得重点关注</p>
<p>（1）在赚到钱的时候一定要思考一个问题：我为什么能赚到这笔钱呢？是因为自己的能力，还是只是因为运气？如果是运气的话，这一次投资决策的逻辑就不能作为下一次的参考。
（2）如何避免过度自信？课程里给了两个方法：一个事前方法是把自己的投资逻辑写下来，以便根据结果对比分析；还有一个事后方法是要及时止损，想清楚了再回到市场里，</p>
<h3 id="反向复利">反向复利</h3>
<p>这部分主要强调了一个常识，就是产品的收益与其风险是成正比的，而亏损会带来的一个很可怕的问题是负复利，也是这一部分的小标题“反向复利”，课程里举了如下例子</p>
<blockquote>
<p>假设你连续10年的投资收益是这样的，第一年赚20%，第二年亏15%，第三年赚20%，
第4年亏15%，第5年又赚20%，第6年再亏15%，以此类推下去。
那么这10年下来你总共的投资回报有多少？稍微计算一下就可以得出答案,
就是10.4%，
10年总的回报10.4%，每年连1%都不到。算上通货膨胀的影响，实际上你不但没有赚到钱，还白白损失了10年的宝贵时间</p>
</blockquote>
<p>那普通人还有必要参与这种高风险高收益的投资么？课程里的建议是普通人要有慢慢变富的心理，避免高风险带来上面说的反向复利的问题</p>
<p>而如果要投资这种高风险高收益的产品，课程里给了以下 2 点建议 (1)
如果你要做风险很高的投资，那么它带来的回报一定要足够高，潜在收益最好是几十倍几百倍甚至几千倍，否则是得不偿失的。
(2)
当我们去做高风险投资的时候，一定要做好亏损全部本金的准备。就是说如果这个钱完全损失掉，你也能接受的话，这就是一个相对比较好的心态。</p>
<p>因此，这部分有以下 3 个结论值得重点关注</p>
<ol type="1">
<li>我们应该接受一个事实，通过投资致富其实是一个相对漫长的过程，接受慢慢变富</li>
<li>负复利对我们的长期投资回报率会有很大的影响</li>
<li>如果你真的想去参与高风险高回报的投资项目，那么要记住两点，第一它带来的回报一定要足够高，第二你要做好亏损100%的准备。</li>
</ol>
<h3 id="利益错位">利益错位</h3>
<p>这部分主要强调了一些他人给出的投资建议未必值得参考，或者说<strong>不要简单根据对方的建议就直接采取行动。首先你要判断对方跟他的建议之间到底有什么利益关系，另外你还要考虑对方有没有出于感情等等其他因素有讨好你的可能。</strong></p>
<p>课程以华尔街的分析师不想得罪上市公司而给出卖出评级非常保守为例，说明了这种利益错位的现象，即给出的分析结论不一定是站在投资者角度去考虑的，因为这里面更实在的利益关系是分析师
与上市公司；当然，这里也不是说华尔街的分析师都是没有独立思考能力或者毫无职业品德的人，好的分析师还是很多的，但是由于这种非常独特的利益分配机制，我们在学习他们的观点，获取他们的建议的时候，就要格外的小心，</p>
<p>除了上面这些与钱挂钩的利益错位的问题，很多时候甚至别人只是出于关心，也会给你带来麻烦。比如说作为投资你买了个房子，但是由于市场前景不明，你在考虑是不是要卖出，你和一个懂一点买房投资的朋友聊起了天，你问他说我这个房子买的对吗？现在是不是该卖掉了呢？这个时候你的朋友就成了给你建议的人，而他很有可能出于对你的关心，想安抚你焦虑的情绪。所以分析了一通之后说，我觉得房价之后肯定能涨回去，还是不要卖了。</p>
<p>这些例子不是为了说明不要听取对方的意见，而是为了说明开头的观点：<strong>听取建议时需要从利益层面去考虑建议的适用性，同时要保持独立思考的能力，因为最了解自己的人只有自己</strong>。</p>
<h3 id="场外因素">场外因素</h3>
<p>这部分主要强调了决定我们投资结果成败的，有时候是专业知识和技能之外的一些东西,
即标题说的场外因素。</p>
<p>课程以大空头电影里的<a
href="https://www.zhihu.com/question/41271612">迈克尔巴里</a>为例说明这个观点，大意就是虽然他的投资方向是对的，但是受到了投资者的不解和给的压力，最终虽然在
08
年的次贷危机一战封神，但最后的结果也是遭到撤资，最终关掉所管理的基金。</p>
<p>对普通投资者而言，在做投资的时候也经常要面对别人的质疑和挑战，甚至很多时候他人其实是善意的关心，比如你的老公、老婆、父母、朋友，总会念叨一下你的投资到底是赔是赚，总会拿你的成绩和别人比一比，这个时候能够管理他们的预期，能够让他们很好的理解你长期的投资计划就非常重要了。</p>
<p>在这一点上，同样在次贷危机中狂赚一笔的约翰保尔森就比迈克尔巴里做的好得多。当时在和投资人沟通的时候，他没有渲染自己是在赌博，美国房地产崩盘，而是说自己的基金针对潜在的远期灾难进行了一种对冲，</p>
<p>因此，课程里强调的场外因素有两个</p>
<p>(1)第一个场外因素是：<strong>投资本来就是一件需要独立思考，很多时候非常孤独的事情</strong>，所以能够维护好你能独立决策的环境，对我们的长期成功的确是非常重要的。上面强调的就是这一点
(2)第二个因素是：要<strong>保持你场外赚钱的能力，也就是投资之外的收入</strong>，因为它能反过来帮助你的投资成绩。想象一下，如果你的职业相当成功，工资水平不错，那么即使市场下跌，你的压力也不会特别大，甚至你还可以拿钱来补仓。反过来说，如果你只靠投资赚钱，遇到熊市你可能会非常煎熬，甚至会被迫卖出你的投资，把亏损做实。课程里将这点总结成了这么一句话：<strong>越不需要靠投资赚钱的人，越有可能靠投资赚到钱</strong>。</p>
<h3 id="五大原则">五大原则</h3>
<p>这部分更多是对前面内容的一个总结，即投资的五大原则：<strong>多元分散，被动为主，降低成本，保持恒心，不懂不做</strong></p>
<ol type="1">
<li><p>多元分散:
我们很难预测未来一段时间哪些国家、哪类资产会涨得最好，可以做的就是让自己的投资组合尽量分散，覆盖各个投资市场和各个投资品类，保证足够的多元分散。</p></li>
<li><p>被动为主:
任何人哪怕是专业人士想要长期的打败市场都是很难的，尤其是当你发现一个好的基金经理的时候，很可能他的业绩已经开始走下坡路了，所以与其把钱交给他们，或者听信所谓专业人士的推荐，不如通过投资市场指数来获得平均的回报，长期看是更好的选择。</p></li>
<li><p>降低成本:
在投资中对收益率影响巨大，而且也最容易把握的就是投资的费用和成本，哪怕我们每年只省一点点，累积起来对我们投资的回报都有很大的加成。所以在执行和操作的时候，我们要尽量降低成本，</p></li>
<li><p>保持恒心:
任何人都难以预测短期的市场走向和运动规律，想靠预测市场迅速赚到大钱是不可能的，我们应该长线思考，保持恒心。</p></li>
<li><p>不懂不做:
投资市场非常复杂，里面绝大部分的东西我们都没有能力弄懂，所以最终我们做投资的底线应该是不投资自己不懂的东西。</p></li>
</ol>
<h2 id="小结">小结</h2>
<p>这部分内容小结如下</p>
<p><strong>1.指数基金</strong></p>
<ul>
<li>个股涨跌难以预测，投资基金会是更好的选择</li>
<li>一直被推崇的指数基金比较适合美国市场，但是不一定适合牛短熊长的 a
股</li>
</ul>
<p><strong>2.安全边际</strong></p>
<ul>
<li>好公司不等于好股票，买入价格的高低会严重影响投资收益</li>
<li>要给交易留出足够的安全边际，比如当一个东西的价格跌到了估值的 60%
的时候才买入</li>
<li>这里的估值做点估计比较难，更合理的是做区间估计</li>
<li>安全边际在实操中会有一定局限性</li>
</ul>
<p><strong>3.抄底哲学与专业光环</strong></p>
<ul>
<li>不要盲目抄底，即使是抄底，也尽量要去抄市场的底，而不是个股的底</li>
<li>不盲信专业人士的分析</li>
</ul>
<p><strong>4.交易成本</strong></p>
<ul>
<li>交易成本是影响最终收益的一个重要因素；常见的基金会收取管理费、托管费，交易费等</li>
<li>购买时选择费用低的渠道</li>
<li>对于追踪相同指数被动型基金，收益差别不大，优先选择费用低</li>
<li>不收交易费用时注意是否有销售管理费</li>
<li>降低交易频率</li>
</ul>
<p><strong>5.自我局限</strong></p>
<ul>
<li>过度自信：明确赚钱靠的是运气还是实力，如果是运气需要注意；避免过度自信的方法论有两个，可分为事前方法和事后方法</li>
<li>反向复利：避免高风险带来亏损而导致的反向复利，如果确实要做高风险投资要明确回报要可观</li>
<li>利益错位：听取别人意见时需要考虑他人所站的立场，以及与各方的利益关系</li>
<li>场外因素：投资是一个独立的过程，尽量减少受到外界影响；保持你场外赚钱的能力，越不需要靠投资赚钱的人，越有可能靠投资赚到钱</li>
<li>五大原则：多元分散，被动为主，降低成本，保持恒心，不懂不做</li>
</ul>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习笔记(1)-概述</title>
    <url>/2018/05/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(1)-%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>本文主要介绍强化学习的一些基本概念：包括MDP、Bellman方程等,
并且讲述了如何从 MDP 过渡到 Reinforcement Learning。</p>
<span id="more"></span>
<h2 id="强化学习的任务">强化学习的任务</h2>
<p>这里还是放上 <a
href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html">David
Silver的课程</a>
的图，可以很清楚的看到整个交互过程。这就是人与环境交互的一种模型化表示，在每个时间点，大脑
agent 会从可以选择的动作集合A中选择一个动作 <span
class="math inline">\(a_t\)</span> 执行。环境则根据 agent 的动作给 agent
反馈一个 reward <span class="math inline">\(r_t\)</span>，同时 agent
进入一个新的状态。</p>
<figure>
<img src="https://wulc.me/imgs/image_1ccqng08l1lvo11kge3157hfgj9.png"
alt="RL" />
<figcaption aria-hidden="true">RL</figcaption>
</figure>
<p>知道了整个过程，任务的目标就出来了，那就是要能获取尽可能多的Reward。Reward越多，就表示执行得越好。每个时间片，agent
根据当前的状态来确定下一步的动作。也就是说我们需要一个state找出一个action，使得
reward 最大，从 state 到 action 的过程就称之为一个策略Policy，一般用
<span class="math inline">\(\pi\)</span> 表示:</p>
<p><strong>强化学习的任务就是找到一个最优的策略Policy从而使Reward最多。</strong></p>
<p>我们一开始并不知道最优的策略是什么，因此往往从随机的策略开始，使用随机的策略进行试验，就可以得到一系列的状态,动作和反馈：</p>
<p><span
class="math inline">\((s\_1,a\_1,r\_1,s\_2,a\_2,r\_2,...s\_t,a\_t,r\_t)\)</span></p>
<p>这就是一系列的样本Sample。<strong>强化学习的算法就是需要根据这些样本来改进Policy，从而使得得到的样本中的Reward更好</strong>。由于这种让Reward越来越好的特性，所以这种算法就叫做强化学习Reinforcement
Learning。</p>
<h2 id="mdpmarkov-decision-process">MDP（Markov Decision Process）</h2>
<p>强化学习的问题都可以模型化为<a
href="https://en.wikipedia.org/wiki/Markov_decision_process">MDP</a>(马尔可夫决策过程)的问题，MDP
实际上是对环境的建模；MDP 与常见的 Markov chains 的区别是加入了action 和
rewards 的概念。</p>
<p>因此，一个基本的 MDP 可以用一个五元组 <span
class="math inline">\((S,A,P,R, \gamma)\)</span> 表示，其中</p>
<ol type="1">
<li><span class="math inline">\(S\)</span> 是一个有限状态集</li>
<li><span class="math inline">\(A\)</span> 是一个有限动作集</li>
<li><span class="math inline">\(P\)</span> 是一个状态转移概率矩阵，<span
class="math inline">\(P\_a(s, s′)=P(s\_{t+1}=s′|s\_t=s, a\_t=a)\)</span>
表示在状态 <span class="math inline">\(s\)</span> 下执行动作 <span
class="math inline">\(a\)</span> 后转移到状态 <span
class="math inline">\(s′\)</span> 的概率</li>
<li><span class="math inline">\(R\)</span> 是一个奖励函数，<span
class="math inline">\(R\_a(s, s′)\)</span> 表示在状态 <span
class="math inline">\(s\)</span> 下执行动作 <span
class="math inline">\(a\)</span> 后转移到状态 <span
class="math inline">\(s′\)</span> 所得到的即时回报(reward)</li>
<li><span class="math inline">\(\gamma\)</span>
是一个折扣因子,一般取值在 [0,1];
用来区分当前回报和未来回报的重要性，一般会加在未来的回报前，减小未来回报的权重。</li>
</ol>
<p>因此，<strong>MDP 的核心问题就是找到一个策略 <span
class="math inline">\(\pi(s)\)</span> 来决定在状态 <span
class="math inline">\(s\)</span>
下选择哪个动作</strong>，这种情况下MDP就变成了一个 Markov
chain，且此时的目标跟我们前面提到的强化学习的目标是一致的。</p>
<h2 id="回报与价值函数">回报与价值函数</h2>
<p>状态的好坏等价于对未来回报的期望。因此，引入<strong>回报(Return)</strong>
来表示某个时刻t的状态将具备的回报：</p>
<p><span class="math inline">\(G\_t = R\_{t+1} + \gamma R\_{t+2} + ... =
\sum\_{k=0}^\infty\gamma^kR\_{t+k+1}\)</span></p>
<p>上面 <span class="math inline">\(R\)</span> 是 Reward 反馈，<span
class="math inline">\(\gamma\)</span> 是 discount
factor（折扣因子）,跟前面 MDP 中的符号的含义一致。</p>
<p>从上面的式子可以， <strong>除非整个过程结束，否则我们无法获取所有的
reward 来计算出每个状态的
Return</strong>，因此，再引入一个概念:<strong>价值函数(value
function)</strong>,记为 <span class="math inline">\(V(s)\)</span>，通过
<span class="math inline">\(V(s)\)</span>
来表示一个状态未来的潜在价值。从定义上看，value function
就是<strong>回报的期望</strong>：</p>
<p><span class="math inline">\(V(s) = \mathbb E[G\_t|S\_t =
s]\)</span></p>
<p><strong>引出价值函数，对于获取最优的策略Policy这个目标，我们就会有两种方法</strong>：</p>
<ol type="1">
<li><strong>直接优化策略</strong> <span
class="math inline">\(\pi(a|s)\)</span> 或者 <span
class="math inline">\(a = \pi(s)\)</span> 使得回报更高</li>
<li>通过<strong>估计 value function
来间接获得优化的策略</strong>。道理很简单，通过价值函数可以知道每一种状态的好坏，这样我们就知道该怎么选择了（如选择动作使得下一状态的潜在价值最大），而这种选择就是我们想要的策略。</li>
</ol>
<h2 id="bellman方程">Bellman方程</h2>
<p>采用上面获取最优策略的第 2 种方法时，我们需要估算 Value
Function，只要能够计算出价值函数，那么最优决策也就得到了。因此，问题就变成了<strong>如何计算Value
Function</strong>？</p>
<p>根据前面 <span class="math inline">\(G\_t\)</span> 和 <span
class="math inline">\(V(s)\)</span> 的定义，有</p>
<p><span class="math display">\[
\begin{align}
V(s) &amp; = \mathbb E[G\_t|S\_t = s]\\\
    &amp; = \mathbb E[R\_{t+1}+\gamma R\_{t+2} + \gamma ^2R\_{t+3} +
...|S\_t = s]\\\
    &amp; = \mathbb E[R\_{t+1}+\gamma (R\_{t+2} + \gamma R\_{t+3} +
...)|S\_t = s]\\\
    &amp; = \mathbb E[R\_{t+1}+\gamma G\_{t+1}|S\_t = s]\\\
    &amp; = \mathbb E[R\_{t+1}+\gamma v(S\_{t+1})|S\_t = s]
\end{align}
\]</span></p>
<p>则有</p>
<p><span class="math display">\[V(s) = \mathbb E[R\_{t+1} + \gamma
V(S\_{t+1})|S\_t = s]\]</span></p>
<p>上面这个公式就是Bellman方程的基本形态。从公式上看，当前状态的价值和下一步的价值以及当前的反馈Reward有关,
其中透出的含义就是<strong>价值函数的计算可以通过迭代的方式来实现</strong>。</p>
<h2 id="从-mdp-到-reinforcement-learning">从 MDP 到 Reinforcement
Learning</h2>
<p>回到 MDP 问题，如果我们知道了转移概率 <span
class="math inline">\(P\)</span> 和奖励函数 <span
class="math inline">\(R\)</span>，那么便可通过下面的方法求出最优策略
<span class="math inline">\(\pi(s)\)</span>,
首先，结合上面提到的价值函数和Bellman方程有</p>
<p>公式1：</p>
<p><span class="math display">\[\pi(s):=\arg \max\_a\
\{\sum\_{s&#39;}P\_{a}(s,s&#39;)(R\_{a}(s,s&#39;)+\gamma
V(s&#39;))\}\]</span></p>
<p>公式2:</p>
<p><span class="math display">\[ V(s) :=
\sum\_{s&#39;}P\_{\pi(s)}(s,s&#39;)(R\_{\pi(s)}(s,s&#39;) + \gamma
V(s&#39;)) \]</span></p>
<p>公式 1 表示在状态 <span class="math inline">\(s\)</span>
下的采取的最优动作，公式 2 表示在状态 <span
class="math inline">\(s\)</span> 下的价值，可以看到两者有依存关系</p>
<p>而在 转移概率 <span class="math inline">\(P\)</span> 和奖励函数 <span
class="math inline">\(R\)</span>已知的情况下，求解 MDP 问题常见做法有
<strong>Value iteration</strong> 或 <strong>Policy
iteration</strong></p>
<h3 id="value-iteration">Value iteration</h3>
<p>在 Value iteration 中，策略函数 <span
class="math inline">\(\pi\)</span> 没有被使用，迭代公式如下：</p>
<p><span class="math display">\[V\_{i+1}(s) := \max\_a \sum\_{s&#39;}
P\_a(s,s&#39;)(R\_a(s,s&#39;) + \gamma V\_i(s&#39;))\]</span></p>
<p>下标 <span class="math inline">\(i\)</span> 表示第 <span
class="math inline">\(i\)</span>
次迭代，在每轮迭代中需要计算每个状态的价值，并且直到两次迭代结果的差值小于给定的阈值才能认为是收敛。</p>
<p>计算的出收敛的价值函数后，通过公式1就能够得出策略函数 <span
class="math inline">\(\pi\)</span> 了，其迭代过程如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1cctfljjh1bv918u91j9g1fgs1ln89.png"
alt="Value Iteration" />
<figcaption aria-hidden="true">Value Iteration</figcaption>
</figure>
<h3 id="policy-iteration">Policy iteration</h3>
<p>Policy iteration同时更新价值 <span class="math inline">\(V\)</span>
和策略 <span class="math inline">\(\pi\)</span>, 且一般可分成两步：</p>
<ol type="1">
<li>Policy
Evaluation，策略评估，就是上面公式2的过程。目的是在策略固定的情况下更新Value
Function 直到 value
收敛，从另一个角度来讲就是为了更好地<strong>估计基于当前策略的价值</strong></li>
<li>Policy Improvement，策略改进，就是上面公式1的过程。就是根据更新后的
Value Function 来更新每个状态下的策略直到策略稳定</li>
</ol>
<p>这个方法本质上就是使用当前策略(<span
class="math inline">\(\pi\)</span>)产生新的样本，然后使用新的样本更好的估计策略的价值(<span
class="math inline">\(V(s)\)</span>)，然后利用策略的价值更新策略，然后不断反复。理论可以证明最终策略将收敛到最优</p>
<p>具体的算法流程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1cctgird1rv11gljv1f72esim.png"
alt="Policy Iteration" />
<figcaption aria-hidden="true">Policy Iteration</figcaption>
</figure>
<h3 id="区别与局限">区别与局限</h3>
<p>问题来了，上面的 Policy Iteration 和 Value Iteration有什么区别,
为什么一个叫policy iteration，一个叫value iteration？</p>
<p>原因其实很好理解，policy iteration 最后收敛的 value <span
class="math inline">\(V\)</span> 是当前 policy 下的 value
值（也做对policy进行评估），目的是为了后面的policy
improvement得到新的policy；所以是在<strong>显式地不停迭代
policy</strong>。</p>
<p>而value iteration 最后收敛得到的 value
是当前state状态下的最优的value值。当 value
最后收敛，那么最优的policy也就得到的。虽然这个过程中 policy
在也在隐式地更新，但是<strong>一直在显式更新的是 value</strong>
的，所以叫value iteration。</p>
<p>从上面的分析看，value iteration 较 之policy
iteration更直接。不过问题也都是一样，都需要知道转移概率 <span
class="math inline">\(P\)</span> 和奖励函数 <span
class="math inline">\(R\)</span>。</p>
<p>但是<strong>对于 Reinforcement Learning 这一类问题，转移概率 <span
class="math inline">\(P\)</span> 往往是不知道</strong>，知道转移概率
<span class="math inline">\(P\)</span> 也就称为获得了模型
Model，这种通过模型来获取最优动作的方法也就称为
<strong>Model-based</strong>
的方法。但是现实情况下，很多问题是很难得到准确的模型的，因此就有
<strong>Model-free</strong> 的方法来寻找最优的动作，像
Q-learning，Policy Gradient，Actor Critic这一类方法都是 model-free
的。</p>
<p><strong>前面的方法问题是需要已知转移概率 <span
class="math inline">\(P\)</span>,
目的是为了遍历当前状态后的所有可能的状态，因此如果采用贪婪的思想，那么就不需要不遍历后面所有的状态，而是直接采取价值最大的状态动作来执行。</strong></p>
<p>Q-learning 实际上就是采用这种思想的，Q-Learning的基本思想是根据 value
iteration 得到的，但要明确一点是 value iteration
每次都对所有的Q值更新一遍，也就是所有的状态和动作。但事实上在实际情况下我们没办法遍历所有的状态，还有所有的动作，因此，我们只能得到有限的系列样本。具体的算法流程会再下一篇文章具体介绍。</p>
<p>综上，本文主要介绍了强化学习的任务和一些概念，以及从 MDP 如何过渡到
Reinforcement，在后续的文章中会陆续介绍Q-learning 类方法，Policy
gradient 类方法以及结合两者的 Actor Critic 方法。</p>
<hr />
<p>参考资料</p>
<ol type="1">
<li><a
href="https://en.wikipedia.org/wiki/Markov_decision_process">Markov
decision process</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/21378532?refer=intelligentunit">DQN
从入门到放弃4 动态规划与Q-Learning</a></li>
<li><a
href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-02-RL-methods/">强化学习方法汇总</a></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习笔记(2)-从 Q-Learning 到 DQN</title>
    <url>/2018/05/09/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(2)-%E4%BB%8E%20Q-Learning%20%E5%88%B0%20DQN/</url>
    <content><![CDATA[<p>在上一篇文章<a
href="http://wulc.me/2018/05/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%281%29-%E6%A6%82%E8%BF%B0/">强化学习笔记(1)-概述</a>中，介绍了通过
MDP 对强化学习的问题进行建模，但是由于强化学习往往不能获取 MDP
中的转移概率，解决 MDP 的 value iteration 和 policy iteration
不能直接应用到解决强化学习的问题上，因此出现了一些近似的算法来解决这个问题，本文要介绍的就是基于
value iteration 而发展出来的 Q-Learning 系列方法，包括 Q-Learning、Sarsa
和 DQN。</p>
<span id="more"></span>
<h2 id="q-learning">Q-Learning</h2>
<p>Q-Learning
是一个强化学习中一个很经典的算法，其出发点很简单，就是用一张表存储在各个状态下执行各种动作能够带来的
reward，如下表表示了有两个状态 <span class="math inline">\(s\_1,
s\_2\)</span>，每个状态下有两个动作 <span class="math inline">\(a\_1,
a\_2\)</span>, 表格里面的值表示 reward</p>
<table>
<thead>
<tr class="header">
<th>-</th>
<th>a1</th>
<th>a2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>s1</td>
<td>-1</td>
<td>2</td>
</tr>
<tr class="even">
<td>s2</td>
<td>-5</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>这个表示实际上就叫做 Q-Table，里面的每个值定义为 <span
class="math inline">\(Q(s, a)\)</span>, 表示在状态 <span
class="math inline">\(s\)</span> 下执行动作 <span
class="math inline">\(a\)</span>
所获取的reward，那么选择的时候可以采用一个贪婪的做法，即选择价值最大的那个动作去执行。</p>
<p>这样问题就来了，就是 Q-Table
要如何获取？答案是随机初始化，然后通过不断执行动作获取环境的反馈并通过算法更新
Q-Table。下面重点讲如何通过算法更新 Q-Table。</p>
<p><strong>当我们处于某个状态 <span class="math inline">\(s\)</span>
时，根据 Q-Table 的值选择的动作 <span class="math inline">\(a\)</span>,
那么从表格获取的 reward 为 <span
class="math inline">\(Q(s,a)\)</span>，此时的 reward
并不是我们真正的获取的 reward，而是预期获取的 reward，那么真正的 reward
在哪？我们知道执行了动作 <span class="math inline">\(a\)</span>
并转移到了下一个状态 <span class="math inline">\(s&#39;\)</span>
时，能够获取一个即时的 reward（记为<span
class="math inline">\(r\)</span>）, 但是除了即时的
reward，还要考虑所转移到的状态 <span
class="math inline">\(s&#39;\)</span> 对未来期望的reward，因此真实的
reward (记为 <span
class="math inline">\(Q&#39;(s,a)\)</span>)由两部分组成：即时的 reward
和未来期望的 reward，且未来的 reward
往往是不确定的，因此需要加个折扣因子 <span
class="math inline">\(\gamma\)</span>,则真实的 reward
表示如下</strong></p>
<p><span class="math display">\[Q&#39;(s,a) = r +
\gamma\max\_{a&#39;}Q(s&#39;,a&#39;)\]</span></p>
<p><span class="math inline">\(\gamma\)</span> 的值一般设置为 0 到 1
之间，设为0时表示只关心即时回报，设为 1
时表示未来的期望回报跟即时回报一样重要。</p>
<p>有了真实的 reward 和预期获取的 reward，可以很自然地想到用 supervised
learning那一套，求两者的误差然后进行更新，在 Q-learning
中也是这么干的，更新的值则是原来的 Q(s, a)，更新规则如下</p>
<p><span class="math display">\[Q(s, a) = Q(s, a) + \alpha(Q&#39;(s, a)
- Q(s,a))\]</span></p>
<p>更新规则跟梯度下降非常相似，这里的 <span
class="math inline">\(\alpha\)</span> 可理解为学习率。</p>
<p>更新规则也很简单，可是这一类采用了贪心思想的算法往往都会有这么一个问题：算法是否能够收敛，是收敛到局部最优还是全局最优？</p>
<p>关于收敛性，可以参考 <a
href="http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf">Convergence
of Q-learning: a simple proof</a>，这个文档
证明了这个算法能够收敛，且根据知乎上这个问题 <a
href="https://www.zhihu.com/question/49787932">RL两大类算法的本质区别？（Policy
Gradient 和 Q-Learning)</a>，原始的 Q-Learning
理论上能够收敛到最优解，但是通过 Q 函数近似 Q-Table
的方法则未必能够收敛到最优解（如DQN）。</p>
<p>除此之外， Q-Learning 中还存在着探索与利用(Exploration and
Exploition)的问题,
大致的意思就是不要每次都遵循着当前看起来是最好的方案，而是会选择一些当前看起来不是最优的策略，这样也许会更快探索出更优的策略。</p>
<p>Exploration and Exploition 的做法很多，Q-Learning 采用了最简单的
<span class="math inline">\(\epsilon\)</span>-greedy, 就是每次有 <span
class="math inline">\(\epsilon\)</span> 的概率是选择当前 Q-Table
里面值最大的action的，1 - <span class="math inline">\(\epsilon\)</span>
的概率是随机选择策略的。</p>
<p>Q-Learning 算法的流程如下，图片摘自<a
href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-03-q-learning/">这里</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1cd24g4og10s14pd133n3cvunnm.png"
alt="Q-Learning" />
<figcaption aria-hidden="true">Q-Learning</figcaption>
</figure>
<p>上面的流程中的 Q 现实 就是上面说的 <span
class="math inline">\(Q&#39;(s,a)\)</span>, Q 估计就是上面说的 <span
class="math inline">\(Q(s,a)\)</span>。</p>
<p>下面的 python 代码演示了更新通过 Q-Table 的算法, 参考了这个 <a
href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow">repo</a>
上的代码，初始化主要是设定一些参数，并建立 Q-Table,
<code>choose_action</code> 是根据当前的状态
<code>observation</code>，并以 <span
class="math inline">\(\epsilon\)</span>-greedy 的策略选择当前的动作；
<code>learn</code> 则是更新当前的
Q-Table，<code>check_state_exist</code> 则是检查当前的状态是否已经存在
Q-Table 中，若不存在要在 Q-Table 中创建相应的行。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">QTable</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, actions, learning_rate=<span class="number">0.01</span>, reward_decay=<span class="number">0.9</span>, e_greedy=<span class="number">0.9</span></span>):</span><br><span class="line">        self.actions = actions  <span class="comment"># a list</span></span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        self.gamma = reward_decay</span><br><span class="line">        self.epsilon = e_greedy</span><br><span class="line">        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, observation</span>):</span><br><span class="line">        self.check_state_exist(observation)</span><br><span class="line">        <span class="comment"># action selection</span></span><br><span class="line">        <span class="keyword">if</span> np.random.uniform() &lt; self.epsilon:</span><br><span class="line">            <span class="comment"># choose best action</span></span><br><span class="line">            state_action = self.q_table.ix[observation, :]</span><br><span class="line">            state_action = state_action.reindex(np.random.permutation(state_action.index))     <span class="comment"># some actions have same value</span></span><br><span class="line">            action = state_action.argmax()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># choose random action</span></span><br><span class="line">            action = np.random.choice(self.actions)</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, s, a, r, s_</span>):</span><br><span class="line">        self.check_state_exist(s_)</span><br><span class="line">        q_predict = self.q_table.ix[s, a]</span><br><span class="line">        <span class="keyword">if</span> s_ != <span class="string">&#x27;terminal&#x27;</span>:</span><br><span class="line">            q_target = r + self.gamma * self.q_table.ix[s_, :].<span class="built_in">max</span>()  <span class="comment"># next state is not terminal</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            q_target = r  <span class="comment"># next state is terminal</span></span><br><span class="line">        self.q_table.ix[s, a] += self.lr * (q_target - q_predict)  <span class="comment"># update</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_state_exist</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="keyword">if</span> state <span class="keyword">not</span> <span class="keyword">in</span> self.q_table.index:</span><br><span class="line">            <span class="comment"># append new state to q table</span></span><br><span class="line">            self.q_table = self.q_table.append(</span><br><span class="line">                pd.Series(</span><br><span class="line">                    [<span class="number">0</span>]*<span class="built_in">len</span>(self.actions),</span><br><span class="line">                    index=self.q_table.columns,</span><br><span class="line">                    name=state,</span><br><span class="line">                )</span><br><span class="line">            )</span><br></pre></td></tr></table></figure>
<h2 id="sarsa">Sarsa</h2>
<p>Sarsa 跟 Q-Learning 非常相似，也是基于 Q-Table
进行决策的。不同点在于<strong>决定下一状态所执行的动作的策略</strong>，Q-Learning
在当前状态更新 Q-Table
时会用到下一状态Q值最大的那个动作，但是下一状态未必就会选择那个动作；但是
Sarsa
会在当前状态先决定下一状态要执行的动作，并且用下一状态要执行的动作的 Q
值来更新当前状态的 Q
值；说的好像很绕，但是看一下下面的流程便可知道这两者的具体差异了，图片摘自<a
href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-04-sarsa/">这里</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1cd24f88k2ae10911ipacg01cv49.png"
alt="Q-Learning vs Sarsa" />
<figcaption aria-hidden="true">Q-Learning vs Sarsa</figcaption>
</figure>
<p>那么，这两者的区别在哪里呢？<a
href="https://studywolf.wordpress.com/2013/07/01/reinforcement-learning-sarsa-vs-q-learning/">这篇文章</a>里面是这样讲的</p>
<blockquote>
<p>This means that SARSA takes into account the control policy by which
the agent is moving, and incorporates that into its update of action
values, where Q-learning simply assumes that an optimal policy is being
followed.</p>
</blockquote>
<p>简单来说就是 Sarsa 在执行action时会考虑到全局（如更新当前的 Q
值时会先确定下一步要走的动作）， 而 Q-Learning 则显得更加的贪婪和"短视",
每次都会选择当前利益最大的动作(不考虑 <span
class="math inline">\(\epsilon\)</span>-greedy)，而不考虑其他状态。</p>
<p>那么该如何选择，根据这个问题：<a
href="https://stats.stackexchange.com/questions/326788/when-to-choose-sarsa-vs-q-learning">When
to choose SARSA vs. Q Learning</a>，有如下结论</p>
<blockquote>
<p>If your goal is to train an optimal agent in simulation, or in a
low-cost and fast-iterating environment, then Q-learning is a good
choice, due to the first point (learning optimal policy directly). If
your agent learns online, and you care about rewards gained whilst
learning, then SARSA may be a better choice.</p>
</blockquote>
<p>简单来说就是如果要在线学习，同时兼顾 reward
和总体的策略(如不能太激进，agent 不能很快挂掉)，那么选择
Sarsa；而如果没有在线的需求的话，可以通过 Q-Learning 线下模拟找到最好的
agent。所以也称 Sarsa 为on-policy，Q-Leanring 为 off-policy。</p>
<h2 id="dqn">DQN</h2>
<p>我们前面提到的两种方法都以依赖于
Q-Table，但是其中存在的一个问题就是当 Q-Table
中的状态比较多，可能会导致整个 Q-Table 无法装下内存。因此，DQN
被提了出来，DQN 全称是 Deep Q Network，Deep
指的是通的是深度学习，其实就是通过神经网络来拟合整张 Q-Table。</p>
<p>DQN
能够解决状态无限，动作有限的问题；具体来说就是将当前状态作为输入，输出的是各个动作的
Q 值。以 Flappy Bird 这个游戏为例，输入的状态近乎是无限的（当前 bird
的位置和周围的水管的分布位置等），但是输出的动作只有两个(飞或者不飞)。实际上，已经有人通过
DQN 来玩这个游戏了，具体可参考这个 <a
href="https://github.com/yenchenlin/DeepLearningFlappyBird">DeepLearningFlappyBird</a></p>
<p>所以在 DQN 中的核心问题在于如何训练整个神经网络，其实训练算法跟
Q-Learning 的训练算法非常相似，需要利用 Q 估计和 Q
现实的差值，然后进行反向传播。</p>
<p>这里放上提出 DQN 的原始论文 <a
href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf">Playing atari with
deep reinforcement learning</a> 中的算法流程图</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd2kiaol19ft2kb1dr4ricnorm.png"
alt="DQN" />
<figcaption aria-hidden="true">DQN</figcaption>
</figure>
<p>上面的算法跟 Q-Learning 最大的不同就是多了 <strong>Experience
Replay</strong>
这个部分，实际上这个机制做的事情就是先进行反复的实验，并将这些实验步骤获取的
sample 存储在 memory 中，每一步就是一个
sample，每个sample是一个四元组，包括：当前的状态，当前状态的各种action的
Q
值，当前采取的action获得的即时回报，下一个状态的各种action的Q值。拿到这样一个
sample 后，就可以根据上面提到的 Q-Learning
更新算法来更新网络，只是这时候需要进行的是反向传播。</p>
<p><strong>Experience Replay
机制的出发点是按照时间顺序所构造的样本之间是有关的(如上面的 <span
class="math inline">\(\phi(s\_{t+1})\)</span> 会受到 <span
class="math inline">\(\phi(s\_{t})\)</span> 的影响)、非静态的（highly
correlated and
non-stationary），这样会很容易导致训练的结果难以收敛。通过 Experience
Replay
机制对存储下来的样本进行随机采样，在一定程度上能够去除这种相关性，进而更容易收敛。</strong>当然，这种方法也有弊端，就是训练的时候是
offline 的形式，无法做到 online 的形式。</p>
<p>除此之外，上面算法流程图中的 aciton-value function
就是一个深度神经网络，因为神经网络是被证明有万有逼近的能力的，也就是能够拟合任意一个函数；一个
episode 相当于 一个 epoch；同时也采用了 <span
class="math inline">\(\epsilon\)</span>-greedy 策略。代码实现可参考上面
FlappyBird 的 DQN 实现。</p>
<p>上面提到的 DQN 是最原始的的网络，后面Deepmind
对其进行了多种改进，比如说 Nature DQN 增加了一种新机制 <strong>separate
Target Network</strong>，就是计算上图的<span
class="math inline">\(y\_j\)</span> 的时候不采用网络 <span
class="math inline">\(Q\)</span>, 而是采用另外一个网络(也就是 Target
Network) <span class="math inline">\(Q&#39;\)</span>, 原因是上面计算
<span class="math inline">\(y\_j\)</span> 和 Q 估计都采用相同的网络
<span
class="math inline">\(Q\)</span>，这样<strong>使得Q大的样本，y也会大，这样模型震荡和发散可能性变大</strong>，其原因其实还是两者的关联性较大。而采用另外一个独立的网络使得训练震荡发散可能性降低，更加稳定。一般
<span class="math inline">\(Q&#39;\)</span> 会直接采用旧的 <span
class="math inline">\(Q\)</span>, 比如说 10 个 epoch 前的 <span
class="math inline">\(Q\)</span>.</p>
<p>除此之外，大幅度提升 DQN 玩 Atari 性能的主要就是 Double
DQN，Prioritised Replay 还有 Dueling Network
三大方法；这里不详细展开，有兴趣可参考这两篇文章：<a
href="https://zhuanlan.zhihu.com/p/21547911">DQN从入门到放弃6
DQN的各种改进</a> 和 <a
href="https://zhuanlan.zhihu.com/p/25239682">深度强化学习（Deep
Reinforcement Learning）入门：RL base &amp; DQN-DDPG-A3C
introduction</a>。</p>
<p>综上，本文介绍了强化学习中基于 value 的方法：包括 Q-Learning 以及跟
Q-Learning 非常相似的 Sarsa，同时介绍了通过 DQN 解决状态无限导致
Q-Table过大的问题。需要注意的是 DQN
只能解决动作有限的问题，对于动作无限或者说动作取值为连续值的情况，需要依赖于
policy gradient
这一类算法，而这一类算法也是目前更为推崇的算法，在下一章将介绍 Policy
Gradient 以及结合 Policy Gradient 和 Q-Learning 的 Actor-Critic
方法。</p>
<hr />
<p>参考</p>
<ol type="1">
<li><a
href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-03-q-learning/">Q
Learning</a></li>
<li><a
href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-04-sarsa/">Sarsa</a></li>
<li><a
href="https://stats.stackexchange.com/questions/326788/when-to-choose-sarsa-vs-q-learning">When
to choose SARSA vs. Q Learning</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/21421729">DQN从入门到放弃5
深度解读DQN算法</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/25239682">深度强化学习（Deep
Reinforcement Learning）入门：RL base &amp; DQN-DDPG-A3C
introduction</a></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习笔记(3)- 从 Policy Gradient 到 A3C</title>
    <url>/2018/05/11/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(3)-%20%E4%BB%8E%20Policy%20Gradient%20%E5%88%B0%20A3C/</url>
    <content><![CDATA[<p>在之前的文章 <a
href="http://wulc.me/2018/05/09/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%282%29-%E4%BB%8E%20Q-Learning%20%E5%88%B0%20DQN/">强化学习笔记(2)-从
Q-Learning</a> 到 DQN 中，我们已经知道 Q-Learning 系列方法是基于 value
的方法，
也就是通过计算每一个状态动作的价值，然后选择价值最大的动作执行。这是一种间接的做法，那有没有更直接的做法呢？有！那就是<strong>直接更新策略</strong>。本文要介绍的
Policy Gradient 就是这类 policy-based 的方法， 除此之外，还会介绍结合了
policy-based 和 value-based 的 Actor-Critic 方法，以及在 Actor-Critic
基础上的 DDPG、A3C方法。</p>
<span id="more"></span>
<h2 id="policy-gradient">Policy Gradient</h2>
<h3 id="基本思想">基本思想</h3>
<p>Policy Gradient 就是通过更新 Policy Network
来直接更新策略的。那什么是 Policy
Network？实际上就是一个神经网络，<strong>输入是状态，输出直接就是动作（不是Q值）</strong>，且一般输出有两种方式：一种是概率的方式，即输出某一个动作的概率；另一种是确定性的方式，即输出具体的某一个动作。</p>
<p>如果要更新 Policy Network
策略网络，或者说要使用梯度下降的方法来更新网络，需要有一个目标函数，对于所有强化学习的任务来说，其实目标都是使所有带衰减
reward 的累加期望最大。即如下式所示</p>
<p><span class="math inline">\(L(\theta) = \mathbb E(r_1+\gamma r_2 +
\gamma^2 r_3 + ...|\pi(,\theta))\)</span></p>
<p>这个损失函数和 Policy Network
策略网络简直没有什么直接联系，reward是环境给出的，跟参数 <span
class="math inline">\(\theta\)</span>
没有直接运算上的关系。那么该如何能够计算出损失函数关于参数的梯度 <span
class="math inline">\(\nabla_{\theta} L(\theta)\)</span>?</p>
<p>上面的问题没法给出更新策略，我们不妨换一个思路来考虑问题。</p>
<p>假如我们现在有一个 Policy Network
策略网络，输入状态，输出动作的概率。然后执行完动作之后，我们可以得到reward，或者result。那么这个时候，我们有个非常简单的想法：<strong>如果某一个动作得到reward多，那么我们就使其出现的概率增大，如果某一个动作得到的reward少，那么我们就使其出现的概率减小。</strong></p>
<p>当然，用 reward 来评判动作的好坏是不准确的，甚至用 result
来评判也是不准确的（因为任何一个 reward，result
都依赖于大量的动作才导致的，不能只将功劳或过错归于当前的动作上。但是这样给了我们一个新的思路：<strong>如果能够构造一个好的动作评判指标，来判断一个动作的好与坏，那么我们就可以通过改变动作的出现概率来优化策略！</strong></p>
<p>假设这个评价指标是 <span class="math inline">\(f(s,a)\)</span>,
我们的 Policy Network 输出的 <span
class="math inline">\(\pi(a|s,\theta)\)</span> 是概率,
那么可以通过极大似然估计的方法来优化这个目标。比如说我们可以构造如下目标函数</p>
<p><span class="math inline">\(L(\theta) = \sum
log\pi(a|s,\theta)f(s,a)\)</span></p>
<p>比如说，对于某局游戏，假如最终赢了，那么认为这局游戏中每一步都是好的，如果输了，那么认为都是不好的。好的
<span class="math inline">\(f(s,a)\)</span>
就是1，不好的就是-1，然后极大化上面的目标函数即可。</p>
<p>实际上，除了极大化上面的目标函数，还可以直接对 <span
class="math inline">\(f(s,a)\)</span> 进行极大化，如这篇博文 <a
href="https://blog.csdn.net/jinzhuojun/article/details/72851548">Deep
Reinforcement Learning: Pong from Pixels</a> 中直接最大化 <span
class="math inline">\(f(x)\)</span> 也就是 <span
class="math inline">\(f(s, a)\)</span>
的期望，可以看到，最后的结果跟上面的目标函数是一致的。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd6euujcj611hh21ih71fa38mlm.png"
alt="max f(s,a)" />
<figcaption aria-hidden="true">max f(s,a)</figcaption>
</figure>
<h3 id="评判指标的选择">评判指标的选择</h3>
<p>从上面的推导也可知道，在 Policy Gradient 中，<strong>如何确定评价指标
<span class="math inline">\(f(s,a)\)</span> 是关键。</strong>
上面提到了一种简单地根据回合的输赢来判断这个回合中的每一步到底是好是坏。但是其实我们更加希望的是每走一步就能够获取到这一步的具体评价，因此出现了很多其他的直接给出某个时刻的评估的评价方式。如这篇论文
<a href="https://arxiv.org/abs/1506.02438">High-dimensional continuous
control using generalized advantage estimation</a>
里就对比了若干种评价指标。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd4k6vg5g78tcq1dg6gasrss9.png"
alt="select judge function" />
<figcaption aria-hidden="true">select judge function</figcaption>
</figure>
<p>上面公式（1）中的 <span class="math inline">\(\Psi_t\)</span> 就是 t
时刻的评价指标。从上图可以看到我们可以使用reward，使用 Q、A 或者 TD
来作为动作的评价指标。那这些方法的区别在哪里？</p>
<p>根据这篇文章 <a
href="https://zhuanlan.zhihu.com/p/26882898">DRL之Policy Gradient,
Deterministic Policy Gradient与Actor-Critic</a>, 本质的区别在于 variance
和 bias 的问题</p>
<blockquote>
<p>用reward来作为动作的评价是最直接的，采用上图第3种做法reward-baseline是很常见的一种做法。这样做bias比较低，但是variance很大，也就是reward值太不稳定，会导致训练不会。</p>
<p>那么采用Q值会怎样呢？Q值是对reward的期望值，使用Q值variance比较小，bias比较大。一般我们会选择使用A，Advantage。A=Q-V，是一个动作相对当前状态的价值。本质上V可以看做是baseline。对于上图第3种做法，也可以直接用V来作为baseline。但是还是一样的问题，A的variance比较大。为了平衡variance和bias的问题，使用TD会是比较好的做法，既兼顾了实际值reward，又使用了估计值V。在TD中，TD(lambda)平衡不同长度的TD值，会是比较好的做法。</p>
<p>在实际使用中，需要根据具体的问题选择不同的方法。有的问题reward很容易得到，有的问题reward非常稀疏。reward越稀疏，也就越需要采用估计值。</p>
</blockquote>
<p><strong>以上就是 Policy Gradient 的核心思想，通过 policy network
输出的 softmax 概率 和获取的reward(通过评估指标获取)构造目标函数，然后对
policy network 进行更新。从而避免了原来的 reward 和 policy network
之间是不可微的问题。也因为Policy
Gradient的这个特点，目前的很多传统监督学习的问题因为输出都是softmax的离散形式，都可以改造成Policy
Gradient的方法来实现，调节得当效果会在监督学习的基础上进一步提升。</strong></p>
<h2 id="actor-critic">Actor-Critic</h2>
<p>上面提到的多种评估指标其实已经涵盖了 Actor-Critic 的思想，原始的
Policy Gradient
往往采用的回合更新，也就是要到一轮结束后才能进行更新。如某盘游戏，假如最后的结果是胜利了，那么可以认为其中的每一步都是好的，反之则认为其中的每一步都是不好的。其更新过程如下，图片摘自
<a
href="http://202.38.196.91/cache/5/03/www0.cs.ucl.ac.uk/878f680a35c2cc35e046a7fd7f9c9fb8/pg.pdf">David
Silver 的 Policy Gradient 课件</a> ，这种方法也叫 Monte-Carlo Policy
Gradient</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd6dk9spft51pi59smheenb89.png"
alt="Policy Gradient Update" />
<figcaption aria-hidden="true">Policy Gradient Update</figcaption>
</figure>
<p>图中的 <span class="math inline">\(\log \pi_{\theta}(s_t,
a_t)\)</span> 是 policy network 输出的概率，<span
class="math inline">\(v_t\)</span> 是当前这一局的结果。这是 policy
gradient
最基本的更新形式。但是这个方法显然是有问题的，最后的结果好久并不能说明其中每一步都好。因此一个很直观的想法就是能不能抛弃回合更新的做法，而采用单步更新？Actor-Critic
干的就是这个事情。</p>
<p>要采用单步更新，意味着我们需要为每一步都即时做出评估。Actor-Critic
中的 Critic 负责的就是评估这部分工作，而 Actor
则是负责选择出要执行的动作。这就是 Actor-Critic
的思想。从上面论文中提出的各种评价指标可知，看到 Critic
的输出有多种形式，可以采用 Q值、V值 或 TD 等。</p>
<p>因此 Actor-Critic 的思想就是从 Critic
评判模块(采用深度神经网络居多)得到对动作的好坏评价，然后反馈给
Actor(采用深度神经网络居多) 让 Actor
更新自己的策略。从具体的训练细节来说，Actor 和 Critic
分别采用不同的目标函数进行更新， 如可参考这里的代码 <a
href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/6-1-actor-critic/">Actor-Critic
(Tensorflow)</a>，下面要说的 DDPG 也是这么做的。</p>
<h2 id="deep-deterministic-policy-gradientddpg">Deep Deterministic
Policy Gradient(DDPG)</h2>
<p>上面提到的的 Policy Gradient
处理问题其实还是局限在动作个数是离散和有限的情况，但是对于某些输出的值是连续的问题，上面的方法就不管用了，比如说自动驾驶控制的速度，机器人控制移动的幅度等。</p>
<p>最开始这篇论文 <a
href="http://proceedings.mlr.press/v32/silver14.pdf">Deterministic
Policy Gradient Algorithms</a> 提出了输出连续动作值的 DPG(Deterministic
Policy Gradient) ; 然后 论文 <a
href="https://arxiv.org/abs/1509.02971">Continuous control with deep
reinforcement learning</a> 基于 DPG 做了改进，提出了 DDPG(Deep
Deterministic Policy Gradient)。</p>
<p>这里 DPG 不详细展开说了，简而言之，主要就是证明了 deterministic
policy gradient不仅存在，而且是model-free形式且是action-value
function的梯度。因此 policy 不仅仅可以通过
概率分布表示，也就将动作空间推到了无限大的。具体的理论课参考这篇文章 <a
href="https://blog.csdn.net/jinzhuojun/article/details/72851548">深度增强学习（DRL）漫谈
- 从AC（Actor-Critic）到A3C（Asynchronous Advantage
Actor-Critic）</a></p>
<p>DDPG 相对于 DPG 的核心改进是引入了 Deep
Learning，采用深度神经网络作为 DPG 中的策略函数 <span
class="math inline">\(μ\)</span> 和 <span
class="math inline">\(Q\)</span> 函数的模拟，即 Actor 网络和 Critic
网络；然后使用深度学习的方法来训练上述神经网络。两者的关系类似于 DQN 和
Q-learning 的关系。</p>
<p>DDPG 的网络结构为 Actor 网络 + Critic 网络，对于状态 <span
class="math inline">\(s\)</span>, 先通过 Actor 网络获取 action <span
class="math inline">\(a\)</span>, 这里的 <span
class="math inline">\(a\)</span> 是一个向量；然后将 <span
class="math inline">\(a\)</span> 输入 Critic 网络，输出的是 Q
值，目标函数就是极大化 Q 值，但是更新的方法两者又有一些区别。论文中显示
DDPG 算法流程如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd5bb8ke1d9b1e1d1qcq1ta410f9m.png"
alt="DDPG" />
<figcaption aria-hidden="true">DDPG</figcaption>
</figure>
<p>从算法的流程可知，Actor 网络和 Critic
网络是分开训练的，但是两者的输入输出存在联系，Actor 网络输出的 action 是
Critic 网络的输入，同时 Critic 网络的输出会被用到 Actor
网路进行反向传播。</p>
<p>原始论文没有给出两个网路的具体示意图，这里给出一张<a
href="https://blog.csdn.net/jinzhuojun/article/details/72851548">这篇文章</a>画的示意图，可以看到，Critic
跟之前提到的 DQN 有点类似，但是这里的输入是 state + action，输出是一个 Q
值而不是各个动作的 Q 值。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd6k6nr7c9mqcc1bthhs4ibs13.png"
alt="network visulization" />
<figcaption aria-hidden="true">network visulization</figcaption>
</figure>
<p>由于在 DDPG
中，我们不再用单一的概率值表示某个动作，而是用向量表示某个动作，由于向量空间可以被认为是无限的，因此也能够跟无限的动作空间对应起来。</p>
<h2 id="asynchronous-advantage-actor-critica3c">Asynchronous Advantage
Actor-Critic(A3C)</h2>
<p>在提出 DDPG 后，DeepMind 在这个基础上提出了效果更好的 Asynchronous
Advantage Actor-Critic（A3C），详见论文 <a
href="https://arxiv.org/pdf/1602.01783.pdf">Asynchronous Methods for
Deep Reinforcement Learning</a></p>
<p>A3C 算法和DDPG类似，通过 DNN 拟合 policy function 和 value
function的估计。但是<strong>不同点</strong>在于 1. A3C 中有多个 agent
对网络进行 asynchronous update，这样带来了样本间的相关性较低的好处，因此
A3C 中也没有采用 Experience Replay 的机制；这样 A3C 便支持 online
的训练模式了 2. A3C 有两个输出，其中一个 softmax output 作为 policy
<span
class="math inline">\(\pi(a\_t|s\_t;\theta)\)</span>，而另一个linear
output为 value function <span
class="math inline">\(V(s\_t;\theta\_v)\)</span> 3. A3C 中的Policy
network 的评估指标采用的是上面比较了多种评估指标的论文中提到的 Advantage
Function(即A值) 而不是 DDPG 中单纯的 Q 值。</p>
<p>整体的结构如下所示，图片摘自<a
href="https://blog.csdn.net/jinzhuojun/article/details/72851548">这篇文章</a>。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd746v6om9cmoh1nul1io01fg19.png"
alt="A3C" />
<figcaption aria-hidden="true">A3C</figcaption>
</figure>
<p>从上面的如可知，输出包含两部分，value network
的部分可以用来作为连续动作值的输出，而 policy network
可以作为离散动作值的概率输出，因此能够同时解决前面提到的两类问题。</p>
<p>两个网络的更新公式如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1cd7766d16uk2l812unadu2gt9.png"
alt="A3C update" />
<figcaption aria-hidden="true">A3C update</figcaption>
</figure>
<p>A3C
通过创建多个agent，在多个环境实例中并行且异步的执行和学习，有个潜在的好处是不那么依赖于GPU或大型分布式系统，实际上A3C可以跑在一个多核CPU上，而工程上的设计和优化也是这篇文章的一个重点。</p>
<p>综上，本文主要介绍了 Policy Gradient 这一类的方法，最基础的 Policy
Gradient 是回合更新的，通过引入 Critic 后变成了单步更新，而这种结合了
policy 和 value 的方法也叫 Actor-Critic，Critic
有多种可选的方法。对于输出动作为连续值的情形，前面那些输出动作概率分布的方法无能为力，因此提出了
DPG 和 DDPG，DDPG 对 DPG 的改进在于引入深度神经网络去拟合 policy
function 和 value function。在 DDPG 基础上又提出了效果更好的
A3C，这个方法在 DDPG 上引入了多个 agent 对网络进行 asynchronous
update，不仅取得了更好的效果，而且降低了训练的代价。</p>
<hr />
<p>参考</p>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/21725498">深度增强学习之Policy
Gradient方法1</a></li>
<li><a href="http://karpathy.github.io/2016/05/31/rl/">Deep
Reinforcement Learning: Pong from Pixels</a></li>
<li><a
href="https://blog.csdn.net/jinzhuojun/article/details/72851548">深度增强学习（DRL）漫谈
- 从AC（Actor-Critic）到A3C（Asynchronous Advantage
Actor-Critic）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/25239682">深度强化学习（Deep
Reinforcement Learning）入门：RL base &amp; DQN-DDPG-A3C
introduction</a></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>怎样用数据洞察你的用户</title>
    <url>/2017/06/10/%E6%80%8E%E6%A0%B7%E7%94%A8%E6%95%B0%E6%8D%AE%E6%B4%9E%E5%AF%9F%E4%BD%A0%E7%9A%84%E7%94%A8%E6%88%B7/</url>
    <content><![CDATA[<p>本文内容主要来源于<a
href="https://www.zhihu.com/lives/778739652977770496">该知乎
live</a>，主要介绍了受众定向（用户画像）的分类和方法、具体介绍标签体系建立以及如何进行行为定向。</p>
<span id="more"></span>
<h2 id="受众定向与用户画像">受众定向与用户画像</h2>
<p>原始行为数据无序杂乱，不能直接应用于业务，因此要将用户的原始行为转化为对用户的描述，也就是受众定向（用户画像），但是这里需要注意的是<strong>不能想当然地描述用户，而是要根据需求方（如广告主）的需求来为用户打上相应标签</strong></p>
<p>受众定向与常听到的用户画像的差别不大，均是研究如何描述用户，为用户打上标签，两者只是在着重点上有细微区别</p>
<p>受众定向重点是可优化，也就是跟侧重于效果，而用户画像则更侧重于可解释性，然而在实际中对用户的描述往往是两者混合的，如对广告主需要可解释性强的标签，而对于模型则更侧重那些有效的标签（可解释性不一定好）</p>
<figure>
<img src="https://wulc.me/imgs/image_1big2mr861guqdgv1s9j1qpqttk9.png"
alt="受众定向与用户画像" />
<figcaption aria-hidden="true">受众定向与用户画像</figcaption>
</figure>
<h2 id="受众定向的分类">受众定向的分类</h2>
<p>下面以计算广告为例阐述可受众定向需要在哪些维度上做打标签</p>
<p>1）用户维度 <span class="math inline">\(t(u)\)</span>,
描述用户的固有属性 2）上下文维度 <span
class="math inline">\(t(c)\)</span>，描述用户浏览的内容 3）用户-广告维度
<span
class="math inline">\(t(a,u)\)</span>，描述用户在某个广告主下的特有属性</p>
<p>实际中需要为广告打上标签 <span
class="math inline">\(t(a)\)</span>，用于描述广告的固有属性，从而与用户匹配</p>
<figure>
<img src="https://wulc.me/imgs/image_1big3052b1vspafe19832q11iajm.png"
alt="受众定向方法分类" />
<figcaption aria-hidden="true">受众定向方法分类</figcaption>
</figure>
<p>如上图所示，受众定向建立的标签一般有两种作用，而第一种作用的标签需要可解释性，第二种作用的标签则更强调其效果</p>
<h2 id="受众定向的方法">受众定向的方法</h2>
<p>同样以计算广告为例，下图展示了受众定向常用的方法，左边表示广告的生命周期，右边表示各个阶段的受众定向的方法和效果，其中越往左效果越好，具体方式的含义可参考<a
href="http://wulc.me/2017/04/28/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0%283%29--%E5%8F%97%E4%BC%97%E5%AE%9A%E5%90%91/">这里</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1big3f0l5ki915va17ss1ba0oum13.png"
alt="常见受众定向的方式" />
<figcaption aria-hidden="true">常见受众定向的方式</figcaption>
</figure>
<p>重定向只需要用到第一方数据 look-alike 需要用到第一方数据和第二方数据s
hyper-local 表示根据更精细的位置做定向(移动端)</p>
<h3 id="标签体系的建立">标签体系的建立</h3>
<p>上面讲述了该在那些方面建立标签体系以及建立标签体系的方法，下面要讲一个重点的内容，就是该建立怎样的标签体系</p>
<p>如下图所示，标签体系可以分为两大类，其中一类是结构化标签，可以认为这一类的标签是一个大的树状结构；另外一类则是非结构化的，也就是根据效果和需求驱动的标签体系，关键词就是一个典型的非结构化标签体系。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bigfp0riv981j2p138p1tb31ru89.png"
alt="受众定向标签体系" />
<figcaption aria-hidden="true">受众定向标签体系</figcaption>
</figure>
<p>这里需要注意的是，由于结构化标签结构上的完备性，往往会被大部分人采用，但是这种标签体系的效果未必就好，原因是这些<strong>结构化标签将重点放在了标签体系的完备性而往往忽略了广告主的具体需求</strong>。</p>
<p>结构化的标签体系的一个典型例子是雅虎的 GD
系统的标签体系，这个标签体系根据主观的判断来分类标签，并没有结合广告主的具体需求，在实际的效果并不好</p>
<figure>
<img src="https://wulc.me/imgs/image_1biguif851ctjdsm5v41aq21rqr9.png"
alt="结构化标签" />
<figcaption aria-hidden="true">结构化标签</figcaption>
</figure>
<p>下面的标签体系中虽然形式上类似于结构化标签，但是是根据各个广告主的需求来定制各个标签的，因此是非结构化的，也更实用</p>
<figure>
<img src="https://wulc.me/imgs/image_1biguqfu0mjn1rboe71e031snfm.png"
alt="非结构化标签" />
<figcaption aria-hidden="true">非结构化标签</figcaption>
</figure>
<p><strong>非结构化标签体系的建立过程</strong>如下 1）确定行业
2）了解行业里面用户的决策流程 3）根据决策流程定制各个流程中的标签</p>
<p>如对于汽车行业，一般用户购买时会先考虑预算(价格区间标签)，然后考虑车的用途（车型、大小等标签），最后考虑品牌（品牌标签）。</p>
<p>实际中，具体的标签可通过不同的方法获取，下文要讨论的行为定向中也提供了一种获取具体标签的方法。</p>
<h3 id="行为定向">行为定向</h3>
<p>下面讲述受众定向中的一个重点：行为定向，就<strong>是根据用户的历史行为给用户打标签。</strong></p>
<figure>
<img src="https://wulc.me/imgs/image_1bigvjnbjb1e1lhs1i2s1g761vfi13.png"
alt="行为定向的定义" />
<figcaption aria-hidden="true">行为定向的定义</figcaption>
</figure>
<p>行为定向首先要<strong>将用户的各种行为转化为标签，同时对各种行为进行加权</strong>，如下图所示就是通过三种行为（广告点击，搜索，浏览）为用户打标签，其过程都是根据用户操作对象的具体内容提取出标签（关键词，主题等）并进行叠加。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii2e03km0h1muifn416ji16i89.png"
alt="行为定向的特征选择过程" />
<figcaption aria-hidden="true">行为定向的特征选择过程</figcaption>
</figure>
<p>上面采用的方法并不复杂，其中一个很重要的原因就是行为定向的实时性要求，因为用户的行为的有效期一般不长，即从关注到最终的购买所持续的时间往往并不长，其次是因为要处理的用户的量级非常大。</p>
<p>此外，由于各种行为所反映的用户的意图不一，因此需要对不同行为进行加权，而且对于不同的标签，加权的方式还不完全一样，如下是对不同标签的不同行为加权的一种方法</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii2qh9547r13917u91pg1136hm.png"
alt="加权方式" />
<figcaption aria-hidden="true">加权方式</figcaption>
</figure>
<p>上面建模采用泊松分布来处理，因为<strong>泊松分布就是描述某段时间内，具体数量的事件发生的概率，如上式表示在时间
<span class="math inline">\(t\)</span> 内，用户点击广告次数为 <span
class="math inline">\(h\)</span> 的概率</strong>。其中 <span
class="math inline">\(\lambda\)</span>
表示用户点击广告的频繁程度，也叫频繁性参数，该值越大，表示点击越频繁。</p>
<p><strong><span class="math inline">\(\lambda\)</span>
可描述为各种原始行为的加权和</strong>, 其中 <span
class="math inline">\(w\_{tn}\)</span> 为权重系数, <span
class="math inline">\(x\_{tn}\)</span>
为原始行为（N种，如浏览、搜索等）的统计量，求解时通过 <span
class="math inline">\(h\)</span>
的历史数量进行极大似然估计即可求出权重系数 <span
class="math inline">\(w\_{tn}\)</span>
，然后直接在线上使用权重系数。</p>
<p>此外，上面式子中 <span class="math inline">\(t\)</span>
表示对不同的标签建立不同的权重体系。</p>
<p>上图中将各类行为变为具体的标签方法有以下几种，主要思路是找到用户的行为对应的内容（一般是具体文本），然后借助
NLP 技术将内容转为标签</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii37vdnie4rjrtci1lce1ve913.png"
alt="行为变为标签的方法" />
<figcaption aria-hidden="true">行为变为标签的方法</figcaption>
</figure>
<p>主要方法可以分为两种
1）针对浏览行为、点击行为，相应的都会有具体内容，如浏览的页面的内容，点击的广告的具体内容，通过
NLP 技术对内容提取关键词或主题分布，作为标签
2）针对搜索行为，可分为通用搜索和垂直搜索，要解决的问题都是如何<strong>将搜索关键词变为标签</strong>。对于通用搜索，可以利用已有搜索引擎（百度，谷歌等）模拟用户搜索行为，从得到的搜索结果作为内容，从中提取标签方法可以采用与第一种相同的
NLP
技术；对于垂直搜索，可以通过淘宝、携程、汽车之家等垂直搜索引擎，直接从关键词返回的结果中提取标签，因为像这种垂直搜索引擎一般都会自定义好一套标签了，因此这里是采用了垂直网站已经分好的类。</p>
<p>实际工程中，往往会从不同渠道获取用户不同的行为数据，将各种方式获取的日志整理在一起，称为
Session log。Session log 中一行表示一个用户的数据，这样通过 MapReduce
进行计算时，通过 map 过程即可完成某个用户的 targeting
过程，也就是下图中的局部计算。</p>
<p>除此之外，行为定向中往往要用到用户过去一段时间的数据（7的整数倍，避免周六日带来的偏差），处理的数据是一个时间序列数据，处理的方法有以下两种：滑动窗口和时间衰减。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii44dj0nksliuc6pqo0jeu1g.png"
alt="处理时间序列的行为数据" />
<figcaption aria-hidden="true">处理时间序列的行为数据</figcaption>
</figure>
<p>实际中一般采用时间衰减方式，因为时间衰减的方式计算的效率较高</p>
<h3 id="场景定向">场景定向</h3>
<p><strong>场景定向指的是判断出用户当前所处的场合和状态</strong>（地铁上、开会中、健身房等），针对的是移动设备。利用移动设备的传感器等搜集的信息，可以判断用户当前所处场景。</p>
<p>以早餐推送为例，根据用户当前的速度可以判断出用户是否在坐地铁，根据时间判断用户是要去上班，根据用户的位置可以为用户推荐附近的早餐店，实际上这是一个真实的例子，在东京的一次肯德基推广活动中，通过移动设备行为数据的分析，活动方准确找到了那些从地铁出来准备吃早餐的人群，实时给他们送出了早餐优惠券。</p>
<p>这里需要注意的是场景定向不是上下文定向，上下文定向针对的是媒体内容，而场景针对的是用户。</p>
<h3 id="人口属性定向">人口属性定向</h3>
<p><strong>人口属性定向中主要是要预测性别和年龄阶段</strong>，实际上就是分类问题</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii4v7su11nof3v1ndj12vsiq634.png"
alt="人口属性定向" />
<figcaption aria-hidden="true">人口属性定向</figcaption>
</figure>
<h2 id="受众定向的评判标准">受众定向的评判标准</h2>
<p>上述的受众定向的过程其实就是依据某个用户的各种历史行为，为该用户在所有的标签上打出一个分数，然后线上设定分数阈值，大于这个阈值则判断用户是这个标签的人群。因此一般来说阈值越大，标签人群越少，但是结果也会越可信。</p>
<p>下图展示了该如何评测受众定向的有效性，横轴表示被打上标签的人群的比例，纵轴表示被打上标签的人群对广告的点击率，一般来说，某个标签圈定的人数越少，效果越好，也就是点击率越高，违反了这一变化规律则说明受众定向不起作用。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bii4aqnn1evf16gbpjdgd5rok1t.png"
alt="受众定向评测" />
<figcaption aria-hidden="true">受众定向评测</figcaption>
</figure>
<p>综上，本文主要讲了受众定向中的行为定向</p>
<ol type="1">
<li>确定具体行业</li>
<li>研究行业用户决策过程，制定用户标签体系</li>
<li>制定标签体系不要刻意追求规整、结构化的标签体系</li>
<li>把用户的原始行为映射到标签体系中，并求出各种行为类型的权重</li>
<li>根据 4
可为用户在各个标签上打出一个分数，为标签设定阈值，则通过比较分数和阈值可以判断用户是否属于该标签人群</li>
<li>通过 Reach/CTR 曲线评测定向是否有效</li>
</ol>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>我们在招人(长期有效)</title>
    <url>/2019/06/01/%E6%88%91%E4%BB%AC%E5%9C%A8%E6%8B%9B%E4%BA%BA(%E9%95%BF%E6%9C%9F%E6%9C%89%E6%95%88)/</url>
    <content><![CDATA[<p>这是一则长期有效的招聘广告（包含社招和校招），面向从事计算广告领域或对这个领域感兴趣的同学，各位同学如果希望加入字节跳动广告技术团队的可邮件联系我（<a
href="mailto:wuliangchao@bytedance.com">wuliangchao@bytedance.com</a>）了解详细信息，并进行部门直推。</p>
<span id="more"></span>
<h2 id="部门直推">部门直推</h2>
<p>互联网广告在过去的20多年已经充分证明了其对互联网的价值，广告的收入是各大互联网公司收入的重要来源；而“免费+流量变现”的模式使得广告在当下几乎是不可避免的，既然是不可避免的，那么我们为什么不把广告做得更好一点呢？样式做得更好看？更符合用户的兴趣？更贴合用户近期的需求？建设好广告的生态，让广告作为信息的桥梁而不是一堆辣眼睛的图片视频？</p>
<p>笔者当前就职于字节跳动下的广告技术团队做的就是这件事(关于计算广告这个领域更详细的介绍可参考本博客<a
href="http://wulc.me/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/">计算广告</a>标签下的文章)，广告部门也是字节跳动下营收来源的重要部门</p>
<p>整个团队比较年轻，目前也处于快速发展过程中，工作中工程与算法并重，工程中各种高并发场景，策略中
Bidding、Budget Pacing、Cold start、Trageting、Retrival, CTR/CVR/DeepCVR
estimation、Calibration 等各种问题等你来挑战；</p>
<p><strong>如果你对广告行业感兴趣并希望详细了解我们的团队，欢迎邮件联系我
<a
href="mailto:wuliangchao@bytedance.com">wuliangchao@bytedance.com</a>，可进行部门直推,
校招和社招均可</strong></p>
<p>当前部门 JD 如下，可邮件咨询每个岗位的详细信息</p>
<figure>
<img src="https://wulc.me/imgs/JD.jpeg" alt="JD" />
<figcaption aria-hidden="true">JD</figcaption>
</figure>
<h2 id="校招">校招</h2>
<p><strong>内推码：FRU8F6S</strong></p>
<p>2021
秋招提前批已开始，详细信息如下，需要内推的同学可邮件联系并带上你的简历</p>
<p>1、 提前批有如下优势 -
快：广告系统部门内无笔试流程，直接散招散面，流程快效率高！ -
稳：提前批投递结果不影响秋招，相当于有两次投递机会！ -
早：6月拿offer，提前结束秋招，安心过暑假！ -
多：海量校招HC，机会多！</p>
<p>2、面向对象和招聘岗位？ 2021年应届毕业生：2020年9月-2021年8月期间毕业
岗位：提前批只针对技术+测试序列岗位。广告系统岗位：前后端、算法、大数据、测试/测开、客户端
工作城市：北京、上海、深圳、杭州</p>
<p>3、提前批是否可以投递多个校招岗位？
仅能主动投递一次，且只能投递一个岗位；有被多次复捞的可能性，但一次只能进行一个流程，不能同时在多个业务笔试面试；提前批结束但未拿到offer，可以再次投递正常批。</p>
<h2 id="社招">社招</h2>
<p>社招没有内推码，可<strong>邮件联系我告知你的电话以及邮箱，然后等待你的邮箱收到投递邀请链接后进行投递即可</strong></p>
<p>邮件一般会在1-2天内回复</p>
<p>欢迎有意向的同学加入我们的团队，也祝愿各位都能找到合适的工作。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
      </tags>
  </entry>
  <entry>
    <title>我们这一代人的困惑</title>
    <url>/2015/11/20/%E6%88%91%E4%BB%AC%E8%BF%99%E4%B8%80%E4%BB%A3%E4%BA%BA%E7%9A%84%E5%9B%B0%E6%83%91/</url>
    <content><![CDATA[<p>本文是于宙在TEDx大会上的演讲。这篇文章有点长，不过非常值得你花20分钟把它看完。</p>
<span id="more"></span>
<p>以下是演讲全文： 大家下午好， 很荣幸能够参加本次TEDx大会。</p>
<p>自我介绍：我是大连人，高中就读于大连市二十四中。因为当时学习十分不努力，所以高中毕业之后选择了出国留学。这其实是很多本科出国留学的人不能说的秘密，辗转了几个学校，最终毕业于美国印第安纳大学凯利商学院，主修投资和金融衍生品。</p>
<p>上学的时候迷恋炒股，学习依旧散漫，没能成为一个“放弃了华尔街的高薪工作毅然回国”的海归精英，真的颇为遗憾，因为实在没有什么华尔街的公司愿意要我。碰巧的是，毕业前两年股市和外汇的行情比较好，赚到了一点点资本，于是我决定回国做点生意。现在在大连从事餐饮行业，目前拥有4家芝士蛋糕店和3家火烧店。</p>
<h2 id="引言"><strong>引言</strong></h2>
<p>大学毕业之后第一次面对这么多人做演讲，坦率地说，非常的紧张。虽然年轻的时候我曾经畅想过很多次，功成名就之后能像我曾经的那些偶像一样和年轻的朋友们分享一下我是如何从一无所有走上人生巅峰的经验，然后语重心长地告诉大家，人活着不能像一根草而是要像一棵树，能走到金字塔顶端的只有雄鹰和蜗牛两种动物，我的成功你也可以复制等等。</p>
<p>可是过了26岁之后我忽然意识到一个严肃的问题，就是自己的一生未必会取得很大的成就啊，所以当TEDxDUFE团队找到我说没关系即便你只是一个开小吃店的，我们也愿意为你提供这样一个和很多人交流思想的机会时，我的心情是多么地激动。因为公司还没上市，所以小草大树、雄鹰蜗牛、睡地板捡易拉罐这样的故事还不到说的时候。今天，只想和大家分享几个困扰了我和我身边的一些朋友十几年的问题，和在经历了一些变故和挫折后，我对这些问题的看法。</p>
<h2
id="努力奋斗真的能实现梦想吗"><strong>努力奋斗真的能实现梦想吗？</strong></h2>
<p>大家现在可以想象一下汪峰老师坐在转椅上，深情地望着你，对你说，“你的梦想是什么？”周星驰老师的那句“做人如果没有梦想，和咸鱼有什么区别？”据说也激励了几代人。梦想这个东西是如此的重要，简直就是人生的一盏明灯。成功的人们成功的原因各不相同，但他们都不会忘记告诉你，无论到什么时候，都不曾忘记梦想，是他们成功的首要原因。以至于我们这一代人对于人生意义的最通常的理解，就在于坚持梦想并最终实现它。可很少有人愿意面对的一件事情是，大部分人的梦想永远，没错，永远都实现不了。</p>
<p>你没听错，大部分人的梦想永远都实现不了。</p>
<p>先和大家分享一个我之前的梦想。上大学的时候，我热衷于各式各样的赌博游戏，是学校旁边赌场的常客。我赌徒生涯的起点源于赌场里最基本游戏轮盘赌，轮盘上1到36个数字和两个0，赔率是1赔36。1到36分为红黑两色，押注红黑的赔率是1赔1。</p>
<p>作为一个合格的接受过九年义务教育的人都知道，每一次轮盘开始转动的那一刻，都是一次纯粹的独立随机事件。但是赌博这件事情的魅力就在于，当你真正身处赌场，看到已经连续4次开出红色的时候，几乎所有人都会想把筹码压在黑色的那一面。而我当时的梦想，就是破译这其中的奥秘。</p>
<p>我最初的策略非常简单，当连续三次开出奇数，就押注偶数，连续三次红色，就押注黑色。难以置信的事情发生了，在我严格地执行这个策略的情况下，前几次去赌场不但全身而退，每次都还赚了不少，以至于我产生了一种幻觉，也许游戏是有规律可循的，我已经看到了人生巅峰就在不远处向我招手。当然最终的结尾你们一定想到了，在经历过连续18个偶数，连续开出21次黑色后，我把之前赚到的钱都乖乖地还给了赌场。</p>
<p>后来我知道，我那个愚蠢的梦想叫做<strong>赌徒谬论</strong>，就不具体展开讲了。但它对我意义深刻，我终于明白了在纯粹的随机事件面前，一切规律都是无谓的。</p>
<p>生活中的事情有极个别和轮盘赌一样，属于纯粹的随机事件，比如双色球。可是几乎每一个中了双色球的人都会告诉你啊，他们花了多少精力去钻研往期号码，研究历史规律，付出了多少辛勤的努力，最终获得了成功。<strong>实际上，即使是纯粹由随机性主导的事情，只要参与的人的基数足够大，小概率事件总会发生。</strong>有趣的是，几乎所有在随机事件中的受益者，都会把这完全由运气决定的结果归功于自己的努力上。不仅仅是参与者本身，旁观者也会这么认为。再比如，中国好声音的冠军嘛。</p>
<p><strong>我们生活中遇到的所有事情基本可以分为三类，第一类纯粹由随机性决定，比如布朗运动和轮盘赌博；第二类纯粹由能力决定，比如英语六级考试、110米栏之类；第三类，也是我们最常遇到的，由能力和随机性共同决定，比如创业、投资、恋爱或是梦想。</strong></p>
<p>我对励志大师们总告诉年轻人要不惜一切代价追逐梦想感到深深厌倦的原因就在于，大多数人的梦想虽然不是纯粹的双色球，但也绝对是由随机性主导的。在强大的随机性面前，付出再多辛勤的汗水，就好比夜以继日蹲在轮盘赌旁边渴望参透其中规律。前面说到中国好声音的冠军，张碧晨的那一句
you are my
destiny，听得我也是醉了。但毕竟那一刻，中国又有多少唱歌唱得和她一样好甚至更好的姑娘，如果真把成为好声音冠军作为一生的梦想，一生中都得在痛苦中度过。</p>
<p>我个人很喜欢黄渤，但绝对不会用黄渤作为例子去激励一个我这种长相差的年轻人不惜一切代价去追逐演员梦，注意是不惜一切代价。<strong>因为无论是唱歌还是演戏，再多的努力也只能让你变得很优秀，它们并不存在可以量化的评判标准，想成为万众瞩目的明星，随机性的重要程度都远远大于实力</strong>。</p>
<p>我想，<strong>一个人在年轻的时候，做的每一件事情，能清楚地区分其中随机性所占的比例并能心平气和地接受它，在我看来就是最宝贵的财富。</strong></p>
<p>那么<strong>在你的梦想中，运气又扮演了多重要的角色呢？当你深深地感知到这件事情的随机性也许不会青睐于你，是否还愿意坚持下去呢？</strong>对我而言，梦想永远是值得执着追求的，但我可以无比心平气和地接受，它就是永远无法实现。</p>
<h2
id="既然连梦都实现不了还有什么事情值得努力呢"><strong>既然连梦都实现不了，还有什么事情值得努力呢</strong></h2>
<p>去年这个时候，我发过一条微博:
&gt;这些年我一直提醒自己一件事情，千万不要自己感动自己。大部分人看似的努力，不过是愚蠢导致的。什么熬夜看书到天亮，连续几天只睡几小时，多久没放假了，如果这些东西也值得夸耀，那么富士康流水线上任何一个人都比你努力多了。人难免天生有自怜的情绪，唯有时刻保持清醒，才能看清真正的价值在哪里。</p>
<p>这段话在网上的疯传，是我始料不及的。更出乎我意料之外的是，我在评论中看到了相当一部分的骂声，还有人认真地给我写下了相当深刻的话，“你在拥有自己的光亮时不要吹熄别人的蜡烛，你不能因为你自己的不喜欢就否定别人。”</p>
<p>很莫名其妙是吧，即使你刚刚听完我上一段关于随机性的看法，你也会知道，我从来都不觉得努力是一件无所谓的事情。恰恰相反，我一直相信，<strong>在能力没达到一定程度之前，你连面对随机性的资格都没有啊</strong>。张碧晨能拿好声音冠军自然离不开运气，但换成杨幂，评委不但不会转身，可能直接撒腿就跑了。</p>
<p>可现在问题来了，那究竟<strong>什么才算是有价值的努力</strong>？这可以从我那条微博说起。去年这个时候，我和朋友在琢磨去大庆做点服装生意，决定去考察几个商场。我当时住在北京，因为之前晚上和朋友在外面玩得比较尽兴，回到家里已经比较晚了，担心睡觉睡过头会错过航班，那晚上就直接在沙发上靠了一晚。那是我第一次去哈尔滨，十一月份已经很冷了，衣服拿得不足，下了飞机冻得头疼。又因为没有提前订票，到了哈尔滨之后才买的火车票，发现就只剩站票了。于是，当我一晚上没睡，冻得头晕眼花，又在绿皮火车上站了两个多小时之后，抵达大庆的那一瞬间我觉得自己实在是太不容易了，将来必须要写进回忆录里面。可是，回头仔细一想，这些所谓的“努力”对我最终把那个服装生意做好，没有半毛钱关系。更何况，如果我前一天晚上能早点上床睡觉，多准备点衣服，提前在网上把火车票订好，完全可以舒舒服服地达到同样的目的。?</p>
<p><strong>我的那次经历像是自己二十多年生活中很多事情的缩影，沉溺在对结果没有直接帮助只是因为自己遭受了一些痛苦的行为中，误以为那就是努力。</strong></p>
<p>当我终于意识到我并不是唯一曾经<strong>把无意义的消耗当作努力</strong>的时候，忽然发现，原来生活中我觉得很努力的人，也许没那么勤奋，如果在正确的方向上坚持行动，超过他们也并不困难。</p>
<p>因为<strong>我们这一代人对于勤奋和努力的理解，几乎清一色地来自于学校，更精确地说，在前二十多年的生活中，我们眼中最努力的人，就是那些最能拼命看书和做题的人。</strong>实际上，这种理解是极其片面而幼稚的，因为看书和做题本身，都是为了一个极其鲜明的目的而存在的，就是通过考试。这种勤奋的付出极其纯粹，更多的复习时间，更高的复习强度，一般而言，都可以直接地提高考试的分数，它们之间的联系鲜明而直接，每个人都看得懂。</p>
<p>但生活的美妙之处却在于，很多事情在我们没做到一定程度之前，是完全没法理解的。</p>
<p>这就好比学英语，十几年漫长的岁月里我都在幻想，要通过多么复杂的流程，多么精密的设计，多么全面的涉及和多么不可思议的努力，终于有那么一天，或许我就能因为前期的那些无懈可击的学习，说一口比较流利的英语，像说中文一样，可以边说边想，而不是说每一句话之前设计它的句式时态词汇然后在心里复述几遍再看上去流利地背诵出来。谁不是这么设想的呢？可惜，它不仅从来没有实现，并且让我看不到有任何实现的趋势，对于每一个设立目标的人来说，没有比这更痛苦的感受。</p>
<p>但是在去了美国两年左右的时间之后，我忽然发现自己已经可以毫无障碍地说一口流利的英语了。这并非我采用了什么新的学习方法，而是因为去了印第安纳之后身边中国人很少，在没有选择的情况下，只能被迫用英语去交流和表达，在这个过程中，我并没有认真想过自己每天进步了多少，也没有阶段性的检验学习效果，只是不停地去听和说，因为没有选择嘛。直到两年多后的忽然有一天我才意识到，咦，自己好像真的已经可以了。但是我确实无法总结出来是如何一步一步做到的，只是那两年的时间，我一直都在很不情愿地用英语去生活嘛。</p>
<p><strong>一个人能获得的最可贵的能力，都和掌握一门语言一样，你所付出的努力不是能够获得即时回馈的，甚至在很长的一段时间内没有任何收获，直到积累到了一定的阶段后，忽然爆发出惊人的力量，连你自己都不清楚这一切是如何发生的。</strong>比如锻炼身体，读书写作，或者是做生意。<strong>当你经历了足够的量变终于引起质变时拥有的技能，大部分人是终身难以企及的，不是因为他们太笨，恰恰相反，因为他们都太聪明了。</strong></p>
<p><strong>触发人类行动的最基本原理被称为反射，我们是需要即时回馈的物种。所以绝大多数人对于世界的理解度是线性的，但更多情况下，事物却是以漫长的潜伏震荡后爆发突破的形式发展的。</strong>我现在时常觉得，人在少年时期更容易掌握语言、乐器、美术这些成年后很难学的技艺，并非那小时候就是天资聪颖，而是小孩子很少会一个星期质疑一次自己收获了多少，都是闷头一练就是好几年，直到学会了才知道哦自己已经会了。只有聪明的成年人，才相信一本书读懂易经，10句话揭秘马云的成功之道，30天成为吉他高手的故事。</p>
<p>简而言之，现实生活中，付出和结果之间往往没有那么立竿见影。在离开学校之后，当我们遇到的很多事情不再像做题和考试之间联系得那么紧密的时候，很多人的付出都是浅尝辄止的。而<strong>最可贵的努力，是选择一个正确的方向，那些无法立即获得回报的事情，依然能付出十年如一日的专注和热情，最终的结果也许不足以让你独孤求败，但足以出类拔萃</strong>。</p>
<h2
id="人这一生中是否有一个节点过了之后一切都会好起来"><strong>人这一生中是否有一个节点，过了之后一切都会好起来</strong></h2>
<p>前面说了这么多，谈论的都与目标和实现目标有关。仔细想想，我们的一生好像都是在实现目标中挣扎着度过的。上初中的时候，老师告诉你，中考的淘汰率是最高的，只要闯过去，上了高中一切就好了。但上了高中的时候发现不是那么回事嘛，高中老师又说了啊，考上大学就进了天堂。于是你考上了大学，依然空虚迷茫各种草样年华，父母老师又告诉你，找到工作就好了。工作之后发现烦恼和忧虑依然都在，女朋友给你看马云的故事，告诉你等你事业有成就好了……</p>
<p><strong>你发现了吗，其实人这一辈子的每一个阶段都有新的痛苦和顾虑，周而复始，生生不息。绝对不会因为你考上大学，事业有成，迎娶了女神就从此
happily ever
after。但每一个阶段也有每一个阶段的快乐，无法替代。生活不是安徒生童话也不是好莱坞电影，从出生的那一刻起直到生命的尽头，都不存在什么节点，过去了之后一切幸福美满无忧无虑。</strong></p>
<p><strong>每一段岁月都有它存在的价值，没有高低贵贱之分，都不应该被辜负。而我能想到的人这一生能做的最愚蠢的事情，就是把全部人生的希望都孤注一掷到未来的某个节点上，而忽略了生活本身应有的乐趣。</strong>哪怕你以后真正实现了那个执念中的目标，才会发现它远远没你想的那么美好。</p>
<p>年轻的时候和哥们在操场上打篮球喝可乐的快乐，是以后高尔夫球会所里品红酒替代不了的。尤其男生，千万不要总想着等将来有钱了如何如何，且不说你以后很可能不会太有钱，而且相信我，就是有钱了也真的不能怎么样。<strong>生命就在每天的生活里，一切执念都是虚妄。和身边的人愉快相处，认真安排好每一天的活动，用心去感受每一天的心境，就是生活的意义本身。</strong>这其实是我今天最想分享给你们的事情。</p>
<p>谢谢大家。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>手机监控服务器登陆情况</title>
    <url>/2016/01/03/%E6%89%8B%E6%9C%BA%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%99%BB%E9%99%86%E6%83%85%E5%86%B5/</url>
    <content><![CDATA[<p>通过往手机发短信提醒用户登录的方式也许有很多种，下面讲一种最容易实现的，实现起来也比较简单的。</p>
<span id="more"></span>
<p>原理很简单:<strong>中国移动提供139.com这样的邮箱,如果有邮件到达的会同时发送邮件标题到管理员对应手机，邮箱名是
<code>你的手机号@139.com</code>。</strong>例如:当13036110648@139.com邮箱接收到邮件时，会同时给13036110648这个手机发送邮件到达信息,邮箱注册地址http://mail.139.com/。</p>
<p>其次，用户登录的时候会自动加载其用户主目录下的<code>.bashrc</code>文件,那么我们可以在这个脚本里面加入执行发送邮件的命令，发送的内容为当前登录的用户及来源。</p>
<p>发送邮件的命令为<code>mail</code>,如果提示找不到这个命令需要安装<code>mailx</code>这个软件包，发送邮件的命令如下所示：
<code>mail -s "邮件主题" XXX@139.com &lt; 文本形式的邮件</code></p>
<p>文本形式的邮件里面的内容可以为空，这里的内容是记录该用户所有的登录记录。</p>
<p>只需要在当前用户(这里以test用户为例)主目录下的<code>.bashrc</code>文件添加下面这些内容即可
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="subst">$(who am i)</span>&quot;</span> &gt;&gt; /home/test/login_history.log</span><br><span class="line">mail -s <span class="string">&quot;<span class="subst">$(who am i)</span>&quot;</span> 手机号@139.com &lt;/home/test/login_history.log</span><br></pre></td></tr></table></figure></p>
<p>这样每一次test用户登录都会发邮件到139邮箱，邮件主题是这次登陆的一些信息，正文内容则是这个用户的所有登录记录。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>投资这件事(1)-认知与心态</title>
    <url>/2022/05/04/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B(1)-%E8%AE%A4%E7%9F%A5%E4%B8%8E%E5%BF%83%E6%80%81/</url>
    <content><![CDATA[<p>从年初了解 <a href="https://youzhiyouxing.cn/materials">有知有行</a>
开始，断断续续看了不少上面的内容: 听完了里面投资第一课, E
大干货合集、投资知识体系里的文章也基本是已读状态，一直处于输入的状态;
感觉是时候该 connect the dots，形成一个更系统的框架融入自己的知识体系中,
于是便有了这个系列的文章。</p>
<p>这个系列的文章绝大部分内容来自于有知有行，也会有一些笔者深究后调研的内容，且按照笔者的理解划分为：认知与心态、概念与常识、买与卖三大模块。妄图将投资这个大话题以及有知有行的编辑们整理的上百篇文章浓缩到这篇小小的笔记中，自然无法面面俱到，所以这篇文章还是会挑选笔者关注的一些内容，更详细的内容可参考有知有行以及本文里的相关引用。</p>
<p>本文是认知与心态的部分，主要是投资前的心理建设部分，包括对待财富、投资的认知，投资时的心态管理(收益与风险的预期、投资的时间周期)等。</p>
<span id="more"></span>
<h2 id="关于财富">关于财富</h2>
<p>财富的意义不用赘述，绝大部分人的绝大部分时间都花在了这件事上，这里主要讲
2
部分内容，一是聊聊财富自由这个老生常谈的话题，二是为了达到自由往往需要经历的财富积累环节。</p>
<h3 id="多少钱才算自由">多少钱才算自由</h3>
<p>财富自由，是一个老生常谈的问题，每个人对这个问题都有自己的答案。对于当前笔者而言，<strong>财富自由不意味着能得到什么东西，而是意味着拒绝什么</strong>，比如说拒绝一份强度高但是成长性弱的工作、拒绝在生病时因囊中羞涩而得不到治疗的窘境等，不被某些东西约束，才是笔者认为的自由。</p>
<p>而看着各种把杠杆拉满去买房，因为失去现金流而断供的例子，比如知乎上的<a
href="https://www.zhihu.com/question/305583541/answer/561830151">年底被车企裁员，房贷还不起怎么办？</a>回答，以及笔者在写这篇博客时,
各大互联网公司因为裁员而导致断供的各种新闻，笔者就有个疑问：把未来三十年未知的现金流作为赌注去拉满杠杠，来买个落地安身之处，因为房贷而活得小心翼翼，算是真的自由吗？</p>
<p>另外，从个人角度来看，当前的财富是否能够让其自由，本质上跟这个人的欲望有关，E
大的微博 《 <a
href="https://weibo.com/5687069307/Kff5FkuD0?ref=collection&amp;type=comment">一个人缺不缺钱与欲望相关</a>》也里讲了类似的观点,“欲望如果太多，无论你拥有多少，你都是缺乏的、焦虑的”</p>
<p>然而，这个问题的吊诡之处在于，人是欲望驱动的动物，缺少了多巴胺带来的那种冲动，人很容易裹足不前，那该怎么破？这篇文章《<a
href="https://youzhiyouxing.cn/materials/1210">要多有钱我们才会感到满足？——满足的多世界理论</a>》给出了一个思路，笔者的理解就是通过自我察觉，<strong>问清楚自己到底是什么在驱使你的欲望：是你的真我，还是被规训的思想？</strong></p>
<p>关于这部分，在《<a
href="https://youzhiyouxing.cn/materials/110">金钱的价值究竟是什么</a>》中也给出了类似的观点，同时给了一个衡量标准</p>
<blockquote>
<p>很多人觉得财务自由遥不可及，得几千万，还有说几个亿的，其实根本不用那么多。不说什么大富大贵，单单是让自己的
“睡后收入”
超过目前的工作收入，让我们有能力选择更适合自己的事业、可以根据意愿选择和谁在一起度过时光，对于生活就已经是巨大的助力。</p>
<p>财务自由为的不是想要什么就有什么，而是当有东西不想要的时候，你能有底气拒绝。人的欲望永无止境，但是拒绝糟心事，真的没多难。</p>
</blockquote>
<h3 id="财富的积累">财富的积累</h3>
<p>获取财富的途径从本质来说就是提供他人需要的服务，或者通俗点说就是卖东西，知乎上的<a
href="https://www.zhihu.com/question/37050422/answer/95982957">这个回答</a>概括了常见的四种手段：卖信息、卖钱、卖他人的注意力、卖自己的时间。当然，这里说的只是个人的财富积累，如果放到更宏观的范围，财富来源于生产效率的提升，这部分可参考
《<a
href="https://youzhiyouxing.cn/materials/182">钱是从哪儿来的</a>》</p>
<p>常说的打工人就是在卖自己的时间，除了这个途径外，对于绝大部分人，比较可行的方法，只能是稍微节约一点，然后拿着一点本金去投资，也就是上面说的卖钱。而卖钱其实也依赖着你的积累下来的本金，所以财富的积累是一个绕不过去的问题</p>
<p>如何做好财富的积累？《<a
href="https://youzhiyouxing.cn/materials/849">关于财富和消费</a>》和
《<a
href="https://youzhiyouxing.cn/materials/847">尽早投资，慢慢变富</a>》都给出了一些建议，笔者整理如下</p>
<ul>
<li><strong>积少成多</strong>;
无论你的收入是多少，除非真的特别特别少，每次拿到任何收入，都强制性存起来至少
20%,
然后用适当的精力稍微学点理财的知识，选择一些相对安全的方式，把你的钱投出去，股票、基金、债券、余额宝，甚至房地产……然后好好工作，继续提升自己，多挣点，然后多存点，多投点……</li>
<li><strong>尽早开始</strong>;
一个是复利(复利其实并没有那么神奇，后面会详细说)，一个是给自己尽早试错的机会，《<a
href="https://youzhiyouxing.cn/materials/99">为什么说投资要趁早</a>》</li>
<li><strong>开源</strong>：要么在本行业努力，争取做到前列，拿到更高的回报。要么利用业余时间做一点自己喜欢的副业，增加收入。主业
+ 副业 +
金融投资，一个人变成三个人，财富积累自然快。收入越多，结余越多，距离自己的目标就会更近。</li>
<li><strong>节流</strong>；不要被消费主义洗脑，消费主义的形式太多了无法一一列举，具体可以参考这个问题下的回答,
<a
href="https://www.zhihu.com/question/59001664">有哪些专门为中产阶级量身定制的消费陷阱？</a></li>
<li><strong>理性投资</strong>。辛苦积累的财富，迅速消失只有四个方式：黄、赌、毒，以及乱投资。</li>
</ul>
<p>虽然上面的两篇文章强调了财富积累的重要性，但是也强调了存钱、节流这个环节过犹不及</p>
<blockquote>
<p>不要存太多。除非你收入特别高，真的花不完。一般的工薪阶层，不要存超过
40%。我这人最相信「平衡」两个字。<strong>生活是用来享受的，金钱是我们的奴隶，不是我们的主人。在先把那部分投资的钱存好后，剩下的就用来好好生活，享受人生。为了投资，牺牲生活，得不偿失</strong>。终有一天，你会发现，你的工资与你的投资收益相比，已经微不足道了。</p>
<p>不要很痛苦地做一件事。比如说很痛苦地坚持攒钱，很痛苦地面对亏损，很痛苦地学习和投资，很痛苦地工作等等。因为持续痛苦地做一件事，大概率不会有太好的结果。也许在你的心中，坚持这件事的未来是非常光明的。但是，也许<strong>你的意志并没有你自己想的那么坚强。终有一天，稻草压倒了骆驼，爆发出来的负面情绪可能会让你觉得过去的坚持都是无用、可笑的</strong></p>
</blockquote>
<p>另外,
关于财富的积累，知乎上的这个回答也很好，基本也包含了上面说的开源节流的思想，同时也外延了婚姻、生娃等抉择，强烈推荐阅读，<a
href="https://www.zhihu.com/question/23444019/answer/28016620">23 岁到
35 岁该如何实现资产增值？如何不陷入结婚生孩子买房的恶性循环中？ -
李艾维的回答 - 知乎</a></p>
<h2 id="关于投资">关于投资</h2>
<p>为什么要投资，为了赚钱啊；前面也提到了，搞钱的手段里，卖钱是普通人最可行的途径之一，而《<a
href="https://youzhiyouxing.cn/materials/847">尽早投资,
慢慢变富</a>》里面给了如下这个说法，其实就是强调了常说的被动收入的重要性</p>
<blockquote>
<p>穷这个字，底下是个「力」字。富呢？底下是个「田」字。什么意思呢，意思就是，你朝九晚五，辛苦劳作，每天起得比鸡早，睡得比狗晚，最后大概率还是穷。因为你是在出卖体力，手停口停。
然而有资产的人呢，有房的收房租；有股票的拿股息，碰上牛市翻几倍；有公司的雇一帮人为自己挣钱……当你的资产大到一定程度，你就变成了「富」人，因为你有了「田」，于是你可以恬不知耻不劳而获地成为社会的寄生虫了。</p>
</blockquote>
<h3 id="神奇的复利">神奇的复利？</h3>
<p>说到投资，往往少不了的一个概念就是复利，几乎所有的投资入门的文章都在强调着复利的重要性，但是复利真的有那么神奇吗？</p>
<p>在这之前，我们先看下由复利这个概念衍生出来的一个励志公式，即每天进步一点点，一年后的变化是巨大的，<code>1.01^365 = 37.7834</code>，反之则是
<code>0.99^365 = 0.02551</code></p>
<p>这个公式初看时也许能给人打满鸡血，但是仔细思考便会发现其中的 2
个逻辑漏洞</p>
<ol type="1">
<li>指数级增长要求每天都在昨天基础上提升 1%,
这显然是不现实的，加法增长更加符合个人的成长</li>
<li>增长是有饱和区，或者说瓶颈期的，增长到一定阶段大概率会出现疲软阶段,
增长曲线会是 s 型而不是指数型的</li>
</ol>
<p>《<a
href="https://youzhiyouxing.cn/materials/101">你看到的神奇复利都是骗人的</a>》里，就针对这个问题做了拆解，我们可以把复利公式拆成如下形式</p>
<p><code>复利 = 本金 × (1 + 收益率)^时间</code></p>
<p>可以看到，关键因素在本金、收益率和时间，对这三个因素进一步分析，便能得到如下结论</p>
<blockquote>
<ol type="1">
<li><p><strong>足够多的本金很重要</strong>。本金的增加并不是理财能带来的，是要你不断努力去从外部获取。现在市面上<strong>各种沙雕的理财培训，坏就坏在他们只给你讲复利的重要性，却从来不告诉你，你那点本金，复利上天也没多少</strong>。</p></li>
<li><p><strong>时间周期要拉得足够长</strong>。“一年里，每天都比前一天进步
1%“”这件事情是极不合理的。你可能会说，我每天能比昨天多背 5
个单词啊？不难啊？抱歉，这是线性叠加，不是复利。而且，不光不是复利，你还会背的越多，忘的越多。<strong>365
次方的确是非常美好的想像，可惜现实生活中并不存在。比较合理的算法，应该是用
「年」 为单位。这样你会发现，要达到 365
次方，你大概需要十辈子</strong></p></li>
</ol>
<p>(3)<strong>收益率往往被高估</strong>。做任何复利增长的曲线的时候，都会假设一个
10% 或者 15% 这样的增长率。但是，在真实世界中，你不但找不到 20%
的利率，你也找不到 15% 的利率，你甚至找不到 10% 的利率。</p>
</blockquote>
<p>这里并不是要否定复利这个概念，而是需要强调如果你真的相信复利增长曲线，那你就应该接受一个现实：<strong>变富是需要慢慢实现的</strong>（这部分后面会详细说）。这个慢慢，可能是三年五年、更可能是十年二十年的持之以恒丝毫不敢懈怠。</p>
<h3 id="管理好预期收益率">管理好预期收益率</h3>
<p>预期很重要，预期过高，带来的是失落，预期较低，带来的也许是意外的小惊喜，这是个公理，不止适用于投资</p>
<p>前面提到计算复利时收益率往往被高估，那在投资中的预期收益率是多少才合理呢呢？《<a
href="https://youzhiyouxing.cn/materials/185">股票的预期收益率应该是多少？</a>》里从宏观经济出发分析了这个值，先说结论：<strong>8%～10%
的长期年化收益率是可以预期的</strong></p>
<p>首先是“长期年化”这个词，这个把时间拉到以年为维度，身边经常能听到有人赚
20%、50%，动辄翻倍的也不在少数，这里很有可能是 1 个月或 1
笔买卖的收益，但均摊到一年，未必就是这么多，甚至可能是负的。</p>
<p>而从宏观经济角度来说，整个经济体的增长，是每个企业、每个劳动者共同努力不断创造财富的结果，量化的指标就是
GDP（国内生产总值）。过去 20 年，中国 GDP 年均增速在 9% 左右。如果把 GDP
增速理解成「所有大大小小的企业增长速度的均值」，那么投资到运营水平更高的企业也会获得一些超额收益。文章里给的经验，8%～10%
的长期年化收益率是可以预期的。</p>
<p>8%～10% 的估算逻辑就是这样来的，而如果进一步深挖，文章里使用 ROE(<a
href="https://www.investopedia.com/terms/r/returnonequity.asp#:~:text=Return%20on%20equity%20%28ROE%29%20is,the%20return%20on%20net%20assets.">Return
on Equity</a>) 这个指标来做了估算，ROE
通俗来说就是股东放在公司的每一块钱，能产生多少的回报。所以查理·芒格说过，一只股票的长期回报率，基本会和企业长期实现的
ROE 靠拢，文章里举了一个咖啡店的例子，值得一看。</p>
<p>文章还提到了长期坚持“低买高卖”，并且系统性地选到表现比较好的公司，我们就有可能把预期收益率拉高到
12%～15% 的水平。那15%
的长期收益率高不高？其实非常高了。股神巴菲特这么多年的长期收益率，也差不多就是
12%～15% 的水平</p>
<p>另外，E 大的文章《<a
href="https://youzhiyouxing.cn/materials/660">请把预期收益率降下来</a>》提到了类似的观点，这里不赘述了，只摘录下面这段对笔者比较有启发的话</p>
<blockquote>
<p>别跟别人比赛。不要在熊市中安慰自己，大盘跌了
60%，我只赔了55.5%。我跑赢了大盘。那没有任何意义。不要在牛市里懊恼，大盘涨了
100%，我只赚了
80%，我真是个loser。看看新闻，那么多人发了大财，为什么不是我？<strong>记住，你要的是绝对收益。要比，你只需要跟自己比——我的资产，有没有比上个月、上个季度、去年增加了？</strong></p>
</blockquote>
<p>这段话其实跟张潇雨的播客 《<a
href="https://www.xiaoyuzhoufm.com/episode/61518f2a64cb39f688d0786b">场上没有别人</a>》里的观点很相似，那就是投资可能是每个人一生中最能掌控的事情之一，这个过程不需要排名，不需要跟外部比较，只需要对自己诚实。</p>
<h3 id="接受慢慢变富">接受慢慢变富</h3>
<p>看了上面的对复利的拆解和预期收益率，我们不得不接受一个事实：那就是变富的过程会很漫长。上面的《你看到的神奇复利都是骗人的》里也提到了：巴菲特的巨额资产，绝大部分都是在他
50 岁以后赚到的</p>
<p><img src="https://wulc.me/imgs/InvestMent_Buffett.jpg" height="50%" width="50%"></p>
<p>《<a
href="https://youzhiyouxing.cn/materials/98">接受了慢慢变富，才能越来越有钱</a>》里提到了这个观点</p>
<blockquote>
<p>投资和做其他生意相比，优势绝不在于来钱快，投资的优势在于可以一直做下去，而且可以慢慢越做越大。而大部分做生意的人，来钱都比投资快，但很难长久，即使可以做的久，也基本保持在一个规模，没法越做越大。</p>
<p>所以我们做投资要发扬投资的优点，就是要有耐心慢慢来，把财富越积越多，而速度恰恰是投资的缺点。而很多人完全搞反了，只想快速赚一把就走人，这完全是避开了投资的优点，而发扬了投资的缺点，逆势而行。</p>
</blockquote>
<p>想要接收慢慢变富，行动上有几点笔者觉得较为重要：闲钱投资、别加杠杆和停止内耗</p>
<ul>
<li>闲钱投资</li>
</ul>
<p>想要有好的心态，一定要用闲钱投资，什么是闲钱？就是短期内亏了也不会影响生活的钱，这一点非常重要，否则心态上很容易崩，也很容易造成主动亏损。这一点在半佛
2018 的 live 《<a
href="https://www.zhihu.com/lives/927612860245364736">2018，如何通过投资理财让自己过得更好？</a>》里听到过，时至今日仍然印象</p>
<ul>
<li>别加杠杆</li>
</ul>
<p>另一点就是不要加杠杆了，还是上面的那个
live，印象深刻的一句话是“<strong>投资里，从 1 块到 100，1 万，1000
万都是有可能的，但是从 0 到 1 是不可能的</strong>”，E 大的文章 《<a
href="https://youzhiyouxing.cn/materials/661">只要本金还在，就有无数机会</a>》也是相同的观点</p>
<ul>
<li>停止内耗</li>
</ul>
<p>在播客《<a
href="https://youzhiyouxing.cn/materials/1003">孟岩对话张潇雨：在投资这件事儿上就别折磨自己了</a>》里,
提到了如下观点，也是笔者认为心态上比较重要的一点</p>
<blockquote>
<p>我们在生活中不要自己找新的事情折磨自己，给自己找麻烦。什么意思呢？就是我总觉得好多人学投资，是苦大仇深的，是来这翻身来了。周围的人都不理解自己，投资变成了一个出口。努力学习没有问题，但没必要卷，<strong>没必要非要在这件事情上证明什么。因为你证明不了什么。而是要在这个过程中去了解自己、舒展自己</strong>。在一个没有那么多内耗和磨损的情况下去做这些事情，这个事情才会越做越顺，越做越好。
同时，在这个过程中学会不去苛责自己，不去过度地评价自己，想那么多有的没的。这个是非常非常重要的。</p>
</blockquote>
<h3 id="价值投资长期投资">价值投资？长期投资？</h3>
<p>在投资里，经常能听到的一个词就是价值投资，同时也常伴随着的另一个词是长期投资；那价值投资里的价值指的是什么？多长时间的投资才算长期投资？价值投资是否意味着长期投资？</p>
<p>如果用 Wikipedia 上对<a
href="https://zh.m.wikipedia.org/zh-hans/%E5%83%B9%E5%80%BC%E6%8A%95%E8%B3%87">价值投资</a>定义，主要特点就是对于买入价格与公司资产估值之间的差距必须有足够安全边际</p>
<p>在 E 大比较早之前写的《<a
href="https://youzhiyouxing.cn/materials/665">我所理解的价值投资</a>》，定义也是类似的</p>
<blockquote>
<p>价值投资，不必然是长期投资，不能用时间长短来衡量；
价值投资，不必然是低市盈率投资，不能用市盈率来衡量；
价值投资，必然是以远低于股票内在价值的价格买入，要学会如何衡量企业真正的内在价值；
价值投资，必然是以保住本金为前提，以足够的安全边际为度量衡，取得合理的投资回报。</p>
</blockquote>
<p>更通俗来说就是低买高卖，但是这个事情很难，难在哪里？文章里给出的答案如下(但是笔者觉得更难的是比较难判断是当前是贵了还是便宜了，这部分在买与卖会介绍一些参考指标)</p>
<blockquote>
<p>就难在一个字：忍。</p>
<p>贵的时候，忍着不买。不管别人如何冷嘲热讽，坚持内心的标准。只要不够便宜，我就是不买。</p>
<p>不贵的时候，忍着不卖。抗拒自己所有的人性，拿着自己看好的标的。死死拿着，哪管你大浪滔天？</p>
</blockquote>
<p>值得注意的是，价值投资并不是唯一的投资方式，也不是最好的投资方式，或者说没有最好的投资方式。常常被自诩为价值投资者们嗤之以鼻的趋势投资，在
E 大上面的文章和 《<a
href="https://youzhiyouxing.cn/materials/666">我所理解的趋势投资</a>》中，是这么说的</p>
<blockquote>
<p>趋势投资不去管价值，主要任务是判断趋势，趋势延续就继续持有/空仓，趋势改变就卖出/买入。在趋势投资者的眼中，价格有时候倒是高了更值得买入。比如雪球的28策略，你会发现历史收益也会很不错。</p>
<p>价值和趋势我不能说谁一定好，适合你自己就好。但是，有一点请注意。<strong>千万不要某个品种一路上涨你总是狠不下心去追，结果它涨了很多后跌了一点趋势已变的时候你就抱着价值投资的信心接了进去。然后它一路暴跌已经很有价值的时候你又变成了趋势投资者，觉得趋势很差不如卖掉以后走势好了再买</strong></p>
<p>价值投资者的势，应该是对于一个国家，一个地区，一个公司真正大势的把握。</p>
</blockquote>
<p>而说到长期投资，各种投资课程、投资大师，都会强调长期投资、长期持有、长期规划的重要性，多久才算长呢？
《<a
href="https://youzhiyouxing.cn/materials/188">投资多久才算长期？</a>》针对美股和
A 股的数据做了回测，给出的大致结论无论是美股还是 A股，持有 10
年以上，收益都是正的。</p>
<p>如果说长期投资能拿到收益，那为什么长期投资还那么难坚持呢？文章给出了
2 个原因</p>
<p>(1)<strong>投资回报在时间上的分布不均匀</strong>，即主要收益是由 1%
的交易日贡献的(所以需要保证“当闪电劈下来的时候，你最好保证自己在场”)。这导致了不管对于市场，还是对于个股，很可能我们大部分时间都在进行无聊的等待，而真正的上涨（或者下跌），只是在很短的时间内发生的。换句话说，等待相当煎熬，所以很多人就会选择卖出，然后去追新的热点
(2)<strong>市场总是轮动的</strong>，这里的轮动，指的可能是资产表现的轮动，可能是投资风格的轮动，也可能是行业板块的轮动等等，其实也就是周期的一种体现（关于周期在后面的概念与常识中会讲到），这导致了当前市场最受到追捧的那个主题，和你喜欢或者擅长的主题不一致，那么再坚定的人，也会对自己的持仓产生怀疑。</p>
<p>了解了这些后，文章给了如下建议</p>
<blockquote>
<p>长期投资需要的时间。这些因素都是客观的，并不会因为我们希望快速变富而产生变化。唯一能控制的，是投资的本金。
因此，对我们来说，可能更重要的事情是，<strong>放下焦虑、专注在工作和生活上，在我们自己不断变得更好的同时，去收获更多的工资、股权等其它收入。与此同时，做好资产配置，根据自己的兴趣慢慢地拓展能力圈，在合理的范围内提高我们能获得的收益率</strong></p>
</blockquote>
<p>而如果针对基金这个投资标的，《<a
href="https://youzhiyouxing.cn/materials/100">基金投资应该持有多长时间？</a>》给了更详细的数据的回测和分析，给出的结论如下</p>
<blockquote>
<p>回到「基金应该持有多长时间」这个问题，答案如下：</p>
<p>（1）我们需要刷新一下「长期持有」的概念，<strong>8
年以上</strong>才是真正意义上有稳定绩效表现的「长期投资」，即至少持有 2
个以上完整的周期。 （2）如果你还接受不了 8
年以上的周期，那么你可以<strong>考虑持有 4～5
年（回报效率最高），而且，务必做个「战略性择时」，千万别在估值高点买入基金</strong>！
（3）在合适的点位买入，并持有足够多的周期，这是基金投资成功的关键。</p>
</blockquote>
<p>了解上面的价值投资和长期投资后，我们知道两者没有必然的联系，很多价值投资者在下跌时自称的长期投资，很多时候都是在自欺欺人而已</p>
<h2 id="重新认识你自己">重新认识你自己</h2>
<p>很多时候，我们都认为自己对自己都是非常了解的，但事实上并非如此; 2022
年上半年，股市有了几次大跌，孟岩在 03/17 的写的《<a
href="https://youzhiyouxing.cn/materials/1198">恐惧</a>》里面有段话是这样的</p>
<blockquote>
<p>在牛市的时候填写调查问卷，大家都觉得下跌 30%
完全能够承受，但真的到了熊市，即使只跌了 15%，可能你已经非常恐慌了。</p>
<p>另外，在风险测评问卷上填写下跌 30% 很简单，但你很容易低估真的下跌 30%
会对你的心理造成什么样的影响。我们可以在脑海中做压力测试，但无法测试当我们投资失败回到家，看到家人失望表情时的心情。</p>
</blockquote>
<p>出现这个问题可能原因是多重的，比如说可能仓位控制不合理，杠杆太高等；而其中的一个不可忽略的原因就是我们其实并没有真正认识自己，或者说不清楚极端环境下自己会作出何种表现</p>
<p>文章的结尾写到：“恐惧是真实的，也是宝贵的。它是一种微妙的身体信号，也是检验我们是否真的相信的试金石。记住那些恐惧的时刻，让恐惧穿过自己”。其实就是建议我们在极端情绪下进行自我察觉，学会体会自己的情绪，与自己的情绪和平共处。E
大的《<a
href="https://youzhiyouxing.cn/materials/750">聊聊投资中的那些恐惧</a>》里则提到了面对这些恐惧一些更详细的方法</p>
<blockquote>
<p>从小仓位开始，训练自己能享受盈利。不要怕回吐利润。坚定一点：只要你买的不贵，最终一定会一路向上。</p>
<p>面对资本市场的危机，我的建议： 首先，不要慌。
第二，冷静地看自己手里的东西。有没有可能死的，有没有特别贵的。如果有，找机会处理掉。
第三，保命。 第四，找机会进场捡漏。如果没有能力识别，就不捡，保命。
第五，坚持不慌。一开始不慌，最惨的时候更不慌。再次审视手里的东西。跌得很惨，但是会不会死。不会就不用慌。尝试捡漏。</p>
</blockquote>
<p>另外，关于察觉并自己的情绪，推荐读一下这个回答，<a
href="https://www.zhihu.com/question/20789554/answer/132621010">怎样进行良好的情绪管理？</a>，里面提到的三步法值得实践一下</p>
<p><img src="https://wulc.me/imgs/Emotion_control.jpg" height="50%" width="50%"></p>
<p>回到投资上，《<a
href="https://youzhiyouxing.cn/materials/524">认识你自己，才是投资这件事的终极乐趣</a>》里也提到类似的问题</p>
<blockquote>
<p>无论是什么样的投资，要赚钱的路径只有一个：在价格低的时候买入，价格高的时候卖出。有趣的是，大多数散户回过头观看自己的行为，结果常常是反过来：他们在价格高涨时杀入市场，迅速下跌时期匆匆离场。也就是说，他们在高买低卖。</p>
<p>是恐惧驱动了我们的大部分行为。经历过才知道，真正能做到低买高卖绝非容易。它需要在还没有媒体宣传和大众舆论的时候就有独立思考的精神，需要耐得住寂寞，忍受住波动，需要不执着，拿得起放得下，需要随时准备承认自己错了，需要远见、信心、谦逊、坚持……</p>
</blockquote>
<p>另外，文章还提到了一个观点：<strong>无论是有限游戏还是无限游戏，属于你的机会，一辈子就那么几次。我所说的机会，是长时间，相对意义上改变结局的大机会。大的机会是时代造就的，不是你自己。</strong>那这些机会长啥样呢？文章给了几个例子：</p>
<ul>
<li>信息不对称，特指找到和自己相关的，熟悉的市场</li>
<li>市场失效，一个新兴市场在刚开始常常是不够有效的</li>
<li>技术、算法和投资理论，但文章指出了“投资圣杯”根本不存在，任何投资理论都是暂时的，且没有高低贵贱之分</li>
</ul>
<p>至此，文章提出说真正的圣杯是<strong>对于自我的了解</strong></p>
<blockquote>
<p>向内看。在大部分人向外求索的时候，你能明白那不可能成为真正的钥匙，最多只能让大家站在同一起跑线上，而真正的「圣杯」是对自我的了解，那本身就是一种优势</p>
</blockquote>
<p>此外，文章里提到的创业的例子，笔者比较有共鸣，因为笔者前一段时间也常常在问自己，为什么懂得很多道理,
但是仍过不好这一生？原因就是知易行难，懂得的成本太低了，但是真正执行的成本太高了，这个成本意味着长期坚持，意味着要反馈频次低的情况下重复做着同一件事，这需要一种愚。</p>
<blockquote>
<p>在创业的那几年，我读过很多书，见过很多人，也曾试图找规律，到底什么样的创业者才能成功？聪明的？学历高的？创业经验丰富的？有人格魅力的？能忽悠的？……</p>
<p>终于有天我体会到：太聪明的人，并不适合创业。因为他们能在很短的时间内分析出利弊，甚至计算出成与不成的概率。他们能设计出漂亮的商业模式，能说服一流的投资人，能招到很好的团队。<strong>可是，他们不够愚痴，不够执拗</strong>。</p>
<p>世界上的聪明人那么多，如果机会是能分析出来的，为什么轮到你？最顶尖的创业者，一定在某种程度，某些方面有一种傻劲儿。他们并非料事如神，占尽先机。他们一定在一段或长或短的时间里，做了所有聪明人都不愿意做的事。他们是所有理性人中的非理性者，把脑子无法算计的东西，甩手交给了心。</p>
<p>这种傻来源于什么呢？</p>
<p>某种热爱。某种感性。某种直觉。</p>
</blockquote>
<p>回到主题，投资这个过程，也是一个不断自我觉察的过程；金融市场，也是一个认识自我的绝佳修炼场，场上只有你自己，在那些大跌和大涨的日子里，体会自己的恐惧和狂喜，重新认识你自己。</p>
<h2 id="小结">小结</h2>
<p>本文主要讲了投资前的一些心理建设部分，主要包括对财富、投资的理解，对投资时长、收益率的预期，如何通过投资去重新认识自己等。</p>
<p>如果说投资是一场游戏，收益是我们的得分，那么在游戏前，做好心理建设和必要的认知，放下焦虑，才能享受这场游戏的美妙，也能从这场游戏中重新认识自我。</p>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>投资这件事(3)-买与卖</title>
    <url>/2022/07/02/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B(3)-%E4%B9%B0%E4%B8%8E%E5%8D%96/</url>
    <content><![CDATA[<p>从年初了解 <a href="https://youzhiyouxing.cn/materials">有知有行</a>
开始，断断续续看了不少上面的内容: 听完了里面投资第一课, E
大干货合集、投资知识体系里的文章也基本是已读状态，一直处于输入的状态;
感觉是时候该 connect the dots，形成一个更系统的框架融入自己的知识体系中,
于是便有了这个系列的文章</p>
<p>这个系列的文章绝大部分内容来自于有知有行，也会有一些笔者深究后调研的内容，且按照笔者的理解划分为：认知与心态、概念与常识、买与卖三大模块。妄图将投资这个大话题以及有知有行的编辑们整理的上百篇文章浓缩到这篇小小的笔记中，自然无法面面俱到，所以这篇文章还是会挑选笔者关注的一些内容，更详细的内容可参考有知有行以及本文里的相关引用。</p>
<p>本文是买与卖部分，也是实操部分；投资赚取的收益本质上就四个字：<strong>低买高卖</strong>，虽然只有四个字，但是如果要做好这个事情非常难，本文试图为这个没有标准答案的问题寻找一些可参考的解。</p>
<p>这个系列前面两部分的内容可参考</p>
<ul>
<li>《<a
href="https://wulc.me/2022/05/04/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B%281%29-%E8%AE%A4%E7%9F%A5%E4%B8%8E%E5%BF%83%E6%80%81/">投资这件事(1)-认知与心态</a>》</li>
<li>《<a
href="https://wulc.me/2022/06/18/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B%282%29-%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%B8%B8%E8%AF%86/">投资这件事(2)-概念与常识</a>》</li>
</ul>
<span id="more"></span>
<p>如果将“低买高卖”进一步拆解，我们能够进一步拆成以下几个直观问题</p>
<ul>
<li>买什么</li>
<li>什么时候买, 买多少</li>
<li>什么时候卖, 卖多少</li>
</ul>
<p>而这几个问题又涉及到实操中常说的资产配置、仓位控制、估值等实操部分，下面会详细介绍这几部分，并在最后尝试回答上面几个问题。</p>
<h2 id="资产配置">资产配置</h2>
<p>资产配置本质上就是在做分配，即把我们需要投资的金额分配到各种投资标的上，具体的投资标的在上一篇文章《投资这件事(2)-概念与常识》中已经提到了，基本就是：股票(A股、美股、港股)、债券(利率债、信用债)、黄金、大宗商品、现金等；每个大类里还可以细分，比如A股可以分成大盘小盘，再加上消费医药这样的长牛指数，美股可以分大盘小盘，美国医药美国消费，美国房地产。在
E 大其主导的长赢计划中，把其投资的标的细分如下</p>
<p><img src="https://wulc.me/imgs/ETF_150.png" height="50%" width="50%"></p>
<p>上图从内开始第二圈的类别，分别是：<strong>A股、货币、债券、海外新兴市场股票、海外成熟市场股票、商品</strong>。</p>
<p>第三圈更加细分，在以上大类中，再次细分为：<strong>A股价值股、A股大盘股、A股中小盘股、A股行业股、国内债券、海外债券、港股、海外互联、欧洲、美国、原油、黄金</strong>。</p>
<p>这就是资产配置，关键在于<strong>区分大类，配置比例</strong></p>
<p>资产配置的一个重点是资产相关性，即需要<strong>将资产分配到相关性低的品种</strong></p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/706">详解家庭资产配置</a>》中，有一张资产相关性的参考图，表里的数字表示资产之间的相关性，相关系数的计算方法比较多，笔者猜测这里是使用了<a
href="https://zh.wikipedia.org/wiki/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%A7%AF%E7%9F%A9%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0">皮尔逊相关系数</a>，取值在
-1 和 1 之间，表示从负相关到正相关，绝对值越大，相关性越强</p>
<p><img src="https://wulc.me/imgs/property_relation.png" height="70%" width="70%"></p>
<p>文章的的观点是把资金分散到相关性很低的品种中，这样当某个品种表现不佳时，另一个品种可以将我们的收益率保持在不差的水平，其实就是风险分散</p>
<p>文章里以上证 50 和中证 500 的相关性作为例子，说明了要同时持有大小盘这
2 种类型的资产</p>
<blockquote>
<p>在某些时段，大、小盘股票会表现出不同力度的上涨，这种上涨是很难预期的。所以，<strong>最佳策略是同时持有大、小盘，动态平衡。谁涨得多就卖一些，买入涨得少的</strong>。在熊市初期与中期，尽量多持有大盘股指数。跌幅会比小盘股指数小很多。在估值回归到正常情况下，开始加大力度加仓小盘股。未来这部分投资的弹性会远大于大盘股。</p>
</blockquote>
<p>那 A 股的大、小盘具体有哪些选择？《<a
href="https://youzhiyouxing.cn/materials/706">相关性与资产配置（4）</a>》里指出，大的选
50 和 300，小的选 500 和创业。另外，还提到了行业指数是否需要考虑</p>
<blockquote>
<p>我个人认为，做为宽基指数的补充，<strong>行业指数非常有必要配置</strong>。尤其是一些长期必然走牛的行业。这些行业的持有，应该比宽基指数更加坚定。<strong>不到出奇高估的时候，绝不卖出,宁愿做过山车也要持有</strong>。当然，可以用我们的策略平滑收益。比如目标市值。</p>
<p>当然，<strong>行业指数配置的比例要低于宽基</strong>。可以考虑的是医药、消费大类下的细分指数，或者干脆就是医药和消费指数。信息指数与创业板指数走势相关性
0.99，确实没有必要重复配置。</p>
<p>另外像养老、环保这样非基础性行业，偏向概念性的指数，也可以在特定时间段配置</p>
</blockquote>
<p>这样，未来路线图已经清晰：50、300、500、创业、医药、消费。当然，你如果就选其中的几个也没有任何问题,比如你觉得就买
50、500，或者 300、创业，都没有问题;
关键在于，<strong>一定要大小搭配</strong></p>
<p>上面是 16 年的结论，而在 21 年，《<a
href="https://youzhiyouxing.cn/materials/706">详解家庭资产配置</a>》针对资产相关性的结论进化成了：<strong>相关性分析更多的应该是作用于大类资产配置，如股（国内外）、债、金、油等。具体到每一个小类品种配置，相关性分析的意义则小了很多</strong>。因为A股市场很多时候是齐涨共跌，只是每个品种涨跌幅度不同，这样就无法由相关性分析来体现差异性</p>
<p>另外，上面讲的基本上都是长期投资中的资产配置，而在有知有行中，则把这个范围拓展得更大，即把一个人的所有资产分为了四笔钱：<strong>长期投资、活钱广利、稳健理财和保险保障</strong>；也是其投资体系中的四大模块，本系列文章讲的基本都是长期投资的内容，其他部分内容可参考
<a
href="https://youzhiyouxing.cn/topics/skeleton/nodes/31">投资知识体系</a></p>
<h2 id="仓位控制">仓位控制</h2>
<p>上面提到了要配置何种资产，紧接着的问题自然就是要配置多少，而这就涉及到尤为重要的仓位配置，这部分会介绍仓位配置的一些基本思路和原则，具体的仓位配置方法也会简单介绍，但是这里的方法也只是一个大的指导。</p>
<h3 id="涨跌都要舒服">涨跌都要舒服</h3>
<p>在《<a
href="https://youzhiyouxing.cn/materials/710">仓位控制的艺术</a>》提到，<strong>仓位是个性化的</strong>，没有一个仓位配置能适合所有人，因为每个人对风险和收益的要求不同。</p>
<p>而投资，首先心里要舒服。因为“你不舒服，你慌乱，你兴奋或者痛苦，就很容易犯大错”，文章给出的实践经验如下</p>
<blockquote>
<p>首先，你要问自己几个问题：如果我手上的股票或者指数，跌了40%，我会不会痛苦？如果我手上的股票或者指数，涨了
40%，我会不会难过？
你的股票跌了，你会痛苦，就说明你的仓位重了；反之，你的股票涨了，你痛苦，说明你仓位太轻。
好了，现在遵照这两个问题答案，<strong>把你的仓位调整到最平衡的位置：也就是说，涨
40% 和跌 40% 的时候，都不是那么难过</strong>。这时候，就合适了。</p>
</blockquote>
<p>在《<a
href="https://youzhiyouxing.cn/materials/758">你凭什么在股市赚钱</a>》中提到的“涨跌都舒服”,
是同样的观点,
同时也指出“很多朋友以为自己舒服了，结果市场跌一跌才发现并不了解自己。我早就跟你说过了，你很可能没有你自己想象的这么坚强。即使现在不难受，随着市场进一步下跌，你才有机会认识真正的自己”，这部分在系列文章的第一篇-认知与心态。里面讲的重新认识你自己是同样观点</p>
<h3 id="满仓与空仓">满仓与空仓</h3>
<p>在《<a
href="https://youzhiyouxing.cn/materials/710">聊聊动态再平衡</a>》和《<a
href="https://youzhiyouxing.cn/materials/711">贪字的二重定义</a>》都提到，满仓或空仓都不是非常理智的行为</p>
<blockquote>
<p>对于一个心智相对成熟的、愿意长期投资的投资人来说，「满仓」、「空仓」都不是应有的状态。不论你的本钱是
10 万，50 万，100 万还是 5000
万。满仓意味着你极度看好后市，空仓意味着你认为下跌不远。基于人类对于预测的没有天分，这样
show hand 的赌博虽然可能赢，但无疑长期来看破产是不可避免。</p>
</blockquote>
<p>关于空仓，则提到有 2
个误区，一是不要空仓等大底，因为没人能预测绝对的大底；另一个则是在极度高估的时候也要保留一些仓位；笔者对这里的第二点存疑，既然都知道是极度高估了，为什么还要留仓位，笔者没亲身经历过大牛市，但是看
E 大的文章在 2015
的狂热时候是都清仓了的，可能这里想表达的意思是总体狂热的市场里也有一些被低估的资产，可以持有这些资产?</p>
<blockquote>
<p><strong>空仓等大底，也是一种贪。只要是贪，就会有风险</strong>。「踏空」在
72 倍 PE 不可怕，如果有些板块十几倍 PE 还不敢买哪怕
1%，那么真的就有点风险了</p>
<p>估值过高的时候大量卖出，但<strong>至少留 15%
仓位永不离场</strong>。朋友们，放心，<strong>长期看，指数会一路上扬</strong>。不信你看看深综指的走势。这
15%
不会让你赔钱。估值回到历史均值附近，开始少量买入。回到大底区域，重仓买入。其他时间，用各种方法保本，赚钱，等待大牛市。通常我的经验是，这样做一轮熊市到最低点总资产减少幅度不会超过
15%。而牛市资产则会增加 N 倍。</p>
</blockquote>
<h3 id="足够的低成本仓位">足够的低成本仓位</h3>
<p>前面虽然提到投资赚取收益的关键在于低买高卖，但是而影响收益除了低买高卖，另一个很关键的因素，那就是具体买多少，在《<a
href="https://youzhiyouxing.cn/materials/709">建立足够的低成本仓位</a>》提到了这一点</p>
<blockquote>
<p>对于大多数普通人来说，进行金融投资活动的重点，我个人认为，应该是「建立足够的低成本仓位」。这里面有两个重点。</p>
<p>第一个是「足够的」。仓位不够，说什么都白搭。<strong>想要实质性地在金融投资中得到足够的回报，仓位一定要够</strong>。我本人除房产外，大概
90%～93% 的可投资资产都在除现金等价物外的金融投资中。大概 70%～75%
的资产都在 ETF
计划中。这十几年的投资经历告诉我，足够的仓位才能在上涨中赚到足够的钱。</p>
<p>第二个是「低成本」。我对控制持仓成本有着异乎寻常的执着，哪怕有时候会错失一些机会，也在所不惜。<strong>低成本持仓带来的好处显而易见：除了会让你赚得更多，也会使你的心态非常平和</strong>。在上涨赚钱的时候更容易拿得住——大多数人赚不到钱的原因，就是某个品种一套十年，好不容易回本后马上卖出，再买入另一个套十年的品种。如果你的成本低，你就会更容易安安静静地等着你的持仓利润不断增长，让利润飞奔。</p>
</blockquote>
<h3 id="分配策略">分配策略</h3>
<p>终于到了具体的分配策略，看了几篇文章总结下来，基本思路就是先分配各大类的比例，然后根据每个大类当前的估值，分配在这个类中应投入的仓位</p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/705">没人能替你做资产配置，除了你自己</a>》和《<a
href="https://youzhiyouxing.cn/materials/1157">细说资产配置</a>》中，就提到了该为每个大类配置的仓位比例</p>
<blockquote>
<p>在你的终极配置中，单个品种配置<strong>不要低于
5%</strong>。低于这个数字对你的资产组合没有意义。然而也尽量不要高于
20%，<strong>最多不能高于
30%</strong>（如果你特别钟爱A股，可以把大、小股票分为单个品种，也就是不要多于
60% 配置）。 在大类投资组合中，仓位在 5% ~ 10%
以内，属于偏小，这样的仓位即使上涨较多，对总收益贡献也不会很大。而如果你的单一品种仓位超过
30%，则一定是过高，万一有个风吹草动，会对你的组合造成非常大的影响。那么总体来说，建议持仓品种的<strong>仓位在
15% ~ 20% 之间，大类品种不超过 6 ~ 7 个</strong>。</p>
</blockquote>
<p>上面的策略是给每个大类分配比例，在分配好大类的比例后，还需要考虑的是每个大类当前的仓位控制：即将分配给当前大类的
15% ~ 20%
的现金，具体该投入多少到大类对应的标的中？答案就是<strong>估值</strong></p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/1144">如何避免底部「吃不饱」？</a>》，给了一个比较简易的仓位配置方法</p>
<blockquote>
<p>根据指数基金历史百分位，进行仓位控制。 如果目前<strong>在历史 50%
的地方，则将仓位控制在 50%。 如果目前是历史 10%，那么给 90%
仓位</strong>。 如果现在是历史 90%，那么就给 10%。 以此类推。
这是中性投资者的仓位，激进与保守，可以分别 ±10%。</p>
</blockquote>
<p>而在《<a
href="https://youzhiyouxing.cn/materials/730">我们任何的买入，都要以估值为基础</a>》则更加细化这个方法</p>
<blockquote>
<p>仓位的确定是看全市场估值。要综合全市场 PE、PB 和加权 PE
五年、十年数据。对于计划来说，<strong>大的原则是：100% -
现处百分位</strong>，得出应该配置多少仓位。这是适合一般投资者的。</p>
<p>比如说，现在全市场估值是 75%，那么 100 - 75 = 25，则一般投资者应配置
25% 仓位。对于计划来说，用得是更加保守的一种算法：在现处百分位还在 50%
以上的时候，配置仓位减半。</p>
<p>那么，上面的公式就变成：(100 - 75) / 2 = 13%。也就是在历史 75%
的时候，配置 13% 仓位。当现处百分位回到 50% 附近，则迅速将仓位补足到接近
50% 的地方。比如可以补到 40%～45%。随着估值继续下降，则完全按照 100% -
现处百分位的仓位配置。到了 35%
以下，则将这个数字艺术性地放大。比如在历史 30% 的时候，应该配置 70%
仓位，但可以在这个时候加大投入，配置 75% 乃至 80%。也就是说，<strong>在
100% -
现处百分位这个公式的基础上，估值高的时候保守配置，估值低的时候激进配置</strong>。</p>
</blockquote>
<h3 id="再平衡">再平衡</h3>
<p>在平衡在之前的文章《<a
href="https://wulc.me/2021/11/28/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%283%29-%E6%8A%95%E8%B5%84%E7%BB%84%E5%90%88%E6%9E%84%E5%BB%BA/">张潇雨的个人投资课(3)-投资组合构建</a>》中也提到了，在《<a
href="https://youzhiyouxing.cn/materials/707">设计适合你自己的资产配置组合</a>》提出了相同的方法论，并且提供了更多细节</p>
<blockquote>
<p>具体方法：用动态平衡的方式，操作优质行业 +
优质增强指基（标准指基亦可，大小平衡，如300 + 500）+ 优质主动基金。</p>
<p>具体操作步骤如下：
首先，确定你的<strong>调仓周期</strong>。最低不要低于三个月，最高不要超过一年。原因我不解释，我建议经验少的朋友可以六个月调整一次。
其次，确定你的<strong>最高、最低仓位</strong>。我建议除非特别激进的朋友，<strong>股票仓位最好不要超过80%-85%。如果你只是个普通投资者，那么
5:5 或者 6:4 都很适合</strong>。
第三，确定你的品种。我的建议是增强或标准宽基指数基金（50、300、500、1000、创业、科创）与优质行业基金结合。有能力可以再去找几个优质主动基金加入配置。这里要注意，这只是我的建议，如果你学有余力，这部分的配置甚至可以延伸到个股上。买了好股票赚钱，同时可以有打新收益。只要是股票类资产，都可以算作仓位。只是我强烈建议
70% 的普通投资者就不要买个股了。
第四，考虑目前合适的仓位。这个可以考虑估值，也可以参考我经常会给出的仓位建议。
第五，定期实施你的计划。</p>
</blockquote>
<p>在《<a
href="https://youzhiyouxing.cn/materials/1141">假如没有下一轮，自己该如何参考长赢进行投资？</a>》，提到类似观点，而且提到了更极致的动态比例的仓位配置方法，但同时风险也会更高</p>
<blockquote>
<p>固定比例配置
根据自己的风险承受能力，确定各大类资产的基础配置比例。风险承受能力低，就多配置利率债。承受能力高，就多配置权益类资产，然后再平衡。
<strong>再平衡从两个角度考虑：空间、时间</strong>。时间好理解，不要太频繁，也不要太久。我看
3
个月到半年比较合适。空间意味着你要给每个品种设置涨跌空间。比如，你给A股设置
50% 配比，结果它几个月涨了 50%，占比已经超过
60%。这时候你就要根据空间原则，将它的持仓占比降下来，卖出一些。</p>
</blockquote>
<blockquote>
<p>动态比例配置
等你有了经验，就可以尝试动态配比。根据每类资产的便宜程度，一定范围内给它不同的占比。比如如你所说，A股估值极低的时候，你给
70% 仓位，极高的时候给
30%。如果你有能力，这样长期看效果会更好一点。但是要注意，这个对于投资人要求极高。没有经验没有能力，很可能弄巧成拙。所以要慎重。</p>
</blockquote>
<h2 id="估值体系">估值体系</h2>
<p>仓位控制中提到每一大类里的仓位控制依赖这个大类当前的估值，那如何估值是一个核心问题，这部分给出了一些参考方法</p>
<h3 id="识别顶部与底部">识别顶部与底部</h3>
<p>在《<a
href="https://youzhiyouxing.cn/materials/1144">如何避免底部「吃不饱」？</a>》中，提到了怎么识别顶部和底部区域，给出了一些可参考的标准，<strong>指数估值，以及估值历史百分位</strong>就是其中一个方法。这个方法是基于历史数据以及“合理”的股市数据，综合考虑一个市场以及一个指数处于合理，又或者过冷还是过热的情况。</p>
<p>这个方法极具指导意义，但不能只靠这个判断，因为还要考虑<strong>投资者情绪以及政策变化</strong>，包括货币政策、财政政策以及专门针对市场的政策。而
E 大在判断 2015 的顶部和 2018 的底部时其实都依赖了这个估值指标, 即 PE 和
PB</p>
<p>在《<a href="https://youzhiyouxing.cn/materials/732">回顾 2015
年的哈迪斯之顶</a>》是这么说的</p>
<blockquote>
<p>中国股市自 1995 年以来，有过三次 <strong>PE 超过 60</strong>
的尖峰时刻，分别是 2001 年、2007 年和 2015 年 其中，尤以 2015
年风云变幻、诡异莫测。 6 月 15 日，两市全市场 PE 超过 72
倍，远远将历史最高抛在身后。随后，暴雨倾盆，泥沙俱下。短短的三周时间内，PE
居然已经跌到了历史均值附近！ 要知道，2001 年，阴跌整整 2 年，才在 2003
年跌破 PE 均值，进入投资区域；2007 年 10 月创出最高后，在 2008 年 5
月才跌破 PE 均值，进入投资区域</p>
<p><strong>A股整体 PE 60 倍，整体 PB 5.5
倍以上，被我定义为「哈迪斯之顶」</strong></p>
</blockquote>
<p>而在《<a href="https://youzhiyouxing.cn/materials/737">2018
年钻石底发车解说</a>》里，是这么说的</p>
<blockquote>
<p>今天数据没出来，但如果尾盘半个小时没有猫腻，那么今天A股全市场
<strong>PB 应该会降至 2.5</strong>
以下了。这是一个标志性的事件，意味着进入<strong>真正意义上的低估区域</strong>。
根据我的评价体系，A股整体即将由「黄金区域」进入「钻石区域」。除非我的评价体系失效了，否则各位投资的A股即将进入一个极其难得的大底区域。
这个区域从 2005 年至今，出现过四次。大致是 2005、2008、2012 和现在
2018。十三年四次，十年三次，其实真的并不容易，各位且买且珍惜。</p>
<p>但是请注意，<strong>「区域」并不意味着不会再跌。区域也是有空间的</strong>。
PB 从 2 跌到 1.5，不考虑业绩增长，也还有 25% 的空间，所以做好思想准备。
有同学问，为什么不等 PB 到 1.5 再买？这么想的同学，2012 年将错过 2008
年以后，近十年来唯一的超级大底。当时 PB 也只是到 2
而已。三年后，创业板涨了 590%
「钻石底」是一个底部区域，不存在预测某个点是大底的情况。预测某个点是大底这件事，不是傻子就是骗子才会干</p>
</blockquote>
<p>在《<a href="https://youzhiyouxing.cn/materials/731">A
股的历史估值</a>》中，也提到了判断顶部和底部的一些参考指标</p>
<blockquote>
<p>一个<strong>指数的估值是否进入过去十年最高 10%
区域</strong>，具有非常非常重要的意义。通常情况下，某个指数进入过去十年最高
10% 区域，就是本人清仓区域。</p>
<p>从全市场加权估值（非市值加权，外部综合经济数据加权）来看，A股历史出现过
4 次大顶，分别是
1996、1997、2000、2007、2015。<strong>这三次大顶的高度几乎完全一致，超过
45 的区域</strong></p>
<p><strong>大底则不完全相同</strong>。2005 年之前大底只是 30。2005
年之后的大底全部在 20 左右或以下。分别是2005、2008、2012。2008
比较特殊，杀的太厉害，居然杀到了 15 左右。</p>
</blockquote>
<p>这几篇没有给出全市 PE、PB 数据获取的参考地址，但是<a
href="https://legulegu.com/stockdata/market_pe">乐咕乐股</a>上分别提供了沪市和深市的数据，<a
href="https://data.eastmoney.com/gzfx/scgk.html">东方财富网</a>上也提供了近两年的市场估值走势情况，可以参考一下。</p>
<p>上面的例子虽然提供了顶部和底部的参考数据，但<strong>不是说当前的
PE、PB
的绝对值一定要比历史大底低才可进场</strong>，因为绝对的底部是无法预测的；《<a
href="https://youzhiyouxing.cn/materials/711">贪字的二重定义</a>》里是这么说的</p>
<blockquote>
<p>用我们跟踪超过 10 年的A股全市场 PE 来看，2008 年这个数字到过 17
倍。如果在 2012 年你还希望 17 倍入场，那么到现在你都一分钱也赚不到——2012
年大底，全市场 PE 值是 25 倍。
同时，随着无风险利率的变化，我们不能用刻舟求剑的方法，去推导「大底」的估值应该是多少</p>
</blockquote>
<p>而在《<a
href="https://youzhiyouxing.cn/materials/1152">如果现在买还可能再跌，为什么不等估值更低时买？</a>》，也提到了类似的观点，笔者理解本质就是绝对的底的点难以预估，因为受到了太多因素的影响，只能大概率买在不贵的地方；另外，文章还提到一点笔者觉得比较值得借鉴：<strong>在进行一笔投资之前，我更愿意想到的是最多会赔多少，而不是赚多少。其实很多时候，困难之所以会成为困难，正是因为你没有做好准备。如果你做好了准备，那么困难来临的时候，通常会变成机遇。</strong></p>
<p>回到“避免底部吃不饱的”这个问题，通过数据、情绪、政策导向判断底部后，进行仓位布局是，还需要注意节奏问题，即“<strong>到了底部区域，你的节奏一定不能再继续慢慢买。
因为金融市场，极度高估和极度低估都非常罕见</strong>，一旦出现，必须大力买入”。而在《<a
href="https://youzhiyouxing.cn/materials/711">投资要讲求节奏</a>》则更详细描述了控制节奏的一些方法,
简单来说就是到了很贵或很便宜的时候要加速卖出/买入，否则投资节奏可以放缓</p>
<blockquote>
<p>交易节奏的速度。在<strong>上涨趋势良好的时候，你的卖出节奏要放慢</strong>。不着急，慢慢卖。留出空间——也就是说，第二份卖出和第一份之间要有空间。
买入当然也是同理。在趋势向下的时候，第二份买入也要和第一份拉开空间。</p>
<p>那么，<strong>什么时候该加速买入</strong>？就是当你发现目标已经便宜到与你手上的仓位完全不匹配，要尽快建立仓位的时候，比如去年底我们做的。同理，当价格贵到手中仓位已经明显太大的时候，就不要再慢慢卖出。</p>
</blockquote>
<h3 id="pepb-的缺陷">PE、PB 的缺陷</h3>
<p>那 PE/PB 有没有缺陷？在《<a
href="https://youzhiyouxing.cn/materials/729">判断估值的方法</a>》提到了一个点，即
PE、PB 不一定适用于个股，因为存在发展和周期的问题</p>
<p>文章没有详细展开讲，但是知乎上这个<a
href="https://www.zhihu.com/question/263996148/answer/1410965655">回答</a>针对这两点举了比较详细的例子</p>
<blockquote>
<p>企业发展其实有不同阶段，有<strong>创业期，成长期，繁荣期，衰退期</strong>。不同阶段，企业的估值可能会有比较大的变化。一般而言，<strong>创业期与成长期，企业快速发展，在这个时候也是容易给予高估值的时候</strong>。很简单，企业营业收入从无到有，基数低，增速相对就快，所以我们看到为什么创业板股给予高估就是这样的道理。有时候，PE高有其逻辑。如果你不能接受一定的高PE，事实上你也就排除了成长股的个股了。这类股确实是爆发力猛，十倍股往往从这其中出现，但大家也清楚，十倍股不是那么好抓的，高收益潜力的背后，其实是高风险，这对个人的能力要求极高。
繁荣期，则对应的是企业的发展成熟阶段，一般慢慢发展也成了行业的龙头企业了。盈利稳定的情况下，市盈率可能会回落到20左右</p>
<p>很多新手投资者容易拿当前的估值比较低，就觉得他是好票。事实上并不是，在这里要讲一个价值陷阱的问题。<strong>价值陷阱特别容易出现在周期股中</strong>。很多<strong>上游原材料个股</strong>，因为原材料的涨价，业绩连续一年甚至持续多年上涨，所以股价也飙的老高，市盈率看起来可能只有个位数，很多人就认为估值低，可以买。但事实上，行业的反应可能往往令人大失所望，在这里列一个逻辑：原材料持续上涨——有利可图——很多人会去扩产——等到扩产产能出来之后——产品供大于求——价格开始出现下降——恶性竞争持续——企业利润出现下滑，利润下滑之后——市盈率一算就跟之前不一样了——可能变成市盈率大。对于周期股，我自己的心得是在低市盈率时卖出，在高市盈率买入，就是对于周期股来说，和我们平时的认知不同，他们不是估值越低越好，可能估值存在滞后性。</p>
</blockquote>
<p>但是，对于<strong>所有股票这个大群体来说，整体估值就非常重要，因为不可能所有的股票都高成长，也不是所有的股票都具备周期特征</strong>。如果一个市场上绝大多数股票都很贵，那么这个市场大多数人就很难赚钱。</p>
<p>PE、PB 不适用于个股，但是适用于市场的这个观点，在其他文章中《<a
href="https://youzhiyouxing.cn/materials/733">别做盛宴之后买单的那个</a>》也提到了，而个股的估值在《<a
href="https://youzhiyouxing.cn/materials/456">最直观的估值方法</a>》中有提到，这里就不展开了</p>
<h3 id="一些工具">一些工具</h3>
<p>这里介绍一些能看各类指数或者总体大盘估值情况的工具</p>
<ul>
<li>蛋卷基金上的<a
href="https://danjuanfunds.com/djmodule/value-center?channel=1300100141">指数排行</a></li>
<li>有知有行的<a href="https://youzhiyouxing.cn/data">温度计</a></li>
<li>且慢的<a href="https://qieman.com/idx-eval">每日估值</a></li>
<li>乐咕乐股的全市<a
href="https://legulegu.com/stockdata/shanghaiPE">指数估值</a></li>
<li>....</li>
</ul>
<h2 id="定投策略">定投策略</h2>
<p>定投在各个理财课程里都被塑造成一个个美丽的神话：每月省下一笔小钱做定投，三、五、十年以后突然发现变成了一大笔财富。</p>
<p>这个传说是如此美好：不需要学习高深的投资知识，不需要盯盘，只要每月省下一点钱，不知不觉中就能赚上大钱，以至于不少人对其趋之若鹜。</p>
<p>但结果真的如此吗？结论是不一定，下面就从几方面说明定投可能存在的一些陷阱</p>
<h3 id="定投不用择时">定投不用择时？</h3>
<p>经常听到的一个说法是定投可以随时开启，不用择时，但是《<a
href="https://youzhiyouxing.cn/materials/767">什么时候开启定投合适</a>》告诉我们开启的定投的时间很重要，文章模拟了四种情况下定投的收益，这四种情况分别是先跌后涨、先涨后跌、震荡上涨，震荡下跌,
这四种情况模拟的定投结果如下</p>
<p>从收益的角度来说，定投最适合的行情是先下跌后上涨，其次是震荡下跌。因为这两种情况都能很好的利用定投平摊成本的特点，<strong>借助市场下跌摊低成本</strong>，等待行情回归时迅速回本并赚取收益；而最糟糕的情况则是先上涨后下跌，</p>
<p>回到标题里的问题，定投也要择时，但这里的择时不是要精确踩准一个时间点，而是选择一个大概率是底的地方开启，结合市场牛熊轮回的周期特性，<strong>熊市时更适合开启定投</strong>。</p>
<p>另外，《<a
href="https://youzhiyouxing.cn/materials/933">别纠结</a>》指出日定投、周定投、月定投实际对收益影响不大，不需要在这部分上考虑过多，还提到了过度交易这个现象</p>
<blockquote>
<p>为什么很多平台最后还是推出了「周定投」，甚至「日定投」呢？这主要是为了满足很多人心理上的需求——经常操作一下账户，似乎这样可以提高收益。
行为金融学里，把人们这种喜欢频繁交易的现象称作：过度交易。而根据研究，多数时候，频繁的交易并不会带来更高的收益，反而增加了交易成本。</p>
</blockquote>
<h3 id="降低定投成本">降低定投成本</h3>
<p><strong>定投最大的特点是平摊成本</strong>——只要我们能把成本摊得越低，就越有助于我们提高定投的收益。这就是市场上常见的一些定投策略的基础思路：进一步摊低定投成本。</p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/841">定投成本，还能更低吗？</a>》中，提到了降低定投成本的三种方法：均线偏离法、移动平均成本法和估值法。原理都是类似的：<strong>借助某种指标，判断目前市场的高低情况，在低位多投入，高位少投入</strong>；最大区别则在于所选取的市场高低判断指标不同。</p>
<p>这几种方法的细节对比这里不展开，文章最终推荐的是估值定投法，即基于
PE、PB
等估值指标进行定投，低估值时投入多份，高估值时少投入或不投入。具体的估值可以看前面估值体系里提供的一些工具</p>
<p>同时文章通过数据分析指出，<strong>合理卖出才是提高定投收益的更大杀器</strong>，那该在何时卖出？</p>
<h3 id="何时卖出">何时卖出？</h3>
<p>看到这个问题，基本上大家都会不假思索地回答在最高点卖出，但要识别牛市顶端肯定是很难的，我们也很难期望卖在牛市的顶端。</p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/888">买得好不如卖得好？</a>》中，提了三种定投卖出的基础策略：目标收益率法、目标估值法、最大回撤法</p>
<p>这几种方法的细节对比这里不展开，文章推荐的方法是最大回撤法，因为前两种方法都存在着无法绝对估准的问题，因为<strong>每一轮牛市的涨幅都不同且不可预测，难以设置绝对的止盈目标和估值</strong></p>
<p>最大回撤法会设置一个<strong>可容忍的最大回撤幅度，当目标指数下跌超过该幅度，就卖出所有资产，结束定投</strong>。文章举了天天基金的慧定投的例子</p>
<blockquote>
<p>它先设置了一个目标收益率，但牛市究竟能上涨多少，这是不能测算的，为了让投资者能享受牛市更多的收益，慧定投在达到
20% 的目标收益后，如果市场继续上涨则继续持有，一旦出现回撤，回撤幅度达到
10%，就迅速卖出全部资产。</p>
<p>对比前两种方法，这种方法在该时间区间内，获得的累计收益率最高。原因是它<strong>充分利用了牛市过程中情绪性上涨不可预测的特点，转而判断牛市结束时点</strong>，避免了目标收益率设置不合理导致的过早卖出</p>
</blockquote>
<p>因此，文章的结论是：<strong>目标收益率 + 最大回撤法、目标估值法 +
最大回撤法</strong>，实际中，天天基金的慧定投是这么做的，且会在低估的时候加大定投的金额。</p>
<h3 id="定投何种资产">定投何种资产？</h3>
<p>定投是一种灵活控制成本的投资模式，而如果要获取收益，本质上还是要投入到好的资产，在《<a
href="https://youzhiyouxing.cn/materials/924">定投依旧要选好资产</a>》中，提到了选择资产的
2 个要素: <strong>长期收益情况和波动情况</strong>。</p>
<p>长期收益是定投收益的最大来源,
而<strong>一个资产的价值高低从根本上来说还是其未来现金流</strong>决定的。以股票为例，未来的现金流来源首先是公司的盈利增长，其次是股息，最后是估值。再比如债券，未来现金流来源主要是利息。</p>
<p>另一个则是波动情况，一些定投的文章就主张定投要选高波动资产，《定投依旧要选好资产》指出这个说法对也不对。说对，是因为高波动资产确实能增加我们在低位买入的概率增加，从而摊低成本；说不对，是因为从最终结果来看意义并不大。</p>
<p>文中举了中证 500 和标普的例子，两者涨跌幅很接近，差不多都是 90%
左右，但是，中证500的波动率要大得多，回测结果显示最终定投中证500的收益还被指数收益率稍低的标普500反超了，原因是中证500虽然波动率大，但我们<strong>没办法总是买在便宜的时候</strong></p>
<p>而回到具体的投资标的上，还是之前一直推崇的指数基金，因为主动型股票基金存在着基金经理不稳定的问题，但指数基金不受这个影响</p>
<blockquote>
<p>主动型基金基金经理变更的这个大问题，在指数基金身上是基本不存在的。因为指数基金的管理基本上是量化的，基金经理在里面起到的作用很小，不怕他离职。最差的情况是这只指数基金终止清盘，我们也可以很容易在市场上找到跟踪同个指数的产品替代。这也是为什么很多人说的指数基金「永远不会死」。</p>
<p>不过，在指数基金定投里还有一点要注意，就是最好选择宽基指数而非单一行业或主题指数。</p>
</blockquote>
<h2 id="网格策略">网格策略</h2>
<p>这里的网格策略，是一种<a
href="https://baike.baidu.com/item/%E6%B3%A2%E6%AE%B5/17666670">波段</a>策略。在《<a
href="https://youzhiyouxing.cn/materials/833">波段随谈</a>》中提到了波段的一些优势,
包括心态上会更舒适，同时能增加安全垫等</p>
<blockquote>
<p>它会让你对下跌能够乐观接受甚至有些期盼。尤其是当实现一波收益后，你甚至盼着赶紧跌好让你再来一次，虽然你的长线持仓会有损失。这种心态的改变会让你的状态变得极度舒适。投资的时候，状态是否舒适非常非常重要。不舒适就有可能带来变态的心理以及变形的交易。</p>
<p>你买的品种趋势不好，中期会下跌。但下跌并非一路跌到底，中间会有无数反弹。你把反弹利润吃到了，你的安全垫就加厚了。当品种持续下跌后，你买了很多筹码，但由于过程中不断吃反弹利润，成本持续降低，最终在底部区间你只是极少浮亏甚至没有浮亏。</p>
</blockquote>
<p>同时，文章也指出“这不是赚大钱的路”,
因为<strong>大钱是坚定持有中赚到</strong>的。这点你还不明白，以后就会懂。但是波段很必要，为什么？因为波段给你提供源源不断利润的同时，也能让你真正坚定持有未来赚大钱的仓位。</p>
<p>那网格策略具体是如何的操作？E 大有 2 篇文章详细介绍了这个策略</p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/830">网格策略基础（1.0
版）</a>》中，指出了网格策略的一些基本步骤</p>
<blockquote>
<p>第一步：确定交易品种。
第二步：列出网格表格。表格中包括交易价格、交易金额、交易日期。
第三步：做压力测试。 第四步：设置交易提醒。
第五步：按照交易提醒进行交易。</p>
</blockquote>
<p>首先，<strong>做网格的品种，一定是有底的品种。也就是说，不会死的品种。</strong>什么会死？比如个股，这里不是说个股一定会退市，凉透了那种死。它如果基本面发生变化，这辈子也涨不回来了，在网格策略中，也算死了。而做网格最佳的品种，则是“那些没完没了的上下折腾，几年后回头一看我去你怎么一点都没动啊；这种品种简直可以说是网格策略的最佳伴侣，如果你能找到一个，基本上就等同于你找到提款机了。”</p>
<p>其次，一定要做好压力测试，因为“<strong>网格策略最关键的地方不是能赚多少钱，而是你可以知道最坏情况发生后，自己的账户会怎样</strong>”；具体做法文章描述如下</p>
<blockquote>
<p>设计交易表格的时候，根据具体情况，模拟最大下跌幅度。比如说，你现在要开始一个中证500的网格，那你就应该知道，下跌
60%，几乎一定是最坏情况了。甚至下跌 50%
也非常困难。那么你如果相对来说激进一点，就可以以 40%
设计压力测试。保守一点，就按照 50% 或者 60% 设计。
如果你真的不知道到底应该给多少最大下跌空间，你可以参考 ETF
计划里面每次关于指数最大跌幅的判断。在那个基础上，再加 10%
基本上就是铁底。</p>
</blockquote>
<p>具体的交易策略，就是列出网格表格,
包括交易价格、交易金额、交易日期，然后随着下跌逐步购买，且在上涨时卖出,
文章里是这么说的</p>
<blockquote>
<p>如果从 1 开始，以 5%
幅度为一网，则买入价格分别为：1、0.95、0.9、0.85、0.8……卖出价格除第一网
1.0 买入的要在 1.05 卖出外，其它每一网都是上一网的买入价格。即， 0.95
买入的一网，1 元卖出；0.9 买入的，0.95 卖出，依次类推。</p>
<p>所以，你 1 元买入的部分，在 1.05 清仓，赚到 5% 利润。0.95 买到的，在
1 元清仓，赚到 5.26%……最终，在 0.7 元买入的部分，0.75
清仓，则这部分收益率就可以到 7.14%。</p>
</blockquote>
<p>可以看到，这里的策略有 2
个关键点，一是<strong>开始的时机</strong>，文章指出是“价格略低于价值的时候”，但是这个很难有一个统一的标准，文章建议是观察
ETF 计划，如果 ETF
计划开始买入，说明这个东西不太贵；二是<strong>网格大小</strong>,
文章给的参考值是普通的品种一般给 5%。波动大的品种(比如券商指数)给
10%</p>
<p>另外，还提到了走势相似的品种不要重复开，比如说都是大盘股指数，50 和
300 就别开 2 个网格了。</p>
<p>上面是 1.0 的策略，在《<a
href="https://youzhiyouxing.cn/materials/710">网格策略进阶（2.0
版）</a>》则提出了进阶的策略，相对于 1.0 有了三个点的改建</p>
<ol type="1">
<li>留利润，即每次的卖出时只拿回本金，剩余的利润继续放在里面</li>
<li>逐格加码，即约低估，买入的金额越多，这里跟定投时低估加倍定投原理一致</li>
<li>多级网格，即除了 5% 的网格，还可以可以再设置一个 15% 的中网，一个
30% 的大网</li>
</ol>
<h2 id="小结">小结</h2>
<p>本文主要讲了投资中的实操部分：买与卖；在了解了本文所介绍的知识体系后，再回到我们在最开始提的几个问题</p>
<ul>
<li>买什么</li>
<li>什么时候买, 买多少</li>
<li>什么时候卖, 卖多少</li>
</ul>
<p>相信答案也就就很明确了，做好资产配置，买入相关性低的资产；在低估值的时候买，高估值的时候卖，指数的估值一般参考
PE 和
PB，更着重看其区间(历史百分位)而不是绝对值；而买卖多少依赖仓位控制中的分配方法，低估时仓位更重，高估时仓位更轻。</p>
<p>另外，本文还提到两种策略：定投策略和网格策略，前者偏向长期的投资，后者则更偏向短期的波段操作，里面都给出了一些实操建议。</p>
<p>即便如此，投资还是很难；因为上面只是说了一个大原则，或者说“正确的废话”，具体每个品类，PE、PB
到了多少认为是低估值，也没有一个明确的答案，历史上每次的大涨和大跌时这两个值也不尽相同；又或者是即便是道理没错，面对真实的下跌
80% 时，逆势加仓还需要有足够的勇气和子弹。</p>
<p>在笔者整理的过程中，虽然尽量把文章的内容尽量整理得脉络比较清晰，但总体感觉还是会比较混沌，没有绝对的真理或圣杯，几乎任何觉得有道理的建议或理论，都能找到反例来推翻；回到最终，你会发现还是一个“度”的问题，但是这个“度”的把控则是非常非常奇妙的，而这也许就是投资被称作一项艺术的原因？</p>
<p>投资里有个“盈亏同源”的概念，顾名思义，就是盈利与亏损都是出自同一个源头，或者说都是同一个原因造成的；其本质是也是在描述上面说的混沌的现象，市场是不确定的，无法预测的，要放弃对所谓确定性的追求，同时摸索出适合自己的选择判断体系；这几篇文章在做的事情就是尝试归纳
E
大、有知有行已经摸索出一套体系，不能称得上是完美，但是自洽，而且在真实的系统中验证过有效性的；当然有效的系统肯定不止一套，但是愿意这么系统地整理且公开的，笔者目前就找到这一套，也希望对你有用。</p>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>搜狗、百度、QQ输入法的词库爬虫</title>
    <url>/2016/03/27/%E6%90%9C%E7%8B%97%E3%80%81%E7%99%BE%E5%BA%A6%E3%80%81QQ%E8%BE%93%E5%85%A5%E6%B3%95%E7%9A%84%E8%AF%8D%E5%BA%93%E7%88%AC%E8%99%AB/</url>
    <content><![CDATA[<p>本文主要讲述了通过 python
实现的用于下载搜狗、百度、QQ三个输入法的词库的爬虫的实现原理。主要利用了python自带的<code>urllib2</code>、<code>Queue</code>、<code>re</code>、<code>threading</code>模块，并分别通过单线程和多线程实现。最后会给出完整的源码地址。</p>
<span id="more"></span>
<h2 id="原理及注意事项">原理及注意事项</h2>
<p>爬取每个输入法的实现原理都一样，步骤如下：</p>
<p>（1）获取输入法词库的分类 （2）下载各个分类并按分类在本地存储</p>
<p>其中（1）实现的关键点是正则表达式提取网页中的词库分类，（2）实现的关键点是通过广度优先搜索（bfs）来遍历某一类别的所有页面。</p>
<h3 id="正则表达式提取词库分类">正则表达式提取词库分类</h3>
<p>步骤（1）通过解释词库分类的网页源码来获取具体分类（以搜狗输入法为例，词库分类的网页为http://pinyin.sogou.com/dict/
)。先人工观察网页源码的结构，一般同一级的分类的在源码中的
<code>href</code>(超链接)的结构都是一样的，仅仅是id或名字不同，这就可以<strong>通过正则表达式来提取网页中的分类，并用嵌套的字典来存储多级分类</strong>。</p>
<h3 id="bfs遍历某一分类的所有页面">BFS遍历某一分类的所有页面</h3>
<p>步骤（1）提供了词库的分类，步骤（2）需要考虑的就是怎么下载某一类词库。因为词库文件的数量较多，所以<strong>即使是某一类的词库往往也会分多个页面来展示（常见的如通过点击上一页、下一页跳转），所以要完整下载这一类的词库必须遍历这一类词库的所有页面。</strong></p>
<p>这里采用BFS来实现，实现步骤如下：
1）先通过正则表达式分析当前访问页面的源码，获取<strong>当前页面可以跳转到的其他页面的url</strong>，然后将这些URL放入到<strong>队列</strong>中作为待访问的URL
2）通过正则表达式获取分析当前访问的页面的源码，获取可以下载的词库文件的url存入一个临时的列表（List）中，并开始逐一下载各个文件
3）将当前页面url放入到一个集合（set）中，标记为已访问的url，防止下一次重复访问
4）从队列中取出下一个url，到步骤3）的集合中检查url是否被访问，如果被访问过则继续取下一个，否则将这个url设为当前url并回到步骤1）</p>
<p>按照上面的步骤一直循环执行直到队列为空，这样便可下载了某一类的词库。如法炮制，便可下载所有类的词库了。</p>
<p>这里需要注意的是，在下载词库文件的时候有可能会出现<strong>防盗链</strong>的问题。简单来说就是<strong>下载词库文件的http请求头中的来源（Referer）不属于本站的就拒绝下载，返回403
forbidden。</strong>这种设计就是为了防止爬虫的整站下载，在爬取过程中发现搜狗输入法中有防盗链，而百度、QQ输入法则没有。解决方法也很简单，就是在<strong>下载文件是构造一个http请求头（headers），设置里面的<code>Refererr</code>为该站的任一url即可。</strong></p>
<h2 id="单线程下载">单线程下载</h2>
<p>单线程下载的注意事项上面基本提到了，下面贴出QQ输入法单线程下载的关键代码，注意这个代码直接执行会报错，可执行的完整代码见文末。
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载某一类别的关键代码，具体代码见文末链接</span></span><br><span class="line">    queue =Queue.Queue()  <span class="comment"># 存放待访问url</span></span><br><span class="line">    visited = <span class="built_in">set</span>()       <span class="comment"># 已经访问过的url</span></span><br><span class="line">    downloaded = <span class="built_in">set</span>()    <span class="comment"># 已经下载过的文件</span></span><br><span class="line">    firstURL = <span class="string">&#x27;&#x27;</span>         <span class="comment"># url入口</span></span><br><span class="line">    queue.put(firstURL)</span><br><span class="line">    <span class="comment"># bfs遍历直至队列为空</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> queue.empty():</span><br><span class="line">        currentURL = queue.get()</span><br><span class="line">        <span class="keyword">if</span> currentURL <span class="keyword">in</span> visited:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            visited.add(currentURL)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = urllib2.urlopen(currentURL)</span><br><span class="line">        <span class="keyword">except</span> :</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 找到链接到其他页面的连接</span></span><br><span class="line">        data = response.read()</span><br><span class="line">        pagePattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&amp;page=(\d+)&quot;&#x27;</span>)</span><br><span class="line">        pageList = re.findall(pagePattern,data)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> pageList:</span><br><span class="line">            pageURL = smallCateURL+<span class="string">&#x27;&amp;page=&#x27;</span>+i</span><br><span class="line">            queue.put(pageURL)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载当前页面存在的文件</span></span><br><span class="line">        filePattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;a href=&quot;/dict_detail\?dict_id=(\d+)&quot;&gt;(.*?)&lt;/a&gt;&#x27;</span>)</span><br><span class="line">        fileList = re.findall(filePattern,data)</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">id</span>, name <span class="keyword">in</span> fileList:</span><br><span class="line">             fileURL = <span class="string">&#x27;http://dict.qq.pinyin.cn/download?dict_id=&#x27;</span>+<span class="built_in">id</span></span><br><span class="line">             filePath = cateDir.decode(<span class="string">&#x27;utf8&#x27;</span>)+<span class="string">&#x27;/&#x27;</span>+name.decode(<span class="string">&#x27;gbk&#x27;</span>)+<span class="string">&#x27;.qpyd&#x27;</span></span><br><span class="line">             <span class="comment"># 文件已存在则不下载</span></span><br><span class="line">             <span class="keyword">if</span> fileURL <span class="keyword">in</span> downloaded:</span><br><span class="line">                 <span class="keyword">continue</span></span><br><span class="line">             <span class="keyword">else</span>:</span><br><span class="line">                 downloaded.add(fileURL)</span><br><span class="line">                 downloadSingleFile(fileURL) <span class="comment">#下载这个文件</span></span><br></pre></td></tr></table></figure></p>
<h2 id="多线程下载">多线程下载</h2>
<p>单线程虽然能够下载词库文件，但是消耗的时间过长，这时候可通过多线程来下载。关于python多线程实现以及python多线程是否能够提高效率可以参考<a
href="http://wulc.me/2016/03/26/python%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B/">这篇文章</a>。<strong>因为爬虫属于IO密集型的任务，所以可以通过多线程来提高下载效率。</strong>实测多线程开到10个的时候，下载速度比原来快了7倍。</p>
<p>多线程下载实现的思路与单线程的类似，只是在<strong>下载某一类别的词库时采用多线程完成</strong>，这就需要注意下面几个方面：</p>
<ul>
<li>线程完成下载的时间不一样，<strong>早完成的线程需要等到最后一个线程下载完成才能一起开始下一个类别的下载</strong>,可通过python的Queue模块中的<code>join()</code>方法和<code>task_done()</code>方法实现</li>
<li>需要<strong>用线程锁保护可能会被修改的变量</strong>，采用python的队列数据结构（Queue）则不用，因为python的Queue模块已经实现了这个锁的功能，具体参见<a
href="https://docs.python.org/2/library/queue.html">Queue — A
synchronized queue class</a></li>
</ul>
<p>关于队列模块中的<code>join()</code>方法和<code>task_done()</code>方法，<a
href="https://docs.python.org/2/library/queue.html">官方文档</a>说明如下：</p>
<blockquote>
<p>If a join() is currently blocking, it will resume when all items have
been processed (meaning that a task_done() call was received for every
item that had been put() into the queue).</p>
</blockquote>
<p>也就是说Queue调用了join方法后，必须要收到每个取出的item（这里为url）返回的task_done()消息才会继续执行，否则会一直block等待，这就实现了我们说到的早完成的线程需要等到最后一个线程下载完成才能一起开始下一个类别的下载。</p>
<p>实现的关键代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建自己的线程类</span></span><br><span class="line">queue =Queue.Queue()  <span class="comment"># 存放待访问url</span></span><br><span class="line">visited = <span class="built_in">set</span>()       <span class="comment"># 已经访问过的url</span></span><br><span class="line">downloaded = <span class="built_in">set</span>()    <span class="comment"># 已经下载过的文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">downloadThread</span>(threading.Thread):</span><br><span class="line">    <span class="comment"># 重写run函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> queue.empty(): <span class="comment"># 防止一开始队列内容太少导致后创建的线程退出</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            currentURL = queue.get()</span><br><span class="line">            <span class="comment"># 查看url是否被访问过，需要用锁保护</span></span><br><span class="line">            threadingLock.acquire()</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> currentURL <span class="keyword">in</span> visited:</span><br><span class="line">                    queue.task_done() <span class="comment"># 不可少，否则queue调用了join()会一直block下去</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    visited.add(currentURL)</span><br><span class="line">            <span class="keyword">finally</span>:</span><br><span class="line">                threadingLock.release()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解析当前页面</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                response = urllib2.urlopen(currentURL)</span><br><span class="line">            <span class="keyword">except</span> :</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 找到链接到其他页面的连接</span></span><br><span class="line">            data = response.read()</span><br><span class="line">            pageList = re.findall(pagePattern,data)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> pageList:</span><br><span class="line">                pageURL = smallCateURL+<span class="string">&#x27;&amp;page=&#x27;</span>+i</span><br><span class="line">                queue.put(pageURL)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 下载当前页面存在的文件</span></span><br><span class="line">            fileList = re.findall(filePattern,data)</span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">id</span>, name <span class="keyword">in</span> fileList:</span><br><span class="line">                fileURL = <span class="string">&#x27;http://dict.qq.pinyin.cn/download?dict_id=&#x27;</span>+<span class="built_in">id</span></span><br><span class="line">                filePath = downloadDir.decode(<span class="string">&#x27;utf8&#x27;</span>)+<span class="string">&#x27;/&#x27;</span>+name.decode(<span class="string">&#x27;gbk&#x27;</span>)+<span class="string">&#x27;.qpyd&#x27;</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 检查文件是否被下载</span></span><br><span class="line">                threadingLock.acquire()</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="keyword">if</span> fileURL <span class="keyword">in</span> downloaded:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        downloaded.add(fileURL)</span><br><span class="line">                <span class="keyword">finally</span>:</span><br><span class="line">                    threadingLock.release()</span><br><span class="line">                downloadSingleFile.downloadSingleFile(fileURL, filePath, logFile)</span><br><span class="line">           <span class="comment">#告诉queue当前任务已完成，否则因为queue调用了join，会一直block下去</span></span><br><span class="line">            queue.task_done()  </span><br></pre></td></tr></table></figure></p>
<p>最后，下载三个输入法的词库的python源码已放到github上，链接https://github.com/WuLC/ThesaurusSpider</p>
<p>文章为博主个人总结，如有错误，欢迎交流指正</p>
]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>广度优先搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>投资这件事(2)-概念与常识</title>
    <url>/2022/06/18/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B(2)-%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%B8%B8%E8%AF%86/</url>
    <content><![CDATA[<p>从年初了解 <a href="https://youzhiyouxing.cn/materials">有知有行</a>
开始，断断续续看了不少上面的内容: 听完了里面投资第一课, E
大干货合集、投资知识体系里的文章也基本是已读状态，一直处于输入的状态;
感觉是时候该 connect the dots，形成一个更系统的框架融入自己的知识体系中,
于是便有了这个系列的文章。</p>
<p>这个系列的文章绝大部分内容来自于有知有行，也会有一些笔者深究后调研的内容，且按照笔者的理解划分为：认知与心态、概念与常识、买与卖三大模块。妄图将投资这个大话题以及有知有行的编辑们整理的上百篇文章浓缩到这篇小小的笔记中，自然无法面面俱到，所以这篇文章还是会挑选笔者关注的一些内容，更详细的内容可参考有知有行以及本文里的相关引用。</p>
<p>本文是概念与常识的部分，主要是笔者在学习过程中接触到的一些概念性的知识，对于熟悉的人来说，也许是“常识”，笔者则是在尝试将这些不熟悉的内容变为自己的常识，也希望对你有用。</p>
<p>第一部分的内容见 《<a
href="https://wulc.me/2022/05/04/%E6%8A%95%E8%B5%84%E8%BF%99%E4%BB%B6%E4%BA%8B%281%29-%E8%AE%A4%E7%9F%A5%E4%B8%8E%E5%BF%83%E6%80%81/">投资这件事(1)-认知与心态</a>》</p>
<span id="more"></span>
<h2 id="周期">周期</h2>
<p>春夏秋冬，阴晴圆缺，万物皆有周期，市场也存在着周期，这部分主要讲市场周期的表现形式，产生原因以及应对方法。</p>
<h3 id="牛熊交替与轮动">牛熊交替与轮动</h3>
<p>市场是有周期，主要变现为股市每天的起起伏伏，或者是各个行业的此起彼伏；最常见的就是牛熊交替，行业轮动与风格轮动</p>
<p>以牛熊交替为例，《<a
href="https://youzhiyouxing.cn/materials/140">市场皆有周期：牛市特征、熊市特征</a>》里就讲了牛市和熊市的几个阶段</p>
<blockquote>
<p>「牛市三阶段」：
第一阶段，只有少数特别有洞察力的人相信，基本面情况将会好转；
第二阶段，大多数人都认识到，基本面情况确实好转了；
第三阶段，每个人都得出结论，基本面情况将会变得更好，而且永远只会更好</p>
<p>「熊市三阶段」:
第一阶段，只有少数深谋远虑的投资人才能意识到，尽管形势一片大好，基本面普遍被乐观看涨，但是基本面肯定不会一直顺风顺水；
第二阶段，大多数人都认识到基本面正在越变越糟；
第三阶段，每个人都相信基本面只会变得越来越糟。</p>
</blockquote>
<p>E 大的文章《<a
href="https://youzhiyouxing.cn/materials/687">什么是熊市，什么是牛市？</a>》里也提到类似的观点，这里就不赘述了，而牛熊交替，意味着市场总是在极度乐观和极度悲观中来回摆动，在《<a
href="https://youzhiyouxing.cn/materials/151">什么是钟摆意识？</a>》中，把这种现象描述如下</p>
<blockquote>
<p>证券市场中的情绪波动，就像一个钟摆的运动一样。这个钟摆来回摆动，形成一道弧线，弧线的中心点完美地描述了这个钟摆的「平均」位置。但是事实上，钟摆待在这个弧线的中心点位置的时间极短，一晃而过。相反，钟摆几乎大部分时间都在走极端，弧线两端各有一个极端点，钟摆不是在摆向极端点，就是在摆脱极端点</p>
</blockquote>
<p>除了牛熊交替形成的周期，行业轮动也会形成周期，《<a
href="https://youzhiyouxing.cn/materials/528">聊聊A股历史上的机构抱团事件</a>》里就提到了由于行业轮动以及机构投资者的考核机制、排名压力等因素，形成了各种「抱团」行为，文章里是这么说的</p>
<blockquote>
<p>按照我们的定义，持续加仓并持有一个板块接近至超过
30%，视为「抱团」。类似的情况发生过四次，分别是： (1)2007Q1-2010Q1
抱团金融，持续 13 个季度 (2)2009Q3-2012Q3 第一次消费抱团，持续 13
个季度； (3)2013Q1-2016Q1 抱团信息科技，持续 13 个季度
(4)2016Q1-当前第二次消费抱团，已经持续了 13 个季度；但如果从
2017Q1算正式开始抱团，目前只持续了 10 个季度</p>
<p>每个板块的业绩推动自有其原因和逻辑，货币超发和信贷放量时金融板块业绩改善并大幅回升的动力；通胀升温是消费板块业绩大幅改善的动力；新技术和并购趋势是信息科技板块业绩大幅改善的动力。</p>
</blockquote>
<p>除了行业轮动，风格轮动也是常见的周期表现，《<a
href="https://youzhiyouxing.cn/materials/686">证券市场是轮回，是周期</a>》里提到从规模上可以将风格归为大、小两种</p>
<blockquote>
<p>证券市场上，是讲究「风格」的。比如<strong>从规模上讲，大、小就是两种风格</strong>。</p>
<p><strong>我们持仓中的
50、红利（策略指数，可以归入大指数）、300、金融（行业指数，也算大指数）都算是「大股票指数」</strong>。</p>
<p>500 当然不算大指数，但在目前这个市场上，也不能算小指数。毕竟已经有
3500 只A股，第 301～800
怎么能算「小」呢。中证1000勉强算是小指数。我们买的创业板指数其实严格来说也不能算小指数，姑且把它列入。</p>
</blockquote>
<p>基于这个维度划分的风格是存在轮动的，表现如下</p>
<blockquote>
<p>「风格」是会不断轮换的。虽然这个轮换周期甚至可能长达十年，但一定会轮换。很多人<strong>在
2012 年到 2014
年，小股票动辄数倍涨幅而大股票纹丝不动的时候，戏称大蓝筹是「大烂臭」</strong>，甚至写出万字雄文论证大股票将永远退出A股历史舞台。当然，后面发生的事大家都知道了。</p>
<p><strong>2017
年以来，蓝筹股走出了一波行情。颇有一些近视的同学，又开始坚定否认小股票的投资价值</strong>。「大的就是好的，漂亮
50 最好，小股票永远没戏了。」</p>
</blockquote>
<p>同样地，如果去分析美国的股市，也会发现相同的现象，观察美股历史（因为美股历史较长，数据极其丰富翔实，所以用它举例），你会发现非常明显的大小轮动记录。也就是说，大股票和小股票通常会各领风骚数年，最终两者超长期涨幅不会差太多，甚至小股票会稍微略高一点</p>
<h3 id="什么导致了周期">什么导致了周期</h3>
<p>周期是如何产生的？ 《<a
href="https://youzhiyouxing.cn/materials/186">为什么市场会有周期？</a>》里提到，市场周期主要由三个周期影响决定——经济周期、企业盈利周期和情绪周期</p>
<ul>
<li>经济周期</li>
</ul>
<p>经济周期是某个国家、或者整个世界在一定时间内的经济产出情况，增长或衰退。一个经济体的长期经济发展情况，通常是由人口出生率、劳动生产率、科技发达程度等等这样的因素决定</p>
<ul>
<li>企业盈利周期</li>
</ul>
<p>即使 GDP
的变化不大，企业盈利水平的波动也可能会很大，造成这种现象的原因有多个，文章里提到了两个原因：经营杠杆和财富杠杆，这里就不张开讲了</p>
<ul>
<li>情绪周期</li>
</ul>
<p>市场是参与者行为的总和，而人心的变化，往往会导致市场出现非常极端的变化，而这就是情绪周期。文章认为前面两个周期变化，都比不上情绪周期对市场波动的影响大文章里举了「漂亮50」的例子，旨在说明人们对这些大蓝筹股的情绪的转变</p>
<p>至此，文章指出了一次完整的周期如下</p>
<blockquote>
<p><strong>市场的气氛和叙事开始变化 &gt;&gt;
导致投资者开始追捧某一类股票 &gt;&gt;
随着追捧股价节节走高印证了牛市的故事 &gt;&gt;
更多的人蜂拥而至并让市场产生这种景气不会消失的错觉 &gt;&gt;
市场气氛开始掉转 &gt;&gt; 投资者接连出逃股价大幅下降 &gt;&gt;
公司股价长时间的一蹶不振……</strong></p>
</blockquote>
<p>经济形势好的时候，企业家过度盲目地投资再生产，<strong>银行等金融机构在经济上升周期的信用宽松（容易贷款）也助长了这种行为，这些在经济好的时候进一步放大了企业的盈利</strong>。</p>
<p>反应到市场周期上——媒体都是好消息，企业盈利屡超预期，一片欣欣向荣。这时候投资者的心理和情绪就接管了现场。「这样的景象一定能持续下去，黄金十年不是梦」，于是股票价格大涨。</p>
<p>某个时候、某个因素导致企业盈利不及预期，而这时最后的接盘手也已经进场，于是股市开始下跌。<strong>经济形势良好时候的经营和财务杠杆，此时变成了企业的包袱，企业的盈利迅速减少甚至亏损</strong>。股市进一步下跌，媒体上都是坏消息，投资人认为这样的景象一定会持续下去，经济要完，于是抛售股票。企业裁员、投资者身家缩水，大家纷纷勒紧裤腰带，减少不必要的消费，企业的收入和盈利进一步降低……直到开始下一个周期。</p>
<p>因此，经济周期、企业盈利周期、市场情绪周期，波动逐级放大，但<strong>终会收敛回归到长期趋势本身，这个长期趋势，也就是一个国家经济和企业盈利的增长</strong>。
但是这三个周期，以及各种其他周期（比如信贷周期）与因素的叠加，造成了整个市场的起伏波动，而人心在这里的作用尤其之大。</p>
<h3 id="经济机器是怎么运行的">经济机器是怎么运行的</h3>
<p>上面虽然在探讨周期是如何产生时最后提到了债务周期，但是没有详细说，而
Ray Dalio 的《<a
href="https://youzhiyouxing.cn/materials/680">经济机器是怎样运行的</a>》里面则详细分析了债务周期是如何影响经济周期的，并且从宏观经济的角度，用通俗的语言解释了经济运作原理，值得一看</p>
<p>关于 Ray Dalio，张潇雨的播客里也介绍过这位大佬，<a
href="https://www.ximalaya.com/sound/35106165">#12：（奇葩的）华尔街大佬与人生导师
Ray Dalio</a>，主要讲了 principle 对其的指导意义</p>
<p>文章指出世界经济运行主要由三个因素驱动：1.生产率的提高 2.短期债务周期
3.期债务周期，这三个因素共同组成了一个经济发展的模型</p>
<p><img src="https://wulc.me/imgs/EconomicMachine.jpg" height="50%" width="50%"></p>
<p><img src="https://wulc.me/imgs/EconomicMachine2.jpg" height="50%" width="50%"></p>
<p>下面则是这个经济模型里的一些要素和发展规律</p>
<ul>
<li>信贷</li>
</ul>
<blockquote>
<p>信贷是经济中最重要的组成部分。如果借款人保证偿还债务，而贷款人相信这一承诺，信贷就产生了。任何两个人都可以通过协定，凭空创造出信贷。
现实生活中大部分所谓的钱，其实都是信贷。美国国内的信贷总额大约为 50
万亿美元，而货币总额只有大约 3
万亿美元。<strong>信贷可以使收入增长在短期内超过生产率的增长，但在长期内并非如此</strong>。信贷如果造成超过偿还能力的过度消费，就是不良信贷。</p>
</blockquote>
<ul>
<li>短期债务危机</li>
</ul>
<blockquote>
<p>信贷会导致支出的增加，且信贷可以立刻凭空产生；而如果支出和收入的增长速度超过所出售的商品的生产速度，价格就会上涨，我们把价格的上涨称为通货膨胀。
央行不希望通货膨胀过高，因为这会导致许多问题。<strong>央行在看到价格上涨时就会提高利率，随着利率的上升，有能力借钱的人就会减少，同时，现有的债务成本也会上升</strong>，每个月信用卡的还款额会增加。
由于人们减少借债，并且还款额度增长，所以剩下来用于支出的资金将会减少，因此支出速度放慢，而由于<strong>一个人的支出是另一个人的收入，环环相扣，人们的收入将下降。由于支出减少，价格就会下跌，我们称之为通货紧缩，经济活动减少，经济便陷入衰退</strong>
如果衰退过于严重，而通货膨胀不再成为问题，央行将降低利率，使经济活动重新加速。随着利率降低，偿债成本下降，借债和支出增加，出现另一次经济扩张
<strong>短期债务周期通常持续 5～8
年</strong>，在几十年里不断重复。但是请注意在每个周期的低谷和高峰后，<strong>经济增长和债务都超过前一个周期</strong>。因此在长期内，债务增加的速度超过收入，从而形成长期债务周期</p>
</blockquote>
<ul>
<li>长期债务危机</li>
</ul>
<blockquote>
<p>尽管人们的债务增加，但贷款人会提供更宽松的借贷条件，这是因为<strong>大家都以为形势一片大好，因为仅注意最近出现的情况</strong>。最近出现的情况是什么呢？收入一直在增加，资产价值不断上升，股票市场欣欣向荣，现在是繁荣时期，用借来的钱购买各类资产，很划算。<strong>当人们过度借贷消费时，泡沫便产生了。</strong>
债务与收入比例称为债务负担，只要收入继续上升，债务负担就可以承受。于此同时资产价格迅猛上升，人们大量借钱来购买资产，因为投资促使资产价格日益升高，人们感觉自己很富有，因此即使积累了大量债务，收入和资产价值的上升帮助借款人在长期内保持良好的信用。但是这种情况显然无法永久持续下去。
<strong>债务负担不断增加使偿贷成本越来越高，到了一定的时候，偿贷成本的增加速度超过收入</strong>，迫使人们削减支出，由于一个人的支出是另一个人的收入，收入开始减少，而偿贷成本继续增加，导致支出继续减少，周期开始逆转。
这时便到达了长期债务的顶峰，债务负担变得过重。美国和欧洲在 2008
年就发生了这一情况。日本在 1989 年和美国在 1929
年因同样原因发生了这一情况</p>
</blockquote>
<p>最后讲的例子，其实就是次贷危机(2008),
日本房地产泡沫(1989)和美国的大萧条(1929)；这个时候经济会进入去杠杆化时代</p>
<blockquote>
<p>在去杠杆化过程中，人们削减支出，收入下降，信贷消失，资产价格下跌，银行发生挤兑，股票市场暴跌，社会紧张加剧，整个过程开始下滑并形成恶性循环
在衰退中，可以通过降低利率来刺激借贷。但是在去杠杆化过程中，由于利率已经很低，低至零，从而丧失刺激功能，因此降低利率不起作用。美国国内的利率在
1930 年代的去杠杆化期间下降到零，在 2008 年也是如此。</p>
</blockquote>
<p>为了对去杠杆化，通常采用以下四种办法</p>
<ol type="1">
<li>削减支出（紧缩）</li>
<li>减少债务（债务违约和重组）</li>
<li>财务再分配</li>
<li>发行货币</li>
</ol>
<p>这四种办法的的基本原理和因果关系如下</p>
<blockquote>
<p>削减支出会导致收入下降，当收入下降速度超过还债的速度，因此债务负担实际上更为沉重。削减支出的办法引起通货紧缩。<strong>企业不得不削减成本，这意味着工作机会减少，失业率上升</strong>。这导致下一个步骤，即必须减少债务。</p>
<p><strong>借款人不还钱，存款人会担心银行没钱，于是纷纷取出存款，银行受到挤兑，个人、企业、银行出现债务违约</strong>，这种严重的经济收缩，就是萧条。萧条的一个主要特征是人们发现原来属于自己的财富中很大一部分其实并不存在。
很多贷款人不希望自己的资产消失，同意债务重组。<strong>债务重组意味着贷款人得到的还款减少，或偿还期延长，或利率低于当初商定的水平</strong>，无论如何，合约被破坏，结果是债务减少，贷款人希望多少收回一些贷款，这强过血本无归。</p>
<p>在去杠杆化过程中，政府的预算赤字飙升，原因是政府的支出超过税收。政府必须加税或者举债以填补赤字。但是要从哪里拿钱？<strong>从富人手中，通过征税把财富从富人那里转到穷人手中</strong>。</p>
<p>因为支出的很大一部分是信贷，但是萧条时期信贷消失，所以人们钱不够花，那么怎么办?央行发行更多货币,
央行通过用这些货币<strong>购买金融资产，帮助推升了资产价格，从而提高了人们的信用</strong>，但是这仅仅有助于那些拥有金融资产的人。因此，为了刺激经济，央行和政府必须合作。央行通过<strong>购买政府债券，其实是把钱借给政府，使其可以通过刺激计划和失业救济金，来增加购买商品和服务的支出</strong>，这增加了人们的收入，也增加了政府的债务，但是这个办法将降低经济中的总债务负担。</p>
</blockquote>
<p>文章指出
去杠杆化是一个把高债务水平变化到低债务水平的过程。为了使经济再次恢复正常，这个通货再膨胀的阶段大约要<strong>持续
7～10 年，因此有失去的 10 年这个说法</strong></p>
<p>最后，文章给了三条建议,
其本质都是要不要过渡依赖信贷，而是要依赖生产率的提升(而不是信贷)来提升收入</p>
<blockquote>
<p>第一，不要让债务的增长速度超过收入。因为债务负担最终会将你压垮；
第二，不要让收入的增长速度超过生产率。因为这会使你最终失去竞争力；
第三，尽一切可能提高生产率。因为生产力在长期内起到最关键作用。</p>
</blockquote>
<h3 id="个人如何面对周期">个人如何面对周期</h3>
<p>如果说上面是宏观经济的角度去分析周期产生原因以及一些应对措施，那 E
大下面的几篇文章里讲的就是从个人投资者的角度去看这个周期以及一些应对的手段</p>
<p>《<a
href="https://youzhiyouxing.cn/materials/686">周期如同春夏秋冬</a>》就从个人投资者的角度，谈了对周期的看法，以及对当时(2019年)所处周期的判断</p>
<blockquote>
<p>就像花开有期，每个品种都有它的起伏周期。<strong>从周期的角度讲，你应该做的是尽量识别每个大类的春夏秋冬，然后根据大致的天气状态，增减衣服，舒舒服服地活下去</strong>。</p>
<p>这几年，消费、公用事业走得非常好，去年以及今年债券走得不错，今年黄金异军突起。这所有的现象都说明我们处在典型的——宏观经济下行周期。(笔者附，指的是经济不好时股票也不好，债券黄金等资产更受青睐?)
在这个周期中，受宏观经济影响小的消费、医药（本来医药这两年应该表现非常好，不过行业遭遇新政冲击表现不及预期，但其实已经非常不错）、现金流强的公用事业等板块就成了抱团取暖的避风港。</p>
<p>接下来呢？
简单地说，下一个周期将是逐渐走出宏观经济下行的周期，那个周期股票一定表现很好。其中表现最好的一定不会再是消费或者公用事业，而是金融与科技类这些高弹性、有想象力的板块。债券表现不会太差，因为流动性还在。在目前这个周期表现非常好的贵金属会表现相对来说不会依然这么亮眼。
当你发现上述情况发生，你就应该知道宏观经济已经走入了下一个阶段。不必看太多宏观经济数据，因为只有<strong>资本市场才是最敏感最领先的指标。股票先于宏观数据，而债券又会先于股票，这是因为做股票的人非常敏感，而做债券的人更敏感</strong>。
至于下个阶段什么时候到来，我不知道，但我认为，在合适的时候应该慢慢的为下一个阶段做准备</p>
</blockquote>
<p>面对牛熊交替，《<a
href="https://youzhiyouxing.cn/materials/687">什么是熊市，什么是牛市？</a>》中指出无法判断熊市或牛市何时回来，<strong>你能把握的就是自己账户里的资金、持仓品种，以及自己的心态情绪,
要买入便宜的东西，分配好资产，踏踏实实等着更便宜或者价值回归</strong>。除此，还提到需要耐心</p>
<blockquote>
<p>金融投资中的权益类投资，尤其我们这种自诩为「价值投资」的方式，它绝不是这个月
1%，下个月 1%，今年 12%，明年
12%……权益类投资不是这样的，这样的叫做固定收益，或者 P2P，或者麦道夫。
权益类投资的特点就像春夏秋冬。有的时候发大财，有的时候平平无奇，有的时候黯然神伤。</p>
</blockquote>
<p>而面对风格的轮动，《<a
href="https://youzhiyouxing.cn/materials/686">证券市场是轮回，是周期</a>》给出如下建议</p>
<blockquote>
<p>我给各位的建议，是<strong>投资万万不可短视</strong>。这个短视的意思，不仅是看不到长久的未来，更是被短期的历史所迷惑。熊市的短视中看一切都是利空，一切都是灰暗再无希望；牛市的短视中一切都是利好，股市永无天花板；大股票表现好就是漂亮
50 永远涨涨涨；小股票表现好就是成长股一生牛牛牛。
证券市场是轮回，是周期。大周期套小周期，大轮回里有无数小轮回。<strong>千万千万别被最近发生的事所迷惑。</strong></p>
</blockquote>
<p>另外，资产配置的重要性，也能通过周期的角度说明，即除了权益类资产，还要配置债券、石油、黄金等资产，因为<strong>这些品种的周期与股票不同，而多个相关性很低的品种相叠加，会带给我们被熨平的周期，让我们四季如春，资产不断新高</strong>。最常见的就是股债轮动，</p>
<p>而对于熊市或者说下跌，《<a
href="https://youzhiyouxing.cn/materials/688">我们热切盼望的是下跌</a>》中是这样说的</p>
<blockquote>
<p><strong>没有危机是不会出现让你暴富的大底的</strong>。这也是为什么会出现大底，以及为什么大底没几个人敢买的原因——因为出大事了。</p>
<p>行情最差的时候，很多人预期会更差，因为形势看起来真的很差，而且看起来会更差。这个时候，很多之前看多的人会卖出，很多看空的人会继续看空。之前看多坚持不卖的人已经算好，然而他们已经没钱买了，除了股息。</p>
</blockquote>
<h2 id="投资标的">投资标的</h2>
<p>这里谈到的投资标的主要是指金融类资产，常见的基本上可以分为三大类</p>
<p>(1)权益类资产：股票，基金等
(2)固收类资产：定期，国债，企业债，央行票据，债券基金等
(3)现金类资产：现金，银行存款，货币基金等</p>
<p>权益类资产指的是你拥有这个资产全部或者部分所有权，也享有这部分资产产生的收益；固收类资产一般是债券+定期；现金类的则是常见的各种货币基金，这三类资产风险和收益都是从高到低。</p>
<p>除了上面说的三大类资产，黄金，原油和房地产也是常见的投资标的，但是这里着重讲权益类资产。</p>
<h3 id="指数与个股">指数与个股</h3>
<p>无论是有知有行团队还是 E 大，都更推崇指数而不是个股，在《<a
href="https://youzhiyouxing.cn/materials/714">指数到底哪里好？</a>》、《<a
href="https://youzhiyouxing.cn/materials/712">为什么我很少谈论个股？</a>》、《<a
href="https://youzhiyouxing.cn/materials/713">指数与股票的区别</a>》、《<a
href="https://youzhiyouxing.cn/materials/527">指数基金的五大优势</a>》几篇文章里，总结了指数的一些优势，笔者将其归纳为估值、风险、收益、成本这四个方面。</p>
<ul>
<li>估值</li>
</ul>
<p>指数投资与个股投资最大的不同，是有一个大致可估算的区间</p>
<blockquote>
<p>比如之前说的下跌 80%
原则，就是价格区间。比如钻石坑或者哈迪斯顶，就是价值原则。知道了顶和底，你就可以开心的设计你的策略了。如果你知道它极大概率不会跌破某个价格，你就可以以那个价位为底，设计一整套或者几套长期或者短期交易的策略。</p>
</blockquote>
<p>但是股票则是很难预估出高点和低点</p>
<blockquote>
<p>股票如何估值？PE？PB？ROIC？现金流折现？内含价值？马化腾差点 100
万卖掉腾讯，结果因为没人买而作罢这种事我会乱说？小马哥都没法对自己的公司正确估值，一般人……</p>
<p>我认为股票的低点不是最低点。没有人能预测股票的最低点。买股票最好的时机，我认为是突破布林线中轨的时候。最好是一根大阳线突破，伴随成交量。当然，成交量突破中轨前就要有……这很重要。这时候还不要买，等一等。也许股价会回抽，回抽确认中轨有效的时候，全力买进！</p>
</blockquote>
<ul>
<li>风险</li>
</ul>
<p>指数可以认为是“不会死”的品种，这是由指数的自动更新迭代的机制决定的，《<a
href="https://youzhiyouxing.cn/materials/813">安全的指数投资</a>》是这么说的：<strong>只要交易所不关门，只要基金公司不倒闭，哪怕这只基金清盘了，都没事——基金清盘，扣除一定费用后，你的钱会按照净值还给你。股票退市了你可什么都没有了</strong></p>
<blockquote>
<p>指数会有一个自动更新迭代的机制，比如每年，或者每半年，甚至更加频繁地重新编制。大部分指数重新编制成份股时不会大动干戈，通常只改变其中的
20%，比如对于 50 只成份股的指数来说，每次大概变动就 10 只，先剔除 10
只，再纳入新的 10
只。走人的股票是不符合指数编制要求的，而请进的是那些符合的。所以一旦成份股中有公司亏损，或者甚至业绩不佳就会有可能被轰走。在一个经济正常发展的国家里，永续的指数长期就是上涨的。</p>
</blockquote>
<p>因此，指数具备优胜劣汰的天然属性，这一点在《<a
href="https://youzhiyouxing.cn/materials/715">沪深300十大权重股变化的两点感想</a>》中也提到了，即2021
年的沪深300已经与十年前完全不同，不是当年的「金融300」指数了</p>
<ul>
<li>收益</li>
</ul>
<p>这部分其实在上面的风险中提到的指数自动更新迭代机制中也提到了，</p>
<blockquote>
<p>个人始终认为基金是老百姓最好的投资工具。不管股票基金债券基金还是货币基金。本人的基金金额是股票的
8 倍。我研究了半天，基金的表现始终还是比我好。</p>
</blockquote>
<p>在《为什么我很少谈论个股》中，讨论了为什么牛市中大多数人干不过指数</p>
<blockquote>
<p>第一，<strong>指数本身就是股票组成的，简单来说，一定有一半股票跑不赢全市场指数</strong>。
如果是权重股行情，那就不用说了，80% 股票跑不过大指数。</p>
<p>第二，<strong>大多数人都是不停的交易</strong>。
你自己看成交量。牛市换手率在 100%-200%
之间。半年所有股票就能换手一次，你就知道多少人在不断的买进卖出了。一般都是买<strong>进强势股，卖出弱势。按照均值回归，可想而知大概率是买了就跌</strong>，卖了就涨了。你不换？你不换你手里的就是不涨。服不服？你换了才涨。</p>
<p>第三，<strong>低位是没人买的</strong>。
大多数人是越涨越兴奋。场外观望的也是越高越买。买当然要买强势的，结果就是
gg。</p>
</blockquote>
<ul>
<li>成本</li>
</ul>
<p>这里主要指个人投入精力的人力成本，包括选股、盯盘等花费的精力</p>
<p>指数的优点是，对于选股能力不强的朋友（90%
的散户）来说，可以不用去学习枯燥的会计知识、跟踪瞬息万变的公司变化，只要大致看看历史估值，找个低位买入即可。</p>
<p>但是股票需要学习更多的概念，还需要做到“能选出好的股票、能买在低位、能卖在高位、有坚定的信念在赔钱的时候相信它会涨、回本后坚信还能涨”；这里的每一步都涉及到比较多的细节，这里就不赘述了，更详细可参考文档里的内容。</p>
<p>另外，这篇长文《<a
href="https://mp.weixin.qq.com/s/8Xhx5hN3xLJU6Oeo4GP94w">股票交易背后的残忍真相</a>》里也花了很长篇幅说明个股投资存在的风险，里面还涵盖了很多股票交易的现象，推荐读一下</p>
<h3 id="a-股指数">A 股指数</h3>
<p>在《<a href="https://youzhiyouxing.cn/materials/715">常聊的 A
股指数</a>》，E 大提到了其主要关注的 A
股的指数(2021/01)：沪深300、中证500、创业、科技、消费、医药；其中前两者属于大盘宽基指数，后三者都可归类为行业指数，这些指数都比较好理解，；而有知有行则专门为<strong>红利指数</strong>这个关注度没那么高的指数写了三篇文章</p>
<p>《<a
href="https://youzhiyouxing.cn/materials/795">红利指数系列（一）：深证红利为什么风景独好？</a>》
《<a
href="https://youzhiyouxing.cn/materials/824">红利指数系列（二）：标普红利的高开低走</a>》
《<a
href="https://youzhiyouxing.cn/materials/865">红利指数系列（三）：普通却实用的中证红利</a>》</p>
<p>红利指数是一个根据股票的股息和分红来进行编制的指数，市场上红利指数有很多，即便是主流的红利指数，也分为<strong>上证红利、深证红利、中证红利、标普红利</strong>这
4
个，并且这四个指数虽然在名称中都有「红利」二字，都将自己定位于寻找股息率高、分红稳定的股票，但其实他们四个差别很大，这与
4
个指数的编制方式关系较大。文章提到这点笔者比较认可:<strong>很多人有误区，觉得选主动型基金才需要关注基金经理的投资理念和选股逻辑，指数不需要。事实上，指数基金也是同样需要分析，因为指数的编制方法决定了它的选股策略。</strong></p>
<ul>
<li>深圳红利</li>
</ul>
<p>红利指数的<strong>一般排名规则就是按照股息率从高到低</strong>进行排序，但深证红利却是考虑了股票过去三年累计分红金额（绝对值）占整个深市分红总金额的比例，这个比例越高，排名越靠前，跟通俗来说就是它考虑是分红金额这个绝对值，而不是股息率（<strong>股息率
= 每股分红 /
每股价格</strong>），这样的编制方式会对那些每股价格高但是股息率低的股票有优势，即<strong>深证红利偏向于大盘股</strong></p>
<p>选完成分股后，该考虑每只成分股的权重了，也就是指数的加权方式。深圳红利采用的加权方式<strong>不是股息率加权，而是自由流通市值加权</strong>（其他三个红利指数采用的都是股息率加权）。即哪个股票的自由流通市值大，权重就高。作为一个红利指数，加权的指标却不是红利而是市值</p>
<p>因此，从上面的编制方法可知，深证红利的<strong>红利属性较弱</strong>，跟我们常规认为的红利指数有很大的不同。红利只是它筛选的指标之一，除此之外，它还要看日均成交额、经营状况、现金流等数据。文章认为“深证红利不太像一个红利指数，更偏向于一个基本面指数”</p>
<ul>
<li>标普红利</li>
</ul>
<p>标普红利全称是「标普中国A股红利机会指数」，其编制方式是建立一个成分股备选池，这个备选池需要满足过去
3 年盈利增长必须为正、过去 12
个月的净利润必须为正的要求。然后，所有入选的股票按照年度（过去 12
个月）股息率排名选出最高的 100
只股票，按照股息率加权构成指数。在构成指数的过程中，为了分散，规定了每只股票权重不超过
3%，单个行业不超过 33%。</p>
<p>但是标普指数公司只给了这些介绍，并<strong>不公布历史持仓</strong>，导致大家没办法分析，根本不知道这个指数具体怎么选股，而这种编制方式存在几个隐患</p>
<p>(1)成分股的股息稳定性不好;标普红利想寻找A股市场上具有稳定高分红能力的公司,但事实上它<strong>只看过去一年的股息率排名。过去一年的周期太短了</strong>，这么短的周期，会选中一些出于特殊原因提高自身股息率的公司
(2)<strong>周期股占比太高</strong>;
标普红利选股逻辑会使得它持有很高比例的周期股,
容易在经营业绩很好、分红多的时候纳入周期股，但周期过去后，这些个股的股价会大幅下跌。而股价下跌会进一步导致这类产品股息率一直很高，很难从指数中剔除出去，指数就会被这类成分股的股价下跌所拖累。
(3)对垃圾股的容忍度高; 并没有像其他红利指数那样剔除 ST
等垃圾股，而是在所有A股中进行选择 (4)指数样本调整频率高;
标普红利每半年调整一次样本，调整频率比其他红利指数高,
本来就是按照过去一年的股息率排名选股，成分股变动已经挺大了，再加上半年调整一次，这就导致成分股变动更大</p>
<ul>
<li>中证红利</li>
</ul>
<p>中证红利的成分股是从沪深A股中进行选择，不对某一市场和赛道过于依赖。作为对比上证红利是从沪市中选择，深证红利是深市中进行选择。</p>
<p>虽然标普指数和中证红利都是从整个 A
股中选择，但是相比于标普指数的编制方式导致成本股变动过大，中证红利在这方面好了很跟标普红利比，中证红利是按照过去<strong>两年的股息率</strong>进行加权的，考察周期更长。另外，为了避免公司的特别行为，它要求公司过去两年<strong>连续分红且每年的税后现金股息率都要大于
0</strong>, 具体的编制方式为</p>
<blockquote>
<p>过去两年连续现金分红且每年的税后现金股息率均大于 0,
按照过去两年的平均税后现金股息率由高到低进行排名，选取排名在前 100
名的股票</p>
</blockquote>
<p>文章在这部分给的建议是<strong>中证红利跟其他红利指数比，很普通，但具有市场代表性，如果你想投资红利指数，请选择中证红利</strong>。</p>
<h3 id="海外指数">海外指数</h3>
<p>投资过程中容易有<a
href="https://wiki.mbalib.com/wiki/%E6%9C%AC%E5%9C%9F%E5%81%8F%E5%A5%BD">本地偏好</a>，即只投资自己所处区域对应的金融市场，但是从资产配置的角度来说，把资产合理配置到<strong>相关系数很小的投资品种</strong>中，才能有效平滑风险，关于资产配置会在后续的买与卖中详细展开</p>
<p>E 大早在《<a
href="https://youzhiyouxing.cn/materials/716">聊聊海外市场</a>》中就提到，在全球配置的过程中，<strong>成熟市场
+
新兴市场</strong>比较合理，A股无疑是个新兴市场，那么将A股与美国、欧洲甚至香港的资产统一配置。</p>
<p>在里面提到了投资海外市场的一个工具， QDII(Qualified Domestic
Institutional Investor) 基金，简单来说就是海外市场的基金，基本分类跟 A
股其实也差不多，《<a
href="http://fund.eastmoney.com/a/202004011439644931.html">关于QDII基金的一切
看这一篇就够了</a>》里讲了 QDII 基金发展的一些历史以及 QDII
基金的一些常识，推荐读一下</p>
<p>QDII 基金的种类跟 A
股的基金差不多，有主动股票型、指数型、混合型、债券型、另类投资型(包括商品型、房地产信托型、绝对收益型、资产配置型FOF)等。而QDII-指数型基金，是QDII基金中最重要的工具性品种，覆盖了多个重要的海外市场股指，比如<strong>恒生指数、标普500、纳斯达克100、英国富时100、德国DAX、日经225</strong>等，此外，还覆盖了部分海外医药行业指数，如标普500医疗保健等权重、标普全球1200医疗保健、纳斯达克生物科技等</p>
<p>值得注意的是，除了正常的股市波动的风险，QDII 基金还存在 2
个额外的风险</p>
<p>(1)<strong>汇率风险</strong>;
QDII基金都是出海投资的，到海外市场投资就得换外币，持有外币资产就必然要面对汇率波动的风险。而汇率有涨有跌，汇率波动带来的影响也有正面、有负面。人民币贬值，对基金净值产生积极影响，人民币升值，对基金净值产生负面影响。
(2)<strong>外汇限额带来的流动性风险</strong>;国家采取外汇配额制，基金公司所获配的外汇额度在一定时期内都是固定的。如果QDII基金申购踊跃，导致外汇额度被耗尽，那要想再新增申购，就只能等别人赎回腾出额度才行。比如近来各路资金老想抄海外股市、原油大跌后的底(2020)，大量资金涌入导致大半QDII基金因为没有额度而暂停申购</p>
<p>对于第二个问题，如果基金本身可上市交易，那在<strong>折溢价率合理的前提下，通过二级市场来达成策略计划倒是一种应对方案</strong>。</p>
<h3 id="指数基金与主动型基金">指数基金与主动型基金</h3>
<p>选择股票基金的时候通常有 2
种类型：指数基金和主动基金；选择哪一种是个值得思考的问题</p>
<p>这里的「主动」指的是其选择投资标的，部分或完全由基金管理团队决定，由于基金的信息披露制度是周期性（基金季报）、不完全性（部分股票），非及时性的（季度过去20多天公布季报），所以你<strong>不可能知道一只主动管理基金过去做什么（部分知道），现在在做什么，未来会做什么</strong>。</p>
<p>因此，孟岩在《<a
href="https://youzhiyouxing.cn/materials/541">如何选择主动型基金？</a>》中提到了选择主动型基金的难度：如果只依靠基金经理过去的业绩去选择基金时，会存在下面
2 个问题</p>
<p>(1)在 07
年回测时发现一个有趣的现象，选择每年排行靠后的基金，第二年通常可以跑赢大部分同行，这岂不是意味着可以通过买某年排名后几名的基金来战胜市场了？后来发现，造成这个「结果」的「原因」是：由于<strong>市场风格切换的原因，在某一年成功「赌」到某个风格的基金经理通常会排名市场前列</strong>，大仓位「赌错」的基金经理则会排名靠后。当第二年市场风格切换的时候，排名靠后的基金经理的业绩则又排名前列。
(2)由于基金经理的变动比较频繁，并且存在多人管一只基金、离职造成业绩空档等现象，因此通常会采用市场拟合等各种方式去修补一个基金经理的业绩曲线。这样进一步带来了研究的不准确</p>
<p>而在《<a
href="https://youzhiyouxing.cn/materials/527">指数基金的五大优势</a>》中，就提出了指数基金相对于的
5 个优点，认为指数基金更适合普通投资者。</p>
<blockquote>
<ol type="1">
<li><strong>可预测的投资对象</strong>。指数基金过去和现在投资了什么我们一清二楚；而且指数基金将会如何投资，我们也一清二楚;可预测的投资对象会带来一个巨大的优势：<strong>可估值</strong>。所以大家才会看到指数市盈率，股息率等信息</li>
<li><strong>永续 +
上涨</strong>。指数会有一个自动更新迭代的机制，比如每年，或者每半年，甚至更加频繁地重新编制。一旦成份股中有公司亏损，或者甚至业绩不佳就会有可能被轰走。在一个经济正常发展的国家里，永续的指数长期就是上涨的。</li>
<li>注意力区别。相比选择被动管理基金，那些选择主动管理基金的投资者更容易被短期业绩影响，在买入基金之前的选择标准就喜欢考虑短期业绩</li>
<li><strong>制度风险低</strong>。主动基金有可能会出现老鼠仓或利益输送的现象，而指数基金不会</li>
<li><strong>管理费、托管费低</strong>。指数基金的管理费率相比主动管理类型的基金就低很多，托管费也低一些。有的指数基金，特别是ETF基金会多一个标的指数许可使用费，费率很低。</li>
</ol>
</blockquote>
<p>而 E 大在《<a
href="https://youzhiyouxing.cn/materials/713">指数与股票的区别</a>》和
《<a
href="https://youzhiyouxing.cn/materials/714">指数到底哪里好？</a>》里都提到了更推崇指数基金的原因，原因跟上面的类似</p>
<blockquote>
<p><strong>主动基金的问题就在于决定它成绩好坏的环节过多</strong>。有时候过去的成绩好你并不知道它的基金经理是运气好还是实力强，你也不知道这个实力强的基金经理明天还会不会继续管理这只基金。总之，一切都是未知。</p>
<p>我投资指数基金的两个最重要原因： 第一，指数基金是真正的几乎 100%
「权益类资产」。
<strong>主动基金赋予基金经理的权力太大，可以不断增减仓位。而配置资产这件事我自己完全可以完成，我购买指数基金就是为了配置我资产中「权益类」资产</strong>。我买
10% 的指基，就希望有 10% 的权益类资产；如果主动基金把仓位变成
80%，我的权益类资产变成 8%了，我还怎么配置资产？
第二，<strong>指数基金可以估值</strong>。
指数基金发展到今天，类别已经很多。低估、成长、价值、行业……我可以通过对每个类别进行估值，并计算业绩增速，根据模型投入不同的资金。而主动基金则完全无法估值，你根本不知道这只基金的基金经理下个月会买卖什么股票。你所有的宝，都压在基金经理和基金公司的身上。
简单地说，指数基金持有的股票是有「规则」的，主动基金没有。没有规则的东西很难把握。</p>
<p>长期看，一定有 20%～30%
的主动基金表现会比指数强，即使你能在指数基金上低买高卖，也一定有
10%～20% 的主动基金长期表现更好。如果你能够找到这些在未来表现出色的
10%～20%
主动基金，那么你就适合投资主动。否则，被动指数投资是很适合你的。</p>
</blockquote>
<p>另外，文章还着重提到了“<strong>在股市赔钱，大概率不是因为你买了指数还是主动，而是因为你牛市入场，熊市出场</strong>”,
而相比投资主动还是被动来说，建立你自己的投资体系才是真正重要的事。</p>
<h3 id="选择基金还需要考虑什么">选择基金还需要考虑什么</h3>
<p>前面讲了指数与个股、指数基金与主动性基金的一些区别，且更推崇普通投资者投资指数基金，那在选择时还需要考虑哪些因素。</p>
<p>E 大在《<a href="https://youzhiyouxing.cn/materials/714">我选择指数的
2 个思路</a>》给了 2 个选择指数的参考指标</p>
<blockquote>
<p>第一个是<strong>绝对跌幅</strong>。
我个人的定义是<strong>最高点到最低点绝对跌幅是跌到 20%～32%（跌到
20%～32%。也就是说下跌
68%～80%）</strong>。任何指数到了这个区域我都会大力布局。
第二个是<strong>连跌时间</strong>。
在A股，<strong>连跌三年</strong>被我看做黄金机会。一个是空间，一个是时间。</p>
</blockquote>
<p>而常说的指数往往也分为<strong>宽基指数和行业指数</strong>，顾名思义，前者投资的是整个大盘，后者则是某个行业，在《<a
href="https://youzhiyouxing.cn/materials/197">如何选择好资产中</a>？》，给出的策略是：<strong>通过以沪深300和中证500为主，其它类似消费、医药、信息、红利等指数基金为辅的方式，形成自己的资产组合</strong>。其实就是宽基指数和行业指数相结合的方法，这跟
E 大在在前面提到的 6
种指数也是不谋而合的，至于具体的仓位配置，会放到买与卖中讨论。在《<a
href="https://youzhiyouxing.cn/materials/562">为何普通人应投资多行业均衡配置的基金</a>？》里也提到了类似观点，这里就不展开了。</p>
<p>虽然前面都是在推崇指数基金，但是如果要选择主动基金，孟岩在《如何选择主动型基金？》中还是给了一些参考；这个过程与其说选择主动基金，不如说是在选择主动基金经理</p>
<blockquote>
<p>在《聪明的投资者》中，格雷厄姆认为：要想在一生中获得投资的成功，并不需要顶级的智商、超凡的商业头脑或秘密的信息，而是需要一个稳妥的知识体系作为决策的基础，并且有能力控制自己的情绪，使其不会对这种体系造成侵蚀。</p>
<p>我的公式：知识 x 情绪 x 意愿</p>
<p><strong>知识</strong>
你需要了解一个基金经理的投资哲学和系统。而看人比看公司，要更难。我们可以根据基金经理的访谈、文章等信息来判断他是否具备完整、自洽、符合投资大道的投资哲学，以及拥有进化这个系统的开放心胸和方式。然后再根据他在历史上的业绩、季报中股票的选择和调整来判断他是否在按照自己的「知」来进行「实践」。
<strong>情绪</strong>
观察一个人和组织，最好的方式是当「极端事件」发生的时候。比如 2018 年 10
月市场风声鹤唳的时候，基金经理是否能够平和、稳定、甚至发出一些乐观的声音;除了个人的情绪，我们还需要考察基金公司对情绪带来的影响。
<strong>意愿</strong>
「投资系统」也有了，「情绪控制」也能做到，那如何判断你委托、依靠的人能
100%
的站在你的角度为你着想和服务呢？我想可能有三种方式：名的绑定、利的绑定、时间</p>
</blockquote>
<p>主动基金最关键在于基金经理，但选择主动基金时对及基金本身还是有一些指标可供参考的，在《<a
href="https://youzhiyouxing.cn/materials/796">同一个基金经理，不同的基金，到底选哪个好？</a>》里就讲了一些可参考的指标</p>
<ul>
<li>基金规模</li>
</ul>
<p>规模太小的话，会存在清算的风险，对于投资者来说，基金一旦清算，那就会从浮亏变成实亏，规模<strong>小于
5000 万</strong>的基金，最好不要碰。</p>
<p>而规模太大也会有问题，这里的大指的是<strong>超过百亿</strong>的基金；基金行业的规定，<strong>一只基金持有一家上市公司市值不得超过基金资产净值的
10%；此外，基金持有这只股票的仓位不能超过这家公司股份的
10%</strong>。所以规模太大的话，就要把每只股票的仓位降低，同时也会多配更多的股票，但基金经理可能没有那么多精力去调研那么多家公司，而且市场上好公司本来就不多。</p>
<ul>
<li>仓位集中程度</li>
</ul>
<p>仓位集中的股票起伏都比较大，<strong>谨慎选择规模大，仓位集中的基金</strong>，这类基金的风险会比较大。仓位分散的基金可能在市场震荡或者下跌的时候也分散了风险，业绩更具稳定性。而通过基金的重仓股票，也能初步的判断这只基金的投资风格以及投资的范围</p>
<ul>
<li>机构持有比例</li>
</ul>
<p>在基金资料页面我们可以看到持有人结构比例，一般有个人和机构两大类，机构持有者指的是企业、社会团体、事业法人等组织，个人的话就是散户。</p>
<p>受机构青睐的产品说明是比较优
质的，因为他们投资的不是自己的钱，而是关系到整个机构和整个团队的，投资前都会比较谨慎，会对基金公司以及基金经理做好充分的调研。所以在比较持有人结构上，文章建议选择机构资金占比多的，因为<strong>遇到股灾的时候，相对机构来说，个人投资者可能更容易受情绪影响，会出现频繁申赎的情况</strong>，资金频繁的进出会影响到基金的净值波动。</p>
<ul>
<li>新基金</li>
</ul>
<p>不建议买新基金，因为新基金的往往在牛市发行的频率较高，容易在高点建仓，同时手续费比较贵，很多都不打折</p>
<h3 id="非权益类资产">非权益类资产</h3>
<p>这里要讲的非权益类资产主要是四大类：债券、原油、黄金、房地产</p>
<p>在《<a
href="https://youzhiyouxing.cn/materials/1142">E大是如何看待各个大类品种的特性？（上）</a>》和《<a
href="https://youzhiyouxing.cn/materials/1150">E大是如何看待各个大类品种的特性？（下）</a>》中提到其资产配置的种类和对一些资产的看法</p>
<p>E大的资产配置主要分为了<strong>A股、境内债券、成熟市场股票、新兴市场股票、境外债券、原油、黄金、房地产</strong>，在且慢上可以看到其具体的配置标的和比例</p>
<p>同时谈到了对这些资产的一些看法，这里主要摘录非权益类资产部分</p>
<ul>
<li>债券</li>
</ul>
<p>债券是可估值资产，比如说现在十年期国债收益率 3.2%，你就知道，它就比
2% 的时候有投资价值。</p>
<p>历史十年期国债收益率的波动范围，大致是 2.5%~5%
之间，可以根据这个配置你的债券资产。配置时需要注意 2 点</p>
<ol type="1">
<li>信用债与利率债</li>
</ol>
<p>利率债大多是国债、国开债等国家发行的债券。
它们更多的与利率水平相关，不用考虑信用问题，因为几乎是刚性兑付的。而信用债的收益率会高，但偿付信用是依据发行债券企业的信用。</p>
<p>这样你就应该理解，<strong>在经济危机中，只有利率债会一枝独秀。因为那几乎是唯一可以确定保本的资产</strong>。</p>
<ol start="2" type="1">
<li>债券影响因素</li>
</ol>
<p>债券的走势几乎只与两点有关：<strong>收益率和流动性</strong></p>
<p>所谓流动性就是货币当局释放的货币多少。
<strong>债券投资的最佳时期，就是当局释放大量货币，然而经济又没有起色的时候。
这个时候钱多了，但经济不好人们不敢买股票，结果债券价格就会大涨。</strong></p>
<ul>
<li>黄金</li>
</ul>
<p>黄金的波动特性是巨幅波动，类似于涨十年，跌十年，然后再涨十年这种</p>
<p>通过回顾历史，发现每次美联储降息都预示着美国经济将出现一些问题，股市有可能下跌。
在这种流动性被释放，而经济和股市又出现问题的时候，黄金自然成为很多投资者的选项。</p>
<p>所以黄金的一个投资时间点： <strong>流动性释放 +
预期不好，避险功能被激活</strong></p>
<p>原油和房地产文章里涉及的不多，同时在资产配比里也不高，这里就不详细张开了</p>
<h2 id="几道计算题">几道计算题</h2>
<p>前面都是讲一些概念性的东西，这里则是从数学的角度去讲一下投资中的几道算术题，通过数字能够对股市中的涨跌更加敏感。在《<a
href="https://youzhiyouxing.cn/materials/1088">E大：投资中的六道数学题（上）</a>》就提到了几个让人在初看时就搞混的题目</p>
<h3 id="涨-10-跌-10">涨 10% ≠ 跌 10%</h3>
<p>在投资中能常听到的一道数学题是</p>
<blockquote>
<p>如果你持有的股票下跌 33%，那么需要上涨 50%
才能回本；如果你持仓的基金下跌 50%，那么上涨 100% 才能打平。</p>
</blockquote>
<p>从这道数学题上我们可以总结出一条投资经验：<strong>永远不要让你的资产大幅缩水，否则，回到高位，再创新高将是非常困难的</strong></p>
<h3 id="section">1.8×0.6 &lt; 1.05×1.05</h3>
<p>以下两种场景中选择一种作为你未来的投资收益率，你会选哪个？</p>
<p>(1)第一年赚 80%，第二年赔 40%，第三年赚 80%，第四年赔 40%…… (2)每年赚
5%。</p>
<p>也许很多人在看到第一个选项，直观感觉就是第一年赚 80%，第二年赔
40%，那两年合计能赚 40%，每年 20% ，当然比 5% 强。</p>
<p>但是在了解到前面提到的涨跌幅不能直接等价，我们会发现在偶数年，第一种情况的年化收益率是
4% 左右，还真不如第二种的每年 5%。更极端一些，如果单数年赚 90%，双数年赔
50%，那么长期收益率居然是负的</p>
<p>另外，这个也适用于基金经理和散户朋友</p>
<blockquote>
<p>各类基金经理有多少吗？至少有上万人。这上万人绝大多数因为没有名气，所以管理的基金规模都不大。当他们在某年赚到很多钱的时候，其实赚的绝对数字很小。比如
10 个亿规模，赚 100%，规模到了 20 个亿，赚了 10 个亿。
这样他在牛市成为冠军基金经理，名气大增，申购量暴增 5 倍、10
倍。于是，他管理了 100 亿资金。好的，熊市来了，这时候当他赔
40%，那么两年合计，到底赚了多少钱呢？ 亏损 40 亿 - 盈利 10 亿 = 消失 30
亿。 然而，他第一年赚 100%，第二年赔
40%，其实两年合计收益率还是正的。但是，30 亿就这么消失了。
实际上，<strong>当他的规模到了 100 亿以后，只要下跌 10%，之前牛市赚到的
100% 利润就已经消失殆尽了</strong>。</p>
<p>这个道理，也同样适合散户朋友。当你用一点点小钱在牛市中赚了幅度很大的钱，然后开始信心十足的转移储蓄加码买入的时候，很有可能是在消灭财富的前夜。</p>
</blockquote>
<p>这也是 E
大一直在文章里强调的<strong>“熊市不赔钱或者极少亏损，牛市大致跟上指数”</strong>的原因。如果几轮市场周期你都做到了，你赚到的钱是那些大起大落的人永远也赚不到的。</p>
<h3 id="section-1">80 - 50 ≠ 30</h3>
<p>E 大有一个 7080 定律，即<strong>一个不会死的品种极限跌幅在
80%</strong>。这就引出了一个问题，假如在腰斩，也就是下跌 50%
的地方买入，到了跌幅 80% 的地方，你的亏损幅度是多少？</p>
<p><strong>答案并非你认为的 80% - 50% = 30%，而是
60%</strong>；计算也很简单，假如原来是 10 块，跌到 5
块的时候买入，则跌到 2 块时，对于你而言，亏损是 (5-2)/5 = 60%</p>
<p>同理，你在同样品种已经下跌 60% 的地方买入，到了下跌 80%
的时候并非浮亏 20%，而是 50%。在已经下跌了 70% 的地方买入，到了下跌 80%
的时候并非浮亏 10%，而是 33.33%。</p>
<p>这里说明了一个道理，那就是<strong>从 0 到 -10% 的距离，与 -70% 到
-80%
的距离完全不同</strong>。这也是为什么熊市越到后来越惨烈的原因，那个时候财富的缩水远超一般人的承受能力，即使账面只变动了几个百分点。<strong>在熊市的末期，大多数一路抄底的人都会彻底崩溃。因为他们的损失只比站在山顶上的人小一点而已</strong></p>
<p>另外，这道数学题也说明了一个道理，不要轻易抄底或者说接飞刀，如果基线跌幅在
80%，那你抄在了 60%上，可能的跌幅还有 50%，而 E 大的文章里是这么说的</p>
<blockquote>
<p>对那些非常狂热急于抄底的朋友说几句。
没错，在股市上确实有所谓的<strong>「别人贪婪我恐惧，别人恐惧我贪婪」这句话。但实际上这是在很极端的时候才好用</strong>。在大多数情况下，市场是聪明的，市场大多数时候不是傻子。如果你认为市场大多数时间是傻子，那你才是傻子。
而且，你永远逆潮流而动，最终的结果就是被蜂拥而至的群众们踩在脚下。所以，还是要对市场和群众保持敬畏</p>
</blockquote>
<h3 id="概率与赔率">概率与赔率</h3>
<p>在投资中，我们通常关注的是收益率，而在《<a
href="https://youzhiyouxing.cn/materials/17">概率之外，多数人不会的赔率思维</a>》中，把这个收益率更细地拆成了概率和赔率，文章是这么说的</p>
<blockquote>
<p>投资是基于概率和赔率的游戏。</p>
<p>所谓概率，指的是一个事件发生的可能性有多大；所谓赔率，指的是这件事发生后盈利或亏损的程度。好的投资是两个因素共同作用的。</p>
<p>用一个简单的公式来表达：<strong>投资收益 = 概率 x 赔率</strong>。</p>
<p>如果只注重概率，当遇到极端事件时可能会赔光；如果只注重赔率，那我们可能会浪费掉很多还不错的「积小胜为大胜」的投资机会。</p>
</blockquote>
<p>文章给了一个博彩业的如何利用赔率和概率，来达到坐庄永不亏损的目的</p>
<blockquote>
<p>世界杯决赛，德国对英格兰。赌球玩家们开始下注了：买德国队赢的资金合计有
120 万，买英格兰队赢的合计有 80 万。
如果你是庄家，你需要操控这场比赛来获利吗？你需要准确预测结果来获利吗？答案是：不需要。
赌局里有个因素叫「赔率」。赔率为 1.2，表示玩家投入 100 元，赌对了会拿到
120 元（包含 100 元下注本金）。 假设德国队赢的赔率是
X，根据上面的资金分布，德国队赢时庄家要支付的资金是 120 x X
万，赔给买德国队赢的玩家。 只需要保证120 x X &lt; 120 + 80 ，即 X &lt;
1.67，你就一定不会亏钱。 同样地，英格兰队赢的赔率是 Y，只需要保证 80 x Y
&lt; 120 + 80 ，即 Y &lt; 2.5 ，你就不会亏钱。
当然咯，你还可以设定一点「安全边际」。把德国队赢的赔率设为
1.50，英国队赢的赔率设为 2.25： 则有如下结果 德国队赢，你有 120 + 80 -
120 x 1.50 = 20 万利润； 英国队赢，你有 120 + 80 - 80 x 2.25 = 20
万利润； 决赛没有平局，<strong>无论哪边赢，你都能锁定 20
万</strong>。</p>
</blockquote>
<p>文章还提到了长期资本(<a
href="https://www.investopedia.com/terms/l/longtermcapital.asp#:~:text=Long-Term%20Capital%20Management%20%28LTCM%29%20was%20a%20large%20hedge,prevent%20financial%20markets%20from%20collapsing.">LTCM</a>)忽视了概率小，但是赔率高的情况而导致了最终消失的例子。长期资本的投资策略是单次获利收益不高，但是获利概率很大，因此通过
LTCM
加杠杆的办法扩大收益。但最终因为俄罗斯债务危机，走向了破产清算的末路。</p>
<h2 id="宏观常识">宏观常识</h2>
<p>虽然在之前的《<a
href="https://wulc.me/2021/11/14/%E5%BC%A0%E6%BD%87%E9%9B%A8%E7%9A%84%E4%B8%AA%E4%BA%BA%E6%8A%95%E8%B5%84%E8%AF%BE%281%29-%E5%B8%82%E5%9C%BA%E8%A7%84%E5%BE%8B/">张潇雨的个人投资课(1)-市场规律</a>》提到宏观迷信这个问题，即宏观经济在投资中所起作用并非那么大，不需要整天研究宏观经济。但是在学习了一段时间后，发现了“股票的长期增长来源于经济的增长”，不禁对之前的结论产生了一些怀疑。</p>
<p>后来在E大的《<a
href="https://youzhiyouxing.cn/materials/689">宏观经济跟股票走势有关系吗？</a>》中看到了比较好的分析和比喻</p>
<blockquote>
<p>人们通常关心哪些被认为与股市有关的宏观数据？我想无非是这几个：GDP、CPI
和 PMI（欧美很重要的就业数据在中国完全无用）。
我仔细比较了这几个数据与A股走势的关系，非常惊讶地发现：宏观数据与股票走势几乎没有任何关系——除了
PMI ，这个数据与A股关联度不错</p>
<p>为什么宏观经济数据与股市走势如此让人摸不着头脑？看起来毫无关联性？
在我看来，<strong>宏观经济是一个人，而股市是一条狗</strong>。他们就像主人牵着狗出去遛弯，有时候狗会跑得很快，有时候狗又会停下来对自己感兴趣的东西闻来闻去。而此时，主人的速度虽然有快有慢，但他跟狗不会是同样的快慢，所以他们之间会时远时近。</p>
<p>1996 年、2006 年、2007
年，就是这条狗发现了自己感兴趣的异性，疯狂地试图挣脱主人手里的绳子往前跑；而到了
2005 年、2008
年，它又碰上了打狗队，害怕地躲在主人身后很远很远。这样，有趣的问题就出现了，如果你试图用主人的行走速度去判断狗应该在哪里，就是一件非常可笑的事。</p>
<p>其实，<strong>整件事中你最应该关注的不是主人的速度，而是一样真正有意义的东西，那就是——那根绳子</strong>。你知道主人在哪儿，你就知道狗即使落后或超出，它的极限会在哪儿。这根绳子才是真正有价值的东西。</p>
<p><strong>这根绳子是什么？估值。</strong></p>
<p>当然，还有很重要的东西决定狗的跑动，比如吸引狗的骨头（投资者的预期）、狗的精神状态（货币量）。</p>
</blockquote>
<p>在《<a
href="https://youzhiyouxing.cn/materials/690">是什么决定了股市的涨跌</a>》提到的例子也能用来说明这一点</p>
<blockquote>
<p>当你用很短的时间，透支了很长时间成长的时候，你就需要用更长的时间来还债。2001
年股市 PE 到了 68 倍，之后 5
年虽然中国经济稳步增长，指数照样跌了一半就是这个道理</p>
</blockquote>
<p>所以，前面提到的结论并没错，但宏观经济与股市的关系绝非简单的线性关系。用宏观经济指导股市投资恐怕越错越远。世界上绝大多数正常发展的国家，股市都会一路向上。而我们要做的不要再去盯着上证指数是
2200 点还是 3200
点了(宏观经济与实际投资回报关系不大是是一个原因，而上证指数本身的编制方式是另一个原因)。想办法找到那个万年长青的企业，或者找到一个组合完善的组合才是重要的。</p>
<p>那为什么这里还要提宏观经济呢？因为了解宏光经济一些相关的知识，能然我们对钱的流动有更好的认知，会让我们更好判断出当前的“人”在哪，速度是快是慢等。</p>
<h3 id="银行体系">银行体系</h3>
<p>这里主要介绍现代银行体系，了解这些会对新闻里常说的央行加息、货币紧缩等词汇背后的含义更加清楚</p>
<p>在《<a
href="https://mp.weixin.qq.com/s/RqcrNwlzoMnR4p-M57UAPA">我们真的了解钱吗?</a>》详细讲了货币的演变历史，很有意思，这里摘录其中关于的关于商业银行的部分，也推荐看对应的<a
href="https://www.bilibili.com/video/BV1N34y187z2?spm_id_from=333.999.0.0">视频</a></p>
<p>银行分为两种，<strong>商业银行和中央银行</strong>，的区别如下</p>
<blockquote>
<p>商业银行就是咱们普通老百姓平时存钱，办理贷款业务的银行。一般都是股份制，有机构，或者私人参与，不完全由国家控股，所以它的利益诉求，是为了盈利，也就是说赚钱和发展是它们的首要目的。主要业务就提供<strong>储蓄和贷款</strong>;主要的盈利方式，就是吸收居民的存款，然后给个人或者企业放贷，然后赚中间的息差</p>
<p>中央银行，是一个国家公共机构,
目的是，<strong>调控好国家的宏观经济，监管金融市场，保证国家金融制度良好的运行</strong>。如中国的中央银行全称叫做【中国人民银行】，常听到的【央行】或者【央妈】就是指它；美国的中央银行，全称叫做【美国联邦储备系统】，也就是常听到的【美联储】</p>
</blockquote>
<p>中国的商业银行，其中靠前的六家大型商业银行，<strong>工商、农业、中国、建设、交通、邮储，属于国家控股的国有商业银行</strong>，所以它们除了追求自身盈利之外，同时也承担了配合落实国家货币政策的职责。而往下一级的商业银行比如我们比较常见的
中信、招商、华夏、平安
等等并非完全国有，所以侧重点更偏向于自身盈利和发展。</p>
<p>美国的商业银行大部分都是机构持股，政府持股的比例相对较少所以美国的商业银行基本都是以自身盈利赚钱发展为主要目的，所以立场方面非常的清晰。</p>
<p>央行的主要职能包括</p>
<ul>
<li>印钞，发行货币；比较好理解不展开</li>
<li>作为政府的银行；代理国库的收支，以及代理政府债券的发行，为政府提供贷款，保管管理国家的黄金以及外汇储备等</li>
<li>监管其他商业银行、制定调整货币政策等</li>
<li>与其他商业银行进行存、贷、拆借等业务</li>
</ul>
<p>这里着重讲最后一点，即央行和其他商业银行的业务往来，主要有以下三种</p>
<p>(1)为商业银行做最后贷款人
即商业银行的钱如果都贷款出去了，这个时候如果有很多储户来取钱，商业银行里的钱不够的话，银行的信任就会出现问题，这个时候央行就会贷款给商业银行，帮助兜底。</p>
<p>(2)处理全国商业银行的票据清算
大致的意思是每一家商业银行在央行都有自己的独立账户，我们平时日常的个人或者企业跨行转账的时候，收付的票据以及资金清算这些数据最终都会传导到央行统一处理</p>
<p>(3)集中收取存放所有商业银行的存款准备金
商业银行每收到一笔存款，都要把这笔存款拿出一小部分放在央行，而放在央行的这部分钱就叫做<strong>存款准备金</strong>，这个比例就是存款准备金率,
控制这个准备金率能控制商业银行创造出来的货币量，或者说市场上流通的货币量，文章举了下面的一个例子</p>
<blockquote>
<p>假如现在商业银行里一分钱就都没有，而这个时候你存了100元现金在银行里，你的银行的账户里就有了100元存款。假设存款准备金率是10%
那么按照这个比例，你现在存的这 100 元，商业银行就要放 10
块钱在央行，那么剩下的 90 元商业银行就可以拿去放贷。 假如这 90
元贷给了你的朋友，你的朋友拿到钱以后，用这笔钱去服装店买了一件衣服,
而服装店老板赚到这笔钱以后，又会把这 90
元，存进商业银行。于是现在服装店老板的银行账户里，也有了 90 元
那么现在商业银行里的存款总数，就变成了你的 100 元加上服装店老板的 90
元，总共是 190 元 现在把这个例子继续下去,商业银行收到了服装店老板的 90
元存款以后，又会拿出 90 元的 10%，也就是 9 块钱放在央行,那么它又有了 81
块钱可以放贷，而这 81
块钱贷出去之后，又会被人存回商业银行，然后商业银行又会继续放贷。就这样循环到最后<strong>你会发现最初你存进去的100元，经过商业的银行不断的放贷操作，最终扩张10倍,变成了
1000元</strong></p>
<p>这个倍数就叫做<strong>货币乘数</strong>;
而这1000元里面，只有你最开始存进去的那100元才是真正的纸币，所以这100元，我们称之为“<strong>基础货币</strong>”,
而剩下的那900元，就只是个数字而已，并没有对应的纸币，这种没有纸币对应的钱，我们称之为“<strong>派生货币</strong>”
而这最多就只能扩张10倍，是由于存款准备金率是10%决定的，这个率越低，能扩张的倍数就越大（笔者附，这里的计算基于无穷级数
<span class="math inline">\(\sum_{n=0}^{\infty} x^{n} =
\frac{1}{1-x}\)</span>）</p>
<p>目前我国基础货币+派生货币总量一共是233万亿左右,
而这其中基础货币的数量又占多少呢？答案是：只占了很小一部分，大概<strong>七分之一不到</strong>；就是说咱们社会上流通的钱大部分其实都是派生货币，只是个数字而已，并没有对应的纸币。这也是为什么<strong>银行最怕挤兑</strong>了</p>
</blockquote>
<h3 id="利率">利率</h3>
<p>这里的<a
href="https://zh.wikipedia.org/zh-sg/%E5%88%A9%E7%8E%87">利率</a>，直观理解就是常说的利息，或者获得资金的成本；如存款利率是银行向存款人获取资金的成本，贷款利率则是贷款人向放贷人（一般为银行及金融机构）获取资金的成本；在宏观经济中，利率常常会作为一个调控经济的手段，<strong>一般来说，利率上升时，各方获取资金的成本上升，会抑制积极性，而利率降低时，获取资金的积极性提高，投资扩大，刺激经济</strong>。</p>
<p>常说的 <a
href="https://www.zhihu.com/question/29708481">降准与降息</a>
中的降息，指的就是降低利率，两者的更详细的区别和含义如下</p>
<ul>
<li>降准：降低存款准备金率，这个概念在上面有一个详细的例子说明；降准会让商业银行有更多可放贷的钱</li>
<li>降息，就是降低存款基准利率或者贷款基准利率，投资者存款收益就变少了，于是会更愿意将钱取出来用于投资，例如购买股票、房子。相应的，企业和个人的贷款成本也会降低，从而使更多的人愿意贷款去做投资</li>
<li><strong>降准是放钱出来，增加了市场资金量，而降息并没有增加市场资金，只是改变人们的资金投向，鼓励人们更多的去消费和投资</strong></li>
<li><strong>降息比降准影响更大，市场对利率也更加敏感</strong>；市场货币量的变化，影响主要是对金融机构；而价格的调节，则是直接影响整个市场</li>
</ul>
<p>在这个视频里《<a
href="https://www.bilibili.com/video/BV1S3411g7Gh?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&amp;vd_source=0ecf29444015c908a45366cf8b9a4909">【干货】关于利率，你需要知道的那些事儿</a>》，则更详细地把利率拆成了<a
href="https://zh.m.wikipedia.org/zh-hans/%E6%97%A0%E9%A3%8E%E9%99%A9%E5%88%A9%E7%8E%87">无风险利率</a>，风险溢价和银行的油水三大部分；并指出央妈主要调控的是无风险利率（十年期国债收益率）这部分，并且指出了利率与通胀、债券、股市等关系，这里直接讲结论，</p>
<p>1.利率与通货膨胀：长期低利率容易导致通货膨胀，这时候中央银行往往会提高利率
2.利率与债券：长期利率是拿债券价格反算出来的,
两者成反比关系，所以利率涨了，债券价格会掉(具体公式可以参考视频)，这是比较明确的关系
3.利率与股票：加息初期对股市是利空的，但是长期没有非常明确正相关或负相关；这里举了一个地球与月球的例子很精彩
4.利率与房地产/黄金，关系都是不确定的</p>
<p>而在《<a
href="https://youzhiyouxing.cn/materials/1123">E大是如何对多类品种、信息保持有效关注的</a>》中，也提到了类似观点</p>
<blockquote>
<p>利率会传到到各个大类资产上。 首先会影响债券。
<strong>利率上升，债券价格会下跌。 利率下降，债券价格会上涨</strong>。
然后是股票，然后是商品。</p>
<p>利率又与通货膨胀紧密联系。 通常情况下，恶性通胀会导致利率上涨。
这样就尽量少一些持有债券和股票。多持有金银等贵金属。
缓慢的通胀，利率水平较低，则可以多持有一些债券和股票。
通货紧缩可以多持有债券、少持有商品和股票。</p>
</blockquote>
<h3 id="通货膨胀">通货膨胀</h3>
<p>通货膨胀是一个耳熟能详的概念，大概意思就是钱不值钱了，但是当我们要更深入的去理解通胀，你会发现它比我们所看见的其实要更加复杂。因为在实际的过程中，钱这个东西是流动的，只有当钱流到流到某一个市场的时候，这个市场的东西才会涨价</p>
<p>比如流到了汽车市场，汽车就会涨价，流到的生活用品市场生活用品就会涨价。所以在真实的情况中，每一个市场的通胀都是不一样的</p>
<p>常见的衡量通胀的指标是 <a
href="https://zh.m.wikipedia.org/zh-hans/%E6%B6%88%E8%B2%BB%E8%80%85%E7%89%A9%E5%83%B9%E6%8C%87%E6%95%B8">CPI</a>(Consumer
Price Index)，但是在 《<a
href="https://mp.weixin.qq.com/s?__biz=MzkzNDE3NDgzMw==&amp;mid=2247484104&amp;idx=1&amp;sn=884a6b977dac9aede84d8b93a1f92cc1&amp;chksm=c2400bd6f53782c06dceea5d3a7ee8b076c74920b723e33b4224d3187e4c05d7969b898db13e&amp;scene=21#wechat_redirect">你为什么总是那么穷</a>》
和 《<a
href="https://mp.weixin.qq.com/s?__biz=MzkzNDE3NDgzMw==&amp;mid=2247485277&amp;idx=1&amp;sn=2fdcdb00665a62487e985fd0b935b65c&amp;chksm=c2400e43f5378755b03dde5f386b3ab957e1502fd8653d31d6a91d877a6002c6eac3a0edb12f&amp;scene=21#wechat_redirect">我们真的了解钱么</a>》指出用
<strong>M2 - GDP</strong> 评估更为合理，M2 可以简单理解为全社会所有的钱,
结合上面的银行体系概念，<strong>M2=全社会所有的基础货币+派生货币</strong></p>
<p>CPI的数据是准确的，我们平时买的猪肉，大米，以及生活用品，确实只涨了这么多。但是，它只能反映出一部分，因为各国的
<strong>CPI
往往没有把金融资产这一项计算在内，而现实中最大的通胀往往就发生在这个领域</strong></p>
<p>文章举了如下例子</p>
<blockquote>
<p>08年到现在十几年的时间里,标普500指数从一千多点，一直上涨到了现在的四千多点，翻了三倍多,而这背后很大的一部分原因就是
"通胀" 去年到今年仅仅一年的时间,
比特币的价格从不到一万美元，暴涨到现在的五万多美元，这其中有部分原因也是因为通胀。
因为去年疫情到现在美国疯狂印钱超发了大量的货币，而这些钱又大量流入金融资产导致了金融资产价格上涨。所以无论是股市，比特币，这些金融资产的上涨其实都是一种通胀现象。</p>
<p>而<strong>这种金融资产的通胀，在我国的载体则是房子</strong>。从08年到现在我国的房地产价的大幅上涨，这背后很大一部分原因，其实也是因为通胀。超发的货币大量流入房地产行业循环，所以造成房地产价格大幅的上涨。</p>
</blockquote>
<p>那为什么我国的通胀会发生在房地产呢？</p>
<p>上面的银行体系中提到了货币是如何增发的，在总体 M2
中派生货币占了很大一部分，而能派生出来的原因银行的放贷，或者说<strong>信贷扩张是货币增发的源头</strong></p>
<p>那我们最大的信贷源头，是哪里呢？那就是房地产了，过去这么多年贷款最多就是房企，和居民购房贷款，比如我们去看08年以前，你会发现贷款买房的人是很少的，但08年信贷政策大力开放之后，大家都开始贷款买房，这种大规模的信贷扩张，是支撑各个地方这些年的房价上涨的重要因素之一。</p>
<p>《我们真的了解钱么》是这么描述这个现象的</p>
<blockquote>
<p>房价不断上涨，房地产行业发展旺盛，房企又会不断贷款加大投入盖房子而由于房地产关联的上下游行业非常之多，所以房地产行业发展旺盛的会间接带动很多上下游相关企业向银行贷款的需求
居民、房企、上下游无数行业，这些需求加在一起，就产生了大规模的信贷扩张，也就超发了大量的货币。
所以房地产其实本质上就是一台巨大的印钞机。在正常情况下，这台巨大的印钞机超发出来的货币是可以传导到其他消费市场的。打个比方：
房企发展的好，不断建房子，房地产上下游关联的这些行业从业者，以及持有多套房产的群体收入也会增加，收入增加，家庭消费支出也会随之增加，钱就会传导到其他消费市场，结果应该是整个市场一起发生通胀。应该表现如下图
<img src="https://wulc.me/imgs/currency_circulation.jpg" height="30%" width="30%"></p>
<p>但真实的情况是，<strong>大部分人赚到钱之后，又继续拿这些钱去买房子</strong>了，这样就形成了一个循环，因为房价不断上涨，所以大部分人又都把钱拿去买房子，大量资金不断涌入楼市，显示中的货币变成了这个样子
<img src="https://wulc.me/imgs/currency_circulation2.jpg" height="30%" width="30%"></p>
</blockquote>
<p>那为什么美国的资产通胀主要发生在股市呢？文章也提到了一个区别是在于货币的传导机制不同</p>
<blockquote>
<p>我国主要是通过信贷的扩张的方式增发货币，增发出来的钱大多数只是数字。而美国增发货币，那真的就是实打实的印钱
美国的商业银行并非国有，所以它们的诉求是自身盈利为主。所以当市场出现风险时，商业银行为自己的安全不会大量发放贷款。所以美国在很多时候无法像我们一样通过信贷扩张去增发货币。
但是钱总得往外放出去啊。那怎么办呢？既然商业银行不愿意帮忙，那就是<strong>央行亲自下场买东西把钱放出去</strong>。美国金融市场上有大量的美国国债，房产抵押债券，这样的债券资产，而美联储就会直接印钱，然后用这些印出来的钱，直接在金融市场上大量购买美国的国债，和其他债券资产。这样钱就进入了金融市场，造成了金融资产的不断上涨。
08年美国金融危机股市暴跌，美国政府就是用这样的方式把美股拉了回来；去年疫情美股暴跌，熔断了4次,
美国用的也是同样的套路直接印钱，向金融市场直接注入大量基础货币。才把美股暂时拉回来了。不过美国这样疯狂的印钱迟早是会出问题的,今年美国的消费市场通胀就非常厉害，物价大幅上涨，这都是疯狂印钱的后果
<strong>与我国的房地产一样的逻辑，本来钱是可以通过金融市场传导到其他市场的。但是因为大量货币输入，股市不断上涨，又会导致资本不断回流到金融市场，大量的资金在金融市场内循环，膨胀，于是就有了我们看到美国股市超过10年的大牛市</strong></p>
</blockquote>
<p>看完中美不同的通货膨胀，我们能够得到这个结论：<strong>通胀一直存在，但是通胀的存在是不均衡的，并且这种不均衡在现代金融体系的催化下会愈演愈烈</strong>。在我国，这种现象表现为大家房价涨的太快，所以自己买不起，其实背后更底层的逻辑是：很多人在拿并没有怎么通胀的工资，去买已经大幅通胀的房子，当然会觉得很困难；在美国也是如此，持有金融资产的群体资产大幅的增长，而没有金融资产的人群收入则长期低迷；</p>
<p>所以需要充分认识到：<strong>钱就像水，当钱流到哪里最多，在哪个领域循环，相对应哪里就会出现更多的投资机会</strong>，但是当下房地产的大趋势已经过去，当房子开始逐渐失去投资价值，金融属性开始慢慢减弱，那么分化的拐点就已经不远了。到了那个时候，大量的资金自然会去寻求回报更高的资产领域，文章指出未来长期投资大方向会看好A股的发展</p>
<p>在《<a href="https://youzhiyouxing.cn/materials/766">你是跑赢 CPI
的穷人吗？如何正确理解通货膨胀</a>》，则对持有何种金融资产来应对通胀提出如下观点：在短期内
（持有 1
年）股票、债券和短期国债都很难有效地对冲通货膨胀风险。但是从长期来看
（持有 30
年)），<strong>股票的实际收益率几乎不受通胀影响</strong>，而债券收益率被远远抛在后面</p>
<h2 id="小结">小结</h2>
<p>本文主要讲了投资中的一些概念与常识，包括周期的表现、成因和应对方法，常见投资标的分析，几道容易犯错的计算题以及一些宏观常识，内容不是非常成体系(因为都摘录了笔者不是非常熟悉的部分~)，也无法立刻教会你如何去投资，甚至看完后可能隔几天就忘了；但是为笔者理解这个世界提供了更丰富的角度，套用那句“投资是认知的变现”，这部分就是在拓展认知，帮助我们从更多视角去了解整个社会的财富分配以及运作机制，即便无法立马变现，了解这些这些底层逻辑，也是挺有意思的，而随着个人财富的积累，相信这些知识也有能“变现”的那一天。</p>
]]></content>
      <categories>
        <category>拾人牙慧</category>
      </categories>
      <tags>
        <tag>拾人牙慧</tag>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>文本分类中的一些经验和 tricks</title>
    <url>/2019/02/06/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C%E5%92%8C%20tricks/</url>
    <content><![CDATA[<p>最近在总结之前做的文本分类实验的一些经验和
tricks，同时也参考了网上的一些相关资料(见文末)，其中有些 tricks
没尝试过，先在这里记下，或者日后能用上。</p>
<span id="more"></span>
<p>这里的经验和 tricks
大概可分为两部分：预处理部分和模型训练部分，下面分别介绍</p>
<h2 id="预处理">预处理</h2>
<ul>
<li><p>文本更正，主要是将文本标准化，包括繁体转简体，全角转半角，拼音纠错等</p></li>
<li><p>文本泛化，如一个手机号码，因为有几千万的手机号码，不可能为每个手机号码设一个特征，所以最好将手机号码转化为同一个特征；另外表情符号、人名、地址、网址、命名实体等也要考虑这种泛化，泛化的程度这个视具体的任务，比如说地址可以以国家为粒度，也可以以省份为粒度</p></li>
<li><p>规范文本为统一长度时，取所有长度的均值或者中位数，但是别取最大值；截断时根据具体任务考虑从前面阶段或从后面截断</p></li>
<li><p>构建数据集的 vocabulary 时，需要考虑以下几个方面</p>
<ul>
<li>取前N个高频词或者过滤掉出现次数小于某个阈值的词</li>
<li>根据具体任务确定是否需要去掉 stop words</li>
<li>假如采用了预训练的词向量，要尽可能让 vocabulary
中的词语能找到对应的词向量(这个问题也涉及到预训练的词向量和分词器的选择)</li>
</ul></li>
<li><p>词向量的选择，当数据集较小时，直接使用预训练好的词向量（如google、facebook开源的），且不用微调；当训练集比较大的时候，可随机初始化进行训练，也可以对预训练的词向量进行微调（微调收敛得更快，但是结果差异不大）</p></li>
<li><p>分词时考虑以下几个方面</p>
<ul>
<li>是否需要分词，使用 char-level 的方法时不需要分词，但是在很多场景下
word-level 的效果都要比 char-level 的要好</li>
<li>分词时可以只保留长度大于1的词(会去除很多停止词)，对结果精度没什么影响，但是可以有效降低特征维度</li>
<li>采用预训练的词向量时，要保证分词后的大部分词语能够出现在预训练的词向量表中，否则这个词语的
embedding
就相当于是随机初始化，预训练的词向量没有提供任何信息；具体方法可参考<a
href="https://www.zhihu.com/question/265357659/answer/578944550">这里</a></li>
</ul></li>
<li><p>数据增强</p>
<ul>
<li>常见的方法有：drop(随机删掉文本)、shuffle(随机改变文本顺序)、replace(用近义词进行替换)</li>
<li>数据增强对 word-level 的方法有一定的提升，但是对于 char-level
的方法效果不一定好，甚至会起到反作用</li>
</ul></li>
</ul>
<h2 id="模型训练">模型训练</h2>
<ul>
<li><p>规则有时能解决大部分的问题，不一定要用到模型，使用时要权衡模型带来的收益和复杂性</p></li>
<li><p>传统的机器学习方法根据其特征工程的不同可分为三大类</p>
<ul>
<li>词袋模型：将出现的词记为1，否则记为 0，问题是维度高且稀疏性严重</li>
<li>向量空间模型：根据文档频率、互信息、信息增益、χ²统计量等进行了特征(词语)的选择，同时通过
tfidf
值为每个词赋权重；一定程度上缓解了上面提到的词袋模型维度高且稀疏性严重的问题</li>
<li>主题模型：pLSA/LDA/HDP
等主题模型将文本表示低维实数向量，类似于深度学习中的 embedding，但是比
embedding 有更好的解释性</li>
</ul></li>
<li><p>fasttext 简单、速度快，是一个非常不错的
baseline；随着问题复杂性增加可依次尝试 CNN -&gt; RNN -&gt; BERT</p></li>
<li><p>对于深度学习模型，把模型变得更深更宽更复杂往往能够提升效果；但是当模型复杂到一定程度的时候，提升的效果微乎其微甚至没提升</p></li>
<li><p>rnn 类模型用双向一般会比单向要好</p></li>
<li><p>使用 dropout(经验值为 0.5)
基本都能提升效果，使用的地方包括：embedding 层后、FC层后</p></li>
<li><p>训练震荡问题：增加随机采样因素尽可能使得数据分布 iid，默认
shuffle
机制能使得训练结果更稳定。如果训练模型仍然很震荡，可以考虑调整学习率 或
<code>mini_batch_size</code></p></li>
<li><p>采用预训练的 embedding 并进行 finetune 时，在最开始 embedding
的学习率设为 0，训练到效果较好时才开始 finetune embedding 层</p></li>
<li><p>学习率的设置考虑以下几个方面</p>
<ul>
<li>经验值一般为 1、0.1、0.01、0.001,
一般从1开始尝试。很少见学习率大于10的</li>
<li>学习率一般要随着训练进行衰减，衰减系数一般是0.5；衰减时机可以是验证集准确率不再上升，或固定训练
N 个 epoch 后</li>
<li>比起自定义的衰减方法，更便捷的方法是使用自适应梯度的办法，例如
adam,adadelta,rmsprop
等，这些一般使用相关论文提供的默认值即可，可以避免再费劲调节学习率</li>
<li>对RNN来说，如果要处理的序列比较长，或者RNN层数比较多，那么learning
rate一般小一些比较好，否则有可能出现结果不收敛，甚至Nan等问题。</li>
</ul></li>
<li><p>超参数的设置经验可参考 <a
href="https://arxiv.org/abs/1510.03820">A Sensitivity Analysis of (and
Practitioners' Guide to) Convolutional Neural Networks for Sentence
Classification</a></p></li>
<li><p>模型融合时，差异性越大，融合效果越好，具体可参<a
href="https://zhuanlan.zhihu.com/p/28923961">这里</a></p></li>
</ul>
<hr />
<p>参考</p>
<ul>
<li><a
href="https://www.zhihu.com/question/265357659">在文本分类任务中，有哪些论文中很少提及却对性能有重要影响的tricks？</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/28923961">知乎看山杯夺冠记</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/25928551">用深度学习（CNN RNN
Attention）解决大规模文本分类问题 - 综述和实践</a></li>
<li><a
href="https://zhuanlan.zhihu.com/p/24720954">深度学习网络调参技巧</a></li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>文本文件和二进制文件</title>
    <url>/2015/11/26/%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%92%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="文本文件和二进制文件的定义">文本文件和二进制文件的定义</h2>
<p>　　首先，计算机的存储在物理上是二进制的，也就是在物理存储方面没有区别都是01码。所以<strong>文本文件与二进制文件的区别并不是物理上的，而是逻辑上的，也就是编码上</strong>。简单来说，文本文件是<strong>基于字符编码</strong>的文件，常见的编码有ASCII编码，UNICODE编码等等。二进制文件是基于值编码的文件，你可以根据具体应用，指定某个值是什么意思（这样一个过程，可以看作是<strong>自定义编码</strong>。</p>
<span id="more"></span>
<h2 id="文本文件与二进制文件的存取">文本文件与二进制文件的存取</h2>
<p>　　文本工具打开一个文件的过程是怎样的呢？拿记事本来说，它首先读取文件物理上所对应的<strong>二进制比特流</strong>，然后<strong>按照你所选择的解码方式来解释这个流，然后将解释结果显示出来</strong>。一般来说，你选取的解码方式会是ASCII码形式（ASCII码的一个字符是８个比特），接下来，它8个比特8个比特地来解释这个文件流。例如对于这么一个文件流"01000000_01000001_01000010_01000011"(下划线''_''，为了增强可读性手动添加的)，第一个8比特''01000000''按ASCII码来解码的话，所对应的字符是字符''A''，同理其它3个8比特可分别解码为''BCD''，即这个文件流可解释成“ABCD”，然后记事本就将这个“ABCD”显示在屏幕上。
　　文本文件格式存储时是<strong>将值作为字符然后存入其字符编码的二进制</strong>，文本文件用‘字符’作为单位来表示和存储数据，比如对于1这个值，文本文件会将其看做字符‘1’然后保存其ASCII编码值（这里假定是ASCII编码），这样在物理上就是0x31这个二进制值，而若是二进制保存1，则直接保存其二进制值，比如如果程序中是处理1为整数则保存的二进制值就是
0x00000001 (4字节）。
　　<strong>假如文件存储的编码与读取的编码不同，那么就无法呈现文章原来的信息，例如用记事本打开文本文件会乱码，用音乐播放器无法打开视频文件。</strong></p>
<h2 id="总结">总结</h2>
<p>　　综上，可以知道文本文件与二进制文件就是编码方式不一样而已，而这个是用户行为，<strong>把一个数据以什么样的编码（字符还是值本身）存入文件是由用户主动选择的，也就是写入的接口选择，如果以二进制接口方式写入文件那么就是一个二进制文件，如果以字符方式写入文件就是一个文本文件了。</strong>既然有写入时候的编码也就会有读出的编码，只有两个编码对应才能读出正确的结果，如用记事本打开一个二进制文件会呈现乱码的，这里稍微提一下后缀名，后缀名并不能确定其是否就是文本文件，二进制文件也可以是txt后缀名，后缀名只是用来关联打开程序，给用户做备注用的，与文件的具体编码没有关系。
　　最后文本文件和二进制文件主要是windows下的概念，UNIX/Linux并没有区分这两种文件，他们对所有文件一视同仁，将所有文件都看成二进制文件。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>最优化计算课程总结</title>
    <url>/2017/02/01/%E6%9C%80%E4%BC%98%E5%8C%96%E8%AE%A1%E7%AE%97%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>本文主要是最优化计算这门课程的课程总结，参考的教材为《<a
href="https://book.douban.com/subject/2971114/">最优化计算</a>》，主要讲述的内容是函数优化，相对于函数优化的另外一种优化是组合优化，两者的主要区别是前者的可行解是连续的，后者的可行解是离散的，或者说前者的可行解是无限的，而后者是有限的。</p>
<span id="more"></span>
<p>最优化要解决的问题非常直观，就是给定若干个由若干个变量组成的目标函数，然后使得变量取某一组值时目标函数值最大或最小，这时候变量的取值便称为最优解；有时候变量还有一定的约束，如要满足某些等式或不等式，这时候的约束称为有约束优化，以区别于前面的无约束优化。</p>
<p>可以说，最优化是一门纯数学的课程，但是现实世界中，很多问题都可以通过建模然后将问题最终转化为求解一个最优化问题，比如说在机器学习中，很多算法往往有个目标函数，这个目标函数可以用与描述预测结果与实际结果的误差，这时候就要最小化这个目标函数(回归，SVM等)；而最大化的问题通过改变符号也转为最小化问题。因此，最优化在实际中有广泛应用。</p>
<p>根据目标函数的形式、数量以及是否有约束条件可以将优化问题分为多种类型。本文主要讲述的是单目标规划，并且将单目标规划进一步分为括线性和非线性，有约束和无约束。</p>
<p>在讲述具体的优化算法前，先介绍最优化中常用的概念。</p>
<p>最优化的基本模型为</p>
<p><span class="math display">\[
min\;f(x)\\\
s.t\quad c(x) \ge 0\\\
\]</span></p>
<p>其中 <span class="math inline">\(x =
(x\_1,x\_2,x\_3,...x\_n)\)</span>
是一个变量组成的向量，也就是包含了若干变量，<span
class="math inline">\(c(x)\)</span>则是对各个变量约束的等式和不等式。</p>
<p>有了基本模型，下面介绍在最优化中的常用概念。</p>
<ul>
<li>目标函数：就是<span class="math inline">\(f(x)\)</span></li>
<li>决策变量：目标函数<span
class="math inline">\(f(x)\)</span>中的所有变量</li>
<li>约束条件：<span
class="math inline">\(c(x)\)</span>中包含的所有的等式和不等式</li>
<li>可行域：约束条件在空间围成的区域</li>
<li>可行解：可行域中的每个点都是原问题的一个可行点</li>
<li>最优解：能够使目标函数达到最大或最小的可行解</li>
<li>凸集：集合的一种，用于描述可行域，满足以下性质 &gt;令 <span
class="math inline">\(K\)</span> 为集合，<span
class="math inline">\(\forall x\_1,x\_2 \in K\)</span>,若 <span
class="math inline">\(\alpha x\_1 + (1-\alpha)x\_2 \in
K\)</span>,其中<span class="math inline">\(\alpha \in [0,1])\)</span>,则
<span class="math inline">\(K\)</span> 为凸集</li>
</ul>
<p>凸集直观的图像表示如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b55a6bct1je4lutpsi11781a1d9.png"
alt="凸集" />
<figcaption aria-hidden="true">凸集</figcaption>
</figure>
<h2 id="线性规划">线性规划</h2>
<h3 id="数学模型与基本概念">数学模型与基本概念</h3>
<p>线性规划就是<strong>目标函数和约束条件都是线性的</strong>最优化问题，且一般都是带约束的，线性规划的一般模型如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b54otaeai4918ffi8k2p51v009.png"
alt="线性规划模型" />
<figcaption aria-hidden="true">线性规划模型</figcaption>
</figure>
<p>为了模型的一致性，通常会将以上的模型化为<strong>标准型</strong>，标准型要求
1）目标函数求最小值 2）约束条件全为等式 3）所有的<span
class="math inline">\(x\)</span>有 <span class="math inline">\(x \ge
0\)</span></p>
<p>化为标准型中的关键点是将约束条件中的不等式变为等式 1）对于约束条件为
<span class="math inline">\(\le\)</span> 的情况，在 <span
class="math inline">\(\le\)</span>
左边添加一个<strong>松弛变量</strong>(非负)。 2）对于约束条件为 <span
class="math inline">\(\ge\)</span> 的情况，在 <span
class="math inline">\(\ge\)</span>
左边减去一个<strong>剩余变量</strong>(非负)
注意：松弛变量、剩余变量在目标函数中的价值系数为0。</p>
<p>如下为一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5fmb0if1gatjc1hsq9q41bh16c.png"
alt="化标准型" />
<figcaption aria-hidden="true">化标准型</figcaption>
</figure>
<p>对于化为标准型的线性规划模型中约束条件的 <span
class="math inline">\(m × n\)</span> 系数矩阵<span
class="math inline">\(A\)</span>，从<span
class="math inline">\(A\)</span>中取大小为<span class="math inline">\(m
× m\)</span>的子矩阵<span class="math inline">\(B\)</span>，若<span
class="math inline">\(Rank(B) = m\)</span>(即B为满秩矩阵)，则称<span
class="math inline">\(B\)</span>为线性规划问题的一个<strong>基矩阵</strong>。取<span
class="math inline">\(B = (A\_1,A\_2,···,A\_m)\)</span> ，其中<span
class="math inline">\(A\_j = (a\_{1j},a\_{2j},···,a\_{mj})^T\)</span>
则称<span
class="math inline">\(x\_1,x\_2,···,x\_m\)</span>为<strong>基变量</strong>，其它为<strong>非基变量</strong>。如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5fmv3ah1td1jqoafc1h3i1pnh6p.png"
alt="基变量和非基变量" />
<figcaption aria-hidden="true">基变量和非基变量</figcaption>
</figure>
<p>令所有的非基变量为0，则得到的解称为<strong>基本解</strong>，可知基本解的个数
<span class="math inline">\(\le
C\_n^m\)</span>。但是基本解不一定满足约束条件，满足约束条件的基本解称为<strong>基本可行解</strong>，而基本可行解对应的基变量称为<strong>可行基</strong>。</p>
<p>基本解，基本可行解，可行解，非可行解的关系如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5fn6nh4pkqkcmble1e9lpga76.png"
alt="基本解，基本可行解，可行解，非可行解的关系" />
<figcaption
aria-hidden="true">基本解，基本可行解，可行解，非可行解的关系</figcaption>
</figure>
<p>关于线性规划有三条重要定理</p>
<blockquote>
<p>定理1 若线性规划存在可行域，则可行域为凸集 定理2
线性规划的基本可行解对应于可行域的顶点 定理3
若线性规划有最优解，则一定存在基本可行解为最优解。</p>
</blockquote>
<p>上面直观解释和定理都是为了说明这个事实：<strong>如果线性规划的最优解存在，那最优解一定在可行域的顶点上。</strong>下面要介绍的单纯形法就是利用这个性质。</p>
<h3 id="单纯形法">单纯形法</h3>
<p>单纯形法是解决线性规划的经典方法。其基本思想是先从可行域的一个顶点出发，然后从当前顶点沿着可行域(可行域是一个凸多面体)的边找下一个使得目标函数更小的顶点，假如找得到就移动到更优的顶点，找不到就说明当前顶点是线性规划的最优解。</p>
<p>因此，单纯形法的主要步骤为 1) 确定初始基本可行解 2)
判别当前基本可行解是否是最优解 3)
从一个基本可行解转换到相邻且改善了的基本可行解</p>
<p>在实际运算的时候，一般通过单纯形表实现。其求解过程如下所示</p>
<p>对于下面已经化为标准型的线性规划问题</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5fp2b1n14s01l3ks6ql0v1fiu9.png"
alt="标准型" />
<figcaption aria-hidden="true">标准型</figcaption>
</figure>
<p>其单纯形表为</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5fp3m7v15iac4nl1ro5o1thrm.png"
alt="单纯形表" />
<figcaption aria-hidden="true">单纯形表</figcaption>
</figure>
<p>表中的基指的是基变量，最后一行 <span
class="math inline">\(\sigma\_j\)</span>
是检验数，用于检验当前的基本可行解是否为最优解。</p>
<p>对应于单纯形表，求解步骤如下
（1）<strong>确定初始基本可行解</strong>。
也就是列出如上图所示的初始的单纯形表，将线性规划化为标准型后,通过矩阵的初等行变换,可以使系数矩阵A中包含一个单位阵，而这个单位阵对应的基变量即可作为初始基本可行解。
（2）<strong>判别当前基本可行解是否是最优解</strong>。
通过最后一行的检验数 <span class="math inline">\(\sigma\_j\)</span>
判断，假如所有非基变量的检验数 <span class="math inline">\(\sigma\_j \ge
0\)</span>，则基变量为最优解，计算结束；假如存在<span
class="math inline">\(\sigma\_k \lt 0\)</span>,且<span
class="math inline">\(A\_k \le
0\)</span>,则问题为无界解，计算结束；否则转第（3）步
（3）<strong>从一个基本可行解转换到相邻且改善了的基本可行解</strong>。
这一步要确定一个入基变量和一个出基变量，入基变量就是从非基变量中选择的一个变量，然后将其变为基变量，出基变量就是从基变量中选择一个变量，然后将其变为非基变量。实际上就是将这两个变量的位置(基或非基)互换，对应于从可行域的一个顶点走到另外一个顶点。</p>
<p><strong>入基变量的确定</strong>:从所有的检验数中找出最小的 <span
class="math inline">\(\sigma\_k\)</span>,对应的<span
class="math inline">\(x\_k\)</span>为入基变量。
<strong>出基变量的确定</strong>：通过下式确定的 <span
class="math inline">\(l\)</span>所对应的的 <span
class="math inline">\(x\_l\)</span>作为出基变量</p>
<p><span class="math display">\[\min\_{1 \le i \le m} \lbrace
\frac{b\_i}{a\_{ik}} | a\_{ik} &gt; 0 \rbrace\]</span></p>
<p>上式中的 <span class="math inline">\(a\_{ik}\)</span>
为入基变量对应系数举证 A 的第k列</p>
<p>找到入基变量<span class="math inline">\(x\_k\)</span>和出基变量<span
class="math inline">\(x\_l\)</span>后，用入基变量替换出基变量，通过初等行变换使得<span
class="math inline">\(x\_k\)</span>对应系数矩阵A的一列成为原单位矩阵中<span
class="math inline">\(x\_l\)</span>对应的那列，其他的值做相应的计算(见下图)，画出的新的单纯形表如下所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5fp6uvg1p191fa812h388tjjm1g.png"
alt="新的单纯形表" />
<figcaption aria-hidden="true">新的单纯形表</figcaption>
</figure>
<p>（4）重复步骤（2）和（3），直到找到最优解</p>
<p>注意除了单纯形法以外，解决线性规划还有另外一类方法：内点法。这里不详细展开，具体可以参考这篇论文
<a
href="http://www.cs.toronto.edu/~robere/paper/interiorpoint.pdf">Interior
Point Methods and Linear Programming</a>。</p>
<h3 id="对偶理论">对偶理论</h3>
<p>在求解一个规划问题（不限于线性规划）的时候，我们常常需要知道这个问题<strong>有没有可行解</strong>（有时候约束条件很复杂，不要说最优解，找到可行解都很难），或者是估计一下<strong>目前的解离最优解还有多远</strong>（大型问题多用迭代解法，如果能大致估计当前的解的质量，就对算法什么时候运行结束有一个大致的把握，如果得到了可接受的近似解也可以提前停止），以及判断原问题的最优解是否无界（万一出现这种情况迭代就停不下来了）。</p>
<p>而对偶问题就是回答这些问题的利器：<strong>弱对偶定理给原问题的最优解定了一个界，强对偶定理给出了原问题最优解的一个判定条件。</strong>同时，还有很多别的优良性质：例如可以化难为易（把难以求解的约束条件扔到目标函数的位置上去），如果问题的形式合适(变量少，约束多)还可以通过把约束变量和对偶变量互换来把大规模问题转换成小规模问题。实际上，很多凸优化问题都是通过解对偶问题来求解的，线性规划只是其中一个特例而已。</p>
<p>一般地，对于原问题 <span class="math display">\[min\;z =  c^Tx \quad
\\\
s.t.\,Ax \ge b(x \ge 0)\tag{1}\]</span></p>
<p>其对偶问题为 <span class="math display">\[max\;w =  b^Ty \quad \\\
s.t.\,A^Ty \le c(y \ge 0)\tag{2}\]</span></p>
<p>根据原问题写出其对偶问题时要注意<strong>约束条件和变量的符号变化情况</strong>，其变换规则如下
1. max 问题第 i 个约束取“≥”，则min问题第 i 个变量 ≤ 0 2. min 问题第 i
个约束取“≤”，则max问题第 i 个变量 ≤ 0 3. 原问题第 i
个约束取等式，对偶问题第 i 个变量无约束 4. max 问题第 j 个变量 ≤ 0
,则min问题第j个约束取“≤” 5. min 问题第 j 个变量 ≤ 0
，则max问题第j个约束取“≥” 6.
原问题第j个变量无约束，对偶问题第j个约束取等式</p>
<p>以上规则是具体的变换规则，实际上其变换规律就是<strong>假如原问题不符合以上的给出的(1)或(2)的标准形状，那么原问题的第
i 个不符合要求的约束，对应的对偶问题的第i个变量要 ≤ 0
；同样假如原问题的第 i 个变量不符合要求(就是 <span
class="math inline">\(x\_i\)</span>≤
0)，对应的对偶问题的第i个约束要改变符号。</strong></p>
<p>对偶定理包含了一系列的定理，其中主要有弱对偶定理，强对偶定理，最优性定理，互补松弛定理。通过这些定理可以将原来难以解决的原问题通过引入对偶理论从而得以解决，各定理的具体内容如下:</p>
<p><strong>弱对偶定理</strong> &gt;max
问题任一可行解的目标值为min问题目标值的一个下界； &gt;min
问题任一可行解的目标值为max问题目标值的一个上界</p>
<p><strong>强对偶定理</strong>
&gt;若原问题有最优解，那么对偶问题也有最优解，且两个问题最优解的目标函数值相等。</p>
<p><strong>无界性</strong>
&gt;若原问题(对偶问题)为无界解，则对偶问题(原问题)为无可行解。</p>
<p>需要注意的是，无界性的逆不存在。若原(对偶)问题为无可行解，对偶(原问题)问题或为无界解，或为无可行解。</p>
<p><strong>最优性</strong> &gt;若 <span class="math inline">\(\overline
x\)</span> 和 <span class="math inline">\(\overline y\)</span>
分别为原问题和对偶问题的可行解，那么原问题和对偶问题都有最优解，且当
<span class="math inline">\(c^T\overline x=b^T\overline
y\)</span>时，<span class="math inline">\(\overline x\)</span> 和 <span
class="math inline">\(\overline
y\)</span>分别为原问题和对偶问题的最优解。</p>
<p><strong>互补松弛定理</strong> &gt;若 <span
class="math inline">\(\overline x\)</span> 和 <span
class="math inline">\(\overline y\)</span>
分别为原问题和对偶问题的可行解，则它们分别是原问题和对偶问题的最优解的充要条件是<span
class="math inline">\(\overline x^T(A^T\overline y-c)=0\)</span>和<span
class="math inline">\(\overline y^T(A\overline x-b)=0\)</span></p>
<p>通过互补松弛定理，给出原问题(对偶问题)的最优解，便可求得其对偶问题(原问题)的最优解。</p>
<p>对应于单纯形法有对偶单纯形法，其解法与单纯形的一样，只是找出基变量和入基变量的方法不一样。</p>
<h3 id="灵敏度分析">灵敏度分析</h3>
<p>在许多实际问题中，数据模型的数据未知，需要根据实际情况进行测量、估计和预测，因此这些<strong>数据不是十分精确，数据的略微的变化可能会引起问题解的显著变化。所谓灵敏度分析就是研究输入数据的扰动对LP最优解的影响</strong>，或者说是LP最优解对参数变化、约束条件增减、决策变量增减的Robust(稳健性)。</p>
<p>灵敏度分析主要就是考虑问题</p>
<p><span class="math display">\[min\;z =  c^Tx \quad \\\
s.t.\,Ax \ge b(x \ge 0)\tag{1}\]</span></p>
<p>中，参数 c,b,A 的变化是否会引起最优解的变化。</p>
<p><span class="math inline">\(c\)</span> 的变化可分为两种：<span
class="math inline">\(c\)</span>为非基变量的价值系数和c为基变量的价值系数
1.非基变量价值系数 <span class="math inline">\(c\_k\)</span>的变化 假设
<span class="math inline">\(\overline{c\_k} = c\_k + \Delta
c\_k\)</span>, 则其在单纯形法中的检验数变为$ = _k + c_k <span
class="math inline">\(,只需要让\)</span> $ 即 $_k -c_k
$即可保证最优解不变</p>
<p>2.基变量价值系数 <span class="math inline">\(c\_b\)</span>的变化 假设
<span class="math inline">\(\overline{c\_b} = c\_b + \Delta
c\_b\)</span>, 则其在单纯形法中的检验数变为$ = _b -
(0,0,0,..c_b,...0,0,0)B^{-1}N <span
class="math inline">\(,其中\)</span>(0,0,0,..c_b,...0,0,0)<span
class="math inline">\(为基变量的价值系数的变化量组成的向量，\)</span>B^{-1}N
<span
class="math inline">\(为单纯形表中非基变量对应的系数列组成的矩阵，同样只需要让\)</span>
$ 即可保证最优解不变.</p>
<p>b变化的时候需要保证 <span class="math inline">\(\overline{b} =
B^{-1}(b+\Delta b) \ge 0\)</span>,否则需要将<span
class="math inline">\(\overline{b}\)</span>
作为新的b的值代入到原来的单纯形表中，让后通过<strong>对偶单纯形法</strong>进行求解。对偶单纯形法的步骤与原始单纯形法的步骤非常相似，只是选择出基变量和入基变量的方法不同。出基变量选择为
<span class="math inline">\(b\_k = min\;\lbrace
b\_i,i=1,2,..m\rbrace\)</span>所对应的 <span
class="math inline">\(x\_k\)</span>,入基变量选择为下面公式对应的<span
class="math inline">\(x\_l\)</span>,</p>
<p><span class="math display">\[\frac{\sigma\_l}{a\_{kl}} =
max\;\[\frac{\sigma\_j}{a\_{kj}}|a\_{kj} \lt 0,j=1,2,...n\]\]</span></p>
<h2 id="非线性规划">非线性规划</h2>
<h3 id="数学模型与基本概念-1">数学模型与基本概念</h3>
<p>目标函数或约束函数至少有一个不是决策变量的线性函数。即</p>
<p><span class="math display">\[
min f(x)\\\
s.t\quad h\_i(x) = 0(i=1,2,...,m)\\\
\quad\quad g\_j(x) \ge 0(j=1,2,...,l)\\\
\]</span> 其中，<span
class="math inline">\(f(x),h\_i(x),g\_j(x)\)</span>
中至少有一个是非线性函数。</p>
<h4 id="梯度与海塞矩阵">梯度与海塞矩阵</h4>
<p>梯度和海塞矩阵是在非线性规划中用得较多的概念，其定义如下：</p>
<p><strong>梯度</strong> 可微函数<span
class="math inline">\(f(x)\)</span>的梯度，记为<span
class="math inline">\(\nabla f(x)\)</span>,它是以 <span
class="math inline">\(f (x)\)</span> 对 <span
class="math inline">\(x\)</span>
的偏导数为元素的n维<strong>向量</strong>,如下所示<span
class="math display">\[\nabla f(x) = (\frac{\partial f(x)}{\partial
x\_1},\frac{\partial f(x)}{\partial x\_2},....,\frac{\partial
f(x)}{\partial
x\_n})\]</span>而在某一点的梯度就是将这一点的值代入到上式中，如在点<span
class="math inline">\(x\_0\)</span>上的梯度为<span
class="math display">\[\nabla f(x\_0) = (\frac{\partial
f(x\_0)}{\partial x\_1},\frac{\partial f(x\_0)}{\partial
x\_2},....,\frac{\partial f(x\_0)}{\partial x\_n})\]</span></p>
<p>对于一元函数，其梯度就是其一阶导数。</p>
<p>对于任何函数<span class="math inline">\(f(x)\)</span>，假如<span
class="math inline">\(\overline x\)</span>是<span
class="math inline">\(f(x)\)</span>的局部极小点且<span
class="math inline">\(f(x)\)</span>在<span
class="math inline">\(\overline x\)</span>处可微，那么必有<span
class="math inline">\(\nabla f(\overline x) =0\)</span></p>
<p><strong>海塞矩阵</strong>
海塞矩阵的定义与梯度类似，但是求的是二阶偏导，并且结果是一个矩阵，如下所示</p>
<p><span class="math display">\[
\nabla^2 f(x) =
\begin{pmatrix}
\frac{\partial^2 f(x)}{\partial^2 x\_1} &amp; \frac{\partial^2
f(x)}{\partial x\_1\partial x\_2} &amp; \cdots &amp; \frac{\partial^2
f(x)}{\partial x\_1\partial x\_n}\\\
\frac{\partial^2 f(x)}{\partial x\_2\partial x\_1} &amp;
\frac{\partial^2 f(x)}{\partial^2 x\_2} &amp; \cdots &amp;
\frac{\partial^2 f(x)}{\partial x\_2\partial x\_n}\\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\\
\frac{\partial^2 f(x)}{\partial x\_n\partial x\_1}&amp; \frac{\partial^2
f(x)}{\partial x\_n\partial x\_2} &amp; \cdots &amp; \frac{\partial^2
f(x)}{\partial^2 x\_n}\\\
\end{pmatrix}
\]</span></p>
<p>对于任何函数<span class="math inline">\(f(x)\)</span>，假如<span
class="math inline">\(f(x)\)</span>在<span
class="math inline">\(\overline x\)</span>处有二阶连续偏导，若<span
class="math inline">\(\nabla f(\overline x) =0\)</span>且海塞矩阵<span
class="math inline">\(\nabla^2 f(\overline x)\)</span>正定，则 <span
class="math inline">\(\overline x\)</span>
为<strong>严格局部最小点</strong>。</p>
<h4 id="凸函数">凸函数</h4>
<p>凸函数的定义如下 &gt;设<span
class="math inline">\(f(x)\)</span>为定义在n维欧氏空间中某个凸集S上的函数，若对于任何实数<span
class="math inline">\(\alpha(0&lt;\alpha&lt;1)\)</span>以及S中的任意不同两点<span
class="math inline">\(x^{(1)}\)</span>和<span
class="math inline">\(x^{(2)}\)</span>，均有<span
class="math display">\[f(\alpha x^{(1)}+ (1-\alpha)x^{(2)}) \le \alpha
f(x^{(1)}) + (1-\alpha)f(x^{(2)})\]</span>则称<span
class="math inline">\(f(x)\)</span>为定义在凸集 S
上的凸函数。假如上面不等式中的 <span class="math inline">\(\le\)</span>
改为 <span class="math inline">\(\lt\)</span>， 则称其为严格凸函数。</p>
<p>凹函数的定义类似，只需要把上式的不等号方向改变即可。图像直观表示两者如下所示</p>
<figure>
<img
src="https://wulc.me/imgs/image_1b59bnrlg1h4710k51a9n1os91bup1g.png"
alt="凹函数与凸函数" />
<figcaption aria-hidden="true">凹函数与凸函数</figcaption>
</figure>
<p>凸函数的一个重要的性质是其<strong>局部极小值点为全局极小值点</strong>。</p>
<p>根据凸函数的定义来判断一个函数是否为凸函数往往比较困难，这里分别通过一阶条件和二阶条件判断凸函数。</p>
<p><strong>一阶条件</strong> &gt;设 <span
class="math inline">\(f(x)\)</span> 在凸集 S上有一阶连续偏导数，则 <span
class="math inline">\(f(x)\)</span> 为S上的凸函数的充要条件为：对于
任意不同两点<span class="math inline">\(x^{(1)}\)</span>和<span
class="math inline">\(x^{(2)}\)</span>，均有<span
class="math display">\[f(x^{(2)}) \ge f(x^{(1)}) + \nabla
f(x^{(1)})^T(x^{(2)} - x^{(1)})\]</span></p>
<p>二阶条件 &gt;设 <span class="math inline">\(f(x)\)</span> 在凸集
S上有二阶连续偏导数，则<span class="math inline">\(f(x)\)</span>
为S上的凸函数的充要条件为：<span class="math inline">\(f(x)\)</span>
的海塞矩阵 <span class="math inline">\(\nabla^2
f(x)\)</span>在S上处处半正定(为凹函数的充要条件为处处半负定)。
注意：假如海塞矩阵 <span class="math inline">\(\nabla^2
f(x)\)</span>在S上处处正定，则<span
class="math inline">\(f(x)\)</span>为严格凸函数，但是反过来不成立。</p>
<p>关于正定、半正定、负定的定义及判断方法如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b59d8iqoc1pt3ti7q1lrnud31t.png"
alt="正定矩阵和负定矩阵" />
<figcaption aria-hidden="true">正定矩阵和负定矩阵</figcaption>
</figure>
<p>而<strong>顺序主子式</strong>的定义如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b59dq06e1c8h1htb14upmi1ofe2a.png"
alt="顺序主子式" />
<figcaption aria-hidden="true">顺序主子式</figcaption>
</figure>
<p>通过海塞矩阵判断凸函数例子如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b59faio2c971vrblfcr119t2n.png"
alt="海塞矩阵判断凸函数" />
<figcaption aria-hidden="true">海塞矩阵判断凸函数</figcaption>
</figure>
<h4 id="凸规划">凸规划</h4>
<p>凸规划指<strong>可行域为凸集，目标函数为凸函数</strong>的规划问题。其具体形式如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b59g47ljve7tj11j5m1mm55nn34.png"
alt="凸规划模型" />
<figcaption aria-hidden="true">凸规划模型</figcaption>
</figure>
<p>注意上面的<span
class="math inline">\(g\_j(X)\)</span>为凹函数，这样围起来的可行域才为凸集。</p>
<p>因为凸函数和凸集的性质，凸规划有一条重要的性质：<strong>凸规划的任一局部极小点为全局极小点</strong>。</p>
<h3 id="一维搜索">一维搜索</h3>
<p>一维搜索就是<strong>目标变量只有一个</strong>的时候的最优化问题，又称为单变量函数寻优法。</p>
<p>求解这类问题一般有两种方法，一类是<strong>区间收缩法</strong>（如黄金分割法），一类是<strong>函数逼近法</strong>（如三点二次插值法、牛顿法）。下面分别介绍</p>
<h4 id="单谷函数">单谷函数</h4>
<p>定义：如果函数<span class="math inline">\(f(x)\)</span>在区间 [a,b]
上只有一个极小值点, 则称<span class="math inline">\(f(x)\)</span>为 [a,
b] 上的单谷函数。</p>
<p>单谷函数具有一个重要的<strong>消去性质</strong> &gt;设<span
class="math inline">\(f(x)\)</span>是区间 [a,b] 上的一个单谷函数，<span
class="math inline">\(\overline x \in\)</span> [a,b] 是其极小点， <span
class="math inline">\(x\_1\)</span> 和<span
class="math inline">\(x\_2\)</span>是 [a, b] 上的任意两点，且<span
class="math inline">\(a&lt;x\_1 &lt;x\_2&lt;b\)</span>，那么比较<span
class="math inline">\(f(x\_1)\)</span>与<span
class="math inline">\(f(x\_2)\)</span>的值后，可得出如下结论： 1)若<span
class="math inline">\(f(x\_1)≥f(x\_2),\overline x\in [x\_1,b]\)</span>
2)若<span class="math inline">\(f(x\_1) &lt; f(x\_2),\overline x \in
[a,x2]\)</span> 两种情况如下图所示 <img
src="https://wulc.me/imgs/image_1b5adl8g8vfc1b701sahj6a1gst3u.png"
alt="单谷函数消去性质" /></p>
<h4 id="外推内插法">外推内插法</h4>
<p>在一维搜索中的区间收缩法中需要用到单谷区间，而寻找单谷区间的方法就是下面要介绍的外推内插法。</p>
<p>其思路为从某个初始点出发，沿函数值下降的方向前进，直至发现函数值上升为止。而由两边高，中间低的三点，可确定极小点所在的初始区间。</p>
<p><strong>进退算法</strong> 1.选定初始点a 和步长h;</p>
<p>2.计算并比较<span class="math inline">\(f(a)\)</span>和<span
class="math inline">\(f(a+h)\)</span>；有前进和后退两种情况：
1)<strong>前进算法</strong>：若<span class="math inline">\(f(a) \ge
f(a+h)\)</span>则步长加倍，计算<span
class="math inline">\(f(a+3h)\)</span>。若<span
class="math inline">\(f(a+h) \le f(a+3h)\)</span>，<span
class="math inline">\(a\_1=a, a\_2=a+3h\)</span>,
停止运算；否则将步长加倍，并重复上述运算。
2)<strong>后退算法</strong>：若<span class="math inline">\(f(a) \lt
f(a+h)\)</span>则步长改为 <span
class="math inline">\(-h\)</span>，计算<span
class="math inline">\(f(a-h)\)</span>。若<span
class="math inline">\(f(a-h) \ge f(a)\)</span>，<span
class="math inline">\(a\_1=a-h, a\_2=a+h\)</span>,
停止运算；否则将步长加倍，继续后退。</p>
<p>3.得到的满足“中间小两头大”的三点已经可以作为单谷区间，但是当这个区间太大的时候，也可以进行缩短，缩短的方法如下：</p>
<blockquote>
<p>假如得到的三点 <span class="math inline">\(a&lt;b&lt;c\)</span>，在
<span class="math inline">\(b，c\)</span> 之间内插一点<span
class="math inline">\(\overline b =
(b+c)/2\)</span>。这样得到四个点：<span class="math inline">\(a
，b，\overline
b，c\)</span>。比较这4个点的函数值，令其中函数值最小的点为 <span
class="math inline">\(x\_2\)</span> , <span
class="math inline">\(x\_2\)</span> 的左右邻点为 <span
class="math inline">\(x\_1\)</span> 和 <span
class="math inline">\(x\_3\)</span>，至此得到了更小的极值点存在区间
[<span class="math inline">\(x\_1,x\_3\)</span>]，且 <span
class="math inline">\(x\_1、x\_2、x\_3\)</span>
三点，满足“两头大中间小”的条件。依照此方法可以划出更小的单谷区间。</p>
</blockquote>
<h4 id="黄金分割法">黄金分割法</h4>
<p>黄金分割法的思想是：<strong>反复使用单谷函数的消去性质，不断缩小包含极小点的搜索区间，直到满足精度为止。</strong></p>
<p>该方法的优点是需计算函数值，通用性强。</p>
<h4 id="三点二次插值法">三点二次插值法</h4>
<p>三点二次插值法的思想是：<strong>形式复杂的函数进行数学运算时不方便，因此找一个近似的、解析性能好、便于计算的简单函数来代替，用近似函数的极小点作为原函数极小点的近似，常用于近似的简单函数是二次函数。</strong></p>
<p>三点二次插值多项式近似法（抛物线法）的基本原理为：设目标函数 <span
class="math inline">\(f(x)\)</span> 在三点 <span
class="math inline">\(x\_1 &lt; x\_2 &lt;x\_3\)</span>
上的函数值分别为<span
class="math inline">\(f\_1,f\_2,f\_3\)</span>,假设相应的二次插值多项式为<span
class="math inline">\(P\_2(x)=c＋bx + ax^2\)</span>,令<span
class="math inline">\(P\_2(x)\)</span> 和 <span
class="math inline">\(f(x)\)</span> 在三点上的函数值相等，进而求出<span
class="math inline">\(P\_2(x)\)</span>中三个未知参数 <span
class="math inline">\(a、b、c\)</span> 的值以及<span
class="math inline">\(P\_2(x)\)</span>的稳定点<span
class="math inline">\(\overline x =
-\frac{b}{2a}\)</span>。而这个方法的命名也源于其原理，通过三个点用二次函数去逼近原函数。其图像直观表示如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5ahksco5j451bsl31mcl18fs4b.png"
alt="三点二次插值" />
<figcaption aria-hidden="true">三点二次插值</figcaption>
</figure>
<p>需要注意的是选取的三个点要有一定的要求，若任意取这三个点，则求出的<span
class="math inline">\(\overline x\)</span>
可能位于给定区间之外或误差太大，见下图</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5ahphsk1adrtr6o46fjd1er34o.png"
alt="三点二次插值不符合" />
<figcaption aria-hidden="true">三点二次插值不符合</figcaption>
</figure>
<p>因此，最初的三个点<span
class="math inline">\(x\_1&lt;x\_2&lt;x\_3\)</span>
应构成一个两边高，中间低的极小化框架。</p>
<p>在完成一次计算后，得到近似的<span class="math inline">\(\overline
x\)</span>,要进行搜索区间的收缩，然后在新区间中重新构造三点组成的“极小化框架”
。<strong>构造的方法为比较<span class="math inline">\(f(\overline
x),f(x\_2)\)</span>，以函数值较小的点为中间点，加上左右两点</strong>。</p>
<p>最后终止准则可以采用目标函数值的相对误差或绝对误差来判断。</p>
<h4 id="牛顿法">牛顿法</h4>
<p>牛顿法是一种函数逼近法，其基本思想是<strong>在极小点附近用二阶泰勒多项式近似代替目标函数，求解二阶泰勒多项式的极小点作为目标函数的极小点</strong>。牛顿法在数值分析中是用于求解方程的根，而<strong>求解函数极值点等价于求其导函数为0时的根(假如函数可微)</strong>。</p>
<p>将<span class="math inline">\(f(x)\)</span>在点<span
class="math inline">\(x\_k\)</span>处进行泰勒展开，取前三项有 <span
class="math display">\[f(x) \approx \varphi(x) =
f(x\_k)+f^{&#39;}(x\_k)(x-x\_k)+\frac{1}{2}f^{&quot;}(x\_k)(x-x\_k)^2\]</span></p>
<p>求<span class="math inline">\(\varphi^{&#39;}(x) = 0\)</span>
的根，可得 <span class="math display">\[x\_{k+1} = x\_k -
\frac{f^{&#39;}(x\_k)}{f^{&quot;}(x\_k)}\]</span></p>
<p>通过上面公式进行迭代直至 <span
class="math inline">\(|f^{&#39;}(x\_k)| \lt \epsilon\)</span> (<span
class="math inline">\(\epsilon\)</span>为很小的正数)。</p>
<h3 id="无约束非线性规划">无约束非线性规划</h3>
<p>前面介绍的一维搜索虽然也属于无约束非线性规划，只是仅有一个约束变量。但是由于实际问题中变量的个数往往不止一个，因此多个变量的无约束非线性规划在实际中使用更为广泛。下面主要介绍多变量无约束非线性规划的解决方法。无约束问题的最优化方大致分为两类：</p>
<p><strong>1.
直接法</strong>：求解过程中只用到目标函数值，无须计算导数。如<strong>变量轮换(坐标轮换)，模式搜索</strong>等。
<strong>2.
解析法</strong>：用函数的解析性（一阶、二阶导数），即在计算过程中需要计算目标函数的导数。如：<strong>梯度法、共扼梯度法、牛顿法</strong>等</p>
<p>一般来说，解析法的收敛速率较高，直接法的可靠性较高。</p>
<h4 id="直接法">直接法</h4>
<h5 id="坐标变量轮换法">坐标(变量)轮换法</h5>
<p>坐标轮换法属于直接法，既可以用于无约束优化问题的求解，又可以经过适当处理用于约束优化问题求解。</p>
<p><strong>坐标轮换法是每次搜索只允许一个变量变化，其余变量保持不变，即沿坐标方向轮流进行搜索的寻优方法。</strong>它把多变量的优化问题轮流地转化成单变量（其余变量视为常量）的优化问题，因此又称这种方法为变量轮换法。此种方法只需目标函数的数值信息而不需要目标函数的导数。</p>
<p>如下图为只有两个变量时进行坐标轮换的搜索过程，可以看到，每一个的移动都只在一个方向上改变</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5bvj4d8kv01hn8h9hlu6d4b55.png"
alt="坐标轮换法" />
<figcaption aria-hidden="true">坐标轮换法</figcaption>
</figure>
<p>判断其收敛(终止)的可采用<strong>点距准则或函数值准则</strong>，当点距或函数值只差小于指定的值时则收敛。其中采用的点应该是<strong>一轮迭代的始点和终点</strong>，而不是某搜索方向的前后迭代点。</p>
<p>其流程图如下所示 <img
src="https://wulc.me/imgs/image_1b5bvvnvq1svf15q01g4r15531qrk5i.png"
alt="坐标轮换法流程" /></p>
<p>坐标轮换法程序简单，易于掌握。但是计算效率比较低，尤其是当优化问题的维数较高时更为严重。一般把此种方法应用于维数小于10的低维优化问题。</p>
<h5 id="模式搜索法">模式搜索法</h5>
<p>模式搜索法的思想是算法从初始基点开始，交替实施两种搜索:<strong>轴向搜索和模式搜索</strong>。轴向搜索一次沿着n个坐标轴方向进行，用来确定新的迭代点和有利于函数值下降的方向。模式搜索则沿着相邻两个迭代点的连线方向进行，试图使函数值下降得更快。</p>
<p>其搜索过程与坐标轮换法类似，其中轴向搜索其实就是进行了一轮的坐标搜索，<strong>与坐标轮换法不同点在于在进行了一轮坐标搜索后会进行模式搜索</strong>。如下所示
模式搜索法的具体过程为 <img
src="https://wulc.me/imgs/image_1b5hkuvq4l1c1bhglhm1vovtrm24.png"
alt="模式搜索法具体过程" /></p>
<p>通过图像直观表示如下 <img
src="https://wulc.me/imgs/image_1b5c2evni1d4cnde1jgvf61vko5v.png"
alt="模式搜索过程" /></p>
<h5 id="可变单纯形法">可变单纯形法</h5>
<p>可变单纯形法也称可变多面体搜索法，是一种传统的处理无约束最优化问题的直接算法.</p>
<p>首先在n欧氏空间中构造一个包含n+1个顶点的凸多面体，求出各顶点的函数值，并确定其中的最大值、次大值和最小值，然后通过反射、扩张、内缩、缩边等策略求出一个较好解，用之取代最大(差)点，从而构成新的多面体，如此多次迭代则可逼近一个性能较好的极小点。</p>
<p>算法简单、计算量小、优化快速，且不要求函数可导，因而适用范围较广。但它对初始解依赖性较强，容易陷入局部极小点，而且优化效果随函数维数的增加明显下降。</p>
<p>Lagarias(1998)研究了可变单纯形法求解低维函数时的收敛特性，但结论难以推广到高维问题，也即单一可变单纯形法难以保证对高维复杂函数具有较好的优化效果。</p>
<h4 id="解析法">解析法</h4>
<p>解析法是利用了函数的导数信息的一类方法，其主要思想是通过导数信息找到函数下降的方向，让后沿着这个方向往下走直到走到最小值。</p>
<h5 id="最速下降法">最速下降法</h5>
<p>最速下降法利用了<strong>函数在某点上的负梯度方向是函数在该店下降最快的方向</strong>这一结论。其迭代公式为</p>
<p><span class="math display">\[x^{(k+1)} = x^{(k)} +
\alpha^{(k)}d^{(k)}\]</span></p>
<p>其中<span class="math inline">\(d^{(k)} = - \nabla
f(x^{(k)})\)</span> 为下降方向, <span
class="math inline">\(\alpha^{(k)}\)</span> 为步长，其求解方法是对<span
class="math inline">\(\alpha^{(k)}\)</span>进行一维搜索(因为此时<span
class="math inline">\(x^{(k)},d^{(k)}\)</span>已知)，即</p>
<p><span class="math display">\[f(x^{(k)} + \alpha^{(k)}d^{(k)}) =min\;
f(x^{(k)} + \alpha d^{(k)}) = min\;\varphi(\alpha)\]</span></p>
<p>令<span class="math inline">\(\varphi^{&#39;}(\alpha) =
0\)</span>,求出的 <span class="math inline">\(\alpha\)</span>
的值即为步长。</p>
<p>其收敛的判断准则是梯度足够小，即其二阶范数<span
class="math inline">\(||\nabla f(x^{(k)})|| \lt \epsilon\)</span></p>
<p>在最速下降法中相邻的两个迭代点的梯度是彼此正交的。也即在梯度的迭代过程中，相邻的搜索方向相互垂直。</p>
<p>因此最速下降法向极小点的逼近路径是锯齿形路线，越接近极小点，锯齿越细，前进速度越慢。这是因为梯度是函数的局部性质，从局部上看，在该点附近函数的下降最快，但从总体上看则走了许多弯路，因此函数值的下降并不快。其示意图如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5hob0l72fu68dl2l1hun1g32u.png"
alt="最速下降法示意图" />
<figcaption aria-hidden="true">最速下降法示意图</figcaption>
</figure>
<h5 id="牛顿法-1">牛顿法</h5>
<p>牛顿法跟最速下降法的思想是一样的，都是找一个能够使函数值下降的方向前进，只是最速下降法找的方向是负梯度方向，而牛顿法找的是牛顿方向。根据每次迭代的步长是否固定，可以将牛顿法分为原始牛顿法和阻尼牛顿法两种，实际中应用较多的是阻尼牛顿法。</p>
<h6 id="原始牛顿法">原始牛顿法</h6>
<p>原始牛顿法的思想在一维搜索中已经提到,只是一维搜索中是只有一个 <span
class="math inline">\(x\)</span>变量，而这里处理的是多个<span
class="math inline">\(x\)</span>变量，相应地用梯度和海塞矩阵代替原来的一阶导数和二阶导数。</p>
<p>其思想就是在第 k 次迭代的迭代点 <span
class="math inline">\(x^{(k)}\)</span>
邻域内，通过泰勒展开用一个二次函数去近似代替原目标函数<span
class="math inline">\(f(x)\)</span>，然后求出该二次函数的极小点作为对原目标函数求优的下一个迭代点，依次类推，通过多次重复迭代，使迭代点逐步逼近原目标函数的极小点。</p>
<p>其主要步骤为</p>
<p>设目标函数<span
class="math inline">\(f(x)\)</span>具有连续的一、二阶导数，在<span
class="math inline">\(x^{(k)}\)</span>点邻域内取<span
class="math inline">\(f(x)\)</span>的二次泰勒多项式作近似式，对于只有一个变量<span
class="math inline">\(x\)</span>时为</p>
<p><span class="math display">\[f(x) \approx \varphi(x) =
f(x\_k)+f^{&#39;}(x\_k)(x-x\_k)+\frac{1}{2}f^{&#39;&#39;}(x\_k)(x-x\_k)^2\]</span></p>
<p>而有多个变量 <span class="math inline">\(x\)</span> 时，有</p>
<p><span class="math display">\[f(x) \approx \varphi(x) =
f(x^{(k)})+\nabla f(x^{(k)})^T\Delta x+\frac{1}{2}\Delta x^TH\_k\Delta
x\]</span></p>
<p>令 <span class="math inline">\(x^{(k+1)}\)</span>
为函数的极小点,则应有 <span class="math inline">\(\nabla
\varphi(x^{(k+1)}) = 0\)</span></p>
<p>令 $ (x)= f(x^{(k)})+H_kx=0$,且 <span class="math inline">\(\Delta x
= x^{(k+1)}-x^{(k)}\)</span></p>
<p>则有 <span class="math inline">\(x^{(k+1)} = x^{(k)}-H\_k^{-1}\nabla
f(x^{(k)})\)</span>，而 <span class="math inline">\(-H\_k^{-1}\nabla
f(x^{(k)})\)</span> 则为点 <span class="math inline">\(x^{(k)}\)</span>
处的牛顿方向，也就是该点的下降方向。通过该公式进行迭代直至该点的梯度收敛，即其梯度的二阶范数<span
class="math inline">\(||\nabla f(x^{(k)})|| \lt \epsilon\)</span>。</p>
<p>牛顿法是具有<strong>二次收敛性</strong>的算法。若用原始牛顿法求某二次目标函数的最优解，则构造的逼近函数与原目标函数是完全相同的二次式，其等值线完全重合，故从任一点出发，一定可以一次达到目标函数的极小点。</p>
<p>其<strong>优点</strong>是：对于二次正定函数，迭代一次即可以得到最优解，对于非二次函数，若函数二次性较强或迭代点已经进入最优点的较小邻域，则收敛速度也很快。</p>
<p>其<strong>缺点</strong>是：由于迭代点的位置是按照极值条件确定的，并未沿函数值下降方向搜索，因此，对于非二次函数，有时会使函数值上升，即
<span class="math inline">\(f(x\_{k+1}) &gt;
f(x\_k)\)</span>，而使计算失败。</p>
<h6 id="阻尼牛顿法">阻尼牛顿法</h6>
<p>阻尼牛顿法对原始牛顿法进行了改进,每次迭代<strong>加入了步长</strong>
<span class="math inline">\(\alpha^{(k)}\)</span>，即将迭代公式从</p>
<p><span class="math inline">\(x^{(k+1)} = x^{(k)}-H\_k^{-1}\nabla
f(x^{(k)})\)</span></p>
<p>变为了</p>
<p><span class="math inline">\(x^{(k+1)} =
x^{(k)}-\alpha^{(k)}H\_k^{-1}\nabla f(x^{(k)})\)</span></p>
<p>最优步长 <span class="math inline">\(\alpha^{(k)}\)</span>
也称为阻尼因子，其求解方法也类似于最速下降中通过一维搜索得到的最优步长。</p>
<p>其<strong>优点</strong>是：
由于阻尼牛顿法每次迭代都在牛顿方向进行一维搜索，<strong>避免了迭代后函数值上升的现象</strong>，从而保持了牛顿法的二次收敛性，而对初始点的选择没有苛刻的要求。</p>
<p><strong>缺点</strong>是：
1）对目标函数要求苛刻，要求函数具有连续的一、二阶导数；为保证函数的稳定下降，海赛矩阵必须正定；为求逆阵要求海赛矩阵非奇异。
2）计算复杂且计算量大，存储量大</p>
<h6 id="拟牛顿法变尺度法">拟牛顿法(变尺度法)</h6>
<p>从前面介绍的最速下降法和牛顿法可知，梯度法的搜索方向只需计算函数的一阶偏导数，<strong>计算量小</strong>，当迭代点<strong>远离最优点时，函数值下降很快</strong>，但当迭代点<strong>接近最优点时收敛速度极慢</strong>。牛顿法的搜索方向不仅需要计算一阶偏导数，而且要计算二阶偏导数及其逆阵，<strong>计算量很大</strong>，但牛顿法具有二次收敛性，当<strong>迭代点接近最优点时，收敛速度很快。</strong></p>
<p>若迭代过程先用梯度法，后用牛顿法并避开牛顿法的海赛矩阵的逆矩阵的烦琐计算，则可以得到一种较好的优化方法，这就是“拟牛顿法”产生的基本构想。为此，综合梯度法和牛顿法的优点，提出拟牛顿法。</p>
<p>拟牛顿法的迭代公式与最速下降和阻尼牛顿法类似，</p>
<p><span class="math inline">\(x^{(k+1)} =
x^{(k)}-\alpha^{(k)}A\_k\nabla f(x^{(k)})\)</span></p>
<p>其中<span class="math inline">\(A\_k\)</span>为构造的构造的
<code>n×n</code> 阶对称矩阵，拟牛顿方向即为<span
class="math inline">\(-A\_k\nabla f(x^{(k)})\)</span>。</p>
<blockquote>
<p>当<span class="math inline">\(A\_k =
I\)</span>时，上式为最速下降法的迭代公式 当<span
class="math inline">\(A\_k =
H\_k^{-1}\)</span>时，上式为阻尼牛顿法的迭代公式</p>
</blockquote>
<p>拟牛顿法原来使通过DFP法构造 <span
class="math inline">\(A\_k\)</span>，构造过程中<strong>避开了二阶导数的计算</strong>，因此收敛速度也比较快；但是DFP算法由于舍入误差和一维搜索的不精确，有可能导致<span
class="math inline">\(A\_k\)</span>奇异，而使数值稳定性方面不够理想。所以1970年提出更稳定的算法，称为BFGS算法。这里不详细展开讨论这两种算法。</p>
<h5 id="共轭梯度法">共轭梯度法</h5>
<p>共轭梯度法的搜索方向采用<strong>梯度法基础上的共轭方向</strong>，如图所示，</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5i1mliksbh1nks1d5a185o14643b.png"
alt="共轭梯度法" />
<figcaption aria-hidden="true">共轭梯度法</figcaption>
</figure>
<p>目标函数 <span class="math inline">\(f(x)\)</span> 在迭代点 <span
class="math inline">\(x^{(k+1)}\)</span> 处的负梯度为<span
class="math inline">\(-\nabla
f(x^{(k+1)})\)</span>，该方向与<strong>前一搜索方向</strong> <span
class="math inline">\(S^k\)</span>
互为正交，在此基础上构造一种具有较高收敛速度的算法，该算法的搜索方向要满足以下两个条件：</p>
<p>1）以 <span class="math inline">\(x^{(k+1)}\)</span> 点出发的搜索方向
<span class="math inline">\(S^{k+1}\)</span> 是<span
class="math inline">\(-\nabla f(x^{(k+1)})\)</span> 与 <span
class="math inline">\(S^k\)</span> 的线性组合。即 <span
class="math display">\[ S^{k+1} = -\nabla f(x^{(k+1)}) +
\beta\_kS^k\]</span></p>
<p><span class="math display">\[\beta\_k = (\frac{||\nabla
f(x^{(k+1)})||}{||\nabla f(x^{(k)})||})^2\]</span></p>
<p>2）<span class="math inline">\([S^{k+1}]^TGS^k=0\)</span></p>
<p>除了计算下降方向方法不同，其迭代公式与前面的方法类似,为</p>
<p><span class="math inline">\(x^{(k+1)} =
x^{(k)}+\alpha^{(k)}S^{(k)}\)</span></p>
<p>收敛的判断也是判断梯度的二阶范数</p>
<p><span class="math inline">\(||\nabla f(x^{(k+1)})|| \lt
\epsilon\)</span> 是否成立即可</p>
<p>共轭梯度法属于解析法，其算法需求一阶导数，所用公式及算法简单，所需存储量少该方法以正定二次函数的共轭方向理论为基础，对二次型函数可以经过有限步达到极小点，所以<strong>具有二次收敛性</strong>。但是对于非二次型函数，以及在实际计算中由于计算机舍入误差的影响，虽然经过
n
次迭代，仍不能达到极小点，则通常以重置负梯度方向开始，搜索直至达到预定精度，其收敛速度也是较快的。</p>
<h4 id="方法对比">方法对比</h4>
<p>为了比较各种优化方法的特性，必须建立合理的评价准则。</p>
<p>无约束优化方法的评价准则主要包括以下几个方面</p>
<p>1、<strong>可靠性</strong>。即在合理的精度要求下，在一定允许时间内能解出各种不同类型问题的成功率。能够解出的问题越多，则算法的可靠性越好
2、<strong>有效性</strong>。即算法的解题效率。它有两个衡量标准。其一是对同一题目，在相同精度和初始条件下，比较机时多少。其二是在相同精度下，计算同一题目所需要的函数的计算次数。
3、<strong>简便性</strong>。一方面指实现该算法的准备工作量的大小。另一方面指算法占用存储单元的数量。</p>
<p>各个算法的性能对比如下：
<strong>可靠性</strong>：牛顿法较差，因为它对目标函数要求太高，解题成功率较低。<br />
<strong>有效性</strong>：坐标变换法和梯度法的计算效率较低，因为它们从理论上不具有二次收敛性。
<strong>简便性</strong>：牛顿法和拟牛顿法的程序编制较复杂，牛顿法还占用较多的存储单元。</p>
<p>在选用无约束优化方法时，一方面要考虑优化方法的特点，另一方面要考虑目标函数的情况。
1、一般而言，对于<strong>维数较低或者很难求得导数</strong>的目标函数，使用<strong>坐标轮换法</strong>较合适。
2、对于<strong>二次性较强的目标函数</strong>，使用<strong>牛顿法</strong>效果好。
3、对于<strong>一阶偏导数易求</strong>的目标函数，使用<strong>梯度法</strong>可使程序编制简单，但精度不宜过高
4、综合而言，共轭梯度法和DFP法具有较好的性能。</p>
<h3 id="约束非线性规划">约束非线性规划</h3>
<p>约束条件下的非线性规划模型如下所示</p>
<p><span class="math display">\[
min\;f(x)\\\
s.t\quad h\_i(x) = 0(i=1,2,...,m)\\\
\quad\quad g\_j(x) \ge 0(j=1,2,...,l)\\\
\]</span></p>
<p>在约束非线性规划中有几个比较重要的概念</p>
<p><strong>起作用约束和不起作用约束</strong></p>
<p>对于约束条件 <span class="math inline">\(g\_j(x) \ge
0(j=1,2,...,l)\)</span>,满足它有两种可能：其一是<span
class="math inline">\(g\_j(x) \gt 0\)</span>, 这时, <span
class="math inline">\(x\)</span>
不是处于由这一约束条件形成的可行域的边界上，因此当点不论沿什么方向稍微离开时,都不会违背这一约束条件,这样的约束就称为不起作用约束，即它<strong>对
的微小扰动不起限制作用</strong>,也就是约束中的所有等式约束均是起作用约束，包括
所有的<span class="math inline">\(h(x)\)</span> 和 <span
class="math inline">\(g(x)\)</span>
中取等号的约束。注意，<strong>不起作用约束并不是无效约束</strong>！</p>
<p><strong>有效集(积极集)</strong>
有效集定义为不等式约束中符号为等号的那些约束条件的下标，如对于上面的带约束的非线性规划模型，其有效集为</p>
<p><span class="math inline">\(I(x) = \lbrace j|g\_j(x)=0, 1 \le j \le l
\rbrace\)</span></p>
<h4 id="kt条件">KT条件</h4>
<p>在不同的资料中，KT(Kuhn-Tucker) 条件也会被称为
KKT(Karush-Kuhn-Tucker)条件。原因是这个理论是 Karush(1939年) 以及
Kuhn和Tucker(1951)
先后独立发表出来的。而且是在Kuhn和Tucker发表之后才逐渐受到重视,所有很多教材都会将这一条件称为KT条件，我们这里只需要知道这KT跟KKT是一样的东西就可以了。</p>
<p>KT条件是非线性规划领域中最重要的理论成果之一，其重要的意义在于它是<strong>确定某点是最优点的一阶必要条件</strong>，只要是最优点就必须满足这个条件。但一般来说它不是充分条件，即满足KT条件的点并不一定是最优点。但是<strong>对于凸规划，KT条件是最优点存在的充要条件</strong>。也就是说在凸规划中通过KT条件可以找到最优解。</p>
<p>对于非线性规划模型 <span class="math display">\[
min\;f(x)\\\
s.t\quad h\_i(x) = 0(i=1,2,...,m)\\\
\quad\quad g\_j(x) \ge 0(j=1,2,...,l)\\\
\]</span></p>
<p>其KT条件为 <span class="math display">\[
\nabla f(x) - \sum\_{i=1}^mr\_i\nabla h\_i(x) -
\sum\_{j=1}^l\lambda\_j\nabla g\_j(x) = 0\\\
\lambda\_j g\_j(x) = 0\quad (j=1,2,3...l)\\\
\lambda\_j \ge 0 \quad (j=1,2,3...l)\\\
\]</span></p>
<p>求解上面的KT条件组成的方程组得到的 <span
class="math inline">\(x\)</span>
值就是KT点，也就是最优点(对于凸规划而言)。另外,下式</p>
<p>$f(x) - _{i=1}^mr_i h_i(x) - _{j=1}^l_j g_j(x) $</p>
<p>通常被称为上面非线性规划问题的<strong>拉格朗日函数</strong>，对应的</p>
<p><span class="math inline">\((r\_1,r\_2,...r\_m)\)</span> 和 <span
class="math inline">\((\lambda\_1,\lambda\_2,...\lambda\_l)\)</span></p>
<p>称为<strong>拉格朗日乘子</strong>。</p>
<h4 id="罚函数法">罚函数法</h4>
<p>罚函数法的思想是<strong>借助惩罚函数将约束问题装化为无约束问题进行求解</strong>，根据惩罚函数的不同，罚函数法又分为外点法，内点法和乘子法。</p>
<h5 id="外点法">外点法</h5>
<p>外点法可以用来解决只有等式约束、只有不等式约束或同时含有等式和不等式约束问题。</p>
<p>先考虑只有等式约束的问题如下 <span class="math display">\[
min\;f(x)\\\
s.t\quad h\_i(x) = 0(i=1,2,...,m)\\\
\]</span></p>
<p>则可以将上面的带约束的问题等价于下面的无约束问题</p>
<p><span class="math display">\[min\;p(x,M) = f(x) + M\sum\_i^m
[h\_i(x)]^2\]</span></p>
<p>其中 M 是充分大的正数(求解时一般让其趋于无穷大),被称为罚因子，而
<span class="math inline">\(p(x,M)\)</span> 称为惩罚函数，<span
class="math inline">\(M\sum\_i^m [h\_i(x)]^2\)</span>
为惩罚项，其作用就是当 <span class="math inline">\(x\)</span>
不满足任一等式约束 <span class="math inline">\(h(x) = 0\)</span>
时，罚项就会变得很大从而使解不能满足最小，也就是惩罚了这个解。</p>
<p>同样对于不等式约束问题 <span class="math display">\[
min\;f(x)\\\
s.t\quad g\_j(x) \ge 0(j=1,2,...,l)\\\
\]</span></p>
<p>构造的惩罚函数为</p>
<p><span class="math display">\[p(x,M) = f(x) + M\sum\_j^l [min(0,
g\_j(x))]^2\]</span></p>
<p>其含义也是当 <span class="math inline">\(x\)</span>
满足不等式约束条件时，罚项为0，不满足是罚项就会变得很大，从而使当前的
<span class="math inline">\(x\)</span> 不忙足目标函数值最小。</p>
<p>对于同时含有等式约束和不等式约束的规划问题，只要将上面的等式约束和不等式约束中的罚项加在一起即可构造惩罚函数：
<span class="math display">\[p(x,M) = f(x) + M( \sum\_i^m [h\_i(x)]^2 +
\sum\_j^l [min(0, g\_j(x))]^2)\]</span></p>
<p>求解时只需要用无约束问题的求解方法求解惩罚函数的最小点即可，如下为一个求解的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5m40a01f1rqtv1n8h1r01a0im.png"
alt="外点法求解例子" />
<figcaption aria-hidden="true">外点法求解例子</figcaption>
</figure>
<p>让 <span class="math inline">\(M\_k \rightarrow \infty\)</span>
即可得到最优解为 <span class="math inline">\(x =(2,1)^T\)</span>。
但是假如让M逐步变化，可以得到以下表格</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5m43kp7qnn1mm31dd4polenv13.png"
alt="外点法渐变过程" />
<figcaption aria-hidden="true">外点法渐变过程</figcaption>
</figure>
<p>从上面的表格可知，当 <span class="math inline">\(M\_k\)</span>
从<span class="math inline">\(1 \rightarrow \infty\)</span>
过程中，<strong>罚函数的一系列无约束极小点是从可行域的外部趋近最优解的</strong>，因此，这也是外点法名称的来历。</p>
<h5 id="内点法">内点法</h5>
<p>这里讲述的内点法只考虑不等式约束的问题，对于问题</p>
<p><span class="math display">\[
min\;f(x)\\\
s.t\quad g\_j(x) \ge 0(j=1,2,...,l)\\\
\]</span></p>
<p>其严格内点集合(又称可行域内部)定义为</p>
<p><span class="math inline">\(H = \lbrace g\_j(x) &gt; 0
|j=1,2,...,l\rbrace\)</span></p>
<p>内点法就是通过<strong>在严格内点集合中进行迭代</strong>得到最优解，这也是内点法这一说法的来历，需要注意的是<strong>内点法得到的最优解并不一定是全局最优解，因为内点法只是在严格内点中迭代，而全局最优解有可能落在边界上</strong>。但是对于最优解不落在边界的问题，内点法能够得到最优解，并且对于那些最优解落在边界上的问题，内点法也能够获得较好的近似解。</p>
<p>对于上面的模型可以构造障碍函数</p>
<p><span class="math display">\[p(x,r\_k) = f(x) + r\_k \sum\_j^l
\frac{1}{g\_j(x)}\]</span></p>
<p>或</p>
<p><span class="math display">\[p(x,r\_k) = f(x) - r\_k \sum\_j^l
ln(g\_j(x))\]</span></p>
<p>求解障碍函数的最小值就相当于求解原来的带约束问题；障碍函数类似于外点法中的惩罚函数，其中
<span class="math inline">\(r\_k \sum\_j^l \frac{1}{g\_j(x)}\)</span> 或
<span class="math inline">\(- r\_k \sum\_j^l ln(g\_j(x))\)</span>
被称为障碍项，<span class="math inline">\(r\_k\)</span>
称为障碍因子。</p>
<p>障碍函数的作用是惩罚靠近可行域边界的 <span
class="math inline">\(x\)</span> 点，即那些使 <span
class="math inline">\(g(x) = 0\)</span> 的点，当 <span
class="math inline">\(x\)</span>
靠近这些边界的时候，障碍项会变得很大，从而使得其不满足障碍函数最小。</p>
<p>其求解的一个例子如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5m65o8q1don3qn14u0hp57nq1g.png"
alt="内点法求解例子" />
<figcaption aria-hidden="true">内点法求解例子</figcaption>
</figure>
<h5 id="乘子法">乘子法</h5>
<p>乘子法类似于上面提到的外点法和内点法，也是通过引入<strong>乘子罚函数</strong>使约束问题变为无约束问题。但是与前面不同的地方是乘子罚函数是在罚函数的基础上增加了拉格朗日乘子项，从而称为増广拉格朗日函数。这里只讨论等式约束的情况。</p>
<p>对于问题 <span class="math display">\[
min\;f(x)\\\
s.t\quad h\_i(x) = 0(i=1,2,...,m)\\\
\]</span></p>
<p>定义<strong>增广拉格朗日函数(乘子罚函数)</strong>为</p>
<p><span class="math display">\[\varphi (x,\lambda, M) = f(x) -
\sum\_{i=0}^m \lambda\_i h\_i(x) + \frac{M}{2} \sum\_{i=1}^m
[h\_i(x)]^2\]</span></p>
<p>其中，<span class="math inline">\(\overrightarrow \lambda =
(\lambda\_1,\lambda\_2,...\lambda\_m)^T\)</span>
为拉格朗日乘子向量。则原问题的求解转为了求解增广拉格朗日函数的极小点。</p>
<p>乘子罚函数 <span class="math inline">\(\varphi (x,\lambda,
M)\)</span> 与<a
href="https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0">普通拉格朗日函数</a>的区别是增加了罚项
<span class="math inline">\(\frac{M}{2} \sum\_{i=1}^m
[h\_i(x)]^2\)</span>, 与罚函数的区别是增加了乘子项$ - _{i=0}^m _i
h_i(x)$.</p>
<p>假如知道拉格朗日乘子 <span class="math inline">\(\overrightarrow
\lambda\)</span>,
再给定一个足够大的罚因子M(M不必趋于无穷大)，就可以通过极小化 <span
class="math inline">\(\varphi (x,\lambda, M)\)</span>
得到问题的局部最优解。但是由于 <span
class="math inline">\(\overrightarrow \lambda\)</span>
事先无法知道，所以给定一个足够大的 <span
class="math inline">\(M\)</span> 和初始的估计量 <span
class="math inline">\(\overrightarrow
{\lambda^{(1)}}\)</span>，每次通过下面的公式对 <span
class="math inline">\(\overrightarrow \lambda\)</span> 进行修正。</p>
<p><span class="math display">\[ \overrightarrow {\lambda^{(k+1)}} =
\overrightarrow {\lambda^{(k)}} - Mh\_i(x^{(k)})\]</span></p>
<p>上式中的 <span class="math inline">\(x^{(k)}\)</span> 是第 k
次迭代拉格朗日乘子为 <span class="math inline">\(\overrightarrow
{\lambda^{(k)}}\)</span> 时得到的极小点。通过上式进行迭代直至 <span
class="math inline">\(\overrightarrow \lambda\)</span> 收敛。</p>
<p>在乘子法中，罚因子 <span class="math inline">\(M\)</span>
不必趋于无穷大，只要足够大，就可以通过极小化乘子罚函数，得到原来约束问题的局部最优解，而这避免了罚函数法中的病态问题。实践证明，乘子法优于罚函数法,使用范围比罚函数要广。</p>
<p>下面为一个求解的简单例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5mc6mvkgkess9b9c1lou1tdu2a.png"
alt="乘子法的例子" />
<figcaption aria-hidden="true">乘子法的例子</figcaption>
</figure>
<p>得到上面的等式后假设 <span class="math inline">\(\overrightarrow
{\lambda^{(k)}}\)</span> 的收敛值为 <span
class="math inline">\(\alpha\)</span>,则有 <span
class="math inline">\(\alpha = \frac{7}{23} \alpha +
\frac{28}{23}\)</span></p>
<h4 id="二次规划">二次规划</h4>
<p>二次规划是特殊的非线性规划，形式简单，既可以使用求耳机非线性规划的一般方法，又可以使用特定的解法。在实际中有广泛应用，如支持向量机（SVM）本质上就是一个二次规划问题。</p>
<p>二次规划问题的一般模型也如下 <span class="math display">\[
min\;f(x)\\\
s.t\quad h\_i(x) = 0(i=1,2,...,m)\\\
\quad\quad g\_j(x) \ge 0(j=1,2,...,l)\\\
\]</span></p>
<p>但是<strong>要求 <span class="math inline">\(f(x)\)</span>
是二次函数，而 <span class="math inline">\(h\_i(x)\)</span> 和 <span
class="math inline">\(g\_j(x)\)</span> 是线性函数。</strong>
因此可以展开写成如下的形式：</p>
<p><span class="math display">\[
min\;f(x) = \frac{1}{2}x^TGx + r^Tx\\\
s.t\quad A\_i^Tx - b\_i = 0(i=1,2,...,m)\\\
\quad\quad\quad A\_i^Tx-b\_i \ge 0(i=m+1,...,m+l)\\\
\]</span></p>
<p>其中 G 为 <span class="math inline">\(n × n\)</span> 阶对称矩阵(
<span class="math inline">\(n\)</span> 为未知变量个数)，<span
class="math inline">\(r,A\_i\)</span> 为n 位列向量，<span
class="math inline">\(b\_i\)</span> 为实数。<strong>若矩阵 G
为(正定)半正定矩阵，那么将问题称为严格)凸二次规划</strong>。前面提到，对于凸规划，<span
class="math inline">\(\overline x\)</span>
为全局极小点的充要条件是该点满足如下的KT条件。</p>
<p><span class="math display">\[
G\overline x + r - \sum\_{i=1}^{m+l}\lambda\_iA=0\\\
\lambda\_i (A\_i^Tx-b\_i) = 0(i=m+1,...,m+l)\\\
\lambda\_i \ge 0(i=m+1,...,m+l)
\]</span></p>
<p>通过求解KT条件组成的方程组，能够解出二次规划的最优化问题，这只是求解非线性规划的一般方法，还有一些专门用来求解二次规划的方法，对于只含有等式约束的二次规划问题可采用消去法，而同时含有等式约束和不等式约束的解决方法是有效集法，这是更一般的解决方法，下面主要介绍有效集法的原理和过程。</p>
<p>有效集法又称积极集法，其基本思想是<strong>通过求解有限个等式约束二次规划问题来求解一般约束下的二次规划问题。</strong>从直观上理解，不起作用的约束在解的附近不起任何作用，可以去掉不考虑，而起作用(积极)的不等式约束由于在解处等于0，故可以用等式约束来代替不等式约束。</p>
<p>有效集方法中的有效集指的是约束中取等号的那些约束条件，对于上面的问题，定义</p>
<p>$I(x) = i| A_i^Tx =b_i, m+1 i m+l$</p>
<p>则有效集为</p>
<p><span class="math inline">\(E = \lbrace 1,2,...m\rbrace \bigcup
I(x)\)</span></p>
<p>有效集方法就是将其转化为以下问题进行求解，并对得到的解进行讨论 <span
class="math display">\[
min\;f(x) = \frac{1}{2}x^TGx + r^Tx\\\
s.t\quad A\_i^Tx = b\_i (i \in E)\\\
\]</span></p>
<p>其具体计算步骤如下</p>
<p><img
src="https://wulc.me/imgs/image_1b5mp3qbeafq14ma1865obmk7e34.png"
alt="有效集法计算步骤1" /> <img
src="https://wulc.me/imgs/image_1b5mp5eok1thd14gl39epfk1k763h.png"
alt="有效集计算步骤2" /></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>有价值的数据应该如何交易</title>
    <url>/2017/06/16/%E6%9C%89%E4%BB%B7%E5%80%BC%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%94%E8%AF%A5%E5%A6%82%E4%BD%95%E4%BA%A4%E6%98%93/</url>
    <content><![CDATA[<p>本文的内容主要来源于<a
href="https://www.zhihu.com/lives/778740481268920320">该知乎
live</a>，主要介绍了哪些行为数据是有价值的，以及广告领域中数据是如何交易的，最后还讨论了数据隐私的问题。</p>
<span id="more"></span>
<h2 id="有价值的数据分类">有价值的数据分类</h2>
<p>数据有价值密度之分，并不是说数据量越多就一定越有效</p>
<p>这里的数据主要指的是用户的行为数据和用户的标识数据，而有价值的用户行为数据主要有:
决策行为、主动行为、半主动行为、被动行为，这些行为的价值递减，但是数据的量递增，因为有价值的数据一般量都不大</p>
<h3 id="决策行为">决策行为</h3>
<p>决策行为对应着<strong>转化(conversion)或预转化(pre-conversion)</strong>,
也就是购买了商品或将商品加入了购物车。这些行为对应着非常明确的用户兴趣，价值也非常高</p>
<h3 id="主动行为">主动行为</h3>
<p>主动行为对应着<strong>搜索（search）、广告点击（Ad
Click)、搜索点击（Search
Click）</strong>，这种行为表明了用户已经有了明确的意图，但是最终决定还不清楚，价值也很高。</p>
<p>需要注意的是，这些行为里面往往会有作弊的流量在里面，需要去除掉。</p>
<h3 id="半主动行为">半主动行为</h3>
<p>半主动行为对应着分享<strong>（share），网页浏览（page
view)</strong>,这种数据的量最大，用户意图较弱，因为用户可能只是随意在浏览，这些数据也有一定价值。</p>
<h3 id="被动行为">被动行为</h3>
<p>被动行为是强加给用户的行为，如广告的浏览（注意不是点击，而是强推给用户浏览），这种行为甚至会有负面作用，价值基本可以忽略</p>
<h3 id="社交关系">社交关系</h3>
<p>社交关系指的是不直接利用用户的行为数据（有可能是用户的行为数据过于稀疏），而是利用与其在社交网络（微博、Facebook
等）上有关联的的用户的信息进行定向。</p>
<p>这种方法在某个人的行为不足而无法进行精准的行为定向时有效。</p>
<h3 id="用户-id">用户 ID</h3>
<p>用户 ID
，也就是用户标示，是最重要的数据，因为所有的行为数据有效的前提是需要先确认这些行为数据是属于哪个用户的，标识一个用户的
ID 在不同的环境下有不同的方法，下面是常见的场景和方法</p>
<ol type="1">
<li>web/wap 环境：使用
cookie，生命周期短（1~2周），存续性差，但是跨域名的时候需要映射</li>
<li>ios 应用：使用 IDFA（ID For Advertiser)，存续性好于 cookie，但 ios10
有更严格的政策</li>
<li>安卓应用：使用 Android ID，存续好于 IDFA；有些也使用
IMEI（手机标识），但是 Google Play 上是不给用的</li>
<li>无以上 ID 场景：使用 FingerPrint（IP+UserAgent -&gt; hash），存在
http 头中，可作缺省标识;
但是在移动端使用效果不是很好，因为几乎每个应用都有一个内置的浏览器</li>
</ol>
<h2 id="三方数据划分">三方数据划分</h2>
<p>下面以广告中用到的用户数据为例讲述三方数据的划分，在广告中根据数据来源的不同可以将数据划分为第一方数据，第二方数据和第三方数据。</p>
<p>如下图所示，第一方和第二方分别是指广告主和广告平台，而不直接参与广告交易的其他数据提供方统称为第三方。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bijcs38i1i2l1au243pm9u15sq1g.png"
alt="三方数据" />
<figcaption aria-hidden="true">三方数据</figcaption>
</figure>
<h2 id="数据管理平台dmp">数据管理平台(DMP)</h2>
<p>第一方数据的收集和加工是广告市场上非常重要的环节，不过对于没有这方面技术积累的广告主而言，专门设团队进行数据加工是没有必要的，因此市场上出现了
数据管理平台（DMP),专门从事此业务，而 DMP 又可划分为第一方 DMP 和第三方
DMP。</p>
<h3 id="第一方-dmp">第一方 DMP</h3>
<p>第一方 DMP
的目的是对广告主提供的第一方数据（也可结合公开市场第三方数据）进行加工，进而得到广告主指定的用户标签，用于支持网站业务运营和广告投放。</p>
<p>需要注意的是第一方 DMP
只能加工第一方数据，而不能使用第一方的数据，也就是不能把数据进行售卖（除非与广告主达成协议）</p>
<p>因此，第一方的 DMP 的商业模式如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bijepnkc1uv2sthoap143vce82a.png"
alt="第一方DMP商业模式" />
<figcaption aria-hidden="true">第一方DMP商业模式</figcaption>
</figure>
<h3 id="第三方-dmp">第三方 DMP</h3>
<p>对于中小网站，其规模不大，没有利用数据的能力，只是单纯想将数据卖给需要数据的广告主，同时也没有加工数据的能力，因此产生了满足中小网站的这项需求的第三方
DMP。</p>
<p>第三方 DMP 与第一方 DMP
的一个不同点在于服务对象的不同，另外一个不同点则是两者的加工标签的逻辑不一样，第一方
DMP 是根据广告主的需求进行标签的加工，而第三方 DMP 则是根据 DMP
其自己的逻辑进行加工然后售卖。</p>
<p>第三方的 DMP 的商业模式如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bijf1h1m1tk0os71sei1dgava02n.png"
alt="第三方DMP的商业模式" />
<figcaption aria-hidden="true">第三方DMP的商业模式</figcaption>
</figure>
<h2 id="数据的交易">数据的交易</h2>
<p>上面提到的 DMP
的一个重要功能就是售卖标签，实际上就是一种数据交易，这些标签一般售卖的对象是广告主，而广告主往往由于缺乏相应的技术而将手中定向委托给其他平台也就是
DSP（Demand Side Platform），因此交易发生在 DMP 和 DSP 之间。</p>
<p>同时由于往往存在着多个 DMP 和多个 DSP，假如 DMP 和 DSP
间都要一一连接的话，那么通信的代价会非常大，因此在实际中往往是通过广告交易平台也就是
ADX（AD Exchange)
将两者联系起来，从而降低通信代价。整个数据交易的过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bijffr3s16rc1etl15nllao1pan34.png"
alt="数据交易怎么做" />
<figcaption aria-hidden="true">数据交易怎么做</figcaption>
</figure>
<p>通过 ADX 进行 DMP 和 DSP 间的通信避免了 DMP 和 DSP
直接通信的开销，因为实时竞价的时候 ADX 本来就要跟 DSP
发生通信，因此没有增加二次通信。</p>
<p>上面简单提到数据交易时的收费是按照实际的广告展示次数付费的，目前来说这种市场化的定价方式是唯一的选择，这种方式并没有限制数据供给次数，直觉上似乎是利润最大化的。</p>
<p>但是这有可能间接地抬高了流量价格，而低估了数据价格。因为不限量地售卖标签，会导致竞价同一次展示的广告主的数目增加，因为有了标签，各个广告主能够更精准地定向到更多用户，因此更多的广告主的竞价抬高了流量的价格，
而假如广告主的预算是一定的情况下，购买流量需要更多的钱，因此用于购买数据支出会变少。当然这只是宏观上的探讨，目前业界对此并没有一套完善的理论来指导。</p>
<p>如果采用限量的售卖，那就要采用竞价的方式，而有了竞价，整个市场的活跃程度和价值会最大化。</p>
<h2 id="数据隐私">数据隐私</h2>
<p>在数据交易过程中不可避免地会设计到数据隐私的问题。针对数据隐私，欧盟负责隐私保护条例指定的委员会
A29 制定了以下相关原则</p>
<ol type="1">
<li>Personal Identifiable
Information（PII）不能使用，PII指的是可以主动接触到用户的信息，比如手机号、QQ号、微信号、e-mail等都不能使用</li>
<li>用户可以要求系统停止记录和使用自己的行为数据，比如说网站会在网页上说明收集到的用户数据的作用，同时可让用户选择是否允许收集其数据，实际上对商业影响非常小，因为选择不允许收集的用户比例不大</li>
<li>不能长期保存和使用用户的行为数据，实际上数据也具有时效性，时间太久远的数据基本上无价值</li>
</ol>
<p>另外一个数据隐私问题就是稀疏的行为数据带来的挑战，一个典型的例子就是
Netflix
推荐大赛中，有人从数据集里面发现了自己的同时是同性恋，原因是数据的稀疏性使得个人的行为数据更加容易被熟悉这个人的其他人所辨识。</p>
<p>目前对于这个领域相关的研究课题是差分隐私（differential
privacy）。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统课程总结</title>
    <url>/2016/12/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>本文为操作系统的课程小结，主要讲述 Linux
内核的一些知识，参考的主要教材为《<a
href="https://book.douban.com/subject/6097773/">Linux内核设计与实现(第3版)</a>》，除此之外还参考了网络上的若干资料，因为Linux本来就是可以写若干本书的内容，所以这里只会涉及到博主上课时接触到的一些知识点，由于博主知识有限，个中定存在错漏地方，望不吝指出。</p>
<span id="more"></span>
<h2 id="第一章内核简介">第一章：内核简介</h2>
<h3 id="linux-内核特点">Linux 内核特点</h3>
<ul>
<li><p>动态加载内核模块</p></li>
<li><p>支持对称多处理（<a
href="https://zh.wikipedia.org/wiki/%E5%B0%8D%E7%A8%B1%E5%A4%9A%E8%99%95%E7%90%86">SMP</a>）
&gt;
在计算领域，对称多处理是一种多处理机硬件架构，有两个或更多的相同的处理机（处理器）共享同一主存，由一个操作系统控制</p></li>
<li><p>内核可抢占(Preemption): 要理解 Preemption 首先要了解操作系统的
Context Switch &gt;Context Switch (上下文切换)
指任何操作系统上下文(<strong>上下文简单说来就是一个环境，如进程上下文就是CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，中断上下文就是硬件的参数和内核需要保存的一些其他环境</strong>)保存和恢复执行状态，以便于<strong>被安全地打断和稍后被正确地恢复执行</strong>。当发生进程调度时，<strong>进行进程切换就是上下文切换</strong>,一般操作系统中通常因以下三种方式引起上下文切换:
&gt;1. <strong>Task Scheduling
(任务调度)</strong>。任务调度一般是由<strong>调度器代码在内核空间</strong>完成的。
通常需要将当前 CPU
执行任务的代码，用户或内核栈，地址空间切换到下一个要运行任务的代码，用户或内核栈，地址空间。
&gt;2. <strong>Interrupt (中断) 或 Exception
(异常)</strong>。中断和异常是由硬件产生但由软件来响应和处理的。这个过程中，涉及到将用户态或内核态代码切换至中断处理代码。
&gt;3. <strong>System Call
(系统调用)</strong>。系统调用是由用户态代码主动调用，使用户进程陷入到内核态调用内核定义的各种系统调用服务。系统调用实质就是通过指令产生中断，也称为软中断。
&gt;
&gt;实际上，<strong>进程从用户态进入内核态的方式只有两种:中断和异常</strong>。(系统调用实际上最终是中断机制实现的)</p></li>
</ul>
<p>Preemption (抢占)
是指操作系统允许满足某些重要条件(例如：优先级，公平性)的任务<strong>打断当前正在
CPU
上运行的任务而得到调度执行</strong>。并且这种打断不需要当前正在运行的任务的配合，同时被打断的程序可以在后来可以再次被调度恢复执行。</p>
<ul>
<li>线程的实现：内核并不区分线程和其他的一般进程，线程是一个标准的进程，与进程的最大区别在于是否有独立的地址空间</li>
<li>设备管理: 所有设备都是文件</li>
</ul>
<h3 id="内核版本号">内核版本号</h3>
<p><code>主版本号.从版本号.修订版本号</code>，从版本号为偶数时为稳定版本，奇数时为开发版</p>
<h3 id="内核应用">内核应用</h3>
<ul>
<li>内核开发、移植</li>
<li>驱动</li>
<li>文件系统</li>
<li>云计算与虚拟化</li>
</ul>
<h2 id="第二章内核的编译与安装">第二章：内核的编译与安装</h2>
<p>简单教程：http://www.cnblogs.com/hdk1993/p/4910362.html</p>
<p>补丁概念</p>
<p>内核开发特点：</p>
<ul>
<li>不能访问c库，只能使用c的语法</li>
<li>缺乏内存保护机制</li>
<li>浮点数难以使用</li>
<li>注意同步和并发（原因：竞争条件（可抢占多任务系统），解决方法：自旋锁和信号量）</li>
<li>保持可移植性</li>
</ul>
<h2 id="第三章进程管理">第三章：进程管理</h2>
<h3 id="进程描述符">进程描述符</h3>
<p>内核通过一个任务队列（<code>task list</code>）组织所有的进程，任务队列是一个双向链表，结构如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b3i3p5eothk76t1tbq96ajik9.png" /></p>
<p>图中链表中每一项都是类型为 <code>task_struct</code>
，称为<strong>进程描述符</strong>的结构。进程描述符包含了一个具体进程的所有信息，如：</p>
<ul>
<li>进程状态</li>
<li>进程的地址空间</li>
<li>PID</li>
<li>指向父、子进程的指针</li>
<li>打开的文件</li>
<li>......</li>
</ul>
<h4 id="task_struct-的存放位置">task_struct 的存放位置</h4>
<ul>
<li>2.6 之前存放在进程的内核栈底</li>
<li>2.6之后改为了通过内核栈底的一个结构（<code>thread_info</code>），这个结构中有一个指针指向其<code>task_structure</code></li>
</ul>
<blockquote>
<p><strong>关于进程的内核栈和用户栈</strong>
参考：http://blog.csdn.net/dlutbrucezhang/article/details/9326857
每个进程都有自己的堆栈，内核在创建一个新的进程时，在创建进程控制块<code>task_struct</code>的同时，也为进程创建自己堆栈。<strong>一个进程有2个堆栈，用户堆栈和系统堆栈</strong>；用户堆栈的空间指向用户地址空间，内核堆栈的空间指向内核地址空间。当进程在用户态运行时，CPU
堆栈指针寄存器指向的
用户堆栈地址，使用用户堆栈，当进程运行在内核态时，CPU堆栈指针寄存器指向的是内核栈空间地址，使用的是内核栈；</p>
<p>当进程由于中断或系统调用从用户态转换到内核态时，进程所使用的栈也要从用户栈切换到内核栈。进程因为中断（软中断或硬件产生中断），使得CPU切换到特权工作模式，此时进程陷入内核态，进程进入内核态后，首先把用户态的堆栈地址保存在内核堆栈中，然后设置堆栈指针寄存器的地址为内核栈地址，这样就完成了用户栈向内核栈的切换。当进程从内核态切换到用户态时，最后把保存在内核栈中的用户栈地址恢复到CPU栈指针寄存器即可，这样就完成了内核栈向用户栈的切换。</p>
</blockquote>
<h4 id="task_struct-的组成部分">task_struct 的组成部分</h4>
<p><code>task_struct</code>中包含了进程的所有信息，如<strong>进程的状态，优先级，pid，父进程与子进程，运行的时间，与文件系统的交互情况，内存使用情况(<code>mm_struct</code>)</strong>等。</p>
<p>这里详细介绍的几个重要组成部分：</p>
<h5 id="进程的状态">进程的状态</h5>
<p>广义来说，对所有操作系统而言，进程的状态一般可以分为<code>running</code>,<code>ready</code>和<code>block</code>状态，其中<code>running</code>表示进程正在cpu上跑,<code>ready</code>表示进程正在等待cpu分配执行的时间片，一旦分配了时间片即可进入<code>running</code>状态，而<code>block</code>表示当前的进程正在等待某些资源(如用户的输入)，只有得到了这些资源，才可进入<code>ready</code>状态。</p>
<p>但是在 Linux
中，为进程定义了五种状态，与上面所说的状态略有不同，每种状态定义如下：</p>
<p><strong>1. R (task_running) : 可执行状态</strong></p>
<p>只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的<code>task_struct</code>结构（进程控制块）被放入对应CPU的<strong>可执行队列中</strong>（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。这种状态包含了正在执行的进程和等待分配时间片的进程，即包含了上面的<code>running</code>和<code>ready</code>状态。</p>
<p><strong>2. S (task_interruptible): 可中断的睡眠状态</strong></p>
<p>处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的<code>task_struct</code>结构被放入<strong>对应事件的等待队列中</strong>。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。</p>
<p>通过<code>top</code>命令我们会看到，一般情况下，进程列表中的<strong>绝大多数进程都处于<code>task_interruptible</code>状态（除非机器的负载很高）</strong>。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。</p>
<p><strong>3. D (task_uninterruptible): 不可中断的睡眠状态</strong></p>
<p>与<code>task_interruptible</code>状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指<strong>进程不响应异步信号</strong>。</p>
<p>绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。但是<code>task_uninterruptible</code>
状态的进程<strong>不接受外来的任何信号，因此无法用 <code>kill</code>
杀掉这些处于D状态的进程</strong>，无论是 <code>kill</code>,
<code>kill -9</code>还是<code>kill -15</code>，这种情况下，一个可选的方法就是reboot。</p>
<p>处于<code>task_uninterruptible</code>状态的进程通常是在<strong>等待IO</strong>，比如磁盘IO，网络IO，其他外设IO，如果进程正在等待的IO在较长的时间内都没有响应，那么就被ps看到了，同时也就意味着很有可能有IO出了问题，可能是外设本身出了故障，也可能是比如挂载的远程文件系统已经不可访问了.</p>
<p>而<strong><code>task_uninterruptible</code>状态存在的意义就在于，内核的某些处理流程是不能被打断的。</strong>如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。</p>
<p>在<strong>进程对某些硬件进行操作时，可能需要使用<code>task_uninterruptible</code>状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态</strong>。这种情况下的<code>task_uninterruptible</code>状态总是非常短暂的，通过ps命令基本上不可能捕捉到。</p>
<p><strong>4. T(task_stopped or
task_traced)：暂停状态或跟踪状态</strong></p>
<p>向进程发送一个<code>sigstop</code>信号，它就会因响应该信号而进入<code>task_stopped</code>状态（除非该进程本身处于<code>task_uninterruptible</code>状态而不响应信号）。</p>
<p>向进程发送一个<code>sigcont</code>信号，可以让其从<code>task_stopped</code>状态恢复到<code>task_running</code>状态。</p>
<p><strong>当进程正在被跟踪时，它处于<code>task_traced</code>这个特殊的状态</strong>。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在调试的时候对被跟踪的进程下一个断点，<strong>进程在断点处停下来的时候就处于<code>task_traced</code>状态</strong>。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。</p>
<p>对于进程本身来说，<code>task_stopped</code>和<code>task_traced</code>状态很类似，都是表示进程暂停下来。而<code>task_traced</code>状态相当于在<code>task_stopped</code>之上多了一层保护，处于<code>task_traced</code>状态的进程不能响应<code>sigcont</code>信号而被唤醒。只能等到调试进程通过<code>ptrace</code>系统调用执行<code>ptrace_cont</code>、<code>ptrace_detach</code>等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复<code>task_running</code>状态。</p>
<p><strong>5. Z (task_dead -
exit_zombie)：退出状态，进程成为僵尸进程</strong></p>
<p>在Linux进程的状态中，僵尸进程是非常特殊的一种，它是<strong>已经结束了的进程，但是没有从进程表中删除。太多了会导致进程表里面条目满了</strong>(PID数目有限)，进而导致系统崩溃，倒是不占用其他系统资源。</p>
<p><strong>僵尸进程已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。</strong></p>
<p>进程在退出的过程中，处于<code>TASK_DEAD</code>状态。在这个退出过程中，进程占有的所有资源将被回收，除了<code>task_struct</code>结构（以及少数资源）以外。于是进程就只剩下<code>task_struct</code>这么个空壳，故称为僵尸。</p>
<p><strong>之所以保留<code>task_struct</code>，是因为<code>task_struct</code>里面保存了进程的退出码、以及一些统计信息，而其父进程很可能会关心这些信息</strong>。比如在shell中，<code>$?</code>变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。</p>
<p>当然，内核也可以将这些信息保存在别的地方，而将<code>task_struct</code>结构释放掉，以节省一些空间。但是<strong>使用<code>task_struct</code>结构更为方便，因为在内核中已经建立了从<code>pid</code>到<code>task_struct</code>查找关系，还有进程间的父子关系</strong>。释放掉<code>task_struct</code>，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。</p>
<p><strong>子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。</strong>
父进程可以通过 <code>wait</code>
系列的系统调用（如<code>wait4、waitid</code>）来等待某个或某些子进程的退出，并获取它的退出信息。然后<code>wait</code>系列的系统调用会顺便将子进程的尸体（<code>task_struct</code>）也释放掉。</p>
<p>但是<strong>如果他的父进程没调用<code>wait</code>或<code>waitpid()</code>等待子进程结束，那么它就一直保持僵尸状态，子进程的尸体（<code>task_struct</code>）也就无法释放掉。</strong></p>
<p><strong>如果这时父进程结束了，那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是为什么系统中有时会有很多的僵尸进程。</strong></p>
<p><strong>当进程退出的时候，会将它的所有子进程都托管给别的进程</strong>（使之成为别的进程的子进程）。托管的进程可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。</p>
<p><strong>1号进程，就是pid为1的进程，又称init进程</strong>。linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命：
1）<strong>执行系统初始化脚本，创建一系列的进程</strong>（它们都是init进程的子孙）；
2）<strong>在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作</strong></p>
<p><strong>init进程不会被暂停、也不会被杀死（这是由内核来保证的）</strong>。它在等待子进程退出的过程中处于<code>task_interruptible</code>状态，“收尸”过程中则处于<code>task_running</code>状态。</p>
<p><img
src="https://wulc.me/imgs/image_1b3sdbqevlfs1qdv217qog1acb1g.png" /></p>
<h5 id="父进程与子进程">父进程与子进程</h5>
<ul>
<li>进程<strong>只有一个父母</strong> ，在进程的
<code>task_struct</code>中的<code>parent</code>表示</li>
<li>进程可以有<strong>0个以上的子女</strong>，在进程的
<code>task_struct</code>中的<code>children</code>表示
比较有趣的一点是在windows 中并没有父子进程的概念。</li>
</ul>
<h5 id="进程的若干id">进程的若干ID</h5>
<ul>
<li><strong>pid</strong>：进程的ID,唯一标识一个进程,系统中可用的PID
是有限制的, 因此系统中进程的总数也是有限制的</li>
<li><strong>pgrp</strong>：进程的组id，进程</li>
<li><strong>uid</strong>：启动进程的用户id</li>
<li><strong>gid</strong>：启动进程的用户所在组的id</li>
<li><strong>euid，egid</strong>
：euid和egid又称为有效的uid和gid。出于系统安全的权限的考虑，运行程序时要检查euid和egid的合法性。通常，uid等于euid，gid等于egid。<strong>有时候，系统会赋予一般用户暂时拥有root的uid和gid(作为用户进程的euid和egid)，以便于进行运作。</strong>（特殊权限：suid，sgid）</li>
</ul>
<p>上面关于task_struct的组成所涉及到的只是很小一部分，更详细的内容可参考
<a
href="https://book.douban.com/subject/6097773/">linux进程描述符task_struct详解</a>和<a
href="http://alick.blog.51cto.com/10786574/1786269">task_struct结构体字段介绍--Linux中的PCB</a>。</p>
<h3 id="进程与线程">进程与线程</h3>
<h4 id="线程基本概念">线程基本概念</h4>
<p>按照教科书上的定义，进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，<strong>从进程演化出线程，最主要的目的就是更好的支持SMP以及减小（进程/线程）上下文切换开销。</strong></p>
<p><strong>一个进程至少需要一个线程作为它的指令执行体，进程管理着资源（比如cpu、内存、文件等等），而将线程分配到某个cpu上执行。一个进程可以拥有多个线程，此时，如果进程运行在SMP机器上，它就可以同时使用多个cpu来执行各个线程，达到最大程度的并行，以提高效率</strong>；同时，即使是在单cpu的机器上，采用多线程模型来设计程序，正如当年采用多进程模型代替单进程模型一样，使设计更简洁、功能更完备，程序的执行效率也更高，例如采用多个线程响应多个输入，而此时多线程模型所实现的功能实际上也可以用多进程模型来实现，而与后者相比，<strong>线程的上下文切换开销就比进程要小多了</strong>，从语义上来说，同时响应多个输入这样的功能，实际上就是共享了除cpu以外的所有资源的。</p>
<h4 id="线程与进程的比较">线程与进程的比较</h4>
<p><strong>1)
调度</strong>。在传统的操作系统中，拥有资源和独立调度的基本单位都是进程。在引入线程的操作系统中，线程是独立调度的基本单位，进程是资源拥有的基本单位。<strong>在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换,如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。</strong></p>
<p><strong>2)
系统开销</strong>。由于<strong>创建或撤销进程时，系统都要为之分配或回收资源</strong>，如内存空间、
I/O设备等，因此<strong>操作系统所付出的开销远大于创建或撤销线程时的开销</strong>。而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此，这些线程之间的同步与通信非常容易实现，甚至无需操作系统的干预。</p>
<p><strong>3)
地址空间和其他资源（如打开的文件）</strong>：进程的地址空间之间互相独立，同一进程的各线程间共享进程的资源（包括地址空间），某进程内的线程对于其他进程不可见。</p>
<p><strong>4) 通信方面</strong>： 进程间的通信方式有这样几种：</p>
<ul>
<li>共享内存</li>
<li>消息队列</li>
<li>有名管道</li>
<li>无名管道</li>
<li>信号</li>
<li>文件</li>
<li>socket</li>
</ul>
<p>线程间的通信方式上述进程间的方式都可沿用，且还有自己独特的几种</p>
<ul>
<li>互斥量</li>
<li>自旋锁</li>
<li>条件变量</li>
<li>读写锁</li>
<li>线程信号</li>
<li>全局变量</li>
</ul>
<h4 id="线程的实现方式">线程的实现方式</h4>
<p>线程的实现可以分为两类：用户级线程(<code>User-Level Thread, ULT</code>)和内核级线程(<code>Kemel-Level Thread,  KLT</code>)。<strong>前者更利于并发使用多处理器的资源，而后者则更多考虑的是上下文切换开销。</strong></p>
<p>在用户级线程中，有关<strong>线程管理的所有工作都由应用程序完成，内核意识不到线程的存在</strong>。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程起始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。下图(a)说明了用户级线程的实现方式。</p>
<p>在内核级线程中，<strong>线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口</strong>。内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成。下图(b)说明了内核级线程的实现方式。</p>
<p>在一些系统中，使用组合方式的多线程实现。线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些（小于或等于用户级线程的数目）内核级线程上。下图(c)说明了用户级与内核级的组合实现方式。</p>
<p><img
src="https://wulc.me/imgs/image_1b3tl18eari3e8j77e14fn14442a.png" /></p>
<h4 id="多线程模型">多线程模型</h4>
<p>有些系统<strong>同时支持用户线程和内核线程</strong>，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式，如上面的图实际上就包含了三种经典的多线程模型。</p>
<p><strong>1) 多对一模型</strong></p>
<p>将多个用户级线程映射到一个内核级线程，线程管理在用户空间完成。</p>
<p>此模式中，<strong>用户级线程对操作系统不可见</strong>（即透明）。</p>
<p>优点：线程管理是在用户空间进行的，因而效率比较高。</p>
<p>缺点：当<strong>一个线程在使用内核服务时被阻塞，那么整个进程都会被阻塞；多个线程不能并行地运行在多处理机</strong>上。</p>
<p><strong>2) 一对一模型</strong></p>
<p>将每个用户级线程映射到一个内核级线程。</p>
<p>优点：当<strong>一个线程被阻塞后，允许另一个线程继续执行，所以并发能力较强</strong>。</p>
<p>缺点：每创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。</p>
<p><strong>3) 多对多模型</strong></p>
<p>将 n 个用户级线程映射到 m 个内核级线程上，要求 m &lt;= n。</p>
<p>特点：在多对一模型和一对一模型中取了个折中，克服了多对一模型的并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程，开销太大的缺点。又拥有多对一模型和一对一模型各自的优点，可谓集两者之所长</p>
<p>需要注意的是<strong>在Linux
中，从内核的角度来说，它并没有线程这个概念，内核把所有的线程都当成进程来实现。在内核中，线程看起来就像是一个与其他进程共享了一些资源的普通进程，每一个线程有其唯一的<code>task_struct</code></strong>；</p>
<p>关于这个说法，可参考<a
href="http://mp.weixin.qq.com/s?__biz=MzA4MjA0MTc4NQ==&amp;mid=402087399&amp;idx=1&amp;sn=4cc1419e01df0142c1131b6843880087#rd">Linux线程的前世今生</a>
&gt;在 Linux
创建的初期，内核一直就没有实现“线程”这个东西。后来因为实际的需求，便逐步产生了<code>LinuxThreads</code>
这个项目，其主要的贡献者是Xavier
Leroy。<code>LinuxThreads</code>项目使用了 <code>clone()</code>
这个系统调用对线程进行了模拟，按照《Linux内核设计与实现》的说法，调用
<code>clone()</code> 函数参数是
<code>clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0)</code>，即<strong>创建一个新的进程，同时让父子进程共享地址空间、文件系统资源、文件描述符、信号处理程序以及被阻断的信号等内容</strong>。也就是说，此时的所谓“线程”模型符合以上两本经典巨著的描述，即在内核看来，<strong>没有所谓的“线程”，我们所谓的“线程”其实在内核看来不过是和其他进程共享了一些资源的进程罢了</strong>。</p>
<p>Linux 的内核线程</p>
<ul>
<li>内核线程是标准的进程，<strong>只存在于内核空间</strong></li>
<li>内核线程<strong>没有地址空间</strong></li>
<li>内核线程只能由其他内核线程创建</li>
</ul>
<h3 id="进程的创建和结束">进程的创建和结束</h3>
<h4 id="进程创建的两个步骤">进程创建的两个步骤</h4>
<p>进程的创建可以分为两个步骤： <strong>1)
fork</strong>:创建一个子进程即复制当前的任务，新进程与其父进程的区别仅在于<strong>PID,
PPID以及特定的资源(如某些资源的统计量，没有必要继承)</strong>。父子进程同时执行，因此调用一次返回两次。</p>
<p><strong>2)
exec</strong>：将一个程序装入地址空间并执行，只有子进程执行，重建其地址空间，区别于父进程。</p>
<p>fork
操作直接把所有资源复制给新创建的子进程，这种实现大批量的复制无疑或导致执行效率低下，因为行为是非常耗时的，因为它需要：</p>
<ul>
<li>为子进程的页表分配页面</li>
<li>为子进程的页分配页面</li>
<li>初始化子进程的页表</li>
<li>把父进程的页复制到子进程相应的页中</li>
</ul>
<p>创建一个地址空间的这种方法涉及许多内存访问，消耗许多CPU周期，并且完全破坏了高速缓存中的内容。<strong>在大多数情况下，这样做常常是毫无意义的，因为许多子进程通过装入一个新的程序开始它们的执行，这样就完全丢弃了所继承的地址空间。</strong>所以
linux
采用了<strong>写时复制(<code>copy-on-write</code>)</strong>的策略。</p>
<p>写时拷贝是一种可以推迟甚至免除拷贝数据的技术。<strong>内核此时并不复制整个进程地址空间，而是让父进程和子进程共享同一个拷贝。只有在需要写入的时候，数据才会被复制，从而使各个进程拥有各自的拷贝。</strong>也就是说，资源的复制只有在需要写入的时候才进行，在此之前，只是以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候。在页根本不会被写入的情况下—举例来说，fork()后立即调用exec()—它们就无需复制了。<strong>fork()的实际开销就是复制父进程的页表以及给子进程创建惟一的进程描述符。</strong></p>
<p>实现的时候 <code>fork</code>
通过<code>clone()</code>系统调用实现，<code>clone()</code>通过一系列的参数标志指定父子进程需要共享的资源，<code>clone()</code>调用<code>do_fork()</code>,而<code>do_fork()</code>调用<code>copy_process()</code>,而<code>copy_process()</code>做了以下事情：</p>
<ul>
<li>调用<code>dup_task_struct</code>复制内核栈、<code>thread_info</code>和<code>task_struct</code></li>
<li>检查用户进程限额</li>
<li>改变子进程<code>task_struct</code>结构中的部分内容，子进程状态置为<code>TASK_UNINTERRUPTIBLE</code></li>
<li>为子进程获取一个有效的<code>PID</code></li>
<li>根据传递给<code>clone()</code>的参数复制资源</li>
<li>父子进程平分剩余的时间片</li>
<li>返回指向子进程的指针</li>
</ul>
<p>除了 <code>fork</code> 以外，linux中还有一种创建进程的方式
<code>vfork</code>，<code>vfork</code>与<code>fork</code>功能相同，<strong>子进程共享父进程的地址空间(内核连子进程的虚拟地址空间结构也不创建)。创建完成后父进程阻塞，直到子进程结束或执行<code>exec</code></strong>。<code>vfork</code>
也是通过向<code>clone</code>系统调用传递特定的标志实现。</p>
<h4 id="进程的结束">进程的结束</h4>
<p>以下几种情况会出现进程的结束：
1）正常结束(显示或隐式地调用<code>exit()</code>系统调用）
2）进程收到不能忽略也不能处理的信号或异常</p>
<p>执行<code>exit()</code>函数的过程：</p>
<ul>
<li>释放进程的<strong>地址空间</strong></li>
<li>释放进程<strong>使用的资源</strong></li>
<li>给其父进程发送一个信号，并标示自己的状态为<code>TASK_ZOMBIE</code></li>
<li>调用调度程序，执行其他进程</li>
</ul>
<p>当父进程收到子进程结束信号时，收回子进程的
<code>task_structure</code>和<code>thread_info</code>,没有回收就称为了僵尸进程。</p>
<h3 id="信号">信号</h3>
<h4 id="基本概念">基本概念</h4>
<p>信号机制是<strong>进程之间相互传递消息的一种方法</strong>，信号全称为<strong>软中断信号</strong>，也有人称作软中断。<strong>在linux中每个信号有一个名字(以<code>SIG</code>开头)，且定义为一个整数，共有64个信号</strong>。</p>
<p>软中断信号（signal，又简称为信号）用来<strong>通知进程发生了异步事件</strong>。进程之间可以互相通过系统调用<code>kill</code>发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。注意，<strong>信号只是用来通知某进程发生了什么事件，并不给该进程传递任何数据。</strong></p>
<p>信号来源分为硬件类和软件类：</p>
<ul>
<li><strong>硬件方式</strong>
<ul>
<li>用户输入：比如在终端上按下组合键ctrl+C，产生SIGINT信号；</li>
<li>硬件异常：CPU检测到内存非法访问等异常，通知内核生成相应信号，并发送给发生事件的进程；</li>
</ul></li>
<li><strong>软件方式</strong>
通过系统调用，发送signal信号：kill()，raise()，sigqueue()，alarm()，setitimer()，abort()等</li>
</ul>
<p><strong>收到信号的进程对各种信号有不同的处理方法。处理方法可以分为三类</strong>：
1）类似中断的处理程序，对于需要处理的信号，进程可以<strong>指定处理函数</strong>，由该函数来处理。
2）<strong>忽略某个信号</strong>，对该信号不做任何处理，就象未发生过一样。但是有些信号是不能忽略的，如<code>SIGKILL</code>、<code>SIGSTOP</code>和一些硬件异常信号
3）对该信号的处理<strong>保留系统的默认值</strong>，这种缺省操作，<strong>对大部分的信号的缺省操作是使得进程终止</strong>。</p>
<h4 id="相关的系统调用">相关的系统调用</h4>
<p>上面的第一种处理方式是通过系统调用<code>signal</code>来指定进程对某个信号的处理行为。signal函数的定义如下
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;signal.h&gt;</span><br><span class="line">typedef void (*sighandler_t)(int);</span><br><span class="line">sighandler_t signal(int signum, sighandler_t handler);</span><br><span class="line">(返回值: 如果成功则返回先前的handler，否则返回SIG_ERR)</span><br><span class="line"></span><br><span class="line">“handler”可取下面的三个值中任意一个：</span><br><span class="line">用户定义的函数，或</span><br><span class="line">SIG_DEF(恢复参数signum所指信号的处理方法为默认值),或</span><br><span class="line">SIG_IGN(忽略参数signum所指的信号)</span><br></pre></td></tr></table></figure></p>
<p>通过<code>kill()</code>系统调用可以给进程发送一个信号，kill函数的声明如下
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line">#include &lt;signal.h&gt;</span><br><span class="line">int kill(pid_t pid, int sig);</span><br><span class="line">(返回值: 成功为0, 否则为-1)</span><br></pre></td></tr></table></figure></p>
<p>而<code>raise()</code>系统调用可以说是<code>kill()</code>系统调用的一个特例，用于给当前进程发送一个信号，其定义如下：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;signal.h&gt;</span><br><span class="line">int raise(int sig);</span><br><span class="line">  (返回值: 成功为0, 否则为-1)</span><br></pre></td></tr></table></figure></p>
<p>除此之外，系统调用<code>alarm()</code>的功能是<strong>设置一个定时器，当定时器计时到达时，将发出一个信号<code>SIGALRM</code>给进程</strong>。该调用的声明格式如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">unsigned int alarm(unsigned int seconds);</span><br><span class="line">(Returned value: 0, or the number of seconds remaining of previous alarm)</span><br></pre></td></tr></table></figure>
<p>而系统调用<code>pause</code>的作用是等待一个信号。该调用使得发出调用的进程进入睡眠，直到接收到一个信号为止。该调用的声明格式如下：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int pause(void); </span><br></pre></td></tr></table></figure></p>
<p>利用 <code>alarm</code> 函数和 <code>pause</code> 函数实现
<code>sleep</code>,同时可参考<a
href="http://www.judymax.com/archives/235">这里</a> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">unsigned int sleep1(unsigned int nsecs) &#123;</span><br><span class="line">    if ( signal(SIGALRM, sig_alrm) == SIG_ERR)</span><br><span class="line">        return(nsecs);</span><br><span class="line">    alarm(nsecs);     /* 开始计时 */  </span><br><span class="line">    pause();      /*定时信号来时被唤醒*/</span><br><span class="line">    return(alarm(0) ); /*关闭定时器 */</span><br><span class="line">&#125;</span><br><span class="line">int sig_alrm() &#123;</span><br><span class="line">   signal(SIGALRM, sig_alrm) ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="可靠的信号机制">可靠的信号机制</h4>
<p>Linux系统共定义了64种信号，分为两大类：可靠信号与不可靠信号</p>
<ul>
<li>不可靠信号：
也称为<strong>非实时信号，不支持排队，信号可能会丢失,</strong>
比如发送多次相同的信号, 进程只能收到一次. 信号值取值区间为1~31；</li>
<li>可靠信号： 也称为<strong>实时信号，支持排队, 信号不会丢失</strong>,
发多少次, 就可以收到多少次. 信号值取值区间为32~64</li>
</ul>
<h5 id="信号的注册与注销">信号的注册与注销</h5>
<ul>
<li><strong>注册</strong></li>
</ul>
<p>在进程<strong>task_struct</strong>结构体中有一个未决信号的成员变量
struct sigpending
pending。<strong>每个信号在进程中注册都会把信号值加入到进程的未决信号集。</strong></p>
<p>非实时信号发送给进程时，如果该信息已经在进程中注册过，不会再次注册，故信号会丢失；
实时信号发送给进程时，不管该信号是否在进程中注册过，都会再次注册。故信号不会丢失；</p>
<ul>
<li><strong>注销</strong></li>
</ul>
<p>非实时信号：不可重复注册，最多只有一个sigqueue结构；当该结构被释放后，把该信号从进程未决信号集中删除，则信号注销完毕；
实时信号：可重复注册，可能存在多个sigqueue结构；当该信号的所有sigqueue处理完毕后，把该信号从进程未决信号集中删除，则信号注销完毕；</p>
<h5 id="信号的处理">信号的处理</h5>
<p>内核处理进程收到的signal是在当前进程的上下文，故进程必须是Running状态。当进程唤醒或者调度后获取CPU，则会<strong>从内核态转到用户态时检测是否有signal等待处理</strong>，处理完，进程会把相应的未决信号从链表中去掉。</p>
<p>也就是说signal信号处理时机为：
<code>内核态 -&gt; signal信号处理 -&gt; 用户态</code>：</p>
<ul>
<li>在内核态，signal信号不起作用；</li>
<li>在用户态，signal所有未被屏蔽的信号都处理完毕；</li>
<li>当屏蔽信号，取消屏蔽时，会在下一次内核转用户态的过程中执行；</li>
</ul>
<h5 id="信号相关函数">信号相关函数</h5>
<p>进程<strong>处理某个信号前，需要先在进程中安装此信号</strong>。安装过程主要是建立信号值和进程对相应信息值的动作。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">信号安装函数</span><br><span class="line">signal()：不支持信号传递信息，主要用于非实时信号安装；</span><br><span class="line">sigaction():支持信号传递信息，可用于所有信号安装；（通过sigaction实现signal函数）</span><br></pre></td></tr></table></figure>
<p>信号的发送系统调用 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kill()：用于向进程或进程组发送信号；</span><br><span class="line">sigqueue()：只能向一个进程发送信号，不能像进程组发送信号；主要针对实时信号提出，与sigaction()组合使用，当然也支持非实时信号的发送；</span><br><span class="line">alarm()：用于调用进程指定时间后发出SIGALARM信号；</span><br><span class="line">setitimer()：设置定时器，计时达到后给进程发送SIGALRM信号，功能比alarm更强大</span><br><span class="line">abort()：向进程发送SIGABORT信号，默认进程会异常退出。</span><br><span class="line">raise()：用于向进程自身发送信号；</span><br></pre></td></tr></table></figure></p>
<p>信号阻塞函数： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sigprocmask(int how, const sigset_t *set, sigset_t *oldset))：检测或更改(或两者)进程的信号掩码</span><br><span class="line">不同how参数，实现不同功能</span><br><span class="line">SIG_BLOCK：将set中的信号添加到进程阻塞信号集（并集）</span><br><span class="line">SIG_UNBLOCK：从进程阻塞信号集删除set中的信号(差集)</span><br><span class="line">SIG_SETMASK：将set指向信号集中的信号，设置成进程阻塞信号集</span><br><span class="line"></span><br><span class="line">sigpending(sigset_t *set))：获取已发送到进程，却被阻塞的所有信号，也就是当前未决的信号集</span><br><span class="line"></span><br><span class="line">sigsuspend(const sigset_t *mask))：用mask代替进程的原有掩码，并暂停进程执行，直到收到信号再恢复原有掩码并继续执行进程。（pause)</span><br></pre></td></tr></table></figure></p>
<h2 id="第四章-进程调度">第四章 进程调度</h2>
<p>调度器用于选择进程运行，分配CPU执行时间</p>
<h3 id="调度器运行的时机">调度器运行的时机</h3>
<ul>
<li>进程阻塞在一个I/O操作上.</li>
<li>硬件中断.</li>
<li>进程时间片到.</li>
<li>内核主动调用调度器</li>
</ul>
<h3 id="调度目标">调度目标</h3>
<ul>
<li>有效性：完成尽可能多的工作。</li>
<li>交互性：尽快响应用户</li>
<li>公平性：不允许任何进程饥饿。</li>
</ul>
<p>哪一个目标最重要取决于取决于目标场景</p>
<ul>
<li>桌面系统:交互性，尽快相应用户</li>
<li>服务器:有效性，保证每个用户的请求都能够被完成</li>
</ul>
<h3 id="调度策略">调度策略</h3>
<h4 id="进程的类型">进程的类型</h4>
<ul>
<li><p>I/O密集型进程:
<strong>较多的交互性，高优先级，大时间片</strong>。如文本编辑</p></li>
<li><p>CPU密集型进程:
<strong>较少的交互性，低优先级，较小的时间片</strong>。如视频解码</p></li>
</ul>
<h4 id="进程优先级表示">进程优先级表示</h4>
<p>在linux中用top或者ps命令会输出PRI/PR、NI这两个指标值，其含义如下</p>
<blockquote>
<p>PRI
：进程优先权，代表这个进程可被执行的优先级，<strong>其值越小，优先级就越高</strong>，越早被执行
NI
：进程Nice值，可用于改变PRI的值，<code>PRI(new)=PRI(old)+nice</code>。</p>
</blockquote>
<p>在Linux系统中，Nice值的范围从-20到+19（不同系统的值范围是不一样的），每个进程都在其计划执行时被赋予一个nice值。在通常情况下，子进程会继承父进程的nice值，比如在系统启动的过程中，init进程会被赋予0，其他所有进程继承了这个nice值（因为其他进程都是init的子进程）。</p>
<p>进程的nice值是可以被修改的，修改命令分别是<code>nice</code>和<code>renice</code>,
对<strong>非 root 用户，只能将其底下的进程的 nice
值变大而不能变小</strong>,若想变小，得要有相应的权限。对root用户，可以给其子进程赋予更小的nice值。</p>
<p>进程抢占的时机</p>
<ul>
<li>当一个进程的优先级高于当前正在运行的进程的优先级</li>
<li>当一个进程的时间片为0.</li>
</ul>
<h4 id="调度器">调度器</h4>
<p>内核2.4是O(n)调度器，2.5及后改成了O(1)调度器，采用的新的数据结构为<strong>运行队列和优先级数组</strong>，同时改善了<strong>SMP的可拓展性</strong>。</p>
<p>两种数据结构的解释如下 <strong>运行队列(<code>struct runqueue</code>
)</strong>：给定处理器上可执行进程的链表，运行队列进行操作前要先锁住。
<strong>优先级数组</strong>：Linux
调度器维护两个优先级数组：<strong>活跃的和过期</strong>的数组。优先级数组是提供
<code>O(1)</code> 调度的数据结构</p>
<p>优先级数组是一个结构体，其定义如下所示： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct prio_array &#123; </span><br><span class="line">  int nr_active; /* 任务数目*/ </span><br><span class="line">  unsigned long bitmap[BITMAP_SIZE]; /* 优先级位图*/ </span><br><span class="line">  struct list_head queue[MAX_PRIO]; /* 优先级队列*/ </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p><strong>调度器为每一个CPU维护了两个进程队列数组：active数组和expire数组。数组中的元素着保存某一优先级的进程队列指针。系统一共有140个不同的优先级，因此这两个数组大小都是140。同时该调度算法为每个优先级都设置一个可运行队列,
即包含140个可运行状态的进程链表，每一条优先级链表上的进程都具有相同的优先级，而不同进程链表上的进程都拥有不同的优先级。</strong></p>
<p>除此之外,
每个优先级数组还包括一个优先级位图bitmap。该位图使用一个位(bit)来代表一个优先级，而140个优先级最少需要5个32位来表示，
因此只需要一个<code>int[5]</code>就可以表示位图，该位图中的所有位都被置0，当某个优先级的进程处于可运行状态时，该优先级所对应的位就被置1。</p>
<p>优先级数组中分为了活跃和过期两种，过期的优先级数组存放<strong>过期队列</strong>，活跃的优先级数组存放<strong>实际队列</strong>。</p>
<p>过期队列是所有用完了时间片的进程。 实际队列是没有用完时间片的进程。
当一个进程用完了时间片时，<strong>重新计算其时间片</strong>，并放入到过期队列中。
当实际进程队列为空时，交换过期队列和实际队列。</p>
<p><img
src="https://wulc.me/imgs/image_1b4071g0o1vf1a801ouoi451hel3h.png" /></p>
<p>重新计算时间片过程</p>
<ul>
<li><p><strong>动态优先级用于计算优先级</strong>
<code>nice+进程交互性的奖励或罚分</code> 为了确定一个进程是否是交互性的,
Linux记录了一个进程用于休眠和用于执行的时间（0-MAX_SLEEP_AVG，默认10ms）。一个进程从休眠恢复到执行时，优先级增加；运行一段时间后会减小。</p></li>
<li><p><strong>静态优先级用于计算时间片</strong>
进程创建时，子进程与父进程均分父进程剩余的时间片.
任务的时间片用完时，基于任务的静态优先级重新计算时间片</p></li>
</ul>
<p>负载平衡程序 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">找最繁忙的运行队列</span><br><span class="line">选择一个优先级数组（过期的优先）</span><br><span class="line">选择优先级最高的链表</span><br><span class="line">选择一个不是正在运行的，不在高速缓冲的，可移动的进程抽取</span><br><span class="line">重复上述步骤，直至平衡</span><br></pre></td></tr></table></figure></p>
<p>抢占可分为<strong>用户抢占和内核抢占</strong>： 用户抢占发生在</p>
<ul>
<li>从系统调用返回用户态</li>
<li>从中断服务程序返回用户态</li>
</ul>
<p>内核抢占发生在</p>
<ul>
<li>中断服务程序正在执行，且返回内核空间之前</li>
<li>内核代码再一次具有可抢占性时 处于核心态的任务直接调用schedule()</li>
<li>内核中的任务阻塞</li>
</ul>
<p>实时调度策略
<code>SCHED_FIFO</code>:先入先出方式调度的实时进程，即该进程一旦执行便一直运行到结束。
<code>SCHED_RR</code>:
通过时间片轮转的方式调度的实时进程。在运行了指定的时间片后会被抢占并重新调度。但如果没有其他优先级高于或等于它的实时进程与其竞争，它还会得到继续运行的机会。</p>
<h2 id="第五章-系统调用">第五章 系统调用</h2>
<h3 id="基本概念-1">基本概念</h3>
<p>系统调用为用户空间进程提供一个访问内核接口，在Linux中，系统调用是唯一合法访问内核的入口。</p>
<p>系统调用的目的主要有两个： 1）为用户空间提供一个统一接口。
2）保证系统的安全和稳定</p>
<h3 id="apiposixc库">API、POSIX、C库</h3>
<p>API/POSIX/C库的区别与联系</p>
<p><strong>一般情况下应用程序通过应用编程接口API，而不是直接通过系统调用来编程。在Unix世界，最流行的API是基于POSIX标准的,即POSIX说明API和系统调用之间关系，。</strong></p>
<blockquote>
<p>api是函数的定义，规定了这个函数的功能，跟内核无直接关系。它们<strong>可以实现成一个系统调用，也可以通过调用多个系统调用来实现，而完全不使用任何系统调用也不存在问题</strong>。实际上，API可以在各种不同的操作系统上实现，给应用程序提供完全相同的接口，而它们本身在这些系统上的实现却可能迥异。</p>
</blockquote>
<p>Linux的系统调用接口,像大多数Unix系统一样，以C 库的形式提供，C库实现了
Unix系统的主要API，包括标准C库函数和系统调用。</p>
<p><img
src="https://wulc.me/imgs/image_1b41abhsb1rv1t8922r1f436o39.png" /></p>
<h3 id="系统调用的实现">系统调用的实现</h3>
<p>在Linux中, 每一个系统调用分配有一个<code>syscall</code>
号.这是一个唯一的整数，用于指定系统调用.
<code>syscall</code>号分配后，不能够改变或回收.</p>
<p>一般地，系统调用都是通过<strong>软中断</strong>实现：产生一个<strong>异常</strong>，系统切换到内核模式，执行异常处理程序，即<strong>系统调用处理程序</strong>，在x86上，定义的软中断是函数<code>system_call()</code>。</p>
<p><code>system_call()</code>函数检查系统调用号<code>syscall</code>，如合法，调用指定的系统调用。</p>
<p><img
src="https://wulc.me/imgs/image_1b41b355s1phf5gu1t1nhh5118lm.png" /></p>
<p><strong>增加一个系统调用的过程</strong> 1.
首先在系统调用表的最后加入一个表项。 2.
对于每一种支持的体系结构，系统调用号必须定义在
<code>&lt;asm/unistd.h&gt;</code>. 3. 系统调用必须被编译进内核映像。</p>
<p><strong>实现一个新的系统调用的好处</strong>：
1）系统调用容易使用容易实现。 2）系统调用的性能在Linux中非常快。
<strong>缺点</strong>: 1）系统调用号需要官方授权给你。
2）系统调用一旦进入稳定的内核，其接口就不能再改变，否则会影响用户空间的应用.
3）需要<strong>将系统调用分别注册到每个需要支持的体系结构</strong>。
4）系统调用在脚本中不宜使用，不能直接从文件系统访问。
5）如果仅仅进行简单的信息交换，系统调用就大材小用</p>
<p><strong>从用户空间访问系统调用：Linux
提供了一组宏，用于直接访问系统调用</strong>。它设置寄存器内容，并执行<code>trap</code>指令。这些宏是
<code>_syscalln()</code>, 这里n：0-6。</p>
<h2 id="第六章-内核数据结构">第六章 内核数据结构</h2>
<ul>
<li>链表</li>
<li>队列</li>
<li>映射</li>
<li>红黑树</li>
</ul>
<p>映射是键到值的关联关系。Linux中的映射是将一个唯一的标识符（UID）映射到一个指针，实现方式有：</p>
<ul>
<li>数组</li>
<li>散列表</li>
<li>自平衡二叉树</li>
<li>Linux采用的方式：radix树（）</li>
</ul>
<p><strong>数据结构的选择原则如下</strong>：</p>
<ul>
<li>链表：主要操作是遍历数据</li>
<li>队列：生产者消费者模式</li>
<li>映射：映射一个UID到一个对象</li>
<li>红黑树：存储大量数据，并且迅速检索</li>
</ul>
<p><strong>红黑树是一种自平衡二叉搜索树</strong>，具有以下性质：</p>
<ul>
<li>所有的节点或者红色，或者黑色</li>
<li>所有叶节点都是黑色</li>
<li>叶节点不包含数据</li>
<li>所有非叶节点都有两个字节点</li>
<li>如果一个节点是红色，则其子节点都是黑色</li>
<li>在一个节点到其叶子节点的路径中，如果总是包含同样数目的黑色节点，则该路径相比其他路径是最短的</li>
</ul>
<h2 id="第七八章-中断和中断处理">第七、八章 中断和中断处理</h2>
<h3 id="基本概念-2">基本概念</h3>
<p>操作系统要管理硬件，就必须要能够与硬件通信。中断能够使硬件能够发出通知给处理器(CPU)，例如按下键盘时，键盘控制器就会发出一个中断请求；处理器(CPU)接收到中断请求后，会马上通知内核进行处理，因此硬件设备生成中断时并不会考虑与处理器的时钟同步，也就是说中断可以随时产生。</p>
<p><strong>不同情况下对应的中断不同，每个中断都有一个唯一的数字标示，通常被称为中断号（IRQ）</strong>，如键盘和硬盘的中断号就不同。中断号的不同，内核处理的程序也不同，因此有一张表格用于记录每个中断号及其对应的处理程序，称为<strong>中断向量表</strong>。</p>
<p>说到中断，常常会提及到异常。<strong>异常与中断不同，异常产生的时候必须考虑与处理器的时钟同步</strong>。实际上异常也常被称为同步中断。常见的异常有处理器执行过程中由于代码的缺陷而执行了错误指令（如除上0），或者是在执行期间出现了特殊情况（如缺页），必须依靠内核来处理的时候，处理器就会产生一个异常。前面说到的系统调用实际上就是通过异常来实现的，异常也可称为软中断。</p>
<h3 id="中断处理程序">中断处理程序</h3>
<p>由前面的简介可知，响应一个特定的中断，内核会执行一个与之对应的特定函数，这个函数就叫做<strong>中断处理程序</strong>。</p>
<p>在Linux中，一个设备的中断处理程序是它设备驱动程序（管理设备的内核代码）的一部分，因此，中断处理程序实际上就是普通的C函数，与其他内核函数的真正区别在于这些程序运行于被称为<strong>中断上下文</strong>的特殊上下文中，该上下文不可被阻塞，也就是说进入中断服务程序后,
不会被其他响应中断。</p>
<h3 id="上半部和下半部">上半部和下半部</h3>
<p>中断要求尽快处理，但是往往中断又要完成较多的工作量。考虑两者间做一个权衡，中断处理被分成了两个部分：<strong>上半部和下半部，上半部完成那些重要、有严格时限的、与硬件相关的工作，下半部则完成那些允许被稍后完成的工作</strong>。接收到一个中断后，上半部（实际上就是中断处理程序）会立即执行，然后返回中断前原先运行的程序，而下半部会在合适的时机在执行（通常下半部分在中断处理程序一返回就会马上运行）。中断处理程序的下半部分（如果有的话）几乎做了中断处理程序所有的事情。<strong>它们最大的不同是上半部分不可中断，而下半部分可中断。</strong>下面以网卡为例做简单说明：</p>
<p>当网卡接收到来自网络的数据包的时候，网卡会向内核发出中断，内核通过网卡已注册的中断处理程序来做出应答，中断开始的时候，内核会快速拷贝网络数据包到系统内存，因为网卡上接收的网络数据包的缓存是固定的，而且相比于内存来说很小，假如数据包占满了缓存，后续的数据包只能被丢弃，所以这个任务是最紧急的，当网络数据包全被拷到内存后，中断任务算是完成了，这个它会将控制权返回给系统中断前原先运行的程序。至于处理数据包的操作会在下半部进行。</p>
<p>尽管上半部和下半部的结合能够改善系统的响应能力，但是，Linux设备驱动中的中断处理并不一定要分成两个半部。如果中断要处理的工作本身就很少，则完全可以直接在上半部全部完成。</p>
<h3 id="上半部">上半部</h3>
<h4 id="注册与释放中断程序">注册与释放中断程序</h4>
<p>对于设备的每一种中断，设备的驱动程序需要为其注册一个相关的中断处理程序，以便通知内核该如何处理该中断。</p>
<p>驱动程序通过<code>request_irq()</code>函数注册一个中断处理程序。</p>
<p>卸载驱动程序的时候，需要注销相应的中断处理程序，并释放中断线（设备的中断处理器与CPU的直连线），通过调用<code>free_irq()</code>
实现</p>
<h4 id="编写中断处理程序">编写中断处理程序</h4>
<p>典型的定义 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static irqreturn_t intr_handler (int irq, void *dev_id, struct pt_regs *regs)</span><br><span class="line"></span><br><span class="line">irq: 中断号</span><br><span class="line">dev_id: 区分共享中断线的多个设备</span><br><span class="line">regs: 保存中断前的处理器的寄存器和状态</span><br><span class="line">irqreturn_t：IRQ_NONE, IRQ_HANDLED</span><br></pre></td></tr></table></figure>
Linux中的中断处理程序都是<strong>无须重入</strong>的，也就是说一个给定的中断处理程序正在执行的时候，<strong>相应的中断线在所有的处理器上都会被屏蔽，以防止在同一中断线上接收另外一个新的中断，</strong>但是其他的中断线上的中断能够被处理。</p>
<h4 id="中断上下文">中断上下文</h4>
<p>在讨论中断上下文之前先讨论一下进程上下文。</p>
<p>用户空间的应用程序，通过系统调用，进入内核空间。这个时候用户空间的进程要传递
很多变量、参数的值给内核，内核态运行的时候也要保存用户进程的一些寄存
器值、变量等。<strong>所谓的“进程上下文”，可以看作是用户进程传递给内核的这些参数以及内核要保存的那一整套的变量和寄存器值和当时的环境等。</strong></p>
<p>相对于进程而言，就是进程执行时的环境。具体来说就是各个变量和数据，包括所有的寄存器变量、进程打开的文件、内存信息等。<strong>一个进程的上下文可以分为三个部分:用户级上下文、寄存器上下文以及系统级上下文。</strong></p>
<p>（1）用户级上下文: 正文、数据、用户堆栈以及共享存储区；
（2）寄存器上下文:
通用寄存器、程序寄存器(IP)、处理器状态寄存器(EFLAGS)、栈指针(ESP)；
（3）系统级上下文:
进程控制块<code>task_struct</code>、内存管理信息(<code>mm_struct</code>、<code>vm_area_struct</code>、<code>pgd</code>、<code>pte</code>)、内核栈。</p>
<p>当<strong>发生进程调度时，进行进程切换就是上下文切换(context
switch)</strong>.操作系统必须对上面提到的全部信息进行切换，新调度的进程才能运行。</p>
<p>而对于中断上下文而言，硬件通过触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的
一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。所谓的“
<strong>中断上下文”，其实也可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被打断执行的进程环境）</strong>。中断时，内核<em>不代表任何进程运行</em>，它一般只访问系统空间，而不会访问进程空间，内核在中断上下文中执行时一般不会阻塞。</p>
<p><strong>Linux
内核工作在进程上下文或者中断上下文。提供系统调用服务的内核代码代表发起系统调用的应用程序运行在进程上下文；另一方面，中断处理程序则代表硬件运行在中断上下文。中断上下文和特定进程无关。</strong></p>
<p>运行在<strong>进程上下文的内核代码是可以被抢占的</strong>（Linux2.6）。但是一个<strong>中断上下文，通常都会始终占有CPU，不可以被打断</strong>。正因为如此，运行在中断上下文的代码就要受一些限制，不能做下面的事情：
<strong>1、睡眠或者放弃CPU</strong>：这样做的后果是灾难性的，因为内核在进入中断之前会关闭进程调度，一旦睡眠或者放弃CPU，这时内核无法调度别的进程来执行，系统就会死掉。除此之外，在中断处理函数中调用一个内核API之前，应该仔细分析它以确保其内部不会触发阻塞等待。
<strong>2、尝试获得信号量</strong>：如果获得不到信号量，代码就会睡眠，会产生和上面相同的情况
<strong>3、执行耗时的任务</strong>：中断处理应该尽可能快，因为内核要响应大量服务和请求，中断上下文占用CPU时间太长会严重影响系统功能。
<strong>4、访问用户空间的虚拟地址</strong>：因为中断上下文是和特定进程无关的，它是内核代表硬件运行在内核空间，所以在终端上下文无法访问用户空间的虚拟地址</p>
<h4 id="中断处理的实现">中断处理的实现</h4>
<p>中断处理系统在linux中的实现是非常依赖于体系结构的，例如要依赖于处理器，所使用的的中断控制器的类型，体系结构的设计及机器本身。</p>
<p>下图是中断从硬件到内核进行处理的一个流程</p>
<p><img
src="https://wulc.me/imgs/image_1b438je76f681l1n146882itog9.png" /></p>
<h3 id="下半部">下半部</h3>
<p>下半部的任务主要是执行与中断相关的工作，这些工作没有被中断服务程序本身完成.
下半部分并不需要指明一个确切时间，只要把这些任务推迟一点，让它们在系统不太忙并且中断恢复后执行就可以了。通常下半部分在中断处理程序一返回就会马上运行。内核中实现下半部的手段不断演化，目前已经从最原始的BH（bottom
half）衍生出BH（在2.5中去除）、软中断（<code>softirqs</code>在2.3引入）、<code>tasklet</code>（在2.3引入）、工作队列（<code>work queue</code>在2.5引入）。</p>
<h4 id="softirqs机制">softirqs机制</h4>
<p>软中断结构定义如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct softirq_action &#123;</span><br><span class="line">               void (*sction) (struct softirq_action *);/*待执行的函数*/</span><br><span class="line">               void *data;  /*传给函数的指针*/</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<code>kernel/softirq.c</code>定义了一个32个元素的结构数组,
每个被注册的软中断都占据该数组的一项，因此最多可能有32个软中断，且下标小的软中断优先级高。</p>
<p>中断处理程序在返回前触发它的软中断，使其在稍后执行。在执行过程中，一个软中断不会抢占另外一个软中断，唯一可以抢占软中断的是中断处理程序。执行就是遍历上面提到的结构数组，并处理那些有软中断的位置（值为1）。</p>
<p>软中断保留给对<strong>时间要求最严格和最重要的下半部使用</strong>，如网络和SCSI设备。使用软中断的过程大致为<code>分配索引号-&gt;注册处理程序-&gt;触发软中断</code></p>
<h4 id="tasklet机制">tasklet机制</h4>
<p>tasklet
是基于软中断实现的，与软中断相比，tasklet更常用，<strong>软中断一般用于那些执行频率很高和连续型要求很高的情况</strong>。</p>
<p>引入tasklet，最主要的是考虑支持SMP，提高SMP多个cpu的利用率；不同的tasklet可以在不同的cpu上运行。tasklet可以理解为softirq的派生，所以它的调度时机和软中断一样。</p>
<p>每个处理器都有一个用于辅助处理软中断的内核线程:<code>ksoftirqd/n</code>,当内核中出现大量软中断的时候，这些内核线程就会辅助处理他们。<strong>这个内核线程是对于重新触发的软中断是否立即处理的问题的一个折中</strong>，最终是不会立即处理这些重新触发的软中断，而是添加这样一个线程使得在软中断数目过多时也能够被迅速处理。</p>
<h4 id="work-queue-机制">work queue 机制</h4>
<p>工作队列可以把工作推后，然后交给一个内核线程去执行，这些内核线程被称为<strong>工作线程</strong>。工作队列一个很重要的特性就是<strong>允许工作重新调度和睡眠</strong>。</p>
<h4 id="选择何种机制">选择何种机制</h4>
<p>从设计上讲，Softirq提供最少的顺序保证，这需要Softirq处理函数采取一些额外的步骤保证数据安全，因为两个以上的同类型softirqs只能同时运行于不同的CPU。<strong>Softirq多用于时间要求严格和使用频度高的场合</strong>。</p>
<p>如果代码不能很好地线程化，tasklet意义较大 Tasklets
有一个简单的接口，由于两个同类型的不能同时运行，他们非常易于实现。</p>
<p>如果你的延期的工作需要运行于进程上下文（重新调度和睡眠）,
唯一的选择是work queue</p>
<h2 id="第九十章-内核同步">第九、十章 内核同步</h2>
<h3 id="基本概念-3">基本概念</h3>
<p>在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核也需要一些同步机制来<strong>同步各执行单元对共享数据的访问</strong>。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。</p>
<p><strong>临界区和竞争条件</strong>
临界区：访问和操作共享数据的代码段。
竞争条件：多个执行线程处于同一个临界区中。</p>
<p>同步就是保证不安全的并发不发生，即竞争条件不发生。需要同步的情况有：</p>
<ul>
<li>中断</li>
<li>Softirqs和tasklets</li>
<li>内核抢占</li>
<li>用户空间的睡眠和同步</li>
<li>SMP</li>
</ul>
<h4 id="死锁的产生条件">死锁的产生条件</h4>
<p>1.互斥(mutual exclusion)：系统存在着临界资源； 2.占有并等待(hold and
wait)：已经得到某些资源的进程还可以申请其他新资源； 3.不可剥夺(no
preemption)：已经分配的资源在其宿主没有释放之前不允许被剥夺；
4.循环等待(circular
waiting)：系统中存在多个（大于2个）进程形成的封闭的进程链，链中的每个进程都在等待它的下一个进程所占有的资源；</p>
<h4 id="死锁预防与死锁避免">死锁预防与死锁避免</h4>
<p><strong>死锁预防</strong>
防止死锁的发生只需破坏死锁产生的四个必要条件之一即可 <strong>1)
破坏互斥条件</strong></p>
<p><strong>如果允许系统资源都能共享使用，则系统不会进入死锁状态</strong>。但有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，<strong>破坏互斥条件而预防死锁的方法不太可行，而且在有的场合应该保护这种互斥性</strong>。
<strong>2) 破坏不剥夺条件</strong></p>
<p>当<strong>一个已保持了某些不可剥夺资源的进程，请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请</strong>。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺了，或从而破坏了不可剥夺条件。</p>
<p>该策略实现起来比较复杂，<strong>释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐量。这种方法常用于状态易于保存和恢复的资源，如CPU的寄存器及内存资源</strong>，一般不能用于打印机之类的资源。
<strong>3) 破坏请求和保持条件</strong></p>
<p>釆用<strong>预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源</strong>，在它的资源未满足前，不把它投入运行。一旦投入运行后，这些资源就一直归它所有，也不再提出其他资源请求，这样就可以保证系统不会发生死锁。</p>
<p>这种方式实现简单，但缺点也显而易见，<strong>系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会导致“饥饿”现象，当由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行</strong>。
<strong>4) 破坏循环等待条件</strong></p>
<p>为了破坏循环等待条件，可釆用<strong>顺序资源分配法。首先给系统中的资源编号，规定每个进程，必须按编号递增的顺序请求资源，</strong>同类资源一次申请完。也就是说，只要进程提出申请分配资源Ri，则该进程在以后的资源申请中，只能申请编号大于Ri的资源。</p>
<p>这种方法存在的问题是<strong>，编号必须相对稳定，这就限制了新类型设备的增加；</strong>尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使甩资源的顺序与系统规定顺序不同的情况，造成资源的浪费；此外，这种按规定次序申请资源的方法，也必然会给用户的编程带来麻烦。</p>
<p><strong>死锁避免</strong></p>
<p><strong>死锁的预防是通过破坏产生条件来阻止死锁的产生，但这种方法破坏了系统的并行性和并发性。。</strong></p>
<p>死锁产生的前三个条件是死锁产生的必要条件，也就是说要产生死锁必须具备的条件，而不是存在这3个条件就一定产生死锁，那么<strong>只要在逻辑上回避了第四个条件就可以避免死锁</strong>。</p>
<p><strong>避免死锁采用的是允许前三个条件存在，但通过合理的资源分配算法来确保永远不会形成环形等待的封闭进程链，从而避免死锁。</strong></p>
<p>其主要思想如下：
1.如果一个进程的当前请求的资源会导致死锁，系统拒绝启动该进程；
2.如果一个资源的分配会导致下一步的死锁，系统就拒绝本次的分配；</p>
<p>在这个思想下诞生出来的便是著名的<strong>银行家算法</strong>：把操作系统看做是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源，<strong>当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就推迟分配。当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过了该进程对资源的最大需求量。若超过则拒绝分配资源，若没有超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。</strong></p>
<h3 id="同步的机制">同步的机制</h3>
<h4 id="原子操作">原子操作</h4>
<ul>
<li>基本的操作</li>
<li>不可中断</li>
<li>不能分割的指令 <img
src="https://wulc.me/imgs/image_1b459o3m316no1f0o1kqvhnvtdo9.png" /></li>
</ul>
<p>原子操作的两组接口 1. 原子整数操作：使用一种特殊的类型
<code>atomic_t</code> 2. 原子位操作: 在位级别上进行操作</p>
<h4 id="自旋锁">自旋锁</h4>
<p>原子位和原子整数仅能对简单的整形变量进行原子操作，对于复杂的数据复杂的操作并不适用。需要更复杂的同步方法实现保护机制——锁。</p>
<p>自旋锁：<strong>同一时刻只能被一个可执行线程持有，获得自旋锁时，如果已被别的线程持有则该线程进行循环等待锁重新可用然后继续向下执行。</strong></p>
<p>使用自旋锁时要防止死锁：</p>
<ul>
<li>自旋锁<strong>不可递归</strong>，自旋处于等待中造成死锁；</li>
<li>中断处理程序中，<strong>获取自旋锁前要先禁止本地中断</strong>，中断会打断正持有自旋锁的任务，中断处理程序有可能争用已经被持有的自旋锁，造成死锁。</li>
</ul>
<p><strong>读写自旋锁：将锁的用途直接分为读取和写入。</strong></p>
<ul>
<li>多个读者能同时持有读锁</li>
<li>没有读者时只能有一个写者能持有写锁</li>
</ul>
<h4 id="信号量">信号量</h4>
<p>信号量是<strong>睡眠锁</strong>。如果有一个任务试图获取信号量时，有一下两种情况：
1）<strong>信号量未被占用</strong>：该任务获得成功信号量；
2）<strong>信号量已被占用</strong>：信号量将任任务推进等待队列，让其睡眠，处理器继续工作；当信号量被释放后，唤醒信号量队列中的任务，并获取该信号量。</p>
<p>信号量适用于长时间的持有。持有信号量的进程可以睡眠，但是不能试图获自旋锁。</p>
<p>读写信号量，与读写自旋锁类似</p>
<h4 id="自旋锁与信号量的对比">自旋锁与信号量的对比</h4>
<p>自旋锁与信号量对比如下：</p>
<table>
<thead>
<tr class="header">
<th>需求</th>
<th>建议使用锁</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>低开销加锁</td>
<td>优先使用自旋锁</td>
</tr>
<tr class="even">
<td>短期锁定</td>
<td>优先使用自旋锁</td>
</tr>
<tr class="odd">
<td>长期锁定</td>
<td>优先使用信号量</td>
</tr>
<tr class="even">
<td>中断上下文加锁</td>
<td>自旋锁</td>
</tr>
<tr class="odd">
<td>持有锁需要睡眠</td>
<td>使用信号量</td>
</tr>
</tbody>
</table>
<h4 id="完成变量">完成变量</h4>
<p>信号量的简易方法。
一个任务在等待完成变量，另一个进程在进行某种工作。当一个进程完成工作后，使用完成变量去唤醒在等待的任务，使两个任务得以同步。</p>
<h4 id="bkl-大内核锁">BKL: 大内核锁</h4>
<p>大内核锁本质上是一个<strong>全局自旋锁</strong>，但是它又不同于自旋锁，自旋锁是不可以递归获得锁的，因为那样会导致死锁。<strong>但大内核锁可以递归获得锁。大内核锁用于保护整个内核，而自旋锁用于保护非常特定的某一共享资源</strong>。同时持有BLK是也可睡眠。</p>
<p><strong>整个内核只有一个大内核锁</strong>，其实不难理解，内核只有一个，而大内核锁是保护整个内核的，当然有且只有一个就足够了。</p>
<p>大内核锁是历史遗留，内核中用的非常少，一般保持该锁的时间较长，因此不提倡使用它。</p>
<h4 id="顺序锁">顺序锁</h4>
<p>内核2.6引入，类似于读者自旋锁，但是为写者赋予了较高的优先级，<strong>写者优先，读者正在读时允许写者写</strong>。</p>
<h4 id="禁止抢占">禁止抢占</h4>
<p>内核是可抢占的，被抢占的进程可能处于临界区。</p>
<p>解决方法：使用自旋锁作为非抢占区的标志，因为一个自旋锁被持有，内核便不能进行抢占。</p>
<h4 id="顺序和屏障">顺序和屏障</h4>
<p>当处理器和硬件交互时，时常需要<strong>确保一个给定的读操作发生在其他读或写操作之前</strong>。在多处理器上，可能需要按写数据的顺序读数据。但是<strong>编译器和处理器为了提高效率，可能对读和写重新排序</strong>。但是，处理<strong>器提供了机器指令来确保顺序</strong>，指示编译器不要对给定点周围的指令序列进行重新排序。这些确保顺序的指令称为<strong>屏障(barrier)</strong>。</p>
<p><code>rmb()</code>方法提供了一个“读”内存屏障，也就是说，<strong>在rmb()之前的读操作不会被重新排在该调用之后，同理，在rmb()之后的读操作不会被重新排在该调用之前。</strong>
<code>wmb()</code>方法提供了一个“写”内存屏障，这个函数的功能和rmb()类似，区别仅仅是它是针对写而非读。</p>
<h4 id="总结">总结</h4>
<ul>
<li>保证同步的最简单的方法, 原子操作</li>
<li>自旋锁, 最常用的方式，轻量级，只能有一个保持者，忙等</li>
<li>信号量, 睡眠锁，适用稍少</li>
</ul>
<h2 id="第十二章-内存管理">第十二章 内存管理</h2>
<h3 id="连续分配">连续分配</h3>
<p>连续分配是指为一个用户程序分配连续的内存空间。连续分配有单一连续存储管理和分区式储管理两种方式。</p>
<h4 id="单一连续存储管理">单一连续存储管理</h4>
<p>在这种管理方式中，<strong>内存被分为两个区域：系统区和用户区</strong>。应用程序装入到用户区，可使用用户区全部空间。其特点是，最简单，适用于单用户、单任务的操作系统。CP／M和
DOS
2．0以下就是采用此种方式。这种方式的最大优点就是易于管理。但也存在着一些问题和不足之处，例如对要求内存空间少的程序，造成内存浪费；程序全部装入，使得很少使用的程序部分也占用—定数量的内存。
伙伴系统</p>
<h4 id="分区式存储管理">分区式存储管理</h4>
<p>为了支持多道程序系统和分时系统，支持多个程序并发执行，引入了分区式存储管理。分区式存储管理是<strong>把内存分为一些大小相等或不等的分区，操作系统占用其中一个分区，其余的分区由应用程序使用，每个应用程序占用一个或几个分区。</strong>分区式存储管理虽然可以支持并发，但难以进行内存分区的共享。</p>
<p>分区式存储管理引人了两个新的问题：内碎片和外碎片。内碎片是占用分区内未被利用的空间，外碎片是占用分区之间难以利用的空闲分区(通常是小空闲分区)。</p>
<p>为实现分区式存储管理，操作系统应维护的数据结构为<strong>分区表</strong>或分区链表。表中各表项一般包括每个分区的起始地址、大小及状态(是否已分配)。分配方式有固定分区和动态分区。</p>
<p><strong>固定分区(nxedpartitioning)</strong></p>
<p>固定式分区的特点是<strong>把内存划分为若干个固定大小的连续分区</strong>。分区大小可以相等：这种作法只适合于多个相同程序的并发执行(处理多个类型相同的对象)。分区大小也可以不等：有多个小分区、适量的中等分区以及少量的大分区。根据程序的大小，分配当前空闲的、适当大小的分区。</p>
<p><strong>动态分区(dynamic partitioning)</strong></p>
<p>动态分区的特点是动态创建分区：<strong>在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小</strong>。</p>
<p>与固定分区相比较其优点是：没有内碎片。但它却引入了另一种碎片——外碎片。动态分区的分区分配就是寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求的大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区分配的先后次序通常是从内存低端到高端。动态分区的分区释放过程中有一个要注意的问题是，将相邻的空闲分区合并成一个大的空闲分区。</p>
<h4 id="伙伴系统">伙伴系统</h4>
<p>固定分区和动态分区方式都有不足之处。<strong>固定分区方式限制了活动进程的数目</strong>，当进程大小与空闲分区大小不匹配时，内存空间利用率很低。<strong>动态分区方式算法复杂，回收空闲分区时需要进行分区合并等，系统开销较大</strong>。伙伴系统方式是对以上两种内存方式的一种折衷方案。</p>
<p><strong>伙伴系统规定，无论已分配分区或空闲分区，其大小均为 2 的 k
次幂，k 为整数， l≤k≤m，其中</strong>：</p>
<p>2^1 表示分配的最小分区的大小， 2^m 表示分配的最大分区的大小，</p>
<p>假设系统的可利用空间容量为2^m个字， 则系统开始运行时，
整个内存区是一个大小为2^m的空闲分区。在系统运行过中，
由于不断的划分，可能会形成若干个不连续的空闲分区，将这些空闲分区根据分区的大小进行分类，<strong>对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。这样，不同大小的空闲分区形成了k(0≤k≤m)个空闲分区链表</strong>。</p>
<p>当需要为进程分配一个长度为n 的存储空间时:</p>
<p>首先计算一个i 值，使
<code>2^(i－1) &lt; n ≤ 2^i</code>，然后在空闲分区大小为2<sup>i的空闲分区链表中查找。若找到，即把该空闲分区分配给进程。否则，表明长度为2</sup>i的空闲分区已经耗尽，则在分区大小为2<sup>(i＋1)的空闲分区链表中寻找。若存在2</sup>(i＋1)的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于配，而把另一个加入分区大小为2<sup>i的空闲分区链表中。若大小为2</sup>(i＋1)的空闲分区也不存在，则需要查找大小为2^(i＋2)的空闲分区，
若找到则对其进行两次分割，以此类推。</p>
<p>在最坏的情况下，可能需要对 2^k的空闲分区进行 k
次分割才能得到所需分区。合并空闲内存的过程与分割的过程类似。</p>
<h3 id="离散分配">离散分配</h3>
<p>前面的几种存储管理方法中，为进程分配的空间是连续的，使用的地址都是物理地址。如果允许<strong>将一个进程分散到许多不连续的空间，就可以避免内存紧缩(将各个占用分区向内存一端移动，然后将各个空闲分区合并成为一个空闲分区)，减少碎片。基于这一思想，通过引入进程的逻辑地址，把进程地址空间与实际存储空间分离，增加存储管理的灵活性。</strong>地址空间和存储空间两个基本概念的定义如下：</p>
<p><strong>地址空间</strong>：将源程序经过编译后得到的<strong>目标程序，存在于它所限定的地址范围内</strong>，这个范围称为地址空间。<strong>地址空间是逻辑地址的集合</strong>。</p>
<p><strong>存储空间</strong>：指主存中一系列存储信息的<strong>物理单元的集合</strong>，这些单元的编号称为物理地址存储空间是物理地址的集合。</p>
<p>根据分配时所采用的基本单位不同，可将离散分配的管理方式分为以下三种：
<strong>页式存储管理、段式存储管理和段页式存储管理</strong>。其中段页式存储管理是前两种结合的产物。</p>
<h4 id="页式管理">页式管理</h4>
<p>将程序的<strong>逻辑地址空间划分为固定大小的页(page)，而物理内存划分为同样大小的页框(page
frame)</strong>。程序加载时，可将任意一页放人内存中任意一个页框，这些页框不必连续，从而实现了离散分配。</p>
<p>该方法需要CPU的硬件支持，来实现<strong>逻辑地址和物理地址之间的映射</strong>。在页式存储管理方式中<strong>地址结构由两部构成，前一部分是页号，后一部分为页内地址w（位移量）</strong>.</p>
<p>页式管理方式的<strong>优点</strong>是：</p>
<p>1）没有外碎片，每个内碎片不超过页的大小 2）一个程序不必连续存放。
3）便于改变程序占用空间的大小(主要指随着程序运行，动态生成的数据增多，所要求的地址空间相应增长)。</p>
<p><strong>缺点</strong>是：要求程序全部装入内存，没有足够的内存，程序就不能执行。</p>
<p>每个进程有一个页表，用于完成逻辑页号(本进程的地址空间)到物理页面号(实际内存空间，也叫块号)的映射，如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b45qltgkeb61kjs1brv18n717vo9.png" /></p>
<h4 id="段式管理">段式管理</h4>
<p>在段式存储管理中，<strong>将程序的地址空间划分为若干个段(segment)</strong>，为每个段分配一个连续的分区，而进程中的各个段可以不连续地存放在内存的不同分区中。程序加载时，操作系统为所有段分配其所需内存，这些段不必连续，物理内存的管理采用动态分区的管理方法。</p>
<p>段式存储管理也需要硬件支持，实现逻辑地址到物理地址的映射。</p>
<p>程序通过分段划分为多个模块，如代码段、数据段、共享段，<strong>这样做的优点是：可以分别编写和编译源程序的一个文件，并且可以针对不同类型的段采取不同的保护，也可以按段为单位来进行共享。</strong></p>
<p>段式存储管理的优点是：<strong>没有内碎片，外碎片可以通过内存紧缩来消除</strong>；便于实现内存共享。缺点与页式存储管理的缺点相同，进程必须全部装入内存。</p>
<p>类似页式管理的进程页表，段式管理中每个进程也有一张<strong>进程段表</strong>。</p>
<h4 id="页式管理-vs-段式管理">页式管理 vs 段式管理</h4>
<p>页式和段式系统有许多相似之处。比如，<strong>两者都采用离散分配方式，且都通过地址映射机构来实现地址变换</strong>。但概念上两者也有很多区别，主要表现在：</p>
<p>1)、需求：是信息的物理单位，<strong>分页是为了实现离散分配方式，以减少内存的碎片，提高内存的利用率</strong>。或者说，分页仅仅是由于系统管理的需要，而不是用户的需要。段是信息的逻辑单位，它含有一组其意义相对完整的信息。<strong>分段的目的是为了更好地满足用户的需要。因为一条指令或一个操作数可能会跨越两个页的分界处，而不会跨越两个段的分界处。</strong></p>
<p>2)、大小：<strong>页大小固定且由系统决定</strong>，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的。<strong>段的长度不固定，且决定于用户所编写的程序</strong>，通常由编译系统在对源程序进行编译时根据信息的性质来划分。</p>
<p>3)、逻辑地址表示：<strong>页式系统地址空间是一维的</strong>，即单一的线性地址空间，程序员只需利用一个标识符，即可表示一个地址。<strong>分段的作业地址空间是二维的</strong>，程序员在标识一个地址时，既需给出段名，又需给出段内地址。</p>
<p>4)、段比页大，因而段表比页表短，可以缩短查找时间，提高访问速度。</p>
<h3 id="linux-中的内存管理">linux 中的内存管理</h3>
<h4 id="页和区">页和区</h4>
<p>linux
采用上面提到的页式管理方法。MMU以页为单位管理内存。对于32位，每个页的大小为
4K；而对于64位而言每个页的大小为8K。内核用<code>struct page</code>结构体表示每个物理页,它们组织在<code>mem_map</code>数组中</p>
<p>内核把页划分在不同的区(zone),总共3个区，具体如下：</p>
<table>
<thead>
<tr class="header">
<th>区</th>
<th>描述</th>
<th>物理内存（MB）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ZONE_DMA</td>
<td>DMA使用的页</td>
<td>&lt;16</td>
</tr>
<tr class="even">
<td>ZONE_NORMAL</td>
<td>可正常寻址的页</td>
<td>16 ~896</td>
</tr>
<tr class="odd">
<td>ZONE_HIGHMEM</td>
<td>动态映射的页</td>
<td>&gt;896</td>
</tr>
</tbody>
</table>
<p>执行DMA操作的内存必须从<code>ZONE_DMA</code>区分配
一般内存，既可从<code>ZONE_DMA</code>，也可从<code>ZONE_NORMAL</code>分配，但不能同时从两个区分配</p>
<h4 id="内存分配和释放">内存分配和释放</h4>
<p><strong>页的分配与释放</strong>：页的分配通过
<code>alloc_pages</code> 函数实现，而释放则通过<code>__free_pages</code>
实现</p>
<p><strong>字节的分配与释放</strong>：字节的分配可通过<code>kmalloc</code>，<code>vmalloc</code>实现</p>
<p>1）<code>kmalloc</code> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void * kmalloc(size_t size, gfp_t flags)</span><br></pre></td></tr></table></figure>
该函数返回的是一个指向内存块的指针，其内存块大小至少为size,所<strong>分配的内存在物理内存中连续且保持原有的数据</strong>(不清零)，释放时通过<code>kfree</code>释放</p>
<p>其中部分flags取值说明：</p>
<p><code>GFP_USER</code>： 用于用户空间的分配内存，可能休眠；
<code>GFP_KERNEL</code>：用于内核空间的内存分配，可能休眠；
<code>GFP_ATOMIC</code>：用于原子性的内存分配，不会休眠；典型原子性场景有中断处理程序，软中断，tasklet等</p>
<p>2）<code>vmalloc</code> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void * vmalloc(unsigned long size)</span><br></pre></td></tr></table></figure>
该函数返回的是一个指向内存块的指针，其内存块大小至少为size,所分配的内存是<strong>逻辑上连续的，物理上可能连续也可能不连续。</strong></p>
<p>与kmalloc不同，该函数没有flags,默认是可以休眠的。</p>
<p><strong>Slab分配器</strong></p>
<p>slab分配器是一种策略，用于缓存内核对象，其主要工作是<strong>针对一些经常分配并释放的对象</strong>，如进程描述符等，这些对象的大小一般比较小，<strong>如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢</strong>。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从存储某一类对象的高速缓存组中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统。slab分配对象时，会使用最近释放的对象内存块，因此其驻留在CPU高速缓存的概率较高。</p>
<p>其中高速缓存(cache),slab 和 对象的关系如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Cache: 存储某种类型的对象.</span><br><span class="line">Slab: 包含有缓存的对象（由cache划分出来）</span><br><span class="line">Object: 经常使用的数据结构，例如inode</span><br></pre></td></tr></table></figure> <img
src="https://wulc.me/imgs/image_1b465ihrl16um2136e1l4lnvom.png" /></p>
<p>slab有三种状态 <strong>Full</strong>：没有自由的对象
<strong>Partial</strong>：部分自由，先从这里分配(<strong>减少了页的分配和释放</strong>)，再找empty的，如果两者都找不到，创建一个新的slab
<strong>Empty</strong>：含有未分配的对象</p>
<p><strong>选择哪种方法分配</strong></p>
<table>
<thead>
<tr class="header">
<th>频繁分配和释放</th>
<th>Slab分配器.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>需要以页为单位分配内存</td>
<td><code>alloc_pages()</code></td>
</tr>
<tr class="even">
<td>从高端内存分配</td>
<td><code>alloc_pages()</code></td>
</tr>
<tr class="odd">
<td>默认</td>
<td><code>kmalloc()</code></td>
</tr>
<tr class="even">
<td>不需要连续的页</td>
<td><code>vmalloc()</code></td>
</tr>
</tbody>
</table>
<h2 id="第十五章-进程地址空间">第十五章 进程地址空间</h2>
<h3 id="基本概念-4">基本概念</h3>
<p>进程地址空间指进程能够使用的地址范围，每一个进程看到的是一个不同的线性地址，一个进程使用的地址与另一个进程使用的地址无关。内核会通过增加或删除线性地址中的区域，动态修改进程地址空间。</p>
<p>进程地址空间由进程可寻址的虚拟内存组成，<strong>linux采取的虚拟内存技术使得所有进程以虚拟方式共享内存</strong>。对于某个进程，它好像可以访问所以物理内存，而且它的地址空间可以远远大于物理内存.</p>
<p>进程只能访问有效区域中的内存地址。<strong>如果进程访问的内存地址不再有效内存区域，或者以非法的方式访问有效区域，内核会杀掉这个进程并输出一个“<code>Segmentation Fault</code>”
信息</strong></p>
<h3 id="内存描述符">内存描述符</h3>
<p>内核用一个称之为内存描述符的数据结构（<code>mm_struct</code>）表示一个进程的地址空间。<code>mm_struct</code>部分组元素如下：</p>
<ul>
<li><code>mmap</code>和<code>mm_rb</code>字段是不同的数据结构，但含有同样的东西，即地址空间中的所有内存区域</li>
<li><code>mm_users</code> 字段表示使用这个地址空间的进程数目</li>
<li><code>mmlist</code> 链表将所有<code>mm_struct</code>连接在一起</li>
</ul>
<p><strong>内存描述符的分配与释放</strong></p>
<p><code>copy_mm()</code> 函数用于在
<code>fork()</code>时复制父进程的内存描述符（使用<code>vfork()</code>的时候进程与子进程共享地址空间），当与指定的地址空间相关联的进程结束时，会调用<code>exit_mm()</code>
函数</p>
<h3 id="进程的内存区域">进程的内存区域</h3>
<p>进程的地址空间可划分为不同的区域，应用在不同的场景，如下就是常见的几种内存区域：</p>
<p>1）<strong>文本段（<code>text section</code>）</strong>，存放可执行文件的操作指令，也就是可执行文件的代码的内存映像，包含一些字符串、常量和只读数据
2）数据段（<code>data section</code>），数据段用来存放可执行文件中已初始化全局变量，也就是存放程序<strong>静态变量和全局变量</strong>
3）<code>bss section</code>，<strong>未初始化全局变量</strong>的内存映像
4）堆（<code>heap</code>），堆是用于存放进程运行中被<strong>动态分配的内存区域，它的大小并不固定，可动态扩张或缩减。</strong>当进程调用<code>malloc</code>等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用<code>free</code>等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）
5）栈（<code>stack</code>），栈是用户存放程序<strong>临时创建的局部变量</strong>，除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中</p>
<p>每个内存区域均由以下参数刻画 1）起始地址 2）长度 3）访问权利</p>
<p>内存区域由内存区域对象表示，存于<code>vm_area_struct</code>
结构，也叫VMA，描述给定的地址空间上的一个独立的内存区域。VMA
结构能够表示上面提到的多种类型的内存区域。</p>
<p><code>task_struct</code>，<code>mm_struct,</code>
<code>vm_area_struct</code>的关系如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b46965a11log1kgsapita91bdd1g.png" /></p>
<p>VMA中还有VMA标志，用于指定内存区域中页的行为或信息，各标志及其含义如下
<code>VM_READ</code>：页可读 <code>VM_WRITE</code>：页可写
<code>VM_EXEC</code>：页可执行 对于代码:
可被映射为<code>VM_READ</code>和<code>VM_EXEC</code>，但不能映射为<code>VM_WRITE</code>
对于数据：可被映射为<code>VM_READ</code>和<code>VM_WRITE</code>，但不能映射为<code>VM_EXEC</code></p>
<h3 id="linux的分页">Linux的分页</h3>
<p>下面先以32位的系统为例讲述原始的分页</p>
<p>每个地址可以通过一个32位的整数描述，其中整数的32为分配如下</p>
<p><img
src="https://wulc.me/imgs/image_1b46af1oj1h4e1in01q605u11dd1t.png" /></p>
<ul>
<li>页目录包含1024（2^10）个页表</li>
<li>页表描述1024（2^10）个页</li>
<li>每页大小 4 KB（2^12） (PAGE_SIZE)</li>
<li>1024 * 1204 * 4KB = 4GB</li>
<li>CR3 (在task_struct的TSS)含有页目录的物理基地址</li>
</ul>
<p>寻址时利用线性地址的低22<sub>31位从页目录找到对应的页表，然后利用线性地址的低12</sub>21为从页表找到对应的页，最后用低12位从页中找到最终地址。过程如下所示：</p>
<p><img
src="https://wulc.me/imgs/image_1b46ahh71jfvtu1m2e1bolunm2a.png" /></p>
<p>上面是原始的两级分页，但是Linux使用<strong>3级分页</strong>，
顶层页表是<code>page global directory (PGD)</code>，二级页表是<code>page middle directory (PMD)</code>，最后一级是
<code>PTE</code>，整体如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b46au0e31vsutbp75v1d341omv34.png" /></p>
<p>与task_struct 等关系如下图所示 <img
src="https://wulc.me/imgs/image_1b46b337k3lg1c431bik457do3h.png" /></p>
<h2 id="第十三章-文件系统">第十三章 文件系统</h2>
<h3 id="ext2-文件系统">ext2 文件系统</h3>
<p>ext2于1993 年创建，是ext的改进版本，具有如下的特点：</p>
<ul>
<li>支持UNIX所有标准的文件特征</li>
<li>可管理大硬盘，一个分区的容量最大可达4TB</li>
<li>它使用变长的目录项
，支持255个字符的长文件名，可扩展到1012个字符</li>
<li><strong>使用位图来管理数据块和节点的使用情况</strong></li>
<li>使用了块组的概念，从而使数据的读和写更快，更有效，也使系统变得更安全可靠</li>
</ul>
<h4 id="文件系统结构">文件系统结构</h4>
<p>整个ext2文件系统结构如下所示：</p>
<p><img
src="https://wulc.me/imgs/image_1b46bfka6aej1ats115nfv179h4b.png" /></p>
<p>文件系统中存储的最小单位是块（
Block），一个块究竟多大是在格式化时确定的，例如 <code>mke2fs</code>的
<code>-b</code>选项可以设定块大小为 1024、 2048或
4096字节。而上图中引导块（Boot Block）的大小是确定的，就是
1KB，引导块是由
PC标准规定的，用来<strong>存储磁盘分区信息和启动信息</strong>，任何文件系统都不能使用启动块。</p>
<p>启动块之后才是
ext2文件系统的开始，ext2将磁盘分区看成是<strong>由块组组成，每个块组包含一个或多个块</strong>。每个块组大小相同，顺序存放，且每个块组都由以下部分组成。</p>
<p><strong>1）超级块(Super
Block)</strong>：描述<strong>整个分区的文件系统信息</strong>，例如块大小、文件系统版本号、上次
<code>mount</code>的时间等等。超级块在每个块组的开头都有一份拷贝。
<strong>2）组描述符(Group Descriptor
Table)</strong>：由很多块组描述符组成，<em>整个分区分成多少个块组就对应有多少个块组描述符</em>。每个块组描述符存储<strong>一个块组的描述信息</strong>，例如在这个块组中从哪里开始是
inode 表，从哪里开始是数据块，空闲的 inode
和数据块还有多少个等等。和超级块类似，块组描述符表在每个块组的开头也都有一份拷贝，这些信息是非常重要的，<strong>一旦超级块意外损坏就会丢失整个分区的数据，一旦块组描述符意外损坏就会丢失整个块组的数据，因此它们都有多份拷贝。</strong></p>
<p><strong>3）块位图(Block
Bitmap)</strong>。块位图就是用来<strong>描述整个块组中哪些块是空闲可用的</strong>，它本身占一个块，其中的每个
bit代表本块组中的一个块，这个 bit为 1表示该块已用，这个 bit为
0表示该块空闲可用。</p>
<p>与此相联系的另一个问题是：在<strong>格式化一个分区时究竟会划出多少个块组</strong>呢？主要的限制在于块位图本身必须只占一个块。用
mke2fs格式化时默认块大小是 1024字节，可以用
-b参数指定块大小，现在设块大小指定为 b字节，那么一个块可以有 8b个
bit，这样大小的一个块位图就可以表示
8b个块的占用情况，因此一个块组最多可以有 8b个块，如果整个分区有
s个块，那么就可以有 s/(8b)个块组。格式化时可以用
-g参数指定一个块组有多少个块，但是通常不需要手动指定，
mke2fs工具会计算出最优的数值。</p>
<p><strong>4）索引节点位图(inode
Bitmap)</strong>。和块位图类似，本身占一个块，其中每个 bit表示一个
inode是否空闲可用。</p>
<p><strong>5）索引接点表(inode
table)</strong>。一个文件除了数据需要存储之外，<strong>一些描述信息也需要存储</strong>，例如文件类型（常规、目录、符号链接等），权限，文件大小，创建/
修改/访问时间等，也就是
<code>ls -l</code>命令看到的那些信息，这些信息存在
inode中而不是数据块中。<strong>每个文件都有一个 inode，一个块组中的所有
inode组成了 inode表。</strong></p>
<p>inode表占多少个块在格式化时就要决定并写入块组描述符中，
mke2fs格式化工具的默认策略是<strong>一个块组有多少个 8KB 就分配多少个
inode</strong>。由于数据块占了整个块组的绝大部分，也可以近似认为数据块有多少个
8KB就分配多少个 inode，换句话说，如果平均每个文件的大小是
8KB，当分区存满的时候
inode表会得到比较充分的利用，数据块也不浪费。<strong>如果这个分区存的都是很大的文件（比如电影），则数据块用完的时候
inode会有一些浪费，如果这个分区存的都是很小的文件（比如源代码），则有可能数据块还没用完
inode就已经用完了，数据块可能有很大的浪费。</strong>如果用户在格式化时能够对这个分区以后要存储的文件大小做一个预测，也可以用
mke2fs的 -i 参数手动指定每多少个字节分配一个 inode。</p>
<p><strong>6）数据块(Data
Block)</strong>。数据块用来存储文件的具体内容，在linux中文件类型有以下几种</p>
<ul>
<li>普通文件</li>
<li>目录</li>
<li>符号连接</li>
<li>字符设备特殊文件</li>
<li>块设备特殊文件</li>
<li>命名管道</li>
<li>Socket</li>
</ul>
<p>于普通文件，文件的数据存储在数据块中。</p>
<p>对于目录，该<strong>目录下的所有文件名及其inode存储在数据块</strong>中，除文件名之外，
<code>ls -l</code>命令看到的其它信息都保存在该文件的inode中。注意这个概念：目录也是一种文件，是一种特殊类型的文件。</p>
<p>对于符号链接，如果<strong>目标路径名较短则直接保存在
inode中以便更快地查找，如果目标路径名较长则分配一个数据块来保存</strong>。</p>
<p>设备文件、FIFO和socket
等特殊文件<strong>没有数据块</strong>，即文件大小为0，设备文件的主设备号和次设备号保存在
inode中。</p>
<h4 id="文件查找">文件查找</h4>
<p>文件查找的流程：
1）从当前进程的根目录项中（<code>current→ fs → root</code>）找到它的<strong>根目录的inode编号</strong>
2）根据该编号和超级块的<code>s_inodes_per_group</code>，计算出该<strong>inode所在的块组</strong>
3）查找该块组中的<strong>inode表</strong>，找到描述根目录文件的inode
4）根据该inode的描述，读取其数据块（如果是文件）或得到目录项列表（如果是目录，然后返回步骤（2）直到读到最终的文件）</p>
<h4 id="ext2的内存数据结构">ext2的内存数据结构</h4>
<p>为提高效率，尽量减少访问磁盘次数，在安装Ext2分区时，内存中存放着部分磁盘数据结构，并使用缓存技术保持磁盘数据结构更新。</p>
<p>缓存模式共有4种</p>
<ul>
<li><code>Always cached</code>：一直缓存</li>
<li><code>Fixed limit</code>：固定数量的数据结构保存在缓存中</li>
<li><code>Dynamic</code>：只要索引节点或块使用，相关数据就保存在缓存中</li>
<li><code>Never</code>：任何高速缓存中都不保存</li>
</ul>
<p>ext2 中的数据结构及其缓存情况如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b46f36m11v5i16h21j101pkl2he4o.png" /></p>
<h4 id="文件系统的创建">文件系统的创建</h4>
<p>创建Ext2文件系统实际上就是建立Ext2文件系统<strong>的磁盘数据结构与内存数据结构</strong>，在linux中通过mke2fs程序实现，这个程序实际上执行了以下两个步骤：
1）格式化 2）创建文件系统</p>
<h4 id="ext3与ext4">ext3与ext4</h4>
<p>ext2 文件系统的下一个版本是 ext3 文件系统，它和 ext2
文件系统在硬盘布局上是一样的，其差别仅仅是 ext3
文件系统在硬盘上多出了一个特殊的
inode（可以理解为一个特殊文件），用来<strong>记录文件系统的日志</strong>，也即所谓的
journal。Ext4 支持更大的文件和无限量的子目录。</p>
<h3 id="虚拟文件系统vfs">虚拟文件系统（VFS）</h3>
<h4 id="基本概念-5">基本概念</h4>
<p>为支持各种文件系统，Linux内核在用户进程（或C标准库）和具体的文件系统之间引入了一个抽象层，<strong>使得文件、目录、读写访问等概念成为抽象层的概念，因此各种文件系统看起来用起来都一样</strong>，该抽象层称之为“虚拟文件系统（VFS）”。类似于类和对象的关系，其中VFS是类，各种文件系统是具体的对象。</p>
<p>VFS一方面提供一种操作文件、目录及其他对象的统一方法，使用户进程不必知道文件系统的细节。另一方面，VFS提供的各种方法必须和具体文件系统的实现达成一种妥协，毕竟对几十种文件系统类型进行统一管理并不是件容易的事。
为此，VFS中定义了一个通用文件模型，以支持文件系统中对象（或文件）的统一视图。</p>
<p>Linux对Ext文件系统族的支持是最好的，因为<strong>VFS抽象层的组织与Ext文件系统类似，这样在处理Ext文件系统时可以提高性能，因为在Ext和VFS之间转换几乎不会损失时间。</strong></p>
<p><strong><code>task_struct</code> 结构中 VFS 相关的字段</strong></p>
<ul>
<li>fs – 包括root, pwd,指向<code>dentrie</code>的指针</li>
<li>files – <strong>文件描述符矩阵</strong> fd[
],每一个元素指向打开文件对象的指针</li>
</ul>
<h4 id="主要的数据结构">主要的数据结构</h4>
<p><strong>1）超级块</strong> 对于每个已经挂载的文件系统，VFS
在内核中都生成一个超级块结构（<code>struct super_block</code>实例），超级块代表一个已经安装的文件系统，用于存储文件系统的控制信息，例如文件系统类型、大小、所有inode对象、脏的inode链表等。</p>
<p>超级块相关的文件系统操作为读、写、清除和删除inode。</p>
<p><strong>2）inode</strong>
VFS处理文件的关键是inode，每个<strong>文件或目录</strong>都有且只有一个对应的inode（<code>struct inode</code>实例），其中<strong>包含元数据(权限，拥有者，时间信息，大小，连接计数
)和指向文件数据的指针</strong>，但inode并不包含文件名。系统中所有的inode都有一个<strong>特定的编号，用于唯一的标识各个inode</strong>。文件名可以随时更改，但是索引节点对文件是唯一的，并且随文件的存在而存在。</p>
<p>inode和super
block在存储介质中都是<strong>有实际映</strong>射的，即存储介质中也存在超级块和inode。但是<strong>由于不同类型的文件系统差异，超级块和inode的结构不尽相同</strong>。而<strong>VFS的作用就是通过具体的设备驱动获得某个文件系统中的超级块和inode节点，然后将其中的信息填充到内核中的<code>struct super_block</code>和<code>struct inode</code>中，以此来试图对不同文件系统进行统一管理。</strong></p>
<p>inode的相关操作包括： <code>create</code> – 创建一个普通文件
<code>link/unlink/rename</code> – 增加、删除、修改目录内容
<code>symlink, readlink, follow_link</code> – 软连接操作
<code>mkdir/rmdir</code> – 创建目录文件 <code>mknod</code> –
创建设备文件 <code>truncate</code> – 修改文件大小
<code>permission</code> – 检查访问权限</p>
<p><strong>3）dentry</strong>
VFS把目录当做文件对待，为了方便路径查找，VFS引入了目录项的概念，每个目录项代表路径中的一个特定部分如(<code>/bin/vi</code>中包含了<code>/</code>,<code>bin</code>和<code>vi</code>三个目录项目对象)。目录项对象通过
dentry 结构体表示。<strong>dentry 结构的主要用途就是建立文件名和相关的
inode 之间的联系。</strong></p>
<p>目录项有三种有效状态</p>
<ul>
<li>used:表示该目录项对应一个有效的索引节点，且该对象正在被使用</li>
<li>unused:
表示该目录项对应一个有效的索引节点，但是该对象没有被使用</li>
<li>negative:表示该目录项没有对应的有效索引节点</li>
</ul>
<p>由于块设备速度较慢（于内存而言），可能需要很长时间才能找到与一个文件名关联的inode。<strong>Linux使用目录项缓存来快速访问此前的查找操作结果。</strong>在VFS读取了一个目录或文件的数据之后，则创建一个
dentry
实例（<code>struct dentry</code>），以缓存找到的数据。Dentry缓存通过哈希表访问，因此时间较快。</p>
<p><strong>4）打开的文件对象</strong>
文件对象主要用于关联文件和进程，在打开文件的时候创建，主要描述一个打开文件的相关信息，包括当前的读写指针等，通过<code>struct file</code>结构体表示。</p>
<p>在<code>task_struct</code>中有一个数组，数组中的每一个元素都是指向一个打开的文件对象，这个数组就称为<strong>文件描述符</strong>数组。</p>
<p>上面提到的数据结构之间的关系如下所示 <img
src="https://wulc.me/imgs/image_1b47qm20g168d1fg6t5fcbpu0o9.png" /></p>
<p><strong>共享数据结构的情况：</strong></p>
<ul>
<li>在不同的目录上挂载同一个文件系统 ：<strong>共享超级块</strong></li>
<li>通过不同的硬连接打开同一个文件：<strong>共享 inodes</strong></li>
<li>打开同一个文件两次：<strong>共享 dentries</strong></li>
<li>调用 dup()：<strong>共享打开文件对象</strong>，例如:
2&gt;&amp;1</li>
</ul>
<p>参考： <a
href="http://alick.blog.51cto.com/10786574/1786269">task_struct结构体字段介绍--Linux中的PCB</a>
<a
href="http://blog.csdn.net/tianlesoftware/article/details/6457487">Linux
进程状态说明</a> <a
href="https://www.ibm.com/developerworks/cn/linux/kernel/l-thread/">Linux
线程实现机制分析</a> <a
href="http://www.cnblogs.com/wuchanming/p/4495479.html">Linux进程管理——fork()和写时复制</a>
<a
href="http://blog.csdn.net/cheyuxuan/article/details/9100607">linux中断处理的上半部和下半部</a>
<a
href="http://www.cppblog.com/wolf/articles/67077.html">死锁的产生、预防和避免</a>
<a
href="http://blog.chinaunix.net/uid-28748002-id-4273771.html">linux内存管理总结之进程地址空间</a>
<a
href="http://blog.csdn.net/jnu_simba/article/details/11759809">Ext2文件系统布局，文件数据块寻址，VFS虚拟文件系统</a>
<a
href="http://blog.csdn.net/jasonchen_gbd/article/details/51511261">Linux
虚拟文件系统（VFS）介绍</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中样本比例不平衡的处理方法</title>
    <url>/2017/07/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%A0%B7%E6%9C%AC%E6%AF%94%E4%BE%8B%E4%B8%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>在机器学习中，常常会遇到样本比例不平衡的问题，如对于一个二分类问题，正负样本的比例是
10:1。这种现象往往是由于本身数据来源决定的，如信用卡的征信问题中往往就是正样本居多。样本比例不平衡往往会带来不少问题，但是实际获取的数据又往往是不平衡的，因此本文主要讨论面对样本不平衡时的解决方法。</p>
<span id="more"></span>
<p>样本不平衡往往会导致模型对样本数较多的分类造成过拟合，即总是将样本分到了样本数较多的分类中；除此之外，一个典型的问题就是
<a href="https://en.wikipedia.org/wiki/Accuracy_paradox">Accuracy
Paradox</a>，这个问题指的是模型的对样本预测的准确率很高，但是模型的泛化能力差。其原因是模型将大多数的样本都归类为样本数较多的那一类，如下所示</p>
<table>
<thead>
<tr class="header">
<th>category</th>
<th>Predicted Negative</th>
<th>Predicted Positive</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Negative Cases</td>
<td>9700</td>
<td>150</td>
</tr>
<tr class="even">
<td>Positive Cases</td>
<td>50</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>准确率为 <span class="math display">\[\frac{9700+100}{9700 + 150 + 50
+ 100} = 0.98\]</span></p>
<p>而假如将所有的样本都归为预测为负样本，准确率会进一步上升，但是这样的模型显然是不好的，实际上，模型已经对这个不平衡的样本过拟合了。</p>
<p>针对样本的不平衡问题，有以下几种常见的解决思路</p>
<ol type="1">
<li>搜集更多的数据</li>
<li>改变评判指标</li>
<li>对数据进行采样</li>
<li>合成样本</li>
<li>改变样本权重</li>
</ol>
<h2 id="搜集更多的数据">搜集更多的数据</h2>
<p>搜集更多的数据，从而让正负样本的比例平衡，这种方法往往是最被忽视的方法，然而实际上，当搜集数据的代价不大时，这种方法是最有效的。</p>
<p>但是需要注意，当搜集数据的场景本来产生数据的比例就是不平衡时，这种方法并不能解决数据比例不平衡问题。</p>
<h2 id="改变评判指标">改变评判指标</h2>
<p>改变评判指标，也就是不用准确率来评判和选择模型，原因就是我们上面提到的
Accuracy Paradox
问题。实际上有一些评判指标就是专门解决样本不平衡时的评判问题的，如准确率，召回率，F1值，ROC（AUC），<a
href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Kappa</a> 等。</p>
<p>根据<a
href="http://alexkong.net/2013/06/introduction-to-auc-and-roc/">这篇文章</a>，ROC
曲线具有不随样本比例而改变的良好性质，因此能够在样本比例不平衡的情况下较好地反映出分类器的优劣。</p>
<p>关于评判指标更详细的内容可参考文章： <a
href="http://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/">Classification
Accuracy is Not Enough: More Performance Measures You Can Use</a></p>
<h2 id="对数据进行采样">对数据进行采样</h2>
<p>对数据采样可以有针对性地改变数据中样本的比例，采样一般有两种方式：<code>over-sampling</code>
和
<code>under-sampling</code>，前者是增加样本数较少的样本，其方式是直接复制原来的样本，而后者是减少样本数较多的样本，其方式是丢弃这些多余的样本。</p>
<p>通常来说，当总样本数目较多的时候考虑
<code>under-sampling</code>，而样本数数目较少的时候考虑
<code>over-sampling</code>。</p>
<p>关于数据采样更详细的内容可参考 <a
href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis">Oversampling
and undersampling in data analysis</a></p>
<h2 id="合成样本">合成样本</h2>
<p>合成样本(Synthetic
Samples)是为了增加样本数目较少的那一类的样本，合成指的是通过组合已有的样本的各个
feature 从而产生新的样本。</p>
<p>一种最简单的方法就是从各个 feature
中随机选出一个已有值，然后拼接成一个新的样本，这种方法增加了样本数目较少的类别的样本数，作用与上面提到的
<code>Over-sampling</code>
方法一样，不同点在于上面的方法是单纯的复制样本，而这里则是拼接得到新的样本。</p>
<p>这类方法中的具有代表性的方法是 SMOTE（Synthetic Minority
Over-sampling Technique），这个方法通过在相似样本中进行 feature
的随机选择并拼接出新的样本。</p>
<p>关于 SMOTE 更详细的信息可参考论文 <a
href="http://www.jair.org/papers/paper953.html">SMOTE: Synthetic
Minority Over-sampling Technique</a></p>
<h2 id="改变样本权重">改变样本权重</h2>
<p>改变样本权重指的是<strong>增大样本数较少类别的样本的权重</strong>，当这样的样本被误分时，其损失值要乘上相应的权重，从而让分类器更加关注这一类数目较少的样本。</p>
<p>参考：</p>
<p><a
href="http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/">8
Tactics to Combat Imbalanced Classes in Your Machine Learning
Dataset</a> <a
href="https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set">In
classification, how do you handle an unbalanced training set?</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中模型优化不得不思考的几个问题</title>
    <url>/2017/05/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E4%B8%8D%E5%BE%97%E4%B8%8D%E6%80%9D%E8%80%83%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>文章为转载，原文链接在<a
href="http://tech.meituan.com/machine-learning-model-optimization.html">这里</a>，文章从业界的角度出发介绍了机器学习如何发挥其价值，非常接地气，值得一看，以下为原文</p>
<span id="more"></span>
<h2 id="机器学习工程师的知识图谱">机器学习工程师的知识图谱</h2>
<p><img src="https://wulc.me/imgs/image_1bgvc1hi3led5tl1hb0n1i1hhm9.png"
alt="机器学习工程师的知识图谱" /> 图1 机器学习工程师的知识图谱</p>
<p>图1列出了我认为一个成功的机器学习工程师需要关注和积累的点。机器学习实践中，我们平时都在积累自己的“弹药库”：分类、回归、无监督模型、Kaggle上面特征变换的黑魔法、样本失衡的处理方法、缺失值填充……这些大概可以归类成<strong>模型和特征两个点</strong>。我们需要参考成熟的做法、论文，并自己实现，此外还需要多反思自己方法上是否还可以改进。如果模型和特征这两个点都已经做得很好了，你就拥有了一张绿卡，能跨过在数据相关行业发挥模型技术价值的准入门槛。</p>
<p><strong>在这个时候，比较关键的一步，就是高效的技术变现能力</strong>。</p>
<p>所谓高效，就是解决业务核心问题的专业能力。本文将描述这些专业能力，也就是模型优化的四个要素：模型、数据、特征、业务，还有更重要的，就是它们在模型项目中的优先级。</p>
<h2 id="模型项目推进的四要素">模型项目推进的四要素</h2>
<p><strong>项目推进过程中，四个要素相互之间的优先级大致是：业务&gt;特征&gt;数据&gt;模型</strong>。</p>
<p><img
src="https://wulc.me/imgs/image_1bgvc94uuh0c1o0sj9d1urb19d2m.png"
alt="四要素解决问题细分+优先级" /> 图2 四要素解决问题细分+优先级</p>
<h3 id="业务">业务</h3>
<p>一个模型项目有好的技术选型、完备的特征体系、高质量的数据一定是很加分的，不过真正决定项目好与坏还有一个大前提，就是这个项目的技术目标是否在解决当下核心业务问题。</p>
<p>业务问题包含两个方面：业务KPI和deadline。举个例子，业务问题是在两周之内降低目前手机丢失带来的支付宝销赃风险。这时如果你的方案是研发手机丢失的核心特征，比如改密是否合理，基本上就死的很惨，因为两周根本完不成，改密合理性也未必是模型优化好的切入点；反之，如果你的方案是和运营同学看
bad
case，梳理现阶段的作案通用手段，并通过分析上线一个简单模型或者业务规则的补丁，就明智很多。如果上线后，案件量真掉下来了，就算你的方案准确率很糟、方法很low，但你解决了业务问题，这才是最重要的。</p>
<p>虽然业务目标很关键，不过一般讲，业务运营同学真的不太懂得如何和技术有效的沟通业务目标，比如：</p>
<ol type="1">
<li>我们想做一个线下门店风险评级的项目，希望运营通过反作弊模型角度帮我们给门店打个分，这个分数包含的问题有：风险是怎么定义的、为什么要做风险评级、更大的业务目标是什么、怎么排期的、这个风险和我们反作弊模型之间的业务关系你是怎么看的？</li>
<li>做一个区域未来10min的配送时间预估模型。我们想通过运营的模型衡量在恶劣天气的时候每个区域的运力是否被击穿（业务现状和排期？运力被击穿可以扫下盲么？运力击穿和配送时间之间是个什么业务逻辑、时间预估是刻画运力紧张度的最有效手段么？项目的关键场景是恶劣天气的话，我们仅仅训练恶劣天气场景的时间预估模型是否就好了？）。</li>
</ol>
<p>为了保证整个技术项目没有做偏，项目一开始一定要和业务聊清楚三件事情：</p>
<p><strong>1. 业务核心问题、关键场景是什么。</strong></p>
<p><strong>2. 如何评估该项目的成功，指标是什么。</strong></p>
<p><strong>3.
通过项目输出什么关键信息给到业务，业务如何运营这个信息从而达到业务目标。</strong></p>
<p>项目过程中，也要时刻回到业务，检查项目的健康度。</p>
<h3 id="数据与特征">数据与特征</h3>
<p>要说<strong>正确的业务理解和切入，在为技术项目保驾护航，数据、特征便是一个模型项目性能方面的天花板。garbage
in， garbage out 就在说这个问题</strong>。</p>
<p>这两天有位听众微信问我一个很难回答的问题，大概意思是，数据是特征拼起来构成的集合嘛，所以这不是两个要素。从逻辑上面讲，数据的确是一列一列的特征，不过数据与特征在概念层面是不同的：数据是已经采集的信息，特征是以兼容模型、最优化为目标对数据进行加工。就比如通过word2vec将非结构化数据结构化，就是将数据转化为特征的过程。</p>
<p>所以，我更认为特征工程是基于数据的一个非常精细、刻意的加工过程。<strong>从传统的特征转换、交互，到embedding、word2vec、高维分类变量数值化，最终目的都是更好的去利用现有的数据。</strong>之前有聊到的将推荐算法引入有监督学习模型优化中的做法，就是在把两个本不可用的高维ID类变量变成可用的数值变量。</p>
<p>观察到自己和童鞋们在特征工程中会遇到一些普遍问题，比如，特征设计不全面，没有耐心把现有特征做得细致……也整理出来一套方法论，仅供参考：</p>
<p><img
src="https://wulc.me/imgs/image_1bgvcqct213oq6ingm1v1c1eti13.png"
alt="变量体系、研发流程" /> 图3 变量体系、研发流程</p>
<p>在特征设计的时候，有两个点可以帮助我们把特征想的更全面：</p>
<p><strong>1. 现有的基础数据</strong> <strong>2.
业务“二维图”</strong></p>
<p>这两个方面的整合，就是一个变量的体系。变量（特征），从技术层面是加工数据，而从业务层面实际在反应RD的业务理解和数据刻画业务能力。“二维图”，实际上未必是二维的，更重要的是我们需要把业务整个流程抽象成几个核心的维度，举几个例子：</p>
<p>外卖配送时间业务（维度甲：配送的环节，骑手到点、商家出餐、骑手配送、交付用户；维度乙：颗粒度，订单粒度、商家粒度、区域城市粒度；维度丙：配送类型，众包、自营……）。</p>
<p>反作弊变量体系（维度甲：作弊环节，登录、注册、实名、转账、交易、参与营销活动、改密……；维度乙：作弊介质，账户、设备、IP、WiFi、银行卡……）。</p>
<p><strong>通过这些维度，你就可以展开一个“二维图”，把现有你可以想到的特征填上去，你一定会发现很多空白，</strong>比如下图，那么哪里还是特征设计的盲点就一目了然：</p>
<p><img
src="https://wulc.me/imgs/image_1bgvcvkkqo0q1kgt15qjdv54jm1g.png"
alt="特征问题" /> 图4
账户维度在转账、红包方面的特征很少；没有考虑WiFi这个媒介；客满与事件数据没考虑</p>
<p>数据和特征决定了模型性能的天花板。deep
learning当下在图像、语音、机器翻译、自动驾驶等领域非常火，但是 deep
learning在生物信息、基因学这个领域就不是热词：这背后是因为在前者，我们已经知道数据从哪里来，怎么采集，这些数据带来的信息基本满足了模型做非常准确的识别；而后者，即便有了上亿个人体碱基构成的基因编码，技术选型还是不能长驱直入——超高的数据采集成本，人后天的行为数据的获取壁垒等一系列的问题，注定当下这个阶段在生物信息领域，人工智能能发出的声音很微弱，更大的舞台留给了生物学、临床医学、统计学。</p>
<h3 id="模型">模型</h3>
<p><img
src="https://wulc.me/imgs/image_1bgvd7gs41k9e1g0s1d016dmdq1t.png"
alt="模型" /> 图5 满房开房的技术选型、特征工程roadmap</p>
<p><strong>模型这件事儿，许多时候追求的不仅仅是准确率，通常还有业务这一层更大的约束。如果你在做一些需要强业务可解释的模型，比如定价和反作弊，那实在没必要上一个黑箱模型来为难业务。这时候，统计学习模型就很有用。</strong></p>
<p>这种情况下，比拼性能的话，我觉得下面这个不等式通常成立：<code>Glmnet&gt;LASSO&gt;=Ridge&gt;LR/Logistic</code>。相比最基本的LR/Logistic，ridge通过正则化约束缓解了LR在过拟合方面的问题，lasso更是通过L1约束做类似变量选择的工作。</p>
<p>不过<strong>两个算法的痛点是很难决定最优的约束强度，Glmnet是Stanford给出的一套非常高效的解决方案。</strong>所以目前，我认为线性结构的模型，Glmnet的痛点是最少的，而且在R、Python、Spark上面都开源了。</p>
<p>如果我们开发复杂模型，通常成立第二个不等式
<code>RF（Random Forest，随机森林）&lt;= GBDT &lt;= XGBoost</code>
。拿数据说话，29个Kaggle公开的winner
solution里面，17个使用了类似GBDT这样的Boosting框架，其次是 DNN（Deep
Neural Network，深度神经网络），RF的做法在Kaggle里面非常少见。</p>
<p>RF和GBDT两个算法的雏形是CART（Classification And Regression
Trees），由L Breiman和J
Friedman两位作者在1984年合作推出。但是在90年代在发展模型集成思想the
ensemble的时候，两位作者代表着两个至今也很主流的派系：stacking/ Bagging
&amp; Boosting。</p>
<p><strong>一种是把相互独立的CART（randomized variables，bootstrap
samples）水平铺开，一种是深耕的Boosting，在拟合完整体后更有在局部长尾精细刻画的能力。</strong>同时，GBDT模型相比RF更加简单，内存占用小，这都是业界喜欢的性质。XGBoost在模型的轻量化和快速训练上又做了进一步的工作，也是目前我们比较喜欢尝试的模型。</p>
<p>作者简介
胡淏，美团算法工程师，毕业于哥伦比亚大学。先后在携程、支付宝、美团从事算法开发工作。了解风控、基因、旅游、即时物流相关问题的行业领先算法方案与流程。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石--PLA</title>
    <url>/2017/02/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3--PLA/</url>
    <content><![CDATA[<p>本文是《机器学习基石》第二讲 <code>Learning to Answer Yes/No</code>
课程的笔记。主要介绍了机器学习的基本概念，以及感知机及其训练算法
PLA。</p>
<span id="more"></span>
<h2 id="机器学习的基本概念">机器学习的基本概念</h2>
<p>该讲以根据客户的特征来决定是否给客户发放信用卡的例子引出了机器学习要解决的问题：对于我们的问题，存在着一个未知的理想目标函数
<span class="math inline">\(f\)</span>
能够满足我们的决策需求(在该例子中就是根据给定用户的特征，输出是否给用户发放信用卡)，但是这个函数是未知的，我们只能从观测到的数据集
<span class="math inline">\(D\)</span> 中通过算法 <span
class="math inline">\(A\)</span> 提取出一个近似的函数 <span
class="math inline">\(g\)</span> 来逼近理想的目标函数 <span
class="math inline">\(f\)</span>。而当选定了算法 <span
class="math inline">\(A\)</span> 后，选取 <span
class="math inline">\(g\)</span> 的集合 <span
class="math inline">\(H\)</span>
实际上也确定了(例如目标函数是线性或非线性的)。</p>
<p>下图展示了上面提到的过程</p>
<figure>
<img src="https://wulc.me/imgs/image_1bchr55ih1ie1u9e8tjqi1ttv9.png"
alt="机器学习基本概念" />
<figcaption aria-hidden="true">机器学习基本概念</figcaption>
</figure>
<p>从上面概括了关于机器学习中的基本过程。但是在实际中通过机器学习解决问题的过程往往是的论述可知，机器学习中首先需要确定目前的一个问题，然后根据问题提出假设并依照假设去搜集数据，然后对数据进行特征提取、转换等，接着尝试通过不同算法去建模并验证。在这门课程中往往更关心数据特征的提取以及不同算法的研究，这固然很重要，但是实际中确认问题以及搜集相应的数据也是一个非常重要的步骤，不可忽视。</p>
<p>下面要介绍这门课程的第一个算法：</p>
<h2 id="感知机">感知机</h2>
<p>感知机是神经网络的基础，与线性回归（Linear
Regression），逻辑回归（Logistics
Regression）等模型也非常类似，是一种非常典型的线性模型。</p>
<p>原始的感知机算法用于解决二分类问题，其思想如下：假设样本有 <span
class="math inline">\(d\)</span>
个特征，但是每个特征的重要性不一样，因此各个特征的权重也不一样，对其进行加权后得到的总和假如大于某个阈值则认为归为其中一类，反之归为另一类。如在信用卡的例子中，通过感知机有如下的结果</p>
<figure>
<img src="https://wulc.me/imgs/image_1bchsh08i1b382mv1la0qnbrd4m.png"
alt="感知机的信用卡发放问题" />
<figcaption aria-hidden="true">感知机的信用卡发放问题</figcaption>
</figure>
<p>将上面的化为常数项，即可将得到更一般的表达形式如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bchsm6t3q8812aes38a7327513.png"
alt="感知机更一般表示" />
<figcaption aria-hidden="true">感知机更一般表示</figcaption>
</figure>
<p>上面的 <span class="math inline">\(w\)</span> 和 <span
class="math inline">\(x\)</span> 均是一个列向量。</p>
<h3 id="pla">PLA</h3>
<p>上面只是说明了感知机这一算法的基本模型，但是感知机还要通过学习才能对样本进行正确的分类，这个学习的过程就是我们下面要讲的
PLA(Perceptron Learning Algorithm)。PLA的过程如下</p>
<p>1）随机初始化参数 <span class="math inline">\(w\)</span> 2）利用参数
<span class="math inline">\(w\)</span>
预测每个样本点的值并与其实际的值比较，对于分类错误的样本点<span
class="math inline">\((x\_n, y\_n)\)</span>，利用公式 <span
class="math inline">\(w = w + y\_nx\_n\)</span> 更新参数 <span
class="math inline">\(w\)</span> 的值
3）重复上面的过程直到所有的样本点都能够被参数 <span
class="math inline">\(w\)</span> 正确预测。</p>
<p>对于某个被预测错误的样本点，参数 <span
class="math inline">\(w\)</span> 更新的过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bci20m5k1riicdhcvefunsm1g.png"
alt="参数w在错误点的更新" />
<figcaption aria-hidden="true">参数w在错误点的更新</figcaption>
</figure>
<p>注意上面的算法的前提是所有的样本点都必须线性可分，假如样本点线性不可分，那么PLA按照上面的规则会陷入死循环中。如下是线性可分与线性不可分的例子)</p>
<figure>
<img src="https://wulc.me/imgs/2017-03-29_231245.png"
alt="线性可分与不可分的例子" />
<figcaption aria-hidden="true">线性可分与不可分的例子</figcaption>
</figure>
<h3 id="收敛性">收敛性</h3>
<p>上面提到只有当所有的样本均为线性可分时，PLA才能将所有的样本点正确分类后再停下了，但是这仅仅是定性的说明而已，并没有严格的数学正面来支撑其收敛性，下面要讲的便是通过数学证明来说明
PLA 算法的收敛性。</p>
<p>建议中通过下面两页PPT来说明PLA的收敛性</p>
<figure>
<img src="https://wulc.me/imgs/image_1bci2dhjhiped441fb616lk1pbi1t.png"
alt="PLA收敛性1" />
<figcaption aria-hidden="true">PLA收敛性1</figcaption>
</figure>
<p>上面讲的是随着参数 <span class="math inline">\(w\)</span>
的更新，<span class="math inline">\(w\_f^Tw\_{t+1}\)</span>
的值越来越大，也就是两者越来越相似（衡量两个向量相似性的一种方法就是考虑他们的内积，值越大，代表两者约接近，但是这里还没对向量归一化，所以证明并不严格，但是已经说明了两者具有这个趋势，下面是更严格的过程）</p>
<figure>
<img src="https://wulc.me/imgs/image_1bci2ebjrhvl5tchtk3er1qej2a.png"
alt="PLA收敛性2" />
<figcaption aria-hidden="true">PLA收敛性2</figcaption>
</figure>
<p>上面似乎只是说明了经过 T 次的纠错，<span
class="math inline">\(w\_t\)</span>
的值会限制在一个范围内，但是并没有给出最终结论 <span
class="math display">\[\frac{w\_f}{||w\_f|| }\frac{w\_T}{||w\_T||} \ge
\sqrt{T} *
constant\]</span>的证明过程，因此这里对其推导过程进行描述。(注：这里的
<span class="math inline">\(w\_f\)</span> 是不变的，因此 <span
class="math inline">\(w\_f\)</span> 与 <span
class="math inline">\(w\_f^T\)</span> 是一样的)</p>
<p>假设经过了 T 次纠错，那由第一张PPT可知 <span
class="math display">\[w\_f^Tw\_T \ge w\_f^Tw\_{T-1} + \min\_n
y\_nw\_f^Tx\_n \ge T\min\_n y\_nw\_f^Tx\_n\]</span></p>
<p>而由第二张PPT可知</p>
<p><span class="math display">\[||w\_T||^2 \le ||w\_{T-1}||^2 +
\max\_n||x\_n||^2 \le T\max\_n||x\_n||^2\\
||w\_T|| \le \sqrt{T} \max\_n||x\_n||\]</span></p>
<p>综合上面的两条式子有</p>
<p><span
class="math display">\[\frac{w\_f^T}{||w\_f^T||}\frac{w\_T}{||w\_T||}
\ge \frac{T\min\_n y\_n^Tw\_f^Tx\_n}{||w\_f^T||\sqrt{T} \max\_n||x\_n||}
= \sqrt{T} \frac{\min\_n
y\_n\frac{w\_f^T}{||w\_f^T||}x\_n}{\max\_n||x\_n||} = \sqrt{T} *
constant\]</span></p>
<p>因此上面的命题得证。至此，已经可知道犯错误的次数 T
是受到某个上限的约束的。下面会给出这个具体的上限是多少。</p>
<p>又因为 <span class="math display">\[1 \ge
\frac{w\_f^T}{||w\_f^T||}\frac{w\_T}{||w\_T||} \ge \sqrt{T} *
constant\\\
\frac{1}{constant^2} \ge T\]</span></p>
<p>即犯错的次数的上限为 $ $, 假设令 <span class="math display">\[
\max\_n||x||^2 = R^2, \rho = \min\_n
y\_n\frac{w\_f^T}{||w\_f^T||}x\_n\]</span> 则有 <span
class="math display">\[T \le \frac{R^2}{\rho^2}\]</span></p>
<p>这也说明了PLA会在有限步内收敛，而这也是后面的练习题里面的答案。</p>
<h3 id="优缺点及改进">优缺点及改进</h3>
<p>PLA
的优点和缺点都非常明显，其中优点是简单，易于实现，但是缺点是假设了数据是线性可分的，然而事先并无法知道数据是否线性可分的。正如上面提到的一样，假如将PLA
用在线性不可分的数据中时，会导致PLA永远都无法对样本进行正确分类从而陷入到死循环中。</p>
<p>为了避免上面的情况，将 PLA
的条件放宽一点，不再要求所有的样本都能正确地分开，而是要求犯错的的样本尽可能的少，即将问题变为了<span
class="math display">\[arg\min\_w \sum\_{n=1}^{N} 1\lbrace y\_n \ne
sign(w^Tx\_n) \rbrace\]</span></p>
<p>这个最优化问题是个 NP-hard
问题，无法求得其最优解，因此只能求尽可能接近其最优解的近似解。讲义中提出的一种求解其近似解的算法
<code>Pocket Algorithm</code>。其思想就是每次保留当前最好的 <span
class="math inline">\(w\)</span>, 当遇到错误的样本点对 <span
class="math inline">\(w\)</span> 进行修正后，比较修正后的<span
class="math inline">\(w\)</span> 与原来最好的 <span
class="math inline">\(w\)</span>
在整个样本点上的总体效果再决定保留哪一个，重复迭代足够多的次数后返回当前得到的最好的
<span class="math inline">\(w\)</span>。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石--学习的可行性</title>
    <url>/2017/02/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3--%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<p>本文是《机器学习基石》第四讲 <code>Feasibility of Learning</code>
的课程笔记。通过 <a
href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoeffding
不等式</a>，引出了机器学习中学习的可行性。</p>
<span id="more"></span>
<p>刚刚接触机器学习的时候，往往会被各种机器学习算法搞得昏头涨脑，却往往忽略了一个问题：那就是机器学习中的“学习”二字到底指的是什么，或者说机器为什么能够学习，到底学到了什么东西？</p>
<p>要回答这个问题，首先要确认一个大前提：<strong>数据集（包括训练集和测试集）是从相同分布中产生的，也就是说产生数据的环境应该是一致的，否则假如训练集与数据集的产生方式不一样，那么从训练集中是不可能学习到训练集中相关的知识的</strong></p>
<p>有了上面这个大前提，从概率论的角度来讲，机器学习学的就是这个概率分布，；或者说是模式识别中的模式（pattern）；然后用学习到的概率分布去预测未见过但是也是在这个概率分布下产生的样本，这样一来，便称机器能够“学习”了。</p>
<p>下面的内容便是将这一过程通过数学来严谨化</p>
<h2 id="hoeffding-不等式">Hoeffding 不等式</h2>
<p>为了引入 Hoeffding
不等式，首先来看一下概率论中一个简单的例子：假如一个罐子中有绿色和橙色两种弹珠，现在想知道罐子中橙色弹珠的比例，该怎么做？</p>
<p>最直观的方法就是将罐子中所有的弹珠分类并计数，然后计算橙色弹珠的比例。但是当罐子中的弹珠数目变得很大的时候，在实际中显然是无法将所有弹珠都数一遍。</p>
<p>这时便需要进行抽样并从抽出的样本（sample）中估计橙色弹珠的比例，但是抽样一定会带来一定的误差的，而且直观上来看，抽样的样本数目越多，误差越小。而
Hoeffding
不等式就是描述这个误差跟抽样数目的关系，假如橙色弹珠的真实比例为 <span
class="math inline">\(\mu\)</span> , 而从样本中估计出的比例为 <span
class="math inline">\(\nu\)</span>， 样本大小为 <span
class="math inline">\(N\)</span>, 则对应的 Hoeffding 不等式如下</p>
<p><span class="math display">\[p(|\nu - \mu| \gt \epsilon) \le
2\exp(-2\epsilon^2N)\]</span></p>
<p>上式中的 <span class="math inline">\(\epsilon\)</span>
表示允许的误差范围</p>
<h2 id="从-hoeffding-不等式到机器学习">从 Hoeffding
不等式到机器学习</h2>
<p>假如将上面的罐子中的一个弹珠抽象为机器学习中的一个样本，考虑一个二分类问题，绿色弹珠表示样本标签与我们的模型
<span class="math inline">\(h\)</span>
预测出的标签一致，而橙色弹珠则表示样本标签与预测标签不一致。则橙色弹珠的比例就是模型
<span class="math inline">\(h\)</span> 的错误率。同时将模型 <span
class="math inline">\(h\)</span> 在全部弹珠中的错误率记为 <span
class="math inline">\(E\_{out}(h)\)</span>, 而在样本中的错误率记为 <span
class="math inline">\(E\_{in}(h)\)</span>，则根据 Hoeffding 不等式有</p>
<p><span class="math display">\[p(|E\_{in}(h) - E\_{out}(h)| \gt
\epsilon) \le 2\exp(-2\epsilon^2N)\]</span></p>
<p>也就是说，<strong>训练样本的数目越大，<span
class="math inline">\(E\_{in}(h)\)</span> 和 <span
class="math inline">\(E\_{out}(h)\)</span>，
也就是训练误差和泛化误差越接近。</strong></p>
<p>这一等式实际上代表了 <a
href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">PAC</a>
(probaly approximately correct) 学习理论中的 probably 部分，PAC
理论简单描述如下(摘自 Wikipedia)</p>
<blockquote>
<p>In this framework, the learner receives samples and must select a
generalization function (called the hypothesis) from a certain class of
possible functions. The goal is that, with high probability (the
"probably" part), the selected function will have low generalization
error (the "approximately correct" part).</p>
</blockquote>
<p>上面的 Hoeffding
不等式只是说明了训练误差和泛化误差可以很接近，但是这一接近必须要在训练误差也就是
<span class="math inline">\(E\_{in}(h)\)</span>
很小的情况下才有意义，否则大的训练误差就有大的范化误差，而大的范化误差的模型实际上是没有意义的。而小的训练误差对应到
PAC 中的 AC(approximately correct) 部分。</p>
<h2 id="从一个-hyposthesis-到多个-hypothesis">从一个 hyposthesis 到多个
hypothesis</h2>
<p>上面的 Hoeffding 不等式描述的是一个 hypothesis 也就是一个 <span
class="math inline">\(h\)</span> 的情况，但是实际中往往有多个 hypothesis
可选，这个时候的 Hoeffding 不等式又会变成怎样？</p>
<p>首先回顾一下单个 <span class="math inline">\(h\)</span> 的 Hoeffding
不等式，它告诉我们下面这个事情发生的概率很大：<strong><span
class="math inline">\(h\)</span>
在抽取的样本上得到的样本误差（也就是训练误差）跟 <span
class="math inline">\(h\)</span>
的总体误差（也就是泛化误差）很接近。</strong></p>
<p>从另一个角度来讲，也就是说还是有很小的概率抽出一些样本，使得 <span
class="math inline">\(h\)</span>
在样本上得到的误差与其在总体上得到的误差相差很大（实际上就是抽出的样本不能很好反映总体），讲义中将这部分的
sample 称为 bad data，就是使得 <span class="math inline">\(h\)</span> 的
<span class="math inline">\(E\_{in}(h)\)</span>很小，<span
class="math inline">\(E\_{out}(h)\)</span>
很大的样本。如下图所示，如果进行多次抽样，那么肯定有一些样本会导致 <span
class="math inline">\(E\_{in}(h)\)</span>和 <span
class="math inline">\(E\_{out}(h)\)</span> 的差距较大。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bi8c9bsjveuio7id2ile1fo59.png"
alt="bad data for h" />
<figcaption aria-hidden="true">bad data for h</figcaption>
</figure>
<blockquote>
<p>注：这里 <span class="math inline">\(E\_{in}(h)\)</span> 很小，<span
class="math inline">\(E\_{out}(h)\)</span>
很大其实已经是我们常听到的过拟合现象，影响过拟合的因素有很多，而抽样的数据的分布是否能够代表整体数据的分布则是其中一个因素。下面是一个简单的例子：对于一个高斯分布产生的数据，如果抽样数据是图中的黑色点，那么拟合出来的曲线可能是图中的黑线，也就是说假如抽样数据的分布如果跟原始数据分布不一致，我们的模型拟合了抽样的数据，对于原始数据而言，自然没有预测能力，也就是<span
class="math inline">\(E\_{in}(h)\)</span> 很小，<span
class="math inline">\(E\_{out}(h)\)</span>
很大，可以说是过拟合了抽样的数据。</p>
</blockquote>
<figure>
<img src="https://wulc.me/imgs/gaussian_distribution.png"
alt="gaussian_distribution.png-32.7kB" />
<figcaption
aria-hidden="true">gaussian_distribution.png-32.7kB</figcaption>
</figure>
<p>回到讨论的话题，如果对于 <span class="math inline">\(M\)</span>
个hypothesis 呢？上图可以改为如下形式</p>
<figure>
<img src="https://wulc.me/imgs/image_1bi8cdsrpdstglac2pbkl1jqim.png"
alt="bad data for many h" />
<figcaption aria-hidden="true">bad data for many h</figcaption>
</figure>
<p>在上图中，由于每个 hypothesis 都不同，因此对各个 hypothesis 而言其
bad data 也不同，只有<strong>当样本对各个 hypothesis 而言都不是 bad
的时候，才不会泛化误差和训练误差差距很大的情况</strong>。在有 <span
class="math inline">\(M\)</span> 个 hypothesis 的时候，用 Hoeffding
不等式表示选择了 bad data 的概率为</p>
<figure>
<img
src="https://wulc.me/imgs/image_1bi8fediq174f1egd1s8l1jl217is13.png"
alt="Hoeffding 对多个不等式的情况" />
<figcaption aria-hidden="true">Hoeffding 对多个不等式的情况</figcaption>
</figure>
<p>上面的不等式表明，对于有限多个 hypothesis 而言，<span
class="math inline">\(E\_{in}(h) \approx E\_{out}(h)\)</span> 还是 PAC
的，只是两者误差的 upper bound 变大了，但是数据量 <span
class="math inline">\(N\)</span> 的增大能够抵消这一影响。</p>
<p>在上面的前提下，在有多个 hypothesis 的情况下，只需要选择 <span
class="math inline">\(E\_{in}(h)\)</span> 小的，就能拿保证 <span
class="math inline">\(E\_{out}(h)\)</span>
也是小的，也就是学习是可行的。</p>
<h2 id="小结">小结</h2>
<p>本文主要是通过 Hoeffding 不等式证明了<strong>当模型的所有 hypothesis
的个数 <span class="math inline">\(M\)</span> 为有限个时，样本数目 <span
class="math inline">\(N\)</span> 足够大时，就能够保证泛化误差 <span
class="math inline">\(E\_{out}(h)\)</span> 和训练误差 <span
class="math inline">\(E\_{in}(h)\)</span> 很接近。</strong></p>
<p>这时候只要找到一个 hypothesis 使得 <span
class="math inline">\(E\_{in}(h)\)</span> 很小，那么 <span
class="math inline">\(E\_{out}(h)\)</span>
也会很小，从而达到学习的目的。</p>
<p>当然有一个大前提就是训练样本和测试样本必须要在同一分布下产生，否则学习无从谈起。</p>
<p>上面的内容可通过下图进行描述</p>
<figure>
<img src="https://wulc.me/imgs/image_1bibltpvd144k7me1e2b1elinct18.png"
alt="模型图" />
<figcaption aria-hidden="true">模型图</figcaption>
</figure>
<p>但是还有一个问题，就是实际中某个模型空间里的 hypothesis
往往是无限多个的，这种情况下又该如何通过数学描述？这部分内容将在后面讲述。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基石--机器学习的分类</title>
    <url>/2017/02/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3--%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>本文是《机器学习基石》第三讲 <code>Types of Learning</code>
课程的笔记。主要概括性介绍了机器学习的几个分类标准及其具体分类。</p>
<span id="more"></span>
<h2 id="根据输出来分">根据输出来分</h2>
<p>根据模型输出来对机器学习分类是最常见的分类方法，往往可以分为回归（regression）和分类（classification）两大问题，而根据类比数量的不同，分类问题又往往又有二分类和多分类两种。</p>
<p>除了分类和回归，讲义中还提到了一种
<code>Structured Learning</code>,这一类型的输出的信息之间有结构化的信息。如输入
"I love ML",
输出该句子中各个词对应的词性（如PVN，PVP，NVN等），可以粗略将其看作是一个多分类问题，只是这个多分类问题的类别非常多且类比没有明确的定义。用到这一类型学习方法的例子还包括语音识别（语音-&gt;句子）等</p>
<h2 id="根据样本来分">根据样本来分</h2>
<p>根据给出的样本是否有标记对机器学习进行分类也是一种常见的分类方法，可分为有监督学习（supervised），无监督学习（unsupervised）和半监督学习（semi-supervised）。</p>
<p>有监督学习就是除了给出样本的属性 <span
class="math inline">\(x\)</span> 外，还给出了样本的标记 <span
class="math inline">\(y\)</span>,这个标记可以是样本的分类等。常见的分类、回归等一般都是有监督学习。</p>
<p>而无监督学习则是只给出给出样本的属性 <span
class="math inline">\(x\)</span>，让后要求找出这些样本内在属性及联系。其代表的应用是聚类，如给出若干无标记的文章，根据其主题将其聚成不同的类，最常见的聚类方法是K-Means，但是解决文本聚类问题一般通过主题模型，常见的有LSA，pLSA，LDA，HDP等；除此之外，无监督学习还应用到密度估计（density
estimation）中，如根据交通事故的发生地点做密度估计，从而得到危险的地段，一般解决这类问题可通过混合高斯模型等；无监督学习还可应用在异常点检测（outlier
detection）中，例如从海量的用户日志中找到某个可疑的用户操作，解决这类问题的方法也有很多，比如通过PCA映射到低维度后通过可视化来找。</p>
<p>无监督学习解决了有监督学习中需要获取大量标记样本带来的困难，而半监督学习则是介于两者之间的一种方法。半监督学习主要考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题。如
<a
href="https://en.wikipedia.org/wiki/Active_learning_%28machine_learning%29">active
learning</a>
就是半监督学习的一种，其思想就是让机器标注数据然后对于有疑问的标记进行“提问”。</p>
<p>除了上面提到的三种的学习方法，讲义还提到了另外一种不那么明显依赖于样本的学习方法
<code>Reinforcement Learning</code>：强化学习(增强学习)，这种学习方法通过奖励或惩罚来训练当前的算法。常见的应用有机器人以及各种
AI Game（如AlphaGo，Fine Art等）</p>
<h2 id="根据训练方式来分">根据训练方式来分</h2>
<p>这里根据训练方式主要是指训练时数据的输入方式，根据数据是否一次性送入到模型中训练将其分为
batch learning 和 online learning。</p>
<p>batch learning 指数据整批输进去，训练出一个模型用于预测等。</p>
<p>而 online learning 指每次有新样本的时候就用来训练更新
hypothesis，常见的比如说有垃圾邮件分类系统，这里有两点需要注意：</p>
<p>一是这种方法往往是依赖于训练算法的，如 SGD 等就适用在 online learning
中，因为其每次重新训练只需要依靠新的样本即可，而其他一些算法如果要加入新的数据就需要将所有的数据重新进行训练，这样的算法如果用在
online learning 中的代价就太大了。</p>
<p>二是虽然说每次有新的样本就训练更新
hypothesis，但是也不是来一个就更新一下，这样的训练成本也很高，实际中往往是等样本数积累到一定数量的时候才对这一批进行一个训练和更新。就像
gradient descent 中的 mini-batch。</p>
<h2 id="根据输入来分">根据输入来分</h2>
<p>根据输入的样本的特征来分也可以分为下面三类（虽然这中分类方法并不常见）：concrete
features，raw feaures 和 abstract features。</p>
<p>concrete features
指输入的样本已经明确给出了其各种特征，如信用卡例子中顾客的各项资料等。</p>
<p>raw feaures
一般指图像或音频中的图像或声波，这些信息是原始的信号，需要进行一些转换才能使用。</p>
<p>abstract features 并没有一个严格定义，原讲义给出了KDDCup 2011
的例子：</p>
<blockquote>
<p>given previous (userid, itemid, rating) tuples, predict the rating
that some userid would give to itemid</p>
</blockquote>
<p>这种按照输入样本的 features
进行分类的方法在实际中并不常用，因为输入的样本往往是各种
features交杂在一起的，不同问题需要与其相应的 features
才能得到好的效果，features 对结果的影响比较大。因此机器学习中也产生了
feature engineering 一说。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度裁剪及其作用</title>
    <url>/2018/05/01/%E6%A2%AF%E5%BA%A6%E8%A3%81%E5%89%AA%E5%8F%8A%E5%85%B6%E4%BD%9C%E7%94%A8/</url>
    <content><![CDATA[<p>本文简单介绍梯度裁剪(gradient clipping)的方法及其作用，最近在训练 RNN
过程中发现这个机制对结果影响非常大。</p>
<span id="more"></span>
<p>梯度裁剪一般用于解决 梯度爆炸(gradient explosion)
问题，而梯度爆炸问题在训练 RNN 过程中出现得尤为频繁，所以训练 RNN
基本都需要带上这个参数。常见的 gradient clipping 有两种做法</p>
<ol type="1">
<li>根据参数的 gradient 的值直接进行裁剪</li>
<li>根据若干参数的 gradient 组成的 vector 的 L2 norm 进行裁剪</li>
</ol>
<p>第一种做法很容易理解，就是先设定一个 gradient 的范围如 (-1, 1), 小于
-1 的 gradient 设为 -1， 大于这个 1 的 gradient 设为 1.</p>
<p>第二种方法则更为常见，先设定一个 <code>clip_norm</code>,
然后在某一次反向传播后，通过各个参数的 gradient 构成一个
vector，计算这个 vector 的 L2 norm（平方和后开根号）记为
<code>LNorm</code>，然后比较 <code>LNorm</code> 和
<code>clip_norm</code> 的值，若 <code>LNorm</code> &lt;=
<code>clip_norm</code> 不做处理，否则计算缩放因子
<code>scale_factor</code> = <code>clip_norm</code>/<code>LNorm</code>
，然后令原来的梯度乘上这个缩放因子。<strong>这样做是为了让 gradient
vector 的 L2 norm 小于预设的 <code>clip_norm</code></strong>。</p>
<p>关于 gradient clipping 的作用可更直观地参考下面的图，没有gradient
clipping 时，若梯度过大优化算法会越过最优点。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cco5u3d51gu71jshkkohjb16li19.png"
alt="gradient clipping" />
<figcaption aria-hidden="true">gradient clipping</figcaption>
</figure>
<p>而在一些的框架中，设置 gradient clipping 往往也是在 Optimizer
中设置，如 tensorflow 中设置如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">gvs = optimizer.compute_gradients(cost)</span><br><span class="line">capped_gvs = [(tf.clip_by_value(grad, -<span class="number">1.</span>, <span class="number">1.</span>), var) <span class="keyword">for</span> grad, var <span class="keyword">in</span> gvs]</span><br><span class="line">train_op = optimizer.apply_gradients(capped_gvs)</span><br></pre></td></tr></table></figure>
<p>Keras 中设置则更为简单</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">optimizer = optimizers.SGD(lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>, clipnorm=<span class="number">1.</span>),</span><br></pre></td></tr></table></figure>
<p>除此之外，调试 RNN 是个比较 tricky 的活，可参考知乎上这个问题：<a
href="https://www.zhihu.com/question/57828011">你在训练RNN的时候有哪些特殊的trick？</a></p>
<p>另外，与 grdient explosion 相反的问题 gradient vanishing,
解决方法跟上面不同，不能简单地采用 scaling 的方法，具体可参考这个问题 <a
href="https://www.zhihu.com/question/275856902">梯度消失问题为什么不通过
gradient scaling 来解决？</a>，实际的处理方法一般是采用 LSTM 或 GRU
这类有记忆的 RNN 单元。</p>
<hr />
<p>参考：</p>
<ol type="1">
<li><a
href="https://hackernoon.com/gradient-clipping-57f04f0adae">Gradient
Clipping</a></li>
<li><a href="https://www.zhihu.com/question/29873016">caffe里的clip
gradient是什么意思？</a></li>
<li><a
href="https://www.quora.com/What-is-gradient-clipping-and-why-is-it-necessary">What
is gradient clipping and why is it necessary?</a></li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计知识整理(1)--一维随机变量的分布类型</title>
    <url>/2016/10/03/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86(1)--%E4%B8%80%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%88%86%E5%B8%83%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<p>本文主要讲述三种离散型随机变量的分布(伯努利分布,二项分布,泊松分布)和三种连续型随机变量的分布(均匀分布,指数分布,正态分布)。</p>
<span id="more"></span>
<h2 id="离散型随机变量的分布">离散型随机变量的分布</h2>
<h3 id="伯努利分布">伯努利分布</h3>
<p>伯努利分布又名<strong>两点分布</strong>或者<strong>0-1分布</strong>，只能取两种结果，一般记为0或1。设取1的概率为
<span class="math inline">\(p\)</span>，其分布规律为</p>
<p><span class="math inline">\(P(X=k) = p^k(1-p)^{1-k}, k = 0,1
(1&lt;p&lt;1)\)</span></p>
<p>如果试验E只有两种结果，则称试验E为<strong>伯努利试验</strong>。如果独立的进行
<span class="math inline">\(n\)</span>
次试验E，则称为<strong>n重伯努利试验</strong>。</p>
<h3 id="二项分布">二项分布</h3>
<p>以 <span class="math inline">\(X\)</span> 表示 <span
class="math inline">\(n\)</span> 重伯努利试验中事件 A 出现的次数，则
<span class="math inline">\(X\)</span> 为一个随机变量，令 <span
class="math inline">\(p\)</span> 为事件 A 出现的概率，则事件 <span
class="math inline">\(X\)</span> 服从以下分布：</p>
<p><span class="math inline">\(P(X=k) = C_n^k p^k q^{n-k}, k =
0,1,2,...,n\)</span></p>
<p>其中 <span class="math inline">\(q = 1-p\)</span>,则我们称 X
服从参数为 n,p 的二项分布，记为 <span
class="math inline">\(X\)</span>~<span
class="math inline">\(b(n,p)\)</span>。其概率和根据以下公式为1</p>
<p><span class="math inline">\(\sum\_{k=1}^nP(X=k) = \sum\_{k=1}^nC\_n^k
p^k q^{n-k} = (p+q)^n = 1\)</span></p>
<h3 id="泊松分布">泊松分布</h3>
<p><strong>随机变量 <span class="math inline">\(X\)</span>
的所有可能取值为 0,1,2,3....,且各个取值的概率为</strong></p>
<p><span class="math inline">\(P(X=k) = \frac
{\lambda^ke^{-\lambda}}{k!}, k=0,1,2....\)</span></p>
<p>则我们称 <span class="math inline">\(X\)</span> 服从参数为 <span
class="math inline">\(\lambda\)</span> 的泊松分布，记为 <span
class="math inline">\(X\)</span>~<span
class="math inline">\(\pi(\lambda)\)</span> 其中 <span
class="math inline">\(\lambda\)</span> 为 <span
class="math inline">\(X\)</span> 的期望，即 <span
class="math inline">\(E(X)\)</span></p>
<p>其分布规律通过图像直观表示为</p>
<p><img
src="https://wulc.me/imgs/image_1aubvjc3aa7i1ogehtl12vn1ger13.png" /></p>
<p>泊松分布适合于描述<strong>单位时间内随机事件发生的次数的概率分布</strong>。如某一服务设施在一定时间内受到的服务请求的次数，电话交换机接到呼叫的次数、汽车站台的候客人数、机器出现的故障数、自然灾害发生的次数、DNA序列的变异数、放射性原子核的衰变数等等。从上面的图像也可以看出，对于给定泊松分布的强度
<span class="math inline">\(\lambda\)</span>
,其在单位时间内发生的次数的概率有一个峰值，也就是说发生的次数很多或很少的可能性都不大，且当强度越大，其最大可能发生的次数的值也越大。</p>
<p>下面介绍<strong>用泊松分布来逼近二项分布的定理，也就是泊松定理。</strong></p>
<blockquote>
<p>泊松定理：设 <span class="math inline">\(\lambda &gt;
0\)</span>是一个常数，<span class="math inline">\(n\)</span>
是任意正整数，设 <span class="math inline">\(np =
\lambda\)</span>,则对于任一非负整数 <span
class="math inline">\(k\)</span>，有 <span
class="math display">\[\lim_{n \to \infty} C_n^kp^k(1-p)^{n-k} =
\frac{\lambda^ke^{-\lambda}}{k!}\]</span></p>
</blockquote>
<p>即<strong>当 <span class="math inline">\(n\)</span> 很大且 <span
class="math inline">\(p\)</span>
很小的时候，我们可以使用上面公式等号右边部分来逼近左边部分，从而简化计算。</strong></p>
<h2 id="连续型随机变量的分布">连续型随机变量的分布</h2>
<h3 id="分布函数和概率密度函数">分布函数和概率密度函数</h3>
<p>首先需要清楚，<strong>分布函数是针对随机变量的，离散或连续都可以；而概率密度函数是针对连续随机变量的</strong>。下面是这两者的定义以及联系</p>
<p><strong>分布函数的定义</strong>如下：</p>
<p><span class="math inline">\(X\)</span> 是一个随机变量，<span
class="math inline">\(x\)</span> 是任意实数，则 <span
class="math inline">\(X\)</span> 的分布函数定义为</p>
<p><span class="math inline">\(F(x) = P(X \le x),
(-\infty&lt;x&lt;\infty)\)</span></p>
<p>则对于任意实数 <span class="math inline">\(x\_1,x\_2(x\_1 &lt;
x\_2)\)</span>,有</p>
<p><span class="math inline">\(P(x\_1 &lt; X \le x\_2) = p(X \le x\_2) -
p(X \le x\_1) = F(x\_2) - F(x\_1)\)</span></p>
<p>即如果我们<strong>知道了 <span class="math inline">\(X\)</span>
的分布函数，则可以知道 <span class="math inline">\(X\)</span>
落在任一区间上的概率</strong>，也就是说通过分布函数可以完整描述随机变量的统计规律特性。</p>
<p><strong>概率密度函数定义</strong>如下：</p>
<p>对于分布函数 <span class="math inline">\(F(X)\)</span>，假如存在
<span class="math inline">\(f(x)\)</span> 使得以下公式成立：</p>
<p><span class="math inline">\(F(x) = \int\_{-\infty}^x f(t)
dt\)</span></p>
<p>则 X 为连续型随机变量，<span
class="math inline">\(f(x)\)</span>为随机变量的概率密度函数。<span
class="math inline">\(f(x)\)</span> 具有以下性质</p>
<ol type="1">
<li><p><span class="math inline">\(f(x) \ge 0\)</span></p></li>
<li><p><span class="math inline">\(\int\_{-\infty}^{\infty} f(x) dx =
1\)</span></p></li>
</ol>
<p>3.对于任意实数 <span class="math inline">\(x\_1,x\_2(x\_1 &lt;
x\_2)\)</span>，有<span class="math display">\[P(x\_1&lt; X \le x\_2) =
F(x\_2) - F(x\_1) = \int\_{x\_1}^{x\_2} f(x) dx\]</span></p>
<p>且当 <span class="math inline">\(f(x)\)</span> 在点 <span
class="math inline">\(x\)</span> 连续的时候，有</p>
<p><span class="math inline">\(F&#39;(x) = f(x)\)</span></p>
<p>通过上面这个性质可以推导出下面的约等式 <span
class="math inline">\(P(x &lt;X \le x+\Delta x) \approx f(x)\Delta
x\)</span></p>
<p>也就是说<strong>概率密度函数在某点的值的大小一定程度上反映了随机变量落在该点附近的概率的大小</strong>。</p>
<p>上面讲了<strong>随机变量的分布函数</strong>，下面讲一下<strong>随机变量的函数的分布函数</strong>，例如
<span class="math inline">\(X\)</span> 为一个随机变量，则 <span
class="math inline">\(Y = (X-1)^2\)</span> 是随机变量 <span
class="math inline">\(X\)</span> 的函数，且 <span
class="math inline">\(Y\)</span> 也是一个随机变量， 因此 <span
class="math inline">\(Y\)</span>
也有自己的分布律。下面是两个例子，其中一个是离散型随机变量，一个是连续型随机变量。</p>
<p><img
src="https://wulc.me/imgs/image_1aubr4om61a78q7m1kkp1doba8o9.png" /></p>
<p><img
src="https://wulc.me/imgs/image_1aubr9bv4jl71ou9cjfh2s1mulm.png" /></p>
<p>离散型随机变量的函数的分布律容易求，对于连续型随机变量的函数的分布律的求法一般是<strong>先按定义写出
<span class="math inline">\(Y\)</span> 的分布函数 <span
class="math inline">\(F(Y&lt;=y)\)</span>, 然后替换成 <span
class="math inline">\(F(g(X)&lt;=Y)\)</span>, 再转换成 <span
class="math inline">\(X\)</span> 的分布函数和概率密度函数。</strong></p>
<h3 id="均匀分布">均匀分布</h3>
<p>若随机变量 <span class="math inline">\(X\)</span>
的概率密度函数为</p>
<p><span class="math display">\[f(x) = \begin{cases}  \frac{1}{b-a}
&amp;{a&lt;x&lt;b} \\\ 0&amp;{其他}\end{cases}\]</span></p>
<p>则称X在区间 <span class="math inline">\((a,b)\)</span>
上服从均匀分布，记为 <span class="math inline">\(X\)</span>~<span
class="math inline">\(U(a,b)\)</span></p>
<h3 id="指数分布">指数分布</h3>
<p>若随机变量 <span class="math inline">\(X\)</span>
的概率密度函数为</p>
<p><span class="math display">\[f(x) =
\begin{cases}  \frac{1}{\theta}e^{-x / \theta} &amp;{x&gt;0} \\\
0&amp;{其他}\end{cases}\]</span></p>
<p>则称 <span class="math inline">\(X\)</span> 服从参数为 <span
class="math inline">\(\theta\)</span> 的指数分布。</p>
<p>其图像如下所示:</p>
<p><img
src="https://wulc.me/imgs/image_1auadnrfm1d6a1s11pfa24rtoh76.png" /></p>
<p>其分布函数为</p>
<p><span class="math display">\[F(x) = \begin{cases}  1-e^{-x / \theta}
&amp;{x&gt;0} \\\ 0&amp;{其他}\end{cases}\]</span></p>
<p><strong>如果说上面的泊松分布是描述某个时间段内事件发生次数的概率分布，那么指数分布描述的就是事件发生的时间间隔的概率分布</strong>。指数分布是连续的分布，反映在其实际意义上就是时间是连续的。更详细的描述可查看<a
href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">这里</a></p>
<p>关于指数分布的一个有趣的性质为：</p>
<p><span class="math inline">\(P(X&gt;s+t | X&gt;s) =
P(X&gt;t)\)</span></p>
<p>该性质也称为<strong>无记忆性</strong>，假设 <span
class="math inline">\(X\)</span>
是某一原件的寿命，上面的式子表示的就是该元件在使用了 s
个小时后，至少还能使用 t
个小时的条件概率。而这一条件概率又等于该元件从刚开始使用的算起至少能使用
t
个小时的概率。也就是说原件对使用过的s个小时无记忆性，这个特性与随机过程中的平稳过程非常相似，而这个特性也是指数分布有广泛应用的重要原因。</p>
<h3 id="正态分布">正态分布</h3>
<p>正态分布也叫高斯分布，其概率密度函数为</p>
<p><span class="math display">\[f(x) =
\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
<p>则称 <span class="math inline">\(X\)</span> 服从参数为 <span
class="math inline">\(\mu, \sigma\)</span> 的正态分布，记为<span
class="math inline">\(X\)</span>~<span
class="math inline">\(N(\mu,\sigma^2)\)</span>，而且 <span
class="math inline">\(\mu, \sigma\)</span>
分别是正态分布的期望和标准差。其图像如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1auaeaup2fe91u3t15l1i1214il8q.png" /></p>
<p>从图像可知，当$ X =
$时，取值最大，也就是说随机变量落在这个值附近的概率最大，而这个值也就是正态分布的期望。</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计知识整理(3)--随机变量的统计特征</title>
    <url>/2016/10/14/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86(3)--%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81/</url>
    <content><![CDATA[<p>随机变量的统计特征主要包括期望，方差，协方差以及相关系数。</p>
<span id="more"></span>
<h3 id="期望">期望</h3>
<p>离散型随机变量：<span class="math display">\[E(X) = \sum\_{k=1}^{
+\infty}p\_kx\_k\]</span></p>
<p>连续型随机变量：<span class="math display">\[E(X) = \int\_{-\infty}^{
+\infty} {xf(x)dx} \]</span></p>
<p>期望有以下性质(C为常数,其他均为随机变量):</p>
<p><span class="math inline">\(E(C) = C\)</span></p>
<p><span class="math inline">\(E(CX) = CE(X)\)</span></p>
<p><span class="math inline">\(E(X+Y) = E(X)+E(Y)\)</span></p>
<p>$E(XY) = E(X)E(Y) $ （<span class="math inline">\(X,Y\)</span>
相互独立）</p>
<p>前面讨论随机变量的分布函数时，同时讨论了随机变量的函数的分布函数，这里同样对于<strong>随机变量
<span class="math inline">\(X\)</span>
的函数的期望</strong>进行讨论，其定义及求法如下所示。</p>
<p>设Y是随机变量X的函数：<span
class="math inline">\(Y=g(X)\)</span>(g是连续函数)</p>
<ol type="1">
<li><p>如果 <span class="math inline">\(X\)</span>
是离散型随机变量，它的分布律为 <span class="math display">\[P(X=x\_k) =
p\_k, k = 1,2,...\]</span> 若 $_{k=1}^{}g(x_k)p_k $绝对收敛，则有 <span
class="math display">\[E(Y) = E[g(X)] = \sum\_{k=1}^{\infty}g(x\_k)p\_k
\]</span></p></li>
<li><p>如果 X 是连续型随机变量，它的概率密度函数为 <span
class="math inline">\(f(x)\)</span>, 若 <span
class="math inline">\(\int\_{-\infty}^{\infty}g(x)f(x)dx\)</span>
绝对收敛，则有 <span class="math display">\[E(Y) = E[g(X)] =
\int\_{-\infty}^{\infty}g(x)f(x)dx\]</span></p></li>
</ol>
<p>这个定理的重要意义在于求 <span class="math inline">\(E(Y)\)</span>
的时候，不用再求 Y 的分布律或概率密度函数，直接利用 X
的分布律或概率密度函数即可。</p>
<h3 id="方差">方差</h3>
<p>方差的原始定义为</p>
<p><span class="math inline">\(D(X) = E[(X-E(X))^2] = E(X^2) -
E(X)^2\)</span></p>
<p>方差有以下性质：</p>
<p><span class="math inline">\(D(C) = 0\)</span></p>
<p><span class="math inline">\(D(CX) = C^2D(X)\)</span></p>
<p>$D(X+Y) = D(X) + D(Y) + 2E([X-E(X)][Y-E(Y)]) $</p>
<p>如果 <span class="math inline">\(X，Y\)</span>
是相互独立的，那么<span class="math inline">\(E([X-E(X)][Y-E(Y)]) =
0\)</span>, 当这一项不为0的时候，称作变量 <span
class="math inline">\(X,Y\)</span> 的协方差。</p>
<h3 id="常见分布的期望和方差">常见分布的期望和方差</h3>
<p>前面我们提到了若干种典型的离散分布和连续分布，下面是这几种分布的期望和方差，记住这些常用的期望和方差能够在使用的时候省去推导过程。</p>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>分布类型</th>
<th>概率密度函数</th>
<th>期望</th>
<th>方差</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>伯努利分布~<span class="math inline">\(B(1,p)\)</span></td>
<td><span class="math inline">\(p = p^x(1-p)^{1-x}\)</span></td>
<td><span class="math inline">\(p\)</span></td>
<td><span class="math inline">\(p(1-p)\)</span></td>
</tr>
<tr class="even">
<td>二项分布~<span class="math inline">\(B(n,p)\)</span></td>
<td><span class="math inline">\(p\_i = C\_n^i
p^i(1-p)^{n-i}(i=1,2,3...)\)</span></td>
<td><span class="math inline">\(np\)</span></td>
<td><span class="math inline">\(np(1-p)\)</span></td>
</tr>
<tr class="odd">
<td>泊松分布~<span class="math inline">\(P(\lambda)\)</span></td>
<td>$p_i = (i = 1,2,3,) <span class="math inline">\(|\)</span><span
class="math inline">\(|\)</span>$</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>均匀分布~<span class="math inline">\(U(a,b)\)</span></td>
<td><span class="math inline">\(f(x) = \frac{1}{b-a}\)</span></td>
<td><span class="math inline">\(\frac{a+b}{2}\)</span></td>
<td><span class="math inline">\(\frac{(b-a)^2}{12}\)</span></td>
</tr>
<tr class="odd">
<td>正态分布~<span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td><span class="math inline">\(f(x) = \frac{1}{\sqrt{2\pi}\sigma}
e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
</tr>
<tr class="even">
<td>指数分布~<span class="math inline">\(E(\lambda)\)</span></td>
<td><span class="math display">\[f(x) = \begin{cases}  \lambda
e^{-x\lambda} &amp;{x&gt;0} \\\ 0&amp;{其他}\end{cases}\]</span></td>
<td><span class="math inline">\(\frac{1}{\lambda}\)</span></td>
<td><span class="math inline">\(\frac{1}{\lambda^2}\)</span></td>
</tr>
</tbody>
</table>
<h3 id="切比雪夫不等式">切比雪夫不等式</h3>
<p>切比雪夫不等式的定义如下：</p>
<blockquote>
<p>设随机变量 <span class="math inline">\(X\)</span> 具有数学期望 <span
class="math inline">\(E(X) = \mu\)</span>, 方差 <span
class="math inline">\(D(X) = \sigma^2\)</span>, 则对于任意正数 <span
class="math inline">\(\epsilon\)</span>, 下面的不等式成立<span
class="math display">\[P(|X-\mu|\ge \epsilon) \le
\frac{\sigma^2}{\epsilon^2}\]</span></p>
</blockquote>
<p>从定义可知，切比雪夫不等式也可写成如下的形式：</p>
<p><span class="math display">\[P(|X-\mu| \le \epsilon) \ge 1 -
\frac{\sigma^2}{\epsilon^2}\]</span></p>
<p>切比雪夫不等式的一个重要意义在于<strong>当随机变量 X
的分布未知，只知道 <span class="math inline">\(E(X)\)</span> 和 <span
class="math inline">\(D(X)\)</span> 的情况下，对于事件 $(|X-| ) $
概率的下限的估计</strong>。</p>
<h3 id="协方差">协方差</h3>
<p><strong>协方差表达了两个随机变量的相关性，正的协方差表达了正相关性，负的协方差表达了负相关性。协方差为0
表示两者不相关，对于同样的两个随机变量来说，计算出的协方差的绝对值越大，相关性越强</strong>。</p>
<p>协方差的定义入下:</p>
<p><span class="math inline">\(Cov(X,Y) =
E\{[X-E(X)][Y-E(Y)]\}\)</span></p>
<p>由定义可以知下面等式成立:</p>
<p><span class="math inline">\(Cov(X,Y) = Cov(Y,X)\)</span> <span
class="math inline">\(Cov(X,Y) = E(XY) - E(X)E(Y)\)</span></p>
<p>协方差有以下性质：</p>
<p><span class="math inline">\(Cov(aX,bY) =
abCov(X,Y)\)</span>（a，b是常数）</p>
<p><span class="math inline">\(Cov(X\_1+X\_2, Y) = Cov(X\_1, Y) +
Cov(X\_2,Y)\)</span></p>
<p>假如我们现在有身高和体重这两个未知变量，对于一系列的样本我们算出的的协方差为30，那这究竟是多大的一个量呢？如果我们又发现，身高与鞋号的协方差为5，是否说明，相对于鞋号，身高与体重的的相关性更强呢？</p>
<p>为了能进行这样的横向对比，我们计算相关系数(correlation coefficient)，
相关系数相当于是“归一化”的协方差。</p>
<p><span class="math display">\[\rho\_{XY} =
\frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}}\]</span></p>
<p>相关系数是用协方差除以两个随机变量的标准差。<strong>相关系数的大小在-1和1之间变化，等于0表示不相关</strong>。再也不会出现因为计量单位变化，而数值变化较大的情况，而相关系数的大小的含义与协方差是一样的。</p>
<p>需要注意的是上面提到的<strong>相关</strong>均指<strong>线性相关</strong>，<span
class="math inline">\(X, Y\)</span> 不相关是指 <span
class="math inline">\(X,Y\)</span>
之间不存在线性关系，但是他们还可能存在除线性关系以外的关系。因此，有以下结论:
<strong><span class="math inline">\(X,Y\)</span> 相互独立则 <span
class="math inline">\(X,Y\)</span> 一定不相关；反之 <span
class="math inline">\(X,Y\)</span>
不相关，两者不一定相互独立。</strong></p>
<p>简单的证明如下： 当 <span class="math inline">\(X,Y\)</span>
相互独立的时候有 <span class="math inline">\(E(XY) = E(X)E(Y)\)</span>
， 根据上面协方差的展开式</p>
<p><span class="math inline">\(Cov(X,Y) = E(XY) - E(X)E(Y)\)</span></p>
<p>此时协方差为零，两者不相关。</p>
<p>而当 <span class="math inline">\(X, Y\)</span>
不相关的时候举一个反例如下：</p>
<figure>
<img src="https://wulc.me/imgs/image_1av0covsgggenrpbhar2ftoj2a.png"
alt="不相关但是不独立的例子" />
<figcaption aria-hidden="true">不相关但是不独立的例子</figcaption>
</figure>
<p>上面的例子来源于https://www.zhihu.com/question/26583332,
可知计算出来的协方差为0，即两者不相关，但是 <span
class="math inline">\(P(XY) \neq P(X)P(Y)\)</span>,即 两者不独立，注意
<span class="math inline">\(E(XY) = E(X)E(Y)\)</span> 不是 <span
class="math inline">\(X,Y\)</span> 独立的充分条件。</p>
<h3 id="矩和协方差矩阵">矩和协方差矩阵</h3>
<p>下面介绍概率论中几种矩的定义</p>
<blockquote>
<p>设 <span class="math inline">\(X,Y\)</span> 为随机变量,则</p>
<p><span class="math inline">\(E(X^k), k=1,2,3....\)</span> 称为 <span
class="math inline">\(X\)</span> 的 <strong><span
class="math inline">\(k\)</span> 阶原点矩</strong>，简称 <span
class="math inline">\(k\)</span> 阶矩</p>
<p><span class="math inline">\(E((X-E[X])^k), k=1,2,3....\)</span> 称为
<span class="math inline">\(X\)</span> 的 <strong><span
class="math inline">\(k\)</span> 阶中心距</strong></p>
<p><span class="math inline">\(E(X^kY^l),k,l=1,2,...\)</span> 称为 <span
class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 的 <strong><span
class="math inline">\(k+l\)</span> 阶混合矩</strong></p>
<p><span
class="math inline">\(E((X-E[X])^k(Y-E[Y])^l)),k,l=1,2,...\)</span>称为<span
class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 的 <strong><span
class="math inline">\(k+l\)</span> 阶混合中心矩</strong></p>
</blockquote>
<p>由以上定义我们可以知道，<strong>随机变量的期望是其一阶原点矩，方差是其二阶中心距，协方差是其二阶混合中心矩。</strong></p>
<p>除此之外，另外一个常用的概念是协方差矩阵， 其定义如下：</p>
<p>对于 <span class="math inline">\(n\)</span> 维随机变量 <span
class="math inline">\((X\_1,X\_2,X\_3...,X\_n)\)</span> 构成的矩阵</p>
<p><span class="math display">\[C=
\begin{bmatrix}
c\_{11} &amp; c\_{12} &amp; \cdots &amp; c\_{1n} \\\
c\_{21} &amp; c\_{22} &amp; \cdots &amp; c\_{2n} \\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\\
c\_{n1} &amp; c\_{n2} &amp; \cdots &amp; c\_{nn} \\\
\end{bmatrix}
\]</span></p>
<p>其中各个元素为<span class="math display">\[c\_{ij} = Cov(X\_i,X\_j) =
E((X\_i - E[X\_i])(X\_j - E[X\_j]))，i,j=1,2,3..n\]</span></p>
<p>则称矩阵 <span class="math inline">\(C\)</span>
为协方差矩阵，由于<span class="math inline">\(c\_{ij} = c\_{ji}\)</span>
， 因此上面的矩阵为一个对称矩阵。</p>
<p>协方差矩阵其实是将二维随机变量的协方差一般化后拓展到了 <span
class="math inline">\(n\)</span>
维随机变量上的一种表示形式，但是除了作为一种表示形式以外，协方差矩阵还存在着某些性质使得其在多个领域均有应用，如主成成分分析。</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计知识整理(2)--二维随机变量的分布</title>
    <url>/2016/10/08/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86(2)--%E4%BA%8C%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<p>前面讲到的随机变量都是一维的，但是某些试验中随机变量可能有多个，这里主要讨论二维的随机变量。</p>
<span id="more"></span>
<h2 id="联合分布函数">联合分布函数</h2>
<p>假设 <span class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span>
都是随机变量，那么我们定义其分布函数如下：</p>
<p><span class="math display">\[ F(x,y) = P ((X \le x)\cap(Y \le y))
=  P (X \le x, Y \le y )\]</span></p>
<p>上面的 <span class="math inline">\(F(x,y)\)</span>
称作随机变量(X,Y)的分布函数，也叫作<strong>联合分布函数</strong>。</p>
<h3 id="离散型随机变量联合分布">离散型随机变量联合分布</h3>
<p>如果上面的 <span class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span>
都是<strong>离散随机变量</strong>，那么对于 <span
class="math inline">\((X,Y)\)</span> 的所有取值可记为</p>
<p><span class="math display">\[P(X=x\_i, Y=y\_i) =
p\_{ij},i,j=1,2,....\]</span></p>
<p>上面的所有P的取值为二维离散随机变量的分布律，也叫<strong>联合分布律</strong>。直观用表格表示如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1auhgkmh31s46m2u1rkf1uhe16ui13.png" /></p>
<h3 id="连续型随机变量联合分布">连续型随机变量联合分布</h3>
<p>类似地，如果上面的X和Y都是<strong>连续随机变量</strong>，那么分布函数可定义为</p>
<p><span class="math display">\[ F(x,y) =
\int\_{-\infty}^y\int\_{-\infty}^xf(u,v)dudv \]</span></p>
<p>其中 <span class="math inline">\(f(x,y)\)</span>
被称为概率密度函数，也叫<strong>联合概率密度函数</strong>。</p>
<p>其性质与一维随机变量的概率密度函数非常相似</p>
<ol type="1">
<li><p><span class="math display">\[f(x,y) \ge 0\]</span></p></li>
<li><p><span
class="math display">\[\int\_{-\infty}^{\infty}\int\_{-\infty}^{\infty}f(x,y)dxdy
= F(\infty,\infty)\]</span></p></li>
</ol>
<p>3.设 <span class="math inline">\(G\)</span> 是 <span
class="math inline">\(xOy\)</span> 平面上的区域，点 <span
class="math inline">\((X,Y)\)</span> 落在G内的概率为</p>
<p><span class="math display">\[P((X,Y)\in G) = \int\int
f(x,y)dxdy\]</span></p>
<p>4.若 <span class="math inline">\(f(x,y)\)</span> 在点 <span
class="math inline">\((x, y)\)</span> 连续，则</p>
<p><span class="math display">\[\frac{\partial^2F(X,Y)}{\partial x
\partial y} = f(x, y)\]</span></p>
<h2 id="边缘分布函数">边缘分布函数</h2>
<p>二维随机变量 <span class="math inline">\((X,Y)\)</span>
作为一个整体的时候，其分布函数为联合分布函数，但是 <span
class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span>
是随机变量，各自也有分布函数，将其分别记为 <span
class="math inline">\(F\_X(x),F\_Y(y)\)</span>，称为随机变量 <span
class="math inline">\((X,Y)\)</span> 关于 <span
class="math inline">\(X\)</span> 和关于 <span
class="math inline">\(Y\)</span> 的<strong>边缘分布函数</strong>。</p>
<p><strong>边缘分布函数可通过联合分布函数确定</strong>，关系如下</p>
<p><span class="math display">\[F\_X(x) = P(X \le x) = P(X \le x,Y \lt
\infty) = F(x, \infty)\]</span></p>
<p>即</p>
<p><span class="math display">\[F\_X(x) = F(x,\infty)\]</span></p>
<p>也就是说在联合分布函数 <span class="math inline">\(F(x,y)\)</span>
中令 <span class="math inline">\(y \rightarrow \infty\)</span>
即可得到边缘分布 <span class="math inline">\(F\_X(x)\)</span>, 同理<span
class="math display">\[F\_Y(y) = F(\infty, y)\]</span></p>
<p>下面分别以离散型随机变量和连续性随机基量为例说明</p>
<h3 id="离散型随机变量边缘分布">离散型随机变量边缘分布</h3>
<p>假如 <span class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 是离散型随机变量，那么随机变量 <span
class="math inline">\((X,Y)\)</span> 关于 <span
class="math inline">\(X\)</span> 和关于 <span
class="math inline">\(Y\)</span> 的边缘分布定义下</p>
<p><span class="math display">\[p\_{i.} = \sum\_{j=1}^{\infty} p\_{ij} =
P(X = x\_i), i=1,2,3.....n\]</span></p>
<p><span class="math display">\[p\_{.j} = \sum\_{i=1}^{\infty} p\_{ij} =
P(Y = y\_j), j=1,2,3.....n\]</span></p>
<p>上面的式子分别称为随机变量 <span class="math inline">\((X,Y)\)</span>
关于 <span class="math inline">\(X\)</span> 和关于 <span
class="math inline">\(Y\)</span> 的<strong>边缘分布率</strong>。</p>
<h3 id="连续型随机变量边缘分布">连续型随机变量边缘分布</h3>
<p>假如 <span class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 分别是连续性随机变量，那么随机变量
<span class="math inline">\((X,Y)\)</span> 关于 <span
class="math inline">\(X\)</span>
的<strong>边缘分布函数</strong>定义为</p>
<p><span class="math display">\[F\_X(x) = F(x,\infty) =
\int\_{-\infty}^{x}(\int\_{-\infty}^{\infty}f(x,y)dy)dx\]</span></p>
<p>而</p>
<p><span class="math display">\[ f\_X(x) =
\int\_{-\infty}^{\infty}f(x,y)dy\]</span></p>
<p>则被称为随机变量 <span class="math inline">\((X,Y)\)</span> 关于
<span class="math inline">\(Y\)</span> 的
<strong>边缘概率密度函数</strong></p>
<h2 id="条件分布">条件分布</h2>
<p>由条件概率可以比较容易推导出条件分布的含义，其定义如下：</p>
<h3 id="离散型随机变量的条件分布">离散型随机变量的条件分布</h3>
<p>对于离散型随机变量，条件分布的定义如下：</p>
<blockquote>
<p>设 <span class="math inline">\((X,Y)\)</span>
是二维离散型随机变量，对于固定的 <span
class="math inline">\(j\)</span>，若 <span
class="math inline">\(P(Y=y\_j) \gt 0\)</span>, 则称 <span
class="math display">\[P(X = x\_i|Y= y\_j) = \frac{P(X = x\_i,
Y=y\_j)}{P(Y=y\_j)} = \frac{p\_{ij}}{p\_{.j}}, i = 1,2,3\]</span> 为在
<span class="math inline">\(Y=y\_j\)</span>
条件下随机变量X的条件分布律。同理，交换 <span
class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 的位置得到的是在 <span
class="math inline">\(X=x\_i\)</span> 条件下随机变量 <span
class="math inline">\(Y\)</span> 的条件分布律。</p>
</blockquote>
<h3 id="连续型随机变量的条件分布">连续型随机变量的条件分布</h3>
<p>对于连续型的随机变量，条件分布的定义如下：</p>
<blockquote>
<p>设二维随机变量 <span class="math inline">\((X,Y)\)</span>
的概率密度函数为 <span class="math inline">\(f(x,y),(X,Y)\)</span> 关于
<span class="math inline">\(Y\)</span> 的边缘概率密度为 <span
class="math inline">\(f\_Y(y)\)</span> .若对于固定的 <span
class="math inline">\(y，f\_Y(y) &gt;0\)</span> ，则称 <span
class="math inline">\(\frac{f(x,y)}{f\_Y(y)}\)</span> 为在 <span
class="math inline">\(Y=y\)</span> 的条件下 <span
class="math inline">\(X\)</span> 的条件概率密度。记为 <span
class="math display">\[f\_{X|Y}(x|y) =
\frac{f(x,y)}{f\_Y(y)}\]</span></p>
</blockquote>
<p>有了条件概率密度(就是条件概率密度函数)，我们也可以定义出条件分布函数如下</p>
<p><span class="math display">\[\int\_{-\infty}^x f\_{X|Y}(x|y)dx =
\int\_{-\infty}^x \frac{f(x,y)}{f\_Y(y)}dx\]</span></p>
<p>上面的函数为在 <span class="math inline">\(Y=y\)</span> 的条件下
<span class="math inline">\(X\)</span> 的条件分布函数，记为</p>
<p><span class="math inline">\(F\_{X|Y}(x|y) = P(X \le x|
Y=y)\)</span></p>
<h2 id="相互独立的随机变量">相互独立的随机变量</h2>
<p>两个随机变量 <span class="math inline">\(X,Y\)</span>
相互独立的充要条件如下：</p>
<p><span class="math inline">\(F(x,y) = F\_X(x)F\_Y(y)\)</span></p>
<p>上面的 <span class="math inline">\(F(x,y),F\_X(x),F\_Y(y)\)</span>
分别是二维随机变量的联合分布函数及关于 <span
class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 的边缘分布函数。</p>
<p>除了通过分布函数，对于具体的连续型随机变量或离散型随机变量，还可通过概率密度函数和分布律来定义相互独立的条件。</p>
<p>对于连续型随机变量，上面的式子等价于</p>
<p><span class="math inline">\(f(x,y) = f\_X(x)f\_Y(y)\)</span></p>
<p>式子中的 <span class="math inline">\(f(x,y),f\_X(x),f\_Y(y)\)</span>
分别为 随机变量 <span class="math inline">\((X,Y)\)</span>
的条件概率密度函数和边缘概率密度函数。</p>
<p>对于离散型随机变量则有：</p>
<p><span class="math inline">\(P(X = x\_i, Y = y\_j) =
P(X=x\_i)P(Y=y\_j)\)</span></p>
<h2 id="二维随机变量的函数的分布">二维随机变量的函数的分布</h2>
<p>在讨论一维随机变量的分布函数的时候，也讨论了一维随机变量的函数的分布函数，同样对于二维随机变量，我们也可以讨论其函数的分布函数。下面主要讨论
<span class="math inline">\(Z=X+Y\)</span>，<span
class="math inline">\(Z=XY\)</span>，<span
class="math inline">\(Z=Y/X\)</span>，<span
class="math inline">\(M=max(X,Y)\)</span>，<span
class="math inline">\(N=min(X,Y)\)</span> 这几个函数的分布函数（<span
class="math inline">\(X，Y\)</span>
为相互独立的随机变量），这里主要给出具体的公式，证明省略。</p>
<h3 id="z-x-y-的分布"><span class="math inline">\(Z = X + Y\)</span>
的分布</h3>
<p>设 <span class="math inline">\((X,Y)\)</span>
是二维连续型随机变量，其概率密度函数为 <span
class="math inline">\(f(x,y)\)</span>， <span class="math inline">\(Z =
X+Y\)</span>仍然为连续性随机变量，其概率密度函数为</p>
<p><span class="math display">\[f\_{X+Y}(z) = \int\_{-\infty}^{\infty}
f(z-y,y)dy\]</span> 或 <span class="math display">\[f\_{X+Y}(z) =
\int\_{-\infty}^{\infty} f(x,z-x)dx\]</span></p>
<p>当 <span class="math inline">\(X,Y\)</span>
相互独立时，其边缘概率密度函数具有以下性质</p>
<p><span class="math inline">\(f(x,y) = f\_X(x)f\_Y(y)\)</span></p>
<p>因此上面的式子也可以化成下面的形式</p>
<p><span class="math display">\[f\_{X+Y}(z) = \int\_{-\infty}^{\infty}
f\_X(z-y)f\_Y(y)dy\]</span></p>
<p><span class="math display">\[f\_{X+Y}(z) = \int\_{-\infty}^{\infty}
f\_X(x)f\_Y(z-x)dx\]</span></p>
<h3 id="zxy-和-zyx-的分布"><span class="math inline">\(Z=XY\)</span> 和
<span class="math inline">\(Z=Y/X\)</span> 的分布</h3>
<p>设 <span class="math inline">\((X,Y)\)</span>
是二维连续型随机变量，其概率密度函数为 <span
class="math inline">\(f(x,y)\)</span>， <span class="math inline">\(Z =
\frac{Y}{X},Z = XY\)</span>仍然为连续性随机变量，其概率密度函数为</p>
<p><span class="math display">\[f\_{Y/X}(z) = \int\_{-\infty}^{\infty}
|x|f(x,xz)dx\]</span></p>
<p><span class="math display">\[f\_{XY}(z) = \int\_{-\infty}^{\infty}
\frac{1}{|x|}f(x,z/x)dx\]</span></p>
<p>当 <span class="math inline">\(X,Y\)</span>
相互独立时，同样有下面的性质</p>
<p><span class="math display">\[f\_{Y/X}(z) = \int\_{-\infty}^{\infty}
|x|f\_X(x)f\_Y(xz)dx\]</span></p>
<p><span class="math display">\[f\_{XY}(z) = \int\_{-\infty}^{\infty}
\frac{1}{|x|}f\_X(x)f\_Y(z/x)dx\]</span></p>
<h3 id="m-maxxy-和-n-minxy-的分布"><span class="math inline">\(M =
max(X,Y)\)</span> 和 <span class="math inline">\(N = min(X,Y)\)</span>
的分布</h3>
<p>讨论 <span class="math inline">\(max(X,Y)\)</span> 和 <span
class="math inline">\(min(X,Y)\)</span> 的分布的时候， 一般假设 <span
class="math inline">\(X, Y\)</span>
相互独立，因为这样才有下面的性质。</p>
<p>对于 <span class="math inline">\(M = max(X,Y)\)</span> 的分布有</p>
<p><span class="math inline">\(F\_{max}(z) = P(M \le z) = P(X \le z, Y
\le z) = P(X \le z)P(Y \le z)\)</span></p>
<p>由于 <span class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span> 相互独立，因此有</p>
<p><span class="math inline">\(F\_{max}(z) = F\_X(z)F\_Y(z)\)</span></p>
<p>同样对 <span class="math inline">\(N = min(X,Y)\)</span> 有</p>
<p><span class="math inline">\(F\_{min}(z) = P(N \le z) = 1 - P(N \gt z)
= 1 - P(X &gt; z)P(Y&gt;z)\)</span></p>
<p>即</p>
<p><span class="math inline">\(F\_{min}(z) = 1 - (1 - F\_X(z))(1 -
F\_Y(z))\)</span></p>
<p>推广到 <span class="math inline">\(n\)</span>
个相互独立的随机变量有下面的性质</p>
<p><span class="math inline">\(M = max \lbrace X\_1,X\_2...,X\_n
\rbrace\)</span> 及 <span class="math inline">\(N = min\lbrace
X\_1,X\_2...,X\_n \rbrace\)</span> 的分布函数分别为</p>
<p><span class="math display">\[F\_{max}(z) =
F\_{X\_1}(z)F\_{X\_2}(z)...F\_{X\_n}(z)\]</span></p>
<p><span class="math display">\[F\_{min}(z) = 1 - (1 - F\_{X\_1}(z))(1 -
F\_{X\_2}(z))...(1 - F\_{X\_n}(z))\]</span></p>
<p>而当 $ X_1,X_2...,X_n $ 独立同分布的时候，上式变为如下所示</p>
<p><span class="math display">\[F\_{max}(z) = [F(z)]^n\]</span></p>
<p><span class="math display">\[F\_{min}(z) = 1 - (1 -
F(z))^n\]</span></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计知识整理(4)--大数定律和中心极限定理</title>
    <url>/2016/10/18/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86(4)--%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%92%8C%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/</url>
    <content><![CDATA[<p>大数定律和中心极限定理都是与极限有关的定理，其中大数定律主要描述了当<strong>样本的数量足够多时，其均值(频率)可以用来逼近总体的期望（概率）</strong>；而中心极限定理则描述了在某些条件下，<strong>大量独立同分布的随机变量的和的分布逼近于正态分布</strong>。</p>
<span id="more"></span>
<h2 id="大数定律">大数定律</h2>
<p>大数定律有弱大数定律和强大数定律，两者描述的都是样本数量越多，则其平均就越趋近期望值。两个简单的区别就是弱大数定律表示样本均值<strong>依概率收敛于</strong>总体均值，而强大数定律表示了样本均值可以<strong>以概率为1收敛</strong>于总体均值。弱大数定律比较早被证明出来，强大数定律是比较晚被证明出来的，通俗来说就是数学家先证明了弱大数定律，后来在没有改变前提的情况下把弱大数定律推进了一步，更加确定了这个收敛，也就是强大数定律。</p>
<p>这里主要讲几个弱大数定律的定义</p>
<blockquote>
<p><strong>弱大数定理（辛钦大数定理）</strong> 设 <span
class="math inline">\(X\_1,X\_2,...\)</span>
是独立同分布的随机变量序列，且具有数学期望 <span
class="math inline">\(E(X\_k) = \mu(k=1,2,,....)\)</span>,取前 n
个变量的算术平均 <span class="math inline">\(\frac{1}{n}
\sum\_{k=1}^{n}X\_k\)</span>, 对于任意的 <span
class="math inline">\(\epsilon\)</span>,有 <span
class="math display">\[\lim\_{n \rightarrow \infty} P(|\frac{1}{n}
\sum\_{k=1}^{n}X\_k - \mu| &lt; \epsilon) = 1\]</span></p>
</blockquote>
<p>定义描述的就是<strong>当样本数n足够大时，样本均值与总体期望的差可以无限小，也就是可以通过样本均值估计总体期望。</strong>基于上面的辛钦弱大数定理可以推出下面的伯努利大数定理</p>
<blockquote>
<p><strong>伯努利大数定理</strong> 设 <span
class="math inline">\(f\_A\)</span> 是 n 次独立重复试验中事件 <span
class="math inline">\(A\)</span> 发生的次数，<span
class="math inline">\(p\)</span> 是事件 <span
class="math inline">\(A\)</span> 在每次试验中发生的概率，则对于任意正数
$&gt; 0 <span class="math inline">\(, 有\)</span><span
class="math inline">\(\lim\_{n \rightarrow \infty}P(|\frac{f\_A}{n} - p|
&lt; \epsilon) = 1\)</span><span class="math inline">\(或\)</span><span
class="math inline">\(\lim\_{n \rightarrow \infty}P(|\frac{f\_A}{n} - p|
\ge \epsilon) = 0\)</span>$</p>
</blockquote>
<p>伯努利大数定理主要描述当<strong>样本数足够大时，可以用样本的频率来估计总体的概率</strong>，其本质跟辛钦弱大数定理是一样的。</p>
<h2 id="中心极限定理">中心极限定理</h2>
<p>一般来说，n个独立同分布的随机变量的和的分布函数是比较难求的，而通过中心极限定理，可以描述当n足够大的时候，这些<strong>随机变量的和的分布近似服从正态分布</strong>。下面主要讲述两条中心极限定理的</p>
<blockquote>
<p><strong>独立同分布的中心极限定理</strong> 随机变量 <span
class="math inline">\(X\_1,X\_2,...X\_n\)</span>
独立同分布，且具有数学期望<span class="math inline">\(E(X\_k) =
\mu\)</span>, 和方差 <span class="math inline">\(D(X\_k) = \sigma^2 &gt;
0(k=1,2,3...)\)</span>, 则随机变量之和 <span
class="math inline">\(\sum\_{k=1}^n X\_k\)</span> 的标准化变量 <span
class="math display">\[Y\_n = \frac{\sum\_{k=1}^n X\_k - E(\sum\_{k=1}^n
X\_k)}{\sqrt{D(\sum\_{k=1}^n X\_k)}} = \frac{\sum\_{k=1}^n X\_k -
n\mu}{\sqrt{n}\sigma}\]</span>的分布函数 <span
class="math inline">\(F\_n(x)\)</span> 对于任意 <span
class="math inline">\(x\)</span> 满足 <span
class="math display">\[\lim\_{n \rightarrow \infty} F\_n(x) = \lim\_{n
\rightarrow \infty}P(\frac{\sum\_{k=1}^n X\_k - n\mu}{\sqrt{n}\sigma}\le
x)  = \int\_{-\infty}^x\frac{1}{\sqrt{2\pi}} e^{-t^2/2} dt\]</span></p>
</blockquote>
<p>也就是说，当上面的 <strong><span class="math inline">\(n\)</span>
充分大的时候，<span class="math inline">\(\frac{\sum\_{k=1}^n X\_k -
n\mu}{\sqrt{n}\sigma}\)</span> 服从正态分布 <span
class="math inline">\(N(0,1)\)</span></strong></p>
<p>也可以将上面分布写成下面的形式</p>
<p><span class="math inline">\(\frac{ \overline X-
\mu}{\sigma/\sqrt{n}}\)</span>~<span
class="math inline">\(N(0,1)\)</span> 或 <span
class="math inline">\(\overline X\)</span>~<span
class="math inline">\(N(\mu, \sigma^2/n)\)</span></p>
<p>也就是说，当样本的数量n足够大的时候，样本均值服从均值为 <span
class="math inline">\(\mu\)</span>, 方差为 <span
class="math inline">\(\sigma^2/n\)</span> 的正态分布， 其中 <span
class="math inline">\(\mu\)</span> 和 <span
class="math inline">\(\sigma\)</span>
分别是原来随机变量的所服从的分布的期望和方差，这一结果是数理统计中大样本统计推断的基础。</p>
<p><strong>上面的独立同分布中每个随机变量都是同分布的，也就是具有同样的期望和方差，那么如果随机变量的分布独立呢</strong>？下面是对应这种情况的中心极限定理。</p>
<blockquote>
<p><strong>李雅普诺夫定理</strong> 设随机变量 <span
class="math inline">\(X\_1,X\_2,...X\_n\)</span>
相互独立，具有数学期望和方差<span class="math display">\[E(X\_k) =
\mu\_k, D(X\_k) = \sigma\_k^2 &gt; 0,k=1,2,...\]</span>,记<span
class="math display">\[B\_n^2 = \sum\_{k=1}^n \sigma\_k^2\]</span>
若存在正数 <span class="math inline">\(\delta\)</span>, 使得当 <span
class="math inline">\(n \rightarrow \infty\)</span> 时，<span
class="math display">\[\frac{1}{B\_n^{2+\delta}}\sum\_{k=1}^{n} E(|X\_k
- \mu\_k|^{2+\delta}) \rightarrow 0\]</span> 定义随机变量 <span
class="math inline">\(Z\_n\)</span> 为<span class="math display">\[Z\_n
= \frac{\sum\_{k=1}^n X\_k - \sum\_{k=1}^n  \mu\_k}{B\_n}\]</span>
那么当n很大时,只要满足定理中的条件，那么随机变量 <span
class="math inline">\(Z\_n\)</span> 服从正态分布 <span
class="math inline">\(N(0,1)\)</span>。</p>
</blockquote>
<p>也就是说<strong>当 n 很大的时候，随机变量的和 <span
class="math inline">\(\sum\_{k=1}^{n}X\_k\)</span> 近似服从正态分布<span
class="math inline">\(N(\sum\_{k=1}^n\mu\_k,
B\_n^2)\)</span></strong></p>
<p>下面是应用中心极限定理的一个例子</p>
<p><img
src="https://wulc.me/imgs/image_1avguc66ide01d9vaer3vnsd54o.png" /></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计知识整理(5)--样本及抽样分布</title>
    <url>/2016/11/18/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86(5)--%E6%A0%B7%E6%9C%AC%E5%8F%8A%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/</url>
    <content><![CDATA[<p>前面几部分主要总结了概率论中的一些知识，后面主要讲述与数理统计相关的知识。</p>
<p>概率论与数理统计的主要区别为，在概率论中所研究的随机变量，其<strong>分布都是假设已知</strong>的，在这一前提下去研究它的性质（数字特征，分布函数等）；而在数理统计中研究的随机变量其<strong>分布是未知的</strong>，通过对所研究的随机变量进行<strong>重复独立的试验和观察</strong>，得到许多观察值，再对观察值进行分析，从而<strong>对所研究的随机变量的分布做出各种推断</strong>。</p>
<span id="more"></span>
<p>因此数理统计的主要内容包括两部分，一是如何收集，整理数据资料，二是如何对得到的数据资料进行分析和研究，从而对所研究的对象的性质和特点做出推断。第二部分其实就是统计推断的问题，也是后面主要讲述的内容。本文主要讲述数理统计中的两个基本概念：样本和抽样分布。</p>
<h2 id="样本">样本</h2>
<p>从前面可知，数理统计就是通过数据来推断变量的分布，比如说现在要求求出全国成年男人的身高的一个分布，那只需要测出每个成年男人的身高后进行统计即可。</p>
<p>但是在实际中，受限于人力物力和测试的难度，我们往往不会对每个成年男人进行身高的测试，而是在全国男人中选择部分的男人进行测试(如根据每个地区的人口数量按比例测试)，然后用这部分男人的身高分布来推断全国男人的分布，这样的推断肯定会存在误差，但是通过增加样本的数量，可以减少这种误差(大数定理)。</p>
<p>上面其实就是一个很简单的数理统计过程，当中有几个概念需要注意，例子中的全国男人的身高是一个<strong>总体</strong>，选择出来实际测试身高的男人是一个<strong>样本</strong>，测试得到的身高称为<strong>样本值（观测值）</strong>，总体和样本中的数目分别称为他们的<strong>容量</strong>。</p>
<p>其严格定义如下：</p>
<blockquote>
<p>设 <span class="math inline">\(X\)</span> 是具有分布函数 <span
class="math inline">\(F\)</span> 的随机变量, 若 <span
class="math inline">\(X\_1, X\_2, ...,X\_n\)</span> 是具有同一分布函数
<span class="math inline">\(F\)</span> 的相互独立的随机变量，则称 <span
class="math inline">\(X\_1, X\_2,...X\_n\)</span> 为从分布函数 <span
class="math inline">\(F\)</span>
得到的容量为n的简单随机样本，简称样本，他们的观测值 <span
class="math inline">\(x\_1, x\_2,...x\_n\)</span> 称为样本值，又称为
<span class="math inline">\(X\)</span> 的 <span
class="math inline">\(n\)</span> 个独立的观测值。</p>
</blockquote>
<p>由定义可知样本 $ X_1,X_2,...,X_n $ 相互独立，且他们的分布函数均为
<span class="math inline">\(F\)</span>, 所以 $ (X_1,X_2,...,X_n)
$的分布函数为</p>
<p><span class="math display">\[ F^*(x\_1,x\_2,...,x\_n) =
\prod\_{i=1}^nF(x\_i)\]</span></p>
<p>同样,$ (X_1,X_2,...,X_n) $的概率密度函数为：</p>
<p><span class="math display">\[ f^*(x\_1,x\_2,...,x\_n) =
\prod\_{i=1}^nf(x\_i) \]</span></p>
<h2 id="抽样分布">抽样分布</h2>
<h3 id="统计量">统计量</h3>
<p>样本是进行统计推断的依据，但是在应用中，往往不是直接使用样本本身，而是<strong>针对不同问题构造适当的样本的函数，利用这些样本的函数进行统计推断</strong>。</p>
<p>当这些样本的函数中不含未知变量时，我们称其为<strong>统计量</strong>，如下面就是几个常用的统计量，其中
$ X_1,X_2,....,X_n $ 为总体的一个样本。</p>
<p>样本平均值： <span class="math display">\[\overline X = \frac{1}{n}
\sum\_{i=1}^{n} X\_i\]</span></p>
<p>样本方差：<span class="math display">\[S^2 = \frac{1}{n-1}
\sum\_{i=1}^{n} (X\_i - \overline X)^2\]</span></p>
<p>样本标准差：<span class="math display">\[S = \sqrt {S^2}\]</span></p>
<p>样本 k 阶原点矩： <span class="math display">\[A\_k = \frac{1}{n}
\sum\_{i=1}^{n} X\_i^k (k=1,2,...)\]</span></p>
<p>样本 k 阶中心矩: <span class="math display">\[B\_k = \frac{1}{n}
\sum\_{i=1}^{n}(X\_i - \overline X)^k (k=2,3,4.....)\]</span></p>
<p>这些统计量的定义与概率论中的基本相似，唯一比较奇怪的是为什么样本方差的分母是
<span class="math inline">\(n - 1\)</span> 而不是
n，原因是通过数学证明可以得到<strong>只有当分母取n-1时，用样本来估计总体才是无偏的(无偏指的是估计量的期望与总体的参数一致)</strong>，下面是分母取n时得到的有偏估计的证明过程（<span
class="math inline">\(S\_1^2\)</span>为样本方差）</p>
<p><img
src="https://wulc.me/imgs/image_1b2b4i5eu1923bao1e801k76816p.png" /></p>
<p>更多的解释可参考<a
href="https://www.zhihu.com/question/20099757">这里</a></p>
<p>除了上面的统计量还定义了与总体分布函数 <span
class="math inline">\(F(x)\)</span>
相应的统计量--经验分布函数。其定义如下</p>
<blockquote>
<p>设 $ X_1,X_2,....,X_n $ 为总体的一个样本，$ S(x)(-&lt; x &lt; )
$表示为样本中不大于 <span class="math inline">\(x\)</span>
的随机变量的个数，则经验分布函数 <span
class="math inline">\(F\_n(x)\)</span> 的定义如下<span
class="math display">\[F\_n(x) = \frac{1}{n}S(x) (-\infty &lt; x &lt;
\infty)\]</span></p>
</blockquote>
<p>下面是关于经验分布函数的一个简单例子。</p>
<p>设总体 <span class="math inline">\(F\)</span>
具有一个样本值1,2,3，则经验分布函数 <span
class="math inline">\(F\_3(x)\)</span> 的观测值为</p>
<p><span class="math display">\[f(y) = \begin{cases}  
0 &amp;{x&lt;1} \\\
\frac{1}{3} &amp;{1\le x&lt;2}\\\
\frac{2}{3} &amp;{2\le x&lt;3}\\\
1 &amp;{x \ge 3}\end{cases}\]</span></p>
<p><strong>经验分布函数的意义在于当 n 充分大的时候，<span
class="math inline">\(F\_n(x)\)</span> 以概率1收敛于总体分布函数 <span
class="math inline">\(F(x)\)</span></strong></p>
<h3 id="统计量的分布">统计量的分布</h3>
<p>使用统计量进行统计推断时，常常需要知道其分布，<strong>统计量的分布也称为抽样分布</strong>，下面介绍三种来自<strong>正态分布</strong>的抽样分布：
<span class="math inline">\(\chi^2\)</span> 分布，<span
class="math inline">\(t\)</span> 分布和 <span
class="math inline">\(F\)</span> 分布。</p>
<h4 id="chi2-分布"><span class="math inline">\(\chi^2\)</span> 分布</h4>
<p><span class="math inline">\(\chi^2\)</span> 分布的定义如下</p>
<blockquote>
<p>设 <span class="math inline">\(X\_1, X\_2,...X\_n\)</span> 是来自总体
<span class="math inline">\(N(0,1)\)</span> 的样本，则称统计量<span
class="math display">\[\chi^2 = X\_1^2 + X\_2^2
+....X\_n^2\]</span>为服从自由度为 <span
class="math inline">\(n\)</span> 的 <span
class="math inline">\(\chi^2\)</span> 分布</p>
</blockquote>
<p>上面的自由度指的是右端独立变量的个数。</p>
<p><span class="math inline">\(\chi^2(n)\)</span> 的概率密度函数为</p>
<p><span class="math display">\[f(y) =
\begin{cases}  \frac{1}{2^{\frac{n}{2}}\Gamma(n/2)}y^{n/2-1}e^{-y/2}
&amp;{y&gt;0} \\\ 0&amp;{其他}\end{cases}\]</span></p>
<p>上式的 <span class="math inline">\(\Gamma\)</span> 函数定义为</p>
<p><span class="math display">\[\Gamma = \int\_{0}^{\infty} \frac{t^z -
1}{e^t} dt\]</span></p>
<p><span class="math inline">\(f(y)\)</span> 的图像如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b2b76hpl42rb2o8ig1aki11kq2q.png"
alt="卡方分布的概率密度函数" />
<figcaption aria-hidden="true">卡方分布的概率密度函数</figcaption>
</figure>
<p>关于 <span class="math inline">\(\chi^2(n)\)</span>
有以下几个有用的结论：</p>
<ul>
<li><strong>可加性</strong></li>
</ul>
<p>设 <span class="math inline">\(\chi\_1^2\)</span><sub><span
class="math inline">\(\chi^2(n\_1), \chi\_2^2\)</span></sub><span
class="math inline">\(\chi^2(n\_2)\)</span>, 并且 <span
class="math inline">\(\chi\_1^2, \chi\_2^2\)</span>相互独立，则有 <span
class="math display">\[\chi\_1^2 + \chi\_2^2 \sim \chi^2(n\_1 +
n\_2)\]</span></p>
<ul>
<li><strong>期望和方差</strong></li>
</ul>
<p>若<span class="math inline">\(\chi^2\)</span>~<span
class="math inline">\(\chi^2(n)\)</span>，则<span
class="math inline">\(\chi^2\)</span>的期望和方差如下所示 <span
class="math display">\[E(\chi^2) = n, D(\chi^2)=2n\]</span></p>
<ul>
<li><strong>分位点</strong></li>
</ul>
<p>分位点的定义如下，给定正数 <span class="math inline">\(a,
0&lt;a&lt;1\)</span>, 称满足下面条件</p>
<p><span class="math display">\[P(\chi^2 \gt \chi\_a^2(n)) =
\int\_{\chi\_a^2(n)}^{\infty}f(y)dy= a\]</span></p>
<p>的 <span class="math inline">\(\chi\_a^2(n)\)</span> 为 <span
class="math inline">\(\chi^2(n)\)</span>上的a分位点，其图像如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b2b8ahhmc23e9l80doqjq3q58.png" /></p>
<p>由定义可知，分位点由 <span class="math inline">\(a,n\)</span>
共同决定，因此对于不同的 <span class="math inline">\(a，n\)</span>
可以查阅表格得到其 <span class="math inline">\(a\)</span> 分位点。</p>
<h4 id="t-分布"><span class="math inline">\(t\)</span> 分布</h4>
<p><span class="math inline">\(t\)</span>分布的定义如下： &gt; 设 <span
class="math inline">\(X \sim N(0,1), Y \sim \chi^2(n)\)</span>, 且 <span
class="math inline">\(X,Y\)</span> 相互独立，则称随机变量 <span
class="math display">\[ t = \frac{X}{\sqrt{Y/n}}\]</span> 服从自由度为
<span class="math inline">\(n\)</span> 的 <span
class="math inline">\(t\)</span> 分布, 记为 <span
class="math inline">\(t \sim t(n)\)</span></p>
<p>其概率密度函数和对应的图像如下所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b2b8il5d15avfccade13di1o3062.png"
alt="t分布的概率密度函数和图像" />
<figcaption aria-hidden="true">t分布的概率密度函数和图像</figcaption>
</figure>
<p>其分位点的定义与上面讲述的一样，</p>
<p><span class="math display">\[P(t \gt t\_a(n)) =
\int\_{t\_a(n)}^{\infty}h(t)dt= a\]</span></p>
<p><img
src="https://wulc.me/imgs/image_1b2b8n0cm104q18c2mtbkf9am6f.png" /></p>
<p>且由于其概率密度函数的对称性可知,总是存在这样对称的两个分位点 ：
<span class="math inline">\(t\_{1-a}(n) = -t\_a(n)\)</span></p>
<h4 id="f-分布"><span class="math inline">\(F\)</span> 分布</h4>
<p>F 分布的定义如下 &gt; 设 <span class="math inline">\(U \sim
\chi^2(n\_1), V \sim \chi^2(n\_2)\)</span>， 且 <span
class="math inline">\(U,V\)</span>相互独立，则称随机变量<span
class="math display">\[F =
\frac{U/n\_1}{V/n\_2}\]</span>服从自由度为<span
class="math inline">\((n\_1,n\_2)\)</span>的<span
class="math inline">\(F\)</span>分布，记为<span class="math inline">\(F
\sim F(n\_1, n\_2)\)</span></p>
<p>其概率密度函数为：</p>
<p><span class="math display">\[\psi(y) =
\begin{cases}  \frac{\Gamma((n\_1+n\_2)/2)(n\_1/n\_2)^{n\_1/2}y^{n\_1/2-1}}{\Gamma(n\_1/2)\Gamma(n\_2/2)[1+(n\_1y/n\_2)]^{(n\_1+n\_2/)2}}
&amp;{y&gt;0} \\\ 0&amp;{其他}\end{cases}\]</span></p>
<p>概率密度函数的图像如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b2b92aidk0hul81ehmbr01jjq7m.png"
alt="F分布的概率密度函数" />
<figcaption aria-hidden="true">F分布的概率密度函数</figcaption>
</figure>
<p>其分位点定义同上 <span class="math display">\[P(F \gt
F\_a(n\_1,n\_2)) = \int\_{F\_a(n\_1,n\_2)}^{\infty}\psi(y)dy=
a\]</span></p>
<figure>
<img src="https://wulc.me/imgs/image_1b2b9718u1s8hg3h1m6v10fqs8l83.png"
alt="F分布的分为点" />
<figcaption aria-hidden="true">F分布的分为点</figcaption>
</figure>
<p>且具有以下性质 <span class="math display">\[F\_{1-a}(n\_1,n\_2) =
\frac{1}{F\_a(n\_2,n\_1)}\]</span></p>
<p>上面只是简单地介绍了三大抽样分布，并未介绍其作用，<strong>实际上三大抽样分布主要用于参数的区间估计中，而这主要基于从正态分布中抽取的样本所构造的统计量服从这三大分布这一事实，从下面要介绍的定理中可以看到了这三大抽样分布的作用</strong>。更详细的作用会在区间估计中进一步体现。</p>
<h3
id="正态总体的样本均值与样本方差的分布">正态总体的样本均值与样本方差的分布</h3>
<p>由于正态分布的普遍性，这里特意指出从服从正态分布的总体中抽取出的样本的所服从的分布。</p>
<p>假设上面的 <span class="math inline">\(X\)</span> 服从正态分布 <span
class="math inline">\(N(\mu, \sigma^2)\)</span>,
则有以下几条定理，这几条定理在数理统计的区间估计中起了重要作用。</p>
<blockquote>
<p>定理一： 设<span class="math inline">\(X\_1,
X\_2,....X\_n\)</span>服从<span class="math inline">\(N(\mu,
\sigma^2)\)</span>，<span class="math inline">\(\overline
X\)</span>是样本均值，则有 <span class="math display">\[\overline X \sim
N(\mu,\sigma^2/n)\]</span></p>
</blockquote>
<p>证明如下： <span class="math display">\[E(\overline X) =
E(\frac{1}{n}\sum\_{i=1}^{n} X\_i) = \frac{1}{n}E(\sum\_{i=1}^{n} X\_i)
= \frac{1}{n}n E(X) = \mu\]</span></p>
<p><span class="math display">\[D(\overline X) =
D(\frac{1}{n}\sum\_{i=1}^{n} X\_i) = \frac{1}{n^2}D(\sum\_{i=1}^{n}
X\_i) = \frac{1}{n}n D(X) = \sigma^2/n\]</span></p>
<p><strong>定理一通常用于区间估计中已知总体（服从正态分布）的期望 <span
class="math inline">\(\mu\)</span> 来估计其未知的方差 <span
class="math inline">\(\sigma^2\)</span> ,或已知方差 <span
class="math inline">\(\sigma^2\)</span> 来估计未知的期望 <span
class="math inline">\(\mu\)</span>。</strong></p>
<blockquote>
<p>定理二 ：设<span class="math inline">\(X\_1,
X\_2,....X\_n\)</span>服从<span class="math inline">\(N(\mu,
\sigma^2)\)</span>，<span class="math inline">\(\overline
X\)</span>是样本均值，<span class="math inline">\(S^2\)</span>
是样本的方差，则 <span class="math inline">\(\overline X\)</span> 和
<span class="math inline">\(S^2\)</span> 相互独立，且有 <span
class="math display">\[\frac{(n-1)S^2}{\sigma^2} \sim
\chi^2(n-1)\]</span></p>
</blockquote>
<p>由于该定理的证明部分较为冗长，这里略去证明过程，感兴趣的读者可参考相关书籍。<strong>定理二主要用于区间估计中总体（服从正态分布）的期望、方差均未知时，估计其方差的范围，这也是
<span class="math inline">\(\chi^2\)</span>
分布的作用之一。</strong></p>
<blockquote>
<p>定理三：设<span class="math inline">\(X\_1,
X\_2,....X\_n\)</span>服从<span class="math inline">\(N(\mu,
\sigma^2)\)</span>，<span class="math inline">\(\overline
X\)</span>是样本均值，<span class="math inline">\(S^2\)</span>
是样本的方差，则<span class="math display">\[\frac{\overline X -
\mu}{S/\sqrt{n}} \sim t(n-1)\]</span></p>
</blockquote>
<p>证明： 根据定理一，易知 <span class="math inline">\(\overline X - \mu
\sim N(0, \sigma^2/n)\)</span>, 则 <span
class="math inline">\(\frac{\overline X - \mu}{\sqrt{\sigma^2/n}} \sim
N(0,1)\)</span>, 从定理二可知 <span
class="math display">\[\frac{(n-1)S^2}{\sigma^2} \sim
\chi^2(n-1)\]</span> 则根据t分布的定义有 <span class="math display">\[
\frac{\frac{\overline X - \mu}{\sqrt{\sigma^2/n}}}
{\sqrt{\frac{(n-1)S^2}{\sigma^2(n-1)}}} \sim t(n-1)\]</span></p>
<p>化简可得 <span class="math display">\[\frac{\overline X -
\mu}{\sqrt{\sigma^2/n}} \sim t(n-1)\]</span></p>
<p><strong>定理三主要用于区间估计中总体（服从正态分布）的期望、方差均未知时，估计其期望的范围，这也是
<span class="math inline">\(t\)</span>
分布的作用之一,注意前面讲到的<span
class="math inline">\(\chi^2\)</span>分布估计的是方差。</strong></p>
<blockquote>
<p>定理四：设 <span class="math inline">\(X\_1,
X\_2...X\_n\)</span>与<span
class="math inline">\(Y\_1,Y\_2,...Y\_n\)</span>分别是来自正态总体 <span
class="math inline">\(N(\mu\_1, \sigma\_1^2)\)</span>和<span
class="math inline">\(N(\mu\_2, \sigma\_2^2)\)</span>的样本, <span
class="math inline">\(\overline X, \overline
Y\)</span>分别是其样本均值，<span class="math inline">\(S\_1^2,
S\_2^2\)</span>分别是其样本方差。则有<span
class="math display">\[\frac{S\_1^2/S\_2^2}{\sigma\_1^2/ \sigma\_2^2}
\sim F(n\_1 - 1, n\_2 - 1)\]</span> 且当<span
class="math inline">\(\sigma\_1^2 = \sigma\_2^2 = \sigma^2\)</span>
时，<span class="math display">\[\frac{(\overline X - \overline Y) -
(\mu\_1 - \mu\_2)}{S\_w\sqrt{1/n\_1+1/n\_2}} \sim
t(n\_1+n\_2-2)\]</span>其中，<span class="math inline">\(S\_w =
\sqrt{\frac{(n\_1 -1)S\_1^2+(n\_2 -1)S\_2^2}{n\_1+n\_2-2}}\)</span></p>
</blockquote>
<p>证明如下: 由定理二可知<span
class="math display">\[\frac{(n\_1-1)S\_1^2}{\sigma\_1^2} \sim
\chi^2(n\_1-1), \frac{(n\_2-1)S\_2^2}{\sigma\_2^2} \sim
\chi^2(n\_2-1)\]</span></p>
<p>由 F 分布的定义可知 <span class="math display">\[
\frac{(n\_1-1)S\_1^2}{\sigma\_1^2(n\_1-1)} /
\frac{(n\_2-1)S\_2^2}{\sigma\_2^2(n\_2-1)} \sim F(n\_1-1,
n\_2-1)\]</span>化简可得<span
class="math display">\[\frac{S\_1^2/S\_2^2}{\sigma\_1^2/ \sigma\_2^2}
\sim F(n\_1 - 1, n\_2 - 1)\]</span></p>
<p>当<span class="math inline">\(\sigma\_1^2 = \sigma\_2^2 =
\sigma^2\)</span> 时,</p>
<p>易知 <span class="math inline">\((\overline X - \overline Y) \sim
N(\mu\_1 - \mu\_2,\sigma\_1^2/n\_1 + \sigma\_2^2/n\_2)\)</span></p>
<p>则<span class="math inline">\(\frac{(\overline X - \overline Y)-
(\mu\_1 - \mu\_2)}{\sqrt{\sigma\_1^2/n\_1 + \sigma\_2^2/n\_2}} \sim
N(0,1)\)</span></p>
<p>由定理二可知<span
class="math display">\[\frac{(n\_1-1)S\_1^2}{\sigma\_1^2} \sim
\chi^2(n\_1-1), \frac{(n\_2-1)S\_2^2}{\sigma\_2^2} \sim
\chi^2(n\_2-1)\]</span>, 由 <span class="math inline">\(\chi^2\)</span>
分布的可加性可知： <span
class="math display">\[\frac{(n\_1-1)S\_1^2}{\sigma\_1^2} +
\frac{(n\_2-1)S\_2^2}{\sigma\_2^2} \sim \chi^2(n\_1+n\_2-2)\]</span></p>
<p>由t分布的定义可知： <span class="math display">\[\frac{(\overline X -
\overline Y)- (\mu\_1 - \mu\_2)}{\sqrt{\sigma\_1^2/n\_1 +
\sigma\_2^2/n\_2}} / (\sqrt{(\frac{(n\_1-1)S\_1^2}{\sigma\_1^2} +
\frac{(n\_2-1)S\_2^2}{\sigma\_2^2})/(n\_1+n\_2-2)}) \sim
t(n\_1+n\_2-2)\]</span></p>
<p>将 <span class="math inline">\(\sigma\_1^2 = \sigma\_2^2 =
\sigma^2\)</span>代入到上式化简即可得到<span
class="math display">\[\frac{(\overline X - \overline Y) - (\mu\_1 -
\mu\_2)}{S\_w\sqrt{1/n\_1+1/n\_2}} \sim
t(n\_1+n\_2-2)\]</span>其中，<span class="math inline">\(S\_w =
\sqrt{\frac{(n\_1 -1)S\_1^2+(n\_2 -1)S\_2^2}{n\_1+n\_2-2}}\)</span></p>
<p><strong>定理四的作用是在区间估计时估计两个均服从正态分布的总体的方差的比值（期望未知）以及两者期望的差距（方差未知）</strong></p>
<h2 id="小结">小结</h2>
<p>本文主要介绍了数理统计的概念，数理统计主要做的事情就是通过有限的样本构造的统计量去推断总体分布的参数。同时介绍了数理统计中的三大分布
<span class="math inline">\(\chi^2\)</span>分布， <span
class="math inline">\(t\)</span>分布和<span
class="math inline">\(F\)</span>分布，这三大分布与前面讲的随机变量的分布不同（伯努利分布，泊松分布，正态分布等等），随机变量的分布可以认为是整体的分布，而三大分布则是描述样本的分布情况。这三大分布在区间估计中有重要作用：
其中 <strong><span
class="math inline">\(\chi^2\)</span>分布主要解决总体期望未知时估计其方差的问题，
<span
class="math inline">\(t\)</span>分布主要解决总体方差未知时估计其期望的问题，<span
class="math inline">\(F\)</span>主要解决期望未知时两个正态分布的方差比值问题。需要注意的是上面估计的前提是总体服从正态分布。</strong></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论与数理统计知识整理(6)-参数估计</title>
    <url>/2017/02/18/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86(6)-%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</url>
    <content><![CDATA[<p>在数理统计中，常常需要通过样本来估计总体的参数，估计可划分为两大类：点估计和区间估计。点估计就是估计总体中某个参数的值，而区间估计是估计总体的某个参数落在某个区间的概率大小。本文主要讲述点估计中的矩估计法和最大似然估计法，以及针对服从正态分布的期望和方差进行区间估计。</p>
<span id="more"></span>
<h2 id="点估计">点估计</h2>
<p>点估计一般解决的问题是总体 <span class="math inline">\(X\)</span>
的分布函数 <span class="math inline">\(F(X,\theta)\)</span>
形式为已知，但是 <span class="math inline">\(\theta\)</span>
参数未知。点估计的目的就是通过样本 <span
class="math inline">\(X\_1,X\_2,...X\_n\)</span> 构造一个适当的统计量
<span
class="math inline">\(\theta&#39;(X\_1,X\_2,...X\_n)\)</span>，用于作为未知参数
<span class="math inline">\(\theta\)</span> 的近似值。由于 <span
class="math inline">\(\theta&#39;\)</span>
是样本的函数，因此对于不同的样本，<span
class="math inline">\(\theta&#39;\)</span> 的值一般不同。</p>
<p>点估计中一般用到的方法包括<strong>矩估计法和最大似然估计法</strong>。</p>
<h3 id="矩估计法">矩估计法</h3>
<p><strong>矩估计法的核心思想是样本矩总是依概率收敛于相应的总体矩，因此可通过样本矩作为相应的总体矩的估计量，进而根据总体矩与待估参数的关系求出待估参数。</strong></p>
<p>矩估计法的一般描述如下： 设 <span class="math inline">\(X\)</span>
为连续型随机变量，其概率密度函数为 <span
class="math inline">\(f(x;\theta\_1,
\theta\_2,..\theta\_k)\)</span>；离散型随机变量，其分布律为<span
class="math inline">\(P(X=x) = p(x; \theta\_1,
\theta\_2,..\theta\_k)\)</span>；则总体的 <span
class="math inline">\(k\)</span> 阶矩分别为 <span
class="math display">\[\mu\_k = E(X^k) =  \int\_{-\infty}^{\infty}
x^kf(x;\theta\_1, \theta\_2...\theta\_k) dx\]</span> <span
class="math display">\[\mu\_k = E(X^k) =  \sum\_{x \in R\_x}
x^kp(x;\theta\_1, \theta\_2....\theta\_k)\]</span></p>
<p>上式中的 <span class="math inline">\(R\_x\)</span> 是 <span
class="math inline">\(X\)</span> 可能取值的范围；上面是总体的 k
阶矩的定义，但是实际估计时，往往到只需要使用其一阶矩和二阶矩，也就是
<span class="math inline">\(E(X)\)</span> 和 <span
class="math inline">\(E(X^2)\)</span>。</p>
<p>而样本 <span class="math inline">\(X\_1, X\_2...X\_n\)</span> 的
<span class="math inline">\(k\)</span> 阶矩的定义为 <span
class="math display">\[A\_k = \frac{1}{n}
\sum\_{i=1}^{n}X\_i^k\]</span></p>
<p>由于总体的 k 阶矩往往是未知参数 <span
class="math inline">\(\theta\)</span> 的函数，因此常常先用总体的 k 阶
<span class="math inline">\(\mu\_k\)</span> 矩将参数 <span
class="math inline">\(\theta\)</span> 表示出来，然后用样本矩 <span
class="math inline">\(A\_k\)</span> 代替 <span
class="math inline">\(\mu\_k\)</span>,进而得出估计的 <span
class="math inline">\(\theta\)</span> 的值。下面是一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1bbtqbjdvkhlh8raho11oihu79.png"
alt="矩估计法的例子" />
<figcaption aria-hidden="true">矩估计法的例子</figcaption>
</figure>
<h3 id="最大似然估计法">最大似然估计法</h3>
<p><strong>最大似然估计的思想是既然当前取得了这组样本，那么有理由相信已取得的样本出现的概率是很大的。因此通过极大化这组样本的联合概率来估计未知参数的值。</strong></p>
<h4 id="离散型总体">离散型总体</h4>
<p>单总体为离散型的时候，设当前样本为 <span
class="math inline">\(X\_1,X\_2,...X\_n\)</span>， 则其联合概率为 <span
class="math inline">\(\prod\_{i=1}^{n} p(x\_i;\theta)\)</span>, 其中
<span class="math inline">\(x\_i\)</span> 是 <span
class="math inline">\(X\_i\)</span>
相应的观测值，则上面的联合概率实际上是参数 <span
class="math inline">\(\theta\)</span> 的函数，记为<span
class="math display">\[L(\theta) = \prod\_{i=1}^{n}
p(x\_i;\theta)\]</span> 上面的 <span
class="math inline">\(L(\theta)\)</span>
被称为样本的<strong>似然函数</strong>。</p>
<p>选择 <span class="math inline">\(\theta\)</span> 的值使得 <span
class="math inline">\(L(\theta)\)</span>
最大便是最大似然估计做的事情。一般通过对
似然函数求导便可求得其最大值对应的 <span
class="math inline">\(\theta\)</span>。如下是一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1bbtrksj91lu411vmcbu1ncb11u4m.png"
alt="离散型极大似然估计" />
<figcaption aria-hidden="true">离散型极大似然估计</figcaption>
</figure>
<p>上面最后求解的结果是 <span class="math inline">\(p&#39; = \overline
x\)</span>。同时也注意到求解似然函数最大化时会先对似然函数取 <span
class="math inline">\(log\)</span> ,
目的是将连乘变为连加，方便运算，同时这种方法也被称为对数极大似然估计。</p>
<h4 id="连续型总体">连续型总体</h4>
<p>若总体是连续型，设其概率密度函数为 <span
class="math inline">\(f(x,\theta)\)</span>，则当前样本 <span
class="math inline">\(X\_1,X\_2,...X\_n\)</span> 的联合概率密度函数为
<span class="math display">\[\prod\_{i=1}^{n}f(x\_i;\theta)\]</span>
其中 <span class="math inline">\(x\_1,x\_2,...x\_n\)</span>
是相应于样本的一个样本值，则随机点落在 （<span
class="math inline">\(x\_1,x\_2,...x\_n\)</span>）的领域（边长为 <span
class="math inline">\(dx\_1,
dx\_2,...dx\_n\)</span>的n维立方体）内的概率近似为<span
class="math display">\[\prod\_{i=1}^{n}f(x\_i;\theta)dx\_i\]</span></p>
<p>同样我们要让上式取到最大，但是因子 <span
class="math inline">\(\prod\_{i=1}^{n}dx\_i\)</span> 不随 <span
class="math inline">\(\theta\)</span> 改变，因此只需考虑函数$ L() =
_{i=1}^{n}f(x_i;)$最大即可，这里 <span
class="math inline">\(L(\theta)\)</span>
被称为似然函数，极大化也是通过求导来解决。</p>
<p>下面是一个连续型总体进行极大似然估计的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1bbtt8so0bb71rpm16dh1ces19u13.png"
alt="正态分布" />
<figcaption aria-hidden="true">正态分布</figcaption>
</figure>
<h3 id="评选标准">评选标准</h3>
<p>对于同一参数，不同的估计方法求出的估计量可能不一样，那么如何判断不同的估计量之间的优劣，<strong>无偏性，有效性和相合性</strong>是常用的三个指标。</p>
<h4 id="无偏性">无偏性</h4>
<p>无偏性指的是从样本中得到的估计量 <span
class="math inline">\(\theta&#39;\)</span> 的期望与总体的参数 <span
class="math inline">\(\theta\)</span> 相等，也就是 <span
class="math display">\[E(\theta&#39;) = \theta\]</span> 此时称 <span
class="math inline">\(\theta&#39;\)</span> 是 <span
class="math inline">\(\theta\)</span>
的无偏估计量。无偏估计量的意义是对于某些样本值，这一估计量得到的估计值比真实值要打，而对于另外一些样本则偏小，反复将这一估计量使用多次，就平均来说其偏差为零。</p>
<h4 id="有效性">有效性</h4>
<p>当两个估计量 <span class="math inline">\(\theta\_1&#39;,
\theta\_2&#39;\)</span>
均是无偏估计量时，就要通过比较他们的有效性来决定选取哪个估计量。有效性指的是在样本容量
<span class="math inline">\(n\)</span> 相同的情况下，假如 <span
class="math inline">\(\theta\_1&#39;\)</span> 的观察值较 <span
class="math inline">\(\theta\_2&#39;\)</span> 的值更密集在真值 <span
class="math inline">\(\theta\)</span> 附近，那么认为<span
class="math inline">\(\theta\_1&#39;\)</span> 比 <span
class="math inline">\(\theta\_2&#39;\)</span> 更为理想。</p>
<p>实际上，上面比较的就是两个估计量的方差大小，方差越小，则越有效，因此当两个总体的样本数相同的时候，若
<span class="math inline">\(D(\theta\_1&#39;) &lt;
D(\theta\_2&#39;)\)</span> 时， 就称 <span
class="math inline">\(\theta\_1&#39;\)</span> 比 <span
class="math inline">\(\theta\_2&#39;\)</span> 更有效。</p>
<h4 id="相合性">相合性</h4>
<p>当样本数目 <span class="math inline">\(n \rightarrow \infty\)</span>
时，估计量 <span
class="math inline">\(\theta&#39;(X\_1，X\_2...X\_n)\)</span>
依概率收敛于真正的 <span class="math inline">\(\theta\)</span> ,则称
<span class="math inline">\(\theta&#39;\)</span> 为 <span
class="math inline">\(\theta\)</span>
的相合估计量。即有以下式子成立<span class="math display">\[ \lim\_{n
\rightarrow \infty}P(|\theta&#39; - \theta| &lt; \epsilon) =
1\]</span></p>
<p>相合性是一个估计量的基本要求，如果估计量没有相合性，那么无论样本数量
n 取多大，这些估计量都无法准确估计正确参数，都是不可取的。</p>
<h2 id="区间估计">区间估计</h2>
<p>对于总体中的未知参数，我们的估计总是存在着一定的误差的，如何去衡量这个误差是一个需要考虑的事情。同时，除了上面的点估计，在实际中我们往往还希望估计出参数的一个范围，同时参数落在这个范围的概率，或者是说可信程度。</p>
<p>估计参数落在某个范围以及落在这个范围的可信程度就是区间估计干的事情。</p>
<p>其严格定义如下 &gt;设总体的分布中存在一个未知参数 <span
class="math inline">\(\theta\)</span>, 对于给定的值 <span
class="math inline">\(\alpha(0 &lt; \alpha &lt;1)\)</span>, 若通过样本
<span class="math inline">\(X\_1,X\_2,X\_3...X\_n\)</span>
估计的两个统计量 <span class="math inline">\(\theta&#39;\_1\)</span> 和
<span class="math inline">\(\theta&#39;\_2\)</span>满足下面不等式时<span
class="math display">\[P(\theta&#39;\_1 &lt; \theta &lt; \theta&#39;\_2)
\ge 1 - \alpha\]</span>则称区间 <span
class="math inline">\((\theta&#39;\_1, \theta&#39;\_2)\)</span> 是参数
<span class="math inline">\(\theta\)</span> 置信水平为 <span
class="math inline">\(1-\alpha\)</span> 的置信区间, <span
class="math inline">\(\theta&#39;\_1, \theta&#39;\_2\)</span>
分别称为置信下限和置信上限。</p>
<p>上面式子的含义是若反复抽样多次（每次得到的样本的容量相等），每个样本值确定一个区间<span
class="math inline">\((\theta&#39;\_1,
\theta&#39;\_2)\)</span>，这个区间要么包含 <span
class="math inline">\(\theta\)</span> 的真值，要么不包含 <span
class="math inline">\(\theta\)</span> 的真值,在这么多的区间中，包含
<span class="math inline">\(\theta\)</span> 真值的约占 <span
class="math inline">\(1-\alpha\)</span>.</p>
<h3 id="正态分布均值与方差的区间估计">正态分布均值与方差的区间估计</h3>
<p>由于正态分布的普遍性，下面主要讲述对正态分布的期望和方差进行区间估计的方法，而这里会用到我们前面讲到的统计量的三大分布：
<span class="math inline">\(\chi^2\)</span> 分布， <span
class="math inline">\(t\)</span> 分布， <span
class="math inline">\(F\)</span>
分布，以及对其拓展的一些定理，具体的定理及其证明可参考<a
href="http://wulc.me/2016/11/18/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%285%29--%E6%A0%B7%E6%9C%AC%E5%8F%8A%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/">这篇文章</a>。</p>
<p>下面会讲述单个正态分布的期望和方差的估计，以及两个正态分布的期望差和方差比的估计。</p>
<h4 id="单个正态分布">单个正态分布</h4>
<p>下面的关于单个正态分布的讨论都是基于以下假设：给定置信水平为 <span
class="math inline">\(1-\alpha\)</span>, 设 <span
class="math inline">\(X\_1,X\_2,X\_3...X\_n\)</span> 为总体 <span
class="math inline">\(N(\mu, \sigma^2)\)</span> 的样本，<span
class="math inline">\(\overline X，S^2\)</span>
分别是样本的期望和方差。</p>
<h5 id="估计期望-mu-的置信区间">估计期望 <span
class="math inline">\(\mu\)</span> 的置信区间</h5>
<p>通过样本 <span class="math inline">\(X\_1,X\_2,X\_3...X\_n\)</span>
估计总体 <span class="math inline">\(N(\mu, \sigma^2)\)</span> 的期望
<span class="math inline">\(\mu\)</span> 时可以分为两种情况：</p>
<ol type="1">
<li>总体的方差 <span class="math inline">\(\sigma^2\)</span> 已知</li>
<li>总体的方差 <span class="math inline">\(\sigma^2\)</span> 未知</li>
</ol>
<p><strong>总体的方差 <span class="math inline">\(\sigma^2\)</span>
已知</strong> 若已知总体的方差，则因为 <span
class="math inline">\(\overline X \sim N(\mu , \sigma^2/n)\)</span>,
即<span class="math inline">\(\frac{\overline X -
\mu}{\sqrt{\sigma^2/n}} \sim N(0,1)\)</span>,
下面都会这样不加证明给出这些统计量服从的分布，具体的证明参考<a
href="http://wulc.me/2016/11/18/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%285%29--%E6%A0%B7%E6%9C%AC%E5%8F%8A%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83/">这篇文章</a>。</p>
<p>按照标准正态分布的上 <span class="math inline">\(\alpha\)</span>
分位点的定义有 <span class="math display">\[P(|\frac{\overline X -
\mu}{\sqrt{\sigma^2/n}} | &lt; z\_{\alpha/2}) = 1 - \alpha\]</span></p>
<p>从概率密度函数上直观看为：</p>
<figure>
<img src="https://wulc.me/imgs/image_1bc2bajjf1jgrove10r6tah1ub19.png"
alt="正态分布分位点" />
<figcaption aria-hidden="true">正态分布分位点</figcaption>
</figure>
<p>进一步化简有 <span class="math display">\[P(\overline X -
\frac{\sigma}{\sqrt{n}}z\_{\alpha/2} &lt; \mu &lt; \overline X +
\frac{\sigma}{\sqrt{n}}z\_{\alpha/2}) = 1 - \alpha\]</span></p>
<p>给定 <span class="math inline">\(\alpha, z\_{\alpha/2}\)</span>
的值可以通过查表获得。这样便得到了期望 <span
class="math inline">\(\mu\)</span> 的一个估计区间为 <span
class="math inline">\((\overline X -
\frac{\sigma}{\sqrt{n}}z\_{\alpha/2}, \overline X +
\frac{\sigma}{\sqrt{n}}z\_{\alpha/2})\)</span>, 其置信度为 <span
class="math inline">\(1 - \alpha\)</span>。注意置信水平为 <span
class="math inline">\(1 - \alpha\)</span>
的置信区间并不是唯一的，假如说给定 <span class="math inline">\(\alpha =
0.05\)</span>, 则上面的式子可写为<span
class="math display">\[P(\overline X - \frac{\sigma}{\sqrt{n}}z\_{0.025}
&lt; \mu &lt; \overline X + \frac{\sigma}{\sqrt{n}}z\_{0.025}) = 1 -
\alpha\]</span></p>
<p>同时也可写为 <span class="math display">\[P(\overline X -
\frac{\sigma}{\sqrt{n}}z\_{0.04} &lt; \mu &lt; \overline X +
\frac{\sigma}{\sqrt{n}}z\_{0.01}) = 1 - \alpha\]</span></p>
<p>但是写成不对称的形式计算出来的区间长度要更长，显然，置信度相同的情况下，置信区间肯定是越小越好，所以对于正态分布的分位点往往选择对称形式。</p>
<p>下面的求解方法与这方法类似，只是构造的统计量不同，因而服从的分布也不同。</p>
<p><strong>总体的方差 <span class="math inline">\(\sigma^2\)</span>
未知</strong></p>
<p>当总体方差未知时，就无法利用上面标准正态分布。但是回忆 <span
class="math inline">\(t\)</span> 分布的作用及其定理，可知</p>
<p><span class="math display">\[\frac{\overline X - \mu}{S/\sqrt{n}}
\sim t(n-1)\]</span></p>
<p>同样按照 <span class="math inline">\(t\)</span> 分布的上 <span
class="math inline">\(\alpha\)</span> 分位点的定义有 <span
class="math display">\[P(|\frac{\overline X - \mu}{S/\sqrt{n}}| &lt;
t\_{\alpha/2}(n-1)) = 1 - \alpha\]</span></p>
<p>其对应的概率密度函数如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bc2de1u91i7gd9q1shjm7spnam.png"
alt="t分布的概率密度函数" />
<figcaption aria-hidden="true">t分布的概率密度函数</figcaption>
</figure>
<p>进一步化简可得 <span class="math display">\[P(\overline X -
\frac{S}{\sqrt{n}}t\_{\alpha/2}(n - 1) &lt; \mu &lt; \overline X +
\frac{S}{\sqrt{n}}t\_{\alpha/2}(n - 1)) = 1 - \alpha\]</span></p>
<p>则期望 <span class="math inline">\(\mu\)</span> 的一个置信水平为
<span class="math inline">\(1-\alpha\)</span> 的置信区间为 <span
class="math display">\[(\overline X - \frac{S}{\sqrt{n}}t\_{\alpha/2}(n
- 1), \overline X + \frac{S}{\sqrt{n}}t\_{\alpha/2}(n - 1))\]</span></p>
<h5 id="估计方差-sigma2-的置信区间">估计方差 <span
class="math inline">\(\sigma^2\)</span> 的置信区间</h5>
<p>估计方差 <span class="math inline">\(\sigma^2\)</span>
的置信区间也可分为两种情况</p>
<ol type="1">
<li>总体的期望 <span class="math inline">\(\mu\)</span> 已知</li>
<li>总体的期望 <span class="math inline">\(\mu\)</span> 未知</li>
</ol>
<p><strong>总体的期望 <span class="math inline">\(\mu\)</span>
已知</strong></p>
<p>当期望 <span class="math inline">\(\mu\)</span> 已知时，求解方差
<span class="math inline">\(\sigma^2\)</span>
的置信区间的方法跟上面已知方差 <span
class="math inline">\(\sigma^2\)</span> 求解期望 <span
class="math inline">\(\mu\)</span> 的一样，都是利用 <span
class="math inline">\(\frac{\overline X - \mu}{\sqrt{\sigma^2/n}} \sim
N(0,1)\)</span>，然后写出对应未知量的区间，这里就不详细讲述已知 <span
class="math inline">\(\mu\)</span> 求解方差 <span
class="math inline">\(\sigma^2\)</span> 的详细过程了。</p>
<p><strong>总体的期望 <span class="math inline">\(\mu\)</span>
未知</strong></p>
<p>当期望 <span class="math inline">\(\mu\)</span> 未知时，求解方差
<span class="math inline">\(\sigma^2\)</span>
的区间估计就再也不能利用上面的 <span
class="math inline">\(\frac{\overline X - \mu}{\sqrt{\sigma^2/n}} \sim
N(0,1)\)</span>。结合 <span class="math inline">\(\chi^2\)</span>
分布的特性及其推导的定理可知</p>
<p><span class="math display">\[\frac{(n-1)S^2}{\sigma^2} \sim
\chi^2(n-1)\]</span></p>
<p>同样按照 <span class="math inline">\(\chi^2\)</span> 分布的 <span
class="math inline">\(\alpha\)</span> 分位点的定义有</p>
<p><span class="math display">\[P( \chi^2\_{1 - \alpha/2}(n-1) &lt;
\frac{(n-1)S^2}{\sigma^2} &lt; \chi^2\_{\alpha/2}(n-1)) = 1 -
\alpha\]</span></p>
<p>注意这里不能用绝对值了，原因是 <span
class="math inline">\(\chi^2\)</span>
分布的概率密度函数不像标准正态分布或 <span
class="math inline">\(t\)</span>
分布那样是对称的。其对应的概率密度函数如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bc2g7o8u16mbarpd82nmie6h13.png"
alt="卡方分布的概率密度函数" />
<figcaption aria-hidden="true">卡方分布的概率密度函数</figcaption>
</figure>
<p>进一步化简可得</p>
<p><span
class="math display">\[P(\frac{(n-1)S^2}{\chi^2\_{\alpha/2}(n-1)} &lt;
\sigma^2 &lt; \frac{(n-1)S^2}{\chi^2\_{1 - \alpha/2}(n-1)}) = 1 -
\alpha\]</span></p>
<p>即给定样本，总体期望 <span class="math inline">\(\mu\)</span>
未知的时候，总体方差 <span class="math inline">\(\sigma^2\)</span>
的一个置信水平为 <span class="math inline">\(1-\alpha\)</span>
的置信区间为</p>
<p><span
class="math display">\[(\frac{(n-1)S^2}{\chi^2\_{\alpha/2}(n-1)},
\frac{(n-1)S^2}{\chi^2\_{1 - \alpha/2}(n-1)})\]</span></p>
<p>实际上， <strong><span class="math inline">\(\chi^2\)</span>
分布的一个作用就是在正态总体分布中期望未知时估计其方差的置信区间</strong>。</p>
<h4 id="两个正态分布">两个正态分布</h4>
<p>下面讲述两个正态分布的期望差值的区间估计以及方差比的估计。考虑以下问题：已知产品的某一质量指标服从正态分布，但由于原料、操作人员不同，或工艺过程的改变等因素，引起总体均值、方差有所变化。我们需要知道这些变化有多大，就需要考虑两个正态分布均值差或方差比的估计问题。</p>
<p>下面的讨论都是假设给定了置信水平为 <span class="math inline">\(1-
\alpha\)</span>, 并设 <span class="math inline">\(X\_1,
X\_2,....X\_n\)</span> 是来自第一个总体 <span
class="math inline">\(N\_1(\mu\_1, \sigma\_1^2)\)</span> 的样本，<span
class="math inline">\(Y\_1, Y\_2,....Y\_n\)</span> 是来自第二个总体
<span class="math inline">\(N\_2(\mu\_2, \sigma\_2^2)\)</span>
的样本，并假设 <span class="math inline">\(\overline X, \overline
Y\)</span> 是第一、第二个样本的均值，<span class="math inline">\(S\_1^2,
S\_2^2\)</span> 是第一、第二个样本的方差。</p>
<h5 id="估计-mu_1---mu_2-的置信区间">估计 <span
class="math inline">\(\mu\_1 - \mu\_2\)</span> 的置信区间</h5>
<p>估计 <span class="math inline">\(\mu\_1 - \mu\_2\)</span>
的置信区间时也可以分为两种情况</p>
<ol type="1">
<li>总体的方差 <span class="math inline">\(\sigma\_1^2,
\sigma\_2^2\)</span> 已知</li>
<li>总体的方差 <span class="math inline">\(\sigma\_1^2,
\sigma\_2^2\)</span> 未知，但是知道 <span
class="math inline">\(\sigma\_1^2 = \sigma\_2^2 =
\sigma^2\)</span>（<span
class="math inline">\(\sigma\)</span>未知）</li>
</ol>
<p><strong>总体的方差 <span class="math inline">\(\sigma\_1^2,
\sigma\_2^2\)</span> 已知</strong> 由 <span
class="math inline">\(\overline X \sim N(\mu\_1, \sigma\_1^2/n\_1),
\overline Y \sim N(\mu\_2, \sigma\_2^2/n\_2)\)</span> 可知<span
class="math display">\[\overline X - \overline Y \sim N(\mu\_1 - \mu\_2,
\sigma\_1^2/n\_1 + \sigma\_2^2/n\_2)\\ \frac{(\overline X - \overline Y)
- (\mu\_1 - \mu\_2)}{\sqrt{\sigma\_1^2/n\_1 + \sigma\_2^2/n\_2}} \sim
N(0, 1)\]</span></p>
<p>与上面相同，按照标准正态分布的上 <span
class="math inline">\(\alpha\)</span> 分位点的定义有 <span
class="math display">\[P(|\frac{(\overline X - \overline Y) - (\mu\_1 -
\mu\_2)}{\sqrt{\sigma\_1^2/n\_1 + \sigma\_2^2/n\_2}} | &lt;
z\_{\alpha/2}) = 1 - \alpha\]</span></p>
<p>同样可解得 <span class="math inline">\(\mu\_1 - \mu\_2\)</span>
置信度为 <span class="math inline">\(1-\alpha\)</span> 的区间。</p>
<p><strong>总体的方差 <span class="math inline">\(\sigma\_1^2,
\sigma\_2^2\)</span> 未知，但 <span class="math inline">\(\sigma\_1^2 =
\sigma\_2^2 = \sigma^2\)</span>（<span
class="math inline">\(\sigma\)</span>未知）</strong></p>
<p>根据 <span class="math inline">\(t\)</span>
分布的作用及其推导的定理可知</p>
<p><span class="math display">\[\frac{(\overline X - \overline Y) -
(\mu\_1 - \mu\_2)}{S\_w\sqrt{1/n\_1+1/n\_2}} \sim
t(n\_1+n\_2-2)\]</span></p>
<p>其中 <span class="math inline">\(S\_w = \sqrt{\frac{(n\_1
-1)S\_1^2+(n\_2 -1)S\_2^2}{n\_1+n\_2-2}}\)</span></p>
<p>同样根据 <span class="math inline">\(t\)</span> 分布的上 <span
class="math inline">\(\alpha\)</span> 分位点的定义有 <span
class="math display">\[P(|\frac{(\overline X - \overline Y) - (\mu\_1 -
\mu\_2)}{S\_w\sqrt{1/n\_1+1/n\_2}}| &lt; t\_{\alpha/2}(n\_1+n\_2-2)) = 1
- \alpha\]</span></p>
<p>通过查表同样可以求出 <span class="math inline">\(\mu\_1 -
\mu\_2\)</span> 置信度为 <span class="math inline">\(1-\alpha\)</span>
的区间，结合上面 <span class="math inline">\(t\)</span>
分布在单个正态总体分布参数估计的问题可知， <strong><span
class="math inline">\(t\)</span>
分布专门用于解决正态分布中方差未知时估计其期望的问题</strong>。</p>
<h5 id="估计-sigma_12-sigma_22-的置信区间">估计 <span
class="math inline">\(\sigma\_1^2 / \sigma\_2^2\)</span> 的置信区间</h5>
<p>估计 <span class="math inline">\(\sigma\_1^2 / \sigma\_2^2\)</span>
的置信区间同样可以分为两种情况 1. 总体期望 <span
class="math inline">\(\mu\_1, \mu\_2\)</span> 已知 2. 总体期望 <span
class="math inline">\(\mu\_1, \mu\_2\)</span> 未知</p>
<p>总体期望 <span class="math inline">\(\mu\_1, \mu\_2\)</span>
已知时可以先通过标准正态分布求出 <span
class="math inline">\(\sigma\_1^2, \sigma\_2^2\)</span> 各自的范围,
然后求解 <span class="math inline">\(\sigma\_1^2 / \sigma\_2^2\)</span>
的范围。下面主要讲总体期望 <span class="math inline">\(\mu\_1,
\mu\_2\)</span> 未知时，如何估计 <span class="math inline">\(\sigma\_1^2
/ \sigma\_2^2\)</span> 的范围。</p>
<p>由 <span class="math inline">\(F\)</span>
分布的定义以及推导的定理可知</p>
<p><span class="math display">\[\frac{S\_1^2/S\_2^2}{\sigma\_1^2/
\sigma\_2^2} \sim F(n\_1 - 1, n\_2 - 1)\]</span></p>
<p>根据 <span class="math inline">\(F\)</span> 分布的 <span
class="math inline">\(\alpha\)</span> 分位点的定义有</p>
<p><span class="math display">\[P( F\_{1 - \alpha/2}(n\_1 - 1, n\_2 - 1)
&lt; \frac{S\_1^2/S\_2^2}{\sigma\_1^2/ \sigma\_2^2} &lt;
F\_{\alpha/2}(n\_1 - 1, n\_2 - 1)) = 1 - \alpha\]</span></p>
<p>化简可得</p>
<p><span class="math display">\[P(
\frac{S\_1^2}{S\_2^2}\frac{1}{F\_{\alpha/2}(n\_1 - 1, n\_2 - 1)} &lt;
\frac{\sigma\_1^2}{ \sigma\_2^2} &lt;
\frac{S\_1^2}{S\_2^2}\frac{1}{F\_{1 - \alpha/2}(n\_1 - 1, n\_2 - 1)}) =
1 - \alpha\]</span></p>
<p>即 <span class="math inline">\(\sigma\_1^2 / \sigma\_2^2\)</span>
一个置信度为 <span class="math inline">\(1-\alpha\)</span> 的置信区间为
<span
class="math display">\[(\frac{S\_1^2}{S\_2^2}\frac{1}{F\_{\alpha/2}(n\_1
- 1, n\_2 - 1)} &lt; \frac{\sigma\_1^2}{ \sigma\_2^2},
\frac{S\_1^2}{S\_2^2}\frac{1}{F\_{1 - \alpha/2}(n\_1 - 1, n\_2 -
1)})\]</span></p>
<h4 id="小结">小结</h4>
<p>在上面对正态分布总体进行参数估计中，用到了数理统计中的三大分布：
<span class="math inline">\(\chi^2\)</span>分布， <span
class="math inline">\(t\)</span>分布和<span
class="math inline">\(F\)</span>分布， 其中 <strong><span
class="math inline">\(\chi^2\)</span>
分布主要解决总体期望未知时估计其方差的问题， <span
class="math inline">\(t\)</span>
分布主要解决总体方差未知时估计其期望的问题，<span
class="math inline">\(F\)</span>
主要解决期望未知时两个正态分布的方差比值问题。</strong></p>
<h3 id="单侧置信区间">单侧置信区间</h3>
<p>上面均是讨论未知参数 <span class="math inline">\(\theta\)</span>
的双侧置信区间，但是在实际问题中，往往考虑的只是一个上限或下限，比如说设备、原件的寿命我们关心的是平均寿命
<span class="math inline">\(\theta\)</span>
的下限。这就引出了单侧置信区间的概念。单侧置信区间跟双侧置信区间的概念非常类似。</p>
<blockquote>
<p>总体的参数 <span class="math inline">\(\theta\)</span> 未知,
对于给定的 <span class="math inline">\(\alpha\)</span> ,若由样本 <span
class="math inline">\(X\_1, X\_2..X\_n\)</span> 确定的统计量 <span
class="math inline">\(\theta&#39;\)</span>满足<span
class="math display">\[P(\theta &gt; \theta&#39;) = 1 -
\alpha\]</span>则称 <span class="math inline">\((\theta&#39;,
\infty)\)</span> 是参数 <span class="math inline">\(\theta\)</span>
的置信水平为 <span class="math inline">\(1 - \alpha\)</span>
的单侧置信区间，而 <span class="math inline">\(\theta&#39;\)</span>
是单侧置信下限，将 <span class="math inline">\(\theta &gt;
\theta&#39;\)</span> 变为 <span class="math inline">\(\theta &lt;
\theta&#39;\)</span> 后，相应地变为单侧置信上限。</p>
</blockquote>
<p>单侧置信区间的计算方法与上面提到的双侧置信区间的计算方法已知，都是根据给定的
<span class="math inline">\(\alpha\)</span>
值和统计量服从的分布去查表，找到相应的分位点后带入不等式求解目标估计量的范围即可。</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>浏览器缓存机制</title>
    <url>/2016/02/12/%E6%B5%8F%E8%A7%88%E5%99%A8%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>最近看到一篇比较好的关于浏览器缓存的文章，<a
href="http://www.cnblogs.com/skynet/archive/2012/11/28/2792503.html">原文链接</a>,原文内容如下</p>
<span id="more"></span>
<p>浏览器缓存机制，其实主要就是HTTP协议定义的缓存机制（如： Expires；
Cache-control等）。但是也有非HTTP协议定义的缓存机制，如使用HTML Meta
标签，Web开发者可以在HTML页面的&lt; head &gt;节点中加入&lt; meta
&gt;标签，代码如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">META</span> <span class="attr">HTTP-EQUIV</span>=<span class="string">&quot;Pragma&quot;</span> <span class="attr">CONTENT</span>=<span class="string">&quot;no-cache&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>上述代码的作用是<strong>告诉浏览器当前页面不被缓存</strong>，每次访问都需要去服务器拉取。使用上很简单，但<strong>只有部分浏览器可以支持</strong>，而且<strong>所有缓存代理服务器都不支持，因为代理不解析HTML内容本身。</strong></p>
<p>下面我主要介绍HTTP协议定义的缓存机制。</p>
<h2 id="expires策略"><strong>Expires策略</strong></h2>
<p>Expires是Web服务器响应消息头字段，在响应http请求时告诉浏览器在过期时间前浏览器可以直接从浏览器缓存取数据，而无需再次请求。</p>
<p>下面是宝宝PK项目中，浏览器拉取jquery.js web服务器的响应头：</p>
<p><img src="https://wulc.me/imgs/201211281402425894.png" /></p>
<p>【注：Date头域表示消息发送的时间，时间的描述格式由rfc822定义。例如，Date:
Mon,31 Dec 2001 04:25:57GMT。】</p>
<p>Web服务器告诉浏览器在2012-11-28
03:30:01这个时间点之前，可以使用缓存文件。发送请求的时间是2012-11-28
03:25:01，即缓存5分钟。</p>
<p>不过 <strong>Expires 是HTTP 1.0的东西，现在默认浏览器均默认使用HTTP
1.1，所以它的作用基本忽略。</strong></p>
<h2
id="cache-control策略重点关注"><strong>Cache-control策略（重点关注）</strong></h2>
<p>Cache-Control与Expires的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存取数据还是重新发请求到服务器取数据。只不过Cache-Control的选择更多，设置更细致，如果同时设置的话，其优先级高于Expires。</p>
<p>http协议头Cache-Control ： 值可以是public、private、no-cache、no-
store、no-transform、must-revalidate、proxy-revalidate、max-age
各个消息中的指令含义如下： |值|含义| |:--|:--:|
|public|指示响应可被任何缓存区缓存|
|private|指示对于单个用户的整个或部分响应消息，不能被共享缓存处理。这允许服务器仅仅描述当用户的部分响应消息，此响应消息对于其他用户的请求无效|
|no-cache|指示请求或响应消息不能缓存|
|no-store|用于防止重要的信息被无意的发布。在请求消息中发送将使得请求和响应消息都不使用缓存|
|max-age|指示客户机可以接收生存期不大于指定时间（以秒为单位）的响应|
|min-fresh|指示客户机可以接收响应时间小于当前时间加上指定时间的响应|
|max-stale|指示客户机可以接收超出超时期间的响应消息。如果指定max-stale消息的值，那么客户机可以接收超出超时期指定值之内的响应消息|</p>
<p>还是上面那个请求，web服务器返回的Cache-Control头的值为max-age=300，即5分钟（和上面的Expires时间一致，这个不是必须的）。</p>
<p><img src="https://wulc.me/imgs/201211281402428992.png" /></p>
<h2
id="last-modifiedif-modified-since"><strong>Last-Modified/If-Modified-Since</strong></h2>
<p>Last-Modified/If-Modified-Since要配合Cache-Control使用。</p>
<ul>
<li><strong>Last-Modified</strong>：标示这个响应资源的最后修改时间。web服务器在响应请求时，<strong>告诉浏览器资源的最后修改时间</strong>。</li>
<li><strong>If-Modified-Since</strong>：当资源过期时（使用Cache-Control标识的max-age），发现资源具有Last-Modified声明，则<strong>再次向web服务器请求时带上头
If-Modified-Since，表示请求时间</strong>。web服务器收到请求后发现有头If-Modified-Since
则与被请求资源的最后修改时间进行比对。</li>
</ul>
<p><strong>若最后修改时间较新，说明资源又被改动过，则响应整片资源内容（写在响应消息包体内），HTTP
200；若最后修改时间较旧，说明资源无新修改，则响应HTTP 304
(无需包体，节省浏览)，告知浏览器继续使用所保存的cache。</strong></p>
<h2 id="etagif-none-match"><strong>Etag/If-None-Match</strong></h2>
<p>Etag/If-None-Match也要配合Cache-Control使用。</p>
<ul>
<li><strong>Etag</strong>：web服务器响应请求时，告诉浏览器当前<strong>资源在服务器的唯一标识</strong>（生成规则由服务器决定）。Apache中，ETag的值，默认是对文件的索引节（INode），大小（Size）和最后修改时间（MTime）进行Hash后得到的。</li>
<li><strong>If-None-Match</strong>：当资源过期时（使用Cache-Control标识的max-age），发现资源具有Etage声明，则再次<strong>向web服务器请求时带上头If-None-Match
（Etag的值）。</strong>web服务器收到请求后发现有头If-None-Match
则与被请求资源的相应校验串进行比对，决定返回200或304。</li>
</ul>
<h2
id="既生last-modified何生etag"><strong>既生Last-Modified何生Etag？</strong></h2>
<p>你可能会觉得使用Last-Modified已经足以让浏览器知道本地的缓存副本是否足够新，为什么还需要Etag（实体标识）呢？HTTP1.1中Etag的出现主要是为了解决几个Last-Modified比较难解决的问题：</p>
<ul>
<li><strong>Last-Modified标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间</strong></li>
<li><strong>如果某些文件会被定期生成，当有时内容并没有任何变化，但Last-Modified却改变了，导致文件没法使用缓存</strong></li>
<li><strong>有可能存在服务器没有准确获取文件修改时间，或者与代理服务器时间不一致等情形</strong></li>
</ul>
<p>Etag是服务器自动生成或者由开发者生成的对应资源在服务器端的唯一标识符，能够更加准确的控制缓存。<strong>Last-Modified与ETag是可以一起使用的，服务器会优先验证ETag</strong>，一致的情况下，才会继续比对Last-Modified，最后才决定是否返回304。</p>
<h2 id="用户行为与缓存"><strong>用户行为与缓存</strong></h2>
<p>浏览器缓存行为还有用户的行为有关！！！</p>
<table>
<thead>
<tr class="header">
<th>用户操作</th>
<th>Expires/Cache-Control</th>
<th>Last-Modified/Etag</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>地址栏回车</td>
<td>有效</td>
<td>有效</td>
</tr>
<tr class="even">
<td>页面链接跳转</td>
<td>有效</td>
<td>有效</td>
</tr>
<tr class="odd">
<td>新开窗口</td>
<td>有效</td>
<td>有效</td>
</tr>
<tr class="even">
<td>前进、后退</td>
<td>有效</td>
<td>有效</td>
</tr>
<tr class="odd">
<td>F5刷新</td>
<td>无效</td>
<td>有效</td>
</tr>
<tr class="even">
<td>Ctrl+F5刷新</td>
<td>无效</td>
<td>无效</td>
</tr>
</tbody>
</table>
<h2 id="总结"><strong>总结</strong></h2>
<p>浏览器第一次请求：</p>
<p><img src="https://wulc.me/imgs/201211281402437422.png" /></p>
<p>浏览器再次请求时：</p>
<p><img src="https://wulc.me/imgs/201211281402442505.png" /></p>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>深度优先搜索和广度优先搜索</title>
    <url>/2015/12/03/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%E5%92%8C%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/</url>
    <content><![CDATA[<p>在图论中图的遍历是非常常见的操作，两种图的遍历的经典方法：深度优先搜索和广度优先搜索。因为经常忘记其实现方法，这里特意写篇文章记录这两种方法的实现的关键点。可能会存在很多实现方法，这里只记录我知道而且觉得最好理解的方法。
　　 <span id="more"></span></p>
<h2 id="深度优先搜索">深度优先搜索</h2>
<p>　　深度优先搜索实现的一个关键的思想就是<code>递归</code>。
　　关键代码如下： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> i)</span></span>&#123;</span><br><span class="line">    cout&lt;&lt;i&lt;&lt;<span class="string">&#x27; &#x27;</span>; <span class="comment">//输出点i，代表访问这个点</span></span><br><span class="line">    visited[i]=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++)</span><br><span class="line">        <span class="comment">//访问与点i有连接且还没访问的点</span></span><br><span class="line">        <span class="keyword">if</span>( edge[i][j] == <span class="number">1</span> &amp;&amp; visited[j]==<span class="number">0</span> )&#123; </span><br><span class="line">            <span class="built_in">dfs</span>(j); <span class="comment">//对访问的点再进行深搜</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">return</span> ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>　　完整代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> edge[<span class="number">1000</span>][<span class="number">1000</span>] = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"><span class="type">int</span> visited[<span class="number">1000</span>] = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"><span class="type">int</span> nodes;</span><br><span class="line"><span class="type">int</span> edges;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> i)</span></span>&#123;</span><br><span class="line">	cout &lt;&lt; i &lt;&lt; <span class="string">&#x27; &#x27;</span>; <span class="comment">//输出点i，代表访问这个点</span></span><br><span class="line">		visited[i] = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j&lt;nodes; j++)</span><br><span class="line">		<span class="comment">//访问与点i有连接且还没访问的点</span></span><br><span class="line">		<span class="keyword">if</span> (edge[i][j] == <span class="number">1</span> &amp;&amp; visited[j] == <span class="number">0</span>)&#123;</span><br><span class="line">			<span class="built_in">dfs</span>(j); <span class="comment">//对访问的点再进行深搜</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> s, d;</span><br><span class="line">	cin &gt;&gt; nodes &gt;&gt; edges;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i&lt;edges; i++)&#123;</span><br><span class="line">		cin &gt;&gt; s &gt;&gt; d;</span><br><span class="line">		edge[s][d] = <span class="number">1</span>;</span><br><span class="line">		edge[d][s] = <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">dfs</span>(<span class="number">0</span>);<span class="comment">//从第0个点开始</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输入: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">5 5</span><br><span class="line">0 1</span><br><span class="line">0 2</span><br><span class="line">0 4</span><br><span class="line">1 3</span><br><span class="line">2 4</span><br></pre></td></tr></table></figure> 输出： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0 1 3 2 4 </span><br></pre></td></tr></table></figure></p>
<h2 id="广度优先搜索">广度优先搜索</h2>
<p>　　广度优先搜索实现的一个关键点是通过<code>队列</code>来存储访问过的点，并以队列里面的点作为始点访问其周围的点。
　　关键代码见下： <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; que; <span class="comment">//存储已经访问过的点</span></span><br><span class="line"><span class="type">int</span> head=tail=<span class="number">0</span>; <span class="comment">//head表示当前所访问的点，tail表示最后一个点的后一个点</span></span><br><span class="line">visited[<span class="number">0</span>]=<span class="number">1</span>;<span class="comment">//从第0个点开始访问，访问过的点加入到队列中</span></span><br><span class="line">que.<span class="built_in">push_back</span>(<span class="number">0</span>);</span><br><span class="line">tail++；</span><br><span class="line"><span class="keyword">while</span>(head&lt;tail)&#123; <span class="comment">//当head和tail相等时表示所有点已经访问过了</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;nodes;i++)&#123;</span><br><span class="line">        <span class="type">int</span> cur=que[head];<span class="comment">//获取当前访问节点</span></span><br><span class="line">        <span class="comment">//将与访问点距离为1且还没访问的点加入到队列中</span></span><br><span class="line">        <span class="keyword">if</span>( edge[cur][i] == <span class="number">1</span>  &amp;&amp; visited[i]==<span class="number">0</span> )&#123;</span><br><span class="line">            que.<span class="built_in">push_back</span>(i);</span><br><span class="line">            visited[i]=<span class="number">1</span>;</span><br><span class="line">            tail++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//访问完当前访问点周围的点，再访问下一个点</span></span><br><span class="line">    head++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 　　完整代码见下所示：
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> edge[<span class="number">100</span>][<span class="number">100</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int</span> visited[<span class="number">100</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="type">int</span> nodes,edges, s,d;</span><br><span class="line">    cin&gt;&gt;nodes&gt;&gt;edges;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;edges;i++)&#123;</span><br><span class="line">        cin&gt;&gt;s&gt;&gt;d;</span><br><span class="line">        edge[s][d]=<span class="number">1</span>;</span><br><span class="line">        edge[d][s]=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">vector&lt;<span class="type">int</span>&gt; que; <span class="comment">//存储已经访问过的点</span></span><br><span class="line"><span class="type">int</span> head=<span class="number">0</span>,tail=<span class="number">0</span>; <span class="comment">//head表示当前所访问的点，tail表示最后一个点的后一个点</span></span><br><span class="line">visited[<span class="number">0</span>]=<span class="number">1</span>;<span class="comment">//从第0个点开始访问，访问过的点加入到队列中</span></span><br><span class="line">que.<span class="built_in">push_back</span>(<span class="number">0</span>);</span><br><span class="line">tail++;</span><br><span class="line"><span class="keyword">while</span>(head&lt;tail)&#123; <span class="comment">//当head和tail相等时表示所有点已经访问过了</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;nodes;i++)&#123;</span><br><span class="line">        <span class="type">int</span> cur=que[head];</span><br><span class="line">        <span class="comment">//将与访问点距离为1且还没访问的点加入到队列中</span></span><br><span class="line">        <span class="keyword">if</span>( edge[cur][i] == <span class="number">1</span>  &amp;&amp; visited[i]==<span class="number">0</span> )&#123;</span><br><span class="line">            que.<span class="built_in">push_back</span>(i);</span><br><span class="line">            visited[i]=<span class="number">1</span>;</span><br><span class="line">            tail++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//访问完当前访问点周围的点，再访问下一个点</span></span><br><span class="line">    head++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;que.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">    cout&lt;&lt;que[i]&lt;&lt;<span class="string">&#x27; &#x27;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>输入: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">5 5</span><br><span class="line">0 1</span><br><span class="line">0 2</span><br><span class="line">0 4</span><br><span class="line">1 3</span><br><span class="line">2 4</span><br></pre></td></tr></table></figure> 输出： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0 1 2 4 3</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>图</tag>
        <tag>深度优先搜索</tag>
        <tag>广度优先搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈算力优化</title>
    <url>/2022/10/30/%E6%B5%85%E8%B0%88%E7%AE%97%E5%8A%9B%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<p>当前的推荐或广告系统基本都是做到请求级别的预估和优化，在效果最大化的同时带来的问题是机器成本的上升；而流量分布的不均匀使得这个问题更为严峻，比如说对于抖音或美团，一天内流量往往有两个峰：午高峰和晚高峰，因为这两个时间点餐、刷手机的人数会陡增，而其他时间段流量会下降比较多，如下图所示</p>
<p><img src="https://wulc.me/imgs/unbalanced_traffic.jpg" height="30%" width="30%"></p>
<p>这意味着如果准备足以抗住高峰的机器，那在其他时间段大部分机器是空转的，或者说
roi
很低，因此往往在高峰的时候都需要扩容或降级。降级一般是指指降低请求数，按比例
drop 流量，但是 drop
流量对总体效果肯定是有损的，因此也衍生出了算力优化这个研究方向，算力优化本质上就是做效果和机器成本的
trade-off, 或者说如何尽可能无损地降本</p>
<p>本文主要介绍一些算力优化的常见手段，笔者将其总结为
<strong>drop、cache 和 dynamic</strong>
三类方法；而如果把消耗的算力拆解，可以直观拆成 2 部分：<strong>请求量 ×
请求消耗的算力</strong>，因此可以从这两部分出发去优化算力</p>
<ul>
<li>drop：直接把流量 drop 掉，即直接减少“请求量”</li>
<li>cache：将之前的预估结果存到缓存中，每次预估不用经过实际机器的
inference，即减少了“请求消耗的算力”</li>
<li>dynamic
则是根据请求的价值，动态控制每条请求消耗的算力，这个方法也是减少了“请求消耗的算力”，<a
href="https://arxiv.org/pdf/2006.09684.pdf">DCAF</a>
是这类方法的代表</li>
</ul>
<p>上面的几个方法都是偏流量维度的优化，还有一些方法是对模型 inference 的
耗时进行优化的，主要方向是计算并行（硬件升级）、模型压缩（量化、蒸馏、结构调整等），本文就不详细展开了</p>
<span id="more"></span>
<h2 id="drop">drop</h2>
<p>drop
流量可以说是最原始和粗暴的降级手段，但是在流量突增等场景还是比较有效和立竿见影的手段，除了无差别地
drop 流量的粗暴方式，还可以进一步做得更精细：通过 rule-based 或
model-based 手段来判断一条流量是否要 drop</p>
<p>rule-based
的方法往往需要定义具体业务中的无效请求，比如说这里的“无效”在推荐可能是一些用户无点击且停留时长短的请求，在广告可能是由于没有曝光导致的无扣费等。这样的话就可以梳理出一些基本的规则，比如说针对连续
n 次出无效请求的用户，在下一次的请求可以直接 drop 掉</p>
<p>model-based 的方法跟 ruled-based
方法差不多，一般可建模成一个分类或回归的问题；如果是分类问题，需要明确定义二分类中的正例和负例(即无效请求)；如果是回归问题，需要定义每条流量的价值（如推荐或广告最终排序时使用的预估分）</p>
<p>这里值得注意的点是<strong>为了数据集无偏或者说避免 feedback loop,
需要从不生效 drop 策略的流量中随机划一部分来生成训练集（holdout
数据集）</strong></p>
<h2 id="cache">cache</h2>
<p>cache
也是常用的一种节省算力的手段，即把之前请求的预估结果缓存下来，然后相似请求过来后，把缓存的预估结果直接返回；这里有
2 个关键问题</p>
<p><strong>(1)缓存的粒度</strong>，一般粒度越细，预估结果越准确，但同时消耗的kv
存储会越大；常见的可以考虑的维度包括用户、设备、媒体位置、访问时段等，具体缓存的粒度可以从中选出若干个维度叉乘出来</p>
<p><strong>(2)缓存的预估偏差</strong>，由于不是实时预估的，所以预估偏差往往会比实时预估的要高很多，最直观的解决思路就是在
cache 结果直接再套一个 calibration module（如 <a
href="https://en.wikipedia.org/wiki/Platt_scaling">Platt
scaling</a>）；这个问题其实也跟缓存的 TTL 比较相关，一般 TTL
越大，预估偏差会越大，同时消耗资源会越少，所以保证缓存的预估偏差小对节省资源也是有较大意义的，因为这个时候的
TTL 可以设得更长</p>
<p>这里的预估偏差反映在后验上一般是高估，其实是因为<strong>被低估了的流量竞价会失败而没法曝光</strong>。这个现象跟很多
ab
实验的“<strong>小流量高估问题</strong>”的原因是一样的，实际上并不只是高估，而是预估不准，只是看到的投后数据都是高估投出来的</p>
<p>但这里两者预估不准的原因并不完全一致，前者更多是因为不实时带来的，后者（即小流量高估）本质上则是因为有
2 个模型同时产生训练数据集，两个数据集的分布不太一致（feedback
loop），可理解为有 2 个 domain，然后处于小流量 domain 的模型使用了大流量
domain
的模型产生的数据集，总体<strong>被大流量的模型的数据主导看不到自身的高估</strong>（证据之一就是，如果把两个模型的数据严格隔离开，这个问题会大大缓解，但对大盘有损，因为小流量模型数据太少，这部分流量的变现效率就很低）；所以实际中往往会把一些能区分
domain 的特征（如 model
name、rit等）加入到模型里，也能缓解所谓的小流量高估问题</p>
<h2 id="dynamic">dynamic</h2>
<p>dynamic
可以说是研究得最多的方法，其思想也比较符合直觉：<strong>根据每条流量预估的价值，动态调整每条请求消耗的算力</strong>，如果价值越高，分配的算力越高，反之亦然</p>
<p>基于这个思路，很自然能想到有 3
个需要解决的问题：<strong>（1）流量价值的预估（2）算力的预估（3）分配策略</strong></p>
<p>针对第（1）个问题，在搜广推的业务场景中，会涉及到排序的过程，因此可以把排序分数近似作为流量的价值；对于推荐，这个价值的物理含义可能不是那么强，但对于广告这类业务场景，基于
ecpm 的排序就是意味着这条流量能给平台带来的实际收入</p>
<p>针对第（2）个问题，在召回、粗排、精排的经典三段漏斗中，可以把进入各个模块的候选数来衡量算力；值得注意的是：<strong>候选数和算力两者是正相关，但不是线性的</strong>，后面会详细展开这个问题</p>
<p>针对第（3）个问题，对流量价值和算力进行量化后，可以很自然地用最优化的思路建模这个分配问题，最常见的模式是在算力约束下，最大化流量价值，变量则是每条流量的候选数</p>
<p>分配策略的一个代表性工作是阿里在 2020 发表的 paper，<a
href="https://arxiv.org/pdf/2006.09684.pdf">DCAF: A Dynamic Computation
Allocation Framework for Online Serving System</a>，paper
主要解决的是上面的第三个问题，下面会先讲 paper
中的分配策略，然后再探讨下流量价值和算力建模的一些思路</p>
<h3 id="dcaf">DCAF</h3>
<h4 id="问题建模">问题建模</h4>
<p>paper 很自然把算力分配建模成如下的问题</p>
<p><img src="https://wulc.me/imgs/DCAF_formulation.jpg" height="50%" width="50%"></p>
<p>上面相关符号含义如下</p>
<ul>
<li><span class="math inline">\(i\)</span>: 请求的 index</li>
<li><span class="math inline">\(j\)</span>: action 的 index，这里的
action 一般是指进入各个模块的候选数</li>
<li><span class="math inline">\(x_{ij}\)</span>: 是否采用第 i
条请求中的第 j 个 action，取值为 0 或 1，每条请求只能采用一个
action</li>
<li><span class="math inline">\(q_j\)</span>: 第 j 个 action
消耗的算力资源，注意这里的<strong>假设是相同 action
消耗的算力资源与请求无关</strong></li>
<li><span class="math inline">\(Q_{ij}\)</span>: 第 i 个请求中的第 j 个
action 带来的价值</li>
<li><span class="math inline">\(C\)</span>: 总体的算力限制</li>
</ul>
<p>在建模完这个问题后，paper 提到了这种建模方式面临的 2
个重要问题，其实也是这类最优化范式通常都有的问题</p>
<p>第一个是需要实时求解最优化问题，这个问题的原因在于我们通过这种方式建模时，默认是能拿到全部数据的，如果统计过去
n 天的数据是可以做到的，但是在线上实时 serving 是无法做到这点的</p>
<p>这个问题其实跟 bidding 场景下的最优化建模的问题一致，<a
href="https://wulc.me/2020/07/19/%E3%80%8ABid%20Optimization%20by%20Multivariable%20Control%20in%20Display%20Advertising%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Bid
Optimization by Multivariable Control in Display
Advertising》阅读笔记</a> 是一个例子，而 bidding
的一般套路是<strong>先通过求解最优化问题求解出最优的出价公式的形式，然后线上通过实时调控的来决定公式里的未知变量</strong>，后面我们讨论这个问题的求解时，会发现这篇
paper 里的解决的思路有些不一样，需要直接求解最终的解</p>
<p>第二个是流量价值即 <span class="math inline">\(Q_{ij}\)</span>
计算的问题，paper
里给出的思路是通过模型预估，且提出了模型需要足够轻量级，因为流量维度的预估
qps 会比较大</p>
<h4 id="问题求解">问题求解</h4>
<p>问题求解是通过拉格朗日对偶方法进行求解的，关于这个方法的原理可以参考这篇文章
<a
href="https://wulc.me/2017/05/20/%E5%87%B8%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/">凸优化总结</a>
里面的拉格朗日对偶部分,
根据理论可以写出上面的最优化问题的拉格朗日对偶问题如图下式子（3）所示</p>
<p><img src="https://wulc.me/imgs/lagrange_dual.jpg" height="50%" width="50%"></p>
<p>与 bidding 中的推导不同，<strong>在 bidding
中只需要获取最优出价公式而不需要具体的解</strong>，因此可以最变量直接求导数为
0 推导出最优出价的公式，这部分详细过程可以参考<a
href="https://wulc.me/2020/07/19/%E3%80%8ABid%20Optimization%20by%20Multivariable%20Control%20in%20Display%20Advertising%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Bid
Optimization by Multivariable Control in Display
Advertising》阅读笔记</a> 中的另一种推导方法</p>
<p>而在这里<strong>需要作出具体的决策或者说需要具体的解</strong>，即在请求
<code>i</code> 中应该选择哪个 action，即需要让哪个 <span
class="math inline">\(x_{ij}\)</span> 的值为
1，所以需要求解这个问题，paper 的推导过程如下</p>
<p><img src="https://wulc.me/imgs/problem_derived.jpg" height="50%" width="50%"></p>
<p>下面是笔者对上面推导步骤的理解</p>
<p>1）只有当 <span class="math inline">\(-Q_{ij} + \lambda q_j + \mu_i
\ge 0\)</span>
时，公式（3）中的式子才有下界（笔者不太理解这一点，因为<strong>这里的
<span class="math inline">\(x_{ij}\)</span> 取值是 0 或
1，而不是任意整数，所以即使 <span class="math inline">\(-Q_{ij} +
\lambda q_j + \mu_i \lt
0\)</span>，也不会出现无下界(负无穷)的情况</strong>）</p>
<p>2）有了 <span class="math inline">\(-Q_{ij} + \lambda q_j + \mu_i \ge
0\)</span> 条件后，可以将 min 的约束取消掉，上图的公式
（4）因为这个时候的取 min 一定会使得 <span
class="math inline">\(x_{ij}(-Q_{ij} + \lambda q_j + \mu_i)\)</span>
这一项为 0，这个其实跟推导拉格朗日对偶的过程有点像，如下图所示（<a
href="https://www.bilibili.com/video/BV1HP4y1Y79e/?share_source=copy_web&amp;vd_source=7b70e0a98d81aba8b5e293a7324c3e2a">来源</a>）</p>
<p><img src="https://wulc.me/imgs/lagrange_dual_derive.jpg" height="50%" width="50%"></p>
<p>3）取消掉 min 约束后，剩下的 max 问题的变量就是 <span
class="math inline">\(\lambda\)</span> 和 <span
class="math inline">\(\mu\)</span>, 从约束条件 <span
class="math inline">\(-Q_{ij} + \lambda q_j + \mu_i \ge 0\)</span>
可以推出 <span class="math inline">\(\mu_i \ge Q_{ij} - \lambda
q_j\)</span>，即遍历第 i 个请求下的所有 action 的 <span
class="math inline">\(Q_{ij} - \lambda q_j\)</span> 的最大值，也应该比
<span class="math inline">\(\mu_i\)</span> 小，又因为 max 问题跟 <span
class="math inline">\(\mu_i\)</span> 是负相关的，所以 <span
class="math inline">\(\mu_i\)</span> 的取值应该为公式（5）所示</p>
<p>4）因此，对于第 <span class="math inline">\(i\)</span>
个请求，真正生效的约束条件是 <span class="math inline">\(\max_j (Q_{ij}
- \lambda q_j)\)</span>, （这个约束条件是紧致的），只有这个时候 <span
class="math inline">\(x_{ij}\)</span> 的值才不是0, 亦即最终的
action（见公式（6） ）</p>
<p>因此，从公式 （6）可知，线上 serving 时，还需要知道 <span
class="math inline">\(\lambda\)</span> 的值（<span
class="math inline">\(Q_{ij}\)</span> 和 <span
class="math inline">\(q_j\)</span> 的建模方法下面一部分会讲）</p>
<p>但是 <span class="math inline">\(\lambda\)</span>
的解析解在这个问题中比较难求解，paper 在这里做了 2 个假设</p>
<p><strong>假设一：<span class="math inline">\(Q_{ij}\)</span> 随着
<span class="math inline">\(j\)</span> 的增加而单调递增</strong>
<strong>假设二：<span class="math inline">\(Q_{ij}/q_j\)</span> 随着
<span class="math inline">\(j\)</span> 的增加而单调递增</strong></p>
<p>假设一的含义是随着候选数越多，能从这次价值得到的流量越大（笔者觉得这里还要加个约束，就是线上的资源能抗住的情况下，否则候选数越多可能会导致错误率增加，流量价值下降，paper
后面提到的一个MaxPower
的概念就是在讲这个事情），假设二的含义是随着候选数的增加，边际收益是递减的，这个比较
make sense</p>
<p>基于这两个假设，可以推导出<strong>总体的算力 <span
class="math inline">\(\sum_{ij} x_{ij}q_j\)</span> 会随着 <span
class="math inline">\(\lambda\)</span> 增大而单调递减</strong>,
这部分可参考 paper 中的 4.2
部分，笔者这里做一个更直观的解释，由上面推导的公式（5）可知，<span
class="math inline">\(\max_j (Q_{ij} - \lambda q_j) \ge 0\)</span>, 即
<span class="math inline">\(Q_{ij}/q_j \ge \lambda\)</span>, 而
<strong><span class="math inline">\(Q_{ij}/q_j\)</span>
的物理意义可以理解为单位算力的收益</strong>，由假设 2
可知，随着算力的增加或者说候选数的增加，算力的边际成本是下降的。因此，随着
<span class="math inline">\(\lambda\)</span>
的增加，意味着对算力成本的要求增加，即候选数需要减少（这其实也是 <span
class="math inline">\(\lambda\)</span> 的一个物理含义）</p>
<p>有了上面的“总体的算力 <span class="math inline">\(\sum_{ij}
x_{ij}q_j\)</span> 会随着 <span class="math inline">\(\lambda\)</span>
增大而单调递减”的结论后，可以通过二分法寻找一个 <span
class="math inline">\(\lambda\)</span> 使得消耗的算力刚好接近总体的算力
quota <span class="math inline">\(C\)</span>，算法如下图所示，11
行的符号应该是写反了</p>
<p><img src="https://wulc.me/imgs/DCAF_calc_lambda.jpg" height="50%" width="50%"></p>
<h4 id="系统设计">系统设计</h4>
<p>DCAF 的总体框架如下图所示，左边部分主要是建模 <span
class="math inline">\(Q_{ij}\)</span>, 右边部分则是在线 serving 系统</p>
<p><img src="https://wulc.me/imgs/DCAF_system.jpg" height="50%" width="50%"></p>
<p>左半部分比较好理解，这里着重讲下右半部分，其中右上角的 Information
Collection and Monitoring
部分，会实时搜集当前系统负载的各项数据，如错误率，超时率等，并通过 PID
算法控制错误率和超时率，或者说控制系统当前能承载的上限避免整个系统被打崩，paper
里也把这个称为
MaxPower，可理解为<strong>根据系统的实时负载调整每次请求的候选数的上限</strong></p>
<p>这部分在实验设置里也能体现出来，即随着系统负载 qps 增加，MaxPower
会自动下调，保证整体系统的稳定性，如下图所示</p>
<p><img src="https://wulc.me/imgs/DCAF_maxpower_exp.jpg" height="40%" width="40%"></p>
<p><span class="math inline">\(\lambda\)</span>
则是根据上面的二分搜索算法，利用采样一段时间的数据实时计算 <span
class="math inline">\(\lambda\)</span> 的最优值，算法中的容量 <span
class="math inline">\(C\)</span> 则是根据 QPS
做了兑换计算，如下是离线计算 <span
class="math inline">\(\lambda\)</span> 的过程</p>
<p><img src="https://wulc.me/imgs/DCAF_lambda_offline.jpg" height="50%" width="50%"></p>
<h4 id="实验设计">实验设计</h4>
<p>实验部分做了 2 个实验，离线和在线的</p>
<p>离线实验主要是做了流量回放，<span
class="math inline">\(\lambda\)</span> 还是按照上面的方法计算，算力
<span class="math inline">\(q_j\)</span> 表示请求的候选数量， <span
class="math inline">\(Q_{ij}\)</span> 表示算力 <span
class="math inline">\(q_j\)</span> 下候选里 top-k 个 ecpm 广告的和</p>
<blockquote>
<ul>
<li>Action <span class="math inline">\(j\)</span> controls the number of
advertisements that need to be evaluated by online CTR model in Ranking
stage.</li>
<li><span class="math inline">\(q_j\)</span> represents the
advertisement’s quota for requesting the online CTR model</li>
<li><span class="math inline">\(Q_{ij}\)</span> is the sum of top-k ad’s
eCPM for request <span class="math inline">\(i\)</span> conditioned on
action <span class="math inline">\(j\)</span> in Ranking stage which is
equivalent to online performance closely. And <span
class="math inline">\(Q_{ij}\)</span> is estimated in the
experiment.</li>
</ul>
</blockquote>
<p>离线实验结果如下，左纵轴的 ecpm
是实际的流量价值，右纵轴是实际消耗的算力，从结果可知，离线回放能做到算力下降同时流量价值上涨，且随着
<span class="math inline">\(\lambda\)</span> 值的增大，DCFA
总体消耗的算力和流量价值都是下降的，这个其实跟前面推导 <span
class="math inline">\(\lambda\)</span> 的过程是一致的，因为
<strong><span class="math inline">\(\lambda\)</span>
的物理含义就是增加候选数的边际收益的一个门槛</strong>，随着候选数增加，边际收益是递减的，而小于
<span class="math inline">\(\lambda\)</span>
时就是要截断的候选数，也就是 <span class="math inline">\(q_j\)</span>
具体的值</p>
<p><img src="https://wulc.me/imgs/DCAF_offline_exp.jpg" height="50%" width="50%"></p>
<p>虽然离线实验显示打平算力 ecpm+3.7%, 打平 ecpm
机器成本-49%，但毕竟是离线环境，比较稳定，选择的 action
也不会影响环境，所以如果开线上实验，效果一般会打个折扣，paper
里的在线实验也显示了这一点</p>
<p><img src="https://wulc.me/imgs/DCAF_online_exp.jpg" height="50%" width="50%"></p>
<h3 id="流量价值与算力建模">流量价值与算力建模</h3>
<p>DCAF 这篇 paper
着重讲了分配策略，但是对流量价值和算力的建模讲得比较少，只提到了 <span
class="math inline">\(Q_{ij}\)</span> 是通过一个简单的线性模型来预估，而
<span class="math inline">\(q_j\)</span>
则只是候选数，没有进行建模；但是这两个变量的建模对结果影响又是非常大的，尤其是
<span class="math inline">\(Q_{ij}\)</span></p>
<p>值得注意的一个点是，<strong>流量价值 <span
class="math inline">\(Q_{ij}\)</span> 和消耗算力 <span
class="math inline">\(q_j\)</span>
都跟候选数正相关</strong>，且候选越多，越能接近流量的最大价值（错误率可控前提下），同时消耗的算力也会越大</p>
<p>直接把候选数当做消耗的算力不是非常精确的做法，比如说所有候选都只需要抽一次特征，这个时间不会随着候选数增加而增加；而如果以候选数为横轴，算力为纵轴，大概率会画出一条
<span class="math inline">\(\log(ax)+b\)</span> 形式的曲线（<span
class="math inline">\(a\)</span> 和 <span
class="math inline">\(b\)</span>
是两个参数），即随着候选数增加，边际的算力成本是下降的，<span
class="math inline">\(Q_{ij}\)</span> 同理, 所以可以把 <span
class="math inline">\(Q_{ij}\)</span> 和 <span
class="math inline">\(q_j\)</span> 都写成 <span
class="math inline">\(f(候选数)\)</span> 的函数形式</p>
<p><img src="https://wulc.me/imgs/computational_resource.jpg" height="50%" width="50%"></p>
<p>美团在这篇文章中也描述了其对 DCAF 的一个改进，<a
href="https://tech.meituan.com/2021/06/17/waimai-ai-advertisement.html">美团外卖广告智能算力的探索与实践</a>，其中就包括了对这两部分的详细的建模，下面会大概讲一下美团的做法，并讨论一下其他可能的做法</p>
<h4 id="流量价值建模">流量价值建模</h4>
<p>如果直接建模 <span class="math inline">\(Q_{ij}\)</span>（比如说通过
multi-head 的方式，每个 head 代表一个 action），需要保证 <span
class="math inline">\(Q_{ij}\)</span> 随着 <span
class="math inline">\(j\)</span> 是单调递增的，可以通过在 loss 增加一项
regularization 项来尽量保证预估值是递增的，如在 loss 中增加一项 <span
class="math inline">\(ReLU(pred_{j}-pred_{j+1})\)</span>
来让预估值尽量保序，但这也不能完全保证预估是有序的</p>
<p>针对这个问题，上面的美团的文章的做法是<strong>预估整条流量的价值，然后通过每个广告的预估分来估算不同档位的价值</strong>（即下图的档位价值预估），这样理论上能够计算所有可能的
action，相比于 multi-head 的做法要更加灵活和轻量级</p>
<p><img src="https://wulc.me/imgs/DCFA_meituan_value.jpg" height="50%" width="50%"></p>
<p>而价值预估上，为了保证在线的效率，美团采用的是“离线预估，在线查询”的方法，即离线通过对特征分桶来划分流量，然后通过
xgb 预估每个桶里的流量价值并写入外部 kv；在线时通过实时查询 kv
和插值的方法来
serving，保证任何流量都有一个预估值，最后通过档位价值预估的方法来得到不同
<span class="math inline">\(j\)</span> 下的 <span
class="math inline">\(Q_{ij}\)</span></p>
<p>除了这个思路，前面提到了如果以候选数为横轴，算力为纵轴，大概率会画出一条
<span class="math inline">\(\log(ax)+b\)</span> 形式的曲线（<span
class="math inline">\(a\)</span> 和 <span
class="math inline">\(b\)</span>
是两个参数），我们可以基于这个先验来做更简单的推理和求解，比如说最简单就是基于后验数据直接拟合出
<span class="math inline">\(a\)</span> 和 <span
class="math inline">\(b\)</span>
这两个参数，但是需要考虑做在何种维度，比如说 user 维度、user ×
广告位维度等，核心问题是要考虑做在何种维度，如果维度太细数据过于系数，可能需要考虑做到更大的维度；同时也可以考虑贝叶斯这一类方法</p>
<h4 id="算力建模">算力建模</h4>
<p>美团的文章里算力的建模跟价值的建模很类似，都是离线预估、在线查询的</p>
<p>离线先做特征分桶，然后在桶里建模条数和算力的关系，每个桶的建模采用了分段线性拟合，与上面的价值建模不同的点在于，这里没有插值的过程（就是默认所有流量都能找到对饮的桶？）</p>
<p>而相比于 DCAF 原文采用条数来衡量算力，这里采用了 CPU
的耗时来衡量算力，总体方法如下</p>
<p><img src="https://wulc.me/imgs/DCAF_meituan_computation.jpg" height="50%" width="50%"></p>
<p>而另一种思路跟上面提到的利用 <span
class="math inline">\(\log(ax)+b\)</span>
形式作为先验比较相似，也是需要考虑在特定维度去拟合 a, b 这两个参数</p>
<h2 id="小结">小结</h2>
<p>本文主要从流量维度介绍了一些算力优化的手段，可以将其分为 drop、cache
和 dynamic 三类方法，如果我们把算力拆解为“QPS×平均请求消耗算力”，drop
相当于是有丢弃一些低质请求，cache
则是通过缓存降低平均请求消耗的算力，两个方法都比较直观</p>
<p>dynamic
也是在尝试在降低平均请求消耗的算力，或者更准确的说是重新分配算力，做到在打平业务效果减低机器资源，或者打平机器资源提升业务效果；DCAF
是这类方法的一个典型工作，DCAF
对问题的建模和求解比较值得学习，但是对流量价值和算力的建模讲得比较粗糙，美团技术团队的一篇文章对这部分做了较好的补充，本文也提出了建模这两个变量的一个思路；总体来说，这个方法在理论推导和业界落地上都证明了其有效性，值得学习。</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习在表情识别中的应用</title>
    <url>/2017/09/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%A1%A8%E6%83%85%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E6%8E%A2%E7%B4%A2/</url>
    <content><![CDATA[<p>本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为
<code>positive</code>、<code>negative</code>、<code>neutral</code>
三种，细分可以分为 <code>neutral</code>, <code>angry</code>,
<code>surprise</code>, <code>disgust</code>, <code>fear</code>,
<code>happy</code>, <code>sad</code>
7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类问题。</p>
<p>本文主要讲述如何将深度学习应用在表情识别中，以及在图像分类中深度学习一些常用方法，如采用预训练的模型进行特征的提取，用数据集对预训练的模型进行
Fine-tunning，而这实际上又牵涉到了迁移学习。</p>
<span id="more"></span>
<p>之所以采用深度学习的方法，是因为深度学习中的网络（尤其是CNN）对图像具有较好的提取特征的能力，从而避免了人工提取特征的繁琐，人脸的人工特征包括常用的
68 个 <a
href="http://www.learnopencv.com/facial-landmark-detection/">Facial
landmarks</a>
等其他的特征，而深度学习除了预测外，往往还扮演着特征工程的角色，从而省去了人工提取特征的步骤。下面首先讲述深度学习中常用的网络类型，然后讲述通过预训练的网络(经过ImageNet进行预训练)对图像提取特征，以及对预训练的网络采用自己的数据进行微调的
Fine-Tunning。</p>
<h2 id="数据集">数据集</h2>
<p>表情识别中常用的数据集有 <a
href="http://www.consortium.ri.cmu.edu/ckagree/">CK+</a>， <a
href="https://mmifacedb.eu/">MMI</a>， <a
href="http://www.kasrl.org/jaffe.html">JAFFE</a>， <a
href="http://www.emotionlab.se/resources/kdef">KDEF</a>等，这些数据有些是短视频，有些是图片序列（记录一个表情的若干张图片），有些则是单张表情图片。</p>
<p>在训练时，需要根据实际的应用场景以及采用的模型的输入格式将这些数据集处理成相关格式，这里不在详细说明。</p>
<h2 id="网络类型">网络类型</h2>
<p>假如采用深度学习中常用的网络层 cnn，rnn， fully-connect
等层组合成网络，那么具有非常多种的选择，这些网络的性能需要在实际任务中检验，而经过实践发现，某些网络结构往往在图像分类上具有较好的结果，如ImgeNet比赛中提出的一些列模型：AlexNet，GoogleNet（Inception),
VGG， ResNet 等。这些网络已经经过了 ImageNet
这个数据集的考验，因此在图像分类问题中也常被采用。</p>
<p>至于网络的结构，往往是先通过若干层 CNN
进行图像特征的提取，然后通过全连接层进行非线性分类，这时的全连接层就类似与MLP，只是还加入了
dropout 等机制防止过拟合等，最后一层有几个分类就连接几个神经元，并且通过
softmax 变换得到样本属于各个分类的概率分布。如下是 AlexNet
的网络结构图</p>
<h3 id="alexnet">AlexNet</h3>
<figure>
<img src="https://wulc.me/imgs/image_1bqkulor8935til84914bc3ar9.png"
alt="AlexNet" />
<figcaption aria-hidden="true">AlexNet</figcaption>
</figure>
<p>关于AlexNet 更详细的介绍可参考<a
href="http://wulc.me/2017/05/15/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">这篇文章</a>。</p>
<h3 id="inception">Inception</h3>
<p>而 Inception 是 Google 研发的一个深度神经网络，经历了四个版本
（也叫GoogLeNet），各个版本及其对应的论文如下，各个版本</p>
<p>[v1] Going Deeper with Convolutions, 6.67% test error,
http://arxiv.org/abs/1409.4842 [v2] Batch Normalization: Accelerating
Deep Network Training by Reducing Internal Covariate Shift, 4.8% test
error, http://arxiv.org/abs/1502.03167 [v3] Rethinking the Inception
Architecture for Computer Vision, 3.5% test error,
http://arxiv.org/abs/1512.00567 [v4] Inception-v4, Inception-ResNet and
the Impact of Residual Connections on Learning, 3.08% test error,
http://arxiv.org/abs/1602.07261</p>
<p>Inception 的结构与前面的 AlexNet 的大同小异，其核心是多了 Inception
模块，而 Inception 模块的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqkuvvjd5qp1383rtm1qnu1kic1g.png"
alt="Inception moule" />
<figcaption aria-hidden="true">Inception moule</figcaption>
</figure>
<p>Inception
模块使得网络的当前层可以通过多种方式从前一层网络提取特征，如上图通过了三种不同大小的卷积层以及一个池化层，然后将这些特征进行
concate 送到下一层。</p>
<p>如下是 Inception V3 的结构</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqkvqgl5rojlbnodhtsg89e37.png"
alt="Inception V3" />
<figcaption aria-hidden="true">Inception V3</figcaption>
</figure>
<h3 id="vgg">VGG</h3>
<p>VGG 并没有采用很新颖的结构，整个网络只是采用了 3X3 的卷积层以及 2X2
的池化层，但是层数比较深，就是这么一个靠两种简单网络层堆叠起来的网络，却在
ImageNet 比赛上取得了非常好的结果。VGG
主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能，越深的网络能够容纳更多数据的信息，对于更大的数据具有更好的效果，VGG整个网络的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqkvpc901ufv189f19r6h4q1h1p2q.png"
alt="VGG" />
<figcaption aria-hidden="true">VGG</figcaption>
</figure>
<h3 id="resnet">ResNet</h3>
<p>前面 VGG
提到了网络的深度（层数）起到了一个非常重要的作用，但是如果只是简单地将层堆叠在一起，增加网络的深度并不会起太大作用。这是由于梯度消失和爆炸（vanishing/exploding
gradient）问题，深层的网络很难训练。因为梯度反向传播到前一层，重复相乘可能使梯度无穷小。结果就是，随着网络的层数更深，其性能趋于饱和，甚至开始迅速下降。</p>
<p>而为了解决因深度增加而产生的性能下降问题， ResNet
引入一个“身份捷径连接”（identity shortcut
connection），直接跳过一层或多层，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1bql06cuj1ket1mhveme1l4fvsu3k.png"
alt="ResNet" />
<figcaption aria-hidden="true">ResNet</figcaption>
</figure>
<p><a
href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">提出
ReNet 的这篇论文</a>指出，假设目标映射为 <span
class="math inline">\(H(x)\)</span>，这个模块并不是让 stacked layers
去直接拟合这个目标映射，而是去拟合残差 <span class="math inline">\(F(x)
:= H(x)-x\)</span>，则拟合的 <span class="math inline">\(H(x)\)</span>
则变为了 <span class="math inline">\(F(x) + x\)</span>, 论文假设优化残差
<span class="math inline">\(F(x)\)</span> 比优化 H(x) 更容易。</p>
<p>上面这段话基本翻译自提出 ResNet
这篇论文，更直观的理解就是每一层不仅仅只是能从前一层获取信息了，而是还可以从更前面的几层获取，而
ResNet 最开始的只是建单地将更前面几层的 x 直接加到当前层的输出，也就是
<span class="math inline">\(F(x) + x\)</span>， 而 ResNet
的若干变体则对这部分直接传递的 <span class="math inline">\(x\)</span>
进行了处理，如通过卷积层等操作，但是其核心思想还是跨层连接从而获得更多的信息。</p>
<p>最开始提出的 ResNet 的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqmnubbv1pvf68s1cemeqa1plo41.png"
alt="ResNet" />
<figcaption aria-hidden="true">ResNet</figcaption>
</figure>
<h3 id="cnn-lstm">CNN-LSTM</h3>
<p>上面的模型均是对单张图像进行处理，但是还有一种模型是对连续图片
sequence 进行处理的，由于连续图片 sequence 包含了时序信息，因此通过将
CNN 与 RNN 进行结合对时序图片列进行预测。在表情识别中</p>
<p>CNN-LSTM 是将 CNN 与 LSTM
结合起来的一种模型，其基本结构如下，图片出自<a
href="https://arxiv.org/pdf/1411.4389v4.pdf">该论文</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1bqmosh7oqcsbfa1ksp56de2d4e.png"
alt="cnn-lstm" />
<figcaption aria-hidden="true">cnn-lstm</figcaption>
</figure>
<p>其思想就是首先通过 cnn 提取每张图片的特征，然后将这些带时序的特征传入
LSTM 中，可以取每一个 LSTM 的输出进行平均后连接 softmax
进行输出，也可以直接取最后一个 LSTM 的输出连接 softmax 作为输出。</p>
<p>上面这些网络训练的时候均是通过 SGD 进行反向传播，某些会加入 momentum
等其他改进。</p>
<p>这些网络理解起来可能问题不大，但是如果要代码实现起来的话工作量并不小，好在已经有了若干框架实现了这些模型，在使用时直接调用即可，这里以最简单的框架
<a href="https://github.com/fchollet/keras">Keras</a> 为例说明，Kreas
已经在<a
href="https://github.com/fchollet/deep-learning-models">这里</a>列出了一些实现的网络，可以参考其文档直接进行调用。</p>
<h2 id="预训练模型提取特征">预训练模型提取特征</h2>
<p>上面提到的这些模型少则十几层，多则上百层，其参数数目也达到了百万级别，要训练这么庞大的一个网络，如果数据量不足，很容易会会导致整个网络过拟合（当然，如果训练epoch次数少，也会直接导致欠拟合）。</p>
<p>而在实际中，像 ImageNet
这种庞大的数据集很少，而且某些只是归少数大公司所有，假如个人或缺乏数据的小公司需要用到上面提到的网络时，那就是无米之炊了，因此在实际中使用时，往往不是从头开始训练一个很大的模型，而是采用下面提到的通过模型提取特征以及对模型进行
Fine-Tunning 的方法。</p>
<p>深度学习中的网络的一个好处就是，经过大规模数据集训练过后的，网络具有了抽取图像特征的特性，而抽取出来的图像的特征，跟实际要处理任务没有关系，也就是说经过
ImageNet
训练过后的网络，也可以用于表情识别中抽取人脸的特征，然后用这些特征再训练一个小一点的模型，如
Logistics Regression，
SVM等，这时候的网络完全就是在扮演着一个自动特征工程的角色。</p>
<p>这里“通过网络提取的特征”往往指的是网络最后的某个全连接层的输出值，具体采用哪一层取决于后续处理所需的特征维数。</p>
<p>Keras 也提供了经过 ImageNet
预训练的一些模型，通过这些模型抽取图像特征的样例代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">base_model = VGG19(weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">model = Model(<span class="built_in">input</span>=base_model.<span class="built_in">input</span>, output=base_model.get_layer(<span class="string">&#x27;block4_pool&#x27;</span>).output)</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&#x27;elephant.jpg&#x27;</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">block4_pool_features = model.predict(x)</span><br></pre></td></tr></table></figure>
<p>在实际测试时，用 VGG16 抽取图像的特征后再经过带 L1 正则化的Logistics
Regression，再CK+上进行10-fold cross validation， 得到的准确率约为85%,
也说明了这种方法的有效性。</p>
<h2
id="对预训练模型进行微调fine-tunning">对预训练模型进行微调(Fine-Tunning)</h2>
<p>上面通过预训练的网络提取特征的确有效果，但是这些经过预训练的网络基本都是在
ImageNet 数据集上进行训练的，而实际中的各种任务是千差万别的，光凭
ImageNet 是难以涵盖各个领域的需求的。</p>
<p>因此很自然会想到在预训练的网络基础上，用涉及到的具体任务中的数据集再次训练这个网络，从而让这个网络能够学习到这个数据集内的信息，这种方法也称为
Fine-Tunning。</p>
<p>Keras 的官方blog也写了一篇文章专门阐述这种方法，文章链接为
https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</p>
<p>在这篇文章中，并没有调整整个网络的参数，而是只调整了最后的几层卷积层和全连接层，文章称原因是越底层的卷积层所提取到的图像的特性越是有共性的特征，而越上层的卷积层提取的特征则越是跟具体的领域相关的，当然，到底要调整多少层，还取决于所拥有的数据量，另外，往往还会去掉网络最后的若干层，并根据实际的图像分类数目构建最后一层大小。</p>
<p>通过 Keras 进行 Fine-Tunning 的样例代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br><span class="line"></span><br><span class="line">height, width, categoriees = <span class="number">128</span>, <span class="number">128</span>, <span class="number">7</span></span><br><span class="line"></span><br><span class="line">model_vgg19_conv = VGG19(weights = <span class="string">&#x27;imagenet&#x27;</span>, include_top = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># just fine-tune the top five convulutional layers</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model_vgg19_conv.layers[:-<span class="number">5</span>]: </span><br><span class="line">    layer.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create your own input format (here 128x128X3)</span></span><br><span class="line"><span class="built_in">input</span> = Input(shape=(height, width, <span class="number">3</span>),name = <span class="string">&#x27;image_input&#x27;</span>)</span><br><span class="line"><span class="comment">#Use the generated model </span></span><br><span class="line">output_vgg19_conv = model_vgg19_conv(<span class="built_in">input</span>)</span><br><span class="line"><span class="comment">#Add the fully-connected layers </span></span><br><span class="line">x = Flatten(name=<span class="string">&#x27;flatten&#x27;</span>)(output_vgg19_conv)</span><br><span class="line">x = Dense(feature_dim, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;fc1&#x27;</span>)(x)</span><br><span class="line"><span class="comment"># x = Dense(feature_dim, activation=&#x27;relu&#x27;, name=&#x27;fc2&#x27;)(x)</span></span><br><span class="line">x = Dense(categories, activation=<span class="string">&#x27;softmax&#x27;</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line"><span class="comment">#Create your own model </span></span><br><span class="line">model = Model(inputs = <span class="built_in">input</span>, outputs = x)</span><br></pre></td></tr></table></figure>
<p>最后讲的利用了预训练模型的两部分实际上可以归入到迁移学习的范畴了，原因是我们利用了模型在
ImageNet
上学到的知识，迁移到了一个新的领域(表情识别），同理，也可以将其推广至医学影像等领域，当然，迁移学习远不止这点内容，有兴趣的可以去查找相关资料，这里不在论述。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>混排的那些事儿</title>
    <url>/2023/02/26/%E6%B7%B7%E6%8E%92%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
    <content><![CDATA[<p>混排，往往是的推荐系统的最后一个环节，在这个阶段，自然内容（后面简称item）需要与营销内容（后面简称
ad）进行混合，生成最终推送给用户的 list</p>
<p>如果以 Long Term Value(LTV)的视角来看,这是个在 LT 和 V 之间做
trade-off 的过程，ad 如果出得过多，必然会挤压 item
的数量和位置，进而影响用户体验和留存即 LT，但相应的广告收入，或者说
Average revenue per user(<a
href="https://www.investopedia.com/terms/a/arpu.asp">ARPU</a>)
会提升，反之亦然</p>
<p>所以业界往往的做法是定一个用户体验的约束，在这个约束下尽可能优化 ad
的效率，即达到收入最大化，因此很自然可以把这个建模成一个最优化问题，LinkedIn
在 2020 年的这篇 paper就是这么做的，<a
href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403391">Ads Allocation
in Feed via Constrained Optimization</a></p>
<p>直观地看混排这个问题，有 2 个子问题需要解决 （1）怎么计算每个 item 或
ad 在每个位置上的价值：因为 item 和 ad
是各自排序的，目标不同，最终的值的量纲也不同，这么把两者的 scale
拉到可比范围是一个需要讨论的问题 （2）怎么分配能让最终 list
价值最大化：在 item 和 ad 的价值确认后，怎么插入 item 和 ad
的位置，从而达到整个 list 的最大化</p>
<p>上面提到的 LinkedIn 的 paper
重点是在解决第二个问题，部分内容也涉及到第一个问题 ；本文会先讲一下这篇
paper 的建模方法，然后讨论下计算 item 和 ad
价值的一些思路，混排中一些其他需要注意的事项</p>
<span id="more"></span>
<h2 id="建模方案">建模方案</h2>
<p>paper
把问题建模成如下图最优化问题（单次请求的最优，目前不考虑请求间的优化）</p>
<p><img src="https://wulc.me/imgs/Rerank_optimize.png" height="30%" width="30%"></p>
<p>各符号含义如下</p>
<ul>
<li><span class="math inline">\(i\)</span>: 一次请求中位置的 index</li>
<li><span class="math inline">\(x_i\)</span>: 是否在第 i 个位置插入
ad</li>
<li><span class="math inline">\(j\)</span>: 请求的 index</li>
<li><span class="math inline">\(u_{i}^{o}\)</span>: item 在第 i 个位置的
engagement utility（可理解为内容本身的价值，item和ad都有）</li>
<li><span class="math inline">\(u_{i}^{a}\)</span>: ad 在第 i 个位置的
engagement utility</li>
<li><span class="math inline">\(r_{i}\)</span>: ad 在第 i 个位置的
revenue utility（可理解为商业价值，item没有这个价值）</li>
<li><span class="math inline">\(C\)</span>: 全局 engagement utility
的一个门槛, 一种可能的方式是设置成可能最大的 engagement
utility（没有广告） 的一个百分比</li>
</ul>
<p>通过对偶拉格朗日可以求解出如下的解，式子中的 <span
class="math inline">\(\alpha\)</span>
是上面第一个约束的拉格朗日乘数；这个变量的物理含义是一个 bid，paper
称其为 “shadow bid”，作用是把 engagement utility 的 scale 变换至 revenue
utility 的 scale；则最终在位置 i 插入 ad 或 item 的价值如下图表 1
所示</p>
<p><img src="https://wulc.me/imgs/Rerank_solution.png" height="40%" width="40%"></p>
<p>上面的最优化问题的约束只是总体 list 的 engagement utility
要大于特定预制，但混排往往还有一些硬约束，在paper中提到的是：top slot 和
min gap
，分别表示第一个广告的位置约束，两个广告最小间隔的约束；除了这两个约束，一些常见的约束还有
showtime gap 约束（出现广告的评率）、adload
约束等(广告出现比例的约束)</p>
<p><img src="https://wulc.me/imgs/Rerank_constraint.png" height="30%" width="30%"></p>
<p>这两个约束并没有直接体现在最优化的建模里，而是体现在最后的混排算法里，整个算法流程如下</p>
<p><img src="https://wulc.me/imgs/Rerank_algorithm.png" height="40%" width="40%"></p>
<h2 id="建模关键问题讨论">建模关键问题讨论</h2>
<p>上面的建模虽然比较直观，但涉及到的一些需要解决的关键问题，</p>
<h3 id="shadow-bid-alpha-的计算">shadow bid <span
class="math inline">\(\alpha\)</span> 的计算</h3>
<p>paper 提到的 shadow bid，在经济学上称为<a
href="https://zh.wikipedia.org/wiki/%E5%BD%B1%E5%AD%90%E4%BB%B7%E6%A0%BC">影子价格</a>，物理含义是表示的是增加一个单位的资源所带来的边际收益，关于影子价格更多讨论可参考
<a
href="https://www.zhihu.com/question/23510001">线性规划中的影子价格怎么理解？</a></p>
<p>这里的影子价格 <span class="math inline">\(\alpha\)</span> 是一个关于
<span class="math inline">\(C\)</span> 的函数，paper
提到获取这个值的三种方法，</p>
<p><img src="https://wulc.me/imgs/Rerank_shadowbid.png" height="40%" width="40%"></p>
<p>从上图可知，基本思路是 （1）确定 <span
class="math inline">\(C\)</span> 的值之后求解原问题，得到 <span
class="math inline">\(\alpha\)</span> （2）通过在线 ab
实验来确定这个参数
（3）离线回放（感觉这里跟第一个是重合的，因为求解原问题也是需要回放历史数据，只是用多长的历史数据，以及更新频率有多大）</p>
<h3 id="u_iou_ia-和-r_i的计算"><span
class="math inline">\(u_{i}^{o}\)</span>、<span
class="math inline">\(u_{i}^{a}\)</span> 和 <span
class="math inline">\(r_{i}\)</span>的计算</h3>
<p>关于这几个值的获取，paper 并没有提供明确的方法，只是提到了
<strong><span class="math inline">\(u_{i}^{a}\)</span>、 <span
class="math inline">\(u_{i}^{o}\)</span> and <span
class="math inline">\(r_{i}\)</span> are drawn from the same
distribution as was the historical data</strong></p>
<p>但如果真的这么做，存在的问题必然是历史数据会很稀疏，容易出现新的 item
或 ad
没有数据，或者把统计历史数据的维度拉得更大，这样容易导致效果变差，数据没区分性；因此，最终还是需要往预估方向去做</p>
<p>如果考虑实际的业务，<span class="math inline">\(u_{i}^{o}\)</span> 和
<span class="math inline">\(r_{i}\)</span> 的值比较好获取，直接取原本
item 排序和 ad 排序中各自的分数即可，但 <span
class="math inline">\(u_{i}^{a}\)</span> 的值应该如何获取？（其实这里的
<span class="math inline">\(u_{i}^{o}\)</span> 和 <span
class="math inline">\(r_{i}\)</span>
的值的获取还有个问题，就是怎么获取一个 item 或 ad 在所有位置的 <span
class="math inline">\(u\)</span> 或 <span
class="math inline">\(r\)</span>，这部分在下面的 position bias
会讨论）</p>
<p>如果让 ad 直接走推荐侧的模型，在物理意义上是 make sense
的，但可能会存在 2 个问题（1）ad 的特征未必能跟 item
的完全对齐（2）需要保证 <span class="math inline">\(u_{i}^{a} \lt
u_{i}^{o}\)</span></p>
<p>这里第二个问题尤为重要，因为如果这个不成立，上面的最优化问题最终的解会是全出
ad，这显然是不合理的，那如何做这一点的保证，笔者现在也没想到很好的方法；比如说在推荐模型做
multi-head，一个 head 预估 item，一个 head 预估 ad，通过 regularization
尽量保证 item head 要大于 ad head，但也没法做严格的保证</p>
<h3 id="position-bias">position bias</h3>
<p>这个问题在上面的 <span
class="math inline">\(u_{i}^{o}\)</span>、<span
class="math inline">\(u_{i}^{a}\)</span> 和 <span
class="math inline">\(r_{i}\)</span> 的获取讨论中提到了</p>
<p>如果在计算 <span class="math inline">\(u_{i}^{o}\)</span>、<span
class="math inline">\(u_{i}^{a}\)</span> 和 <span
class="math inline">\(r_{i}\)</span>
不考虑位置信息，那必然是有偏的，因为不同位置的 ctr、cvr 等天然不一致</p>
<p>paper 里提到了一种方法，也是实际比较常用的：<strong>training
阶段使用实际的 position，serving 阶段使用统一的
position，同时保留一张映射表，映射不同位置跟 serving 时使用的统一位置的
discount，映射表可通过后验数据统计获取得到，最终预估值乘上这个 discount
就能等到不同位置的预估值</strong></p>
<p>这种做法的缺点是这张映射表需要经常更新，所以更好的做法是把这张表做到模型里，让模型训练过程中就能学到这个变化，预估阶段同时预估所有的位置的
score</p>
<h3 id="gap-effect">gap effect</h3>
<p>对于推荐而言，往往序准确就可以了，但 a<strong>d
因为涉及到实际扣费，会要求 ctr，cvr
预估足够准确</strong>，才能避免扣费不准确，引起广告主的客诉等问题</p>
<p>除了上面的 position bias 会影响 ctr 准确性，两个 ad 之间的 gap
大小也会影响 ad 的 ctr 等，如下图所示，ad 的 gap 之间如果过小，ad
的点击率会过低，但 item 不会出现这种情况，本质上还是因为 ad
的密集度过高，即使前面提到了有min-gap 这一类硬规则</p>
<p><img src="https://wulc.me/imgs/Rerank_gap_effect.jpg" height="40%" width="40%"></p>
<p>paper 提出的做法是给增加一个 gap 特征来捕捉这个信息，paper
做了如下推导，最终生效的形式跟 position_discount 有点像，等价于在原来的
ctr 基础上乘上一个 gap_discount, 下图中的 <span
class="math inline">\(g\)</span> 是 <a
href="https://en.wikipedia.org/wiki/Logit">Logit function</a>, <span
class="math inline">\(y_{ij}\)</span> 表示是否发生点击（还可进一步把
<span class="math inline">\(\beta\)</span>
参数化，做成个性化的参数）</p>
<p><img src="https://wulc.me/imgs/Rerank_gap_effect_logit.jpg" height="40%" width="40%"></p>
<p>而如果在上面的混排算法上加上 gap effect 的影响，会有如下的流程</p>
<p><img src="https://wulc.me/imgs/Rerank_gap_effect_algo.jpg" height="40%" width="40%"></p>
<h2 id="item-与-ad-价值度量的另一种思路">item 与 ad
价值度量的另一种思路</h2>
<p>paper 认为 item 价值是 engagement utility，ad 的价值是 engagement
utility + revenue utility</p>
<p>而上面也提到了获取 ad 的 engagement utility
会比较难，因此可以也可以考虑使用另一种思路来度量 item 和 ad 的价值</p>
<p>因为涉及到扣费，ad 的价值是比较好衡量的，一般采用的是 ecpm = bid ×
ctr ×
cvr（为了讨论方便，此处省略hidden_cost），因此很自然的一个想法是，<strong>能否为每个
item 也赋予一个 bid，这样也能在 item 侧算出一个类似 ecpm 的指标，与 ad
侧能进行比较</strong></p>
<p>紧接着的问题是，item 侧的 bid 的含义是什么？ad 侧的 bid
是有明确的物理含义的：广告主愿意为一个转化付的钱（还会叠加调价策略修改原始的广告主出价），但在
item 侧并没有广告主这一角色，由谁来出这个 bid 呢？</p>
<p>最直观的方法就是基于 ad 和 item 各自预估值的量级的差异，拍一个 item
侧的全局固定的 bid，但这样显然不是最优的，而且这个 bid
的量级也需要及时监控和更新，因为随着迭代，两边的预估值的 sacle
会发生变化</p>
<p>而如果从另一个角度来看，ad
更多是表达广告主的诉求，目标就是要更多的用户转化；item
更多是平台的诉求，
目标是要为平台带来更多的用户和留存时间；留存时间越长，也意味着可供平台变现的流量会更多，或者说<strong>用户指标其实也是跟平台长期收入挂钩的</strong>；因此可以基于大盘来测算用户指标与平台收入的关系，以
stay_duration 为例，可以对 stay_duration 分桶，测算 stay_duration
与平台长期收入指标的相关关系，建立一个函数 <span
class="math inline">\(f\)</span> 使得 <span class="math inline">\(bid =
f(stay\_duration)\)</span>, 当然这里的变量也不一定是
stay_duration，也可以是考虑 dislike、active
等各种信号，关键是要<strong>把用户在平台的留存、活跃等信息，与平台长期收入量化挂钩，然后基于这个收入倒推出一个
item 侧的 bid</strong></p>
<p>对于 ad 而言，如果与 item 混排时，把 ad 插在 items 的第 <span
class="math inline">\(k\)</span> 位带来的收益, 不仅仅是广告本身的
ecpm，还可进一步考虑由于广告插入给总体 items 带来的损失（VCG
计费的思想），即<strong>混排时 ad 的价值也可以考虑成“ad 带来收益 - item
后移的损失”</strong>；这样的话如果插入的位置导致 item
后移的损失较大，则总体的 ad 价值会下降，避免对 item 的挤压</p>
<h2 id="硬规则是否最优">硬规则是否最优</h2>
<p>上面提到了混排中存在着各种硬规则，比如说广告出现的首位，广告之间的min_gap，show_time
gap等，从技术角度来说，这样的离散的硬规则显然不是最优的，会极大限制算法的搜索空间；而从业务的角度，这种硬规则往往是业务发展初期拍定的，随着业务发展，对当前业务是否合理也是需要重新评估的</p>
<p>举个例子，一个对 ad 敏感和一个对 ad
不敏感的用户，使用同一套硬规则并不是最优的，因为同样的广告频率，在敏感用户那转化率会比较低，同时对用户的留存影响也会比较大（相对于不敏感的用户）；而如果给对
ad 不敏感的用户出更多的 ad，同时减少敏感用户的ad，打平总体的 ad
数，最终总体的 engagement utility 和 revenue utility
理论上也是更优的</p>
<p>具体的实现上，一般需要设置一套规则和计算方法，能够计算出硬规则中的所有可能情况下的
utility，然后加入到 list 的总体价值中</p>
<p>而这其实也涉及到推荐或广告系统里的优化的一个方向，就是个性化，一般大盘策略上对所有用户都相同的超参或策略，都会有个性化的空间</p>
<p>当然在这个过程也要注意个性化往往也会有个限制，以混排为例，需要对不敏感的用户有体验保护，不能逮住这部分用户一个劲地薅</p>
<h2 id="小结">小结</h2>
<p>本文从 LinkedIn 的一篇 paper
展开，介绍了混排需要解决的问题以及一种建模方法，paper
的建模不复杂，关键是建模中使用的各个 utility 的获取，paper
在这部分并没有说得比较详细，可能也是因为这部分跟实际业务耦合比较紧密；因此，本文后面也讨论了一种
item 和 ad 价值可能的计算方式：为 item 计算一个 bid， 同时考虑 ad 插入对
item 的影响</p>
<p>另外，paper 也提到了 position bias 、gap effect
等在混排中常见的问题，本文针对 paper
提出的方法和业界的一些做法做了讨论</p>
<p>最后，也探讨了一个比较比较开放的问题，就是混排中涉及到的 hard
rule，hard rule 一般是红线，但从技术视角来看肯定不是最优的，同时 hard
rule 是否合理，以及如何从业务角度和技术角度来 soften the hard rule，拿到
engagement utility 和 revenue utility
两部分的收益，也许是个值得讨论的问题</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>炒股损失的不仅是钱,年轻人请远离股市</title>
    <url>/2016/01/17/%E7%82%92%E8%82%A1%E6%8D%9F%E5%A4%B1%E7%9A%84%E4%B8%8D%E4%BB%85%E6%98%AF%E9%92%B1-%E5%B9%B4%E8%BD%BB%E4%BA%BA%E8%AF%B7%E8%BF%9C%E7%A6%BB%E8%82%A1%E5%B8%82/</url>
    <content><![CDATA[<p>转载，作者：李晓鹏，侵删</p>
<p>这篇文章本来是该几年前写的，奉劝大家不要去玩股票。因为那个时候我的《中国崛起的经济学分析》这本书刚刚出版，里面用“破坏性要素参与分配”的理论来分析了中国经济。在写作过程中我发现这个理论也可以顺便用来解释股票市场，让大家看清楚股票市场的本质。但当时的大盘指数才1980点，我怕写出来很多人会被我“忽悠”，把手里的股票“割肉”卖掉，回头会恨死我。所以就忍了。
<span id="more"></span></p>
<p>我的观点很简单：股票市场不是年轻人应该去的地方。对年轻人来说，玩股票就跟爱上赌博一样，是在浪费生命。年轻人最大的资本是自己，一旦把自己有限的积蓄投入到股市中去，就会被行情的波动死死的抓住，然后在里面虚度光阴：原本应该学英语的时间，却拿来研究波浪理论；原本计划去听一场学术讲座的，却跑到证券公司去被各种股票大师洗脑；原本可以把本职工作做得更好一些，却敷衍了事然后偷偷打开行情软件看股票；原本可以在自己喜欢并擅长的领域取得成就的，却跟成千上万的“股民”一样天天守在电脑前面想着一夜暴富，沦为庸碌之辈。</p>
<p>总之，炒股，你损失的不仅是钱，最重要的是会耽误你自己最宝贵的财富——个人才干的价值提升。而后者才是你可靠而长远的财富来源。</p>
<p>我进入股市的时间是2006年7月，也就是我研究生毕业的时候。因为几个月前中国股市跌破了1000点，许小年吴敬琏等人炮轰中国股市还不如赌场，应该推倒重来。我却觉得被他们轰到1000点的中国股市的价值被严重低估，到处找人推销我的观点，但是没有人相信，所以就自己找人借了10万块钱去炒股。本来打算早点进去的，但是因为硕士论文的事情折腾了好久，答辩通过的第二天我就去银行开户了，这时大盘已经涨到了1500点了。</p>
<p>总之，就是这么误打误撞，不经意间，竟然闯进了中国股市历史上最大的一轮牛市之中。那个时候挣钱真好挣啊，不管买什么股票都在涨。每隔几天就能撞见一次涨停。但是我并不满足于跟着大盘涨，还想赚的更多。就开始买书来看，把什么《股票作手回忆录》《波浪理论》《巴菲特致股东的信》……等等有关股票投资的“名著”都翻出来看了一遍。</p>
<p>那个时候就有了一种幻想，觉得股票赚钱很容易，以后就可以靠这个吃饭了。也就懒得去找工作，此前还打算自己跟几个朋友一起创业的，那10万块钱既然被我用来炒股了，创业的事情也就不了了之。</p>
<p>2007年股市到6000点的时候，我大概赚了有20万。上证指数涨了300%，我挣了200%，没有跑过大盘，但是也很令人满意了。毕竟那是借来的10万块钱啊。我大概在4000点的时候，就已经把钱还给别人了，所以剩下的钱就都是纯利润。而且这一年的吃喝也都是从股市里出的。如果从这个时间点来看，我一年零三个月挣了20多万，对一个硕士毕业第一年的人来说是很不错了。</p>
<p>但是当大盘指数从6000点开始下跌的时候，我这过去一年多挣的钱就开始一点一点往回吐了。这时候我发现，自己曾经非常得意的那种“炒股技术”，没有一个是真正有用的，买什么股票都在跌。吐啊吐，吐啊吐，一直回吐到3600点，亏得还剩不到十万块钱了，终于受不了，斩仓出局，把剩下的钱全部转回到了银行卡上。退出股市。这个时候算下来，我接近两年的时间，实际上只挣了大约10万块钱。即使纯粹算一个收入帐，也变得非常不划算了。</p>
<p>更要命的是，这个时候我再去找工作，就变得非常困难。因为同年毕业的同学们，都已经工作了一年多快两年了。<strong>一般很好的大公司大企业会给应届毕业生提供一些很好的岗位，一旦不是应届生，就会对工作经验有要求。</strong>我既不是应届毕业生，又没有足够的工作经验。连续给一些大企业投了一轮简历，没有收到一个回复。那个时候真的好惨啊，别说面试什么的了，连面试通知都没有一个。只有一些莫名其妙的小公司给了我面试机会，我跑过去一看，好多都是骗子公司，有做传销的，还有忽悠人炒外汇的……当时觉得自己前途一片渺茫，本来是重点大学的本科、硕士毕业，混了两年变成这个鸟样，哎，有何面目再见人呢？</p>
<p>这个时候没有办法，才想起来重新回学校去读书。还好我考试的功力还是在的，经过几个月的准备，终于考上了博士。后来突然就一帆风顺起来了，去了剑桥、去了哈佛、去麦肯锡、出版《中国崛起的经济学分析》……瞬间整个人都变了，从一个到传销公司找工作的无业游民，变成了一个集各种高大上于一身的学者。</p>
<p>这一段经历，让我刻骨铭心。我知道了什么叫做“珍惜生命，远离股市”。</p>
<p><strong>人的一生，从20岁到30岁之间这一段时光——如果你不是富二代或者官二代的话，是比较难熬的。</strong>包括像任正非、柳传志、马云、刘强东这些白手起家的大牛人，他们在这个年龄也是生活比较黯淡的。<strong>因为这一段时间，从学校这个与世无争的世外桃源走进社会了，要自食其力了，但是资历、经验、关系网络什么的都不够，付出和收获很不成比例。不管是创业还是工作，其实都很难。你的个人期许和社会对你的承认程度，往往有很大的差距。</strong></p>
<p><strong>这段时期其实不是一个学习了很多年以后，开始收获的时期。应该是一个一半工作、一半学习的时期</strong>。就是说你即使去机关企业工作，你这种工作也带有学习的性质。所以机关企业并不会按照你的付出程度支付“足够”的报酬，因为你的工作能力各方面还很不成熟，他们同时也在为你提供一个学习进步的环境。严格来说只能叫做“半工半读”。<strong>通过一段很长时期的“半工半读”之后，等你对于本职工作十分擅长了，人际管理的资源网络也比较健全了，才能度过这一段考验期，进入一个比较好的发展时期。</strong></p>
<p>如果不考虑家庭因素，同龄人之间在20岁到30岁这段时间并不会拉开很大的差距，都差不多，工资高点低点也就是那么一点，农民工和硕士毕业的收入差距不是很大。没有飞来横财的话，大家都过着一样平凡的日子，默默的为自己的理想奋斗着、努力着。<strong>但是过了30岁以后，差距就会拉大了，成功的人可能非常成功，变身土豪名流，而没有进步的人可能会原地踏步，还是原来那样的地位或收入。这种差距可以是天上地下的区别。</strong></p>
<p>正因为如此，年轻人如果把时间放到炒股票上去，每天被行情的波动折腾得对本职工作心不在焉，最大的损失不是钱，而是耽误自己能力素质的积累。对于那些一无所有的年轻人来说，他们最值钱的东西是自己的学识和才干。</p>
<p><strong>股票上挣的钱能够立竿见影的看到：行情最火爆的时候，一两个月就能翻一倍，刺激的很。但是时间长了你会发现，这个东西根本不挣钱、挣到的还会赔回去，得不偿失。</strong></p>
<p><strong>在工作学习上所花的时间，短期内很难挣到什么钱，你做工作努力一点、还是敷衍一点，上班时间是在有空就看看本职工作相关的书籍，还是偷偷摸摸的打开电脑看股票，每个月都是那么一点工资收入，并不会增加。但是，长远来看，平时的一点一点的积累，最终会在关键时刻让你脱颖而出，并因此而受益终身。这种回报，比股票市场上能够挣到的钱，不知道要多出多少倍，不知道要可靠多少倍。</strong></p>
<p>这里边的利害计算，我们一定要想清楚。更何况，我们的理想，难道是一个每天坐在电脑前面看股票行情的人吗？</p>
<p>我觉得，这不仅是20-30岁这个年龄段的年轻人的事情。任何年龄段的人，只要他还没有对自己的事业失去信心，还想着取得比现在更大的进步，那么就不应该去玩什么股票。<strong>股票，要么是专业人士玩，要么是退休了没事干的老爷爷老奶奶去玩，除此以外的其他人都不应该去玩。</strong></p>
<p>股票市场这种制度的设计，本来就不是给普通人赚钱的。我在《中国崛起的经济学分析》里面提出一个理论，就是：<strong>一个人，要想稳定的获得任何形式的收入，都要对应一种这个人所能掌握的资源。</strong>他要么掌握<strong>生产性要素</strong>进行创造获利，要么掌握<strong>破坏性要素</strong>进行破坏获利。</p>
<p>比如，你精通计算机软件，那么就可以从编程中赚到工资；如果你精通企业管理和市场营销，你就可以成为一个成功的企业家，这些都是你<strong>利用自己的能力——也就是你能掌握的生产性要素参与社会分工，获得的合理的报酬。</strong></p>
<p>还有一种相反的，就是你身强力壮，可以晚上找个偏僻的地方拦路抢劫，或者精通攀沿技术，晚上可以入室盗窃把别人的钱变成自己的……这些就是你个人掌握的<strong>破坏性资源，从别人手里掠夺财富来获得收入</strong>，这叫“破坏性要素参与分配”。</p>
<p>不管是生产性还是破坏性要素，你总得占有一样。如果你一样都不占有，纯粹就是去赌钱玩，那么最后一定是得到一个平局：一会儿输钱，一会儿赢钱，最后不输不赢。</p>
<p><strong>但是在真正的赌场里边，输钱的总是赌徒，赚钱的总是庄家。这是因为庄家掌握了“破坏性要素”，就是可以通过操纵规则和作弊来掠夺赌徒的钱。</strong></p>
<p>那么到了股市里，这个不停波动的市场里面，<strong>我们可以问问自己，我们掌握了什么资源可以参与股票市场的财富分配呢？有生产性要素吗？没有。那些能够经营企业上市的企业家才有。有破坏性要素吗？还是没有，那些操作股市的庄家才有。那这些我们普通的年轻人，凭什么能赚到比把钱存在银行吃利息更多的钱呢？相信什么波浪理论、什么趋势线，你能玩的过那些金融、数学专业毕业的研究团队吗？</strong></p>
<p>把这个道理想清楚，我们就不难发现，我们去股市赚钱，最好的结果，就是不亏本，能够不被别人掠夺，挣点跟银行利息加社会最低工资标准差不多的收入就到头了，有时候看起来一夜暴富，其实很快又会吐回去去；但<strong>大部分结果是，被那些掌握了“破坏性要素”的人掠夺，浪费了时间还亏了本</strong>。</p>
<p>不管是哪一种结果，我们的时间都耽误不起。有人会听信关于“价值投资”的谎言，说我就长期投资，学习巴菲特，放在那里不动，又能挣钱又不耽误本职工作。这种想法是同样行不通的：<strong>如果你只用很少的一点钱去炒股，比如收入的10%，这点长期“价值投资”的收益其实对你没有影响，那么为什么要花那个时间呢？如果你投入大钱去炒股，股票的波动会影响你的生活，那么你虽然心里想着价值投资，但还是会变成一个赌博一样，每天除了关注股市行情以外什么事情也做不好。</strong>而这就会毁掉你的生活。不管是那一种，你都应该远离股市。所以，与其“价值投资”，还不如把钱存银行，旱涝保收。</p>
<p>总之，最好的选择，就是把我们的钱安安稳稳的放在那里，别去想什么理财之类的事情。在我们年轻的时候，能够掌握的那一点点资金，根本不值得浪费时间去“理财”。<strong>最需要“理”的“财”，是自己的知识和能力。</strong></p>
<p><strong>如果我们真的要玩股票，学习巴菲特、索罗斯，那应该做的不是拿着自己的钱去玩，而是像他们一样，学一个金融或者数学的学位，然后进入金融行业工作，争取成为基金经理，然后拿着别人的钱去玩，赚了提成，亏了不管。这样，你就可以掌握“生产性要素”——也就是运用各种专业知识和组织专业研究队伍来进行价值判断，真的为企业发展融资，促进企业成长；或者掌握“破坏性要素”，就是具备影响股票走势的能力，玩死那些小散户。</strong></p>
<p>如果你不打算这么干，那么，请远离股市，最好是碰都不要去碰一下；如果你已经进入了股市，最好是马上清仓，把所有的钱转回到银行卡里面。然后专注于自己的梦想，把它一点一点变成现实。</p>
<p>如果你还是对股市恋恋不舍，还做着一夜暴富的美梦，那么，你生活的价值，无非就是花一些时间在电脑屏幕上观察布朗运动罢了。</p>
<p>现在大盘正在蠢蠢欲动，很有可能再现2006年、2007年的盛况，又会有一大波还在校园里或者刚刚工作的年轻人会面对我当年面对的那种诱惑了。我写这篇文章，希望可以帮助一些看到它的人，不要再走一次我当年走过的弯路。</p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫抓取代理IP</title>
    <url>/2016/07/05/%E7%88%AC%E8%99%AB%E4%BB%A3%E7%90%86IP%E7%9A%84%E8%8E%B7%E5%8F%96/</url>
    <content><![CDATA[<p>由于某些网站对会对爬虫做限制，因此常常需要通过代理将爬虫的实际IP隐蔽起来，代理也有分类，如透明代理，高匿代理等。本文主要讲述如何获取代理IP，并且如何存储和使用。</p>
<span id="more"></span>
<p>某些网站会免费提供代理IP，如下面的几个</p>
<ul>
<li>http://www.xicidaili.com</li>
<li>http://www.kuaidaili.com</li>
<li>https://proxy.peuland.com</li>
</ul>
<p>获取这些页面上的代理IP及端口也是通过爬虫抓取，下面以第一个网站<a
href="http://www.xicidaili.com">http://www.xicidaili.com</a>为例，解释如何获取并存储这些代理IP。一般的流程为：<code>解析当前页面--&gt;存储当前页面的代理IP--&gt;跳转到下一页面</code>，重复该流程即可。</p>
<h2 id="解析页面">解析页面</h2>
<p>首先要解析页面，由于网页中显示代理IP时是在表格中显示的，因此只需要通过找出网页源码中相关的表格元素即可。下面是通过python中的<code>requests</code>和<code>bs4</code>获取页面<a
href="http://www.xicidaili.com/nt/">http://www.xicidaili.com/nt/</a>上显示的IP及端口。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">user_agent = <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36&#x27;</span></span><br><span class="line">referer = <span class="string">&#x27;http://www.xicidaili.com/&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: user_agent, <span class="string">&#x27;referer&#x27;</span>: referer&#125;</span><br><span class="line">target = <span class="string">&#x27;http://www.xicidaili.com/nt/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取页面源码</span></span><br><span class="line">r = requests.get(target, headers = headers)</span><br><span class="line"><span class="comment"># 解析页面源码</span></span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> tr <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;tr&#x27;</span>)[<span class="number">1</span>:]:</span><br><span class="line">    tds = tr.find_all(<span class="string">&#x27;td&#x27;</span>)</span><br><span class="line">    proxy = tds[<span class="number">1</span>].text+<span class="string">&#x27;:&#x27;</span>+tds[<span class="number">2</span>].text</span><br><span class="line">    <span class="built_in">print</span> proxy</span><br></pre></td></tr></table></figure>
<p>输出如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">36.235.1.189:3128</span><br><span class="line">219.141.225.149:80</span><br><span class="line">125.44.132.44:9999</span><br><span class="line">123.249.8.100:3128</span><br><span class="line">183.54.30.186:9999</span><br><span class="line">110.211.45.228:9000</span><br><span class="line">...........</span><br></pre></td></tr></table></figure></p>
<h2 id="代理ip的存储">代理IP的存储</h2>
<p>上面代码获取的代理IP可以通过在代码一开始建立一个集合（set）来存储，这种情况适用于一次性使用这些代理IP，当程序发生异常或正常退出后，这些存储在内存中的代理IP也会丢失。但是爬虫中使用代理IP的情况又是非常多的，所以有必要把这些IP存储起来，从而可以让程序多次利用。</p>
<p>这里主要通过<a
href="http://redis.io/">redis</a>数据库存储这些代理IP，redis是一个NOSQL数据库，具体使用参照官方文档，这里不做详细解释。</p>
<p>下面是<code>ConnectRedis.py</code>文件，用于连接redis <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">&#x27;XXX.XXX.XXX.XXX&#x27;</span> <span class="comment"># redis所在主机IP</span></span><br><span class="line">PORT = <span class="number">6379</span>              <span class="comment"># redis服务监听的端口</span></span><br><span class="line">PASSWORD = <span class="string">&#x27;XXXXXX&#x27;</span>      <span class="comment"># 连接redis的密码</span></span><br><span class="line">DB = <span class="number">0</span>                   <span class="comment"># IP存储的DB编号</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_connection</span>():</span><br><span class="line">    r = redis.Redis(host = HOST, port = PORT, password = PASSWORD, db= DB)</span><br><span class="line">    <span class="keyword">return</span> r</span><br></pre></td></tr></table></figure>
下面是在上面的代码基础上将IP存储到redis中， <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> ConnectRedis <span class="keyword">import</span> get_connection</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取redis连接</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    conn = get_connection()</span><br><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Error while connecting to redis&#x27;</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">user_agent = <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36&#x27;</span></span><br><span class="line">referer = <span class="string">&#x27;http://www.xicidaili.com/&#x27;</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: user_agent, <span class="string">&#x27;referer&#x27;</span>: referer&#125;</span><br><span class="line">target = <span class="string">&#x27;http://www.xicidaili.com/nt/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取页面源码</span></span><br><span class="line">r = requests.get(target, headers = headers)</span><br><span class="line"><span class="comment"># 解析页面源码</span></span><br><span class="line">soup = BeautifulSoup(r.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> tr <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;tr&#x27;</span>)[<span class="number">1</span>:]:</span><br><span class="line">    tds = tr.find_all(<span class="string">&#x27;td&#x27;</span>)</span><br><span class="line">    proxy = tds[<span class="number">1</span>].text+<span class="string">&#x27;:&#x27;</span>+tds[<span class="number">2</span>].text</span><br><span class="line">    conn.sadd(<span class="string">&quot;ip_set&quot;</span>, proxy)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;%s added to ip set&#x27;</span>%proxy</span><br></pre></td></tr></table></figure></p>
<p>上面的<code>conn.sadd("ip_set", proxy)</code>将代理<code>proxy</code>加入到redis的集合<code>"ip_set"</code>，这个集合需要预先在redis中创建，否则会出错。</p>
<h2 id="页面跳转">页面跳转</h2>
<p>上面的代码获取的只是一个页面上显示的代理，显然这个数量不够，一般通过当前页面中的下一页的超链接可以跳转到下一页，但是我们测试的由于每页的的url都有规律，都是<code>http://www.xicidaili.com/nt/page_number</code>,其中的<code>page_number</code>表示当前在哪一页，省略时为第一页。因此，通过一个for循环嵌套上面的代码即可获取多个页面的代理。但是更一般的方法是通过在当前页面获取下一页的超链接而跳转到下一页。</p>
<h2 id="代理ip的使用">代理IP的使用</h2>
<p>当我们需要通过代理访问某一网站时，首先需要从redis中随机选出一个代理ip，然后<strong>尝试通过代理ip是否能连到我们需要访问的目标网站，因为这些代理IP是公共使用的，所以往往也会被封的很快</strong>，假如通过代理无法访问目标网站，那么就要从数据库中删除这个代理IP。反之即可通过此代理访问目标网站</p>
<p>下面是实现上面所说流程的代码： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> ConnectRedis <span class="keyword">import</span> get_connection</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断IP是否能访问目标网站</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_valid</span>(<span class="params">url, ip</span>):</span><br><span class="line">    proxy = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://%s&#x27;</span> %ip</span><br><span class="line">    &#125;</span><br><span class="line">    user_agent = <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36&#x27;</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;user-agent&#x27;</span>: user_agent&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, headers = headers, proxies = proxy, timeout = <span class="number">6</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    my_proxy, proxies, ip_set = <span class="literal">None</span>, <span class="literal">None</span>, <span class="string">&#x27;amazon_ips&#x27;</span></span><br><span class="line">    conn = get_connection()</span><br><span class="line">    target = <span class="string">&#x27;https://www.amazon.com/&#x27;</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> is_valid(target, my_proxy):</span><br><span class="line">            <span class="keyword">if</span> my_proxy:</span><br><span class="line">                conn.srem(ip_set, my_proxy) <span class="comment">#删除无效的代理IP</span></span><br><span class="line">            <span class="keyword">if</span> proxies:</span><br><span class="line">                my_proxy = proxies.pop()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                proxies = conn.srandmember(ip_set, <span class="number">5</span>) <span class="comment">#从redis中随机抽5个代理ip</span></span><br><span class="line">                my_proxy = proxies.pop()</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;valid proxy %s&#x27;</span> %my_proxy</span><br></pre></td></tr></table></figure></p>
<p><code>requests.get(url, headers = headers, proxies = proxy, timeout = 6)</code>是通过代理去访问目标网站，超时时间设为6s，也就是说在6秒内网站没有回应或返回错误信息就认为这个代理无效。</p>
<p>除此之外，在爬取免费提供代理的网站上的代理IP的时候，爬取的速度不要太快，其中的一个原因是爬取太快有可能会被封，另外一个原因是如果每个人都无间隙地从这种网站上爬取，那么网站的负担会比较大，甚至有可能垮掉，因此采用一个可持续爬取的策略非常有必要，我爬取的时候是没爬完一个页面后让程序sleep大概2分钟，这样下来不会被封而且爬取的代理的量也足够使用。实际中可以根据自己使用代理的频率来进行调整。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>物理CPU、CPU核数、逻辑CPU、超线程</title>
    <url>/2016/01/06/%E7%89%A9%E7%90%86CPU%E3%80%81CPU%E6%A0%B8%E6%95%B0%E3%80%81%E9%80%BB%E8%BE%91CPU%E3%80%81%E8%B6%85%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<p>由于经常会混淆这几个概念，所以特意借该文比较详细地记录这几个概念的区别以及在Linux下如何查看这几个参数。</p>
<span id="more"></span>
<h2 id="基本概念">基本概念</h2>
<ul>
<li><strong>物理CPU</strong>：物理CPU就是插在主机上的真实的CPU硬件，在Linux下可以数不同的<code>physical id</code>
来确认主机的物理CPU个数。</li>
<li><strong>核心数</strong>：物理CPU下一层概念就是核心数，我们常常会听说多核处理器，其中的核指的就是核心数。在Linux下可以通过<code>cores</code>来确认主机的物理CPU的核心数。</li>
<li><strong>逻辑CPU</strong>：核心数下一层的概念是逻辑CPU，逻辑CPU跟超线程技术有联系，<strong>假如物理CPU不支持超线程的，那么逻辑CPU的数量等于核心数的数量；如果物理CPU支持超线程，那么逻辑CPU的数目是核心数数目的两倍。</strong>在Linux下可以通过
<code>processors</code> 的数目来确认逻辑CPU的数量。</li>
<li><strong>超线程</strong>：超线程是英特尔开发出来的一项技术，使得单个处理器可以象两个逻辑处理器那样运行，这样单个处理器以并行执行线程。这里的单个处理器也可以理解为CPU的一个核心；这样便可以理解<strong>为什么开启了超线程技术后，逻辑CPU的数目是核心数的两倍了</strong>。</li>
</ul>
<h2
id="在linxu下查看物理cpu核心数逻辑cpu和是否支持超线程">在Linxu下查看物理cpu、核心数、逻辑CPU和是否支持超线程</h2>
<p>关于CPU的一些信息可在 <code>/proc/cpuinfo</code>
这个文件中查看，这个文件显示的内容类似于下图所示</p>
<p><img src="https://wulc.me/imgs/2016-01-23_152653.png" /></p>
<p>可以看到里面的内容是以 processor
（也就是逻辑CPU）为基本单元进行划分的，<strong>processor 下的
<code>core id</code>表示这个逻辑CPU属于哪个核心，而<code>physical id</code>则表示这个核心或者说逻辑CPU属于哪个物理CPU。</strong>了解这些信息，便可以方便地查看上面说到的那些参数。</p>
<ul>
<li><p>查看物理CPU数量
物理CPU就是不同的<code>phycical id</code>的个数，可通过下面命令实现：
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /proc/cpuinfo | grep <span class="string">&#x27;physical id&#x27;</span> | <span class="built_in">uniq</span> |<span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure>
uniq是为了去掉多个逻辑CPU属于同一个物理CPU的重复记录。</p></li>
<li><p>查看核心数
核心数就是不同<code>core id</code>的个数，可通过下面的命令实现
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /proc/cpuinfo | grep <span class="string">&#x27;core id&#x27;</span> | <span class="built_in">uniq</span> |<span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure> 原理同上</p></li>
<li><p>查看逻辑CPU数目 逻辑CPU就是<code>processor</code>的数目
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /proc/cpuinfo | grep <span class="string">&#x27;processor&#x27;</span> | <span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure> 查看逻辑CPU时不需要去重</p></li>
<li><p>查看是否支持超线程
如果支持超线程就是说同一个core下会有两个processors，这样可以简单地观察<code>/proc/cpuinfo</code>中的内容，如果两个的processor下的core
id相同，那么说明支持超线程。</p></li>
</ul>
<p>还有另外一种方法是查看siblings和cpu cores的数值是否一致，评判方法如下
&gt; 如果"siblings"和"cpu
cores"一致，则说明不支持超线程，或者超线程未打开。 如果"siblings"是"cpu
cores"的两倍，则说明支持超线程，并且超线程已打开。</p>
<p>另外，top命令中看到的CPU数目是逻辑CPU（输入top后再按1）。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>程序的表示、转换与链接-week1</title>
    <url>/2020/05/30/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week1/</url>
    <content><![CDATA[<p>最近在 coursera 上发现一门不错的课程，<a
href="https://www.coursera.org/learn/jisuanji-xitong/home/welcome">程序的表示、转换与链接</a>，内容是类似《深入理解计算机系统》这本书的，说来惭愧，虽然在上学时零星上过一些相关的课程，但是却没有系统地将这些内容串起来理解。本着算法工程师首先得是个工程的原则，觉得还是有必要去了解一下这块内容;而且课程内容讲得挺通俗的，值得一听。</p>
<p>本文的内容主要是 week1
的内容，较为宏观地介绍了如何从冯·诺依曼体系结构演进至现代计算机结构、程序执行的基本原理、微体系结构与指令集(ISA)等。由于课程
PPT
说得已经较为清晰了，这里大部分内容会直接截图（懒得再打字也是一个原因。。。）</p>
<span id="more"></span>
<h2 id="冯诺依曼结构">冯·诺依曼结构</h2>
<h3 id="基本思想">基本思想</h3>
<p>冯-诺依曼结构主要思想是<strong>存储程序的工作方式</strong>，即让计算机完成的任何的一项工作，事先要编写成程序，然后把这个程序以及程序处理的这个数据先要送到主存，然后启动运行，运行以后，计算机就可以自动的取出一条一条指令，并且取出来进行执行，就是取出指令，执行。然后再取下条指令再执行，这样按部就班的取出指令并执行</p>
<p>按照上面的描述，计算机应该有如下的组成部分</p>
<figure>
<img src="https://wulc.me/imgs/VonNeumannarchitecture.jpg"
alt="Von Neumann architecture" />
<figcaption aria-hidden="true">Von Neumann architecture</figcaption>
</figure>
<p>更抽象一点的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/VonNeumannarchitecture1.jpg"
alt="Von Neumann architecture1" />
<figcaption aria-hidden="true">Von Neumann architecture1</figcaption>
</figure>
<p>因此，冯-诺依曼结构主要思想是</p>
<ol type="1">
<li>计算机由运算器，控制器，存储器，输入设备和输出设备五个基本部件组成</li>
<li>各部件的基本功能是
<ul>
<li><strong>存储器不仅能存放数据，也能存放指令</strong>，形式上两者都是0/1序列</li>
<li>控制器能自动取出指令来执行</li>
<li>运算器能够进行加减乘除、与或非等运算</li>
<li>操作人员可以通过输入设备和输出设备与主机进行通信</li>
</ul></li>
<li>内部以二进制表示指令和数据。<strong>每条指令由操作码和地址码组成</strong>，操作码指出操作类型，地址码指出操作数的地址</li>
<li>采用“存储程序”的工作方式</li>
</ol>
<h3
id="现代计算机的模型结构和工作原理">现代计算机的模型结构和工作原理</h3>
<p>现代计算机采用的基本就是前面提到的冯-诺依曼结构，更深入地看 CPU
的基本组成如下图所示，</p>
<figure>
<img src="https://wulc.me/imgs/VonNeumannarchitecture2.jpg"
alt="Von Neumann architecture2" />
<figcaption aria-hidden="true">Von Neumann architecture2</figcaption>
</figure>
<p>各个部件的作用如下</p>
<ul>
<li>PC（program counter）: 程序计数器，是一个用于存储指令在 memory
中的地址的寄存器，需要执行的指令先送到 PC，然后送到 MAR</li>
<li>MAR(memory address register)：存储 memory
中某些指令或数据的地址(跟总线相连)，除了接收 PC 的指令地址，还可以接收
GPR 的数据地址</li>
<li>MDR(memory data register): 从 memory
读出的指令或数据(跟总线相连)，送给 IR 或 GPR（同理也可往里面写）</li>
<li>IR（instruction register）：存储真实的指令，每条指令由 OP 和 ADDR
组成，表示指令的具体操作和要操作的对象的地址，供控制器读取</li>
<li>标志寄存器：存储运算的结果得到的符号是什么，有没有进位
有没有溢出等等一些标志信息</li>
</ul>
<p>因此，cpu 从内存读取指令/数据的流程是：<strong>PC/GPR -&gt; MAR -&gt;
memory -&gt; MDR
-&gt;IR/GPR</strong>(同时会有一些控制信号，即图中的红色虚线）</p>
<p>下面是以做菜的例子更详细描述计算机是如何工作的</p>
<figure>
<img src="https://wulc.me/imgs/CookVSProgram1.jpg"
alt="cookVSprogram1" />
<figcaption aria-hidden="true">cookVSprogram1</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/CookVSProgram2.jpg"
alt="cookVSprogram2" />
<figcaption aria-hidden="true">cookVSprogram2</figcaption>
</figure>
<h2 id="从机器语言到高级编程语言">从机器语言到高级编程语言</h2>
<ul>
<li>机器语言（01表示指令）：增减指令后需要重新对纸带打孔</li>
<li>汇编语言（符号表示指令）:
增减指令不影响，需要<strong>通过汇编程序转为机器语言</strong></li>
<li>高级语言：与平台无关，编译程序(生成目标文件）和解释程序（不生成目标文件）</li>
</ul>
<p>因此，高级语言(这里以c为例）需要执行如下步骤才能最终被计算机执行</p>
<figure>
<img src="https://wulc.me/imgs/compile2link.jpg"
alt="compile&amp;link1" />
<figcaption aria-hidden="true">compile&amp;link1</figcaption>
</figure>
<p>各个步骤做的事情如下</p>
<ol type="1">
<li>预编译（生成 <code>.i</code> 文件）：主要是处理 <code>#</code>
开头的语句，如进行宏展开、将被 include
的文件插入到对应的地方（递归执行）</li>
<li>编译（生成 <code>.s</code>
文件）：将代码编译成汇编代码，包括词法分析、语法分析、语义分析和生成汇编代码的优化；虽然不同语言都可通过
gcc 来统一编译，但是 gcc
对于对于不同的语言调用了不同的编译程序（如c是cc1，c++是cclplus，java是jc1）</li>
<li>汇编（生成<code>.o</code>文件）：将汇编代码逐条转换成机器指令（有查找表）</li>
<li>链接（生成可执行文件）：静态链接与动态链接</li>
</ol>
<p>下面是一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/compile2link1.jpg"
alt="compile&amp;link2" />
<figcaption aria-hidden="true">compile&amp;link2</figcaption>
</figure>
<p>上面的图中有几点值得注意</p>
<ul>
<li>汇编指令与机器指令是一一对应的</li>
<li>任何程序最终都是通过执行若干条指令来完成</li>
<li>指令集体系结构由计算机硬件决定</li>
</ul>
<h2 id="计算机的层次结构">计算机的层次结构</h2>
<p>计算机简单可分为软件和硬件两个层次，而在这两个层次内又可以做更细的划分，连接着两层的则是指令集(ISA)
如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/ComputerLevel.jpg" alt="level" />
<figcaption aria-hidden="true">level</figcaption>
</figure>
<p>作为软件和硬件的桥梁，ISA 具体做了些啥，简单来说，ISA
规定了如何使用硬件；类似于一个协议，其细节如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/ISA.jpg" alt="ISA" />
<figcaption aria-hidden="true">ISA</figcaption>
</figure>
<p><strong>计算机组成也被称为微体系结构(<a
href="https://en.wikipedia.org/wiki/Microarchitecture">Microarchitecture</a>)</strong>，微体系结构跟ISA的关系不是一一对应的，不同的
ISA 定义了不同的指令集，同一个 ISA 可对应于多个微体系结构</p>
<figure>
<img src="https://wulc.me/imgs/ISAandMicroarchitecture.jpg"
alt="Microarchitecture v.s ISA" />
<figcaption aria-hidden="true">Microarchitecture v.s ISA</figcaption>
</figure>
<h2 id="小结">小结</h2>
<p>week1
的内容比较宏观地介绍了冯·诺依曼结构的计算机系统层次结构、程序在计算机系统内运行的基本原理、高级语言如何转换为机器语言、ISA
的概念等基本内容，课程总共有12周，后面的课程当于是对上述的相关部分内容进行展开。</p>
<figure>
<img src="https://wulc.me/imgs/content.jpg" alt="content" />
<figcaption aria-hidden="true">content</figcaption>
</figure>
]]></content>
      <categories>
        <category>程序的表示、转换与链接</category>
      </categories>
      <tags>
        <tag>程序的表示、转换与链接</tag>
      </tags>
  </entry>
  <entry>
    <title>程序的表示、转换与链接-week10、11</title>
    <url>/2020/10/03/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week10/</url>
    <content><![CDATA[<p>本文是 <a
href="https://www.coursera.org/learn/jisuanji-xitong/home/welcome">程序的表示、转换与链接</a>
中第 10、11
周的内容，主要介绍了从源文件生成可执行文件的步骤(预处理、编译、汇编、链接)，并详细描述了其中的链接这一步骤中的两大过程：<strong>符号解析与重定位</strong>，并对比了链接输入的可重定位目标文件和输出的可执行目标文件的差别；对了解文件的从编译到执行原理有一定帮助，可配合
<a
href="http://wulc.me/tags/%E9%93%BE%E6%8E%A5%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%8E%E5%BA%93/">《链接、装载与库》
阅读笔记</a> 一起阅读。</p>
<span id="more"></span>
<p>通过对源文件的预处理、编译，汇编等转换
可以得到一个个模块对应的机器代码, 也就是目标文件；
但是目标还不能直接执行，还需要将这些目标文件链接起来才能得到一个可执行文件</p>
<p>链接过程用到的目标文件主要有： -
编译、汇编后得到的目标文件，称为可重定位目标文件 -
链接后生成的目标文件，称为可执行目标文件， - 共享库文件</p>
<p>下面以Linux平台所用的elf格式 为例，来讲解这些目标文件的相关内容</p>
<h2 id="程序转换过程">程序转换过程</h2>
<p>以 c 语言为例，从源码到可执行文件的典型过程如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/ProgramConv.jpg" alt="转换过程" />
<figcaption aria-hidden="true">转换过程</figcaption>
</figure>
<p>在 Linux 下，通过 gcc 命令能完成上面各个步骤，而实际上， gcc
命令实际上是由具体程序(如 ccp，cc1,
as，ld等)包装的命令，用户实际上是通过 gcc 命令来使用具体的预处理程序
ccp，编译程序 cc1 ，汇编程序 sa 和链接程序 ld 等。</p>
<p>以 c 语言为例，各个步骤的 input/output 及其主要做的事情如下所示</p>
<h3 id="预处理">预处理</h3>
<p>主要处理以 <code>#</code>
开头的代码，具体处理包括宏展开、条件预编译等</p>
<p>input: 源代码文件（文本文件，<code>.c</code> 文件）
output：预处理后的代码文件（文本文件，<code>.i</code> 文件）</p>
<p>预处理主要做的事情有</p>
<ul>
<li>删除 <code>#define</code> 并展开所定义的宏</li>
<li>处理所有条件预编译指令，如
<code>#if</code>、<code>#ifdef</code>、<code>#endif</code> 等</li>
<li>插入头文件到 <code>#include</code> 处，可用递归方式进行处理</li>
<li>删除所有注释</li>
<li>保留行号和文件名标识，以便编译时编译器产生调试用的行号信息</li>
<li>保留所有 <code>#pragma</code> 指定的编译指令(编译器需要使用)</li>
</ul>
<p>下面是一个预编译例子, 其实就是把头文件嵌入到源文件中</p>
<figure>
<img src="https://wulc.me/imgs/Precompiled.jpg" alt="preCompiled" />
<figcaption aria-hidden="true">preCompiled</figcaption>
</figure>
<h3 id="编译">编译</h3>
<p>对预处理后的文件进行<strong>词法分析、语法分析、语义分析并优化</strong>，生成汇编代码文件；这个步骤通过编译程序(就是编译器）完成的</p>
<p>input: 预处理后的代码文件（文本文件，<code>.i</code> 文件）
output：汇编代码文件（文本文件，<code>.s</code> 文件）</p>
<p>这部分详细内容就不展开了，详细可参考这一系列的文章 <a
href="https://zhuanlan.zhihu.com/p/102250532">LLVM概述——基础架构</a></p>
<h3 id="汇编">汇编</h3>
<p>对编译后的文件通过查表操作（因为机器指令和汇编指令是一一对应的）生成机器指令序列；这个步骤通过汇编程序(就是汇编器）完成的</p>
<p>input：汇编代码文件（文本文件，<code>.s</code> 文件）
output：目标文件/可重定位文件（二进制文件，<code>.o</code> 文件）</p>
<h3 id="链接">链接</h3>
<p>input: 多个可重定位文件 output: 可执行文件</p>
<p>后面会详细介绍链接的主要内容</p>
<h2 id="链接的由来与本质">链接的由来与本质</h2>
<h3 id="链接的由来">链接的由来</h3>
<p>程序往往会被分成多个模块，在进行模块间会进行引用(reference)操作，因此在运行时需要确定被引用的符号的地址，而链接可以认为是在<strong>生成可执行文件时确定程序中引用的符号的地址</strong></p>
<p>如下是通过两个目标文件生成一个可执行文件的简单例子</p>
<figure>
<img src="https://wulc.me/imgs/LinkExample.jpg" alt="link example" />
<figcaption aria-hidden="true">link example</figcaption>
</figure>
<p>上图中的四个步骤从概念上又可分为<strong>符号解析和重定位两大步骤</strong>，符号解析是就是在合并之前先确定引用和定义之间的关系。
重定位则是代码和代码
合并、数据和数据合并，合并以后它就在一个地址空间里面，
这个地址空间实际上我们称为虚拟地址空间。</p>
<p>虚拟地址可以认为是从 0
开始连续增长的，在虚拟地址空间中，能得到各个符号的地址。
再把这个地址填到引用的地方，那么就得到了每一条指令真实的 01
序列。每个进程都有自己独立的虚拟地址空间，那最终虚拟地址空间怎么跟物理内存挂钩呢，实际上这个是由操作系统进行内存管理与分配时确定的,
详细可参考 <a
href="http://abcdxyzk.github.io/blog/2015/04/18/kernel-mm-vm-rm/">Linux
虚拟内存和物理内存的理解</a></p>
<p>链接的好处是 1.
模块化编程：程序可分为多个源程序文件多人协助开发、可构建共享函数库等 2.
效率高：重新编译时只需要编译那些被修改过的源代码</p>
<h3 id="链接的本质">链接的本质</h3>
<p>链接的本质实际上就是在合并不同目标文件中相同的节，这部分跟之前写的<a
href="http://wulc.me/2020/05/31/%E3%80%8A%E9%93%BE%E6%8E%A5%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%8E%E5%BA%93%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5/">《链接、装载与库》
阅读笔记(1)-基本概念与静态链接</a> 内容比较相似，这里不再赘述</p>
<figure>
<img src="https://wulc.me/imgs/LinkMerge.jpg" alt="merge" />
<figcaption aria-hidden="true">merge</figcaption>
</figure>
<p>存储在磁盘中的可执行文件中有一个比较重要的组成部分：<strong>程序头表</strong>，该部分存储着<strong>各个节到虚拟地址空间的映射关系</strong>,
这部分后面会详细描述</p>
<h2 id="目标文件">目标文件</h2>
<p>目标文件可分为三大类：可重定位目标文件、可执行目标文件 和
共享的目标文件，这三类文件的特点如下</p>
<ul>
<li>可重定位目标文件（<code>.o</code> 文件）
<ul>
<li>其代码和数据可和其他重定位文件合并成可执行文件</li>
<li>每个 .o 文件由对应的 .c 文件组成</li>
<li>每个 .o 文件的<strong>代码和数据地址都从 0 开始</strong></li>
</ul></li>
<li>可执行目标文件（Linux 的 <code>.out</code>文件，Windows 下的
<code>.exe</code> 文件）
<ul>
<li>包含的代码和数据可直接被复制到内存并被执行</li>
<li>代码和数据的地址为<strong>虚拟地址空间</strong>中的地址</li>
</ul></li>
<li>共享的目标文件(Linux 下的 <code>.so</code> 文件，Windows 下的
<code>.dll</code> 文件)
<ul>
<li>用于动态链接</li>
<li>在<strong>装入和运行时</strong>(前面的都是在链接阶段就用到了目标文件)被转入到内存并自动被链接</li>
</ul></li>
</ul>
<p>在 Linux 下最常见的目标文件格式就是 ELF
格式，其实就是将代码和数据放到不同的节(section) 中，如下 ELF
文件的基本格式和一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/ELFFile.jpg" alt="elf file" />
<figcaption aria-hidden="true">elf file</figcaption>
</figure>
<p>值得注意的是，目标文件与可执行文件的格式非常相似，基本都是 ELF
文件格式，因此可以从两种视角来看ELF
文件，即链接视角和执行视角，两者的简单对比如下,
后面会详细分析这两种视角下的 ELF 文件的异同</p>
<figure>
<img src="https://wulc.me/imgs/ELF2View.jpg" alt="elf2view" />
<figcaption aria-hidden="true">elf2view</figcaption>
</figure>
<h3 id="可重定位文件">可重定位文件</h3>
<p>可重定位文件主要由 ELF 头、各种类型的节和节头表(Section header
table)组成，各部分的含义如下如所示</p>
<figure>
<img src="https://wulc.me/imgs/ReloadFile.jpg" alt="reload file" />
<figcaption aria-hidden="true">reload file</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/ReloadFile1.jpg" alt="reload file1" />
<figcaption aria-hidden="true">reload file1</figcaption>
</figure>
<p>为什么要将未初始化的变量(<code>.bss</code>节)与已初始化的变量(<code>.data</code>节)分开？
主要是为了<strong>节省磁盘空间</strong>，因为<code>.data</code>节中存放的是具体的初始值，需要占磁盘空间；而
<code>.bss</code> 节中无需存放初始值，只要说明 <code>.bss</code>
中的每个变量将来在执行时占用几个字节即可（通过节头表来说明应该为 .bss
节预留多大的空间）</p>
<p>除了上面提到的各个节，ELF 头和节头表也是 ELF
文件的两个重要组成部分</p>
<p>ELF
头位于一个ELF文件的最开始的地方，里面包含了一些文件结构的说明信息，如ELF
魔数、版本、小端/大端、操作系统平台、目标文件的类型、机器结构类型、程序执行的入口地址、节头表的起始地址和长度等；且根据操作系统主要分两种结构，一种是32位系统对应的结构，一种是
64位系统对应的结构</p>
<p>如下是通过 readelf 读取 ELF 头信息的一个例子</p>
<figure>
<img src="https://wulc.me/imgs/ELFHEader.jpg" alt="ELF Header" />
<figcaption aria-hidden="true">ELF Header</figcaption>
</figure>
<p>除了 ELF 头，节头表是 ELF
可重定位目标文件中最终要的部分，节头表主要描述了<strong>各个节的节名及其在文件中的偏移、大小、访问属性、对齐方式等</strong>，如下是一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/SectionHeaderTable.jpg"
alt="SectionHeaderTable" />
<figcaption aria-hidden="true">SectionHeaderTable</figcaption>
</figure>
<p>从上面的 Off 和 Size
可知，有四个节会分配存储空间：.text、.data、.bss、.rodata</p>
<h3 id="可执行目标文件">可执行目标文件</h3>
<p>可执行目标文件与可重定位目标文件很像，两者的不同点在于</p>
<p>（1）在ELF头里面，有一个字段 e_entry，表示程序的执行入口，e_entry
在可
重定位文件当中是0，因为可重定位文件只是用来链接的；而在可执行目标文件当中，这个字段给出这个<strong>程序执行的时候第一条指令的地址</strong>
（2）可执行目标文件多了一个程序头表，也称为段头表（segment header
table）；
类似可重定位目标文件中的节头表，描述的是各个段的一些信息，而可执行目标文件中的<strong>一个段(segment)是由可重定位目标文件中的多个有相同访问属性的节(section)组成的</strong>;
如下图是可执行文件中的各个段及组成其的各个节 （3）多了一个
<code>.init</code> 节, 用于定义 _init
函数，该函数用来进行可执行目标文件开始执行是的初始化工作 <img
src="https://wulc.me/imgs/ExecFile.jpg" alt="ExecFile" /></p>
<p>程序头表/段头表主要是用来说明可执行目标文件中各个段的一些属性，如<strong>各个段在可执行文件中的位移、大小、在虚拟地址空间中的位置、对齐方式、访问属性</strong>等，如下是其定义和一个例子</p>
<figure>
<img src="https://wulc.me/imgs/SegmentHeaderTable.jpg"
alt="SegmentHeaderTable" />
<figcaption aria-hidden="true">SegmentHeaderTable</figcaption>
</figure>
<h2 id="符号解析">符号解析</h2>
<p>前面提到，链接主要分为符号解析和重定位两大步骤，符号解析的目的是<strong>把符号的引用和符号的定义关联起来</strong>；每个定义符号在代码段和数据段都分配了存储空间，而在引用符号和定义符号建立关联以后，重定位时就可以把引用符号的地址重定位成相关联的定义符号的地址(虚拟地址空间中的地址)</p>
<p>每个可重定位目标模块的符号存都放在各自的符号表(在
<code>.symtab</code> 节)，这些符号可分为三种</p>
<ul>
<li>全局符号(Global
symbols)：由当前模块定义且能被其他模块引用的符号(不带 static)</li>
<li>外部符号(External symbols)：由其他模块定义且被当前模块应用的</li>
<li>局部符号(Local symbols)：仅有当前模块定义和引用的本地符号</li>
</ul>
<p>值得注意的是，这里的<strong>局部符号(Local
symbol)不是指程序当中的局部变量</strong>，局部变量是分配在栈中
的临时性的变量，链接器是不关心这种局部变量的, 而局部符号则是分配在静态
数据区，且在整个模块里面都可以使用的。 如下是一个例子：<strong>局部变量
temp 分配在栈中，不会在外部过程被调用，因此不是符号定义</strong></p>
<figure>
<img src="https://wulc.me/imgs/SymbolType.jpg" alt="symbolType" />
<figcaption aria-hidden="true">symbolType</figcaption>
</figure>
<h3 id="符号强弱性">符号强弱性</h3>
<p><strong>当一个符号在多个地方有定义的时候，最终解析的时候只能有一个确定的定义</strong>；因此有如下规则：</p>
<ol type="1">
<li>强符号不能多次定义</li>
<li>若一个符号被定义为一次强符号和多次弱符号，则以强符号为准(即对弱符号的引用被解析为其强定义符号)</li>
<li>若有多个弱符号的定义，则任选其中一个(gcc -fno-common 链接时会有
warning)</li>
</ol>
<p>那强符号和弱符号的定义又是什么呢？全局符号又可分为强符号和弱符号，区分两者特点如下</p>
<ul>
<li>所有的<strong>函数名和已初始化的全局变量名</strong>都是强符号</li>
<li><strong>未初始化的全局变量</strong>名是弱符号</li>
</ul>
<p>如下是一些例子</p>
<p>下面的例子中由于 x 被重定义了多次，因此链接时会报错</p>
<figure>
<img src="https://wulc.me/imgs/StrongSymbolsMultiDef.jpg"
alt="多重定义" />
<figcaption aria-hidden="true">多重定义</figcaption>
</figure>
<h3 id="静态库文件">静态库文件</h3>
<p>静态库文件实际上是把若干可重定位文件打包好的一个文件，如C
自带的标准库 libc.a
就是一个静态库文件，下面是一个例子，描述了<strong>如何定义与使用静态库文件</strong></p>
<figure>
<img src="https://wulc.me/imgs/StaticLibrary_.jpg"
alt="static library" />
<figcaption aria-hidden="true">static library</figcaption>
</figure>
<p>符号解析过程描述如下所示</p>
<figure>
<img src="https://wulc.me/imgs/ParseSymbol.jpg" alt="parse symbol" />
<figcaption aria-hidden="true">parse symbol</figcaption>
</figure>
<p>此外，值得注意的是，上面的链接中如果调换了 mylib.a 和 main.o
的位置会报错，原因是先扫描 mylib.a 时，<strong>由于找不到 mylib.a
中定义的函数被调用的地方，因此mylib.a 中的所有 <code>.o</code>
文件都会被丢弃</strong>, 然后扫描 main.o 文件时，myfunc1 无法解析。</p>
<p>因此，使用静态库时链接器对外部引用的符号的解析算法如下</p>
<figure>
<img src="https://wulc.me/imgs/LinkProcess.jpg" alt="link process" />
<figcaption aria-hidden="true">link process</figcaption>
</figure>
<h2 id="小结">小结</h2>
<p>这一周主要讲了从源文件生成可执行文件的步骤，并详细描述了其中的链接这一步骤的过程，包括使用链接的优点，链接如何将可重定位目标文件组合成可执行目标文件，以及这两类文件的差别，两类文件都是
ELF
格式，但是可执行目标文件中多包含了一些程序执行的入口信息和初始化信息（因为可重定位目标文件是无法执行了），且两类文件中都有一个表头用来描述
section/segment
的一些属性，在可重定位目标文件中是节头表，而在可执行目标文件中是段头表。</p>
]]></content>
      <categories>
        <category>程序的表示、转换与链接</category>
      </categories>
      <tags>
        <tag>程序的表示、转换与链接</tag>
      </tags>
  </entry>
  <entry>
    <title>程序的表示、转换与链接-week2</title>
    <url>/2020/06/06/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week2/</url>
    <content><![CDATA[<p>本文的内容主要是 <a
href="https://www.coursera.org/learn/jisuanji-xitong/home/welcome">程序的表示、转换与链接</a>
这门课第二周的内容，主要介绍了浮点数和整数在机器内如何编码和存储(大端和小端)的，了解这些细节后，能够更好地理解代码中进行数值计算和比较时出现的违反直觉的结果，同时也能避免出现这样的问题。</p>
<span id="more"></span>
<p>数据在机器中都是 01
编码的，而在程序中常用的数值类型是整数和浮点数，下面会描述下两者在计算机中的表示方式，且会重点描述浮点数部分</p>
<h2 id="整数的表示">整数的表示</h2>
<p>整数主要分为带符号（signed） 和无符号
（unsigned）的，需要注意的是无论是否带符号，整数在内存中都通过<a
href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E8%A3%9C%E6%95%B8">补码</a>来表示，正数和0的补码就是该数字本身。负数的补码则是将其对应正数按位取反再加1</p>
<p>对于 C 语言，需要注意的是，<strong>若同时带有无符号和带符号整数，C
编译器会将带符号整数强制转为无符号数</strong>，比如说对于如下关系表达式，某些结果并不符合直觉就是由这个原因引起的</p>
<p>下图中的后面带 <code>U</code>
的数字表示这是个无符号的整数，反之就是有符号的，其中标红的就是结果不符合直觉的例子</p>
<figure>
<img src="https://wulc.me/imgs/signVSunsigned.jpg"
alt="signedVSunsigned" />
<figcaption aria-hidden="true">signedVSunsigned</figcaption>
</figure>
<p>上面那三个不符合直觉的例子原因分析如下</p>
<ul>
<li>第三个例子由于右边的 0U 是个无符号数，因此左边的 -1
也被解析成一个无符号数，而其补码是 32 个 1，被解析成无符号整数后就是
<span class="math inline">\(2^{32}-1\)</span></li>
<li>第五个例子由于同理，右边的结果 -2147483648 的补码是首位的 1 加上 31
个0，被解析成无符号数后就是 <span
class="math inline">\(2^{31}\)</span></li>
<li>第六个例子中， 2147483648U 的补码同样也是是首位的 1 加上 31
个0，但是因为前面加了一个 (int)
后被转换成一个带符号整数，则在解释的时候变成了 <span
class="math inline">\(-2^{31}\)</span></li>
</ul>
<p>同理，在 printf 时通过 <code>%u</code> 和 <code>%d</code>
分别将整数解析成无符号和带符号的，因此也会出现如下结果</p>
<figure>
<img src="https://wulc.me/imgs/signVSunsigned1.jpg"
alt="此处输入链接的描述" />
<figcaption aria-hidden="true">此处输入链接的描述</figcaption>
</figure>
<h2 id="浮点数表示">浮点数表示</h2>
<p>在介绍浮点数之前，先介绍一些移码的含义，因为在浮点数的表示中用到了这个概念</p>
<figure>
<img src="https://wulc.me/imgs/ExcessNotion.jpg" alt="ExcessNotion" />
<figcaption aria-hidden="true">ExcessNotion</figcaption>
</figure>
<p>整数的通过 01
表示很好理解，那小数中的小数点该如何在计算机中表示？采用的<strong>基本思想就是用科学计数法来表示小数，然后将科学计数法中不同部分(包括正负、尾数部分和指数部分三大部分)分段存储在
01 序列中</strong>，如下是详细的描述</p>
<figure>
<img src="https://wulc.me/imgs/float.jpg" alt="float" />
<figcaption aria-hidden="true">float</figcaption>
</figure>
<p>上面提到了任何实数都能通过科学计数法表示成 <span
class="math inline">\(X=(-1)^s × M × R^E\)</span>，
而在计算机中都是二进制表示的，因此 R 固定为 2</p>
<p>而 M 的取值则可以有很多种方式了，如让 M 的取值小于 1
且小数点后第一位为 1, 则对于十进制的 12.0，写成二进制是 1100.0，相当于
<span
class="math inline">\(0.11×2^4\)</span>，则可以得出s=0，M=0.11，R=2，E=4；
且由于 M
的小数点后第一位总是1，可以将其省略掉，则对于浮点数有以下的表示方式</p>
<figure>
<img src="https://wulc.me/imgs/FloatPoint.jpg" alt="floatpoint" />
<figcaption aria-hidden="true">floatpoint</figcaption>
</figure>
<p>而在通用的 <strong>IEEE754 标准下，定点小数 M 是一个值在 1-2
之间的数</strong>；比如说对于十进制的 12.0，写成二进制是 1100.0，相当于
<span
class="math inline">\(1.1×2^3\)</span>，则可以得出s=0，M=1.1，R=2，E=3；而对于十进制的-12.0，相当于-1.1×2^3吗，则
s=1，M=1.1，R=2，E=3，因此 IEEE745 的标准跟上面的很类似，具体如下</p>
<figure>
<img src="https://wulc.me/imgs/IEEE745.jpg" alt="IEEE754" />
<figcaption aria-hidden="true">IEEE754</figcaption>
</figure>
<p>如下是通过 IEEE754 标准来存储和解析浮点数的两个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/IEEE754_example.jpg"
alt="机器数-&gt;真值" />
<figcaption aria-hidden="true">机器数-&gt;真值</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/IEEE754_example1.jpg"
alt="真值-&gt;机器数" />
<figcaption aria-hidden="true">真值-&gt;机器数</figcaption>
</figure>
<p>上面的 IEEE754 标准中，阶码是全 0 和全 1
表示的是特殊值，而这可以分为以下几种情况</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">-</th>
<th style="text-align: left;">尾数 M 全 0</th>
<th style="text-align: left;">尾数 M 非全 0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">阶码 E 全 0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">非规格化数/Denorms</td>
</tr>
<tr class="even">
<td style="text-align: left;">阶码 E 全 1</td>
<td style="text-align: left;">无穷大</td>
<td style="text-align: left;">非数/Nan(Not a number)</td>
</tr>
</tbody>
</table>
<p>Nan 表示的是不合法的数值如 <span
class="math inline">\(\sqrt{-4.0}\)</span>、<span
class="math inline">\(0/0\)</span>、<span
class="math inline">\(+\infty+(-\infty)\)</span> 等都是非数</p>
<p>而 Denorms 则是被用来标识前面通过 IEEE754 标准中最小正数到 0
之间的这段距离</p>
<figure>
<img src="https://wulc.me/imgs/Denorms.jpg" alt="denoms" />
<figcaption aria-hidden="true">denoms</figcaption>
</figure>
<p>从上面的描述中可知，<strong>并非每个浮点数都可以用 01
精确表示</strong>，对于那些无法找到精确表示的浮点数，只能进行舍入来进行近似,如下图所示是一个例子</p>
<figure>
<img src="https://wulc.me/imgs/float_sheru.jpg" alt="float sheru" />
<figcaption aria-hidden="true">float sheru</figcaption>
</figure>
<h2 id="大端与小端">大端与小端</h2>
<p>大端与小端其实就是数据的字节在地址中是如何排列的：大端指的是 MSB
所在的地址是数的地址，小端指的是 LSB 所在的地址是数的地址</p>
<p><img src="https://wulc.me/imgs/byteStore.jpg" /></p>
<h2 id="小结">小结</h2>
<p>week2
的内容很多细节，但是比较重点的就是整数和浮点数是如何在计算中表示和存储的，其中整数都是以补码来表示的，同时要注意同一个补码会根据上下文被解析成
signed 或
unsigned，而这会导致一些违反直觉的情况出现；而浮点数通过科学计数法写成了三个主要部分：正负号、尾数和指数，并在计算机中分三段分别存储这些数，解决了无法直接表示小数点的问题，单精度和双精度的表示凡是是一致的，只是各个段的长度不一，需要注意的是，并非每个浮点数（这个集合是无穷大）都可以用
01
精确表示，对于那些无法找到精确表示的浮点数，只能进行舍入来进行近似，因此在浮点数进行比较时要慎重使用
<code>==</code></p>
]]></content>
      <categories>
        <category>程序的表示、转换与链接</category>
      </categories>
      <tags>
        <tag>程序的表示、转换与链接</tag>
      </tags>
  </entry>
  <entry>
    <title>程序的表示、转换与链接-week5、6</title>
    <url>/2020/06/14/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week5%E3%80%816/</url>
    <content><![CDATA[<p>本文是 <a
href="https://www.coursera.org/learn/jisuanji-xitong/home/welcome">程序的表示、转换与链接</a>
中第 5、6
周的内容，主要介绍了程序和指令的关系，目标文件的基本格式，并详细地介绍了
IA-32
体系下的指令系统，包括各种指令的类型、指令执行的基本流程，通过以上内容可以对计算机内部如何执行程序有一个感性的认识。</p>
<span id="more"></span>
<p>目前所用的主流计算机基本上都是基于 intel 架构的，因此本文主要基于
IA-32 指令系统介绍</p>
<h2 id="程序与指令">程序与指令</h2>
<p>在介绍IA-32指令系统之前，需要了解如何将高级语言程序转换为用机器指令表示的机器代码</p>
<p><a
href="http://wulc.me/2020/05/30/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week1/">程序的表示、转换与链接-week1</a>
中介绍了计算机的硬件基本组成，基于这个硬件上面
采用的是一种<strong>存储程序的工作方式</strong>：即所有要通过计算机完成的任务事先要编写成程序,然后将程序装入到存储器里面，一旦要执行这个程序，计算机就可以把
程序当中的指令一条一条取到这个CPU里面自动的来完成</p>
<p>从计算机的执行角度来看，程序可认为是由指令和数据组成的，它们都是存放在存储器里面的，
指令和数据都是用二进制的01进行编码的，<strong>在指令执行过程当中，指令和数据从存储器要取到CPU，然后存放在CPU的寄存器里面</strong>，两者的关系如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/instructionAndData.jpg"
alt="instructionAndData" />
<figcaption aria-hidden="true">instructionAndData</figcaption>
</figure>
<p>上面说的指令指的是机器指令，在一些其他地方往往也能看到<strong>微指令与伪指令</strong>的概念，三者简单对比如下</p>
<ul>
<li>指令:
也叫机器指令，在<strong>硬件和软件交界面上</strong>的，表示计算机的一个完整的基本动作</li>
<li>微指令:
<strong>硬件范畴</strong>，一条机器指令的功能是若干条微指令组成的序列来实现的</li>
<li>伪指令：<strong>软件范畴</strong>，由若干个机器指令构成的一个指令序列</li>
</ul>
<p>机器指令和汇编指令是一一对应的，由硬件决定</p>
<h2 id="目标代码">目标代码</h2>
<p>这一小节的内容基本在 <a
href="http://wulc.me/2020/05/31/%E3%80%8A%E9%93%BE%E6%8E%A5%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%8E%E5%BA%93%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5/">《链接、装载与库》
阅读笔记(1)-基本概念与静态链接</a>
有描述，因此这里只做简单的记录，下图描述了编译的过程，即如何从源文件生成目标文件</p>
<figure>
<img src="https://wulc.me/imgs/compile.jpg" alt="compile" />
<figcaption aria-hidden="true">compile</figcaption>
</figure>
<p>上图中的 <code>.c</code> 表示 C 语言的源文件、<code>.i</code>
表示预编译文件、<code>.s</code> 表示汇编文件、<code>.o</code>
表示目标文件(也叫可重定位目标文件)</p>
<p>从上图可知，原始的汇编文件中的指令与反汇编得到的汇编指令在形式上有一点差别，主要体现在
(1) 编译得到的汇编指令的助记符当中都带长度后缀, 而反汇编的都没有 (2)
编译得到的汇编指令用的是十进制，反汇编用的则是十六进制</p>
<p>此外的 <strong>test.o
里面的起始地址总是从零开始，因为它还没有链接，还没生成可执行文件，所以它的地址是不确定的</strong>，需要被链接生成可执行目标文件，链接的过程也可参考上面的<a
href="http://wulc.me/2020/05/31/%E3%80%8A%E9%93%BE%E6%8E%A5%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%8E%E5%BA%93%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5/">文章</a>，从下图中可知，可执行目标文件中的地址不再是从
0 开始的, 而是一个确切的地址</p>
<figure>
<img src="https://wulc.me/imgs/ObjectFileCompare.jpg"
alt="objectFilesCompared" />
<figcaption aria-hidden="true">objectFilesCompared</figcaption>
</figure>
<p>这个确切的地址是什么地址呢？实际上是一个虚拟地址，它是在一个虚拟地址空间里面的，其实就是进程的虚拟地址空间，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/object_file_mapping.jpg"
alt="object file mapping" />
<figcaption aria-hidden="true">object file mapping</figcaption>
</figure>
<h2 id="intel-处理器与-ia-32-指令系统">Intel 处理器与 IA-32
指令系统</h2>
<p>x86实际上是 Intel 开发的一类处理器体系结构的一个泛称，比如说
8086、80286是16位的； 而386、486这些是 32 位的
因为这些架构后面都带有86，所以就称为x86，Intel
处理器中涉及的产品如下</p>
<figure>
<img src="https://wulc.me/imgs/IntelProcess.jpg" alt="IntelProcessor" />
<figcaption aria-hidden="true">IntelProcessor</figcaption>
</figure>
<p>Intel把32位的x86架构的名称 x86-32 改为IA -32，IA 实际上是Intel
Architecture的缩写
因此<strong>IA-32就是Intel体系结构的32位机器的一个泛称</strong></p>
<p>IA-32 体系结构规定了寄存器的个数、
各自指令功能以及寄存器的宽度、存储空间等；整体体系结构大致如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/IA-32.jpg" alt="IA-32" />
<figcaption aria-hidden="true">IA-32</figcaption>
</figure>
<p>从上图可知，IA-32的体系结构的一些特点如下</p>
<ul>
<li>8 个通用寄存器，编号就是 0 到 7</li>
<li>2个专用寄存器：标志寄存器 EFLAGS 和指令计数器(PC),叫EIP</li>
<li>6 个段寄存器（间接给出段基址）</li>
<li>可寻址的空间是4GB，也就是 寻址空间是从 0 一直到 0xffffffff</li>
</ul>
<p>随着体系结构从8位的机器，逐渐扩展到16位、32位的机器，寄存器的宽度也在不断地扩展，如下图所示是</p>
<figure>
<img src="https://wulc.me/imgs/IA32Register.jpg" alt="IA32-Register" />
<figcaption aria-hidden="true">IA32-Register</figcaption>
</figure>
<p>后面的80位的寄存器和120位的寄存器在后面的内容中会有介绍。</p>
<h2 id="寻址方式">寻址方式</h2>
<p>什么叫寻址方式？寻址方式是<strong>根据指令当中给出来的信息得到操作数或者操作数地址的方式</strong>
根据操作数可能的地址，寻址方式也有多种</p>
<ul>
<li>指令中：立即寻址</li>
<li>寄存器中：寄存器寻址</li>
<li>存储单元(属于<strong>存储器操作数，按字节编址</strong>)：其他寻址方式（多种）</li>
</ul>
<p>详细如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/SearchAddress.jpg" alt="searchAdd" />
<figcaption aria-hidden="true">searchAdd</figcaption>
</figure>
<p>下面是高级语言中的一个寻址例子，描述了声明变量时，内存的分配情况以及访问变量时的寻址方法（以
Windows 为例）</p>
<figure>
<img src="https://wulc.me/imgs/CSearchAddress.jpg"
alt="CSearchAddress" />
<figcaption aria-hidden="true">CSearchAddress</figcaption>
</figure>
<p>前面提到，寻址指的是从如何从机器指令中获取找到操作数的地址，那 IA-32
中的指令是怎么组织然后坐到这一点的呢?
下面是关于这个指令的一张详细的图，比较复杂，这里不展开讨论了</p>
<figure>
<img src="https://wulc.me/imgs/MachineCode.jpg" alt="MachineCode" />
<figcaption aria-hidden="true">MachineCode</figcaption>
</figure>
<h2 id="ia-32-常用指令类型">IA-32 常用指令类型</h2>
<h3 id="传送指令">传送指令</h3>
<p>IA-32当中的指令类型有很多种，最基本的就是传送指令，就是从一个地方传到另外一个地方。传送指令又可分为以下几种</p>
<ul>
<li>数据传送指令，数据传送指令一般是用MOV指令来实现的;</li>
<li>地址传送指令，用于加载有效地址</li>
<li>输入输出指令，用于输入/输出端口和通用寄存器之间进行数据的交换</li>
<li>标志传送指令，将标志寄存器的值入/出栈</li>
</ul>
<p>如下图中的 LEA(Load Effective Address)
指令就是用来加载有效地址的，leal 做的就是把 edx
的值(相当于是基址值)加上eax的值(相当于是变址值),
基址加变址，这样两个寄存的内容加起来，这样就是一个有效地址</p>
<figure>
<img src="https://wulc.me/imgs/TransformInstruction.jpg"
alt="Transform Instruction" />
<figcaption aria-hidden="true">Transform Instruction</figcaption>
</figure>
<p>如下如所示是一个程序通过反汇编得到的指令，标红的是就是数据传送指令；实际执行时会从上到下依次执行</p>
<figure>
<img src="https://wulc.me/imgs/Program2Instruction.jpg"
alt="program2instruction" />
<figcaption aria-hidden="true">program2instruction</figcaption>
</figure>
<p>下面以上图中第一条指令即 55 这条指令介绍其执行过程,
这条指令可大概分为 3
个步骤，下面其描述过程，可配合后面的图进一步理解</p>
<ol type="1">
<li>取指令，取指令的过程主要分为下面 3
步（1）控制器把指令地址（即80483d4）写入指令计数器即PC，在 IA-32 中 PC
为
EIP，然后MAR<strong>把指令的地址送到地址线</strong>（2）时控制器会发出一个读命令，<strong>把控制信号送到控制线</strong>上面去，告诉存储器说，我要去读
读这个单元的内容（3）存储器接收到读命令和地址以后，开始进行读
读操作并<strong>把地址里面的内容读到数据线</strong></li>
<li>指令译码，数据线上的指令（即5589e5）读过来，读到 MDR
里面去以后，再把它送到 IR
即指令寄存器里面去译码，而指令寄存器里面的高位，就是op字段，会送到控制器里面进行译码;
译码以后，计算机就知道这条指令的功能是<strong>把
esp(栈指针，用于指向栈的栈顶) 内容减4送到
esp（即入栈，因为栈地址是从高到低增长的）;然后把
ebp(帧指针，指向当前活动记录的底部) 的内容送到 esp
所指向的那个内存单元</strong></li>
<li>指令执行，这一步执行的其实就是根据步骤 2 译码出来的过程，对 esp 减 4
是在 ALU 中完成的（就是从 bfff0000 变为 beeefffc），然后把 ebp 的内容(即
bfff0020)写到 beeefffc 中，原理也跟取指令的过程差不多，MAR 把地址
beeefffc 送到地址线上，同时把写的数据（即 ebp 的内容）写入 MDR 中， MDR
通过数据线把内容传输给存储器；这样当控制器发一个写信号到存储器时，存储器会将数据线的内容写入到存储器中，最后则是将
EIP 加1，继续执行下一条指令</li>
</ol>
<p>下图是上面步骤 1~2 步骤的执行过程和结果</p>
<figure>
<img src="https://wulc.me/imgs/mov_instruction_exec.jpg"
alt="step1-2" />
<figcaption aria-hidden="true">step1-2</figcaption>
</figure>
<p>下图是上面步骤 3 步骤的执行过程和结果</p>
<figure>
<img src="https://wulc.me/imgs/mov_instruction_exec1.jpg" alt="step3" />
<figcaption aria-hidden="true">step3</figcaption>
</figure>
<h3 id="定点运算指令">定点运算指令</h3>
<p>常用的定点运算指令包括下面这些，可以有个大概的认识，这里就不详细展开讲了</p>
<figure>
<img src="https://wulc.me/imgs/fixednum_instruction.jpg"
alt="fixed num" />
<figcaption aria-hidden="true">fixed num</figcaption>
</figure>
<h3 id="逻辑运算指令">逻辑运算指令</h3>
<p>常用的逻辑运算指令包括下面这些，同样地可以有个大概的认识，不详细展开讲了</p>
<figure>
<img src="https://wulc.me/imgs/logic_instruction.jpg"
alt="logic instruction" />
<figcaption aria-hidden="true">logic instruction</figcaption>
</figure>
<h3 id="条件转移指令">条件转移指令</h3>
<p><strong>指令的执行有两种顺序</strong>，一种是按顺序执行，还有一种是跳转到一个转移目标指令处执行，也称为条件转移指令</p>
<p>条件转移指令也可以根据是否要满足条件来跳转分为以下几种</p>
<figure>
<img src="https://wulc.me/imgs/jump_instruction.jpg"
alt="jump instruction" />
<figcaption aria-hidden="true">jump instruction</figcaption>
</figure>
<ul>
<li><strong>无条件转移指令</strong>，比如说jump指令就是无条件地转移到DST所指出的那个目标指令处执行</li>
<li><strong>条件转移指令</strong>，这个指令属于分支指令，可能是按顺序执行，也可能要跳转到转移目标指令处执行；所以在这个指令当中有一些是表示条件的
助记符，如上面的 cc 就是一个条件码，是根据标志
也就是条件标志来判断是否满足条件 如果满足条件就转移到目标指令 DST
处执行，否则就按顺序执行</li>
<li><strong>条件设置指令</strong>， 跟上面的条件转移指令类似的
在指令助记符当中有条件码，如果满足这个条件就把目标寄存器 DST
里面置1，否则是0</li>
<li><strong>调用和返回指令</strong>，就是在函数调用或者过程调用的时候使用的指令，调用指令就是
call 指令 CALL，返回指令就是 return 指令
RET。这两个指令会通过调用函数的地址关联起来，其实就是我们常听到的函数调用时入栈和出栈的操作</li>
<li><strong>中断指令</strong>它也是一种跳转指令，
实际上是<strong>从用户态跳转到了内核态</strong>
详细的信息在后面的章节中介绍</li>
</ul>
<p>在这些条件转移或者条件设置指令
当中有一个非常重要的寄存器就是标志寄存器，如下图所示，这些标志信息
实际上是用来进行判断条件是否满足的一些信息</p>
<figure>
<img src="https://wulc.me/imgs/flag_register.jpg" alt="flag register" />
<figcaption aria-hidden="true">flag register</figcaption>
</figure>
<p>在C语言里面规定，在一个表达式当中
只要有一个变量是无符号数变量，unsigned的，
那么所有的运算都按无符号数进行运算。
所以这边比较的结果按无符号数来比。</p>
<h2 id="小结">小结</h2>
<p>IA-32 是典型的 CISC (复杂指令集计算机) 风格 ISA，前几章提到 ISA
是一种规约，<strong>规定了软件如何使用硬件</strong>，包括指令的集合、寄存器的类型和数量、指令可接受的操作数类型</p>
<p>而 IA-32 复杂的点在于：指令可能会很长
有些字段有可无，操作码和指令是不定长
且每个字段的含义还要有另外一个字段来解释</p>
<p>其特点包括</p>
<ul>
<li>有 8 个通用的寄存器， 并且可以扩展，从8位扩展到16位，到32位</li>
<li>有 2 个专用寄存器：EIP（PC）、标志寄存器（EFLAGS）</li>
<li>有 6
个段寄存器是间接的给出段址（存放的是一个指针，根据这个指针到另外一个地方去取，取出来的就是段基址）</li>
<li>寻址空间是4个GB(存储单元的地址是32位的)</li>
<li>寻址方式有多种
<ul>
<li>立即寻址</li>
<li>寄存器寻址</li>
<li>存储器寻址</li>
<li>相对寻址</li>
</ul></li>
<li>指令和操作码是变长的</li>
</ul>
<p>同时介绍了 IA-32
常用指令类型包括传送指令、运算指令、逻辑指令、条件转移指令等，并且介绍了一些执行结果不符合源程序的例子，其原因往往是类型的默认装换导致了最终生成的指令不同，这一点可以作为程序排查时的一个思路。</p>
]]></content>
      <categories>
        <category>程序的表示、转换与链接</category>
      </categories>
      <tags>
        <tag>程序的表示、转换与链接</tag>
      </tags>
  </entry>
  <entry>
    <title>程序的表示、转换与链接-week7</title>
    <url>/2020/07/04/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week7/</url>
    <content><![CDATA[<p>本文是 <a
href="https://www.coursera.org/learn/jisuanji-xitong/home/welcome">程序的表示、转换与链接</a>
中第 7 周的内容，主要介绍了 C
语言程序中过程调用、也就是函数调用对应的机器级表示，
包括如何传递参数，如何将控制转移到被调用过程，
寄存器使用约定，递归函数的实现等等。
通过了解这些内容，能够更清楚机器执行的详细过程，同时也能更清楚函数调用过程中栈空间是如何变化的；课程选用的指令系统是前面介绍过的IA-32指令系统。</p>
<span id="more"></span>
<h2 id="过程调用概述">过程调用概述</h2>
<p>如下是一个简单的例子，通过这个例子主要阐述 3 个问题</p>
<ul>
<li>过程调用的机器级代码是什么</li>
<li>参数怎么传递到 <code>add</code> 函数中</li>
<li><code>add</code> 的结果是如何返回给调用过程的</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x+y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> t1=<span class="number">125</span>;</span><br><span class="line">    <span class="type">int</span> t2=<span class="number">80</span>;</span><br><span class="line">    <span class="type">int</span> sum=add(t1, t2);</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于第一个问题和第三个问题，当 <code>main</code> 中调用
<code>add</code> 函数时，实际上是通过 call 指令实现的，<strong>call
指令会把返回地址，也就是call指令下一条指令的地址放到栈里面</strong>，这样的话在
<code>add</code> 函数最后执行 return
指令的时候，可以从栈里面取出这个返回地址使得它能够正确的返回到main执行。</p>
<p>关于第二个问题，参数是通过栈传递的，即在调用的时候会把参数压栈，如下所示是进程的虚拟地址(也叫)空间分布的情况，其中<strong>栈是从高地址往低地址增长的，指向栈顶的指针也叫
ESP 指针</strong></p>
<figure>
<img src="https://wulc.me/imgs/exec2virtualaddress.jpg"
alt="exec2virtualaddress" />
<figcaption aria-hidden="true">exec2virtualaddress</figcaption>
</figure>
<p>如下图所示是过程调用的机器级表示，调用的函数执行的是 P
过程，被调用的函数执行的是 Q 过程；P
过程做的事情主要是把参数和返回地址压栈，Q
过程做的则是保存现场、执行被调用函数，恢复现场并返回调用函数；其中<strong>现场指的是共享的通用寄存器</strong>，因为是共享的，因此被
Q 使用时需要先保存 P 之前在上面的值，后面再恢复</p>
<figure>
<img src="https://wulc.me/imgs/procedure_call_process.jpg"
alt="过程调用机器执行过程" />
<figcaption aria-hidden="true">过程调用机器执行过程</figcaption>
</figure>
<p>前面提到因为过程 P 和 Q
共享通用寄存器，因此需要保存和恢复现场，实际上这<strong>只是针对部分的寄存器</strong>，在
IA-32 中的具体约定如下：</p>
<ul>
<li>EAX、EDX 和 ECX
是<strong>调用者保存</strong>的寄存器(必要时)，被调用者不需要先保存再使用</li>
<li>EBX、ESI 和 EDI
是<strong>被调用者保存</strong>的寄存器(必要时)，被调用者需要先保存在使用</li>
</ul>
<p>因此，<strong>为了减少准备和结束阶段的开销，每个过程应该优先使用
EAX、EDX 和 ECX 这几个寄存器</strong></p>
<p>由于 IA-32 共有 8 个寄存器，剩下的两个 <strong>EBP 和 ESP
是帧指寄存器和栈指寄存器，分别用来指向当前栈帧的底部和顶部</strong></p>
<p>因此，过程 P 调用过程 Q 时栈和栈帧的变化如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/stackAndStackFrame.jpg"
alt="stackAndStackFrame" />
<figcaption aria-hidden="true">stackAndStackFrame</figcaption>
</figure>
<p>上面简单介绍了过程调用的一些基本操作，下图则是基于上面的例子更详细地描述其对应的汇编指令和栈的变化</p>
<figure>
<img src="https://wulc.me/imgs/procedure_example.jpg"
alt="procedure example" />
<figcaption aria-hidden="true">procedure example</figcaption>
</figure>
<p>caller
这个函数对应的指令序列如上图所示，指令对应的基本操作在图中已经描述的比较清楚了，在这里着重讲指令序列中前三条指令，<strong>前三条指令是准备阶段，
做的事情是保存P的现场，并且形成新的栈帧</strong>，这三条指令的执行过程如下所示</p>
<p>第一条 pushl 指令：把老的 EBP 的值压栈，在这条指令执行完后，栈顶指针
ESP 也会自动指向这个地方 第二条 movl 指令：<strong>把当前的 ESP 赋给了个
EBP, 相当于是栈底的形成</strong> 第三条 subl 指令：会把 ESP 减去
24(相当于用了 24 个字节来存储在 caller 中的变量、参数等)</p>
<p>而在被调用的 add 函数中最开始的两条指令其实也是上面的 pushl 和
movl，起作用便是形成栈底</p>
<p>最后的 <strong>leave 指令实际上是退栈，其操作是把 EBP
的内容送到ESP</strong>，相当于是把栈里面所有的空间释放掉了</p>
<p>此外，汇编指令中一些符号含义如下</p>
<ul>
<li>前加 <code>$</code> 符号的表示这是一个立即数，如第四条指令的
<code>$125</code></li>
<li><code>-8(%ebp)</code> 表示 EBP 的地址减去 8
个字节后<strong>所在地址里存的值</strong></li>
<li><code>(%ecx)</code> 表示 ECX 寄存器存的地址对应的值</li>
</ul>
<p>因此，一个 C 过程的大致结构如下</p>
<figure>
<img src="https://wulc.me/imgs/procedure_summary.jpeg" alt="summary" />
<figcaption aria-hidden="true">summary</figcaption>
</figure>
<h2 id="过程调用的参数传递">过程调用的参数传递</h2>
<p>这里讲了一个比较经典的例子，就是按地址传参和按值传参带来的会带来不同结果，其中的原因就是这两种方式最终对应的机器指令是不一样的</p>
<figure>
<img src="https://wulc.me/imgs/swap_compare.jpg" alt="swap compare" />
<figcaption aria-hidden="true">swap compare</figcaption>
</figure>
<p>下面是上面分别按地址传递和按照参数传递对应的汇编指令，从中可知，两者的一些关键区别有</p>
<ul>
<li><strong>按地址传递时被压栈的是参数的地址而不是参数本身(使用 leal
指令)，按参数传递时被压栈的是参数本身（使用 movl 指令）</strong></li>
<li>按地址传递时会通过寄存器 ebx 和 ecx
暂时存储两个参数的值，然后把参数赋值给存储着这两个参数地址的寄存器 eax
和 ebx 中，一共用了 4 个寄存器；而按值传递参数时，则只用了 2
个寄存器，只是对入口的参数进行交换</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/swap_address_val.jpg"
alt="swap address" />
<figcaption aria-hidden="true">swap address</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/swap_value_val.jpg" alt="swap val" />
<figcaption aria-hidden="true">swap val</figcaption>
</figure>
<h2 id="递归过程调用">递归过程调用</h2>
<p>下图是一个简单的递归过程对应的机器指令，假定这个过程是通过P调用的</p>
<figure>
<img src="https://wulc.me/imgs/recursive_call_compilation_code.jpg"
alt="recursive compile code" />
<figcaption aria-hidden="true">recursive compile code</figcaption>
</figure>
<p>从上图中可知</p>
<ul>
<li>在递归过程中，栈帧是一个个累积叠加生成的</li>
<li>在递归过程当中用到了被调用者保存的寄存器
ebx，起作用是保护调用过程的现场</li>
<li>ebp 加 8 即<code>8(%ebp)</code>是第一个参数的地址</li>
<li>eax 中存储着返回值</li>
<li>cmpl 和 jle 指令是用来表示上面的条件比较部分的，如果满足条件就会跳到
L2
执行退栈等清理工作；如果不满足，则会递归地执行入栈、生成新的栈帧的操作等</li>
<li>addl 指令会在递归返回后一次执行累加操作得到最终结果</li>
</ul>
<p>因此，递归过程的总体执行流程如下</p>
<figure>
<img src="https://wulc.me/imgs/recursive_call.jpg" alt="recursive" />
<figcaption aria-hidden="true">recursive</figcaption>
</figure>
<p>递归调用中有很多额外的开销，这种额外的开销体现在</p>
<ul>
<li><strong>空间</strong>：每递归调用一次都会形成一个新的栈帧，如果递归深度很大，栈帧的个数也变大，导致占用的栈的空间越来越多，最终引起栈溢出</li>
<li><strong>时间</strong>：每递归调用一次，都需要额外执行一些指令用于生成新的栈帧、进行参数压栈等等
而这些<strong>准备阶段以及恢复阶段的额外的指令</strong>的执行都需要花时间</li>
</ul>
<p>因此，正常情况下如果能够不用递归，尽量不要用递归，因为它在空间上面和时间上面都会增加很多额外的开销</p>
<h2 id="选择结构的机器级指令">选择结构的机器级指令</h2>
<p>if-else, 用了条件转移指令 jbe 和无条件转移指令 jmp</p>
<figure>
<img src="https://wulc.me/imgs/if_else_compilation_code.jpg"
alt="if-else" />
<figcaption aria-hidden="true">if-else</figcaption>
</figure>
<p>switch-case 语句有一张跳转表, 即下图中的 L8，
其跳转到的目标实际上是通过基址加比例变址加位移量的方式来找到的。这个跳转表实际上是在在后面讲到的目标文件中(可重定位目标文件或者是可执行目标文件)。
在这些文件当中都有相应的一个段，叫只读数据节，rodata。</p>
<figure>
<img src="https://wulc.me/imgs/switch_compilation.jpg"
alt="swithc compilation" />
<figcaption aria-hidden="true">swithc compilation</figcaption>
</figure>
<h2 id="循环结构的机器级指令">循环结构的机器级指令</h2>
<p>循环结构的逻辑及其机器级表示如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/cycle_structure.jpg"
alt="cycle structure" />
<figcaption aria-hidden="true">cycle structure</figcaption>
</figure>
<p>下面是 for
循环语句的机器代码及其分析，其他循环结构的机器指令结构类似，从中可知，实现同样功能，循环比起递归要节省时间和空间，因此优先使用循环方式去实现</p>
<figure>
<img src="https://wulc.me/imgs/for_compilation.jpg"
alt="for compilation" />
<figcaption aria-hidden="true">for compilation</figcaption>
</figure>
<h2 id="小结">小结</h2>
<p>这一章主要介绍了C
语言中常见的过程调用、递归调用、选择语句、循环语句等对应的机器级指令和具体的执行过程，通过了解这些语句的具体执行过程，能够更清楚计算机在执行时栈内存是如何分配的，以及为什么通过循环来实现相同功能时比递归更节省资源</p>
]]></content>
      <categories>
        <category>程序的表示、转换与链接</category>
      </categories>
      <tags>
        <tag>程序的表示、转换与链接</tag>
      </tags>
  </entry>
  <entry>
    <title>维特比算法</title>
    <url>/2017/03/02/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>维特比算法（Viterbi
algorithm）是在一个用途非常广的算法，本科学通信的时候已经听过这个算法，最近在看
<a
href="https://en.wikipedia.org/wiki/Hidden_Markov_model">HMM</a>（Hidden
Markov model）
的时候也看到了这个算法。于是决定研究一下这个算法的原理及其具体实现，如果了解动态规划的同学应该很容易了解维特比算法，因为维特比算法的核心就是动态规划。</p>
<span id="more"></span>
<p>对于 HMM
而言，其中一个重要的任务就是要找出最有可能产生其观测序列的隐含序列。一般来说，HMM问题可由下面五个元素描述</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">观测序列（observations）：实际观测到的现象序列</span><br><span class="line">隐含状态（states）：所有的可能的隐含状态</span><br><span class="line">初始概率（start_probability）：每个隐含状态的初始概率</span><br><span class="line">转移概率（transition_probability）：从一个隐含状态转移到另一个隐含状态的概率</span><br><span class="line">发射概率（emission_probability）：某种隐含状态产生某种观测现象的概率</span><br></pre></td></tr></table></figure>
<p>下面以<a
href="https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95">维基百科</a>上的具体例子来说明
&gt;想象一个乡村诊所。村民有着非常理想化的特性，要么健康要么发烧。他们只有问诊所的医生的才能知道是否发烧。
聪明的医生通过询问病人的感觉诊断他们是否发烧。村民只回答他们感觉正常、头晕或冷。
假设一个病人每天来到诊所并告诉医生他的感觉。医生相信病人的健康状况如同一个离散马尔可夫链。病人的状态有两种“健康”和“发烧”，但医生不能直接观察到，这意味着状态对他是“隐含”的。每天病人会告诉医生自己有以下几种由他的健康状态决定的感觉的一种：正常、冷或头晕。这些是观察结果。
整个系统为一个隐马尔可夫模型(HMM)。
医生知道村民的总体健康状况，还知道发烧和没发烧的病人通常会抱怨什么症状。
换句话说，医生知道隐马尔可夫模型的参数。则这些上面提到的五个元素表示如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">states = (<span class="string">&#x27;Healthy&#x27;</span>, <span class="string">&#x27;Fever&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">observations = (<span class="string">&#x27;normal&#x27;</span>, <span class="string">&#x27;cold&#x27;</span>, <span class="string">&#x27;dizzy&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">start_probability = &#123;<span class="string">&#x27;Healthy&#x27;</span>: <span class="number">0.6</span>, <span class="string">&#x27;Fever&#x27;</span>: <span class="number">0.4</span>&#125;</span><br><span class="line"> </span><br><span class="line">transition_probability = &#123;</span><br><span class="line">   <span class="string">&#x27;Healthy&#x27;</span> : &#123;<span class="string">&#x27;Healthy&#x27;</span>: <span class="number">0.7</span>, <span class="string">&#x27;Fever&#x27;</span>: <span class="number">0.3</span>&#125;,</span><br><span class="line">   <span class="string">&#x27;Fever&#x27;</span> : &#123;<span class="string">&#x27;Healthy&#x27;</span>: <span class="number">0.4</span>, <span class="string">&#x27;Fever&#x27;</span>: <span class="number">0.6</span>&#125;,</span><br><span class="line">   &#125;</span><br><span class="line"> </span><br><span class="line">emission_probability = &#123;</span><br><span class="line">   <span class="string">&#x27;Healthy&#x27;</span> : &#123;<span class="string">&#x27;normal&#x27;</span>: <span class="number">0.5</span>, <span class="string">&#x27;cold&#x27;</span>: <span class="number">0.4</span>, <span class="string">&#x27;dizzy&#x27;</span>: <span class="number">0.1</span>&#125;,</span><br><span class="line">   <span class="string">&#x27;Fever&#x27;</span> : &#123;<span class="string">&#x27;normal&#x27;</span>: <span class="number">0.1</span>, <span class="string">&#x27;cold&#x27;</span>: <span class="number">0.3</span>, <span class="string">&#x27;dizzy&#x27;</span>: <span class="number">0.6</span>&#125;,</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>其对应的状态转移图如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bcm8p9sv1jgsn7pgdigu7im.png"
alt="状态转移图" />
<figcaption aria-hidden="true">状态转移图</figcaption>
</figure>
<p>现在的问题是假设病人连续三天看医生，医生发现第一天他感觉正常，第二天感觉冷，第三天感觉头晕。
于是医生产生了一个问题：怎样的健康状态序列最能够解释这些观察结果。维特比算法解答了这个问题。</p>
<p>首先直观地看这个问题，在HMM中，一个观测现象后面的对应的各个状态都有一个概率值，我们只需要选择概率值最大的那个状态即可，但是这个概率值是跟前面一个状态有关的（马尔科夫假设），因此不能独立考虑每个观测现象。</p>
<p>为了从时间复杂度方面进行比较，现在将问题一般化：假设观测序列的长度为
m，隐含状态个数为
n。则有下面的隐含状态转移图（下图为了便于表示，将只画出n = 3
的图）。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bcm8uuhtr41apimam1sml1t4613.png"
alt="Viterbi 算法的状态图" />
<figcaption aria-hidden="true">Viterbi 算法的状态图</figcaption>
</figure>
<p>假如采用穷举法，穷举出所有可能的状态序列再比较他们的概率值，则时间复杂度是
<span class="math inline">\(O(n^m)\)</span>,
显然这样的时间复杂度是无法接受的，而通过维特比算法能把时间复杂度降到
<span class="math inline">\(O(m*n^2)\)</span></p>
<p>从动态规划的问题去考虑这个问题，根据上图的定义，<strong>记
<code>last_state</code>
为上一个观测现象对应的各个隐含状态的概率，<code>curr_state</code>
为现在的观测现象对应的各个隐含状态的概率。则求解<code>curr_state</code>实际上只依赖于<code>last_state</code></strong>。而他们的依赖关系可通过下面的
python 代码表示出来</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> cs <span class="keyword">in</span> states:</span><br><span class="line">    curr_state[cs] = <span class="built_in">max</span>(last_state[ls] * </span><br><span class="line">                         transition_probability[ls][cs] *             </span><br><span class="line">                         emission_probability[cs][observation] </span><br><span class="line">                         <span class="keyword">for</span> ls <span class="keyword">in</span> states) </span><br></pre></td></tr></table></figure>
<p>计算过程利用了转移概率 <code>transition_probability</code> 和发射概率
<code>emission_probability</code>，选出那个最有可能产生当前状态
<code>cs</code> 的上一状态 <code>ls</code>。</p>
<p>除了上面的计算，同时<strong>要为每个隐含状态维护一个路径
<code>path</code>， <code>path[s]</code> 表示到达状态 <code>s</code>
前的最优状态序列。通过前面的计算选出那个最有可能产生当前状态
<code>cs</code> 的上一状态 <code>ls</code>后，往<code>path[cs]</code>
中插入 <code>ls</code>
。则依照这种方法遍历完所有的观测序列后，只需要选择
<code>curr_state</code> 中概率值最大的那个 <code>state</code>
作为最终的隐含状态，同时从 path 中取出 <code>path[state]</code>
作为该最终隐含状态前面的状态序列。</strong></p>
<p>从上面的分析可知，观测序列只需要遍历一遍，时间复杂度为 <span
class="math inline">\(O(m)\)</span>，而每次要计算当前各个状态最可能的前一状态，时间复杂度为
<span class="math inline">\(O(n^2)\)</span>,因此总体的时间复杂度为 <span
class="math inline">\(O(m*n^2)\)</span>.</p>
<p>假如在 NLP 中应用
HMM，则将词序列看做是观测到的现象，而词性、标签等信息看做是隐含状态，那么就可以通过维特比算法求解其隐含状态序列，而这也是
HMM
在分词，词性标注，命名实体识别中的应用。其关键往往是找出上面提到的初始概率（<code>start_probability</code>）、转移概率（<code>transition_probability</code>）、发射概率（<code>emission_probability</code>）。</p>
<p>而在通信领域中，假如将收到的编码信息看作是观测序列，对应的解码信息为隐含状态，那么通过维特比算法也能够找出概率最大的解码信息。</p>
<p>需要注意的是维特比算法适用于多步骤多选择的最优问题，类似于下面的网络，《数学之美》中将其叫做“篱笆网络(Lattice)”。每一步都有多个选择，并且保留了前面一步各个选择的最优解，通过回溯的方法找到最优选择路径。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bcn1c6fd1hcbiq49ch1no21bsv9.png"
alt="篱笆网络" />
<figcaption aria-hidden="true">篱笆网络</figcaption>
</figure>
<p>这里要强调的是 viterbi 算法可以用于解决 HMM
问题，但是也可以用于解决其他符合上面描述的问题。</p>
<p>最后，上文中的完整的代码见<a
href="https://github.com/WuLC/MachineLearningAlgorithm/blob/master/python/Viterbi.py">这里</a></p>
<hr />
<p>参考： <a
href="https://zh.wikipedia.org/wiki/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95">维特比算法</a></p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊管理</title>
    <url>/2022/09/25/%E8%81%8A%E8%81%8A%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>管理，似乎是职场人无法回避的一个话题，因为随着组织的庞大，由于沟通、分工、人员参差不齐等问题，人效不可避免地下降，管理就是在缓解人员数量增加而带来的边际收益递减问题。而无论是管理者还是被管理者，笔者觉得都有必要去了解一下管理的相关内容，才能更好地扮演自己在职场中的角色</p>
<p>在这个话题下，有着不同的派系和理论，每一种看起来都讳莫如深；但是回到管理的本质，就是如何高效地组织一群人去完成一个任务，并且是长期可持续的</p>
<p>虽入职场时间不长，也有一些谈不上正式的管理经历，同时有幸从接触到的多位直属
leader
身上、从与一些前辈的谈话中，都获得了不少的启发和指导，自己也在这个问题上做了一些简单的调研，一直想对这部分做个总结，于是就有了这篇文章</p>
<p>文章主要是笔者的一些经历以及对管理的简单认知，样本必然是有偏的，未必在所有场景下都适用，文章可能会比较发散，祝开卷有益</p>
<span id="more"></span>
<h2 id="身边的那些管理者">身边的那些管理者</h2>
<p>在笔者当前有限的职业经历中，有几位给笔者留下较为深刻印象的的老板，下面会简单讲一讲他们的故事，以及笔者从中学到的一些东西</p>
<h3 id="能力是出众的态度是谦和的">能力是出众的，态度是谦和的</h3>
<p>一般从 IC(Individual Contributor)
到管理者的角色的转变，都是做了一些比较成功的项目；而这也意味着管理者的业务能力一般是会比较强的，从笔者的经历来看，也的确如此</p>
<p>在笔者接触到的大老板里，都有这样的特性：他们的能力是出众的，态度是谦和的（这里的能力更多的是指业务能力）</p>
<p>在这一点上，Z 老板给笔者留下的印象最深，也是笔者尤为佩服的一点，Z
老板是那种工作了好多年，但是仍然保留着对技术与业务的热情和好奇心的老板，就是那种如同<strong>刚毕业的年轻人对新鲜的职场的热情与好奇心</strong></p>
<p>Z
老板是笔者毕业进厂时就认识的老板，当年刚毕业的时候觉得这种状态很正常，但是工作了几年后，似乎在经历着职场的
Burnout(关于 Burnout，<a
href="https://www.xiaoyuzhoufm.com/episode/62036d09c18c718fa5d0076b">永不停止的列车</a>)
时，才意识到这一点的可贵之处，尤其是 Z
老板的经历如同做过山车一般，即使在所谓的底部，也是依然保留着这种热情不变，respect~</p>
<p>也许也是因为这一点，Z
老板能够一直保持这对业务的敏感性，能够很好地判断出业务上各类事情的优先级，也能在各种讨论会中提出很多
IC 也没有考虑到问题</p>
<p>此外，笔者接触过的老板，对人的态度都是很谦和的，或者说是比较“真”的；这一点
Z
老板留下的印象也是尤为深刻，当你有问题或者说需要做出职场上的选择去找他时，他会站在你的角度，考虑你总体的利益，给你很多中肯的建议，哪怕这些建议对他来说并不是利益最大化的；<strong>换位思考的确是一种技巧，但是如果能够知行合一且长期地身体力行，在笔者看来就是一种难能可贵的“真”</strong></p>
<p>这一点在 D 老板身上也是如此，我跟 D
老板是两条线的，没有直接或间接的汇报关系，但是今年面临一些选择去找他时，他还是很客观地给我提供了非常多的有效信息和建议，这里也实名感谢匿名的
D 老板，respect~</p>
<p>而<strong>或许保持一种“真”，在漫长的职业生涯中，才会有真正愿意长期追随你的人</strong>；因为员工也不傻，当你是真的站在他的利益角度上为他考虑问题，考虑如何培养他、为他争取应有的利益时，他也是会怀着感激之心愿意跟随着你去打仗的</p>
<p>而假装强大，只会吸引那些来依附你的人，而不是能跟你一起打仗的人，这不是威信，这是一种负担。<strong>坦诚会让管理变得没那么累，对下属坦诚，也让下属对自己坦诚</strong></p>
<p>见证着 Z 老板经历过的起起落落，如果从功利的角度或者说业务的 scope
大小，现在 Z 老板似乎在底部，但是笔者是很相信均值回归的，相信 Z
老板肯定会回归到他应属 scope 那一天~</p>
<h3 id="边界需要清晰才会有-owner-意识">边界需要清晰，才会有 owner
意识</h3>
<p>一些厂常提到的不设边界，但同时又要有 owner
意识的理念，似乎跟上面是很矛盾的，但两者解析的角度不太一样，不设边界这个理念笔者觉得对个人更适用：即<strong>个人不应该局限于本质工作，而是去多了解其他人、其他团队工作，更好地融会贯通，同时需要对自己手上的工作有
owner 意识</strong></p>
<p>而笔者这里提的“边界需要清晰，才会有 owner
意识”则是在团队角度去考虑的：即<strong>需要把团队工作清楚划分到具体的人上，才能让每个人都有
owner 意识</strong>。这一点，笔者在过去一年里感悟尤为深刻</p>
<p>这里不得不介绍 J 老板，J
老板也是上面说的那种能力出众、态度谦和的老板，而令我印象深刻的是 J
老板可以说是手把手教了我很多管理上的知识</p>
<p>在 J
老板正式接收我所在的小团队前，团队内的分工可以说是惨不忍睹，每个人同时参与着
4、5 个项目，但是每个项目又没有明确的负责人，导致的后果就是每个方向的
roadmap 都不明确、每个方向下关键的 action
也没有厘清楚，人效很低，团队里的很多同学的士气也比较低落（后来跟 J
老板的沟通中才发现，这是由于团队里较多初入职场的员工且缺少成就感）</p>
<p>而 J
老板过来后，做的第一件是就是把这个小团队的方向划分清楚成几个重点的业务方向，并且为每个方向指定一个较为资深的同学作为
owner，每个 owner 下有几个新同学（PS,
现在回头看，这个策略也许并不普适，比如说面对着都是资深的同学；但也许是当时的团队组织中最好的策略）</p>
<p>作为其中一个方向的 owner，我也依葫芦画瓢，把这个方向的
roadmap、重点的子方向梳理并划分清楚，分配到具体的新同学上，同时作为陪练的角色，指导每位同学去解决各个子方向上遇到的卡点问题等</p>
<p>在这个过程中，遇到的另一个有意思的问题，就是在何种情况下需要 “get
hands
dirty”，一开始看到很多事情，笔者都会忍不住想上手去做，因为的确觉得短期内会让事情推进更快；但现在回看，这样的弊端也会很明显，一是下面的同学得不到锻炼，二是这其实是一个“老黄牛”类型的伪中层（这部分会在下面介绍），会把自己搞得很累，团队也得不到发展；而
J
老板在这个过程中跟我说过、现在仍然印象深刻的一个观点是：<strong>要长期培养有战斗力的团队，需要让每个成员成长，让每个成员有成就感</strong></p>
<p>这个过程往往会存在一个<strong>事和人的权衡</strong>，或者说业务产出和培养成员的权衡，业务产出是能比较好去量化的，但是培养成员的产出就不太好去衡量。最理想的状态下把团队成员在进步，同时把业务完成得更好，但这往往需要更多时间与上级的耐心。在实际中，需要考虑的更实际的问题是：<strong>短期内需要保证业务产出到何种程度，长期又应该如何建设好团队，是一个以业务产出为约束，最大化团队长期发展的优化问题</strong>，这个问题没有标准答案，只能说是不同业务、发展规模、团队规模下可能的最优解都是不同的</p>
<p>经过半年这样的安排，总体的业务收入增长了 1.5
倍，同时每位同学都有相应产出，部分同学也在 one one
反馈中与笔者透露过这种安排让他更明确了自己的任务，并在完成了这个项目的一些
milestone 后，有信心迎接更大的挑战了，而在这之前，这位同学差点就要被 pip
了。这样的结果，印证了 J
老板的方法的正确性，也从某个角度说明了管理对于挖掘个人潜能的重要性</p>
<p>虽然跟着 J
老板的时间并不长，但是从他身上学习到了很多，无论是管理还是技术，也是非常感谢
J 老板几乎是手把手教会了我这些管理的基本知识~</p>
<h3
id="明确团队定位组建有凝聚力的团队">明确团队定位，组建有凝聚力的团队</h3>
<p>业务的迅速发展不免会导致组织的频繁调整，而在这个过程也让我有机会看到了
G 老板到一个新团队的 landing 的过程</p>
<p>G 老板首先以项目维度，与-1、-2组织了多次会议，来 review
当前组里进行的绝大多数项目，同时判断其合理性，笔者觉得这个过程挺好的，首先让
G 老板能同时了解团队已有的项目和人员情况</p>
<p>而判断项目合理性的一个重要依据是当前团队定位，即我们当前团队做这个事情是否合理<strong>，如果这个事情已经有其他团队在做，我们参与到其中是否符合团队长期的定位，是否有一些事情是团队应该做但是没有做的</strong>？这种方式笔者理解是站在整个大团队的视角去考虑最优的解决问题的方法，需要较好的业务理解能力、扛得住一些短期的压力以及魄力；同时也让笔者第一次意识到，想象中的所谓组与组中间的“卷”、“抢地盘”等现象，其实并不会发生在所有的公司和团队里~respect</p>
<p>通过这种方式，G 老板最终 close 了一些跟其他团队 overlap
比较严重且定位不太符合团队的项目，同时通过与团队配合比较紧密的销售团队的沟通，也新立项了一些项目。重新调整后，组里做的事情，虽然看起来不是并不是那么高大上，但是更符合了团队的定位；虽有被调整的同学体感可能会有些不舒服，但如果
YY 一下，站在 G 老板的+1
的角度，相信对这次的调整应该也是满意的，毕竟站在 G 老板的+1
并不会希望看到团队下的所有同学都去卷同一个方向比如说
ranking，而是需要尽可能保持各司其职，避免一些“脏活累活”没人干</p>
<p>G 老板做的第二件事，就是组建组里的核心团队(比较常见的就是 XX-core
团队)，主要是 G 老板的 -1 以及一些核心项目里的 -2
同学。令笔者印象比较深刻的有几件事，一是 G
老板愿意主动授人以渔，会给他的 -1
赠送过一些管理上的相关书籍，并且非常真诚地说了这本书对他的其他很大；二是还会跟
-2 的一些同学定期
one-one，聊业务、团队发展、职业发展等问题（说实话这是笔者第一次跟 +2
的老板的定期 one
one）；三是对组里的核心团队，会定期进行面试等培训，统一面试的标准（这个在招聘还是挺重要的，如果不对齐标准，面试里就很容易出现类似
ranking 中的召回与精排不一致等问题），同时亲力亲为组织核心团队的一些
tb</p>
<p>通过这一系列的动作，至少在笔者的体感上，团队是更有凝聚力了，因为对于比较大的团队，上面的老板肯定无法亲自去了解每个人、把控每个项目的方向；而
G
老板的做法就是在<strong>大面上明确了整个团队的定位，同时把一小部分的同学组建为核心团队，把一些理念传递给这些同学，让这些同学去把控各个子方向</strong>；避免了放养式的管理导致团队方向不明确，在兼顾了手下同学的体感，愿意放权；或许这就是管理所希望达到的目标吧</p>
<p>因为业务调整等原因，与 G
老板的汇报线只持续了大半年；但是在这大半年里，因为跟 G
老板坐得比较近，从 G 老板身上看到了一个高阶的管理者的 landing
过程，也看到了成熟的谈吐和处理问题的方式，更从与他的 one one
中学习到了很多，回想这段经历，还是非常感谢 G 老板的</p>
<h3 id="坚持做长期正确的事情">坚持做长期正确的事情</h3>
<p>坚持做长期正确的事情，是一句政治正确、但在实际执行中往往会因为各种约束而变形的话</p>
<p>在这点一上，给笔者留下比较深刻印象的是 H 老板；H
老板不算非常高阶的管理者，但是还是较好地践行了这一点，且最终证明了其价值的；这一点需要很强的业务判断能力，以及能顶住压力来拍板的魄力</p>
<p>之前 H
老板接手的一个项目，老大不太看好，曾负责过的相关同学也不愿意继续去做，但
H
老板从业务角度出发，觉得这个方向还是有价值的，于是还是坚持投入了人力去做了这个事情，最终产品还是做起来了</p>
<p>后来跟 H 老板沟通过程中，H
老板告诉了我他坚持做这件事情的原因，或者说怎么去判断要做的这个产品是否有价值（主要是广告主侧的产品）；H
老板给出的答案是能否真的能够给客户带来价值（非常官方但是正确的一句话），如提升了投放效率、或者提高了
roi（即使短期的的消耗是掉的，但长期来看随着 roi
的提升客户会增加预算，也正对应了他之前做的一个业务）等；而<strong>这样的结论了其实是真正把广告主当合作伙伴，并站在他们的角度去考虑他们的真实利益，才能有的一些思考</strong></p>
<p>另外，H
老板给我留下的另一个比较印象深刻的点是敢拍板，也看过隔壁的某个团队老大在很多事情上都唯唯诺诺，一直不敢拍板或给结论，之前不理解，知道看到这个故事才懂：<a
href="https://m.okjike.com/originalPosts/62a9a3cb42f7aac7b1237734">为什么不靠谱的管理者能稳如泰山</a>,
因为<strong>敢拍板意味着对自己的决定有充分的认知和信心，因为如果真的出了问题需要扛得住</strong></p>
<blockquote>
<p>往上爬需要领导的信任和至少看起来好看的成绩；但是要想不掉下来，关键是<strong>不犯错、学会免责</strong>，让错误决策都归因不到自己头上去</p>
<p>为什么有时候，我会遇到某些管理者，碰到重大决策时一定先开会。<strong>会上他把本该由他做出的决策丢给大家。这个时候态度很谦卑：“我也左右为难，需要大家建议</strong>。”</p>
<p>然后不管你给他什么建议，他都说出好多问题。为的其实就是把这些问题留在会议纪要里。为的也是这个重大决策一旦失败，是“大家一起做的，不是我一个人做的”，可以不用担责。</p>
<p>这样带来的好处是他个人的，他就像个泥鳅，你觉得他有问题、想找到到底是什么问题时，发现他滑不留手。</p>
<p><strong>这样带来的问题是什么呢？如果10个人一起讨论，必须要所有人都达成一致才能决策。那最后，大概率决策的质量是这10个人中最蠢的人所能理解的决策的质量。</strong>为什么很多影响我们生活的决策，看起来总是让人忍不住吐槽。因为参与决策的人们需要免责。</p>
<p>如果你在工作中，遇到这样的管理者——越是重大决策，越要开会讨论，而且在会上总在唱反调，就是不做出自己的选择。
就要小心了，这是个为了自保，不惜坑害业务和其他团队的人。</p>
</blockquote>
<p>当然，<strong>做长期正确的事情，哪怕短期有损失，这样肯定会有压力，这个时候往往需要跟老板的信任感</strong>，而信任感的建立，往往是在一起打过几次胜战</p>
<h2 id="打造好团队这个产品">打造好团队这个产品</h2>
<p>如果我们把团队也当做一个产品，那作为管理者需要考虑的问题，就是如何设计好这个产品。</p>
<p>设计好这个产品，需要清楚产品演进的过程，需要产品的执剑人在清楚意识到自己在这个过程需要扮演的角色，以及需要执行的动作</p>
<p>衡量这个产品的效果，则是整个团队是否能打，你的团队成员（用户）是否了解且认可这个产品的，当一个新的成员加入你的团队的时候，他是否清楚整个团队的职责，他负责的任务以及考核的目标等。</p>
<h3 id="从-ic-到管理者">从 IC 到管理者</h3>
<p>一般 IC 被提拔为管理者，都是因为其较为出众的业务能力，而从 IC
到管理者的过程往往过程如下</p>
<ol type="1">
<li><strong>短期要为了结果服务</strong>，不能让结果掉链子，这个过程往往是
IC 来主导，然后几个新人跟着来做</li>
<li>中期慢慢的是新人做 IC 看、新人说 IC
听，慢慢的要从一个尖兵般的特种部队的队长，变成一个真正是通过你的队员都变成合格的特种队员</li>
<li>最后才是你彻底形成了一个管理者，更多的是理清一些<strong>事务制度、流程机制</strong>等等。然后你管的部分你减少了，因为他们都成熟了，然后也代表你变成一个成熟的管理者，能够
cover 更多的人了。就<strong>再给你来 10
个人，你这套东西你也知道有节奏有理念，给你时间你都能盯得起来</strong></li>
</ol>
<p>而作为管理者，尤其是中后期阶段的管理者，需要<strong>确认自己比下属“闲”</strong>：先让下属忙起来，确保业务正常(图生存)；管理者要闲下来思考解决更大、更长远的问题(谋发展)；因为作为一个球队的队长，最主要的职责不是进球，而是带领团队进球，需要分辨哪些是必须自己做的事</p>
<p>套用一个比喻：如果你原来是一条鱼，成为管理者后你需要做的不是成为一条大鱼；而是要蜕变成鸟，得飞起来，否则，按照原来的方式，活多了会累死你。所以<strong>成为管理者，不是从做一件事，到多做一件事，而是完全换一种方式去做事</strong>；</p>
<h3 id="招人">招人</h3>
<p>成为管理者，常常需要肩负起的任务是招人</p>
<p>首先需要清楚，为什么要招人？一定是<strong>从业务出发，即业务现在因为要做哪些事情，所以需要有什么样的团队的成员来一起做</strong></p>
<p>既然招什么样的人，取决于这个公司做什么样的业务，那就不一定说有经验的比年轻的更好，有的时候也会有所谓的资源陷阱或者经验陷阱，这就涉及到了招聘时的年龄限制的问题</p>
<p>虽然整个社会都有所谓的 35 岁焦虑或 35
岁危机，但这里面最重要的是<strong>心态是否足够年轻</strong>，就是这个候选人是否有足够的热情和好奇心；只要是持续迭代，持续成长的人，年龄会显得不那么重要，当然前提是能力要匹配你的岗位</p>
<p>另外，在团队要扩张之前，一定要想明白<strong>怎么用最小的资源去验证这件事情是不是正确的</strong>。人越多一定是信息的流通变慢，而且会有信息的扭曲。这就好比在产品设计之初通过
mvp 版本去初步验证这个事情的收益和可能的局限</p>
<p>除了招人，还要培养人（这里的人更多是指团队下属），需要记住一点是需要影响人，而不是控制人，管理者需要有<strong>成就他人的心态</strong>，即你不再是为自己负责，而是为整个团队，为团队里的每个同学，一定要打从心里希望看到自己的同学能够成长，能够晋升；因为管理是通过别人拿结果，需要记住功劳都是团队里实打实干活的同学的</p>
<h3 id="围绕着事而不是人">围绕着事而不是人</h3>
<p>管理者一定要知道：要围绕着事情，而不是围绕着人</p>
<p>永远不要想“他很资深，他是公司的老员工，所以我今天当他的 leader
的话会发生什么问题”；也不要担心谁不服我，谁比我资深很多，我管不管得住他；总体就是不要戴有色眼镜去看自己，也不要戴有色眼镜去看别人</p>
<p>这个时候要想的是，<strong>我们要完成一件事情的话，每个人的分工是什么，它的产出是什么</strong>；当这些都能讲得明白的时候，这个时候就有了标准，就能够去做客观的绩效的考核</p>
<p>如何围绕着事情开展的方法论因人而异，笔者这里提供一个听到过的较好的说法：<strong>复杂的结果看过程，标准的过程看结果，短期的结果看策略，长期的发展看团队</strong></p>
<p>（1）复杂的结果看过程：<strong>无法预测的结果</strong>，更多精力应该关注过程，过程的纠偏到位才有可能确保复杂的记过拿到
（2）标准的过程看结果：标准或者说比较常规的事情，基本可预测，主要看<strong>执行力</strong>
（3）短期的结果看策略：短期的事情往往取决策略是否得当，策略适合，拿到的结果可能效率更高、质量更好
（4）长期的发展看团队：组织、事业的长期发展，一定要依靠组织能力，或者说培养一个有战斗力的团队</p>
<p>另外，<strong>当你要去 push
一个人的时候，本质上就是大家对目标还有分工上面没有讨论清楚</strong>，这个时候要做的事情不是去
push、而要拉回来再讨论清楚我们的目标是什么，我们的分工是什么，当然前提是这个员工基本还算靠谱，而不是真的赖着不干活的老白兔</p>
<p>而从心态上，需要承认的事实是，一个良性发展的团队，肯定会有下属在特定的专业能力上比自己要强；而我们都是用人所长，整个公司范围内大家都是用人所长，所以不要想着什么事情自己都要做到最好，而是要想着这个人的这个能力，放在哪个岗位上能发挥出他最大的价值，当然识别长处这一点也很考验管理者的识人能力和业务能力</p>
<h3 id="做个好的翻译">做个好的翻译</h3>
<p>管理相当于不需要你亲自做很多很多事了，但是你得有办法让更多的人把这件事做得更好更大。从这个角度来看，<strong>管理就是在做翻译的工作，即把上级的任务翻译成需要下达的任务</strong></p>
<p>而管理者的老板或者公司压下来的那个东西，是不能不经你翻译直接再传递给员工；因为<strong>如果你的工作只做中转站，那你一定会发现你的工作是没有价值的，不要原封不动地传话，需要带上自己的思考和判断</strong></p>
<p>比如说一些事情如果传递下来，本身对于团队来说没有积极正向作用，可能你作为一个上级，你的价值就在于你需要把它过滤掉，就是不要往下再去传递</p>
<ul>
<li><strong>信息传递要清晰</strong></li>
</ul>
<p>有时候如果下达命令时如果对方“不听”，或者说疑惑为什么员工会做得这么慢；先问自己是否说清楚，很多时候是因为你还是<strong>把自己的认知强加在员工身上</strong>，没把上下文或优先级同步到位，本质的问题还是信息的传递之间出了问题</p>
<p>《<a
href="https://www.xiaoyuzhoufm.com/episode/62b23f72482bcc5dedb96dd7">新晋管理者的避坑指南</a>》里的提到了很常见的一种现象：今天你要把一个工作交给你的团队成员的时候，你交代的够不够清楚他对这件事情的理解认知。有时候你问他懂不懂，你会发现
99.99%
的员工一定会回答，尤其是中国的员工一定会回答你。懂了，但是他下一步的动作你如果仔细观察之后，他会回去，然后问旁边的同学，那个老板交给我一个工作，我怎么做？他不敢去告诉你，他没有听懂。</p>
<p>很多管理者需要学的一个技能是<strong>你怎么再三确认他对你交代给他的工作或任务理解到位，给下属安排任务时，不要只说“要做什么”，还得说“为什么要做”“什么时候做完”“要做到的结果”</strong></p>
<p>为了确保有效沟通，你还需要再做两个动作：
1.告诉员工为什么要做这个活动，目标是什么，这比告诉他怎么做更重要
2.信息来回确认三回，每次你讲完，最好让员工复述一遍。“你能复述一下你是怎么理解的吗”“你能再复述一遍吗”，“这个任务给到你了，你接下来会怎么做？”不断修正信息，来回确认他想的跟你想的尽可能接近</p>
<ul>
<li><strong>沟通</strong></li>
</ul>
<p>管理中沟通的重要性不言而喻，一些沟通的技巧和方法</p>
<p>（1）不要恶意假设对方，不要揣测
当你对事情不理解的时候，带着好奇多问一句：“你是怎么想的？这么做你的考虑是什么？”</p>
<p>（2）坦诚清晰
说话方式有很多种，总体要坦诚清晰，因为不管是正向的还是负向的，对于员工来讲，他能够比较好的接受这个事情，而这个比较清晰的接收到了你的反馈，是好过于你支支吾吾啥都不讲的；但是也要注意表达，不让别人误解，曲解自己的意思</p>
<p>（3）把批评变成动力
高效的管理是激发一个人的善意，而不是一个人的阻抗；从提问开始转变，“你为什么总是
XX” 到 “你怎么样才能避免XX”</p>
<p>（4）包容开放
沟通是互动的，包容、开放地接受他的反馈，不要情绪一上来一激动，就给别人塞很多东西，但凡觉得他有个地方做的不好了，就非常激动的直接告诉他这个事情你做的不对，叭叭讲一大堆，然后不给他机会说话（能力强的
IC 的这个问题越为为严重）</p>
<ul>
<li><strong>跨部门合作的翻译</strong></li>
</ul>
<p>除了上下级的翻译，跨部门的合作其实也是在翻译</p>
<p>在上面的播客中，Zara
提到的很有意思的一点是<strong>把我们想要实现的目标翻译成对方的目标</strong>，让人帮你的最高境界就是让他觉得你在帮他。所以如果要跟跨部门合作，Zara
会先去看他的 OKR 然后看他的 OKR
里有哪些是我这件事情可能能帮他实现的，然后就翻译成他的目标</p>
<h3 id="调动积极性">调动积极性</h3>
<p>虽然员工在工作中的积极性往往取决于其自身的目标、追求和欲望的强烈程度，但是一个管理者的重要任务之一也是激励和激发，激励员工的能动性，激发员工的创造力</p>
<ul>
<li><strong>要激励而不是洗脑</strong></li>
</ul>
<p>虽然说激励很重要，如果你这个做的太过了，就又会让人觉得在洗脑，怎么找到一个平衡？</p>
<p>可能最重要的是<strong>要倾听下属的声音</strong>，然后针对下属的想法和诉求，尽量满足他的诉求，设置较好的激励；很多管理者一上来很容易变成纯单向的输出，就是给下属讲各种自己的愿景、价值观等等，但是忘了去倾听下属的声音，包括下属的真实想法，他实际的诉求等</p>
<p>当然，这种双向的沟通需要信任：在还没有信任没有建立之前，一个员工跟你讲他心里的话是很困难的，也不要去做这样的预期；而建立信任则是一个比较长的过程了，可能是一块打过仗，或者管理者的办事作风、人格魅力等能打动员工</p>
<ul>
<li><strong>耐心</strong></li>
</ul>
<p>对于一些初入职场的新人员工，需要更多的耐心，让他们去慢慢地去成长。不能说一上来就以过高的标准去要求他，因为你要意识到其实你也是这么一路走过来的，不能说你做到今天，然后你要求他在一个很短时间内达到你那样的一个水准，这是不科学的，这也是不现实的</p>
<p>要给他信心，告诉他做错了不要紧，做错了之后可以总结、复盘。这样的调整之后，你会发现他也就越做越有信心，而且也愿意去跟你交流；他的自信建立起来了之后，这件事情就越做越顺，越做越好</p>
<p>同时要避免新人员工的结果不达预期就自己动手去做，还是要<strong>坚持让你的团队的同学去做事情</strong>，不要去插手把他推到一边说放着我来，这个会特别大的去影响到他的积极性，以及对他长远的跟你的配合会有很大的影响</p>
<ul>
<li><strong>识人</strong></li>
</ul>
<p>人不是千篇一律的，管理者千万不要幻想我用一套标准对所有的人都适用</p>
<p>有些人就是以情绪为导向，就是你今天给了他正反馈，他就开心的像一只小鸟一样满屋子飞，然后就好好工作；有些人是不吃你那一套鼓励的，他不吃鸡汤的，他需要的是你要用逻辑征服我；有些人就是不愿意听你讲逻辑，他是那种行动派，就说不要叨叨了，站起来就去干吧</p>
<p>而在公司的两大类业务（创新性业务和成熟业务）中，往往需要两类不同的人才
（1）公司在面临寻找第二曲线，要去找一些探索型业务的时候，需要找一批很愿意探索创新东西，创造新的东西，同时韧性特别强，不怕失败的人；因为探索型业务就意味着叫胜率低赔率高，一旦做成了很棒，但是做不成是大概率，就是派出去的敢死小分队一样
（2）对于成熟期的业务，需要另外一拨人：逻辑严谨，很少犯错，对风险很厌恶，对安全感有要求。这部分人他的整个思维是相对比较缜密，能保证你现在成熟期的业务少犯错，不出现短板，导致业务崩掉</p>
<p>另外，还着重提到了一种人群:
<strong>推土机</strong>，即专业能力是很强的，然后自信心也很强。正是因为他自信心和专业能力很强，就很自我；这种人适合单兵作战缺，管理上我们叫<strong>保护性和限制性使用</strong>，避免它影响现有团队的一些文化；因为能力越强，水准越高，其实破坏力也越大，比如说阿里也出现过的例子，两位科学家来了，一人带个上百人的团队，然后花多少亿吵两年什么结果没有，俩人互相不对付，一起走了留下烂摊子</p>
<ul>
<li><strong>从员工的追求出发</strong></li>
</ul>
<p>这部分本质上就是要换位思考，即从员工的角度去推进一些事情，<a
href="https://m.okjike.com/originalPosts/6297673ee21f494ee4daf62c">这里</a>有个很好的例子,
从这个故事我们也能看到，<strong>管理者应该是一个通过“帮助团队每个人实现个人目标”，从而实现管理者自己目标的角色。</strong></p>
<blockquote>
<p>我为啥要指出他身上的问题呢？是因为希望他改掉问题。
那他为啥会改掉问题呢？会因为我指出了他就改掉吗？肯定不会呀！他要改掉问题，只会是为他自己！
于是，第二天，我试了一下用新的谈话策略，和一个小朋友聊问题。分成四步走：</p>
<p>1、“XX，你未来希望自己在职业巅峰时在做什么呀？”
他说：“我想当一个创业者！”</p>
<p>2、“那你觉得，可以让你成为一个成功创业者的最大优势是啥？”
他说：“我觉得我能坚持正确的事儿！只要一件事儿，我想明白了，就会坚决执行。”</p>
<p>3、“我觉得，你离成功创业者此刻还有个差距，你看这回这个项目这里、这里都有考虑不全的地方。如果要想成功创业，你得比现在细致才行。”
他说：“对哎，我是觉得我还应该更细致。”</p>
<p>4、“不过我很认可你的优点。细致这个问题你已经意识到了，我相信你会发挥你的优点，把它解决掉的！”</p>
<p>从此，我再向团队指出问题的时候，对方常常都很开心，也会在谈话后很快行动起来。团队的氛围也在快速改善。</p>
<p>其实就是想清楚了一件事：
<strong>每个人是不会仅仅为了别人的要求就改变自己的。能让他行动起来的，只会因为他自己的目标，尝试将需要他改变的地方跟他的目标联系起来；如果没有目标，那就是个混子，不适合呆在面对挑战的位置</strong></p>
</blockquote>
<h3 id="关于伪中层">关于伪中层</h3>
<p>这里之所以提到这个话题，是因为听到这期播客 《<a
href="https://www.xiaoyuzhoufm.com/episode/62f2db0e5efbdc148aeae2c6?s=eyJ1IjoiNjIxZjkzN2RlZGNlNjcxMDRhYWM4NThhIn0=">汇报要彩排，遇事先甩锅，工作中遇到伪中层怎么办</a>》特别有感触，同时在每个人职业生涯过程中不可避免会遇到这一类的伪中层，要思考的是如何识别这一类伪中层，更重要的是同时如何避免称为这一类伪中层</p>
<p>这里主要摘自听了播客的一些笔记，也有一些个人思考</p>
<ul>
<li><p>中层应该具备的的三层能力 （1）向上的战略理解能力
（2）业务的精专，尤其是技术这一类岗位
（3）管理能力：能不能发挥好手下员工的能动性</p></li>
<li><p>三种类型的伪中层：传话筒型、欺上瞒下型、老黄牛型
（1）传话筒：没有经过自己的翻译和拆解, 只会机械地传话
（2）欺上瞒下：只会汇报和甩锅
（3）老黄牛：不懂授权，手下员工得不到发挥，没有成就感</p></li>
<li><p><strong>如何应对伪中层</strong>
（1）高层视角：大老板走到一线(包括访谈一线客户、与一线员工约谈、看一线的数据)，不接受单一的中层的二手信息；需要降低大老板获取一线信息的成本
（2）中层视角：把信息(问题和功劳)尽可能快地传递到老板处，因为往往谁先说，谁就有先发优势，后面说的在大老板看来都是在狡辩；优雅地邀功；不要替老板做判断，客观地陈述数据的变化和具体过程，体现自己对业务的思考和洞察，老板自然会
get 到这是你做出来的一个成绩
（3）员工视角：老板是伪中层，如果能汇报且为你争取利益没问题，但往往伪中层都会把利益归到自己身上；与伪中层相处：1）不独食且有能力类型：要让伪中层觉得你是他的自己人，为他解决问题然后你分得相应的利益；2）独食或无能力类型，想办法干掉或者跑路（如果是新人，可能只能跑路，但工作时间长了，可以想办法干掉），干掉关键打破信息壁垒，但是要提防伪中层的+1，也是一个伪中层（反映时要关系到伪中层+1
的实际利益，比如说可能会影响公司的股价或期权价格）</p></li>
<li><p><strong>怎么在面试识别伪中层</strong>（面试时反问的一些技巧）
（1）公司目标如何制定、如何考核的，既当裁判又当运动员容易滋养伪中层【合理的范式应该是从上到下定目标，有独立的裁判】
（2）高层是否会有 all hands 或者 -1、-2 的 one one
（3）反问面试官做过的最有意义的或者印象深刻成果，如果是真实参与的会滔滔不绝跟你说
（4）问面试官当前团队的员工有哪几个来源；伪中层一般会带着自己的嫡系，形成一个稳固的小圈子，这种情况小心被招进去当做背低绩效的替罪羊【合理的范式应该是老板手下有多个来源，存在有能力的老员工，能够信服这个老板】</p></li>
</ul>
<p>最后，着重讲一些<strong>老黄牛类型的中层的问题</strong>，因为笔者也曾迈入过相似的误区；当你不懂得授权的，严格地控制所有的动作，最后会发生几个问题，第一个是他<strong>自己会越来越累</strong>，他整个人会变成团队的瓶颈；第二个是<strong>团队的所有人会越来越失去主动性</strong>，大家没有什么发挥的空间，最后主动性会流失。第三个就是<strong>团队的所有同学也会失去成就感，越优秀的人走得越早，然后越早会离开他</strong>。最后只有那些就是希望自己有一个安稳工作，不要承担责任的小白兔才会留下来。</p>
<p>套用一句比较形象的话就是<a
href="https://m.okjike.com/originalPosts/63045c3c188db1d5d07af49e?s=eyJ1IjoiNWM1YmZiMmU3ZjYyNTEwMDE1MTk2Mzk3In0=">救火容易救出成就感</a>，每天无数人找管理者救火，管理者会觉得自己好像是英雄、整个公司非自己不可;
这也是人的弱点。下面的例子也许不适用所有的业务，但是做法值得参考，主要想表达的观点是<strong>成功的管理者一定是能将紧急的事情借机制分担，保证自己最主要精力得以分配在重要事务上的人</strong>,</p>
<blockquote>
<p>每天我的团队要找我很多次——很多时候是看方案，很多方案，我得看一眼，团队才能往下推进。有时候是出了问题，得赶快查问题。还有的时候，是推进遇到了阻力，得我帮团队找到其他部门，把资源谈下来
我也要找团队很多次。有很多事儿，我心里挂着，是真不放心。时不时想起来就找团队问一嘴：做了没有？效果如何？
但是，这些事儿，就不会发生在他与团队之间。</p>
<p>1、 他在自己的团队内，搞了个小规模的数据分析的团队。</p>
<p>不过他的数据分析，可不是仅仅支持AB测试。他让这个团队，<strong>量化了自己的评价标准</strong>。
于是，再有团队拿着方案，找他看行不行的时候，他都说：
你去找那个数据分析的负责人，他掌握着我的评价标准，他帮你测算一下，他说行，那就行。于是，团队需要找他过的方案，大大减少。</p>
<p>2、 他还搞了个项目经理。</p>
<p>团队有遇到资源问题，自己搞不定？也先不用找他。先找项目经理！
公司有哪些资源、怎么协调，项目经理门儿清。
真遇到项目经理搞不定，需要他说句话的。
项目经理会帮他把微信说啥编好，他一键转发。
于是，团队需要找他协调资源的情况，也基本消失。</p>
<p>3、
项目经理还负责催进度。凡是他在意的事儿，他都让项目经理管理起来，周期性催活儿。于是，他需要找团队问东问西的情况也大大减少。</p>
<p>那什么事儿他必须亲自干呢——团队在方法上遇到了困难，实在找不到办法，他和团队一起讨论。
<strong>他花了大量时间面试和接触更好的候选人,他还会听大量的用户访谈、每天自己看很多数据。</strong></p>
<p>相比之下，<strong>我们大多数管理者，每天都被不得不做的紧急事务催得团团转。紧急的事儿消耗精力，但是重要的事儿才会产出关键业绩</strong>。</p>
</blockquote>
<h3 id="文化与战略">文化与战略</h3>
<p>文化与战略，似乎是一个很大又很虚的词，但是在听了《<a
href="https://www.xiaoyuzhoufm.com/episode/63585cac5e3d8a7ab9ef9051">十点读书林少：一线员工可以为公司战略做些什么？</a>》
后，发现从高层视角去审视管理这件事情，文化和战略对一个公司的长期发展也是不可缺少的手段</p>
<ul>
<li><strong>关于文化</strong></li>
</ul>
<p>随着企业变大、人变多后，大家认知体系必然会不同频，必须要<strong>有一个同频的目标去做决策的一个标准</strong>，这个时候就凸显了企业文化的重要性，而文化就是帮战略、帮组织纠偏，它是很好的一个纠偏剂；套用林少的话是这么说的</p>
<blockquote>
<p>首先文化确实蛮虚的，但我个人觉得其实从一家公司的底层来看，文化它是一个底座，它可能没有那么显性，但是它对这个公司的长远的一个指导是有非常重要的一个作用的。
<strong>战略、组织、文化</strong>这三件事情其实是一个公司成功的比较重要的三个要素。那战略这个事情咱们比如说每年甚至每个季度都要开战略会，为什么？因为市场在变化，所以你的战略可能是会变化的，而且很有可能你的战略是会制定错误，可能会跑偏。组织其实它也是跟着战略变化的。那有可能我们这段时间我们这个战略出现了偏差，那我们大的这个组织它也会有一些变化，那组织里面也会有不同的同学加入。那可能有些同学非常合适，但有些同学他可能就不合适，可能也会又走偏的时候。
那什么是文化呢？我觉得其实文化就是帮战略纠偏，帮组织纠偏，它是很好的一个纠偏剂。就<strong>从长远的发展来看，当我们有一些公司发展碰到瓶颈，公司走了弯路，那这个时候我们靠什么？就靠你的文化里面的使命，还是回到原点，到底我们做这件事情意义是什么？然后到底我们长远我们要去向何方？然后我们从起点走向愿景的这条过程中，我们的行为准则是怎样的？我们是跑着去，走着去，还是抄着小路去？还是说我们可能通过一些不常规的道路去？我觉得这些都是文化可能在起到指导的作用。</strong>
我们企业文化其实比较核心的是三个部分，<strong>第一个是使命，第二个愿景，第三个价值观</strong></p>
</blockquote>
<ul>
<li><strong>关于战略</strong></li>
</ul>
<p><strong>战略应该是简单的</strong>，应该是你一说出来大家觉得他是容易理解的，跟公司的使命是极度契合的，然后跟我们自己的能力也是非常的契合的；战略不太需要多条，也不太需要说你去经常换方向，反而是你围绕着自己主赛道，然后好好的去进行战略的一些比较简单的升级</p>
<p>战略的制定往往分不同的阶段，<strong>早期更多就是靠直觉拍脑袋</strong>，就是老板看到有一个机会，还是一个无人地带；直觉这里会有机会，所以自己就往前冲了，可能大部分会失败，但少数会成功。战略直觉是挺重要的，就是一个
CEO
他每天都在接触这个公司的所有的信息，然后他也在跟很多外部的一些市场去打交道，就是这每天的信息其实是会让
CEO 去产生一些战略直觉的。有些 CEO
其实是有<strong>战略直觉天赋的，会是一家公司一个 CEO
非常核心的竞争力</strong>。但仅有这个不够，因为即便如此，一个人依然是有盲区的。那这个时候就需要多方的视角，<strong>需要有高管团队帮忙来从不同的维度去做战略的复盘，做战略的探寻，结合外部的顾问，结合
CEO
的直觉，再结合整个管理团队的多维度的战略的探寻，是会制定出相对比较有效的战略方向</strong>。</p>
<p>而战略直觉依赖的的信息来源，播客里提到了三个（1）跟更多的同事去交流，不仅仅高管，跟更多的中层甚至是基层的员工去交流，一线的员工其实是离炮火最近的；可以听听他们的想法，他们对公司的看法，然后听听他们对市场的看法，他们对用户的看法（2）每天要有大量的输入，这些输入可以是来自于你所关注的一些账号，有公众号，有抖音账号（3）保持足够频率的跟外部的同行交流，他们可以是你的密友，也可以是你新认识的一些创业者，也可以是你的投资人，从他们这边也可以获取到非常高质量的一些信息跟建议</p>
<p>有了战略信息，如何向员工传递？需要靠机制一层层落实；比如说每个季度制定一个战略
OKR 分享会，向全员表达（类似字节的 all
hands）；把战略贴在会议室墙上，每个人都很聪明，当他们的信息足够，当公司的信息差越来越少之后，那这个时候其实战略的理解、推行他就会相对比较容易得多。很多时候战略落地不了，可能是信息的传达不够</p>
<ul>
<li><strong>管理需要工具化</strong></li>
</ul>
<p>除了文化和战略这些看起来比较大而虚的内容，播客还提到比较实在的一点，就是管理需要工具化</p>
<p>管理很多其实是非标的，因为每个人的管理方式不太一样，每个人他自己的管理风格也不太一样，他的性格也不太一样。那这个时候，<strong>一个新员工加入试点，他怎么更好地去理解我们的沟通方式、协调方式跟会议方式？</strong></p>
<p>如果能够<strong>将非标的管理工具化，通过更多的文档、通过OKR、通过绩效把它工具化</strong>。那这个时说一个新员工进入公司，他通过飞书等工具，他能够接触到的这些资料他就能够很快地
get
到这家公司是怎么通过文档交流的，开会的互动的，然后通过周报到底是怎么去协调的</p>
<h2 id="小结">小结</h2>
<p>管理这个词看起来似乎高深莫测，整篇文章看下来，的确也有很多的技巧和方法论，但回归到本质，还是如何通过高效的方式组织一群人去完成任务，并且是长期可持续的</p>
<p>正如没有一种通用的技术能适用于所有的业务，也没有一种通用的管理方式使用所有的团队，因为这跟业务类型、业务发展阶段、团队规模、团队成员的特点都有关；而回到最开头说的像打造一个产品一样打造一个团队，我们要做的就是随着业务等发展，不断地调整团队的这个产品的形态</p>
<p>往往我们会被传达这样的一个理念：当上了管理者似乎就能一劳永逸，避免 35
岁危机，虽没实证过，但相信也不会是真的，只是一个妄念。而随着业务的发展不断调整、进化自己，以更年轻和开放的心态去迎接当前的挑战，有管理工作委任时能够扛得起，没有也能做个能打的
IC，可能才是“一劳永逸”的答案；毕竟真正当上管理者的人是少的，而当上管理者可能也需要在合适的时机踩中合适的机会，有运气与努力成分；好好生活，快乐工作，才是每个普通人应该去努力追求的，与君共勉。</p>
<hr />
<p><a
href="https://www.xiaoyuzhoufm.com/episode/63585cac5e3d8a7ab9ef9051">十点读书林少：一线员工可以为公司战略做些什么？</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/62b23f72482bcc5dedb96dd7">新晋管理者的避坑指南</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/636082181bc3371399053ec5">做一个受欢迎的管理者</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/627ae4384af32f2190f6b26f">如何管理比自己年龄大的人</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/62f2db0e5efbdc148aeae2c6?s=eyJ1IjoiNjIxZjkzN2RlZGNlNjcxMDRhYWM4NThhIn0=">汇报要彩排，遇事先甩锅，工作中遇到伪中层怎么办</a>
<a
href="https://www.xiaoyuzhoufm.com/episode/62c4b59e07b14a212561a2ea">为什么晋升总是轮不到你？可能是因为忽视了这项能力</a>
<a href="https://book.douban.com/subject/35799634/">职场晋升101</a></p>
]]></content>
      <categories>
        <category>闲话几句</category>
      </categories>
      <tags>
        <tag>闲话几句</tag>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告笔记(1)--广告的基本知识</title>
    <url>/2017/04/20/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0(1)--%E5%B9%BF%E5%91%8A%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>本系列文章是刘鹏老师的<a
href="http://study.163.com/course/courseMain.htm?courseId=321007">计算广告学</a>中的一些记录。本文是第一章的相关笔记：广告的基本知识，主要介绍广告的定义与模型，目前在线广告的特点、技术架构与市场形态，可以说简要地概括了整个课程的内容。</p>
<span id="more"></span>
<h2 id="什么是广告">什么是广告？</h2>
<p>广告有商业上的诉求和目的，并不是简单的技术的堆砌。</p>
<h3 id="广告的定义">广告的定义</h3>
<blockquote>
<p>广告是由已确定的出资人通过各种媒介进行的有关产品(商品、服务和观点)的，通常是有偿的、有组织的、综合的、劝服性的非人员的信息传播活动。</p>
</blockquote>
<p>重点：</p>
<p><strong>广告的主体</strong>：出资人(sponsor)即广告主(advertiser)，媒介(medium)，受众(audience)
<strong>广告的本质功能</strong>：是借助某种有广泛受众的媒介的力量，完成较低成本的用户接触(reach)</p>
<h3 id="品牌广告brand-awareness与效果广告direct-response">品牌广告(Brand
Awareness)与效果广告(Direct Response)</h3>
<p>品牌广告：创造独特良好的品牌或产品形象,
目的在于提升较长时期内的离线转化率</p>
<figure>
<img src="https://wulc.me/imgs/image_1bedb9224c2f10df1pn9m1o1fg413.png"
alt="品牌广告" />
<figcaption aria-hidden="true">品牌广告</figcaption>
</figure>
<p>效果广告：有短期内明确用户转化行为诉求的广告。用户转化行为例如：购买,
注册, 投票, 捐款等。大部分互联网广告都是这种类型。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bedb9svv5n4h6217d81g8pg4b1g.png"
alt="效果广告" />
<figcaption aria-hidden="true">效果广告</figcaption>
</figure>
<h2 id="广告的有效性模型">广告的有效性模型</h2>
<p>三个大阶段，同时可分为6个小阶段</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh7rmedu2b68f41qkd19imfbr9.png"
alt="广告有效性模型" />
<figcaption aria-hidden="true">广告有效性模型</figcaption>
</figure>
<p>这里值得注意的几点有</p>
<p>1.广告的天然属性（如广告的位置）很重要，远远强于技术带来的效果
2.引起用户关注时需要遵循一定的原则：以上列出了三点
3.解释阶段包括用户对广告的<strong>理解和认可</strong>两方面；理解阶段
4.保持（retention）主要指品牌在用户中树立起其形象，但是点击率往往不会高</p>
<p>下面一些广告策略的效果,这些广告策略都是有利有弊的，下面的
<code>+</code> 表示对该项有正面效果， <code>-</code>
表示对该项有负面效果。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh7rp7pc10ti1am4on0cd919uhm.png"
alt="广告策略的效果" />
<figcaption aria-hidden="true">广告策略的效果</figcaption>
</figure>
<h2 id="在线广告">在线广告</h2>
<p>在线广告是与传统的线下广告对比而言的，下面主要介绍在线广告的特点、目前的市场、核心计算问题。</p>
<h3 id="在线广告的特点">在线广告的特点</h3>
<p>当前的在线广告行业的有以下特点</p>
<p>1）
<strong>技术和计算导向</strong>。原因是数字媒体的特点使在线广告可以进行精细的受众定向，而技术使得广告决策和交易朝着计算驱动的方向发展
2）
<strong>可衡量性</strong>。指的是可以用量化的方式来衡量广告的效果，广告的点击是效果的直接收集途径
3）
<strong>标准化</strong>。指的是有行业制定了相关的规则来指导广告市场。如下是一些美国广告行业相关的机构。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bedfs4ft1dau44j10of1dbfstvm.png"
alt="iab" />
<figcaption aria-hidden="true">iab</figcaption>
</figure>
<ul>
<li><strong>Interactive Advertising Bureau</strong>
<ul>
<li>在线广告供给方的行业协会，推动数字化市场营销行业的发展</li>
<li>制定市场效果衡量标准和在线广告创意的标准</li>
<li>会员: Google, Yahoo, Microsoft, Facebook等</li>
</ul></li>
</ul>
<figure>
<img src="https://wulc.me/imgs/image_1bedfsgru1ndc14qe1n3v1ps5n1t13.png"
alt="4a" />
<figcaption aria-hidden="true">4a</figcaption>
</figure>
<ul>
<li><strong>American Association of Advertising Agencies</strong>
<ul>
<li>主要的协议是关于广告代理费用的收取约定(17.65%)，以避免恶意竞争</li>
<li>主要集中在创意和客户服务，在线业务是一部分</li>
<li>会员：Ogilvy &amp; Mather, JWT,
McCann等,Dentsu等非4A会员的大公司但也被列为4A公司</li>
</ul></li>
</ul>
<figure>
<img src="https://wulc.me/imgs/image_1beejom04mi91t2t1j9pjh6c6a9.png"
alt="ana" />
<figcaption aria-hidden="true">ana</figcaption>
</figure>
<ul>
<li><strong>Association of National Advertisers</strong>
<ul>
<li>主要代表广告需求方的利益(也有媒体和代理会员)</li>
<li>会员：AT&amp;T, P&amp;G, NBA等</li>
</ul></li>
</ul>
<h3 id="在线广告市场">在线广告市场</h3>
<p>在线广告市场发展情况如下所示，主要分为了三大部分：需求方，供给方和连接两者的平台，需求方指的是需要投放广告的广告主，供给方指的是提供广告位的媒体。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh7sbaqo4u216vppmrfo3cm13.png"
alt="在线广告市场" />
<figcaption aria-hidden="true">在线广告市场</figcaption>
</figure>
<p>从媒体也就是supply端来看，其变现的手段有以下三种</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh7sru9gvr71qtd1uufl1le3r1g.png"
alt="在线广告变现手段" />
<figcaption aria-hidden="true">在线广告变现手段</figcaption>
</figure>
<p>方式一：将广告位托管给广告网络(Ad net1)
方式二：将广告位对接到广告交易平台(Adx), 以实时竞价的方式变现
方式三：将广告位托管给SSP（supply side platform),
通过SSP可以对接多个广告网络和DSP，按照动态分配的逻辑选择变现最高的需求方。</p>
<p>上面简单的说明了媒体方通过广告位进行变现的方式，涉及到多个概念，可以参考刘鹏的《<a
href="https://book.douban.com/subject/26596778/">计算广告</a>》中的第六章内容。</p>
<h3 id="在线广告核心计算问题">在线广告核心计算问题</h3>
<p>在线广告的<strong>核心计算问题</strong>是 ROI（Return On
Investment，投资回收率）其定义如下</p>
<blockquote>
<p>Find the best match between a given user u, in a given context c, and
a suitable ad a.<span class="math display">\[\max\sum_{i=1}^{T} ROI(a_i,
u_i, c_i)\]</span></p>
</blockquote>
<p>上面的 <span class="math inline">\(T\)</span> 表示广告共展示 <span
class="math inline">\(T\)</span> 次,ROI 主要有两部分构成:
<code>Investment</code> 和
<code>Return</code>，一般来说主要优化的目的在于<code>Return</code>，
其计算公式如下</p>
<p><span class="math display">\[Return = \sum\_{i=1}^{T} \mu(a\_i,
u\_i,c\_i)v(a\_i,u\_i) = \sum\_{i=1}^{T} e(a\_i, u\_i,c\_i)\]</span></p>
<p>其中</p>
<p><span class="math inline">\(\mu(a\_i, u\_i,c\_i)\)</span> 表示点击率
<span class="math inline">\(a\_i, u\_i,c\_i\)</span>
分别表示广告，用户和广告上下文 <span
class="math inline">\(v(a\_i,u\_i)\)</span> 表示点击价值 <span
class="math inline">\(e(a\_i, u\_i,c\_i)\)</span> 表示 eCPM（expected
CPM，预期每次展示能够带来的价值）</p>
<p>而对上式的不同的分解对应不同的市场形态：</p>
<ul>
<li><strong>CPM(<a
href="https://en.wikipedia.org/wiki/Cost_per_mille">Cost per
mille</a>)市场</strong>:
按照千次展示结算。是需求方与供应方约定好千次展示的计费。在这种方式下，<strong>点击率和点击价值都需要需求方预估。</strong></li>
<li><strong>CPC(<a
href="https://en.wikipedia.org/wiki/Pay-per-click">Cost per
click</a>)市场</strong>:
按照点击结算，最早产生于搜索广告。在这种方式下，<strong>点击率估计交给供给方，点击价值的估计交给需求方</strong>，并通过点击出价的方式向市场通知自己的估价。</li>
<li><strong>CPA(<a
href="https://en.wikipedia.org/wiki/Cost_per_action">Cost per
action</a>)/CPS(<a
href="https://en.wikipedia.org/wiki/Pay_per_sale">Cost per
Sale</a>)/ROI市场</strong>:
按照转化行为数、销售订单数和投入产出比来结算。这三个都是按照转化付费的一些变种。在这种方式下，<strong>点击率和点击价值都需要供给方预估</strong>。</li>
</ul>
<p>CPA/CPS/ROI市场中需要注意广告主可能会有作弊行为：
如隐瞒订单，卖高价物品（品牌得到了展示，但是转化率低，不用向平台付费）</p>
<p>优化 ROI
的问题可从以下两个角度来考虑，每个角度都有其重点关注的点，下面简单列出</p>
<p><strong>从优化角度来看</strong>，主要的关注点在于</p>
<ul>
<li>特征提取：受众定向</li>
<li>微观优化：CTR预测</li>
<li>宏观优化：竞价市场机制</li>
<li>受限优化：在线分配</li>
<li>强化学习：探索与利用</li>
<li>个性化重定向：推荐技术</li>
</ul>
<p><strong>从系统角度来看</strong>，主要的关注点在于</p>
<ul>
<li>候选查询：实时索引</li>
<li>特征存储：No-sql技术</li>
<li>离线学习：Hadoop</li>
<li>在线学习：流计算</li>
<li>交易市场：实时竞价</li>
</ul>
<p>在线广告计算的主要挑战有</p>
<ol type="1">
<li><strong>大规模
(Scale)</strong>：百万量级的页面，十亿量级的用户，需要被分析处理;
高并发在线投放系统 (例: Rightmedia 每天处理百亿次广告交易); Latency
的严格要求 (例: ad exchange 要求竞价在 100ms 内返回)</li>
<li><strong>动态性
(Dynamics)</strong>：用户的关注和购物兴趣非常快速地变化</li>
<li><strong>丰富的查询信息 (Rich query)</strong>：
需要把用户和上下文中多样的信号一起用于检索广告候选</li>
<li><strong>探索与发现 (Explore &amp;
exploit)</strong>：用户反馈数据局限于在以往投放中出现过的 <span
class="math inline">\((a, u, c)\)</span>
组合，需要主动探索未观察到的领域，以提高模型正确性</li>
</ol>
<h2 id="搜索广告与推荐">搜索、广告与推荐</h2>
<p>搜索，广告和推荐可以说是联系紧密同时又有各自特点的三个领域。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bedoi0jlq2t1i4v1io719501uo82n.png"
alt="比较" />
<figcaption aria-hidden="true">比较</figcaption>
</figure>
<p>比起搜索，广告不需要爬虫，索引数也比较少。</p>
<p>推荐不等于个性化，个性化是推荐的一个准则，其他准则还包括新鲜性，多样性等。</p>
<p>广告与推荐系统：文字广告点击率高于图片广告点击率，但是推荐系统刚好相反</p>
<p>推荐与广告的一个重要区别在于 Downstream
优化，推荐出来的物品还可顺带其他的推荐物品，优化的目的是一系列用户可能会点击的物品；而广告的推送只是要优化用户对这个广告的点击率。</p>
<h2 id="在线广告系统结构">在线广告系统结构</h2>
<p>下面的在线广告系统结构图，需要注意这并非实际设计图，只是概念性的结构图</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh7suuk0sm21em8lvg1743ajr1t.png"
alt="在线广告系统" />
<figcaption aria-hidden="true">在线广告系统</figcaption>
</figure>
<p>从上图可以看到，整个系统可以分为四大部分</p>
<ol type="1">
<li><p><strong>高并发的投送系统(Ad Server)</strong>：在线部分，根据
<span class="math inline">\(u,c\)</span> 决定出 <span
class="math inline">\(a\)</span>,特点是高并发</p></li>
<li><p><strong>受众定向平台</strong>：离线部分，分布式机器学习，用于预估点击率等信息，常用的是
Hadoop 平台</p></li>
<li><p><strong>数据高速公路</strong>：收集线上日志文件等供其他部分使用</p></li>
<li><p><strong>流式计算平台</strong>：重点在于实时性，比 Hadoop
要快，包括反作弊，计价，实时索引(广告的加入和删除)等任务</p></li>
</ol>
<p>将上面的架构图各部分做更细致的划分时，可以得到如下的划分图</p>
<figure>
<img src="https://wulc.me/imgs/image_1beg937q514t51k1r2j6158uie013.png"
alt="在线广告系统更细致的分类" />
<figcaption aria-hidden="true">在线广告系统更细致的分类</figcaption>
</figure>
<ol type="1">
<li>Ad Serveing: 主要指 Ad Server
接受两种请求，一种来源于用户（USer），另外一种是广告交易市场发过来的（RTBS）</li>
<li>Ad retrival：找出与页面和用户相关的广告</li>
<li>Ad ranking：有多个广告满足要求时，根据某种指标 (如eCPM)
来排序，选出最符合要求的广告</li>
<li>Streaming Computing：流式计算平台</li>
<li>Data highway：把线上数据传到 Hadoop 平台或流式计算平台</li>
<li>Session log generation:
搜集用户的浏览、搜索的行为整理成一份标准日志，提供给其他的系统</li>
<li>Customized audience
segmentation：受众的定制化，不由平台固定受众分类，而是由广告主选择具体的受众类型，因为业务的需求是各式各样的</li>
<li>Page attribute system：爬取有广告展示的页面，用于广告的
retrieval</li>
<li>Audience
targeting：受众定向，根据用户及其浏览的上下文决定出推送哪个广告</li>
<li>Ad management system: 供广告主投放广告的平台</li>
</ol>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告笔记(2)--合约广告系统</title>
    <url>/2017/04/25/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0(2)--%E5%90%88%E7%BA%A6%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>本系列文章是刘鹏老师的<a
href="http://study.163.com/course/courseMain.htm?courseId=321007">计算广告学</a>中的一些记录。本文是第二章:合约广告系统，主要介绍了广告系统中一些常用的开源工具，合约广告系统的概念以及在线分配问题的建模与求解。</p>
<span id="more"></span>
<h2 id="常用广告系统开源工具">常用广告系统开源工具</h2>
<p>广告系统中常用的工具有以下这些</p>
<figure>
<img src="https://wulc.me/imgs/image_1begf63m7ar31mth7jb143bm2n9.png"
alt="常用广告系统开源工具" />
<figcaption aria-hidden="true">常用广告系统开源工具</figcaption>
</figure>
<p>总体可分为两类工具：离线与在线</p>
<p><strong>离线</strong></p>
<ul>
<li>HBASE（列存储的NOSQL数据库，类似的有BigTable，HyperTable，Cassandra）</li>
<li>Pig: 一种脚本语言</li>
<li>Elephant-bird：将二进制文件转为 pig 可处理的文本文件</li>
<li>Hive: 一种脚本语言</li>
<li>mahout: 分布式机器学习</li>
</ul>
<p><strong>在线</strong></p>
<ul>
<li>ZooKeeper/Chubby: 分布式环境下解决一致性问题</li>
<li>Avro/Thrift: 分布式环境下跨语言的通信问题</li>
<li>S4/Storm: 流式计算平台</li>
<li>Chuhwa/Scribe/Flume: data highway,
分布式日志收集工具，并送到其他平台</li>
</ul>
<h2 id="合约广告系统">合约广告系统</h2>
<p>合约广告有两个重要组成部分：<strong>广告位合约和展示量合约</strong>。</p>
<p><strong>广告位合约</strong>：实际上是将线下的模式搬到了线上，指的是广告主与媒体约定在某一时间段内，在某些广告位上固定投放该广告主的广告，相应的结算方式是
CPT(Cost Per
Time)（也就是按照展示时间结算），<strong>这种模式下售卖给广告主的是广告位</strong>。</p>
<p><strong>展示量合约</strong>：展示量合约广告指的是约定某种受众条件下的展示量，然后按照事先约定好的单位展示量价格来结算，这种结算方式是
CPM(Cost Per
Mille)（也就是每一千次展示的付费）。这种方式也叫<strong>担保式投放(Guarantee
Delivery,
GD)</strong>，意思就是先广告主担保其提出的广告展示量会被满足。<strong>这种模式下售卖给广告主的是广告位+人群</strong>。</p>
<h3 id="广告位合约">广告位合约</h3>
<p>广告位合约对供给方和需求方的技术的要求都不高。</p>
<p>供给方即媒体往往会使用一种在合同确定以后自动的执行合同的广告管理工具：<strong>广告排期系统</strong>。广告排期系统能够帮助媒体自动执行多个合同的排期，可以将广告素材直接插入页面，且对于图片等静态资源，会放到
CDN 上进行加速。</p>
<p>需求方即广告主往往会通过代理商（agency）进行媒介采买（也就是广告位采买），代理商帮助广告主策划和执行排期，而<strong>对于广告的质和量，是根据代理公司人员对媒体广告位的历史经验以及对广告主业务的了解通过人工优化的方式来满足</strong>。这样的代理公司的代表有我们前面一讲提到的
4A 公司。</p>
<h3 id="展示量合约">展示量合约</h3>
<p>媒体从前面的广告位售卖变为按 CPM
的售卖，初衷是为了在受众定向的基础上提高单位流量的变现能力，可是面向的任然是原来的品牌广告主。广告主按广告位采买时，比较容易预估到自己能够拿到的流量，可是按照人群定向的方式采买，流量有诸多不确定的因素，因此，需求方希望在合约中加入对量的保证，才能放心购买。而假如约定的量未完成，则需要向广告商补偿。</p>
<p>因此，<strong>这种方式卖的不仅仅是广告位，而是人群。</strong>
后面半句我们很容易理解，而前面半句话的指的是在 CPM
这种结算方式下，任然没有摆脱广告位这一标的物，原因是无法将多个差别很大的广告位打包成统一售卖标的（这样的话每个广告主都会抢着要那些曝光率更高的广告位）；因此<strong>实际中的展示量合约往往是以一些曝光量很大的广告位为基础，再切分人群售卖</strong>，最典型的例子就是视频网站的铁片位置或者门户网站首页的广告位。</p>
<p>展示量合约这种模式的出现实际上已经反映了互联网广告计算驱动的本质：<strong>分析得到用户和上下文的属，并且由服务器端根据这些属性以及广告库情况动态决定广告候选。</strong>这一商业模式的出现，需要有一系列技术手段的支持，这些技术手段主要包括<strong>受众定向、流量预测、在线分配</strong>等。下面主要介绍流量预测和在线分配，受众定向会在下一讲中详细讲解。</p>
<h2 id="流量预测">流量预测</h2>
<p>流量预测(traffic forecasting)
简单来说就是预测某个标签的人群访问某个站点的量。流量预测其目的有多种，典型的有<strong>售前指导，在线流量分配，出价指导</strong>，前面两个是合约广告中的内容，而后面一个是竞价广告中的内容。</p>
<p>1）售前指导指的是在展示合约广告系统中，由于要约定曝光总数，事先尽可能准确地预测个人群标签的流量非常重要。因为如果流量低估，会出现资源售卖量不足的情形；而如果流量严重高估，则会出现一部分合约不能达成的状况。</p>
<p>2）在线流量分配指的是在展示量合约广告系统中，由于合约之间在人群的选择上会有很多的交集，因此一次的曝光往往会满足多个合约的要求，这时候就需要在多个合约之间进行分配，目的是达到整体满足所有合约的目的。这也是下面要详细探讨的在线流量分配的问题。</p>
<p>3）出价指导是竞价广告中的内容，在竞价广告中，没有了量的保证，广告主往往需要根据自己预计的出价先了解一下可能获得多少流量，以判断自己的出价是否合理。与前面在合约广告中的应用不同，这里还多了出价这一因素。</p>
<p>综上，广告里一般的流量预测问题，可以描述为对流量 <span
class="math inline">\(t(u,b)\)</span> 这个函数的估计，其中 <span
class="math inline">\(u\)</span> 是给定的人群标签或这些标签的组合，而
<span class="math inline">\(b\)</span>
是具体的出价。在展示量合约中，由于没有竞价，可以看成是 <span
class="math inline">\(b \rightarrow \infty\)</span> 的特例。</p>
<h2 id="在线分配">在线分配</h2>
<p><strong>在合约广告系统中主要讨论在线分配（Online
Allocation）问题</strong>，在线分配问题指的是在通过对每一次广告展示进行实时在线决策，从而达到在满足某些量的约束的前提下，优化广告产品整体收益的过程。</p>
<p>在线分配是广告中比较关键的算法框架之一，适用于许多量约束下的效果优化问题，而这实际上是广告业务非常本质的需求。</p>
<h3 id="问题建模">问题建模</h3>
<p>在线匹配可看作是一个二部图匹配问题，二部指的是代表广告库存的供给节点（集合记为
<span
class="math inline">\(I\)</span>）和代表广告合约的需求节点（集合记为
<span class="math inline">\(A\)</span>）。如下图所示，上边为集合 <span
class="math inline">\(A\)</span>, 下边为集合 <span
class="math inline">\(I\)</span>,
如果供给节点的受众标签能够满足某个需求节点的要求时，就在相应的两个节点之间建立一条连接边，所有边的连接记为集合
<span class="math inline">\(E\)</span>。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bhbevjhb1h4lp9g5p317n11k8a9.png"
alt="在线分配" />
<figcaption aria-hidden="true">在线分配</figcaption>
</figure>
<p>在线分配技术并不仅仅适用于展示量合约中的担保投放（GD）问题，还适用于
AdWords 问题，展示广告问题等。下面主要介绍 GD 问题和 AdWords 问题。</p>
<p><strong>GD 问题</strong></p>
<p>前面已经提到了GD的概念，在这里如果<strong>不考虑合约 <span
class="math inline">\(a\)</span>
未完成的惩罚</strong>，收益一定是常数。那么 GD 的优化问题可以表示为</p>
<p><span class="math display">\[\begin{align\*}
&amp;\max \quad C\\\
&amp;\begin{array}\\\
s.t. &amp;\sum\_{a \in \Gamma(i)} x\_{ia} \le 1 &amp;\forall i \in I\\\
&amp;\sum\_{i \in \Gamma(a)} s\_i x\_{ia} \ge d\_a &amp;\forall a \in
A\\\
&amp;x\_{ia} \ge 0 &amp;\forall (i,a) \in E
\end{array}
\end{align\*}\]</span></p>
<p>上面各式的符号含义如下</p>
<p><span class="math inline">\(C\)</span> 是一个常数，指的是总收益 <span
class="math inline">\(I\)</span>、<span
class="math inline">\(A\)</span>、<span class="math inline">\(E\)</span>
上面已经提到，分别表示供给点集合，需求点集合，边的集合 <span
class="math inline">\(\Gamma(i)\)</span> 表示与供给节点 <span
class="math inline">\(i\)</span> 连接的所有需求节点的集合 <span
class="math inline">\(x\_{i,a}\)</span> 表示供给节点 <span
class="math inline">\(i\)</span> 分配给需求节点 <span
class="math inline">\(a\)</span> 的流量的比例 <span
class="math inline">\(\Gamma(a)\)</span> 表示所有与需求节点 <span
class="math inline">\(a\)</span> 连接的供给节点 <span
class="math inline">\(i\)</span> 的集合 <span
class="math inline">\(s\_i\)</span> 表示供给节点 <span
class="math inline">\(i\)</span> 的总流量 <span
class="math inline">\(d\_a\)</span> 表示需求节点 <span
class="math inline">\(a\)</span> 的展示量需求</p>
<p><strong>Adwords 问题</strong></p>
<p>AdWorks
问题，也被称为有预算约束的出价问题，是竞价广告领域内的问题。简单来说，这个问题讨论的是在按照
CPC
方式结算的广告环境下，给定广告主的预算，整体化市场营收问题。需要注意的是，竞价广告中已经没有了量的约束，广告主给的约束是其预算费用。因此可以将这个问题表示为如下的优化问题</p>
<p><span class="math display">\[\begin{align\*}
&amp;\max\_{(i,a) \in E} \quad q\_{ia} s\_i x\_{ia}\\\
&amp;\begin{array}\\\
s.t. &amp;\sum\_{a \in \Gamma(i)} x\_{ia} \le 1  &amp; \forall i \in
I\\\
&amp;\sum\_{i \in \Gamma(a)} q\_{ia}s\_i x\_{ia} \le d\_a &amp; \forall
a \in A\\\
&amp;x\_{i,a} \ge 0 &amp;\forall (i,a) \in E
\end{array}
\end{align\*}\]</span></p>
<p>上式大部分的符号跟 GD 问题相同，不同的地方主要是以下两个符号 <span
class="math inline">\(q\_{ia}\)</span> 表示需求节点(广告主) <span
class="math inline">\(a\)</span> 对供给节点（某个人群标签） <span
class="math inline">\(i\)</span> 的出价 <span
class="math inline">\(d\_a\)</span> 表示则表示广告主 <span
class="math inline">\(a\)</span> 的总预算</p>
<h3 id="问题求解">问题求解</h3>
<p>上面的两个最优化问题均是线性规划问题，未知量是 <span
class="math inline">\(s\_i\)</span>（供给节点 <span
class="math inline">\(i\)</span> 的流量） 和 <span
class="math inline">\(x\_{ia}\)</span>（供给节点 <span
class="math inline">\(i\)</span> 分配给需求节点 <span
class="math inline">\(a\)</span> 的流量的比例）。但是对于 <span
class="math inline">\(s\_i\)</span>
，常常利用历史流量去估计它的值，因此上面的优化问题变成了仅仅需要求解
<span class="math inline">\(x\_{ia}\)</span>
的问题。下面解决这个问题的几种思路</p>
<h4 id="直接求解">直接求解</h4>
<p>对于这类线性规划问题，可以通过内点法或单纯形法直接进行求解，但是在大型的广告合约系统中，供给节点和需求节点的数目都很大，因此边
<span class="math inline">\(|E|\)</span>
的数目也会非常大（百万级以上),这样会使得对应的分配问题变得过于复杂而无法直接有效求解。令
<span class="math inline">\(n\)</span>
为变量的个数，则内点的时间复杂度为 <span
class="math inline">\(n\)</span> 的多项式级别，单纯形法的时间复杂度为
<span class="math inline">\(O(n^2)\)</span>, 这样直接求解的解参数正比于
<span class="math inline">\(|E|\)</span>
的数量，规模有可能过于庞大，无法进行实时的在线分配。因此有必要探索更新效率更高的的在线分配方案。</p>
<h4 id="对偶求解">对偶求解</h4>
<p>通过拉格朗日对偶可将原问题装化为对偶问题，但是对偶问题的变量数目仍然正比于约束的数目（供给约束和需求约束），前者的变量的量级为十万甚至百万千万，但后者的量级在数千级别。</p>
<p>为了减少所需求解的变量，这篇文献 <a
href="http://dl.acm.org/citation.cfm?id=1807360">Optimal Online
Assignment with Forecasts</a>
提出了一个方法：<strong>只保留需求约束对应的对偶变量，然后通过数学变换恢复出供给约束对应的对偶变量和分配率</strong>。具体的算法过程可参考上面提到的文献。</p>
<p>上面的方法在求解对偶问题时代价仍然比较高，因此在文献 <a
href="http://dl.acm.org/citation.cfm?id=2339718">SHALE: an efficient
algorithm for allocation of guaranteed display advertising</a> 提出了
SHALE
算法，优化了求解对偶变量的步骤，采用了原始对偶方法迭代进行求解，求解出对偶变量后，通过数学变换恢复出供给约束对应的对偶变量和分配率跟上面的方法一致。</p>
<h4 id="启发式分配方案-hwm">启发式分配方案 HWM</h4>
<p>上面根据历史流量数据来求解的分配方案原理上可行，但是在实际的工程应用中仍然显得有些复杂，比如离线仍然要消耗大量的时间求解对偶解。因此，人们希望实现一种快速算法，保持前述方法的紧凑分配的特性，效果上也能够近似最优。前述方法中通过合同节点的对偶变量即可恢复最优解，受其讨论启发，可以发现，<strong>只要大体确定好每个合同在分配中的相对优先级以及分配时得到某次展示的概率，就可以构造出一种直觉上可行的在线分配方案。</strong></p>
<p>文献 <a href="http://dl.acm.org/citation.cfm?id=2229038">Ad serving
using a compact allocation plan</a> 提出的 HWM（High Water MArk）
算法便是这样一种方案，虽然在数学上并不完全严谨，但是由于根据历史数据来指定的分配方案本身就具有相当程度的近似，因此其实际效果也不错，而工程上的便利性则是这个算法的一大优点。</p>
<p>HWM 分配算法有两个关键点：
1）根据历史流量确定每个广告合约资源的稀缺程度，通过可满足各合约的供给节点总流量的升序排列进而得到分配优先级
2）根据优先级确定每个广告合约的分配比例</p>
<p>具体过程可参考文献内容</p>
<h2 id="合约广告系统主要模块">合约广告系统主要模块</h2>
<p>在前面提到的广告提供架构图中，合约广告系统主要表示为以下模块</p>
<figure>
<img src="https://wulc.me/imgs/image_1behcsvao1se81fl1jub1j6s1bh0m.png"
alt="合约广告系统" />
<figcaption aria-hidden="true">合约广告系统</figcaption>
</figure>
<p>上面是竞价广告系统中截取出来的，但是截取出来的部分在概念上与合约广告系统相差不大；主要由以下几个部分构成</p>
<p>Ad retrieval：搜索页面内容相关的广告 Ad Ranking：计算
CTR，根据CTR排序 Yield management（Allocation）：广告分配的问题
流量预测模块：跟 Allocation 打交道，在上图中没有画出来 Billing 和
Anti-spam：实时计算部分，用于计价和防作弊，任何广告系统都有</p>
<h2 id="hadoop-介绍">Hadoop 介绍</h2>
<p>上面简单介绍了一些计算广告系统中常用的开源工具，下面主要介绍 Hadoop
这个使用最为广告的分布式系统。</p>
<p>Hadoop 源于Lucene项目一部分, 2006年成为子项目,
后来成为Apache顶级项目</p>
<p>Hadoop最为重要的两个部件： 1. HDFS：一个高可靠性,
高效率的分布式文件系统 2. MapReduce: 一个海量数据处理的编程框架</p>
<h3 id="hdfs">HDFS</h3>
<p>HDFS的架构如下： <img
src="https://wulc.me/imgs/image_1belcu4ugon1c7713n41irb5tnm.png"
alt="HDFS架构" /></p>
<p>HDFS中主要有 Namenode 和 Datanodes 两种角色，其中 Namenode 存储的的是
metadata，其包含的信息是组成文件的各个block存储在哪个 Datanode 上，而
DataNodes
是真正存储文件数据的地方，并且为了达到高可用的效果，文件的一个block会以多个replication的方式存在多个Datanode上。</p>
<p>当 client 访问 HDFS 上的文件时，会先访问 NameNode，得到 文件所在的
DataNode 的后再去对文件进行具体操作。</p>
<h3 id="mapreduce">MapReduce</h3>
<p>MapReduce
是一个分布式计算框架，整个过程包括一个Map过程和一个Reduce过程。相比于MPI,Map
过程处理之间的独立性使得整个系统的可靠性大为提高；并且分布式操作和容错机制由系统实现,
应用级编程非常简单。</p>
<p>MapReduce的计算流程非常类似于简单的Unix pipe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Pipe: cat input   | grep  |        sort    | uniq -c   &gt; output</span><br><span class="line">M/R:   Input      |  map  | shuffle &amp; sort |   reduce | output</span><br></pre></td></tr></table></figure>
<p>MapReduce中进程间通信的时间只能是在map和reduce间的 shuffle &amp; sort
过程，该过程主要是将经过map操作后 key
相同的那些记录聚合到一起，已进行后面的reduce操作。其过程如下图示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b5or34n01nrhp533c31evp9939.png"
alt="MapReduce" />
<figcaption aria-hidden="true">MapReduce</figcaption>
</figure>
<h3 id="mapreduce-与-分布式机器学习">MapReduce 与 分布式机器学习</h3>
<p>在分布式机器学习中常用的统计模型有两种：<strong>指数族分布和指数族混合分布</strong></p>
<p>指数族分布(<a
href="https://en.wikipedia.org/wiki/Exponential_family">Exponential
Family</a>)是条件概率服从某种形式的，常见的很多分布（如高斯分布，泊松分布，多项式分布等）通过变换都能够转化为这种形式，也就是常见的分布很多都是指数族分布。</p>
<p>这种分布的一个好处是通过最大似然(Maximum likelihood,
ML)估计可以通过充分统计量(sufficient
statistics)链接到数据，或者说得到数据的规律。这里的充分统计量(sufficient
statistics)是指数族分布中的一个组成部分，一般来说就是模型的参数（如高斯分布的均值和方差）。</p>
<p>而当单个的指数族分布无法刻画数据的分布的时候，就要考虑多个指数族分布混合在一起的分布，也就是指数族混合分布；常见的指数族混合分布有Mixture
of Gaussians, Hidden Markov Models, Probabilistic Latent Semantic
Analysis (PLSI)等。</p>
<p>在指数族混合分布中， ML估计一般通过EM算法迭代得到. 每个迭代中,
我们使用上一个迭代的统计量更新模型。</p>
<p>而一般的 ML 和 EM 算法能够通过 MapReduce 过程较好地刻画</p>
<figure>
<img src="https://wulc.me/imgs/image_1belf793j11fo1or618tno6ufs9.png"
alt="MapReduce与EM" />
<figcaption aria-hidden="true">MapReduce与EM</figcaption>
</figure>
<p>对于 ML 过程只需要一个 mapper 和 一个 reducer 即可，上面从 reducer
经过 model 返回到 mapper 的过程代表 EM 的迭代过程。</p>
<p>这样刻画的好处使得在 mapper 中仅仅生成比较紧凑的统计量,
其<strong>大小正比于模型参数量,
与数据量无关</strong>；同时这样的流程可以抽象出来,
而具体的模型算法只需要关注统计量计算和更新两个函数。</p>
<p>但是对于需要迭代的算法，MapReduce 需要与 HDFS
进行多次交互从而导致性能不佳，而这也是 Spark
等框架致力于解决的问题之一。</p>
<h3 id="mapreduce-的多种实现方式">MapReduce 的多种实现方式</h3>
<p>MapReduce提供了多样的编程接口，除了上面介绍的直接通过 Java
写MapReduce程序外；通过 Streaming 可以利用标准输入输出模拟以上
pipeline；而通过Pig只需关注数据逻辑，无须考虑M/R实现</p>
<p>Hadoop 的 Streaming 模拟 Pipe 方式执行Map/Reduce Job,
并利用标准输入/输出调度数据；<strong>开发者可以使用任何编程语言实现map和reduce过程,
只需要从标准输入读入数据, 并将处理结果打印到标准输出</strong>.</p>
<p>其限制是只支持文本格式数据, 数据缺省配置为每行为一个Record,
Key和value之间用<code>\t</code>分隔,如生成大量文本上的字典可通过下面的linux命令模拟map操作和reduce操作</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">map：   awk  <span class="string">&#x27;&#123;for (i=1; i &lt;=NF; i ++)&#123;print $i&#125;&#125;&#x27;</span></span><br><span class="line">reduce: <span class="built_in">uniq</span></span><br></pre></td></tr></table></figure>
<p>Pig 通过类SQL操作在Hadoop上进行数据处理，如下是一段 pig 代码实例：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Users = load ‘users’ as (name, age); </span><br><span class="line">Fltrd = filter Users by </span><br><span class="line">    age &gt;= 18 and age &lt;= 25; </span><br><span class="line">Pages = load ‘pages’ as (user, url); </span><br><span class="line">Jnd = join Fltrd by name, Pages by user; </span><br><span class="line">Grpd = group Jnd by url; </span><br><span class="line">Smmd = foreach Grpd generate group, </span><br><span class="line">    COUNT(Jnd) as clicks; </span><br><span class="line">Srtd = order Smmd by clicks desc; </span><br><span class="line">Top5 = limit Srtd 5; </span><br><span class="line">store Top5 into ‘top5sites’;</span><br></pre></td></tr></table></figure></p>
<p>Pig 解释器会进行整体规划以减少总的map/reduce次数，而如果需要通过 Java
来写 MapReduce 程序的话，会非常冗长，如下所示是实现相同功能的 MR
代码</p>
<figure>
<img src="https://wulc.me/imgs/image_1belg5n9m11kd1pni1krdb6d1220m.png"
alt="naive java code" />
<figcaption aria-hidden="true">naive java code</figcaption>
</figure>
<p>pig 常用的一些语句如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1belga1ij1tn01nov1ota1kmr9a1g.png"
alt="pig常用语句" />
<figcaption aria-hidden="true">pig常用语句</figcaption>
</figure>
<p>Hadoop上还有一个工作流引擎：Oozie，用于连接多个Map/reduce Job,
完成复杂的数据处理，处理各Job以及数据之间的依赖关系（可以依赖的条件：数据,时间,其他Job等);
Oozie使用hPDL(一种XML流程语言)
来定义DAG工作流。这里需要注意的是<strong>工作流引擎在线上环境中非常重要，原因是当执行任务多了以后，任务间的关系依赖关系不能出错，否则会带来各种意想不到的后果。</strong></p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告笔记(3)--受众定向</title>
    <url>/2017/04/28/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0(3)--%E5%8F%97%E4%BC%97%E5%AE%9A%E5%90%91/</url>
    <content><![CDATA[<p>这一讲主要介绍了受众定向的概念和若干种定向的方法。</p>
<h2 id="受众定向概念">受众定向概念</h2>
<p>受众定向是目前广告系统的核心部分，要做的就是根据人群划分进行广告售卖和优化。</p>
<p>受众定向可以认为是为
AUC（Ad，User，Context）打标签的过程，上下文标签可以认为是即时受众标签，如下所示是AUC上的标签类别</p>
<span id="more"></span>
<figure>
<img src="https://wulc.me/imgs/image_1bemrnn561kk85bhka521jii9.png"
alt="AUC上的标签系统" />
<figcaption aria-hidden="true">AUC上的标签系统</figcaption>
</figure>
<p>标签的两大主要作用 1.
建立面向广告主的流量售卖体系，注意这些特征需要有具体的意义才能展现给广告主，一般通过事先定义而不是通过文本聚类方法获取
2. 为各估计模块(如CTR预测)提供原始特征</p>
<p>下图的定向方式从右到左效果逐渐变好，从上到下表示不同阶段的定向方式；</p>
<figure>
<img src="https://wulc.me/imgs/image_1bi17ii0n2qr1s3169rersvho1t.png"
alt="定向方式" />
<figcaption aria-hidden="true">定向方式</figcaption>
</figure>
<p>上图中的 <span class="math inline">\(f(u)\)</span>, <span
class="math inline">\(f(c)\)</span>, <span
class="math inline">\(f(a,u)\)</span> 含义如下：</p>
<p><span
class="math inline">\(f(u)\)</span>：用户标签，即根据用户历史行为给用户打上的标签
<span
class="math inline">\(f(c)\)</span>：上下文标签，即根据用户当前的访问行为得到的即时标签
<span
class="math inline">\(f(a,u)\)</span>：定制化标签，也是一种用户标签，但是是针对某一广告主而言</p>
<p>除了上面提到的三种标签还有一中标签 <span
class="math inline">\(f(a)\)</span>
表示广告标签，便于与上下文标签或用户标签做匹配。广告标签常常有两种选择
1）直接将广告投放中的广告主、广告计划、广告组、关键词等直接作为标签
2）用人工的方式归类</p>
<p>除此之外，各种定向方式中的数字表示该方式有利于某个个阶段需要遵循的原则，各个阶段及其需要遵循原则如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bi0joe626h46ri1vhc137216o9m.png"
alt="各阶段主要原则" />
<figcaption aria-hidden="true">各阶段主要原则</figcaption>
</figure>
<p>各种定向方式含义如下所示：
<strong>重定向</strong>：如果用户曾经访问过广告主的网站，就会给用户推该广告主的广告。（品牌广告较为常用）
<strong>上下文</strong>：用户目前浏览的网页内容相关的广告
<strong>行为</strong>：根据用户的历史行为进行推荐
<strong>网站/频道</strong>：根据网站的属性投放与该网站内容相关的某一领域的广告（如汽车广告）
<strong>Hyper-local</strong>：将定位做得更细（如定位到某条街道的小饭馆，一般在移动广告较容易实现）
<strong>Look-alike</strong>：一般来说重定向的量比较少，该方式可以找到与广告主提供的种子用户相似的用户进行广告投放
<strong>人口属性</strong>：人口，性别，教育水平，收入水平等，主要给广告商看，效果不是很好
<strong>地域</strong>：主要给广告商看，效果不是特别好</p>
<p>下面介绍一下audience targeting 在业界的一种商业模式</p>
<p>Audience Science 是一个做audience
targeting的第三方发公司，其核心业务有两个：</p>
<ol type="1">
<li>主要提供面向publisher（如NewYork
Times）的数据加工服务，从publisher提供的数据中提取出用户标签供 publisher
使用</li>
<li>直接运营ad
network，并帮助广告主进行campaign管理和优化；该过程中会通过上面提取出来的用户标签优化效果，同时使用标签创造的营收按照一定比例跟publisher分成</li>
</ol>
<h2 id="行为定向">行为定向</h2>
<p>根据用户的历史行为给用户打上标签(上面提到的<span
class="math inline">\(f(u)\)</span>)，下面是九种重要原始行为(按信息强度排序，往往强度越大，量越少)</p>
<ol type="1">
<li>Transaction, 就是用户购买行为</li>
<li>Pre-transaction, 用户购买前的一些行为，如商品浏览、加入购物车等</li>
<li>Paid search click, 搜索广告中的点击行为</li>
<li>Ad click, 广告的点击行为</li>
<li>Search click, 搜索引擎上的点击行为</li>
<li>Search, 搜索引擎上的搜索行为</li>
<li>Share, 分享行为，如微博等</li>
<li>Page View,
浏览页面的行为，注意这个页面不是上面搜索出来的页面，而是用户在某个站点中只能看到的页面（如贴吧），量大但是效果一般</li>
<li>Ad view，看某个广告的次数，但是带来的效果往往是负面的</li>
</ol>
<p>行为定向计算的一种方式如下 (<span
class="math inline">\(t^{(i)}(u)\)</span>表示用户 <span
class="math inline">\(u\)</span> 在标签 <span
class="math inline">\(i\)</span> 上的强度)</p>
<figure>
<img src="https://wulc.me/imgs/image_1ben0lcj01qsn1j1m2ji1o9a11ao1g.png"
alt="定向行为计算" />
<figcaption aria-hidden="true">定向行为计算</figcaption>
</figure>
<p>上面的方式比较简单，但是在海量数据中首先要做的是shallow的挖掘。</p>
<p>行为定向的还有其他一些问题：如 session log 和 long-term 行为定向</p>
<p><strong>Session log</strong></p>
<p>session log 关系到怎么从日志文件中提取出所需数据，有以下两点建议</p>
<ol type="1">
<li>将各种行为日志整理成<strong>以用户ID为key的形式</strong>，完成作弊和无效行为标注，作为各数据处理模块的输入源</li>
<li>可以将targeting变成<strong>局部计算</strong>，大大方便整个流程</li>
</ol>
<p><strong>Long-term 行为定向</strong></p>
<p>Long-term
行为定向指的是如何从用户的长期行为中提取出用户的标签，常用的有两种方法：滑动窗口方式和时间衰减方式。</p>
<p>滑动窗口方式：直接将前面 <span class="math inline">\(T\)</span>
天的行为标签进行相加。下面的公式中 <span
class="math inline">\(f\)</span> 为 long-term 标签，下标为日期</p>
<p><span class="math display">\[f\_d^{(i)}(u) = \sum\_{j=0}^T
t\_{d-j}^{(i)}(u)\]</span></p>
<figure>
<img src="https://wulc.me/imgs/image_1ben1h50a2kf1kou1rea1qad1l7e1t.png"
alt="滑动窗口方式" />
<figcaption aria-hidden="true">滑动窗口方式</figcaption>
</figure>
<p>时间衰减方式：按照时间衰减方式，对前n天的标签进行相加，时间越长，权重越小。这种方式<strong>空间复杂度低</strong>，仅需昨天的
<span class="math inline">\(f\)</span> 和今天的 <span
class="math inline">\(t\)</span></p>
<p><span class="math display">\[f\_d^{(i)}(u) = t\_{d}^{(i)}(u) + \alpha
f\_{d-1}^{(i)}(u)\]</span></p>
<figure>
<img src="https://wulc.me/imgs/image_1ben1i4ub15gve341f251kp89b92a.png"
alt="指数衰减方式" />
<figcaption aria-hidden="true">指数衰减方式</figcaption>
</figure>
<p>实际中上面两种方法的效果差异不大，但是时间衰减方式的计算代价较小。<span
class="math inline">\(T\)</span> 的选择与实际商品相关，如汽车的 <span
class="math inline">\(T\)</span> 往往较大，而运动鞋的 <span
class="math inline">\(T\)</span>
往往不大，目前这个值主要是根据经验来设。</p>
<p><strong>如何评判为用户打的标签？</strong></p>
<p>受众定向评测可以借助Reach/CTR曲线，该曲线如下所示，横轴表示reach到的用户，纵轴表示广告点击率</p>
<figure>
<img src="https://wulc.me/imgs/image_1ben1to0fpsr1unj1aao66qu232n.png"
alt="Reach/CTR曲线" />
<figcaption aria-hidden="true">Reach/CTR曲线</figcaption>
</figure>
<p>上图从左到右阈值设置逐渐变小，设为0时，可以reach到所有人，但是这个时候就相当于无定向投放了</p>
<p>注意拐点以及该曲线是否服从一个递减的趋势；如果不是递减，可能标签没意义，而拐点可以知道设置在哪一个值能够将有更强的购买倾向的人群与其他人群分开。</p>
<h2 id="上下文定向">上下文定向</h2>
<p>上下文定向指的是根据用户的访问内容给用户打标签 (上面提到的 <span
class="math inline">\(f(c)\)</span>)，这样的定向中有一些根据广告请求中的参数经过简单运算就可以得到，如地域定向，频道/URL
定向、操作系统定向等。另外一类则是根据上下文页面的一些特征标签，如关键词、主题、分类等进行定向，下面重点讨论这种上下文定向方式。</p>
<p>上下文定向（打标签）主要有以下几种思路：
1）用规则将页面归类到一些频道或主题分类，如将 auto.sohu.com
归类到“汽车”的分类中 2）提取页面的关键词
3）提取页面的入链锚文本中的关键词，这需要一个全网的爬虫作支持
4）提取网页流量来源中的搜索关键词，这种方法除了页面内容，也需要页面访问的日志数据作支持
5）用主题模型将页面内容映射到语义空间的一组主题上</p>
<h3 id="半在线抓取系统">半在线抓取系统</h3>
<p>确定了对上下文页面打标签的方法后，在在线广告投放时，页面标签系统需要某个查询
url
返回其对应的标签。在广告系统中，可以通过<strong>半在线(Near-line)上下文定向系统</strong>实现这个事情，如下就是一个
Near-line 上下文定向系统</p>
<figure>
<img src="https://wulc.me/imgs/image_1ben5m1qh1idkc571i9v1n21u3p34.png"
alt="near-line 上下文定向系统" />
<figcaption aria-hidden="true">near-line 上下文定向系统</figcaption>
</figure>
<p>该系统用一个缓存(Redis)来保存每个 URL
对应的标签，当在线广告请求到达的时候，执行如下操作</p>
<ol type="1">
<li>如果请求的上下文 URL 在缓存中存在，直接返回其对应的标签</li>
<li>如果 URL
在缓存中不存在，为了广告请求能够及时得到处理，立刻返回空的标签集合，同时向后台的抓取队列中加入此
URL 进行抓取和存储</li>
<li>考虑到页面的内容会不定期更新，可以设置缓存合适的 TTL 以自动更新 URL
对应的标签</li>
</ol>
<p>步骤 2
中能够返回空标签的原因是在广告系统中，某一次展示时标签的缺失带来的影响是可以忍受的，因为对于广告系统而言，这部分只是起到一个锦上添花的作用。</p>
<h3 id="主题模型">主题模型</h3>
<p>除了直接提取页面内容的关键词作为页面的特征以外，还可以通过主题模型（Topic
models）这一类模型对文本进行聚类得到文本的主题分布情况。</p>
<p>主题模型分两大类：<strong>有监督和无监督的</strong>。有监督指的是预先定义好主题的集合，用监督学习的方法将文档映射到这一集合的元素上；无监督指的是不预先定义主题集合，而是控制主题的总个数或聚类程度，用非监督的方法自动学习出主题集合以及文档到这些主题的映射函数。</p>
<p>广告中的主题挖掘有两种用途</p>
<ol type="1">
<li>用于广告效果优化的特征提取</li>
<li>用于售卖给广告主的标签体系</li>
</ol>
<p>对于第一种用途,
用有监督或非监督的方法都可以；对于第二种用途，应该优先考虑采用监督学习的方法，因为这样可以预先定义好对广告主有意义而且可解释的标签体系。下面先介绍非监督方法，再介绍监督方法。</p>
<p><strong>非监督方法</strong></p>
<p>非监督的主题模型的发展经历了 <strong>LSA -&gt; PLSA -&gt;
LDA</strong> 的过程，下面简单介绍这三种模型。</p>
<p>LSA(Latent Semantic Analysis) 有时也叫 LSI(Latent Semantic
Indexing)，这种方法实际上是将 SVD 分解应用到了 “文本-单词”
矩阵中，即</p>
<p><span class="math display">\[X \approx U \Sigma V^T\]</span></p>
<p><span class="math inline">\(X\)</span>
矩阵中的值有多种选择：0-1，出现次数，TF-IDF值。则 <span
class="math inline">\(U\)</span>
矩阵的一行对应的就是一篇文本在各个主题上的分布， <span
class="math inline">\(V\)</span>
矩阵每行对应的就是一个单词在各个主题上的分布，而选择奇异值的个数则决定了隐含主题的个数，也就是代表文本或词语的向量的维度。通过比较向量间的余弦相似性，便可比较文本或单词间的相似性。</p>
<p>这样的方法虽然直观，但是有几个问题，一是分解后矩阵 <span
class="math inline">\(U\)</span>、<span class="math inline">\(V\)</span>
中可能存在着负值，二是这些数值在概率上没有意义。为了解决这些问题，便提出了PLSA。</p>
<p>PLSA(Probabilistic Latent Semantic
Analysis)可以说是概率化了的LSA，但是采用的方法与 LSA 完全不同，PLSA
没有涉及到 SVD，而是采用混合模型的做法。</p>
<p>PLSA
方法假设文本包含多个主题，这些主题服从多项式分布，而每个主题下的有多个词，这些词也服从多项式分布。假设有
M 篇文档，每篇文档有 N 个词，则生成这 M
篇文档的过程通过有向图模型表示如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bi41ptsp1junofgd5satp1d3dm.png"
alt="PLSA" />
<figcaption aria-hidden="true">PLSA</figcaption>
</figure>
<p>在有向图模型中，灰色的点表示能够观察到的点，其他白色的点表示需要求解的点，而最后需要求解的点是没有入度的点，其他的有入度和出度的点会被积分积掉，框及其框内符号表示框里面的内容重复若干次</p>
<p>而上图中 <span class="math inline">\(d\)</span> 表示文本，<span
class="math inline">\(c\)</span> 表示主题， <span
class="math inline">\(w\)</span> 表示词语，且文本 <span
class="math inline">\(d\)</span> 中生成词语 <span
class="math inline">\(w\_i\)</span> 的概率是</p>
<p><span class="math display">\[P(w\_i|d) = \sum\_c P(c|d)
P(w\_i|c)\]</span></p>
<p>其中 <span class="math inline">\(P(c|d)、
P(w|c)\)</span>均服从多项式分布</p>
<p>则整篇文本生成的概率为</p>
<p><span class="math display">\[P(d) = \prod\_i P(w\_i|d) \]</span></p>
<p>这个模型跟混合高斯模型（mixture of
Gaussian）非常相似，都是融合了多个指数族分布的模型，这一类模型也可以称为混合模型，而求解这一类的问题的方法便是
EM 算法，这里不详细展开。除此之外，假如将上面 PLSA
中文本主题服从的多项式分布改为伽马分布，将主题下的词语服从的多项式分布改为泊松分布，那么
PLSA 就变为了GaP(Gamma-Poisson)模型。</p>
<p>LDA(Latent Dirichlet Allocation) 则是在 PLSA
的基础上为其两个多项式分布加上了贝叶斯先验, 先验选为 Dirichelet
分布，原因是更多是数学上的便利性，因为Dirichelet 是 multinational
的共轭先验，容易求解。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bi59lp0fpu112r111hoq6m1d702a.png"
alt="LDA" />
<figcaption aria-hidden="true">LDA</figcaption>
</figure>
<p>上图中 <span class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\beta\)</span> 表示参数为 <span
class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\beta\)</span>
的狄利赫里分布，这两个分布分别是文本的主题概率分布和主题下词语的概率分布的先验分布。文本的主题概率分布的先验分布为</p>
<p><span class="math display">\[ \theta\_i \sim Dir(\alpha),~i=1, 2...M
\]</span></p>
<p><span class="math inline">\(\theta\_i\)</span> 表示第 <span
class="math inline">\(i\)</span> 篇文档的主题分布，而 <span
class="math inline">\(\theta\_{i,k}（k=1,2...K）\)</span> 表示第 <span
class="math inline">\(i\)</span> 篇文档中包含第 <span
class="math inline">\(k\)</span> 个主题的概率</p>
<p>而主题下的词语的概率分布的先验分布为</p>
<p><span class="math display">\[ \phi \_k \sim Dir(\beta),~k=1,2...K
\]</span></p>
<p><span class="math inline">\(\phi\_k\)</span> 表示第 <span
class="math inline">\(k\)</span> 个主题下的词语分布，而 <span
class="math inline">\(\phi\_{k,j}（j=1,2...V）\)</span> 表示第 <span
class="math inline">\(k\)</span> 个主题中包含第 <span
class="math inline">\(j\)</span> 个词的概率，<span
class="math inline">\(V\)</span> 为语料库的词表的大小</p>
<p>确认先验分布后，文档中的主题分布以及主题下的词语分布均服从多项式分布，与
PLSA 相同，求解 LDA 得思路是先求解出其最终的联合概率分布，然后通过 Gibbs
Sampling 收敛到该概率。</p>
<h3 id="经验贝叶斯empirical-bayes11">经验贝叶斯(<a
href="https://en.wikipedia.org/wiki/Empirical_Bayes_method">Empirical
Bayes</a>)</h3>
<p>如下图模型, 如何确定hyperparameter <span
class="math inline">\(\eta\)</span>?</p>
<figure>
<img src="https://wulc.me/imgs/image_1bep1f616m1h1k4e1jtl1tp61jrn13.png"
alt="经验贝叶斯" />
<figcaption aria-hidden="true">经验贝叶斯</figcaption>
</figure>
<p>用 Empirical Bayes 估计的解为：<span class="math display">\[\widehat
\eta = arg \max\_{\eta} \int
\prod\_{k=1}^{K}p(D\_k|\theta\_k)p(\theta\_k|\eta)d\theta\_k\]</span></p>
<p>当 <span class="math inline">\(p(x|\theta)\)</span>
为指数族分布，<span class="math inline">\(p(\theta|\eta)\)</span>
为其共轭先验时，可用EM求解, 其中E-step为Bayesian inference过程, 由 <span
class="math inline">\(\eta^{old}\)</span> 得到后验参数 <span
class="math inline">\(\widetilde \eta\_k^{old}\)</span> ,
而M-step为:<span class="math display">\[(\theta,
ln[g(\theta)])\_{\eta^{new}} = \frac{1}{K}\sum\_{k=1}^{K}(\theta,
ln(g(\theta)))\_{\widetilde \eta\_k^{old}}\]</span></p>
<h3 id="从经验贝叶斯看lda">从经验贝叶斯看LDA</h3>
<p>LDA可以视为PLSI的经验贝叶斯版本，由于PLSI不是指数族分布，而是其混合分布，因此其贝叶斯版本不能使用前面的EM算法。工程上常用的求解方法有两种：Deterministic
inference 和 Probabilistic inference</p>
<p><strong>Deterministic inference</strong>：
可用变分近似，假设z和θ的后验分布独立迭代求解过程与EM非常相似，称为VBEM，但是在大多数问题上无法保证收敛到局部最优</p>
<p><strong>Probabilistic inference</strong>:
可用Gibbs-sampling(Markov-chain Monte-Carlo, MCMC
的一种)，以概率1收敛到局部最优值；还有一种方法是 Collapsed
Gibbs-sampling</p>
<h3 id="topic-model的并行化">Topic model的并行化</h3>
<ul>
<li>EM及VBEM的并行化较为简单
<ul>
<li>E-step(mapper): 可以方便地并行计算</li>
<li>M-step(reducer): 累加E-step各部分统计量后更新模型</li>
<li>将更新后的模型分发到新的E-step各个计算服务器上</li>
</ul></li>
<li>AD-LDA: Gibbs Sampling的并行化
<ul>
<li>Mapper: 在部分data上分别进行Gibbs sampling</li>
<li>Reducer: 全局Update</li>
</ul></li>
</ul>
<p><span class="math display">\[n\_{i,j} \leftarrow
n\_{i,j}+\sum\_p(n\_{i,j,p} - n\_{i,j}),~n\_{i,j,p}\leftarrow
n\_{i,j}\]</span></p>
<p>文档的Topic
model抽取可以认为是一个大量(而非海量)数据运算，采用类MPI架构的分布式计算架构(例如spark)会比
MapReduce 效率更高</p>
<p>虽然LDA能够聚类，但是supervisord learning 对标签体系更有意义。</p>
<h2 id="数据加工和交易">数据加工和交易</h2>
<p>精准的广告业务是什么？下面的图将数据的加工过程类比于石油的加工和提炼的过程，在这个过程中，实际上与媒体的关系已经不大了。</p>
<figure>
<img src="https://wulc.me/imgs/image_1ben9omrm1ko71qrkp2kl6u13bc4o.png"
alt="精准广告业务" />
<figcaption aria-hidden="true">精准广告业务</figcaption>
</figure>
<h3
id="精准广告业务的若干值得探讨的观点">精准广告业务的若干值得探讨的观点</h3>
<ul>
<li>越精准的广告，给市场带来的价值越大</li>
<li>媒体利益与广告主利益是相博弈的关系</li>
<li>精准投放加上大数据可以显著提高营收</li>
<li>人群覆盖率较低的数据来源是不需要的（长尾？）</li>
<li>不同的广告产品应该采用不同的投放机</li>
</ul>
<h3 id="有价值的数据">有价值的数据</h3>
<p>下面列出了一些在广告系统中有价值的数据</p>
<ul>
<li>用户标识
<ul>
<li>除上下文和地域外各种定向的基础，需要长期积累和不断建设</li>
<li>可以通过多家第三方ID绑定不断优化</li>
</ul></li>
<li>用户行为
<ul>
<li>业界公认有效行为数据（按有效性排序）</li>
<li>交易，预交易，搜索广告点击，广告点击，搜索，搜索点击，网页浏览，分享，广告浏览</li>
<li>需去除网络热点话题带来的偏差</li>
<li>越靠近demand的行为对转化越有贡献</li>
<li>越主动的行为越有效</li>
</ul></li>
<li>广告商(Demand)数据
<ul>
<li>简单的cookie植入可以用于retargeting。</li>
<li>对接广告商种子人群可以做look-alike，提高覆盖率。</li>
</ul></li>
<li>用户属性和精确地理位置
<ul>
<li>非媒体广告网络很难获取，需通过第三方数据对接。</li>
<li>移动互联和HTML5为获得地理位置提供了便利性。</li>
</ul></li>
<li>社交网络
<ul>
<li>朋友关系为用户兴趣和属性的平滑提供了机会</li>
<li>实名社交网络的人口属性信息相对准确</li>
</ul></li>
</ul>
<h3 id="数据管理平台data-management-platform">数据管理平台(Data
Management Platform)</h3>
<ul>
<li>目的:
<ul>
<li>为网站提供数据加工和对外交易能力(如Audience Science)</li>
<li>加工跨媒体用户标签，在交易市场中售卖</li>
<li>是否应直接从事广告交易存在争议</li>
</ul></li>
<li>关键特征:
<ul>
<li>定制化用户划分</li>
<li>统一的对外数据接口：demand端提供给supply端</li>
</ul></li>
<li>代表:
<ul>
<li>Bluekai, AudienceScience</li>
</ul></li>
</ul>
<p>DMP的系统架构示意图如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1benb74qa1au91vh21t2b1kifi55.png"
alt="DMP架构" />
<figcaption aria-hidden="true">DMP架构</figcaption>
</figure>
<p>DMP主要是Data highway部分，主要完成两个工作： 1. 挖掘出各个用户的标签
2. 利用挖掘出来的用户的标签，售卖或使用</p>
<p>这里介绍一个Data Highway 的工具：<strong>Scribe</strong></p>
<ul>
<li>大规模分布式日志收集系统，可以准实时收集大量日志到
HDFS，利用Thrift实现底层服务</li>
<li>类似工具: Flume, Chukwa</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/image_1bep5kb521id3iav1vlo7dcl3a9.png"
alt="scribe" />
<figcaption aria-hidden="true">scribe</figcaption>
</figure>
<p>这个工具在 Facebook 经过实践，验证了其面对大规模数据时的可靠性。</p>
<p>下面介绍一下audience targeting 在业界的一种商业模式
上面提到了Bluekai这个公司，其核心业务主要有以下两个：</p>
<ol type="1">
<li>为中小网站主提供数据加工和变现的方式</li>
<li>通过汇聚众多中小网站用户资料和行为数据，加工成受众定向标签，通过Data
exchange对外售卖</li>
</ol>
<p>Bluekai
提供大量细分类别、开放体系上的标签，如“对宝洁洗发水感兴趣的人”，“想去日本旅游的人”；靠数据出售变现，并与提供数据的网站主分成，但是并不直接运营广告业务；对于设计用户隐私的问题，用户可以看到自己的资料被谁使用，也可以选择“捐给慈善机构”</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告笔记(4)--竞价广告系统</title>
    <url>/2017/05/07/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0(4)--%E7%AB%9E%E4%BB%B7%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>本文是刘鹏老师的<a
href="http://study.163.com/course/courseMain.htm?courseId=321007">计算广告学</a>中的一些笔记。本文是第四章:
竞价广告系统。主要介绍竞价系统理论，广告网络的概念，以及点击率预测设计到的一些技术。</p>
<span id="more"></span>
<p>合约广告系统两个核心问题：在线分配和受众定向。</p>
<p>竞价广告系统是广告系统发展的里程碑。从搜索引擎的关键词
的竞价延伸到展示广告，标签精细化的必然发展。</p>
<p>不保量，但是保质，量由 demand 端的 agency 保证。</p>
<h2 id="竞价系统理论">竞价系统理论</h2>
<p>竞价广告系统可以被描述成一个位置拍卖问题(Position
auctions)，该问题描述如下</p>
<ol type="1">
<li>该问题要解决的是将广告对象 $ a = , 2, … A $ 排放到位置 $ s = , 2, …,
S $，这里的位置主要针对搜索广告而言</li>
<li>假设对象 <span class="math inline">\(a\)</span> 的出价(bid)为 <span
class="math inline">\(b\_a\)</span> , 而其对位置 <span
class="math inline">\(s\)</span> 的计价为 <span
class="math inline">\(u\_{as} = v\_ax\_s ,(x\_1&gt;x\_2
&gt;…&gt;x\_S)\)</span>， <span class="math inline">\(v\_a\)</span>
视为点击价值，<span class="math inline">\(x\_s\)</span>
视为点击率，该模型可近似描述广告系统竞价问题(对显示广告，可以认为S =
1，但是与搜索广告的不同点在于搜索广告可以一个都不出，而显示广告至少要出一个)</li>
<li>可以将问题描述成一个对称纳什均衡(Symmetric Nash equilibrium)
其目标是 $(v_s – p_s)x_s &gt;= (v_s – p_t)x_t $, 其中 <span
class="math inline">\(p\_t = b\_{s+1}\)</span>,这里的 <span
class="math inline">\(p\_s\)</span>
表示根据广告的位置实际的收费情况，<span
class="math inline">\(b\_{s+1}\)</span> 在位置 <span
class="math inline">\(s+1\)</span>
的广告的出价；寻找收入最大化且稳定的纳什均衡状态是竞价系统设计的关键</li>
</ol>
<p>上面的问题建模比较复杂，需要较多的数学推导，这里主要关注上面问题建模求解以后得到的结论：就是定价机制该如何设置。这里讲的定价机制有两种：<strong>VCG(Vickrey–Clarke–Groves)机制和广义第二高价(Generalized
second pricing)机制</strong>。</p>
<p>从理论上来讲，VCG 机制是最优的，VCG
认为某对象的收费应等于给他人带来的价值损害，而且其有一个很好的性质：整体市场是truth-telling的，也就是每个广告主只需要根据自己真实想法出价，避免广告主间的博弈。</p>
<p>但是实际的定价机制是广义第二高价，就是每个位置收取的费用是其下一个位置的出价加1（比下一个位置高即可）即
<span class="math display">\[p\_s = b\_{s+1} + 1\]</span>
这种做法看似会降低收益，但是实际上与VCG机制相比，会收取广告主更多的费用。关于原因，视频讲解时给了一个例子
&gt;假如说现在第一高价的广告是5块，第二高价的是3块。
&gt;假如采用第一高价的机制，那么出了第一高价的广告主就会设法调低自己的价格，比如说调到3块1毛，因为这时候仍然可以拿到第一位且支出更少，而如果再来一个人要第一的广告位，那么他可能就会调到3块2；
&gt;而采用第二高价的时候，出了第一高价的广告主不会设法调低自己的价格，因为收取的是第二高价的价格，而此时如果来了一个想要第一的广告位的广告主，那么他出的价格必须要在5元以上了</p>
<p>广义第二高价的整体市场不是truth-telling的，从上面的例子也可看到，商家之间会存在着博弈，但是由于其简单易行，为在线广告系统广泛采用，而VCG则用得较少</p>
<h2 id="广告网络ad-network">广告网络(Ad Network)</h2>
<p>维基百科对广告网络的定义如下： &gt;Connects advertisers to web sites
that want to host advertisements</p>
<p>在竞价广告系统中，其主要的特征有：</p>
<ul>
<li>竞价系统(Auction system)</li>
<li>淡化广告位概念：卖的是人群，而不是媒体，媒体已经变成了一个载体</li>
<li>最合适的计价方式为CPC（Cost Per Click）:
非实时竞价方式，广告网络估计CTR，广告主估计每个广告的价值</li>
<li>不足：不易支持定制化用户划分：广告主只能购买广告网络指定的关键词</li>
</ul>
<p>广告网络的系统架构示意如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf0nmt3b1ommui91hkvt1pja9.png"
alt="广告网络架构" />
<figcaption aria-hidden="true">广告网络架构</figcaption>
</figure>
<p>该架构的工作原理大致如下： 1. <code>User</code>
开始浏览某个页面时，<code>Ad retrieval</code> 根据 <code>User</code> 的
<code>User Attributes</code> 和页面的 <code>Page Attributes</code> 从
<code>Ad Index</code>
中找到相关的广告(如果有广告主将广告新加进来时，也要通过
<code>Real-time indexing</code> 将广告加入 <code>Ad Index</code> 中) 2.
对相关广告根据 eCPM 进行排序，由于点击的 value
已经由广告主决定，这时只需要预估点击率即可。 3.
进行排序后需要将排序的结果及其用户后续的点击行为记录到日志中，从而便于改进点击率预估模型，同时通过流式计算平台进行反作弊监测以及对广告主收费（如果用户有点击行为的话）。</p>
<p>下面要介绍以上广告网络中提到的一些技术，</p>
<h2 id="广告检索ad-index">广告检索(Ad Index)</h2>
<p>规模较大的时候才用。检索是一种搜索技术，这里主要介绍<strong>两个重点：布尔表达式检索和长Query情况下的相关性检索</strong>。</p>
<p><strong>布尔表达式检索</strong>
将每篇文档看做一个布尔表达式，同时将每个查询也看做一个布尔表达式。</p>
<p>如下面是一个表示文档的布尔表达式</p>
<figure>
<img src="https://wulc.me/imgs/image_1bfgdlkaf1qak17g091h7k61is8m.png"
alt="boolean" />
<figcaption aria-hidden="true">boolean</figcaption>
</figure>
<p>只有当文档满足查询的布尔表达式条件时，才能出这个广告，为了加快这个检索过程，布尔表达式检索通过建立两层索引来实现加速。其涉及到的一些概念和具体方法如下(摘自PPT）</p>
<figure>
<img src="https://wulc.me/imgs/image_1bfgds6l21a3612tjrdcjim14cd13.png"
alt="b1" />
<figcaption aria-hidden="true">b1</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1bfgdu07595q1lcnob94if14lu1t.png"
alt="b2" />
<figcaption aria-hidden="true">b2</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1bfgdudgo3bnqsqmv01luqt7i2a.png"
alt="b3" />
<figcaption aria-hidden="true">b3</figcaption>
</figure>
<p>长 Query
情况下的相关性检索指的是当查询的布尔表达式中的条件较多时，如果采用传统的搜索引擎的搜索方法，会导致计算量非常大，这里提供的思路是：<strong>在查找候选文档的过程中做一个近似的评估，切掉那些理论上不需要再考虑的文档，只对进候选的文档进行相关性计算，比Top-N最小堆最小值大的插入</strong></p>
<p>采用的具体算法是WAND算法，其细节如下（摘自PPT）</p>
<figure>
<img src="https://wulc.me/imgs/image_1bfge9mqrt061s24esg10381b8i2n.png"
alt="WAND" />
<figcaption aria-hidden="true">WAND</figcaption>
</figure>
<h2 id="一致性问题">一致性问题</h2>
<h3 id="zookeeper">Zookeeper</h3>
<p>Zookeeper
是在基于消息传递通信模型的分布式环境下解决一致性问题的基础服务</p>
<p>用层次式Namespace维护同步需要的状态空间</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf8gbr9c1bqd13151j4d1nsid829.png"
alt="zk1" />
<figcaption aria-hidden="true">zk1</figcaption>
</figure>
<p>保证实现特性：Sequential Consistency, Atomicity, Single System Image,
Reliability,
Timeliness，较复杂的同步模式需要利用API编程实现。Zookeeper的实现利用了Paxos算法。</p>
<h3 id="paxos-算法概念">Paxos 算法概念</h3>
<p>目的是解决分布式环境下，怎么分布式地决策某些状态使得所有机器都处于一致性。</p>
<p><strong>节点角色</strong>： P(roposer): (提出提案(n, value)),
A(cceptor), L(earner)</p>
<p><strong>三个约束</strong>： 1. value只有在被提出后才能被批准 2.
在一次算法的执行实例中，只批准一个value 3.
learners只能获得被批准的value</p>
<p><strong>准备阶段</strong> 1. P选择某提案编号n并将
prepare请求发给A中的某多数派； 2.
A收到消息后，若n大于它已经回复的所有消息，则将自己上次接受的提案回复给P，并承诺不再回复小于n的提案；</p>
<p><strong>批准阶段</strong>： 1.
当P收到了多数A回复后，进入批准阶段。它要向回复请求的 A发送 accept
请求，包括编号 n 和根据约束决定的 value 2.
在不违背向其他P的承诺的前提下，A收到请求后即接受。</p>
<h2 id="点击率预测">点击率预测</h2>
<p>从广告检索出相关的广告后，需要根据 eCPM
对相关广告进行排序，由于出价由广告主决定，因此实际中需要估算的往往是广告的点击率。</p>
<p>基于统计的模型</p>
<p><span class="math display">\[ u(a,u,c) = p(click|a,u,c)\]</span></p>
<p>在这个问题上，Regression比Ranking合适一些，因为广告的实际排序是根据eCPM，而eCPM由点击率和出价相乘决定，因此需要尽可能准确估计CTR，而不仅仅是各候选的CTR排序正确</p>
<p>冷启动问题：指的是新的广告非常多，这种情况下利用广告层级结构(creative,
solution, campaign, advertiser)，以及广告标签对新广告点击率做估计</p>
<p><strong>捕获点击率的动态特性</strong>，两种方案： 动态特征:
快速调整特征 在线学习: 快速调整模型</p>
<h2 id="逻辑回归">逻辑回归</h2>
<p>逻辑回归是工程中常用的点击率预估方法。</p>
<h3 id="动态特征">动态特征</h3>
<p>在线广告的三个维度 <span class="math inline">\((u,a,c)\)</span>
上均有不同的特征，可以通过组合这些特征构造高纬特征</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf8lhie51q4h1rc6eftmgf1n352n.png"
alt="三个维度上的特征" />
<figcaption aria-hidden="true">三个维度上的特征</figcaption>
</figure>
<p>上面的组合特征均为静态特征，如果在这些组合的静态特征上加上这个特征的历史数据就变成了动态特征，和某个静态特征为“年龄为25~35且为男性”，如果这个特征的取值为在某段时间的下单量而不是单纯的0或1，那么这个特征就是一个动态特征。因此动态特征即在标签组合维度上聚合点击反馈统计作为CTR预测的特征。</p>
<p><strong>优势</strong> 1. 工程架构扩展性强，变 features 不变
model(与在线学习相比) 2. 对新 <span class="math inline">\((a, u,
c)\)</span> 组合有较强back-off能力</p>
<p>缺点 1. 在线特征的存储量大，更新要求高</p>
<p>组合维度举例:</p>
<ul>
<li>cookie(u) and creative(a)</li>
<li>gender(u) and topic(c)</li>
<li>location(u) and advertiser(a)</li>
<li>Category(a) and category(u)</li>
<li>cookie(u)</li>
<li>creative(a)</li>
<li>gender(u)</li>
</ul>
<h3 id="优化方法">优化方法</h3>
<h4 id="l-bfgs"><strong>L-BFGS</strong></h4>
<p>基于梯度的方法在工程上的收敛性不好，因为工程上的问题总是<strong>病态的</strong>。用二阶的方法，一般用
Quasi-Newton 方法。</p>
<p>BFGS (Broyden, Fletcher, Goldfarb, and Shanno)
是Quasi-Newton方法的一种，
思路为用函数值和特征的变化量来<strong>近似Hession矩阵，以保证正定性</strong>，并减少计算量。</p>
<p>BFGS方法Hession计算公式如下 (空间复杂度为 <span
class="math inline">\(O(n^2)\)</span> )：</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf8ibdkh1enm1sdn6gh6udjdf13.png"
alt="BFGS" />
<figcaption aria-hidden="true">BFGS</figcaption>
</figure>
<p>L(imited memory)-BFGS 是为了解决 BFGS 的空间复杂度问题。将 nxn
的Hession阵用下图方式加以近似(<span class="math inline">\(B\_k\)</span>
为Hession近似)</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf8ilp9l7m41pga1opf1vf83ku1g.png"
alt="Hessian近似" />
<figcaption aria-hidden="true">Hessian近似</figcaption>
</figure>
<p>这样的方法将空间复杂度降为 <span
class="math inline">\(O(nk)\)</span>, 在特征量大时比BFGS实用</p>
<p>可以非常容易地用 map/reduce
实现分布式求解，这种方法也适用于梯度法：mapper
求部分数据上的梯度，reducer 求和并更新参数</p>
<h4 id="admm"><strong>ADMM</strong></h4>
<p>Alternating Direction Method of Multipliers 的形式</p>
<p><span class="math display">\[\min f(x)+g(z)\\\
s.t. Ax + Bz = c\]</span></p>
<p>Augmented Lagrangian及迭代解法如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf8jl7lr10uq196pjs4s0hacs1t.png"
alt="ADMM" />
<figcaption aria-hidden="true">ADMM</figcaption>
</figure>
<p>上面的迭代方法也可以用下面的迭代公式描述，其效果是一致的，但是下面的描述更加简便，而且在实际中也更常用</p>
<figure>
<img src="https://wulc.me/imgs/image_1bf8jnibpk3o14g81cj1fqnna2a.png"
alt="ADMM 更一般表示方法" />
<figcaption aria-hidden="true">ADMM 更一般表示方法</figcaption>
</figure>
<p>ADMM这种迭代的解法能够很容易地通过 MapReduce 模式迭代进行求解。</p>
<p>下面介绍逻辑回归的ADMM分布式解法，这种方法将将样本划分为 N 份，每个
mapper 负责一份，其描述的最优化问题如下</p>
<p><span class="math display">\[\min \sum\_{i=1}^{N}\sigma
(w\_ix\_i)+r(z)\\\
s.t. w - z = 0\]</span></p>
<p>分布式的迭代解法入下:</p>
<p><span class="math display">\[w\_i^{k+1} \leftarrow \arg \min\_{w\_i}
(\sigma(w\_ix\_i) + \frac{\rho}{2}||w\_i - z^k + \mu\_i^k||\_2^2)\\\
z^{k+1} \leftarrow \arg \min\_{z} (r(z) + \frac{N\rho}{2}||z^k -
\overline w^{k+1}+ \overline \mu\_k||\_2^2)\\\
\mu\_i^{k+1} \leftarrow \mu\_i^k + w\_i^{k+1} - z^{k+1}
\]</span></p>
<h2 id="探索与利用explore-and-exploit-ee">探索与利用(Explore and
exploit， E&amp;E)</h2>
<p>这一问题主要是为<strong>长尾</strong>的 <span
class="math inline">\((a, u, c)\)</span>
组合创造合适的展示机会以积累统计量，从而更准确地估计其CTR</p>
<p>原因是真实的环境中，数据总是长尾的，总体集没法通过采样获得，实际上大批广告主的广告是没有机会展示，为了让更多的广告主的广告能够得到恰当的展示，需要做一些探索（即不选择当前出价最高的广告，而是选择一些符合要求的长尾广告），但是最终的目的仍是提升整体的广告收入，即需要严格控制探索的量和有效性</p>
<p><strong>基本方法思路</strong> 1. 通常描述为 Multi-arm Bandit (MAB)
问题: 有限个 arms(或称收益提供者) <span
class="math inline">\(a\)</span>, 每个有确定有限的期望收益 <span
class="math inline">\(E(r_{t,a})\)</span> 2.
在每个时刻t,我们必须从arms中选择一个,最终目标是优化整体收益 基本方法为
<span class="math inline">\(\epsilon\)</span>–greedy: 将 <span
class="math inline">\(\epsilon\)</span> 比例的小部分流量用于随机探索</p>
<p>上面的方法应用在广告中的主要挑战有：</p>
<ol type="1">
<li>海量的组合空间需要被探索</li>
<li>各个arm的期望收益是动态变化的</li>
</ol>
<p>因此提出了以下两个思路， UCB 和 Contextual Bandit</p>
<p><strong>UCB</strong>
在时刻t，通过以往的观测值以及某种概率模型,计算每个arm的期望收益的upper
confidence bound (UCB)，并选择UCB最大的arm。</p>
<p>实际上是将每个arm的收入看作一个分布，选择所有分布中可能达到最大的那个arm作为最终的选择。</p>
<p>我们不可能一直选择非最优的arm, 原因是我们选择的此arm次数越多,
其UCB就越接近于其期望收益</p>
<p>具体UCB策略有以下两种：</p>
<ol type="1">
<li>β-UCB策略: 依一个很大的概率, 我们选择非最优arms的次数存在着一个上界,
该上界与总的选择次数无关</li>
<li>UCB-tuned策略: 我们已选择的次数越多,
就越可以自信地抛弃不太有前途(但仍有可能最优)的arm.</li>
</ol>
<p><strong>Contextual Bandit</strong></p>
<p>解决 arm 数目过多问题，降维，映射到另外的特征空间</p>
<ul>
<li>对每次展示，每个 arm (广告) <span class="math inline">\(a\)</span>
有一个对应的特征矢量 <span class="math inline">\(x(u,a)\)</span></li>
<li>用此特征矢量代替 arm 本身进行 Bandit 决策</li>
</ul>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告笔记(5)--搜索广告与广告网络Demand技术</title>
    <url>/2017/05/10/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0(5)--%E6%90%9C%E7%B4%A2%E5%B9%BF%E5%91%8A%E4%B8%8E%E5%B9%BF%E5%91%8A%E7%BD%91%E7%BB%9CDemand%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p>本文是刘鹏老师的<a
href="http://study.163.com/course/courseMain.htm?courseId=321007">计算广告学</a>中的一些笔记。本文是第五章:
搜索广告与广告网络Demand技术。主要介绍搜索广告中的几个典型问题以及广告网络中demand端需要用到的技术</p>
<span id="more"></span>
<h2 id="搜索广告的特点">搜索广告的特点</h2>
<p>搜索广告与显示广告不同的特点在于</p>
<ul>
<li>用户定向标签 <span class="math inline">\(f(u)\)</span>:
远远弱于上下文影响（query），一般可以忽略</li>
<li>Session内的短时用户搜索行为作用很重要</li>
<li>上下文定向标签 <span class="math inline">\(f(c)\)</span>:
关键词</li>
</ul>
<p>搜索广告是一种典型的位置竞价模式，如下是搜索广告中常见的三种位置</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgt5kq0e1ona1hsp1m1a1mr214g1m.png"
alt="搜索广告中的位置" />
<figcaption aria-hidden="true">搜索广告中的位置</figcaption>
</figure>
<p>根据上图，可知搜索广告中的位置一般分为北，南，东三个广告区块，根据各位置的reference
ctr决定，各位置在竞价系统中的位次 reference ctr
可以通过ε流量较准确测定出</p>
<h2 id="搜索广告的典型问题">搜索广告的典型问题</h2>
<p>搜索广告中需要考虑的几个典型问题如下</p>
<ol type="1">
<li>查询词扩展(Query Expansion)</li>
<li>用户相关的搜索广告决策</li>
<li>短时用户行为反馈</li>
</ol>
<h3 id="查询词扩展query-expansion"><strong>查询词扩展(Query
Expansion)</strong></h3>
<p>目的是 supply
端为了赚取更多的利润，同时拓展了广告主的竞价范围，常见的思路有以下三种</p>
<p>（1）<strong>基于推荐的方法</strong>：挖掘(session,
query)矩阵找到相关query, 可类比(user,
item)矩阵，这种方法利用的是搜索数据
（2）<strong>基于语义的方法</strong>：用topic
model或概念化的方法中找语义相关query，这种方法利用的是其他文档数据
（3）<strong>基于收益的方法</strong>：根据实际eCPM统计得到变现能力最好的相关query，这种方法利用的是广告数据</p>
<h3
id="用户相关的搜索广告决策"><strong>用户相关的搜索广告决策</strong></h3>
<p>首先需要明确结果个性化对于搜索广告作用有限，原因是上下文信息(c)太强,
个人兴趣基本可以忽略；同时搜索页上的结果需要保证主题上某种一致性</p>
<p>但是广告展示条数是可以深度个性化的，因为约一半的用户无法明确区分广告与搜索结果，在平均广告条数的约束下，可以对每个用户的广告条数进行个性化，以最大化营收。因此这又一个约束优化问题！</p>
<p>另外可以根据同一 session
内的行为调整广告结果，如在第一页没点的广告是否要放到第二页。</p>
<h3 id="短时用户行为反馈"><strong>短时用户行为反馈</strong></h3>
<p>短时用户行为的定义如下，狭义来说是用户在一个session内的行为，广义来说是
用户在短时间(一般为一到两天)内的行为</p>
<p>通过短时用户行为反馈，可以实现： <strong>（1）短时受众定向</strong>:
根据短时行为为用户打上的标签 <strong>（2）短时点击反馈</strong>:
根据短时广告交互计算的动态特征</p>
<p>而短时用户行为计算需要准实时(分钟级)对用户行为进行加工，不适合在Hadoop上进行
可以利用<strong>流式计算(stream computing)平台</strong>,
如S4（雅虎开源的一个流式计算平台）, Storm等</p>
<h2 id="流式计算平台">流式计算平台</h2>
<p>前面提到了流式计算平台，下面以 storm 为例简单讲述</p>
<p>Storm
是一个大规模实时数据处理框架，能够自动完成数据分发和可靠性管理,开发者只需要关注处理逻辑，数据流基本在网络和内存进行（极端情况下会有磁盘调度）</p>
<p>Storm 计算逻辑类似Map/Reduce,
区别在<strong>调度数据而非调度计算</strong>，其拓扑及任务分配如下（spout
是输入，根据输入的 key 分发到不同的 Bolt 上处理，最后将结果组成）</p>
<figure>
<img src="https://wulc.me/imgs/image_1bgt781vpmed2b61k9hrkrd41g.png"
alt="storm" />
<figcaption aria-hidden="true">storm</figcaption>
</figure>
<h2 id="广告网络-demand-端技术">广告网络 demand 端技术</h2>
<p>广告购买平台 (Trading Desk) 是 demand 端的一种产品，其目的是
&gt;Allows advertisers buy audience across publishers and ad
networks</p>
<p>其关键特征有</p>
<ul>
<li>连接到不同媒体和广告网络，为广告商提供universal marketplace</li>
<li>非实时竞价campaign的<strong>ROI优化能力</strong></li>
<li>经常由代理公司孵化出来</li>
</ul>
<h3 id="roi优化能力">ROI优化能力</h3>
<p>ROI优化目标是给定总预算，在多广告网络中采买并优化ROI</p>
<p>ROI 优化其中若干关键问题有</p>
<p>（1）在合适的流量segment上投放广告；如SEM中的选词、显示广告网络中的标签组合选择等</p>
<p>（2）在每个投放上合理地出价以优化ROI；与实时竞价不同，采买方无法控制每次展示的出价(因此一般采用每次点击固定价格的策略)，但是因为
<span class="math inline">\(u, c\)</span>
的取值未知，需要在各流量分割上估计其分布并合理出价</p>
<p>（3）对每个segment的量以及Market price进行预估，以完成整体的优化</p>
<p>在这个领域有代表性的公司有
EfficientFrontier，这个公司的核心业务是为搜索广告主提供大量关键词情形下的
ROI
优化服务，并收取固定比例的提成；广告主只需要提供预算、关键词、受众类型等信息即可，EfficientFrontier
会通过计算为其提供最优方案</p>
<p>其核心技术为 <a
href="https://en.wikipedia.org/wiki/Portfolio_optimization">Portfolio
Optimization</a>，原是金融领域内的一个优化算法，目前正在向显示广告领域扩张，需要注意的是除了算法以外，长时间数据积累也很重要</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告(6)--广告交易市场(Ad Exchange)</title>
    <url>/2017/05/14/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E7%AC%94%E8%AE%B0(6)--%E5%B9%BF%E5%91%8A%E4%BA%A4%E6%98%93%E5%B8%82%E5%9C%BA(Ad%20Exchange)/</url>
    <content><![CDATA[<p>本文是刘鹏老师的<a
href="http://study.163.com/course/courseMain.htm?courseId=321007">计算广告学</a>中的一些笔记。本文是第六章:
广告交易市场(Ad
Exchange)。主要介绍目前最常见的实时竞价的广告交易模式，分别介绍了这一模式下的供给方平台(SSP)
和 需求方平台(DSP), 并且重点介绍了 DSP， 因为在这一交易模式下，DSP
负责了绝大多数的关键任务。</p>
<span id="more"></span>
<h2 id="广告交易平台adx">广告交易平台(Adx)</h2>
<p>广告交易平台的关键特征是用<strong>实时竞价(RTB)</strong>方式连接广告和
(上下文，用户)，按照<strong>展示</strong>上的竞价收取广告主费用</p>
<p>实时竞价指的是事先不对广告做retrieval，而是在需要展示的时候向下游的
DSP 展示目前的 context，让各个 DSP
通过竞价的方式获取这次展示的机会。其流程如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh52n8jlgdtn59np2hgqlao9.png"
alt="RTB 过程" />
<figcaption aria-hidden="true">RTB 过程</figcaption>
</figure>
<p>从上图可知，RTB 是一个多方参与的过程，而从实现上可以分为两个阶段</p>
<p>1）cookie mapping：目的是将 supply 网站和 demand
端的用户对应起来；实际中通过 Adx（代表supply） 与 DSP（代表demand）
来进行直接的mapping，后面会提到这方面的具体技术 2）ad
call：指有广告展示机会到来，这时 Adx 通知各个 DSP 进行竞价，DSP
根据自身需求出价，出价最高者获得投放机会。</p>
<p>这种模式的出现是由于广告主需要的定制化受众定向在原来的广告网络上无法得到满足，举例来说：京东商城需要对其用户进行重定向投放广告，但是在广告网络上是采买不到这种流量的，因为哪些用户是京东的只有京东自己知道，因此需要让
demand 端对流量进行选择才能达到深度定制化的要求。</p>
<p>这种主要技术难点在于 1） Adx与DSP之间的用户身份同步，一般通过 cookie
mapping 实现 2） DSP数量较多时的服务和带宽成本优化</p>
<p>但是存在着的潜在问题是： 1）
<strong>存在浏览数据的泄露风险</strong>。指的是某些DSP目的并不是获取广告，而是获取
Adx
展示的用户浏览数据；即每次出价都很低，保证自己不会赢得广告的展示机会，但是却能获得了
Adx 提供的用户 cookie
及其访问的url，为其日后进行受众定向积累数据基础。</p>
<p>2） <strong>多一次 round trip，对 latency
有较大影响。</strong>在之前的广告体系（合约广告，竞价广告）中，supply
端只需要先广告网络进行请求，广告网络根据其 retrieval
以及相关广告主的出价返回相关的广告即可，但是在实时竞价中，Adx 还需要等待
DSP 的出价以及通知获得展示机会的 DSP
进行广告的投放，这样无疑会增加投放的 latency 。</p>
<p>除了实时竞价，广告交易平台另外一个重要的特点是按<strong>展示</strong>计费而不是按照点击收费，其商业逻辑在于<strong>将点击率和点击价值的预估全放到
demand 端</strong>。</p>
<h3 id="adx-的系统架构图">Adx 的系统架构图</h3>
<p>Ad Exchange
的系统架构很简单，原因是其不需要存储广告之类的信息，只需要将广告展示机会告诉给每个
DSP ，然后进行竞价拍卖选出出价最高的那个
DSP。其难点在于系统的吞吐量大且对 latency
的要求严格。其系统架构图如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh54herr190014ap1tqr16c4km4m.png"
alt="Ad Exchange 系统架构" />
<figcaption aria-hidden="true">Ad Exchange 系统架构</figcaption>
</figure>
<p>其流程如下 1）某个 User 访问某个网站，网站通知 Adx 目前有一次展示机会
2）Adx 通过 RTBD 接口向各个 DSP 询价，从而获取
DSP提供的各个广告（相当于图中的 Ad retrieval） 3）Adx
通过出价进行排序，并选择出价最高的广告展示给用户（相当于图中的 Ad
ranking） 4）Adx 在日志中记录该广告的展示记录</p>
<h3 id="cookie-mapping-的技术">cookie mapping 的技术</h3>
<p>cookie mapping 需要弄清楚三个问题：<strong>谁发起 cookie mapping
的请求？在哪里发起的请求？谁存mapping表？</strong></p>
<p>下面以两个例子说明，第一个例子是 DSP 与 Adx 间的cookie
mapping，第二个例子是 DMP 与媒体的 cookie mapping。</p>
<p>下面是 DSP 与 Adx 的 cookie mapping 的过程</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh5a836ap321v1pm491hi1l5n13.png"
alt="DSP与Adx" />
<figcaption aria-hidden="true">DSP与Adx</figcaption>
</figure>
<p>这个例子中 cookie mapping 由 DSP 发起，在有 DSP
代码的广告主网站发起，mapping表存在DSP。其具体流程为</p>
<p>1）DSP 在广告主网站中嵌入 JS 代码，有用户访问时，选择性加载一个 DSP
域名下的 iframe 2）DSP 根据其记录判断该用户是否需要 cookie
mapping，返回包含多个 beacon 的动态 HTML，这里的多个 <a
href="https://en.wikipedia.org/wiki/Web_beacon#Overview">beacon</a>
目的是为了与<strong>多个 Adx</strong> 交换 cookie。 3）通过某个beacon
向对应的 Adx 发送 cookie 映射请求，并带有 <strong>Adx
标识（xid），DSP标识（did）和 DAP cookie（dck）</strong> 三个参数。
4）Adx 通过302 重定向向 DSP 返回 <strong>Adx
标识（xid）及其域名下的cookie（xck)</strong> 5) DSP 返回一个 1x1 的
beacon 并记录下 <strong>Adx 方的 cookie（xcd） 与己方的 cookie（dck）
的对应关系。</strong></p>
<p>下面是媒体与 DMP 的 cookie mapping 的过程</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh5a917b1a32h00pij1f2u1no1g.png"
alt="DMP与媒体" />
<figcaption aria-hidden="true">DMP与媒体</figcaption>
</figure>
<p>这个例子中 cookie mapping 由媒体方发起，在媒体的页面上发起，并且
cookie mapping 的表由 DMP 保存。其过程如下</p>
<ol type="1">
<li>用户访问媒体网站时，媒体网站向媒体的 cookie
映射服务请求一段负责此功能的 JS 代码 2）媒体的 cookie 映射服务返回该段
JS 代码 3）该 JS 代码判断是否需要映射，如果需要，则先 DMP
发送映射请求，并传送两个参数：<strong>媒体的标识（mid）以及媒体方的
cookie（mck）</strong> 4）DMP 返回一个 1x1 的beacon，并记录下媒体方
cookie(mck) 和己方的 cookie(dck) 对应关系。</li>
</ol>
<h2 id="供应方平台supply-side-platform">供应方平台（supply side
platform）</h2>
<p>SSP 完全代表着媒体方的利益</p>
<p>广告市场中，媒体变现流量方式一般有三种</p>
<ol type="1">
<li>合约广告，与广告主签订合约进行投放（CPM 结算）</li>
<li>竞价广告，将广告位托管给广告网络，广告网络根据人群售卖给广告主（CPC
结算）</li>
<li>实时竞价（按展示结算）</li>
</ol>
<p>而 SSP
应该能够为媒体提供上面的所有变现方式，通过组合以上方式达到收益最大化(称为收益管理，Yield
Optimizer)</p>
<p>综合以上可知，SSP的关键特征是</p>
<ul>
<li>提供媒体端的用户划分和售卖能力</li>
<li>可以灵活接入多种变现方式</li>
<li>收益管理</li>
</ul>
<p>整个行业有代表性的公式有： AdMeld，Rubicon，Pubmatic</p>
<h2 id="需求方平台demand-side-platform">需求方平台（Demand Side
Platform）</h2>
<p>将决策交到 demand 端,</p>
<p>维基上对 <a
href="https://en.wikipedia.org/wiki/Demand-side_platform">DSP</a>
的定义如下</p>
<blockquote>
<p>A demand-side platform (DSP) is a system that allows buyers of
digital advertising inventory to manage <strong>multiple ad exchange and
data exchange</strong> accounts through one interface.</p>
</blockquote>
<p>DSP 为广告主提供的便利之处在于，广告主主需要通过 DSP
的一个接口就可以获取各式各样的流量，从而进行定制化广告投放。</p>
<p>DSP的关键特征如下</p>
<ol type="1">
<li>定制化用户划分</li>
<li>跨媒体流量采购</li>
<li>通过 ROI 估计来支持 RTB</li>
</ol>
<p>DSP 的代表公司有 InviteMedia 和 MediaMath</p>
<h3 id="dsp-的架构">DSP 的架构</h3>
<p>DSP 的架构示意图如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh6jcr5hpcd190f1umf1kk1h6s9.png"
alt="DSP" />
<figcaption aria-hidden="true">DSP</figcaption>
</figure>
<p>复杂部分在于计算部分，就是要估计 <strong>eCPM = CTR *
clickValue</strong>，CTR 表示点击率， clickValue
表示点击价值，后面会详细介绍，在这里 DSP 需要同时计算 CTR 和
clickValue，复杂度自然大大提升。</p>
<h3 id="dsp-流量预测">DSP 流量预测</h3>
<p>流量预测指的是给定一组受众定向标签组合以及一个 eCPM
的阈值，估算在将来某个时间段内符合这些受众标签组合的条件、且市场价在该
eCPM 阈值以下的广告展示量。</p>
<p>DSP 也需要预测流量以决定采买策略，因为 DSP 与广告主是 CPM
结算的，DSP只要将市场中符合广告主的那部分低价的流量买下来才能获取更大的利润。</p>
<p>但是由于 DSP
无法拿到所有的流量情况，因此无法像攻击方那样通过历史流量那样进行流量预测，这个问题目前没有一个公认的较好的解决方法</p>
<h3 id="dsp-点击价值预估">DSP 点击价值预估</h3>
<p>点击价值指的是上面提到 <strong>eCPM = CTR * clickValue</strong> 中的
clickValue。一般衡量该点击的价值的指标是点击后的转化率</p>
<p>这个问题的挑战有</p>
<p>1）训练数据非常稀疏（最终得到的训练数据的比例是
<code>点击率*转化率</code>）
2）价值的预估与广告主类型强烈相关的行为模式（比如说游戏领域与电商领域不能相同的方法预估）</p>
<p>这个问题目前也没有很好的解决方法，但是有以下两点原则供参考</p>
<p>1）模型估计的时候，用较大的 bias 换较小的
variance，以达到稳定估计的目的
2）充分利用广告商类型的层级结构以及转化流程上的特征</p>
<h3 id="dsp-重定向retargeting">DSP 重定向（retargeting）</h3>
<p>什么是重定向呢？假如有一个电商网站，每天有几千人访问。当然，这几千人里面大部分当时并没有买东西就离开了。而重定向就是说这些人到了别的网站，就在该网站的广告位上投放该电商的广告，这样一来，用户点击广告和进而下单购买的比例都会相当高。</p>
<p>如下是一个重定向的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh73cv05tlrughefn1mh41qenm.png"
alt="retargeting" />
<figcaption aria-hidden="true">retargeting</figcaption>
</figure>
<p>重定向的分类</p>
<p><strong>1.网站重定向。</strong>就是上面提到的方法
<strong>2.搜索重定向。</strong>根据用户在搜索引擎上与广告主相关的搜索行为
<strong>3.个性化重定向。</strong>对用户购买流程的追踪和推荐，即根据用户在广告主网站上关注的具体产品和购买阶段，推送商品粒度的广告。对于广告主而言，可以视为一个站外推荐引擎。</p>
<p>上面提到了推荐算法，这里对推荐算法做一个简单的介绍，推荐算法可以分为两大类：<strong>基于协同过滤的算法和基于内容算法</strong></p>
<p>基于协同过滤的算法又可分为两种
1）内存方法（非参数方法）：neighbor-based methods，User-based/Item-based
top-N 2）模型方法（参数方法）:matrix factorization, bayesian belief
nets</p>
<p>基于内容的推荐算法指的是从 user 和 item
提取出相同的特征向量，或者说将两者映射到相同的向量空间中再比较两者的相似性。</p>
<p><strong>推荐算法的本质是对 user-item
这一系数矩阵的参数化或非参数化的描述，而推荐算法选择的关键也是探索合适的
bias 与 variance 的平衡，以适应问题的数据的稀疏性。</strong></p>
<p>重定向的典型代表公司是： Magnetic 和 Criteo</p>
<h3 id="新客推荐look-alike">新客推荐（look-alike）</h3>
<p>上面的重定向针对的是广告主已经有的客户，但是对于中小电商，仅仅对老用户定向营销远远不够；而对于某些类型的广告商如银行，大多数用户无法通过重定向渠道捕获。这时候就产生了新客推荐（look-alike）的需求。</p>
<p>新客推荐指的是由广告商提供一部分种子用户，DSP
通过网络行为的相似性为其找到潜在用户。需要注意的是尽量利用非 demand
端的数据，避免在广告主之间倒卖用户。</p>
<h2 id="广告流量交易方式">广告流量交易方式</h2>
<p>目前为止介绍了多种广告流量的交易形式，可以说交易的方式发展趋势为：合约广告-&gt;竞价广告-&gt;实时竞价广告，对应着下图从右到左的顺序。而发展到竞价广告之后，更加强调了
supply 端和 demand 端的分工的专业化。</p>
<figure>
<img src="https://wulc.me/imgs/image_1bh76incp1j3j1kg6oa11idl12nk13.png"
alt="广告流量交易方式" />
<figcaption aria-hidden="true">广告流量交易方式</figcaption>
</figure>
<p><strong>优先销售</strong>有两种模式
1）CPT结算，即传统广告的销售方式，技术要求低 2）GD：CPM 结算 +
人群定向</p>
<p><strong>程序交易</strong>包括竞价广告（Ad
network）和实时竞价广告（Adx），其对应的 supply 端和 demand
端负责的任务也不同，但是其目的均是如何将自身的资源或需求分发到多个点（网络）上从而获取最大的利益。</p>
<p>1）demad：network optimization + RTBS 2）supply：portfolio selection
+ RTBS</p>
]]></content>
      <categories>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络课程总结--BGP协议</title>
    <url>/2016/12/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93--BGP%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<p>路由器工作在IP层，其作用是根据IP地址将数据包传输到正确的目的地，因此路由器必须要知道网络的“地图”才能正确投递，而这个网络的“地图”就是存储在路由表中的路由规则，简称为路由。</p>
<p>根据获得路由的方式可以将其分为静态路由和动态路由，静态路由就是管理员静态配置的路由，动态路由则是路由器通过算法动态地学习和调整而得到的路由。而常说的路由协议就是指这些动态路由的学习算法，根据其作用域的不同，又可分为内部网管协议(IGP)和边界网络协议(BGP)；内部网络协议包括RIP，OSPF等，边界网关协议则包括BGP等。</p>
<p>本文主要讲述BGP相关的一些知识。</p>
<span id="more"></span>
<p>当网络过大的时候，也会导致路由表过大而难以维护，这时候采用分治的方法，将一个大网络划分为若干个小网络，这些小网络称为自治系统(AS)，BGP的诞生就是用于自治系统间的通信。其在网络中的位置如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4prb5s1hkr1g1e10ct6m31tbi9.png"
alt="BGP在网络中的作用" />
<figcaption aria-hidden="true">BGP在网络中的作用</figcaption>
</figure>
<p>那么是不是AS之间的通信都要使用BGP？答案并不是，<strong>只有当两AS间存在多条路径，需要做路由策略和选择才需要BGP；如果AS只有一个出口或者所有出口指向一个ISP的时候，是不需要BGP的。</strong></p>
<h2 id="基本概念">基本概念</h2>
<p>BGP允许基于策略（policy-based）的路由选择，策略与政治、安全和经济等因素相关，由AS的网络管理者确定，也就是说人为影响的因素较大。</p>
<p>从上面可知，每个划分后的小网络称为AS，每个AS都有自己独特的AS号码(ASN),ASN的原来使用16位表示。但是由于和和IP地址一样,ASN同样面临分配告罄的危机，自2006年12月1日起,原为16位(1-65535)
的ASN扩展为32位空间。</p>
<p>AS根据其位置的不同，也被分为为不同类型的AS。</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4priggn1jm11lenathpn3ksfm.png"
alt="AS类型" />
<figcaption aria-hidden="true">AS类型</figcaption>
</figure>
<p>一般来说，AS号码只是在一家ISP与至少两家ISP做对等互联，交换路由的时候才需要用到，也就是说一个国家的AS号码的数量实际上是跟大中型ISP的数量有关。</p>
<p>BGP 是运行在TCP协议上的，与其他路由协议对比如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4ps6iif7jivkb1c48ba08gh13.png"
alt="BGP与其他路由协议所在位置对比" />
<figcaption
aria-hidden="true">BGP与其他路由协议所在位置对比</figcaption>
</figure>
<p>BGP
是一种距离矢量路由协议，但避免了环路；其避免环路的策略是不仅仅记录路径代价，还记录下全路径信息。如下图所示
<img src="https://wulc.me/imgs/image_1b4pt0mcc2f1rg51ql8j0p1iad1g.png"
alt="BGP避免环路" /></p>
<p>BGP有两种邻居，其中运行在同一个AS内的BGP邻居称为IBGP(Interior
BGP),不同AS间的邻居称为EBGP(Exterior
BGP)，注意无论是IBGP或者EBGP，上面都必须运行着BGP协议，也就是说与BGP路由器直连的内部路由器不一定是它的IBGP，如下图所示
<img src="https://wulc.me/imgs/image_1b4ptstpf1kfkdiqc3fe561i561t.png"
alt="BGP的邻居类型" /></p>
<p>注意：BGP邻居不是自动发现的，而是手动配置的，原因有以下两点：
1）可以<strong>与对端设备用任何IP地址建立邻居，而不限于某个固定的接口IP</strong>。这样，当两台
设备采用环回地址而非直连地址建立BGP邻居时，即使主链路中断了，也可以切换到备份链路
上，保持邻居不断。这种稳定性正是BGP作为大型网络路由承载的必要特质。
2）可以<strong>跨越多台设备建立邻居</strong>。当一个AS有多个设备运行BGP
建立域内全连接时，<strong>不必每台设备物理直连，只要用IGP保证建立邻居的地址可达，即可建立全网连接，减少不必要的链路建设。</strong></p>
<h2 id="bgp报文">BGP报文</h2>
<p>BGP报文类型有以下四种：</p>
<ul>
<li><strong>Open报文</strong>：打招呼，“你好，交个朋友吧”（协商参数）</li>
<li><strong>Keepalive报文</strong>：我还活着，别不理我（30秒钟交换一次）</li>
<li><strong>Update报文</strong>：有新闻（链路的变化）</li>
<li><strong>Notification报文</strong>：我不跟你玩了（异常情况的通报，终止连接）</li>
</ul>
<p>BGP的工作机制也可以通过这四种报文描述：
1）通过TCP建立BGP连接时，发送OPEN报文
2）连接建立后，如果有路由器需要发送路由或路由发生变化时，发送UPDATE报文
3）稳定后，<strong>周期发送</strong>KEEPALIVE报文，维持连接有效性
4）当本地BGP运行中发生错误时，发送NOTIFICATION报文通告BGP对端</p>
<h2 id="路由注入及通告">路由注入及通告</h2>
<p>首先要明确一点，BGP路由器的路由注入和通告都是为了<strong>修改BGP路由表</strong>。</p>
<p>当路由器之间建立BGP邻居之后，就可以相互交换BGP路由。一台运行了BGP协议的路由器，会将BGP得到的路由与普通路由分开存放，所以<strong>BGP路由器会同时拥有两张路由表</strong>。</p>
<p>一张是存放普通路由的路由表，被称为<strong>IGP路由表</strong>，就时平时我们使用命令<code>show ip route</code>看到的路由表，IGP路由表的路由信息只能从<strong>IGP协议和手工配置</strong>获得，并且只能传递给IGP协议；另外一张就是运行BGP之后创建的路由表，称为<strong>BGP路由表</strong>，需要通过命令<code>show ip bgp</code>才能查看，<strong>BGP路由表的路由信息只能传递给BGP协议，如果两台BGP邻居的BGP路由表为空，就不会有任何路由传递。</strong></p>
<p>在初始状态下，BGP的路由表为空，没有任何路由，要让BGP传递相应的路由，只能先<strong>将该路由注入BGP路由表，之后才能在BGP邻居之间传递。</strong>注入的方式有多种，如
1）<strong>动态注入</strong>：将IGP(如OSPF)发现的路由纯动态地注入到BGP路由表中，这种方式配置简单，但操控性差，可能不稳定。具体过程及配置如下图所示：
<img src="https://wulc.me/imgs/image_1b4pvi3j614k817qs426jfc1v22a.png"
alt="动态注入" />
2）<strong>半动态路由注入</strong>：通过IGP协议(如OSPF)学习到的路由，再通过
network 发布到BGP中。具体过程及配置如下图所示： <img
src="https://wulc.me/imgs/image_1b4pvj0ts61dfimft2m4k7q2n.png"
alt="半动态路由" /></p>
<p>3）<strong>静态路由注入</strong>：工配置的静态路由，再由network发布到BGP中。具体过程及配置如下图所示：
<img src="https://wulc.me/imgs/image_1b4pvlkhvvb1uai1l5smuc1eks34.png"
alt="静态路由注入" /></p>
<p>在BGP路由表注入路由后，BGP路由器之间会将这些路由在BGP路由器间进行<strong>通告</strong>。通告要遵守以下规则</p>
<ul>
<li>BGP 路由器只把自己使用的路由通告给<strong>相邻体</strong></li>
<li>BGP
路由器从EBGP获得的路由会向它的所有BGP相邻体通告（包括EBGP和IBGP）</li>
<li>BGP路由器从IBGP获得的路由不会向它的IBGP相邻体通告（避免内部产生环路）</li>
<li>BGP
路由器从IBGP获得的路由是否通告给它的EBGP相邻体要依IGP和BGP同步的情况而定</li>
</ul>
<p>对于最后一条，只有当 IGP 与 BGP 同步时（也就是该路由可以通过 IGP
获得），才能通告，反之不通告，这样做的目的是为了避免路由黑洞。</p>
<h2 id="路径属性">路径属性</h2>
<p>在默认情况下，到达同一目的地，BGP只走单条路径，并不会在多条路径之间执行负载均衡。对于IGP路由协议，当有多条路径可以到达同一目的地时，则根据最小metric值来选择最优路径，而
BGP
存在多条路径到达同一目的地时，对于最优路径的选择，BGP并不会以metric值大小为依据，<strong>BGP对于最优路径的选择，需要靠比较路由条目中的Path
Attributes，即路径属性</strong>，只有在比较多条路由的属性之后，才能决定选择哪条为最优路径。</p>
<p>BGP的路径属性可以划分为以下四类：</p>
<ul>
<li>公认强制 （Well-Known
Mandatory）:所有的路由中都需要写入公认强制属性</li>
<li>公认自选 （Well-Known
Discretionary）：能够理解和支持即可，不一定要写入路由</li>
<li>可选可传递 （Optional Transitive）：不一定要理解或支持</li>
<li>可选不可传递（Optional
Nontransitive）：只有特定的BGP路由器才能理解和传递</li>
</ul>
<p>对于任何一台运行BGP的路由器，都必须支持公认强制属性，并且在将路由信息发给其它BGP邻居时，<strong>必须在路由中写入公认强制属性</strong>，这些属性是被强制写入路由中的，一条不带公认强制属性的路由被BGP路由器被视为无效而被丢弃，一个不支持公认强制属性的BGP，是不正常的，不合法的BGP。BGP路由必须携带的公认强制属性有三个：<code>Origin，Next_Hop，AS-path</code>。</p>
<h3 id="origin属性"><strong>origin属性</strong></h3>
<p>origin属性为起源属性，描述路由是以何种方式注入到BGP路由表中的，主要有以下两种情况
1）以 <code>network</code> 命令注入到BGP路由表中，origin 属性为 IGP
2）以 <code>redistribute</code> 命令注入到BGP路由表中，origin 属性为
Incomplete 其中，IGP优先级比Incomplete的要高。</p>
<h3 id="as-path属性"><strong>AS Path属性</strong></h3>
<p>描述了该路由经过的AS组成的路径，AS路径中不能算上自己的AS，从离自己最近的AS开始，以目的网络的AS结束。下图为
AS5 到 AS1 的路由的AS Path属性</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r0qskcqgv7k8qt21502gjo9.png"
alt="as path属性" />
<figcaption aria-hidden="true">as path属性</figcaption>
</figure>
<p>借助路由的AS Path属性，可以避免环路，具体操作就是收到一条AS
Path属性中含有自己AS的路由的时候丢弃该路由。</p>
<p>在选路的时候，优先选<code>AS PATH</code>最短的那条，如果<code>AS PATH</code>距离相等，则优选本AS内到出口路由器最短的那根，如果还相等，则选择Router_ID（发送路由的路由器）最小的那根</p>
<p>但是要注意，这种选择并不总是明智的，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r18fev79qqsg1pin9r7lt1m.png"
alt="as path选路并非最优" />
<figcaption aria-hidden="true">as path选路并非最优</figcaption>
</figure>
<h3 id="next-hop属性"><strong>Next Hop属性</strong></h3>
<p>指示下一个AS的路由器入口的网段，同一个AS内Next
hop的值不变,如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r1jbg51jo0ncd1uc81i4p14mi13.png"
alt="next hop 属性" />
<figcaption aria-hidden="true">next hop 属性</figcaption>
</figure>
<h3 id="local-pref属性"><strong>local pref属性</strong></h3>
<p>可选的属性，用于引导流量，local pref的缺省值是100，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r1m0rh1h0etab7ha14ih38q1t.png"
alt="local pref 属性" />
<figcaption aria-hidden="true">local pref 属性</figcaption>
</figure>
<h3 id="medmulti-exit-distiguisher属性"><strong>MED(Multi Exit
Distiguisher)属性</strong></h3>
<p>当AS有多个出口的时候，告诉上游的AS如何选最优的路，MED值越小，优先级越高
<img src="https://wulc.me/imgs/image_1b4r21j0o1shtjj51ljoksef3j2a.png"
alt="MED属性" /></p>
<p>BGP 选路的策略为</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r2bo1e1g9ff12lu21kf6sr52n.png"
alt="BGP选路策略" />
<figcaption aria-hidden="true">BGP选路策略</figcaption>
</figure>
<h2 id="其他概念">其他概念</h2>
<p><strong>BGP过滤</strong> BGP
拥有强大的过滤功能，可以按照以下规则进行过滤：</p>
<ul>
<li>可按照路由的IP地址过滤</li>
<li>可依照路由经过的AS-Path过滤</li>
<li>可以依照路由的属性过滤</li>
<li>可以依照路由到来的接口过滤</li>
</ul>
<p><strong>BGP聚合</strong>
由于BGP路由器的路由表庞大，往往超过10万条，通过BGP聚合(BGP支持CIDR)解决这个问题，如下图AS100先将内部的路由聚合再通告给AS200</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r3gu921kqn1b8b1nab3i31btbm.png"
alt="BGP聚合" />
<figcaption aria-hidden="true">BGP聚合</figcaption>
</figure>
<p><strong>BGP联盟和反射</strong>
从前面的描述可知，从IBGP收到的路由不会通告给其他的IBGP（避免环路），所以AS内部的IBGP必须全连接。但是IBGP相邻体过多，逻辑全链接不现实，实际中通过BGP联盟和反射解决这个问题。</p>
<p>BGP联盟就是将大的AS分割成小的AS，从而减少全连接的数目。</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r3o8geqal133vuvp1i0ij251j.png"
alt="BGP联盟" />
<figcaption aria-hidden="true">BGP联盟</figcaption>
</figure>
<p>BGP反射是通过将网络内的路由器划分为客户机，非客户机以及路由反射器的角色，从而减少IBGP间的连接，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r4ha631mpv1dhu1hb355dpl420.png"
alt="BGP反射" />
<figcaption aria-hidden="true">BGP反射</figcaption>
</figure>
<p>BGP反射中需要遵循以下规则</p>
<ul>
<li>来自客户机的路由通告给其它的客户机和非客户机</li>
<li>来自非客户机的路由只通告给它的客户机</li>
<li>来自EBGP的路由向所有相邻体通告</li>
</ul>
<p><strong>BGP衰减</strong>
BGP衰减是为了处理不稳定的路由（如路由频繁更新），避免影响整个互联网络的稳定运行</p>
<p> 
路由抑制可以阻止公布不稳定的路由，它为每条路由分配一个动态的度量数字用来反映稳定程度，当一条路由出现摆动，就给他分配一个惩罚值，摆动得越多，惩罚值越大。当一段时间不摆动，惩罚值降低，在一个半衰期后，降到原来的一半。如果惩罚值超过抑制上限，该路由就被抑制，只有当一个半衰期后惩罚值降低到重新使用界限时，才重新使用。</p>
<h2 id="bgp配置">BGP配置</h2>
<p>通常在路由器配置BGP需要开启BGP进程，指定AS号码，指定邻居(EBGP或IBGP)并注入BGP路由，如下是一个简单的例子
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//开启BGP进程，指定AS号</span><br><span class="line">Router(config)#router bgp as-number  </span><br><span class="line">//注入BGP路由</span><br><span class="line">Router(config-router)#network network-number [mask network-mask] </span><br><span class="line">//指定EBGP或IBGP(as-number 决定)</span><br><span class="line">Router(config-router)#neighbor ip-address remote-as as-number</span><br></pre></td></tr></table></figure> 下图是一个简单的例子：</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r55j8612a01umq1ker16cbdbm2d.png"
alt="BGP配置" />
<figcaption aria-hidden="true">BGP配置</figcaption>
</figure>
<p>除此以外，还有一些检查BGP工作情况的命令如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4r58c36qjn1b7s18001rsmq762q.png"
alt="检查BGP配置" />
<figcaption aria-hidden="true">检查BGP配置</figcaption>
</figure>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络课程总结--IPV6</title>
    <url>/2016/12/26/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93--IPV6/</url>
    <content><![CDATA[<p>本文主要讲述 IPV6 的一些基础知识，包括 IPV6
的术语，地址，一些基本协议以及从IPV4过渡到IPV6的的一些技术等。</p>
<span id="more"></span>
<p>IPV6的出现最主要的原因是因为 IPV4 存在着一些不足，主要有</p>
<ul>
<li>地址不足</li>
<li>端到端模式无法实施(NAT)</li>
<li>Qos和性能问题</li>
<li>配置复杂</li>
<li>安全问题</li>
<li>路由表的膨胀</li>
<li>移动性支持不足</li>
</ul>
<p>其中最主要的就是地址不足。</p>
<p>在介绍IPV6的具体知识前，首先了解IPV6中的一些基本术语</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sbuojv11kt1t3q1kv16iuglfm.png"
alt="IPV6基本属于" />
<figcaption aria-hidden="true">IPV6基本属于</figcaption>
</figure>
<p>从上图可知，IPV6 中有以下术语</p>
<ul>
<li>领节点：不跨越网段的两台主机</li>
<li>局域网段：交换机某个端口下的网络</li>
<li>链路：路由器某个端口下的网络</li>
<li>子网(site)：一个机构管辖的所有网络（不同于IPV4中的子网）</li>
</ul>
<h2 id="ipv6地址">IPV6地址</h2>
<h3 id="ipv4地址">IPV4地址</h3>
<p>讲述IPV6地址前，首先回顾一下IPV4地址，IPV4的地址长度为32位，通过点分十进制表示，点分十进制的规则如下</p>
<ul>
<li>将32位IP地址分为4个8位组</li>
<li>每个8位组之间用圆点 “.” 分隔</li>
<li>每个8位组转化为对应的十进制数</li>
</ul>
<p>每个地址被划分为网路地址和主机地址两部分。地址可分为ABCD四类，每一类的地址范围如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4scnmhp153gv0dimp1puc1f5c13.png"
alt="IPV4地址" />
<figcaption aria-hidden="true">IPV4地址</figcaption>
</figure>
<h3 id="ipv6地址表示">IPV6地址表示</h3>
<p>IPV6
地址长度是<strong>128位</strong>，通过冒分16进制表示，冒分16进制将128位划分为8组，组与组之间通过冒号隔开，每一组16位，用四个16进制数表示，如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sd4ro61uug13818dl84g1bcj1g.png"
alt="IPV6 地址" />
<figcaption aria-hidden="true">IPV6 地址</figcaption>
</figure>
<p>但是这样表示出来的地址往往在8各组中有很多组是全0的，为了书写的简便，定义了以下的规则：
1）忽略前导0，
2）忽略全0，用双冒号代替，注意一个地址最多只能有一个双冒号</p>
<p>如下是运用了这两条规则的一个简单例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sdak1jc5j5n8l8m16e11ril1t.png"
alt="IPV6简便书写的规则" />
<figcaption aria-hidden="true">IPV6简便书写的规则</figcaption>
</figure>
<p>除此之外，IPV6中通过<code>/XX</code>表示地址前缀，替代了IPV4中子网掩码的概念。</p>
<p>IPV6中的地址根据其作用域可以分为单播地址(Unicast
Address)，组播地址(Multicast Address)和任播地址(Anycast
Address)三大类。IPV6中没有广播地址的概念。</p>
<h3 id="单播地址">单播地址</h3>
<p>IPV6 单播地址用于唯一标识支持 IPV6 的设备上的接口，与 IPV4 类似，源
IPV6 地址必须是单播地址。在IPV6中，单播地址分为六类</p>
<ol type="1">
<li>链路本地地址(Link Local Address)</li>
<li>环回地址(Loopback Address )</li>
<li>未指定地址(Unspecified Address)</li>
<li>站点本地地址(Site Local Address)</li>
<li>IPV4兼容地址(IPV4 Compatible Address )</li>
<li>可聚合全球单播地址(Aggregate Global Unicast Address)</li>
</ol>
<h4 id="链路本地地址">链路本地地址</h4>
<p>IPV4也有链路本地地址(169.254.0.0/16),但是在IPV4中，该地址的主要被用于地址自动配置：<strong>当主机不能从DHCP服务器处获得IP地址时，它会使用链路本地地址作为自己的地址</strong>。</p>
<p>但是在IPV6中，链路本地地址用于与<strong>同一链路</strong>（同一个路由器端口下的网络）中的其他设备通信，而且也只能用于同一链路中，因此，<strong>路由器不会转发具有本地链路源地址或目的地址的数据包</strong>。需要注意的是，<strong>每个支持
IPV6
的网络接口均需要有链路本地地址</strong>。有了链路本地地址，就可以与与同一子网中的其他支持
IPV6
的设备通信，包括与默认网关（路由器）通信。所以假如只需要在局域网内通信，可以不需要全局单播地址。</p>
<p>支持 IPV6 的主机在<strong>启动时自动创建</strong> IPV6
链路本地地址。链路本地地址格式为 <code>FE80::/64</code> ，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sf3pvl180k10k7b0cm8g1trb2a.png"
alt="链路本地地址" />
<figcaption aria-hidden="true">链路本地地址</figcaption>
</figure>
<p>链路本地地址前64位为<code>FE80:0:0:0</code>，后64位为EUI-64地址，EUI-64地址通过mac地址变换过来，变换规则如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sgcgl0lgr1l5ha1c11bb1prk2n.png"
alt="EUI-64地址变换过程" />
<figcaption aria-hidden="true">EUI-64地址变换过程</figcaption>
</figure>
<p>注意上图中前24位mac地址中用 u
标记的位表示要对原来的位取反。如下为一个简单的例子 <img
src="https://wulc.me/imgs/image_1b4sihd6cvkg9bpkmgvtf1jfp3h.png"
alt="本地链路地址的生成" /></p>
<p>链路本地地址的用途包括：
1）主机使用本地路由器的链路本地地址作为<strong>默认网关</strong> IPV6
地址。 2）路由器使用链路本地地址<strong>交换动态路由协议消息</strong>。
3）转发 IPV6
数据包时，路由器的路由表使用链路本地地址<strong>确定下一跳</strong>路由器。</p>
<h4 id="环回地址">环回地址</h4>
<p>与IPV4的127.0.0.1类似，在IPV6中对应为<code>::1/128</code> 或简单的
<code>::1</code>。</p>
<p>通过环回地址启用 ping 命令，从而测试本地主机的 IP
协议是否正确安装。</p>
<h4 id="未指定地址">未指定地址</h4>
<p>未指定地址是全 0 地址，使用压缩格式表示为 <code>::/128</code> 或
<code>::</code> 。</p>
<p>未指定地址不能分配给接口，仅可作为 IPV6
数据包的<strong>源地址</strong>。
未指定地址的作用在于当设备<strong>尚无永久 IPV6
地址时</strong>或数据包的源地址与目的地址不相关时，使用未指定地址用作源地址。</p>
<h4 id="站点本地地址">站点本地地址</h4>
<p>站点本地地址是IPV6的私网地址，就像IPV4中的私网保留地址（<code>10.0.0.0/8</code>,
<code>172.16.0.0/12</code>,<code>192.168.0.0/16</code>）一样。站点本地地址的前缀范围为
<code>FC00::/10</code>。</p>
<p>最初的 IPV6
规范定义了用于特定用途的本地站点地址，但是因为站点本地地址规范中有很多不明之处，因此，IETF
已经弃用本地站点地址，开始倾向于唯一本地地址。</p>
<h4 id="ipv4兼容地址">IPV4兼容地址</h4>
<p>兼容IPV4的IPV6地址，用于过渡时期在IPV4网络上建立自动隧道，以传输IPV6数据包。其中高96位设为0，后面的32位的IPV4地址，即地址为<code>::IPV4</code>.</p>
<h4 id="可聚合全球单播地址">可聚合全球单播地址</h4>
<p>可聚合全球单播地址是由IANA分配的可在全球路由的<strong>公网IP</strong>，地址由格式前缀
<code>001</code>
标识，设计目标是聚合或汇总该地址以便产生有效的路由基础结构</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sjdh5h1h1a3rqe3315pp1pje3u.png"
alt="可聚合全球单播地址" />
<figcaption aria-hidden="true">可聚合全球单播地址</figcaption>
</figure>
<p>从上图可知，ISP商分配的前缀位为前48位，Site部分则是由ISP下一级的组织机构用于划分子网，最后是64位的接口ID。</p>
<p>接口ID的产生方式有三种 1. EUI-64(前面讲述过，通过mac生成) 2. 随机生成
3. 手工配置</p>
<h3 id="组播地址">组播地址</h3>
<p>IPV6中没有广播的概念，IPV6中通过组播代替广播。</p>
<p>IPV6中组播地址前八位均为1，因此组播地址总是以<code>ff</code>开头，具体的组播地址格式如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sjrjjcs81a9sfmu29avan4b.png"
alt="IPV6组播格式" />
<figcaption aria-hidden="true">IPV6组播格式</figcaption>
</figure>
<p>其中</p>
<ul>
<li>Flags:用来表示permanent(0000)或transient(0001)组播组</li>
<li>Scope:表示组播组的范围 &gt;0：预留 1：节点本地范围 2：链路本地范围
5：站点本地范围</li>
<li>Group ID:组播组ID</li>
</ul>
<p>一些众所周知的组播地址如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4sndbb88pa17l8r291rrhb669.png"
alt="众所周知的组播地址" />
<figcaption aria-hidden="true">众所周知的组播地址</figcaption>
</figure>
<p>除此之外还有有一种特殊的组播地址：Solicited-node节点地址（被请求节点组播地址），主要用于重复地址检测和获取邻居节点的链路层地址。</p>
<p>地址构成为
<strong>前104位</strong>：<code>FF02::1:FF/104</code>（64个零）
<strong>后24位</strong>：单播地址的后24位</p>
<p>凡是单播地址后24位相同的接口会自动加入相应的请求节点组播组，如下为一个实例</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4snpafi1q9d1jd96ph150gj69m.png"
alt="请求组播组地址实例" />
<figcaption aria-hidden="true">请求组播组地址实例</figcaption>
</figure>
<p>关于组播更详细的信息可参考<a
href="http://wulc.me/2016/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93--%E7%BB%84%E6%92%AD%E5%9F%BA%E7%A1%80/">这篇文章</a>。</p>
<h3 id="任播地址">任播地址</h3>
<p>在IP网络上通过一个任播地址标识<strong>一组提供特定服务的主机</strong>，同时服务访问方并不关心提供服务的具体是哪一台主机(比如<strong>DNS</strong>或者<strong>镜像服务</strong>)，访问该地址的报文可以被IP网络路由到这一组目标中的<strong>任何一台主机</strong>上，一般来说，目标地址为任播地址的数据报将发送给最近的一个服务主机。</p>
<p>综合上面提到的地址，可以知道一个接口上可以具有的IPV6地址如下所示</p>
<table>
<thead>
<tr class="header">
<th>地址类型</th>
<th>具体地址</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>链路本地地址</td>
<td>FE80::/10</td>
</tr>
<tr class="even">
<td>环回地址</td>
<td>::1/128</td>
</tr>
<tr class="odd">
<td>所有节点组播地址</td>
<td>FF01::1,FF02::1</td>
</tr>
<tr class="even">
<td>可聚合全球单播地址</td>
<td>2000::/3</td>
</tr>
<tr class="odd">
<td>被请求节点组播地址</td>
<td>FF02::1:FF00:/104</td>
</tr>
<tr class="even">
<td>主机所属组播地址</td>
<td>FF00::/8</td>
</tr>
</tbody>
</table>
<h3 id="ipv6地址配置">IPV6地址配置</h3>
<p>IPV6中地址配置方式有三种 1. 手工配置 2. 无状态地址自动配置（ND协议）
3. 有状态地址自动配置（DHCPv6）</p>
<p>手动配置一般不常用，各系统均有自己的配置方式，这里不详细展开。下面主要讨论自动配置的两种方式。</p>
<h4 id="无状态地址自动配置nd协议">无状态地址自动配置（ND协议）</h4>
<p>无状态地址自动配置指的是无须任何配置即可和外界通信，达到了真正的即插即用。
无状态地址自动配置通过<strong>ND(Neighbor
Discovery,邻居发现)协议</strong>实现，主要包括如何自动获取地址以及实现重复地址检测(DAD)</p>
<h5 id="rs和ra"><strong>RS和RA</strong></h5>
<p>ND协议中有两种重要的消息：<strong>RS和RA</strong>。其中，RS(Router
Solicitation)由主机发出，作用是促使路由器发送RA(Router
advertisment)消息,RA消息中包含了路由器前缀等信息，主机会利用路由器的前缀加上自己的EUI-64地址作为自己的IPV6地址。这两种消息都是以<strong>ICMPv6报文</strong>的形式出现，也是5种ND协议消息中的两种。具体过程如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4svnst0154e1l8a1dcn1kfb1ras9.png"
alt="RS和RA消息" />
<figcaption aria-hidden="true">RS和RA消息</figcaption>
</figure>
<p>注意RS消息的目的地址是<code>FF02::2</code>,也就是主机先整个链路的路由器请求RA消息,RA消息的目的地址是<code>FF01::1</code>，也就是路由器向整个链路的主机发送RS消息。</p>
<p>因此为了避免RS泛滥，节点启动时<strong>最多只能发送3个RS</strong>，而路由器也会主动周期性地发送RA（默认值200秒）。主机在收到路由器的RA之后，自动设置默认路由器，建立默认路由器列表、前缀列表及其它参数。</p>
<p>需要注意的是，<strong>自动配置的IPV6地址在系统中有一个生存周期</strong>，跟优先时间和有效时间有关，对应着以下4种状态</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t02ipn1eu11vja1ht04pcuujm.png"
alt="IPV6地址生存时间" />
<figcaption aria-hidden="true">IPV6地址生存时间</figcaption>
</figure>
<p>在使用的时候需要遵循以下规则</p>
<p>1.在<code>Preferred Lifetime</code>周期内的前缀生成的地址，<strong>任何上层应用都可不受限制地使用</strong>
2.在超过 <code>Preferred Lifetime</code>
但未超过<code>Valid Lifetime</code>周期内的前缀生成的地址，正在使用该地址的上层应用可继续使用，但任何新的上层应用不能使用这个地址
3.在超过<code>Valid Lifetime</code>周期内的前缀构造的地址，任何上层应用都不能使用该地址
<strong>一个链路本地地址的优先时间和有效时间是无限的，即永不超时！</strong></p>
<h5 id="ns和na"><strong>NS和NA</strong></h5>
<p>在自动配置地址后需要检测该地址在链路上是否与其他地址重复(链路上的主机的mac地址可能重复，从而EUI-64重复)，该过程称为DAD(Duplicate
Address
Detection),<strong>所有的IPV6单播地址，不管是自动配置还是手动配置，都必须要通过DAD</strong>。</p>
<p>结合上面地址的生存周期，一个地址在<strong>分配给一个接口之后且通过重复地址检测之前</strong>称为tentative地址，即试验地址。</p>
<p>DAD机制是ND协议的一部分，因此通过ND协议中的<code>NS/NA</code>两种消息实现。DAD的基本流程:
1. 节点组播发送NS(Neighbor Solicitation)消息 2. 如果收到NA(Neighbor
Advertisment)消息，就证明地址重复 3.
如果尝试若干次发送请求，都没有收到邻居通告，即可启用该地址</p>
<p>过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t1koot79sakbke432p9b9.png"
alt="NS和NA" />
<figcaption aria-hidden="true">NS和NA</figcaption>
</figure>
<p>注意上面的<strong>NS消息的目的地址是被请求节点的组播地址</strong>，就是单播地址最后24位相同的主机都会加入的一个组播。而NA消息的目的地址是<code>FF02::1</code>,原因是NS消息中的源地址是未指定地址，发出NA的主机并不知道NS是由那一台主机发出的。</p>
<p>当其他主机收到NS后，会有以下两种情形
1）NS接收者如果发现其中的目标地址对它而言是<strong>tentative</strong>的，则<strong>主动放弃使用</strong>这个地址；
2）NS接收者如果发现其中的目标地址是一个它<strong>正在使用</strong>的地址，则<strong>发送NA</strong>消息，请求发起者
将放弃使用这个试验地址</p>
<p>结合上面的RS和RA，4中ND消息交互入下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t28ah47ooa731b0n13ce76am.png"
alt="四种ND消息交互" />
<figcaption aria-hidden="true">四种ND消息交互</figcaption>
</figure>
<h5 id="前缀重新编制">前缀重新编制</h5>
<p>前缀重新编制允许网络从以前的前缀平稳地过渡到新的前缀，提供对用户透明的网络重新编址能力。</p>
<p>在前缀重新编址时，路由器会继续通告<strong>当前前缀</strong>，只是<strong>优先时间和有效时间被减小到接近0</strong>，同时，路由器开始通告新的前缀，这样，链路中<strong>至少有两个前缀共存</strong>。</p>
<p>节点收到优先时间和有效时间被减小到接近0的RA时，会发现当前前缀的生命周期较短，停止使用；同时开始用新的前缀配置接口，并进行DAD，通过后，获得新的地址使用。</p>
<p><strong>在转换期间，节点有两个单播地址使用</strong>，旧的地址基于旧的前缀，用以维持以前已经建立的连接；新的地址，基于新的前缀，用来建立新的连接。当旧的前缀的有效时间递减为0时，旧的前缀完全废止，此时，RA中只包含新的前缀</p>
<h4 id="有状态地址自动配置dhcpv6">有状态地址自动配置（DHCPv6）</h4>
<p>有状态的自动配置依赖于DHCPv6实现，DHCPv6是DHCP的升级版本。</p>
<p>但是既然有了无状态自动配置，为什么还需要DHCPv6呢？主要有以下几个原因</p>
<ul>
<li>需要动态指定DNS服务时</li>
<li>当不希望MAC地址成为IPV6地址的一部分时(安全性）</li>
<li>当需要良好的扩展性时</li>
</ul>
<p>在讲述DHCPv6前，先介绍一下原始的DHCP协议</p>
<p>DHCP的过程非常自然，主要包括下面三步
1）DHCP客户发送<strong>广播请求</strong>
2）DHCP服务器<strong>单播应答</strong>
3）DHCP客户接收应答，获取IP等信息</p>
<p>具体过程使用四种package来实现这个过程
1）DHCP客户机在本地发送<code>DHCP DISCOVER</code>广播包；
2）DHCP服务器单播发送携带租约信息的<code>DHCP OFFER</code>包；
3）DHCP客户机确认租约信息并发送<code>DHCP REQUEST</code>广播包；
4）DHCP服务器单播送回<code>DHCP ACK</code>確认完成IP地址租用</p>
<p>DHCP有三种地址分配机制：
1）自动分配方式－由DHCP分配一个<strong>永久</strong>的IP
2）手动分配方式－网络管理员<strong>预先安排分配</strong>，由DHCP转达
3）动态分配方式－由DHCP分配具有<strong>租约期</strong>的IP</p>
<p>相比于DHCP，DHCPv6有了以下的改变 1.
使用<strong>UDP</strong>来交换报文，端口546/547（V4：67/68） 2.
使用本地链路地址或其它机制获得的地址来发送和接收DHCPv6报文 3.
没有了广播，客户机只需发送给保留的链路范围组播地址（FF02::1:2,all dhcp
relay agents and servers ） 4.
DHCP中使用的四种package在DHCPv6中依次变为<code>DHCP Solicit</code>,
<code>DHCP Advertis</code>, <code>DHCP Request</code>,
<code>DHCP Relay</code>.</p>
<p>其过程如下所示： <img
src="https://wulc.me/imgs/image_1b4t3ot285554is49mbi11al913.png"
alt="DHCPv6" /></p>
<p>当客户端已经记录了地址和其他配置信息，只需要DNS server、NTP
server等信息的时候，可以通过DHCPv6快速配置来快速获得所需地址。这个过程只需要两个消息的交互，过程如下所示：
<img src="https://wulc.me/imgs/image_1b4t40s8m1h0t17u11pqfs2idac1g.png"
alt="DHCPv6快速配置" /></p>
<h2 id="ipv6报文">IPV6报文</h2>
<p>IPV6的报文主要由三部分组成 1.
基本头（固定40字节，v4不固定，为20~60字节范围内） 2.
拓展头（可选，0~n字节，v4中没有） 3. 有效负载（即上层传输数据）</p>
<h3 id="基本头与v4对比">基本头(与v4对比)</h3>
<p>v4与v6的报文对比如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t4g51f1uca1vd8ua31u80pea1t.png"
alt="v4与v6报文对比" />
<figcaption aria-hidden="true">v4与v6报文对比</figcaption>
</figure>
<p>且v4的报文的具体字段如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t4igjcvm0umj1ofm1gvc1tch2a.png"
alt="v4报文具体字段" />
<figcaption aria-hidden="true">v4报文具体字段</figcaption>
</figure>
<p>v6的报文的具体字段如下所示 <img
src="https://wulc.me/imgs/image_1b4t4jpqm1f2o9tnjjjcin107m2n.png"
alt="v6报文具体字段" /></p>
<p>v6在v4字段的基础上有删除，也有修正的项，其中</p>
<p><strong>修正的项</strong>有</p>
<ul>
<li>服务类型→业务等级</li>
<li>TTL→跳数限制</li>
<li>数据总长度→净荷长度(因为头部固定长度为40个字节)</li>
<li>地址32位→128位</li>
<li>协议→下一个头(next header,也是指示具体的协议的，不要被名称误导)</li>
</ul>
<p><strong>删除的项</strong>有</p>
<ul>
<li>报头长</li>
<li>标志和分段偏移量(与分片相关)</li>
<li>报头校验和</li>
</ul>
<p><strong>增加的项</strong>为</p>
<ul>
<li>流标记</li>
</ul>
<p>下图是一个抓取到的ICMPv6的具体package <img
src="https://wulc.me/imgs/image_1b4t5h5qo1a7jepqvb674d1t8l34.png"
alt="ICMPv6 package" /></p>
<h3 id="拓展头">拓展头</h3>
<p>除此之外，IPV6将一些IP层的<strong>可选功能</strong>实现在上层封装和IPV6基本头部之后的扩展头部中，主要的扩展报头有：</p>
<ul>
<li>逐跳选项</li>
<li>路由报头</li>
<li>分段报头</li>
<li>认证报头</li>
<li>封装安全有效载荷报头</li>
<li>目标选项</li>
</ul>
<p>每一种扩展报头其实也有自己特定的协议号，例如：路由报头为43，AH报头为51。上图中抓到的ICMPv6包的协议号为58(0x3a转为10进制)，其他一些常见的协议号如下所示</p>
<table>
<thead>
<tr class="header">
<th>协议号</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>逐跳扩展头</td>
</tr>
<tr class="even">
<td>1</td>
<td>ICMPv4</td>
</tr>
<tr class="odd">
<td>6</td>
<td>TCP</td>
</tr>
<tr class="even">
<td>17</td>
<td>UDP</td>
</tr>
<tr class="odd">
<td>43</td>
<td>路由扩展头(使数据分组经过指定的中间节点)</td>
</tr>
<tr class="even">
<td>58</td>
<td>ICMPv6</td>
</tr>
<tr class="odd">
<td>89</td>
<td>OSPF</td>
</tr>
</tbody>
</table>
<p>每一个基本报头和扩展报头的<code>NextHeader</code>字段标识后面紧接的内容，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t5t1qn1g6dmthhs71fps19rl3h.png"
alt="拓展报头" />
<figcaption aria-hidden="true">拓展报头</figcaption>
</figure>
<h2 id="icmpv6协议">ICMPv6协议</h2>
<p>ICMPv6协议与回声请求、抑制消息、重定向、参数错误等功能相关，相关的命令为<code>ping</code>、<code>traceroute</code></p>
<p>ICMP报文格式为<code>Type+Code+CheckSum</code>,其报文的格式以及在整个分组的位置如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t7ujoi1s0010q511td1fjir5s9.png"
alt="ICMPv6分组格式和位置" />
<figcaption aria-hidden="true">ICMPv6分组格式和位置</figcaption>
</figure>
<p>ICMPv6报文类型可分为两种
(1)<strong>差错报文</strong>(Type=0~127)：通告IPV6分组传输中出现的错误。如目标不可达、数据包超长、超时、参数问题
(2)<strong>信息报文</strong>(Type=128~255)：提供诊断和附加的主机功能。如回声请求(Type=128)和应答(Type=129)，ND协议等</p>
<p>ICMPv6的三个实际应用为</p>
<ul>
<li>ping</li>
<li>tracert(HopLim与v4中的TTL意思相同) &gt;第一个请求：HopLim=1
第一跳路由器收到，发送超时(HopLim=0)消息 得到第一跳路由器的信息
第二个请求：HopLim=2 第二跳路由器收到，发送超时消息
得到第二跳路由器的信息
注意：HopLim的最大值为30，且为了让每一个请求都返回超时信息，通常设置ICMPv6报文的端口不可达。</li>
<li>PMTU发现：通过试探的方式发现路径允许的最大的MTU,如下为一个简单的过程。</li>
</ul>
<p>1)源机向目的机发送MTU=1500字节的IPV6数据包
2)路由器B向源发送超长消息，指定MTU=1400字节
3)源机向目的机发送MTU=1400字节的IPV6数据包
4)路由器C向源发送超长消息，指定MTU=1300字节
5)源机向目的机发送MTU=1300字节的IPV6数据包
6)此后，该路径的MTU都使用1300字节</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4t9h85q1q6t1jeo2ae131517n2m.png"
alt="PMTU发现" />
<figcaption aria-hidden="true">PMTU发现</figcaption>
</figure>
<h2 id="ipv6路由">IPV6路由</h2>
<p>在讲述IPV6的路由之前先回顾IPV4的路由，IPV4的路由可以分为两大类：同一网络的路由和不同网络的路由。</p>
<p>同一网络间主机的通信主要依赖于ARP协议，根据目标IP查询其对应的mac地址，然后两者便可通信，中间可以不经过路由器。</p>
<p>不同网络间的通信则需要借助路由器,其过程如下所示 <img
src="https://wulc.me/imgs/image_1b4tbvn0s6ut1k9rlri1u4bb1m9.png"
alt="IPV4路由过程" /></p>
<p>而对于 IPV6 的路由也可分为两种情况：
<strong>on-link</strong>：源机和目的机在<strong>同一链路</strong>的数据转发
<strong>off-link</strong>：源机和目的机<strong>不在同链路</strong>的数据转发</p>
<p>通过地址前缀判断源和目的是否在同一链路。</p>
<h3 id="on-link">on-link</h3>
<p>处于同一链路的两条主机要通信就要知道对方的mac地址，在IPV4中通过ARP实现,ARP是通过广播实现的，但是IPV6中并没有广播的概念。在IPV6中，通过ND协议来完成这个地址解析的工作。</p>
<p>ND协议在我们介绍无状态地址自动配置的时候已经介绍过，但是除了无状态地址自动配置外，ND协议还被用于<strong>地址解析和路由重定向</strong>。</p>
<p>ND协议共有五种报文，五种报文都是以<strong>ICMPv6报文</strong>的形式出现，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4td6gl71s651ddh5p5rr1e8cm.png"
alt="NS五种报文" />
<figcaption aria-hidden="true">NS五种报文</figcaption>
</figure>
<p>其地址解析过程如下：</p>
<p>1）首先查找邻居缓存表（IPV6 nc），没有则进行地址解析
（类似于查找ARP表）
2）源主机发送组播<strong>NS报文</strong>，该报文的目的地址为<strong>目标IPV6地址所对应的被请求节点组播地址</strong>（Solicited-node），在其中也包含了自己的链路层地址
3）目标主机收到NS报文后，就会了解到发送主机的IPV6地址和相应链路层地址；同时由于目标主机正在使用报文内的目标地址，所以会目标主机向源主机<strong>单播</strong>发一个邻接点公告报文（NA），该报文中包含自己的链路层地址。</p>
<p><strong>这里需要注意的是最后的NA报文是单播的，而在无状态地址自动配置中NA报文是组播，原因在于无状态地址自动配置的时候发送NS的主机还没有有效的地址，而这里的主机已经有了，只是要找到另外一台主机的mac地址而已。</strong></p>
<p>下图便是上面提的地址解析过程 <img
src="https://wulc.me/imgs/image_1b4tdscaq191a6t81vqpn26lm213.png"
alt="IPV6地址解析" /></p>
<h3 id="off-link">off-link</h3>
<p>当源和目的不在同一链路的时候，需要考虑两个问题</p>
<p>1.主机发给哪个路由器？（主机-路由器）
2.路由器发给哪个路由器？（路由器-路由器）</p>
<p>对于第一个问题，支持IPV6的主机有一个数据结构<code>DestinationCache</code>，要发送数据到某个目的地址的时候，首先查询这个数据结构，如果查不到，就查路由表，让后将查到的信息记录在这个数据结构中。</p>
<p>如果查询到的目的地址是on-link的，将目的地址本身加入DC表的nexthop域；如果目的地址是off-link的，将路由表中的下一跳加入DC的nexthop域。</p>
<p>在这个过程中，会涉及到重定向的问题，重定向的作用其实就是给主机发送更好的路由。下图为一个简单的例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4teq8bo15gdtnoni61hme8701t.png"
alt="路由重定向" />
<figcaption aria-hidden="true">路由重定向</figcaption>
</figure>
<p>当 PC1 要与 PC2 通信时，首先会先向 RT1
查询，RT1查询后发现RT2可以直接提供这个路由，于是RT1告诉PC1以后如果要与PC2通信直接找RT2就好了，效率会更高，这就是路由重定向。</p>
<p>实际中，RT1发现<strong>报文的出口和入口相同或者源地址跟报文下一跳同属一个网段</strong>，则发出重定向报文，重定向报文就是ND报文中的最后一种报文(其他四种是RS，RA，NS，NA)</p>
<p>对于问题2，也就是路由器与路由器之间的传输，就需要依靠路由表了。路由表中的路由根据是否需要人工配置而分为静态路由和动态路由，其中静态路由需要人工配置，动态路由则通过协议学习，在IPV6中的动态路由协议主要有<code>RIPng</code>，<code>OSPFv3</code>和<code>BGP4+</code>。</p>
<p><strong>RIPng</strong>保留了RIP的主要特点</p>
<ul>
<li>距离矢量采用跳数，16跳为不可达</li>
<li>工作机制不变；</li>
<li>仍然采用水平分割、毒性逆转、触发更新等技术减少路由环的发生</li>
</ul>
<p>主要改变的地方：</p>
<ul>
<li>组播代替广播：主机不再受骚扰</li>
<li>下一跳信息由单独的<code>R Table Entry</code>表示 （RTE）</li>
<li>安全考虑：不单独设置验证，由IPV6本身保证</li>
<li>只用于IP网络：不再支持其他网络协议</li>
</ul>
<p>同样，<strong>OSPFv3</strong>保留了OSPFv2的主要工作机理</p>
<ul>
<li>采用链路状态数据库</li>
<li>与邻接路由器同步</li>
<li>DR选举、SPF算法、area区域支持</li>
</ul>
<p>主要改变的地方</p>
<ul>
<li>地址信息从LSA中移除；（LSU载荷中包含地址信息）</li>
<li>RouterID仍然采用32位，但不再跟地址有关</li>
<li>重新定义了LSA（如增加了link-LSA、Intra-Area-Prefix-LAS等，即LSDB的内容发生了变化）</li>
<li>不再支持认证</li>
</ul>
<h2 id="过渡技术">过渡技术</h2>
<p>从IPV4到IPV6的过渡被认为要经过三个阶段</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4tjslmh14gp1unf16qg9un4ot2n.png"
alt="v4到v6的过渡" />
<figcaption aria-hidden="true">v4到v6的过渡</figcaption>
</figure>
<p>过渡的技术共分为三类</p>
<ul>
<li>双栈：网络设备上运行IPV6/IPV4双协议栈</li>
<li>隧道：IPV6网络上承载IPV4分组，或相反</li>
<li>翻译/转换：地址、分组、端口的转换</li>
</ul>
<h3 id="双栈">双栈</h3>
<p>一般基础设施设备，如路由器、交换机、公用服务器等，需要运行和支持双栈，非基础设置则可运行单协议或双协议。</p>
<h3 id="隧道">隧道</h3>
<p>根据创建方式可以大致分为两类 1）<strong>手动隧道</strong>：事前配置
2）<strong>自动隧道</strong>：创建和拆除都依赖当前网络条件</p>
<p>根据实际的网络环境又可以分为两类隧道</p>
<ul>
<li>IPV6分组通过IPV4网络的隧道</li>
<li>IPV4分组通过IPV6网络的隧道</li>
</ul>
<p>IPV6分组通过IPV4网络时，IPV6分组作为数据部分搭载到IPV4分组中，在这种情形下，IPV4分组头部的<code>protocol=41</code>，如下图所示。</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4tkj09h1l3jg7bobd1f5i1mq834.png"
alt="v6 over v4" />
<figcaption aria-hidden="true">v6 over v4</figcaption>
</figure>
<p>根据IPV4网络位置的不同，在不同的位置建立</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4tkrng6qbl1flp1r7en9a1h9q4b.png"
alt="隧道1" />
<figcaption aria-hidden="true">隧道1</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1b4tkrvd51b29vs517np1jk0b9a4o.png"
alt="隧道2" />
<figcaption aria-hidden="true">隧道2</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1b4tks9g21uhsuga1dsh1riecji55.png"
alt="隧道3" />
<figcaption aria-hidden="true">隧道3</figcaption>
</figure>
<figure>
<img src="https://wulc.me/imgs/image_1b4tksuvu3n41oc8onl1u01rtp5i.png"
alt="隧道4" />
<figcaption aria-hidden="true">隧道4</figcaption>
</figure>
<p>IPV4分组通过IPV6网络的情况跟上面一样。</p>
<h3 id="翻译转换">翻译/转换</h3>
<p>翻译/转换就是从IPV4转换到IPV6，或反过来，不仅发生在网络层，还有传输层和应用层。如下图所示是一个翻译/转换的例子。</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4tl0vca1bva1d5f1t04qer189s6c.png"
alt="翻译/转换" />
<figcaption aria-hidden="true">翻译/转换</figcaption>
</figure>
<p>注意：<strong>当双栈和隧道都无法使用的时候，才使用翻译/转换技术</strong>；适用纯IPV4节点和纯IPV6节点间的通信。</p>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络课程总结--RIP与OSPF</title>
    <url>/2016/12/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93--RIP%E4%B8%8EOSPF/</url>
    <content><![CDATA[<p>本文主要讲述内部网关协议中两个著名的协议RIP和OSPF。</p>
<span id="more"></span>
<p>路由器的基本功能是路由(Routing)和转发(Forwarding)。其中路由指的是通过路由选择协议将路由信息注入到路由表中，转发指的是依据路由表和分组携带的信息将分组从入口转到正确的出口的过程。</p>
<p>分组转发的技术有以下几种</p>
<ul>
<li><strong>Source routing（源路由）</strong>：分组携带路径</li>
<li><strong>Table of virtual
circuits（虚电路）</strong>：穿越网络建立链接及状态，使用链接转发分组</li>
<li><strong>Table of global addresses
(IP，数据报交换)</strong>：路由器维持到目的地的下一条，分组需要携带目的地地址</li>
</ul>
<p>本文主要涉及到的是第三种。</p>
<h2 id="静态路由">静态路由</h2>
<p>配置命令
<code>Ip route prefix mask &#123;address|interface&#125; [distance]</code></p>
<p>使用地址(address)和使用接口(interface)的差别</p>
<ul>
<li>使用接口，路由器知道从哪里转发出去，更高效</li>
<li>使用地址需要第二次查找，以确定转发接口</li>
</ul>
<p>距离(distance)的特定</p>
<ul>
<li>直连网络的管理距离为0</li>
<li>静态路由的管理距离为1</li>
<li>值越小，优先级越高</li>
<li>到达某个网络出现多条路由的情况下，可以依据管理距离进行选择</li>
</ul>
<p>还可以通过管理距离配置备份路由（也称为浮动静态路由），如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4uspd50dec1ssb1v7j1aunb379.png"
alt="备份路由" />
<figcaption aria-hidden="true">备份路由</figcaption>
</figure>
<h2 id="动态路由">动态路由</h2>
<p>动态路由就是通过协议动态地学习到路由信息，据其作用域的不同，又可分为内部网管协议(IGP)和边界网络协议(BGP)；内部网关协议有RIP，OSPF，IGRP，EIGRP等，其在网络中的位置入下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4v3ecpin8p1qibhum18j814n05i.png"
alt="路由协议在协议层中的位置" />
<figcaption aria-hidden="true">路由协议在协议层中的位置</figcaption>
</figure>
<p>这里主要讲述内部网络协议中的RIP和OSPF。</p>
<h3 id="rip">RIP</h3>
<p>RIP是典型DV(Distance Vector,距离矢量)协议，其工作原理如下：</p>
<ul>
<li>每个路由器维护两个向量<span
class="math inline">\(D\_i\)</span>和<span
class="math inline">\(S\_i\)</span>来表示<strong>该点到网上所有节点的路径距离及其下一个节点</strong></li>
<li><strong>相邻路由器</strong>之间交换路径信息</li>
<li>各节点<strong>根据路径信息更新路由表</strong></li>
</ul>
<p>向量<span class="math inline">\(D\_i\)</span>和<span
class="math inline">\(S\_i\)</span>的含义如下: <span
class="math inline">\(d\_{i1}\)</span>：从节点i 到节点1 的时延向量 <span
class="math inline">\(S\_{i1}\)</span>：从节点i到节点1的一条最小时延路径上的下一个节点
n ：网络中的节点数</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4uts4rn1k9cm5n1a4scrg1q4213.png"
alt="距离矢量" />
<figcaption aria-hidden="true">距离矢量</figcaption>
</figure>
<p>RIP使用跳数作为路由选择的度量，当到达目的网络的跳数超过15跳，数据包将被丢掉。
RIP路由更新广播默认周期为30秒。</p>
<p>下图是RIP的一个简单例子</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4uulq6n1c0m1fmi1o8qk0pvlc1g.png"
alt="RIP工作原理" />
<figcaption aria-hidden="true">RIP工作原理</figcaption>
</figure>
<p>RIP在ipv4中的协议版本有RIPv1和RIPv2,其中 RIPv1
只支持传输自然网段的地址(也就是ABC三类网络)，而 RIPv2
修复了这个缺陷,增加了一个子网掩码的段，支持所有长度的子网掩码，也支持
CIDR 和 VLSM。</p>
<h4 id="路由环路">路由环路</h4>
<p>RIP协议可能会导致路由环路，下图为一个路由环路的例子，图中初始状态是正常状态，但是当40.0.0.0的网络挂掉后，C
不会修改到网络 40.0.0.0 的距离不可达，而是相信B传过来的关于 40.0.0.0
网路的距离为 1 的消息，从而导致错误信息不断在网络中传输，每个路由器到
40.0.0.0 的距离不断增大，直到距离超过15才将网络40.0.0.0
标记为不可达。</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4uv2n5vcbvshosde131fuv51t.png"
alt="路由环路" />
<figcaption aria-hidden="true">路由环路</figcaption>
</figure>
<p>虽然上面的例子中距离增大到16的时候会将网络 40.0.0.0
标记为不可达，但是这样的话收敛的速度会非常慢。为了提高收敛的速度，常常会有以下方法</p>
<ul>
<li>水平分割（Split Horizon）</li>
<li>毒性逆转（Poison Reverse）</li>
<li>抑制定时器（Hold-Down Timers）</li>
<li>触发更新（Triggered Updates）</li>
</ul>
<p><strong>水平分割（Split Horizon）</strong>
分析上面的例子中路径环产生的原因，就是B向C提供了一条过时的、错误的路由信息。</p>
<p>但是分析可知，B必须经由C方可到达网络40.0.0.0，所以B不可能向C提供任何有价值的路由信息。因此可以修改B对C提供的路由，禁止B向C提供关于此信宿的路由信息，具体操作就是<strong>B告诉C一条在正常情况下不真实的消息：网络40.0.0.0不可达（距离为无穷大，实际中记为16即可）。</strong></p>
<p>通过水平分割可以使得上面的情况的收敛速度加快，如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4uvpghh12mfool1fd3rtq4go2a.png"
alt="水平分割" />
<figcaption aria-hidden="true">水平分割</figcaption>
</figure>
<p><strong>毒性逆转（Poison Reverse）</strong>
分析上面的例子，当网络40.0.0.0
挂掉的时候，路由器C并没有采取任何措施，而是利用了B的信息更新。</p>
<p>而毒性逆转的方法就是指当C
发现网络40.0.0.0发生故障时，主动将到达信宿的距离改为无穷大（实际中改为16即可），收敛过程如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4v183kjv0lpi11m0g16be10p32n.png"
alt="毒性逆转收敛" />
<figcaption aria-hidden="true">毒性逆转收敛</figcaption>
</figure>
<p><strong>抑制定时器（Hold-Down Timers）</strong>
当C发现网络40.0.0.0发生故障时，启动抑制计时器。</p>
<p>在抑制计时期间内，有三种可能 1.
如果网络状态转变，即<code>down→up</code>，则关闭计时器，保留原有路由信息
2.
如果收到来自B的关于信宿的路由信息，且路径比原有路径短，则关闭计时器，更新路由信息
3. 如果无上述两种情况发生，计时器到时，更新路由为信宿不可达。</p>
<p><strong>触发更新（Triggered Updates）</strong>
当C发现网络40.0.0.0发生故障时，不等下一刷新周期到来，<strong>立刻更改路由为“信宿不可达”</strong>，引起全网的连锁反映，迅速刷新</p>
<p>类似于RIP这种DV类协议的优点是算法简单，但是缺点有：</p>
<ul>
<li>交换的路径信息量大</li>
<li>路径信息传播慢，使得路径信息可能不一致。</li>
<li>收敛速度慢，存在无穷计算问题。</li>
<li>不适合大型网络</li>
</ul>
<h4 id="ripng">RIPng</h4>
<p>RIPng 是IPV6 中使用的RIP协议，保留了原来 RIP
协议的一些特性，也增加了一些新的特点。</p>
<p>RIPng有以下特点</p>
<ul>
<li>UDP端口号：使用521端口收、发报文（RIPv2用520端口）</li>
<li>组播地址：<code>FF02::9</code>作为链路本地范围的路由器组播地址</li>
<li>源地址：使用链路本地地址<code>FE80::/10</code>作为源地址发送RIPng路由信息报文</li>
<li>下一跳地址：使用128位的IPv6地址</li>
</ul>
<p>’ RIPng 和 RIPv2的报文对比如下
其中RIPng的一个报文种可包含多条路由信息，而RIPv2一个报文只含有一条路由信息。</p>
<p>RIPng的报文格式为 <img
src="https://wulc.me/imgs/image_1b4v277qo80a1b811qtburvkel3h.png"
alt="RIPng报文" /></p>
<p>RIPv2 的报文格式为</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4v26h5i5v98cq14m015ttk0234.png"
alt="RIPv2报文" />
<figcaption aria-hidden="true">RIPv2报文</figcaption>
</figure>
<p>RIPng中有Request和Response两种报文，其作用分别如下
<strong>Request报文</strong>：当路由器启动或更新时，发该类报文（组播），用于请求其他路由器的路由信息
<strong>Response报文</strong>：对Request的回应，通常包含全部的路由信息。除了收到Request的时候会发送，路由器还会周期性地发送。</p>
<h4 id="配置">配置</h4>
<p>RIP的配置的主要工作就是启动RIP进程并声明路由器所连接的网络。如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4v2k08qtla1dgv8j515s0q733u.png"
alt="RIP配置" />
<figcaption aria-hidden="true">RIP配置</figcaption>
</figure>
<p>默认是RIPv1，如果要配置RIPv2,需要<code>version 2</code>的命令，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4v2or8m2qr1k8qflp1go5er74b.png"
alt="RIPv2配置" />
<figcaption aria-hidden="true">RIPv2配置</figcaption>
</figure>
<p>RIPng的配置过程入下 <img
src="https://wulc.me/imgs/image_1b4v2tuvh1kri12kf90c1qq6133b4o.png"
alt="RIPng配置" /></p>
<h3 id="ospf">OSPF</h3>
<p>OSPF时典型的LS(Link
State,链路状态)协议，其思想是<strong>通过邻居的LSA(Link-state
advertisement,
链路转态通告)构建整个网络的拓扑并构建最小生成树，然后通过dijkstra
计算最短路径，并根据最短路径修改路由表。</strong></p>
<p>OSPF有以下特点</p>
<ul>
<li>无路由自环</li>
<li>支持VLSM、CIDR</li>
<li>使用<strong>带宽</strong>作为度量值（108/BW）</li>
<li>收敛速度快</li>
<li>通过分区实现高效的网络管理</li>
<li>支持帧中继，X2.5, Ethernet, ppp等网络</li>
<li>可以在大型网络中使用</li>
</ul>
<p>OSPF协议的一些基本概念如下;</p>
<ul>
<li><strong>协议号=89</strong>：IP头中代表OSPF报文的协议号是89</li>
<li><strong>RouterID</strong>：一个32位的无符号整数，是一台路由器的唯一标识，在整个自治系统内唯一</li>
<li><strong>路由器间的关系</strong>：邻居(Neighbor)、邻接(Adjacent)、未知(Unknown)</li>
<li><strong>TTL=1</strong>：通常OSPF报文不转发，只被传递一条，即在IP报头的TTL值被设为1，</li>
<li>DR(Designated Router)和BDR(Backup Designated Router):
DR是由所有路由器选举出来的，<strong>目的是减少路由器间同步的次数</strong>，所有路由器只需要和选举出来的DR进行同步即可，原理如下图所示，BDR是DR的备份路由器。</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/image_1b4vf3po2etc1ila1pv3cto3qa6p.png"
alt="选举DR的必要性" />
<figcaption aria-hidden="true">选举DR的必要性</figcaption>
</figure>
<p>这里需要注意的是，DR是路由器选出来的，选举规则根据其priority值的大小，若priority相同则比较router
id；DR一旦当选，除非路由器故障，否则不会更换；DR选出的同时，也选出BDR，DR故障后，由BDR接替DR成为新的DR</p>
<h4 id="报文类型">报文类型</h4>
<p>OSPF的分组有五种，分别如下所示</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>OSPF报文类型</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Type = 1, Hello报文</td>
<td>建立和维护连接，报文中包含自己的RouterID和区域ID</td>
</tr>
<tr class="even">
<td>Type = 2，DD(数据库描述)报文</td>
<td>描述一个OSPF路由器的链路状态数据库内容，传输LSA摘要</td>
</tr>
<tr class="odd">
<td>Type = 3，LSR(链路状态请求)报文</td>
<td>请求对方发送自己没有的LSA</td>
</tr>
<tr class="even">
<td>Type = 4，LSU(链路状态更新)报文</td>
<td>LSR 的应答，可回传<strong>多条</strong>LSA</td>
</tr>
<tr class="odd">
<td>Type = 3，LSAck(链路状态确认)报文</td>
<td>确认收到LSA</td>
</tr>
</tbody>
</table>
<h4 id="建立毗邻关系">建立毗邻关系</h4>
<p>OSPF运行的步骤为 1. 建立路由器毗邻关系 2. 选举DR和BDR 3. 发现路由 4.
选择最佳路由 5. 维护路由信息</p>
<p>OSPF中，一个路由器的的状态可能为</p>
<ul>
<li>Down</li>
<li>Init（初始）</li>
<li>Two-way（双向）</li>
<li>ExStart（准启动）</li>
<li>Exchange（交换）</li>
<li>Loading（加载）</li>
<li>Full adjacency（全毗邻）</li>
</ul>
<p>结合路由器的状态，OSPF建立毗邻关系的步骤如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4v54o4s1a2h1s6d1umht3q1suq5v.png"
alt="OSPF建立毗邻关系" />
<figcaption aria-hidden="true">OSPF建立毗邻关系</figcaption>
</figure>
<p><strong>1）</strong>RT1，RT2在某个接口激活了OSPF后，都会开始在这个接口上去发组播的Hello报文，目的是发现OSPF邻居，此时双方都处于<code>Down</code>状态。</p>
<p><strong>2）</strong>当RT2收到RT1发来的Hello包（Neighbors Seen
为空），此时RT2的状态变为<code>init</code>，然后将RT1的Router-ID存储放在Hello报文中(Neighbors
Seen =
RT1)发送出去，当RT1收到这个hello报文并从中找到自己的Router-ID，RT1会认为与RT2已经完成了双边关系的建立，此时RT1的状态变为<code>Two-way</code>，而RT1会发送Neighbors
Seen = RT2的hello包让RT2的状态也变为<code>Two-way</code>。</p>
<p><strong>3）</strong>接下来RT1和RT2会进入<code>ExStart</code>状态并开始进行Master、Slave的协商。协商M/S的目的是为了决定在后续的LSA交互中，谁来决定DD（Database
Description）报文的序列号（Sequence
Number），而Router-ID大的那个OSPF路由器的接口将会成为Master（注意这里的Master不是DR）.协商过程通过DD报文实现，有三个关键的字段：I、M、MS，其含义如下</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I(Init)</td>
<td>如果是第一个DD报文则置1，其它的均置0</td>
</tr>
<tr class="even">
<td>M(More)</td>
<td>如果是最后一个DD报文则置0，否则均置1</td>
</tr>
<tr class="odd">
<td>M/S</td>
<td>设置进行DD报文双方的主从关系，如果本端是Master角色，则置1，否则置0</td>
</tr>
<tr class="even">
<td>Sequence Number</td>
<td>指定所发送的DD报文序列号。主从双方利用序列号来确保DD报文传输的可靠性和完整性</td>
</tr>
</tbody>
</table>
<p><strong>4）</strong>确认了M/S关系后，两个路由器就进入了
<code>Exchange</code> 状态，
主路由器首先开始和从路由器共享链路状态信息。如果将链路状态数据库比喻成一本书，那么DD报文相当于这本书的目录，通过DD报文，可以发现自己所没有的信息。</p>
<p><strong>5）</strong>当所有的DD报文传输完后，假如从路由器通过DD报文发现了自己所没有的信息后，会发送LSR报文给主路由器，随后主路由器会发送LSU报文给从路由器。从路由器将该信息合并到它的本地链路状态数据库中。从路由器会回应一个LSAck包给主路由器。此时两者处于<code>loading</code>状态。</p>
<p><strong>6）</strong>两者的链路数据库一致，达到了<code>full</code>状态。</p>
<p>其状态转移图如下所示，图中的稳态有三种(<code>Down</code>,<code>Two-way</code>,<code>Full</code>)
<img src="https://wulc.me/imgs/image_1b4v5vjpmrpf1chc1dbt1898o8u6c.png"
alt="OSPF状态转移图" /></p>
<h4 id="其他概念">其他概念</h4>
<p><strong>克服路由自环</strong>
OSPF能够克服路由自环的原因有以下几个</p>
<ul>
<li>每一条LSA都标记了生成者（用生成该LSA的路由器的RouterID标记），其他路由器只负责传输，这样不会在传输的过程中发生对该信息的改变和错误理解。</li>
<li>路由计算的算法是SPF，计算的结果是一棵树，路由是树上的叶子节点，从根节点到叶子节点是单向不可回复的路径。</li>
<li>区域则通过规定骨干区域避免</li>
</ul>
<p><strong>大型网络中存在的问题及对策</strong></p>
<p>在大型网络中，OSPF存在着以下问题</p>
<ul>
<li>链路状态数据库(LSDB)非常庞大，占用大量存储空间</li>
<li>计算最小生成树耗时增加，CPU负担很重,一点变化都会引发从头重新计算</li>
<li>网络拓扑结构经常发生变化，网络经常处于“动荡”之中</li>
</ul>
<p>针对该问题，常用的解决方法是对OSPF划分区域</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4vjo5c2cn367e1m23130j17d87j.png"
alt="ospf划分区域" />
<figcaption aria-hidden="true">ospf划分区域</figcaption>
</figure>
<p><strong>OSPF路由器的类型</strong>
根据位置不同，OSPF路由器可以被被划分为不同类型</p>
<ul>
<li>内部路由器 --- 路由器所有接口都在一个区</li>
<li>主干路由器 --- 所有接口都在主干区域的路由器</li>
<li>区域边界路由器(ABR) ---路由器接口分属不同区域(Area)</li>
<li>自治域边界路由器 (ASBR) ---
路由器至少有一个接口不属于本自治域(AS).</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/image_1b4vjsatj1ugu3lj11tpcfn9rp80.png"
alt="路由器类型" />
<figcaption aria-hidden="true">路由器类型</figcaption>
</figure>
<h4 id="ospfv3">OSPFv3</h4>
<p>OSPFv3保留了OSPFv2的基本机制</p>
<ul>
<li>网络类型和接口类型</li>
<li>邻居发现和邻接（毗邻）建立机制</li>
<li>接口状态机和邻居状态机</li>
<li>基于LSDB计算路由</li>
<li>LSA老化更新机制</li>
<li>泛洪机制(Flooding mechanism)</li>
<li>共五种协议报文: Hello, DD, LSR, LSU, LSAck</li>
</ul>
<p>但是 OSPFv3 在 OSPFv2 的基础上做出的变化为：</p>
<p><strong>1）基于链路运行</strong></p>
<p>在 OSPFv2
中，协议的运行是基于<strong>子网</strong>的，邻居之间形成邻接关系的条件之一就是两端的IP地址属于同一网段而且掩码相同。</p>
<p>而在 OSPFv3
中，协议基于<strong>链路</strong>运行，与具体的IPv6地址、前缀分离开来，即使同一链路上的不同节点具有不同的IPv6地址时，协议也可以正常运行。</p>
<p><strong>2）取消了编址语义</strong></p>
<p>在OSPFv2中，协议分组和LSA中的许多字段都是来自于网络上的某个IP地址，或掩码，或某个IP子网号。严重依赖IPv4。</p>
<p>在OSPFv3中，取消了上述编址性语义，而只保留协议运行必须的核心内容。ID依然保留32位，但只是一个编号，不再包含地址信息。</p>
<p><strong>3）链路本地地址的使用</strong></p>
<p>在OSPFv2中，每一个运行OSPF的接口都必须有一个全局的IPv4地址，协议的运行和路由的计算都依赖于它。</p>
<p>在IPv6中，每个接口都会分配本地链路地址（link-local address），OSPFv3
使用了这个本地链路地址作为协议分组发送的源地址（虚连接除外），而且使用它作为路由的下一跳。</p>
<p>这样可以节省大量的全局地址，同时可以说协议的运行独立于IPv6，可以方便的扩展用于多种协议的路由</p>
<p><strong>4）使用专门的LSA来发布路由前缀信息</strong></p>
<p>新增加了<code>Intra-Area-Prefix-LSA</code>，用于传递区域内路由前缀
新增加了 <code>Link-LSA</code>，用于传递链路范围内的IPv6前缀。</p>
<p><strong>5）明确的LSA泛滥范围</strong></p>
<p>泛滥的范围分为：本地链路范围（Link-local scope），区域范围（Area
scope），AS范围（AS scope）</p>
<p><strong>6）提供了对多实例的支持</strong></p>
<p>在OSPFv2中，不同的实例必须运行在不同的链路上；在OSPFv3中，明确的提供了对多实例的支持，同一链路也可以运行多个OSPF实例了，而且互相独立运行不会影响。</p>
<h4 id="配置-1">配置</h4>
<p><strong>单区域配置</strong></p>
<figure>
<img src="https://wulc.me/imgs/image_1b4vnobbs1k02iu81fso1u1832j8d.png"
alt="OSPF单区域配置" />
<figcaption aria-hidden="true">OSPF单区域配置</figcaption>
</figure>
<p><strong>配置Routert-ID</strong></p>
<p>router-id是一个可选的配置，其获取方式依次为 1）手动配置
2）使用环回地址作为router ID
3）如果没有，选择路由器的最高逻辑地址作为routerID</p>
<p>注意：IOS 的某些早期版本无法识别 router-id
命令；因此，为这些路由器设置路由器 ID 的最佳方法是使用环回接口</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4vo37b6lffipr137u7emv5u8q.png"
alt="配置router-id" />
<figcaption aria-hidden="true">配置router-id</figcaption>
</figure>
<p><strong>配置优先级</strong>
优先级的取值范围为0~255，优先级为0的路由器不能被选举为DR</p>
<figure>
<img src="https://wulc.me/imgs/image_1b4vo4iql9lsc6v13qleu16ku97.png"
alt="优先级配置" />
<figcaption aria-hidden="true">优先级配置</figcaption>
</figure>
<p><strong>配置计时器</strong></p>
<p>广播型OSPF网络，缺省hello包间隔为10秒，down机判断间隔为40秒
非广播型OSPF网络，缺省hello包间隔为30秒，down机判断间隔为120秒</p>
<p>实际配置的例子如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Router（config-if）＃ip ospf hello-interval 5</span><br><span class="line">Router（config-if）＃ip ospf dead-interval 10</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>并行算法的设计</title>
    <url>/2016/06/04/%E8%AE%BE%E8%AE%A1%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>本文主要讲述并行算法设计的一些注意事项。</p>
<span id="more"></span>
<p>设计并行算法首先需要要确认问题是否可以被并行化，最典型的情况是在处理一个任务队列时，队列中的前后任务是独立的，这时候就可以通过并行化让多个进程或线程同时处理其中的多个任务。<strong>关键点在于大任务可以被分解为若干个互相独立的小任务。</strong></p>
<p><strong>设计并行算法可以从以下四方面着手 1）分治(divide and conquer)
2）数据分解(data decomposition) 3）管道分解任务(decomposing tasks with
pipeline) 4）任务分配(processing and mapping)</strong></p>
<h2 id="分治divide-and-conquer">分治(divide and conquer)</h2>
<p>分治法是一个非常常用的思想，通过将一个问题分解成规模更小的子问题，然后并行解决子问题，再合并子问题的结果即可。如快速排序、归并排序都是分治法的经典例子。下图是归并排序的一个例子</p>
<p><img
src="https://wulc.me/imgs/image_1akfr595qsoq1ta91gbl1a1ekra9.png" /></p>
<h2 id="数据分解data-decomposition">数据分解(data decomposition)</h2>
<p>数据分解指当要处理的数据的最小单元间相互独立时，可通过并行化来实现。如将一个2X2的矩阵中的每个元素都乘上4时，如果采取串行化需要按顺序将每个元素逐一乘上4，但是采取并行化时可以同时将每个元素乘上4。如下所示，图中的worker指进程或线程。</p>
<p><img
src="https://wulc.me/imgs/image_1akfrfceq19ja1dve143p18o51m2im.png" /></p>
<p>上面的例子比较简单，仅仅是为了说明数据分解的概念，在实际应用中，往往还需要考虑数据量与worker数量的不对称性问题，并且在将各自的结果合并时中需要考虑不同worker间的通信问题。</p>
<h2
id="管道分解任务decomposing-tasks-with-pipeline">管道分解任务(decomposing
tasks with pipeline)</h2>
<p>管道（pipeline），也可以称为流水线技术，是类似于工厂生产的流水线的一种设计方式。如下图所示就是流水线的一个例子：</p>
<p><img
src="https://wulc.me/imgs/image_1akft46c417969rbn9m1n0b1rmb13.png" /></p>
<p>上图首先将一个大任务分成了四个小任务，然后每个worker分别处理其中的一个任务，每个任务的输出是下一个任务的输入。</p>
<p>假设每个小任务消耗的时间是t，那么当完成1个大任务的时候串行和并行方式消耗的时间均是4t。但是当完成k个大任务时，串行化消耗的时间是<strong>4t*k</strong>,但是并行化需要的时间是<strong>4t+(k-1)*t</strong>,当k很大时，并行化节省的时间就相当可观了。</p>
<h2 id="任务分配processing-and-mapping">任务分配(processing and
mapping)</h2>
<p>上面提到的三种方法均是将大任务分解，然后通过并行完成小任务来实现并行化。但是在将任务分解后,需要注意的是<strong>如何分配任务给各个
worker，使得每个 worker 的负载均衡，从而达到最优的效果</strong>。</p>
<p>在这个问题主要是要<strong>区分独立的任务和需要交换数据（通信）的任务</strong>。独立的任务可以分配给不同的worker去完成，因为这些任务不需要通信的成本；而将需要经常进行通信的任务让单独一个worker完成，考虑到网络通信的开销，这样能够提高性能。</p>
<h2 id="总结">总结</h2>
<p>上面主要提到了并行化算法的几个关键点，包括将大任务进行分解的几种方法（分治、数据分解、管道）以及将分解后的任务分配给worker时的注意事项。要注意的是这几种方法在实际中常常会混用，举一个实际一点的例子，如果要对一个很大的数组排序，单台机器的内存都放不下这个数组了，那该怎么办？</p>
<p>首先将数组分成k份，然后分配给k台机器分别进行排序，排序完毕后我们有了k个sorted
list，然后将k个sorted
list两两合并，当合并后的数据越来越大时，单台机器内存不足时，可以采取外排序，将两个sorted
list存储在硬盘中，每次取出前n个进行合并。</p>
<p>也许在实际中有更好的方法，但是上面的例子中实现的并行化就是利用到了分治法和数据分解法，实际中还可以根据机器的配置情况分配不同的任务负载。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>并行编程</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络课程总结--组播基础</title>
    <url>/2016/12/20/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93--%E7%BB%84%E6%92%AD%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>组播是介于单播和广播间的一种通信方式，单播是单台源机和单台目的机的通信，广播是单台源机和网络中所有其他主机的通信。而组播则是单台源机和网络中部分主机的通信。本文主要介绍组播中的一些基本概念。
<span id="more"></span></p>
<h2 id="基本概念">基本概念</h2>
<p>IP组播是指在IP网络中将数据包以<strong>尽力传送（best-effort）</strong>的形式发送到网络中的某个确定节点子集，这个子集称为一个<strong>组播组</strong>。</p>
<p>组播传输时，源主机<strong>只发送一份数据，这份数据的目的地址为组播组地址</strong>。</p>
<p>组播组中的所有成员都可接收到同样的数据拷贝（通过路由器进行复制分发），并且只有组播组内的主机（成员，目标主机）可以接收该数据。</p>
<p><img
src="https://wulc.me/imgs/image_1b4ks6rmq1d9nkgmuqf1b46bfem.png" /></p>
<p>从上图可知，由于<strong>每个分支只发送一份报文，所以网络规模（如用户数量）的增大不会额外增加网络的负担</strong>。</p>
<p>故组播的优势为 1）降低了骨干上的网络流量
2）降低了应用服务器的负担</p>
<p>但是组播也存在着以下缺点： 1）传送不可靠！（尽力投递/best effort）
2）组播报文的复制开销使得路由器的资源消耗增加！
3）可控可管性差，用户管理困难，存在安全问题（用户可随意加入某个组，无须密码）
## 组播地址 组播组用D类IP地址标识，以 1110 开头。组播范围为
<code>224.0.0.0</code>~<code>239.255.255.255</code>。</p>
<p>各个地址范围段及其含义如下</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>地址范围</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>224.0.0.0</code>～<code>224.0.0.255</code></td>
<td>预留的组播地址（永久组地址），地址224.0.0.0保留不做分配，其它地址供路由协议使用</td>
</tr>
<tr class="even">
<td><code>224.0.1.0</code>～<code>224.0.1.255</code></td>
<td>公用组播地址，可以用于Internet</td>
</tr>
<tr class="odd">
<td><code>224.0.2.0</code>～<code>238.255.255.255</code></td>
<td>用户可用的组播地址（临时组地址），全网范围内有效</td>
</tr>
<tr class="even">
<td><code>239.0.0.0</code>～<code>239.255.255.255</code></td>
<td>本地管理组播地址，也称私人组播地址空间，仅在特定的本地范围内有效</td>
</tr>
</tbody>
</table>
<p>几个常用的组播地址及其含义如下所示</p>
<table>
<thead>
<tr class="header">
<th>地址</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>224.0.0.1</code></td>
<td>子网上所有主机(包括路由器)</td>
</tr>
<tr class="even">
<td><code>224.0.0.2</code></td>
<td>子网上所有路由器</td>
</tr>
<tr class="odd">
<td><code>224.0.0.5</code></td>
<td>所有ospf路由器</td>
</tr>
<tr class="even">
<td><code>224.2.0.0</code>-<code>224.2.255.255</code></td>
<td>多媒体会议呼叫</td>
</tr>
</tbody>
</table>
<p>除了IP地址，组播中的mac地址也有特殊的规定，一个组播mac地址通过映射对应一个组播ip地址，其映射规则为：<strong>将IP组播地址的低23位代替以太网地址<code>01.00.5e.00.00.00</code>(16进制)中的低23位。</strong>，也就是说组播的mac地址一定会以<code>01:00:5e</code>开头。</p>
<p>这种映射方式可能会带来不同的组播IP地址映射成相同的 mac
地址，给定一个组播IP地址，还有几个组播IP地址映射成的mac地址与其相同？
除去低位相同的23位以及高位的<code>1110</code>,还剩下5位，因此还有
2^5-1=31
个地址会与给定的组播IP地址映射成相同的mac地址，也就是说有32:1的组播IP地址的mac地址重叠。</p>
<h2 id="组播转发树">组播转发树</h2>
<p>组播转发树指的是数据从源主机到接受者的传输路径。组播转发树主要有两类：<strong>有源树(SPT)和共享树(RPT)</strong>。</p>
<p><strong>有源树</strong>
有源树中源主机构成了源树的根，数据传输的路径构成了有源树的分支，有源树又称为生成树或最短路径树(沿着最短路径传输)。下图中箭头便是有源树</p>
<p><img
src="https://wulc.me/imgs/image_1b4l9cstt170fr7aef81dgk2nk9.png" /></p>
<p><strong>共享树</strong>
共享树是各个组播组共享的传输路径，如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4l9gr82c2c1ofi15di10oj1bapm.png" /></p>
<p>有源树和共享树均是无回路的树，且均在分支处复制数据包，但是有源树能够提供一个最优的路径，而共享树路径可能不是最优的，相应的代价是有源树会占用较多的内存。</p>
<h2 id="组播路由">组播路由</h2>
<p>组播路由和单播路由是相反的，单播路由关心数据报文要到哪里去，组播路由关心数据报文从哪里来。</p>
<p>组播路由使用 “反向路径转发”机制(<strong>RPF</strong>, Reverse Path
Forwarding)，它是IP组播转发过程的基础，几乎所有的IP组播路由协议都<strong>利用RPF作为决定是否转发或丢弃</strong>从某个接口上接收到的组播信息包。</p>
<p>RPF的具体机制是路由器收到组播数据报文后，只有<strong>确认这个数据报文是从自己到源的出接口（单播）上到来的，才进行转发，否则丢弃报文</strong>。实际上就是在路由器中查询到组播报文源地址的路由，假如该路由的出口就是组播报文的入口，RPF检查成功，转发数据包，否则丢弃数据包。</p>
<p>如下为RPF的具体例子 RPF检查失败 <img
src="https://wulc.me/imgs/image_1b4la1ddp1mlbbkjsais3q1jso13.png" />
RPF检查成功 <img
src="https://wulc.me/imgs/image_1b4la277n1gjg191vi7u1vijl1b1g.png" /></p>
<p><strong>TTL阈值</strong>
IP组播包被路由器转发的时候，IP头中的TTL值要减1；路由器在传输的时候可以在每个接口设置一个TTL阈值，只有数据包的TTL值大于或等于接口的TTL阈值时，路由器才能在出接口转发该数据包。这个机制的目的是为了限制组播的范围。如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4lf3ujgdsv1mhp1c1o12k7183s1t.png" /></p>
<h2 id="组播协议">组播协议</h2>
<p>组播协议分为主机与路由器之间的组成员关系协议和路由器与路由器之间的组播路由协议。</p>
<h3 id="组成员管理协议主机-路由器">组成员管理协议（主机-路由器）</h3>
<p>IGMP（internet group management protocol）是IP
协议簇中负责IP组播组成员管理的协议，用来在
<strong>IP主机和与其直接相邻的组播路由器</strong>之间建立、维护组播组成员关系，所有参与组播的主机必须支持IGMP协议。</p>
<p>注意，IGMP <strong>不包括</strong>
组播路由器之间的组成员关系信息的传播与维护，这部分工作由各组播路由协议完成。</p>
<p>IGMP作为TCP/IP第三层的协议，被封装在IP数据包中进行传输。其报文格式如下所示
<img
src="https://wulc.me/imgs/image_1b4lgopfv7ke1uiec2po8ra772a.png" /></p>
<p>IGMP协议有三个版本，各个版本的功能和区别如下：</p>
<ul>
<li><strong>IGMP
v1</strong>：提供成员关系查询/成员关系报告两个基本功能。</li>
<li><strong>IGMP
v2</strong>：增加了查询器选择/特定组查询/<strong>离开组消息</strong>及最大响应时间字段等扩展功能。</li>
<li><strong>IGMP
v3</strong>：增加了对特定(源,组)的加入离开的支持，以提供对组播应用更好的支持</li>
</ul>
<h4 id="igmp-v1"><strong>IGMP v1</strong></h4>
<p>IGMP v1的报文格式如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4lh0vrvint1gta1qgqbre1ddb2n.png" /></p>
<p>上面的报文中，类型字段有两种取值： 1：成员关系查询(路由器发出)
2：成员关系报告(主机发出)</p>
<p>组地址只有在成员关系报告时才填入，注意这个地址不是发送IGMP数据包时用于寻址的地址，用于寻址的地址在IP报头中。</p>
<p>查询报文是周期性发送的，默认为60s一次，过程如下所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4lhdn731mkl1eq3iqqc1hbu834.png" /></p>
<p>上图出现了报告抑制的情况，这个机制主要是为了<strong>使得当前子网中对于每个组只需有一个成员响应成员关系查询</strong>，在上图中H1和H2属于同一组的，因此只需要一个成员响应成员报告。</p>
<p>报告抑制的步骤如下 1)主机收到 IGMP
成员关系查询后，主机对已经加入的每个组播组启动一个<strong>倒数计时器</strong>，计时器初始化为一个给定时间（在IGMPv1中为固定值10S）范围内的随机值。
2)当<strong>计时器计时值为0时，主机发送成员关系报告</strong>至与该计时器相关的组播组，以通知路由器本地网中有处于活动状态组播组接收者
3)主机在它的倒数<strong>计时器达到0之前收到其他主机发送的某一成员关系报告，那么它就停止与这个组播组相关的倒数计时器的计时</strong>，这样就抑制了主机到这一组播组的成员关系报告</p>
<p><strong>加入组播组</strong>：主机并<strong>不等待</strong>来自路由器的下一次成员关系查询，可<strong>主动</strong>向要加入的组播组发送成员关系报告表示加入
<strong>离开组播组</strong>：IGMPv1中没有定义离开机制，主机在任何时候可以默默地离开</p>
<p>为了避免这种默默离开的机制导致路由器给一个空的组播组发送数据包，路由器设置<strong>组播组关联定时器</strong>（一般为3倍查询周期，3min），超时无组成员报告，则停止转发。</p>
<h4 id="igmp-v2"><strong>IGMP v2</strong></h4>
<p>IGMP v2与IGMP v1的最大区别为： 1）支持特定组查询
2）通过离开消息允许主机主动汇报他们的离开</p>
<p>IGMP v2的报文如下所示：</p>
<p><img
src="https://wulc.me/imgs/image_1b4li84ga19gm11411acd1389117h3h.png" /></p>
<p>上面的报文类型有以下四种：</p>
<ul>
<li>0x11：成员关系查询（与IGMP v1兼容）</li>
<li>0x12：IGMPv1成员关系报告</li>
<li>0x16：IGMPv2成员关系报告</li>
<li>0x17：离开组（组播地址段为目标组播组地址）</li>
</ul>
<p>而成员关系查询消息又分为<strong>两类</strong>
1）普通查询（组播地址段为零）
2）特定组查询：直接对单个组查询（组播地址段为正在查询的组播组地址）</p>
<p>在IGMP
v2中组成员的离开并不是默默离开了，而是会主动发送离开的消息，然后路由器会进行特定组的查询已确认这个离开的主机是不是这个组播组最后的一个成员，有响应报文说明还有其他成员，否则这个成员就是最后的成员。</p>
<p>上面的成员查询报文由<strong>查询路由器</strong>发出。在 IGMP v1
中没有正式的选举规定，它依赖于路由协议，IGMP v2
协议声明了正式的查询路由器选举过程：
1）多访问网络上的每个路由器假设自己为查询器并发出查询
2）IP地址低（接口）的路由器被选为查询器
3）非查询路由器设置定时器，当超时没有收到查询器的周期查询，认为查询器出事了，重新选举</p>
<p>当 IGMP v1 和 IGMP v2
混杂在一个子网的时候，两种协议的交互需要遵循某种规则，这些规则都是因为
<strong>IGMP v1 并不能识别IGMP v2 的报文</strong>。如</p>
<p>IGMPv2 主机与IGMPv1路由器交互时，有以下规则：
1）IGMPv1路由器把v2报告看作无效的信息并且忽略它
2）当V1路由器作为查询路由器时，V2的主机必须发送V1成员报告。</p>
<p>IGMPv2路由器与IGMPv1主机交互时，有以下规则：
1)V2路由器的查询可被V1的主机所处理，只是忽略第二个八位组的信息，就是忽略特定组的查询，全认为是普通查询。
2）v2路由器必须<strong>忽略离开报告</strong>，否则后果很严重！因为v2路由器收到离开报文后会发出的特定查询，而特定组查询并不被v1主机理会，此时假如剩下的全是IGMP
v1的主机，IGMP
v2的路由器收不到响应报文，会认为组播组没有成员从而不再发送数据到这个组播组。</p>
<p>基于上面的原因，同一网段上的所有路由器必须运行同一版本的IGMP协议。缺省为V2。但是<strong>假如网段上存在其它IGMP
v1路由器，所有的路由器必须手工配置为运行IGMP v1</strong>。</p>
<h4 id="igmp-v3"><strong>IGMP v3</strong></h4>
<p>IGMP v3 与 IGMP
v2的最大区别是<strong>允许主机只收到组播组内某个特定信源的传输</strong>，如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4ljrgrkum3pp514db1f271fo23u.png" /></p>
<p>三个版本的 IGMP 协议比较如下</p>
<table>
<thead>
<tr class="header">
<th>协议版本</th>
<th>IGMP v1</th>
<th>IGMP v2</th>
<th>IGMPv3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>查询器选举</td>
<td>依靠上层路由协议</td>
<td>自己选举</td>
<td>自己选举</td>
</tr>
<tr class="even">
<td>离开方式</td>
<td>默默离开</td>
<td>主动发出离开报文</td>
<td>主动发出离开报文</td>
</tr>
<tr class="odd">
<td>指定组查询</td>
<td>无</td>
<td>有</td>
<td>有</td>
</tr>
<tr class="even">
<td>接收组内指定源</td>
<td>无</td>
<td>无</td>
<td>有</td>
</tr>
</tbody>
</table>
<h3 id="路由协议路由器-路由器">路由协议（路由器-路由器）</h3>
<p>组播路由协议的类型主要有两种：密集模式（Dense-mode）和稀疏模式（Sparse-mode）</p>
<ul>
<li><p><strong>密集模式（Dense-mode）</strong> 1）使用“推”（Push）模型
2）组播数据在整个网络的泛滥（Flood） 3）下游不想接收的话则剪枝（Prune）
4）泛滥、剪枝、泛滥、剪枝…周而复始 (通常3分钟折腾一次)</p></li>
<li><p><strong>稀疏模式（Sparse-mode）</strong> 1）使用 “拉”（Pull）模型
2）组播数据只发送到有需要的地方 3）有显式的加入（Join）过程</p></li>
</ul>
<p>目前主要有4种具体的组播路由协议DVMRP，MOSPF，PIM-DM，PIM-SM。</p>
<p>DVMRP是第一个组播路由协议，一个较为古老，具有实验性质的协议，现已经不常使用。属于<strong>密集模式</strong>协议。</p>
<p>DVMRP
基于基于距离矢量，类似于RIP，最大不能超过32跳，不支持共享树，不适合于大规模的网络。</p>
<p>MOSPF是对OSPF单播路由协议的扩展，在OSPF链路状态通告中包含组播信息，以此构建组播分发树。MOSOF与单播路由协议相关，仅在OSPF网络内运行，适合在单路由域中使用。不支持共享树，且支持的厂家较少，市场鲜有使用。</p>
<p>目前最常用的组播协议是 <strong>PIM</strong>（Protocol Independent
Multicast，协议无关组播）。PIM有以下特点：
1）独立于单播协议，也就是支持所有的单播协议 2）扩散和剪枝机制
3）无类</p>
<p>PIM 又分为 PIM-DIM 和PIM-SM 两种模式，对应于密集型和稀疏型的PIM。</p>
<h4 id="pim-dm"><strong>PIM-DM</strong></h4>
<p>该协议用PUSH方式，将组播流量周期性扩散到网络中所有设备，建立和维护SPT(short
path tree) （假设所有主机都需要接收组播数据）。</p>
<p>主要步骤为以下三个： 1）周期性扩散(泛洪,Flood)：为每个路由器创建(S,G)
2）剪枝(Prune)：除去不需要组播数据的路径
3）嫁接(Graft)：迅速得到数据，而不用到下一周期</p>
<p>泛洪和剪枝的过程如下所示 <img src="https://wulc.me/imgs/1.png" />
<img src="https://wulc.me/imgs/2.png" /> <img
src="https://wulc.me/imgs/3.png" /></p>
<p>满足以下任一条件即可发送剪枝消息 1）信息到达PIM-DM
路由器的<strong>非RPF点对点接口</strong>；
2）PIM-DM路由器没有下游邻居，且所有叶网络上没有组成员；
3）PIM-DM路由器接口上<strong>所有的下游邻居</strong>已经通过了剪枝表决</p>
<p>嫁接的目的是为了能够迅速得到数据，从而不用等到下一次的泛洪。过程如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4lt29fp9mtk87m5dq21kmi1d.png" /> <img
src="https://wulc.me/imgs/image_1b4lt2vubb1kjp01iv8qf210pl1q.png" />
<img
src="https://wulc.me/imgs/image_1b4lt3hrr1efk3ld1jru1pkq1cde27.png" /></p>
<p>PIM-DM中还有一种<strong>断言（Assert）机制</strong>。目的是为了避免出现组播流量重复和多份，如下图所示，BCD都会收到重复的数据</p>
<p><img
src="https://wulc.me/imgs/image_1b4ltcboa13da1ei01bjog9rmap2k.png" /></p>
<p>为了避免这种情况，断言机制过程如下
1）当路由器从其组播“出接口列表”(oiflist)中的某个接口收到与其发送的组播数据相同的数据
2）路由器发送 “PIM Assert”消息 3）计算distance和
metric值，谁到源的路由最优谁获胜；如果distance和
metric相等，IP地址大的获胜，输的就停止转发 (剪枝接口)</p>
<p>对于上图运行断言机制后，假如C获胜，那么情况如下 <img
src="https://wulc.me/imgs/image_1b4ltr5cvljd1vn08jj1ivmdss31.png" /></p>
<p>原因是B经Assert断言成了loser之后，将自己的loser接口设为剪枝状态，并向winner
C发送剪枝消息，D的RPF接口也会收到该剪枝消息，发出join消息，否决。</p>
<p>PIM-DM的优点为 1）易于配置 2）实现机制简单（泛滥剪枝）</p>
<p>缺点为 1）泛滥剪枝过程不够高效 2）复杂的Assert机制
3）控制和数据平面混合：导致网络内部的所有路由器上都有(S,
G)，可能会导致非确定性的拓扑行为 4）不支持共享树</p>
<p>PIM-DM适用于 1）小规模的网络 2）组播源和接收者比较靠近
3）源少，接收者多 4）数据流大且稳定</p>
<h4 id="pim-sm"><strong>PIM-SM</strong></h4>
<p>PIM-SM协议假设<strong>没有主机需要接收组播数据，除非它们明确地发出了请求</strong>。</p>
<p>稀疏组播的特点为 1）组成员所在的网络数相对少 2）组成员跨越的区域太大
3）带宽资源还没有富裕到可以忽略DM模式带来的消耗</p>
<p>在PIM-SM中有个重要的概念：<strong>汇聚点，RP(Rendezvous
Point)</strong>，发送者和接收者在RP处进行汇聚，表现为
1）发送者的第一跳路由器把发送者注册到RP上（报个到，挂个号）
2）接收者的DR（直连网络上的负责人）为接收者加入到共享树 (树根在RP)</p>
<p>接收者加入或离开组播组的行为表现为
1)<strong>加入</strong>:接收者发送加入消息，逐跳上行到RP，沿途路由器记录组播转发状态；
2)<strong>离开</strong>:接收者不想要组播数据时，发送剪枝消息，逐跳上行到RP，沿途路由器更新它的转发状态</p>
<p>从上面接收者离开或加入的行为可以看出SM跟DM本质的差别：<strong>路由器转发状态通过组播消息的抵达而建立或更新</strong>。</p>
<p>上面的过程中有几个关键问题， （1）如何知道RP(RP发现)？
（2）如何让源组播数据到达RP？
（3）能否在接收者和源之间建立一个转发树，分担RP的负担？</p>
<p>针对问题（1），采用<strong>自举路由器机制(BSR)</strong>来选出RP，通常通过人工配置，将一组路由器配置为候选自举路由器(C-BSR)，另一组路由器配置为候选汇集点（C-RP），通常建议这两组路由器是同样的路由器。C-RP
会定期把候选汇集点通告消息（C-RP-Advs）以单址的形式发送到C-BSR；汇集点通告消息是一种PIM消息，它包括通告
C-RP 的地址、可选的组播组地址和一个掩码长度域（说明组的前缀）；C-BSR
收集这些通告消息并产生相应的自举报文，自举报文也是一种PIM消息，它包括C-RP和相应的组前缀并由自举路由器以一跳一跳的形式发送到<strong>所有普通路由器</strong>。普通路由器通过接收自举报文便可知道C-RP的地址。</p>
<p>针对问题（2），采用了<strong>源注册</strong>的机制，过程如下;</p>
<p>1）源的DR(执行注册的源第一跳路由器)将组播数据封装进一个注册消息，单播到RP；
2）RP打开注册消息,将组播数据在RPT上转发,发送(S,G)加入消息，沿途建立(S,G)状态
3）当RP察觉到从源到RP的SPT树已经建立，RP发送“注册停止”消息给源</p>
<p>上面的过程图示如下所示; <img
src="https://wulc.me/imgs/image_1b4m0fa731g541t4q1ccoq881i5p3r.png" />
<img
src="https://wulc.me/imgs/image_1b4m0fui01ggdpfp7301ktrqkm48.png" />
<img
src="https://wulc.me/imgs/image_1b4m0gg4v1p9b1etgiop156f17sr4l.png" />
<img
src="https://wulc.me/imgs/image_1b4m0hvccirf1l8016lve8o12ah52.png" />
<img
src="https://wulc.me/imgs/image_1b4m0lfpn1npf2eo121m152m1b6q5f.png" /></p>
<p>需要注意的是当源的SPT建立起来后，源的DR不会马上停止注册，而是等待收到RP的注册停止消息后才会停止，这时候空注册消息和沿着SPT的组播数据流并存。</p>
<p>在通过组播传输数据的时候，数据的传输方向为
<code>源→SPT→RP→RPT</code>，如下图所示</p>
<p><img
src="https://wulc.me/imgs/image_1b4m0r5vui3neb1juo1foakf85s.png" /></p>
<p>从上面的传播路径可知，RP可能会成为瓶颈，针对这个问题，也就是问题（3），提出了<strong>SPT切换</strong>的方法,其过程如下
<img
src="https://wulc.me/imgs/image_1b4m1ullq1vk01oiqqotu9a1ac37t.png" />
<img
src="https://wulc.me/imgs/image_1b4m1v6usqin1i91hl06jq1sog8a.png" />
<img
src="https://wulc.me/imgs/image_1b4m1l71s1efk1f6s10df3cl1dtj69.png" />
<img src="https://wulc.me/imgs/image_1b4m1llim1qpk182folf91io76m.png" />
<img
src="https://wulc.me/imgs/image_1b4m1m95l1iueqvm1nu5q661b8i73.png" />
<img
src="https://wulc.me/imgs/image_1b4m1moiv19a28d7j9o1jdv1vdt7g.png" /></p>
<p>上面中
<strong>SPT切换的条件</strong>为：最后一跳路由器（和接收者直连的路由器）一旦发现某个特定的组播源的数据量超出了某个界限(阈值)，马上向<strong>组播源</strong>发送<code>（S，G）Join</code>消息。</p>
<p><strong>共享树剪枝的条件</strong>为：最后一跳路由器根据自己的状态表中的（*，G）和（S，G）的入接口情况来判断是否发送剪枝消息（剪共享树），触发条件是：在（S，G）的入接口上收到了相符合的组播数据
（源树已经建立）</p>
<p>PIM-SM对于稀疏和密集应用都很高效，其优势为</p>
<ul>
<li>数据流仅沿“加入”的分支向下发送</li>
<li>可以根据流量等条件动态地切换到源树</li>
<li>与具体的单播路由协议无关</li>
<li>域间组播路由的基础(和MBGP、MSDP共同结合使用可以完成跨域的组播 )</li>
</ul>
<p>PIM-SM适用于 1）大规模的企业网络 2）接收者稀少
3）几乎是任何网络的优选方案（目前PIM-SM占主流）</p>
<h2 id="源特定组播ssm">源特定组播(SSM)</h2>
<p>源特定组播（SSM：Source Specific
Multicast）是一种区别于传统组播的新的业务模型，它使用<strong>组播组地址和组播源地址</strong>同时来标识一个组播会话，而不是像传统的组播服务那样只使用组播组地址来标识一个组播会话，由于源地址的加入，组地址在不同源地址之间可以重用。</p>
<p>SSM保留了传统PIM-SM模式中的主机显示加入组播组的高效性，但是<strong>没有
PIM-SM 模式中的共享树和
RP</strong>的概念，SSM直接建立由(S,G)标识的一个有源树，</p>
<p>在 SSM
中，主机<strong>主动发起</strong>对指定(S,G)的加入，由最后一跳路由器直接向源发送（S,G）加入消息。</p>
<h2 id="ipv6组播">ipv6组播</h2>
<p>ipv6 的组播与ipv4的组播非常类似，这里做简单介绍。</p>
<p>ipv6的组播地址规定前8位均为1,也就是以ff开头，其他部分含义如下所示：</p>
<p><img
src="https://wulc.me/imgs/image_1b4pokpvl9c38eo1991ifbcj89.png" /></p>
<ul>
<li>Flags:用来表示permanent或transient组播组</li>
<li>Scope:表示组播组的范围 &gt;0：预留 1：节点本地范围 2：链路本地范围
5：站点本地范围</li>
<li>Group ID:组播组ID</li>
</ul>
<p>ipv6中一些众所周知的组播地址以及与ipv4的对应关系如下：</p>
<p><img
src="https://wulc.me/imgs/image_1b4popspc1ofl119lfqu4oa1utqm.png" /></p>
<p>ipv6组播中的mac地址也是通过映射来的，映射规则为<code>33:33:+IPv6组播地址的后32位</code>。同样也存在mac重复问题。</p>
<p>ipv6的组播协议也分为组管理协议和路由协议。组成员管理协议为MLD（Multicast
listener
Discovery，侦听发现协议）,MLD几乎全盘继承了IGMPv2和IGMPv3，更名为MLDv1和MLDv2，用在路由器和ip主机之间。而路由协议依然是PIM。</p>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>详解Python程序与服务器连接的WSGI接口</title>
    <url>/2015/11/20/%E8%AF%A6%E8%A7%A3Python%E7%A8%8B%E5%BA%8F%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9E%E6%8E%A5%E7%9A%84WSGI%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[<p>文章为转载，原文见<a
href="http://www.jb51.net/article/65195.htm">这里</a>，侵删</p>
<p>这篇文章主要介绍了Python程序与服务器连接的WSGI接口,是Python网络编程学习当中的重要内容,需要的朋友可以参考下</p>
<p>了解了HTTP协议和HTML文档，我们其实就明白了一个Web应用的本质就是：
　　 1.浏览器发送一个HTTP请求; 2.服务器收到请求，生成一个HTML文档;
3.服务器把HTML文档作为HTTP响应的Body发送给浏览器;
4.浏览器收到HTTP响应，从HTTP Body取出HTML文档并显示。</p>
<span id="more"></span>
<p>　 　
所以，最简单的Web应用就是先把HTML用文件保存好，用一个现成的HTTP服务器软件，接收用户请求，从文件中读取HTML，返回。Apache、Nginx、Lighttpd等这些常见的静态服务器就是干这件事情的。</p>
<p>如果要动态生成HTML，就需要把上述步骤自己来实现。不过，接受HTTP请求、解析HTTP请求、发送HTTP响应都是苦力活，如果我们自己来写这些底层代码，还没开始写动态HTML呢，就得花个把月去读HTTP规范。<strong>正确的做法是底层代码由专门的服务器软件实现，我们用Python专注于生成HTML文档。</strong>因为我们不希望接触到TCP连接、HTTP原始请求和响应格式，所以，<strong>需要一个统一的接口，让我们专心用Python编写Web业务</strong>。</p>
<p>这个接口就是WSGI：Web Server Gateway
Interface。<strong>WSGI接口定义非常简单，它只要求Web开发者实现一个函数，就可以响应HTTP请求。</strong>我们来看一个最简单的Web版本的“Hello,
web!”：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">application</span>(<span class="params">environ, start_response</span>):</span><br><span class="line">    start_response(<span class="string">&#x27;200 OK&#x27;</span>, [(<span class="string">&#x27;Content-Type&#x27;</span>, <span class="string">&#x27;text/html&#x27;</span>)])</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;Hello, web!&lt;/h1&gt;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>上面的application()函数就是符合WSGI标准的一个HTTP处理函数，它接收两个参数：</p>
<ul>
<li><code>environ</code>：一个包含所有<strong>HTTP请求信息</strong>的dict对象;</li>
<li><code>start_response</code>：一个发送<strong>HTTP响应</strong>的函数。</li>
</ul>
<p>在application()函数中，调用<code>start_response('200 OK', [('Content-Type', 'text/html')])</code>就<strong>发送了HTTP响应的Header</strong>，注意<strong>Header只能发送一次</strong>，也就是只能调用一次start_response()函数。start_response()函数接收两个参数，一个是HTTP响应码，一个是一组list表示的HTTP
Header，每个Header用一个包含两个str的tuple表示。</p>
<p>通常情况下，都应该把Content-Type头发送给浏览器。其他很多常用的HTTP
Header也应该发送。然后，函数的返回值Hello,
web!将作为<strong>HTTP响应的Body</strong>发送给浏览器。</p>
<p><strong>有了WSGI，我们关心的就是如何从environ这个dict对象拿到HTTP请求信息，然后构造HTML，通过start_response()发送Header，最后返回Body。</strong>整个application()函数本身没有涉及到任何解析HTTP的部分，也就是说，底层代码不需要我们自己编写，我们只负责在更高层次上考虑如何响应请求就可以了。</p>
<p>不过，等等，这个application()函数怎么调用?如果我们自己调用，两个参数environ和start_response我们没法提供，返回的str也没法发给浏览器。
所以<strong>application()函数必须由WSGI服务器来调用</strong>。有很多符合WSGI规范的服务器，我们可以挑选一个来用。但是现在，我们只想尽快测试一下我们编写的application()函数真的可以把HTML输出到浏览器，所以，要赶紧找一个最简单的WSGI服务器，把我们的Web应用程序跑起来。</p>
<p>好消息是Python内置了一个WSGI服务器，这个模块叫wsgiref，它是用纯Python编写的WSGI服务器的参考实现。所谓“参考实现”是指该实现完全符合WSGI标准，但是不考虑任何运行效率，仅供开发和测试使用。</p>
<p>我们先编写hello.py，实现Web应用程序的WSGI处理函数：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#hello.py</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">application</span>(<span class="params">environ, start_response</span>):</span><br><span class="line">    start_response(<span class="string">&#x27;200 OK&#x27;</span>, [(<span class="string">&#x27;Content-Type&#x27;</span>, <span class="string">&#x27;text/html&#x27;</span>)])</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&lt;h1&gt;Hello, web!&lt;/h1&gt;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>然后，再编写一个server.py，负责启动WSGI服务器，加载application()函数：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server.py</span></span><br><span class="line"><span class="comment"># 从wsgiref模块导入:</span></span><br><span class="line"><span class="keyword">from</span> wsgiref.simple_server <span class="keyword">import</span> make_server</span><br><span class="line"><span class="comment"># 导入我们自己编写的application函数:</span></span><br><span class="line"><span class="keyword">from</span> hello <span class="keyword">import</span> application</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 创建一个服务器，IP地址为空，端口是8000，处理函数是application:</span></span><br><span class="line">httpd = make_server(<span class="string">&#x27;&#x27;</span>, <span class="number">8000</span>, application)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;Serving HTTP on port 8000...&quot;</span></span><br><span class="line"> <span class="comment"># 开始监听HTTP请求:</span></span><br><span class="line">httpd.serve_forever()</span><br></pre></td></tr></table></figure>
<p>确保以上两个文件在同一个目录下，然后在命令行输入<code>python server.py</code>来启动WSGI服务</p>
<figure>
<img src="https://wulc.me/imgs/2016-01-09_102745.png"
alt="启动server" />
<figcaption aria-hidden="true">启动server</figcaption>
</figure>
<p>启动成功后，打开浏览器，输入
<code>http://localhost:8000/</code>，就可以看到结果了</p>
<figure>
<img src="https://wulc.me/imgs/2016-01-09_103107.png"
alt="浏览器观察" />
<figcaption aria-hidden="true">浏览器观察</figcaption>
</figure>
<p>再看看刚刚打开的cmd窗口，会输出请求的如下所示</p>
<figure>
<img src="https://wulc.me/imgs/2016-01-09_103748.png" alt="请求情况" />
<figcaption aria-hidden="true">请求情况</figcaption>
</figure>
<p>可以看到总共有两个请求源，其中<code>LC-PC</code>是通过电脑浏览器输入<code>localhost</code>访问,而<code>192.168.1.109</code>是通过手机浏览器访问的（电脑和手机在同一局域网下）；输出的内容包括请求的ip，时间和http请求头。</p>
<p>无论多么复杂的Web应用程序，入口都是一个WSGI处理函数。HTTP请求的所有输入信息都可以通过environ获得，HTTP响应的输出都可以通过start_response()加上函数返回值作为Body。
复杂的Web应用程序，光靠一个WSGI函数来处理还是太底层了，我们需要在WSGI之上再抽象出Web框架，进一步简化Web开发。</p>
<hr />
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>详解Java的TCP网络编程</title>
    <url>/2016/02/08/%E8%AF%A6%E8%A7%A3Java%E7%9A%84TCP%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="网络编程简介">网络编程简介</h2>
<p>网络通讯的方式有TCP和UDP两种，其中TCP方式的网络通讯是指在通讯的过程中保持连接，有点类似于打电话，只需要拨打一次号码(建立一次网络连接)，就可以多次通话(多次传输数据)。这样方式在实际的网络编程中，由于传输可靠，类似于打电话，如果甲给乙打电话，乙说没有听清楚让甲重复一遍，直到乙听清楚为止，实际的网络传输也是这样，如果发送的一方发送的数据接收方觉得有问题，则网络底层会自动要求发送方重发，直到接收方收到为止。</p>
<span id="more"></span>
<p>在Java语言中，对于TCP方式的网络编程提供了良好的支持，在实际实现时，<strong>以java.net.Socket类代表客户端连接，以java.net.ServerSocket类代表服务器端连接。</strong>在进行网络编程时，底层网络通讯的细节已经实现了比较高的封装，所以在程序员实际编程时，只需要指定IP地址和端口号码就可以建立连接了。正是由于<strong>这种高度的封装，一方面简化了Java语言网络编程的难度，另外也使得使用Java语言进行网络编程时无法深入到网络的底层，</strong>所以使用Java语言进行网络底层系统编程很困难，具体点说，Java语言无法实现底层的网络嗅探以及获得IP包结构等信息。但是由于Java语言的网络编程比较简单，所以还是获得了广泛的使用。</p>
<p>在使用TCP方式进行网络编程时，需要按照前面介绍的网络编程的步骤进行，下面分别介绍一下在Java语言中客户端和服务器端的实现步骤。</p>
<h2 id="客户端">客户端</h2>
<p><strong>在网络编程中客户端需要做的事情包括：建立连接-&gt;发送并接受数据-&gt;关闭连接。</strong></p>
<h3 id="建立连接">建立连接</h3>
<p>在客户端网络编程中，首先需要建立连接，在Java
API中以java.net.Socket类的对象代表网络连接，所以建立客户端网络连接，也就是创建Socket类型的对象，该对象代表网络连接，示例如下：
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Socket</span> <span class="variable">socket1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Socket</span>(“<span class="number">192.168</span><span class="number">.1</span><span class="number">.103</span>”,<span class="number">10000</span>);</span><br><span class="line"><span class="type">Socket</span> <span class="variable">socket2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Socket</span>(“www.sohu.com”,<span class="number">80</span>);</span><br></pre></td></tr></table></figure>
上面的代码中，<strong>socket1实现的是连接到IP地址是192.168.1.103的计算机的10000号端口，而socket2实现的是连接到域名是www.sohu.com的计算机的80号端口，至于底层网络如何实现建立连接，对于程序员来说是完全透明的。</strong>如果建立连接时，本机网络不通，或服务器端程序未开启，则会抛出异常。</p>
<h3 id="传输数据">传输数据</h3>
<p>连接一旦建立，则完成了客户端编程的第一步，紧接着的步骤就是按照“请求-响应”模型进行网络数据交换，在Java语言中，数据传输功能由Java
IO实现，也就是说<strong>需要发送的数据写入连接对象的输出流中，在发送完成以后从输入流中读取数据</strong>即可。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">OutputStream</span> <span class="variable">os</span> <span class="operator">=</span> socket1.getOutputStream();   <span class="comment">//获得输出流</span></span><br><span class="line"><span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> socket1.getInputStream();     <span class="comment">//获得输入流</span></span><br></pre></td></tr></table></figure>
<p>上面的代码中，分别从socket1这个连接对象获得了输出流和输入流对象，在整个网络编程中，后续的数据交换就变成了IO操作，也就是遵循“请求-响应”模型的规定，先向输出流中写入数据，这些数据会被系统发送出去，然后在从输入流中读取服务器端的反馈信息，这样就完成了一次数据交换过程，当然这个数据交换过程可以多次进行。</p>
<p>这里获得的只是最基本的输出流和输入流对象，还可以根据前面学习到的IO知识，使用流的嵌套将这些获得到的基本流对象转换成需要的装饰流对象，从而方便数据的操作。</p>
<h3 id="关闭连接">关闭连接</h3>
<p>最后当数据交换完成以后，关闭网络连接，释放网络连接占用的系统端口和内存等资源，完成网络操作，示例代码如下：
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">socket1.close();</span><br></pre></td></tr></table></figure> ### 客户端简单案例
这就是最基本的网络编程功能介绍。下面是一个简单的网络客户端程序示例，该程序的作用是向服务器端发送一个字符串“Hello”，并将服务器端的反馈显示到控制台，数据交换只进行一次，当数据交换进行完成以后关闭网络连接，程序结束。实现的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 简单的Socket客户端</span></span><br><span class="line"><span class="comment"> * 功能为：发送字符串“Hello”到服务器端，并打印出服务器端的反馈</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleSocketClient</span> &#123;</span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">                   <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">OutputStream</span> <span class="variable">os</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="comment">//服务器端IP地址</span></span><br><span class="line">                   <span class="type">String</span> <span class="variable">serverIP</span> <span class="operator">=</span> <span class="string">&quot;127.0.0.1&quot;</span>;</span><br><span class="line">                   <span class="comment">//服务器端端口号</span></span><br><span class="line">                   <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> <span class="number">10000</span>;</span><br><span class="line">                   <span class="comment">//发送内容</span></span><br><span class="line">                   <span class="type">String</span> <span class="variable">data</span> <span class="operator">=</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="comment">//建立连接</span></span><br><span class="line">                            socket = <span class="keyword">new</span> <span class="title class_">Socket</span>(serverIP,port);</span><br><span class="line">                            <span class="comment">//发送数据</span></span><br><span class="line">                            os = socket.getOutputStream();</span><br><span class="line">                            os.write(data.getBytes());</span><br><span class="line">                            <span class="comment">//接收数据</span></span><br><span class="line">                            is = socket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] b = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">                            <span class="comment">//输出反馈数据</span></span><br><span class="line">                            System.out.println(<span class="string">&quot;服务器反馈：&quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(b,<span class="number">0</span>,n));</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                            e.printStackTrace(); <span class="comment">//打印异常信息</span></span><br><span class="line">                   &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">                            <span class="keyword">try</span> &#123;</span><br><span class="line">                                     <span class="comment">//关闭流和连接</span></span><br><span class="line">                                     is.close();</span><br><span class="line">                                     os.close();</span><br><span class="line">                                     socket.close();</span><br><span class="line">                            &#125; <span class="keyword">catch</span> (Exception e2) &#123;&#125;</span><br><span class="line">                   &#125;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在该示例代码中建立了一个连接到IP地址为127.0.0.1，端口号码为10000的TCP类型的网络连接，然后获得连接的输出流对象，将需要发送的字符串“Hello”转换为byte数组写入到输出流中，由系统自动完成将输出流中的数据发送出去，如果需要强制发送，可以调用输出流对象中的flush方法实现。在数据发送出去以后，从连接对象的输入流中读取服务器端的反馈信息，读取时可以使用IO中的各种读取方法进行读取，这里使用最简单的方法进行读取，从输入流中读取到的内容就是服务器端的反馈，并将读取到的内容在客户端的控制台进行输出，最后依次关闭打开的流对象和网络连接对象。</p>
<p>这是一个简单的功能示例，在该示例中演示了TCP类型的网络客户端基本方法的使用，该代码只起演示目的，还无法达到实用的级别。</p>
<h2 id="服务器端">服务器端</h2>
<p>介绍完一个简单的客户端编程的示例，下面接着介绍一下TCP类型的服务器端的编写。</p>
<p><strong>服务器端需要完成的事情包括：监听端口 -&gt; 获得客户端的连接
-&gt; 连接后传送数据 -&gt; 关闭连接。</strong></p>
<h3 id="监听端口">监听端口</h3>
<p>在服务器端程序编程中，由于服务器端实现的是被动等待连接，所以服务器端编程的第一个步骤是监听端口，也就是监听是否有客户端连接到达。实现服务器端监听的代码为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">ServerSocket</span> <span class="variable">ss</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>(<span class="number">10000</span>);</span><br></pre></td></tr></table></figure>
<p>该代码实现的功能是监听当前计算机的10000号端口，如果在执行该代码时，10000号端口已经被别的程序占用，那么将抛出异常。否则将实现监听。</p>
<h3 id="获得客户端的连接">获得客户端的连接</h3>
<p>服务器端编程的第二个步骤是获得连接。该步骤的作用是<strong>当有客户端连接到达时，建立一个和客户端连接对应的Socket连接对象，从而释放客户端连接对于服务器端端口的占用。</strong>实现功能就像公司的前台一样，当一个客户到达公司时，会告诉前台我找某某某，然后前台就通知某某某，
然后就可以继续接待其它客户了。通过获得连接，使得客户端的连接在服务器端获得了保持，另外使得服务器端的端口释放出来，可以继续等待其它的客户端连接。
实现获得连接的代码是：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> ss.accept();</span><br></pre></td></tr></table></figure>
<p>该代码实现的功能是<strong>获得当前连接到服务器端的客户端连接</strong>。需要说明的是accept和前面IO部分介绍的read方法一样，都是一个阻塞方法，也就是当无连接时，该方法将阻塞程序的执行，直到连接到达时才执行该行代码。另外获得的连接会在服务器端的该端口注册，这样以后就可以通过在服务器端的注册信息直接通信，而注册以后服务器端的端口就被释放出来，又可以继续接受其它的连接了。</p>
<p>连接获得以后，后续的编程就和客户端的网络编程类似了，<strong>这里获得的Socket类型的连接就和客户端的网络连接一样了</strong>，只是服务器端需要首先读取发送过来的数据，然后进行逻辑处理以后再发送给客户端，也就是交换数据的顺序和客户端交换数据的步骤刚好相反。这部分的内容和客户端很类似，所以就不重复了，如果还不熟悉，可以参看下面的示例代码。</p>
<h3 id="关闭连接-1">关闭连接</h3>
<p>最后，在服务器端通信完成以后，关闭服务器端连接。实现的代码为：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ss.close();</span><br></pre></td></tr></table></figure></p>
<h3 id="简单例子">简单例子</h3>
<p>这就是基本的TCP类型的服务器端编程步骤。下面以一个简单的echo服务实现为例子，介绍综合使用示例。echo的意思就是“回声”，echo服务器端实现的功能就是将客户端发送的内容再原封不动的反馈给客户端。实现的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * echo服务器</span></span><br><span class="line"><span class="comment"> * 功能：将客户端发送的内容反馈给客户端</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleSocketServer</span> &#123;</span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">                   <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">OutputStream</span> <span class="variable">os</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="comment">//监听端口号</span></span><br><span class="line">                   <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> <span class="number">10000</span>;</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="comment">//建立连接</span></span><br><span class="line">                            serverSocket = <span class="keyword">new</span> <span class="title class_">ServerSocket</span>(port);</span><br><span class="line">                            <span class="comment">//获得连接</span></span><br><span class="line">                            socket = serverSocket.accept();</span><br><span class="line">                            <span class="comment">//接收客户端发送内容</span></span><br><span class="line">                            is = socket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] b = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">                            <span class="comment">//输出</span></span><br><span class="line">                            System.out.println(<span class="string">&quot;客户端发送内容为：&quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(b,<span class="number">0</span>,n));</span><br><span class="line">                            <span class="comment">//向客户端发送反馈内容</span></span><br><span class="line">                            os = socket.getOutputStream();</span><br><span class="line">                            os.write(b, <span class="number">0</span>, n);</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                   &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">                            <span class="keyword">try</span>&#123;</span><br><span class="line">                                     <span class="comment">//关闭流和连接</span></span><br><span class="line">                                     os.close();</span><br><span class="line">                                     is.close();</span><br><span class="line">                                     socket.close();</span><br><span class="line">                                     serverSocket.close();</span><br><span class="line">                            &#125;<span class="keyword">catch</span>(Exception e)&#123;&#125;</span><br><span class="line">                   &#125;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在该示例代码中建立了一个监听当前计算机10000号端口的服务器端Socket连接，然后获得客户端发送过来的连接，如果有连接到达时，读取连接中发送过来的内容，并将发送的内容在控制台进行输出，输出完成以后将客户端发送的内容再反馈给客户端。最后关闭流和连接对象，结束程序。</p>
<p>这样，就以一个很简单的示例演示了TCP类型的网络编程在Java语言中的基本实现，这个示例只是演示了网络编程的基本步骤以及各个功能方法的基本使用，只是为网络编程打下了一个基础，下面将就几个问题来深入介绍网络编程深层次的一些知识。</p>
<h2 id="深入介绍网络编程">深入介绍网络编程</h2>
<p>为了一步一步的掌握网络编程，下面再研究网络编程中的两个基本问题，通过解决这两个问题将对网络编程的认识深入一层。</p>
<h3 id="如何复用socket连接">如何复用Socket连接？</h3>
<p>在前面的示例中，客户端中建立了一次连接，只发送一次数据就关闭了，这就相当于拨打电话时，电话打通了只对话一次就关闭了，其实更加常用的应该是拨通一次电话以后多次对话，这就是复用客户端连接。</p>
<p>那么<strong>如何实现建立一次连接，进行多次数据交换呢</strong>？其实很简单，建立连接以后，将数据交换的逻辑写到一个循环中就可以了。这样只要循环不结束则连接就不会被关闭。按照这种思路，可以改造一下上面的代码，让该程序可以在建立连接一次以后，发送三次数据，当然这里的次数也可以是多次，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 复用连接的Socket客户端</span></span><br><span class="line"><span class="comment"> * 功能为：发送字符串“Hello”到服务器端，并打印出服务器端的反馈</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MulSocketClient</span> &#123;</span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">                   <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">OutputStream</span> <span class="variable">os</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="comment">//服务器端IP地址</span></span><br><span class="line">                   <span class="type">String</span> <span class="variable">serverIP</span> <span class="operator">=</span> <span class="string">&quot;127.0.0.1&quot;</span>;</span><br><span class="line">                   <span class="comment">//服务器端端口号</span></span><br><span class="line">                   <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> <span class="number">10000</span>;</span><br><span class="line">                   <span class="comment">//发送内容</span></span><br><span class="line">                   String data[] =&#123;<span class="string">&quot;First&quot;</span>,<span class="string">&quot;Second&quot;</span>,<span class="string">&quot;Third&quot;</span>&#125;;</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="comment">//建立连接</span></span><br><span class="line">                            socket = <span class="keyword">new</span> <span class="title class_">Socket</span>(serverIP,port);</span><br><span class="line">                            <span class="comment">//初始化流</span></span><br><span class="line">                            os = socket.getOutputStream();</span><br><span class="line">                            is = socket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] b = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i &lt; data.length;i++)&#123;</span><br><span class="line">                                     <span class="comment">//发送数据</span></span><br><span class="line">                                     os.write(data[i].getBytes());</span><br><span class="line">                                     <span class="comment">//接收数据</span></span><br><span class="line">                                     <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">                                     <span class="comment">//输出反馈数据                                     System.out.println(&quot;服务器反馈：&quot; + new String(b,0,n));</span></span><br><span class="line">                            &#125;</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                            e.printStackTrace(); <span class="comment">//打印异常信息</span></span><br><span class="line">                   &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">                            <span class="keyword">try</span> &#123;</span><br><span class="line">                                     <span class="comment">//关闭流和连接</span></span><br><span class="line">                                     is.close();</span><br><span class="line">                                     os.close();</span><br><span class="line">                                     socket.close();</span><br><span class="line">                            &#125; <span class="keyword">catch</span> (Exception e2) &#123;&#125;</span><br><span class="line">                   &#125;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该示例程序和前面的代码相比，将数据交换部分的逻辑写在一个for循环的内容，这样就可以建立一次连接，依次将data数组中的数据按照顺序发送给服务器端了。
如果还是使用前面示例代码中的服务器端程序运行该程序，则该程序的结果是：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.net.SocketException: Software caused connection abort: recv failed </span><br><span class="line">at java.net.SocketInputStream.socketRead0(Native Method) </span><br><span class="line">at java.net.SocketInputStream.read(SocketInputStream.java:129)</span><br><span class="line">at java.net.SocketInputStream.read(SocketInputStream.java:90)</span><br><span class="line">at tcp.MulSocketClient.main(MulSocketClient.java:30)</span><br><span class="line"></span><br><span class="line">服务器反馈：First</span><br></pre></td></tr></table></figure>
显然，客户端在实际运行时出现了异常，出现异常的原因是什么呢？如果仔细阅读前面的代码，应该还记得前面示例代码中的服务器端是对话一次数据以后就关闭了连接<strong>，如果服务器端程序关闭了，客户端继续发送数据肯定会出现异常，这就是出现该问题的原因</strong>。
按照客户端实现的逻辑，也可以复用服务器端的连接，实现的原理也是将服务器端的数据交换逻辑写在循环中即可，按照该种思路改造以后的服务器端代码为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 复用连接的echo服务器</span></span><br><span class="line"><span class="comment"> * 功能：将客户端发送的内容反馈给客户端</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MulSocketServer</span> &#123;</span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">                   <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">OutputStream</span> <span class="variable">os</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">InputStream</span> <span class="variable">is</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="comment">//监听端口号</span></span><br><span class="line">                   <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> <span class="number">10000</span>;</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="comment">//建立连接</span></span><br><span class="line">                            serverSocket = <span class="keyword">new</span> <span class="title class_">ServerSocket</span>(port);</span><br><span class="line">                            System.out.println(<span class="string">&quot;服务器已启动：&quot;</span>);</span><br><span class="line">                            <span class="comment">//获得连接</span></span><br><span class="line">                            socket = serverSocket.accept();</span><br><span class="line">                            <span class="comment">//初始化流</span></span><br><span class="line">                            is = socket.getInputStream();</span><br><span class="line">                            os = socket.getOutputStream();</span><br><span class="line">                            <span class="type">byte</span>[] b = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i &lt; <span class="number">3</span>;i++)&#123;</span><br><span class="line">                                     <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">                                     <span class="comment">//输出</span></span><br><span class="line">                                     System.out.println(<span class="string">&quot;客户端发送内容为：&quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(b,<span class="number">0</span>,n));</span><br><span class="line">                                     <span class="comment">//向客户端发送反馈内容</span></span><br><span class="line">                                     os.write(b, <span class="number">0</span>, n);</span><br><span class="line">                            &#125;</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                   &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">                            <span class="keyword">try</span>&#123;</span><br><span class="line">                                     <span class="comment">//关闭流和连接</span></span><br><span class="line">                                     os.close();</span><br><span class="line">                                     is.close();</span><br><span class="line">                                     socket.close();</span><br><span class="line">                                     serverSocket.close();</span><br><span class="line">                            &#125;<span class="keyword">catch</span>(Exception e)&#123;&#125;</span><br><span class="line">                   &#125;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在该示例代码中，也将数据发送和接收的逻辑写在了一个for循环内部，只是在实现时硬性的将循环次数规定成了3次，这样代码虽然比较简单，但是通用性比较差。
以该服务器端代码实现为基础运行前面的客户端程序时，客户端的输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">服务器反馈：First</span><br><span class="line">服务器反馈：Second</span><br><span class="line">服务器反馈：Third</span><br></pre></td></tr></table></figure>
<p>服务器端程序的输出结果为： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">服务器已启动：</span><br><span class="line">客户端发送内容为：First</span><br><span class="line">客户端发送内容为：Second</span><br><span class="line">客户端发送内容为：Third</span><br></pre></td></tr></table></figure>
在该程序中，比较明显的体现出了“请求-响应”模型，也就是在客户端发起连接以后，首先发送字符串“First”给服务器端，服务器端输出客户端发送的内容“First”，然后将客户端发送的内容再反馈给客户端，这样客户端也输出服务器反馈“First”，这样就完成了客户端和服务器端的一次对话，紧接着客户端发送“Second”给服务器端，服务端输出“Second”，然后将“Second”再反馈给客户端，客户端再输出“Second”，从而完成第二次会话，第三次会话的过程和这个一样。在这个过程中，每次都是客户端程序首先发送数据给服务器端，服务器接收数据以后，将结果反馈给客户端，客户端接收到服务器端的反馈，从而完成一次通讯过程。</p>
<p>在该示例中，虽然解决了多次发送的问题，但是客户端和服务器端的次数控制还不够灵活，如果客户端的次数不固定怎么办呢？是否可以使用某个特殊的字符串，例如quit，表示客户端退出呢,这就涉及到网络协议的内容了，会在后续的网络应用示例部分详细介绍。下面开始介绍另外一个网络编程的突出问题。</p>
<h3
id="如何使服务器端支持多个客户端同时工作">如何使服务器端支持多个客户端同时工作？</h3>
<p>前面介绍的服务器端程序，只是实现了概念上的服务器端，离实际的服务器端程序结构距离还很遥远，<strong>如果需要让服务器端能够实际使用，那么最需要解决的问题就是——如何支持多个客户端同时工作</strong>。</p>
<p><strong>一个服务器端一般都需要同时为多个客户端提供通讯，如果需要同时支持多个客户端，则必须使用前面介绍的线程的概念。简单来说，也就是当服务器端接收到一个连接时，启动一个专门的线程处理和该客户端的通讯。</strong></p>
<p>按照这个思路改写的服务端示例程序将由两个部分组成，MulThreadSocketServer类实现服务器端控制，实现接收客户端连接，然后开启专门的逻辑线程处理该连接，LogicThread类实现对于一个客户端连接的逻辑处理，将处理的逻辑放置在该类的run方法中。该示例的代码实现为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.net.ServerSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 支持多客户端的服务器端实现</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MulThreadSocketServer</span> &#123;</span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">                   <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                   <span class="comment">//监听端口号</span></span><br><span class="line">                   <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> <span class="number">10000</span>;</span><br><span class="line">                   <span class="keyword">try</span> &#123;</span><br><span class="line">                            <span class="comment">//建立连接</span></span><br><span class="line">                            serverSocket = <span class="keyword">new</span> <span class="title class_">ServerSocket</span>(port);</span><br><span class="line">                            System.out.println(<span class="string">&quot;服务器已启动：&quot;</span>);</span><br><span class="line">                            <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">                                     <span class="comment">//获得连接</span></span><br><span class="line">                                     socket = serverSocket.accept();</span><br><span class="line">                                     <span class="comment">//启动线程</span></span><br><span class="line">                                     <span class="keyword">new</span> <span class="title class_">LogicThread</span>(socket);</span><br><span class="line">                            &#125;</span><br><span class="line">                   &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                   &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">                            <span class="keyword">try</span>&#123;</span><br><span class="line">                                     <span class="comment">//关闭连接</span></span><br><span class="line">                                     serverSocket.close();</span><br><span class="line">                            &#125;<span class="keyword">catch</span>(Exception e)&#123;&#125;</span><br><span class="line">                   &#125;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在该示例代码中，实现了一个while形式的死循环，由于accept方法是阻塞方法，所以当客户端连接未到达时，将阻塞该程序的执行，当客户端到达时接收该连接，并启动一个新的LogicThread线程处理该连接，然后按照循环的执行流程，继续等待下一个客户端连接。这样<strong>当任何一个客户端连接到达时，都开启一个专门的线程处理，通过多个线程支持多个客户端同时处理</strong>。</p>
<p>下面再看一下LogicThread线程类的源代码实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.*;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 服务器端逻辑线程</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogicThread</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">         Socket socket;</span><br><span class="line">         InputStream is;</span><br><span class="line">         OutputStream os;</span><br><span class="line">         <span class="keyword">public</span> <span class="title function_">LogicThread</span><span class="params">(Socket socket)</span>&#123;</span><br><span class="line">                   <span class="built_in">this</span>.socket = socket;</span><br><span class="line">                   start(); <span class="comment">//启动线程</span></span><br><span class="line">         &#125;</span><br><span class="line">        </span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span>&#123;</span><br><span class="line">                   <span class="type">byte</span>[] b = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                   <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="comment">//初始化流</span></span><br><span class="line">                            os = socket.getOutputStream();</span><br><span class="line">                            is = socket.getInputStream();</span><br><span class="line">                            <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;i &lt; <span class="number">3</span>;i++)&#123;</span><br><span class="line">                                     <span class="comment">//读取数据</span></span><br><span class="line">                                     <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> is.read(b);</span><br><span class="line">                                     <span class="comment">//逻辑处理</span></span><br><span class="line">                                     <span class="type">byte</span>[] response = logic(b,<span class="number">0</span>,n);</span><br><span class="line">                                     <span class="comment">//反馈数据</span></span><br><span class="line">                                     os.write(response);</span><br><span class="line">                            &#125;</span><br><span class="line">                   &#125;<span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                   &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">                            close();</span><br><span class="line">                   &#125;</span><br><span class="line">         &#125;</span><br><span class="line">        </span><br><span class="line">         <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * 关闭流和连接</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">         <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span>&#123;</span><br><span class="line">                   <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="comment">//关闭流和连接</span></span><br><span class="line">                            os.close();</span><br><span class="line">                            is.close();</span><br><span class="line">                            socket.close();</span><br><span class="line">                   &#125;<span class="keyword">catch</span>(Exception e)&#123;&#125;</span><br><span class="line">         &#125;</span><br><span class="line">        </span><br><span class="line">         <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * 逻辑处理方法,实现echo逻辑</span></span><br><span class="line"><span class="comment">          * <span class="doctag">@param</span> b 客户端发送数据缓冲区</span></span><br><span class="line"><span class="comment">          * <span class="doctag">@param</span> off 起始下标</span></span><br><span class="line"><span class="comment">          * <span class="doctag">@param</span> len 有效数据长度</span></span><br><span class="line"><span class="comment">          * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">         <span class="keyword">private</span> <span class="type">byte</span>[] logic(<span class="type">byte</span>[] b,<span class="type">int</span> off,<span class="type">int</span> len)&#123;</span><br><span class="line">                   <span class="type">byte</span>[] response = <span class="keyword">new</span> <span class="title class_">byte</span>[len];</span><br><span class="line">                   <span class="comment">//将有效数据拷贝到数组response中</span></span><br><span class="line">                   System.arraycopy(b, <span class="number">0</span>, response, <span class="number">0</span>, len);</span><br><span class="line">                   <span class="keyword">return</span> response;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在该示例代码中，<strong>每次使用一个连接对象构造该线程，该连接对象就是该线程需要处理的连接，在线程构造完成以后，该线程就被启动起来了，然后在run方法内部对客户端连接进行处理，</strong>数据交换的逻辑和前面的示例代码一致，只是这里将接收到客户端发送过来的数据并进行处理的逻辑封装成了logic方法，按照前面介绍的IO编程的内容，客户端发送过来的内容存储在数组b的起始下标为0，长度为n个中，这些数据是客户端发送过来的有效数据，将有效的数据传递给logic方法，logic方法实现的是echo服务的逻辑，也就是将客户端发送的有效数据形成以后新的response数组，并作为返回值反馈。</p>
<p>在线程中将logic方法的返回值反馈给客户端，这样就完成了服务器端的逻辑处理模拟，其他的实现和前面的介绍类似，这里就不在重复了。</p>
<p>这里的示例还只是基础的服务器端实现，在实际的服务器端实现中，由于硬件和端口数的限制，所以<strong>不能无限制的创建线程对象，而且频繁的创建线程对象效率也比较低，所以程序中都实现了线程池来提高程序的执行效率。</strong></p>
<p>这里简单介绍一下线程池的概念，<strong>线程池(Thread
pool)是池技术的一种，就是在程序启动时首先把需要个数的线程对象创建好，例如创建5000个线程对象，然后当客户端连接到达时从池中取出一个已经创建完成的线程对象使用即可。当客户端连接关闭以后，将该线程对象重新放入到线程池中供其它的客户端重复使用，这样可以提高程序的执行速度，优化程序对于内存的占用等。</strong></p>
<hr />
<p>转载，作者不详，侵删</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>计算机网络</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>超参搜索中的 Bayesian Optimization 方法</title>
    <url>/2019/07/10/%E8%B6%85%E5%8F%82%E6%90%9C%E7%B4%A2%E4%B8%AD%E7%9A%84%20Bayesian%20Optimization%20%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>机器学习中存在着众多的超参数，如 model 中的超参，optimizer
中的超参，loss function
中的各种超参等，这些超参需要使用者根据经验设定，并根据训练结果进行调整，因为这些超参的最优值跟不同任务、不同数据集相关,
没有一个非常通用的经验值。</p>
<p>这一步骤往往繁琐耗时，为了简化这一过程，有了 <a
href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">Hyperparameter
optimization</a>
的研究，其目的是自动搜索最优的超参。超参搜索最常见的方法是 grid
search，random search，当然也有更高级的方法如基于启发式方法的 heuristic
search、基于统计学的 bayesian optimization等，本文主要介绍超参搜索中的
Bayesian Optimization 方法，这是超参搜索比较常见的做法，Google
也将这部分作为一个 service 提供在 <a
href="https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-cloud-machine-learning-engine-using-bayesian-optimization">Google
Cloud</a> 上。本文主要介绍 Bayesian Optimization 中的 GPR(Gaussian
Process Regression) + GP-BUCB(Gaussian Process Regression-Batch Upper
Confidence Bound) 方法。</p>
<span id="more"></span>
<p>更准确地说， <a
href="https://en.wikipedia.org/wiki/Bayesian_optimization">Bayesian
Optimization</a>
应该是一个算法框架，其目的是为了推断那些不能显示给出函数形式的 black-box
function，而<strong>在超参搜索中，这个函数指的是将超参数 <span
class="math inline">\(x\)</span> 映射至最终的收益 <span
class="math inline">\(y\)</span> 的那个函数</strong>，这里的收益不一定是
loss，还可以是 loss 与评估指标的融合，如在 ctr 预估中可以将 y
定义为：<span class="math inline">\(y = \alpha\_1 \* auc - \alpha\_2 \*
logloss\)</span></p>
<p>常见的 Bayesian Optimization 方法由两部分组成，高斯过程回归(Gaussian
Process Regression, GPR) 和 EE(Exploration Exploitation) trade-off,
下面分别介绍这两部分的具体过程</p>
<h2 id="高斯过程回归gpr">高斯过程回归(GPR)</h2>
<p>首先，从名字上看，高斯过程回归是一种回归方法，而回归就是给一堆已知的
x 和 y，然后当拿出一个新 x
的时候，能够预测出对应的新y，但是<strong>不同于常见的回归方法最终预测出一个值，高斯过程回归最终预测的是新的
y 的分布</strong></p>
<p>那高斯体现在哪里？顾名思义，Bayesian Optimization
是一种贝叶斯方法，而贝叶斯方法往往少不了先验，而在这里高斯其实是作为一种先验，即我们认为所有的
y 服从一个零均值的多维的联合高斯分布（注意这里每个 y
自己也服从一个一维高斯分布），相比于一维高斯分布，多维高斯分布将原来的均值变为了均值向量，方差变为了协方差矩阵，（可参考<a
href="https://www.zhihu.com/question/36339816/answer/67043318">多维高斯分布是如何由一维发展而来的？</a>了解如何从一维高斯分布推广至多维高斯分布)</p>
<p>至于过程(process), 则是指随机过程(<a
href="https://en.wikipedia.org/wiki/Stochastic_process">stochastic
process</a>),
这里指的是多个服从高斯分布的随机变量组成了一个随机过程，但是这里点对于我们理解
GPR 不重要。</p>
<p>推导 GPR 可从 Weight-space 角度 或 Function-space
角度进行，具体可参考 <a
href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf">Gaussian
Processes for Machine Learning</a> 中 p7-p35 部分，这里为了简单起见只从
Function-space
进行描述，并且会尽可能通过直观的方式描述这一点，某些符号与上面的 pdf
可能不一致</p>
<p>在训练集中，假设我们有3个x, 记为 <span
class="math inline">\(x\_1、x\_2、 x\_3\)</span>, 以及这3个点对应的 y,
记为 <span
class="math inline">\(f\_1、f\_2、f\_3\)</span>，由于假设所有的 y
服从一个均值为 0 的多维联合高斯分布，因此可写成如下形式(下面图片摘自<a
href="https://cloud.tencent.com/developer/article/1353538">这篇文章</a>）</p>
<figure>
<img src="https://wulc.me/imgs/multi_gaussian.png" alt="多维高斯分布" />
<figcaption aria-hidden="true">多维高斯分布</figcaption>
</figure>
<p>现在问题关键是模型的协方差矩阵 K
从哪儿来，为了解答这个问题，进行了另一个重要假设：</p>
<p><strong>如果两个x
比较相似（即离得比较近），那么对应的y值的相关性也就较高</strong>，即加入
x3 和 x2 离得比较近，则认为 f3 和 f2 的correlation 要比
f3和f1的correlation 高。换言之，<strong>协方差矩阵是 X
的函数而不是y的函数</strong></p>
<p>那么怎么衡量两个 x 比较相似？这个选择很多了，下面是一些简单的例子，在
GPR 中常用的是 RBF kernel（就是 SVM 中的那个 kernel，理论上，SVM
中的任意 kernel 在这里都适用）简单来说，RBF 隐式地对 x
进行了升维并计算内积，提升了表达能力。</p>
<ul>
<li>协方差</li>
</ul>
<p><span class="math display">\[k(x\_1, x\_2) = E[(x\_1 - E(x\_1))*(x\_2
- E(x\_2)]\]</span></p>
<ul>
<li>相关系数</li>
</ul>
<p><span class="math display">\[k(x\_1, x\_2) = \frac{E[(x\_1 -
E(x\_1))*(x\_2 - E(x\_2)]}{\sigma\_{x\_1}\sigma\_{x\_2}}\]</span></p>
<ul>
<li>RBF kernel</li>
</ul>
<p><span class="math display">\[k(x\_1, x\_2) = \exp(-\frac{||x\_1 -
x\_2||\_2^2}{2\sigma^2})\]</span></p>
<p>则当有新的 <span class="math inline">\(x\_\*\)</span> 要预测新的
<span class="math inline">\(f^\*\)</span> 时，由于假设所有的 y(即f)
服从一个均值为 0 的多维联合高斯分布，因此可写成如下形式,
而由于协方差矩阵是 <span class="math inline">\(x\)</span>
的函数，因此，下图中的 <span class="math inline">\(K\)</span> 和 <span
class="math inline">\(K\_\*\)</span>都可计算出来</p>
<figure>
<img src="https://wulc.me/imgs/multi_gaussian1.png"
alt="多维高斯分布1" />
<figcaption aria-hidden="true">多维高斯分布1</figcaption>
</figure>
<p>其中 <span class="math inline">\(K\_\*\)</span> 的计算方式如下，<span
class="math inline">\(k\)</span> 就是上面提到的衡量两个 <span
class="math inline">\(x\)</span> 有多近的函数，在 GPR 中也被称为
convariance function</p>
<p><span class="math display">\[ K\_\* =  [k(x\_\*, x\_1), k(x\_\*,
x\_2), k(x\_\*, x\*_\*3)]^T\]</span></p>
<p>有了所有 <span class="math inline">\(f\)</span>
的联合分布，根据多维高斯分布的性质，可计算出 <span
class="math inline">\(f^\*\)</span> 的分布如下，即</p>
<figure>
<img src="https://wulc.me/imgs/multi_gaussian3.png" alt="inference" />
<figcaption aria-hidden="true">inference</figcaption>
</figure>
<p>从上面的计算过程可知，GPR 的效果非常依赖于衡量两个 <span
class="math inline">\(x\)</span> 的相似度的函数 <span
class="math inline">\(k\)</span>, 而 RBF kernel 中存在着超参 <span
class="math inline">\(\sigma\)</span>, 因此 GPR
还会根据得到的样本进行MLE，进而更新 RBF kernel
中的超参数，其中要最大化的是样本的 log marginal likelihood,
其定义如下</p>
<p><span class="math display">\[ \log p(y|x,\theta) =
-\frac{1}{2}\log|K| - \frac{1}{2}
(y-\mu)^TK^{-1}(y-\mu)-\frac{n}{2}\log(2\pi)\]</span></p>
<p>因此，得到已有的样本后，将上面式子中的协方差矩阵 <span
class="math inline">\(K\)</span> 中的超参数 <span
class="math inline">\(\sigma\)</span>
视为未知变量，便可通过梯度下降等方法更新超参数</p>
<p>sklearn 中提供的 GPR 的实验，具体的使用方法及实现可参考 <a
href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor">GaussianProcessRegressor</a></p>
<p>通过上述的推导可知，对于每个新 <span
class="math inline">\(x\_\*\)</span>, GPR 会预估出这个 <span
class="math inline">\(x\_\*\)</span> 对应的 <span
class="math inline">\(y\_\*\)</span>
的分布(分布的具体形式为高斯分布)，而分布中均值表示 <span
class="math inline">\(y\_\*\)</span>
的预估值，方差则在一定程度上表示对这个预估值的置信程度（方差越大，预估值越不置信）</p>
<p>因此，GPR 的预估值天然就具备了 EE(Exploration&amp;Exploitation)
的属性，而这也是 Bayesian Optimization
第二步需要解决的问题，解决的方法有很多选择，其中可以贪婪地选择均值最大的，也可以综合考虑均值和方差，这个选择的策略在
Bayesian Optimization 中也被称为 acquisition
function；本文主要讲述其中的一种策略：UCB（Upper Confidence Bound)。</p>
<h2 id="ee-tradeoff">EE tradeoff</h2>
<p>假设现在有了 10000 组候选超参，通过 GPR 分别预测出 10000
组对应的均值和方差，那么该选择哪一组超参？这个问题可以很自然地通过 <a
href="https://en.wikipedia.org/wiki/Multi-armed_bandit">MAB</a>(Multi-armed
bandit) 建模, 而选择期望收益最高的策略在 Bayesian Optimization 中
也被称为 acquisition function，acquisition function
有多种选择，其中最常用的便是 UCB</p>
<p><a href="https://arxiv.org/abs/0912.3995">Gaussian Process
Optimization in the Bandit Setting: No Regret and Experimental
Design</a> 中最早提出了一种应用在GPR 中的 UCB 方法, 也称为
GP-UCB，其方法的流程如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/GP-UCB.png" alt="GP-UCB" />
<figcaption aria-hidden="true">GP-UCB</figcaption>
</figure>
<p>上面的算法流程中每次迭代都是选择出一个 <span
class="math inline">\(x\_t\)</span> ，通过训练或实验获得其真实的 <span
class="math inline">\(y\_t\)</span>, 并根据真实的结果更新 RBF kernel
中的超参数；而选择 <span class="math inline">\(x\)</span>
根据的是其对应的均值和方差的加权求和的值，其中方差权重的值 <span
class="math inline">\(\beta\_t\)</span> 的选择跟 regret bound（MAB
中的概念） 有关，上面的 paper
中证明了这一点，具体证明过程可参考原文，这里只给出最终的结论</p>
<figure>
<img src="https://wulc.me/imgs/GP-UCB-beta.png" alt="GP-UCB-beta" />
<figcaption aria-hidden="true">GP-UCB-beta</figcaption>
</figure>
<p>即 <span class="math inline">\(\beta =
2\log(|D|t^2\pi^2/6\delta)\)</span>, 其中 <span
class="math inline">\(|D|\)</span> 为当前样本的个数，<span
class="math inline">\(\delta\)</span> 需要根据置信程度选择，<span
class="math inline">\(\delta\)</span> 越小，表示选择越为保守，更偏向于
Exploitation</p>
<p>GP-UCB 方法每次只能选择一个 <span class="math inline">\(x\)</span>
进行试验，因此 <a href="https://arxiv.org/abs/1206.6402">Parallelizing
Exploration–Exploitation Tradeoffs with Gaussian Process Bandit
Optimization</a> 中对GP-UCB 进行了简单的改进，每次能够选择多个 <span
class="math inline">\(x\)</span> 并行进行试验，其算法流程如下</p>
<figure>
<img src="https://wulc.me/imgs/GP-BUCB.png" alt="GP-BUCB" />
<figcaption aria-hidden="true">GP-BUCB</figcaption>
</figure>
<p>上面的 fb 函数定义为 <span class="math inline">\(fb[t] = \lfloor
(t-1)/B\rfloor B\)</span>, 则 <span class="math inline">\(fb[0] =
...fb[B] = 0, fb[B+1] = ... fb[2B] = B\)</span>，即每次选择 B
组超参进行同时搜索，然后才根据反馈更新各组超参对应的 y 的均值
，这种方法与在 GP-UCB 中直接选择 B 个最大的区别是这种方法在这 B
次迭代中，每次都会根据选择了的 <span class="math inline">\(x\)</span> 和
<span class="math inline">\(y\)</span> 更新 RBF kernel
中的超参数，进而在下一次能够更新协方差矩阵</p>
<p>新广告或者说冷启动问题中也常常涉及到 EE
的问题，这里对两者的异同进行简单的比较</p>
<p><strong>其中最主要的差别是在新广告的中每个 arm(一个新广告)
的收益是不能通过一次试验确定的，而在超参搜索中每个 arm(一组超参)
的收益通过一次试验就能确定了</strong></p>
<p>在新广告的 EE 问题中，正是由于 arm
的收益是不确定的，所以才需要多次的试验结果来确定每个 arm 的期望收益</p>
<p>频率学派认为只要每个 arm 能够进行足够多次的实验，那每个 arm
的收益便可通过后验数据统计得到，但是正因为无法进行足够多次的实验，才会在不够置信的历史收益基础上增加一个
bound 作为 arm 的收益，而这就是 UCB
的主要思想，如果考虑每次请求上下文那就是 Lin-UCB</p>
<p>贝叶斯学派则认为每个 arm 的收益服从着特定的分布，首先会给每个 arm
一个收益的先验分布，然后通过试验获得似然并更新先验分布获得后验，然后后验作为下一次的先验；通过迭代这个过程让每个
arm 的分布更加接近真实分布，而这就是 Thomson Sampling
的思想，如果不考虑上下文，便是Beta 先验+ Bernoulli
似然；如果考虑了上下文，便是 Gaussian 先验+ Gaussian 似然n</p>
<p>关于这一类型的 EE 问题可参考 <a
href="http://wulc.me/2019/01/05/EE%28Exploitation%20Exploration%29%20%E9%97%AE%E9%A2%98%E6%A6%82%E8%BF%B0/">EE
问题概述</a></p>
<p>而在超参搜索的 EE
问题中，问题就没那么复杂了，只要超参选定了，那么只要用这组超参进行模型的训练或
AB 实验，其收益是确定的(在其他实验条件基本确定下)</p>
<h2 id="小结">小结</h2>
<p>本文主要介绍了超参搜索中的 Bayesian Optimization 中常用的 GPR+GP-UCB
组合。GPR 是一种贝叶斯回归方法，能够回归出 y
的分布而不是一个具体的值，其使用也不限于 Bayesian Optimization 中；而
GP-UCB 与冷启动新广告中的 UCB 等 bandit
算法也不完全相同，主要原因是在超参搜索中的一组超参(arm)的收益
通过一次试验便能够确定了，而一个新广告（arm)的收益在一次试验中并无法完全确定，其方法的区别可参考
EE tradeoff 部分。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 Keras 实现 LRCN 模型</title>
    <url>/2018/04/18/%E9%80%9A%E8%BF%87%20Keras%20%E5%AE%9E%E7%8E%B0%20LRCN%20%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>本文主要介绍了如何通过 Keras 实现 LRCN 模型，模型出自论文 <a
href="https://arxiv.org/abs/1411.4389">Long-term Recurrent Convolutional
Networks for Visual Recognition and
Description</a>，最近需要用这个模型做个实验，在网上搜到的实现代码不多，因此这里记录一下，以供参考。</p>
<span id="more"></span>
<p>这里的 LRCN 模型的结构如下图所示， 输入是 image sequence，然后通过
CNN 提取每帧图像的特征，作为 LSTM 的输入，LSTM可以为每帧预测一个
label，也可在只在最后预测一个 label 作为整个 sequence 的
label。这种想法非常自然，也是 video/image sequence 中的一个 base
model。</p>
<figure>
<img src="https://wulc.me/imgs/image_1cbhou3v21gao17kv1ls215vdk90p.png"
alt="CNN_LSTM" />
<figcaption aria-hidden="true">CNN_LSTM</figcaption>
</figure>
<p>下面首先讲述如何在 Keras
中构建这个模型，然后讲述数据加载的两种模式：分别对应于不定长的输入序列和固定长度的输入序列。</p>
<h2 id="构建模型">构建模型</h2>
<p>在具体的实现中，对于训练数据集不大的情况下， CNN
部分一般可采用预训练的模型，然后选择是否对其进行
FineTunning，这里我采用的是在 ImageNet 上预训练的 VGG16，并且对 VGG16
最上面的5层进行 FineTunning， 其他层的参数不变。</p>
<p>另外，对于输入的每帧图像，通过 CNN 抽取出的 feature map 的
大小为(7,7,512)，而 LSTM 的输入的 size 是
<code>(batch_size, timesteps, input_dim)</code>，因此需要将 (7,7,512)
转为一个一维的 vector，这里我采用最简单的 <code>Flatten()</code>
方法。实际上，在这里可以采用更加灵活的转换，如这篇论文 <a
href="https://arxiv.org/abs/1606.08572">Diversified Visual Attention
Networks for Fine-Grained Object Classification</a> 就提出了一种
attention 机制处理这些feature map。</p>
<p>(7,7,512) 直接 Flatten 后的大小为 25088，直接输入 LSTM
的话比较大，因此这里还加了一个 2048 的全连接层，这样输入 LSTM 的
<code>input_dim</code> 的大小就是 2048.</p>
<p>LRCN 模型中的关键点在于为每个 LSTM 的 step 前连上 CNN 网络部分，在
Keras 中可通过 <a
href="https://keras.io/layers/wrappers/#timedistributed">TimeDistributed</a>
层来实现，同时如果需要长度不固定的输入序列时，对应的 sequence
length的参数要设为 None，在下面的代码中 <code>input_shape</code> 设为了
<code>(None, 224, 224, 3)</code>, None 便是输入序列长度不固定，而 （224,
224, 3）则是预训练 VGG 固定的输入大小。</p>
<p>构建模型的 keras 代码如下，这里为了加快训练速度，将 LSTM 替换成了
GRU</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, TimeDistributed, Flatten, GRU, Dense, Dropout</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_model</span>():</span><br><span class="line">    pretrained_cnn = VGG16(weights=<span class="string">&#x27;imagenet&#x27;</span>, include_top=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># pretrained_cnn.trainable = False</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> pretrained_cnn.layers[:-<span class="number">5</span>]:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># input shape required by pretrained_cnn</span></span><br><span class="line">    <span class="built_in">input</span> = Input(shape = (<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)) </span><br><span class="line">    x = pretrained_cnn(<span class="built_in">input</span>)</span><br><span class="line">    x = Flatten()(x)</span><br><span class="line">    x = Dense(<span class="number">2048</span>)(x)</span><br><span class="line">    x = Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">    pretrained_cnn = Model(inputs = <span class="built_in">input</span>, output = x)</span><br><span class="line"></span><br><span class="line">    input_shape = (<span class="literal">None</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>) <span class="comment"># (seq_len, width, height, channel)</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(TimeDistributed(pretrained_cnn, input_shape=input_shape))</span><br><span class="line">    model.add(GRU(<span class="number">1024</span>, kernel_initializer=<span class="string">&#x27;orthogonal&#x27;</span>, bias_initializer=<span class="string">&#x27;ones&#x27;</span>, dropout=<span class="number">0.5</span>, recurrent_dropout=<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(categories, activation = <span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                optimizer = optimizers.SGD(lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>, clipnorm=<span class="number">1.</span>, clipvalue=<span class="number">0.5</span>),</span><br><span class="line">                metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>上面 LSTM 的参数初始化参考了知乎上这个答案：<a
href="https://www.zhihu.com/question/57828011/answer/155275958">你在训练RNN的时候有哪些特殊的trick？</a>，主要就是
initializer 的方式选择、drop-out 和 graddient
clipping的设置。在我的实验中也证实了 graddient clipping
的设置会直接影响到最终的进度，而且影响比较大。</p>
<h2 id="数据加载">数据加载</h2>
<p>由于 RNN 本身的结构特点，使得其可接受变长的输入，而且往往原始的 img
sequence
数据也会符合这一特点，因此这里就有两种数据加载的方式，第一种是对原始数据不做处理,
每个样本的长度不一定相同；第二种是从各个样本中抽取出固定的长度。</p>
<p><strong>但是这两种加载方式的输入的数据的 shape 都遵循着下面的模式
<code>(batch_size, sequence_length, width, height, channel)</code></strong></p>
<p>对于第一种加载方式，根据 <a
href="https://github.com/keras-team/keras/issues/40">这个
issue</a>，有两种处理方法</p>
<ol type="1">
<li>Zero-padding</li>
<li>Batches of size 1</li>
</ol>
<p>这里采用的是第二种处理方法，也就是将 batch_size 设置为1，
即每次只用一个样本更新模型。因为第二种处理方法要事先设定一个固定长度(可以是最长序列长度或其他方式获取的长度)，而且padding会让原来较短的序列变得更长，消耗的内存会有所增加。</p>
<p>而对于第二种加载方式，给定固定的长度，需要尽可能“均匀”地从原始序列中抽出固定长度的序列，即帧与帧之间的间隔尽可能相等。但是这个可能会取决于具体的数据集和任务，在我的数据集上这样做是比较合理的。</p>
<p>两种加载方式的比较如下：
1）存储数据的方式不一样，固定长度的加载方式由于每个样本的 shape
一样，因此可以直接 concatenate 成一个大的 ndarray，然后在训练时的
<code>batch_size</code>
可设置成任意值；但是对于变长的加载方式，只能每次取一个样本, 然后要通过
<code>np.expand_dims(imgs, axis=0)</code> 的方式为样本添加
<code>batch_size</code> 这个维度（前一种方式不用，因为concatenate
后会自动生成这个维度），然后训练模型同时将 <code>batch_size</code> 和
epoch 设为1。 2）训练速度和效果有差别。首先是 <code>batch_size</code>
的不同使得训练速度上固定长度的方式比变长方式要快，这个比较好理解。
其次，由于 <code>batch_size</code> 也是一个影响 RNN
性能的重要参数，因此也会影响收敛性和效果。在我的实验中，<code>batch_size</code>
设置大于 1 时效果更好。</p>
<p>两种加载方式实现代码如下，加载的是一个样本的数据，
<code>img_dir</code> 目录中包含了一个样本的所有 image
sequence，且根据文件名排序后的序列是根据时间序列的。 <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_sample</span>(<span class="params">img_dir, categories = <span class="number">7</span>, fixed_seq_len = <span class="literal">None</span></span>):</span><br><span class="line">    label = <span class="built_in">int</span>(img_dir.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">2</span>].split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>]) - <span class="number">1</span> <span class="comment"># extract label from name of sample</span></span><br><span class="line">    img_names = <span class="built_in">sorted</span>(os.listdir(img_dir))</span><br><span class="line">    imgs = []</span><br><span class="line">    <span class="keyword">if</span> fixed_seq_len: <span class="comment"># extract certain length of sequence</span></span><br><span class="line">        block_len = <span class="built_in">round</span>(<span class="built_in">len</span>(img_names)/fixed_seq_len)</span><br><span class="line">        idx = <span class="built_in">len</span>(img_names) - <span class="number">1</span></span><br><span class="line">        tmp = deque()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(fixed_seq_len):</span><br><span class="line">            tmp.appendleft(img_names[idx])</span><br><span class="line">            idx = <span class="built_in">max</span>(idx-block_len, <span class="number">0</span>)</span><br><span class="line">        img_names = tmp</span><br><span class="line">    <span class="keyword">for</span> img_name <span class="keyword">in</span> img_names:</span><br><span class="line">        img_path = img_dir + img_name</span><br><span class="line">        img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">        x = image.img_to_array(img)</span><br><span class="line">        imgs.append(x)</span><br><span class="line">    imgs = np.array(imgs)</span><br><span class="line">    label = np_utils.to_categorical(label, num_classes=categories)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> fixed_seq_len: <span class="comment"># add dimension for batch_size</span></span><br><span class="line">        <span class="comment">#（seq_len, width, height, channel）-&gt; (batch_size, seq_len, width, height, channel)</span></span><br><span class="line">        imgs = np.expand_dims(imgs, axis=<span class="number">0</span>) </span><br><span class="line">        label = label.reshape(-<span class="number">1</span>, categories)</span><br><span class="line">    <span class="keyword">return</span> imgs, label</span><br></pre></td></tr></table></figure></p>
<p>最后，在设计网络结构的时候，可通过逐层测试输出的大小来判断每一层是够达到了预期输出的效果，在
keras 中直接通过 <code>model.predict(input)</code> 即可获得当前 model
最后一层的输出。</p>
<p>另外，Keras 虽然能够比较快速地通过其提供的各层 layer
搭建出模型，但是如果要对模型进行更细致的设计的时候， Keras
就不是那么好做了，这时候就要上 tensorflow/pytorch/mxnet
这一类更加灵活的框架了。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 Flask, Docker, Jenkins 和 Kubernets 部署机器学习模型</title>
    <url>/2019/04/19/%E9%80%9A%E8%BF%87%20Flask,%20Docker,%20Jenkins%20%E5%92%8C%20Kubernets%20%E9%83%A8%E7%BD%B2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p>本文主要介绍部署机器学习模型的一种自动化方式，如题所示，通过 <a
href="http://flask.pocoo.org/">Flask</a>，<a
href="https://www.docker.com/">Docker</a>, <a
href="https://jenkins.io/">Jenkins</a> 和 <a
href="https://kubernetes.io">Kubernets</a> 实现。基本原理就是通过 Flask
提供 <a
href="https://searchmicroservices.techtarget.com/definition/RESTful-API">RESTful
API</a> 接收客户端的 predict 请求，然后将这个服务打包成一个 docker image
便于部署和迁移，当代码或模型更新时通过 Jenkins 触发自动构建新的 docker
image，而通过 kubernets
管理容器则让整个服务具备伸缩性和可靠性。本文主要参考了 <a
href="https://medium.com/sfu-big-data/machine-learning-deployment-a-storm-in-a-teacup-10541ec3b0d6">Deploy
a machine learning model in 10 minutes with Flask, Docker, and
Jenkins</a>，并在其基础上进行了完善和拓展，如通过一个简单的 shell script
实现 jenkins 的触发功能，并添加了 kubernets
部分的介绍等。本文的对应的所有代码可从 <a
href="https://github.com/WuLC/DeployMachineLearningModel">DeployMachineLearningModel</a>
获取。</p>
<span id="more"></span>
<p>下文基本可以依样画葫芦走一遍，为了避免不必要的麻烦，尽量不要在
windows 下配置，虽然上述这些工具也提供了 windows
的版本，但是使用起来总是出现各种问题；也不要在win10 的 wsl 中配置，因为
docker 涉及到了 linux 底层的 cgroup，在 wsl 中并不能直接安装
docker。本文的实验时最开始为了方便在上面提到的两个环境中进行了实验，结果是折腾了好久，最后通过在
virtual box 中的 ubuntu 16.04 进行以下的实验。</p>
<p>下图摘自文章前面提到的 Deploy a machine learning model in 10 minutes
with Flask, Docker, and
Jenkins，从中可以看到清晰看到整个部署和访问的流程</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model.png"
alt="deploy model" />
<figcaption aria-hidden="true">deploy model</figcaption>
</figure>
<h2 id="flask-提供-restful-api">Flask 提供 RESTful api</h2>
<p>Flask 的作用主要是提供 RESTful api 供客户端进行 predict，像
Google、Microsoft、Face++ 这些公司提供的 AI
服务（即人脸识别，表情识别等），基本都是通过 RESTful api
提供的，其基本原理是客户端将通过 POST
请求将需要预测的样本发送到服务器，然后服务器提取样本进行预测并返回结果；且通常还需要附带
id
判别身份，从而进行相应的扣费，这里为了简单起见不会去考虑这些问题。</p>
<p>通过 Flask 能够非常简单地在搭建一个 HTTP Server
并在指定端口监听，如果接收到 POST
请求便调用模型进行预测并返回，因此首先需要训练模型并将训练好的模型 load
进内存，为了简单起见，这里的任务是 sklearn 内置的 iris 分类。</p>
<h3 id="训练并保存模型">训练并保存模型</h3>
<p>训练并持久化模型的代码如下所示，对应 <code>train_model.py</code>
文件</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line"><span class="comment"># simple demo for traing and saving model</span></span><br><span class="line">iris=datasets.load_iris()</span><br><span class="line">x=iris.data</span><br><span class="line">y=iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment">#labels for iris dataset</span></span><br><span class="line">labels =&#123;</span><br><span class="line">  <span class="number">0</span>: <span class="string">&quot;setosa&quot;</span>,</span><br><span class="line">  <span class="number">1</span>: <span class="string">&quot;versicolor&quot;</span>,</span><br><span class="line">  <span class="number">2</span>: <span class="string">&quot;virginica&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">.25</span>)</span><br><span class="line">classifier=tree.DecisionTreeClassifier()</span><br><span class="line">classifier.fit(x_train,y_train)</span><br><span class="line">predictions=classifier.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#export the model</span></span><br><span class="line">model_name = <span class="string">&#x27;model.pkl&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished training and dump the model as &#123;0&#125;&quot;</span>.<span class="built_in">format</span>(model_name))</span><br><span class="line">pickle.dump(classifier, <span class="built_in">open</span>(model_name,<span class="string">&#x27;wb&#x27;</span>))</span><br></pre></td></tr></table></figure>
<h3 id="加载模型并提供调用-api">加载模型并提供调用 api</h3>
<p>通过 Flask 能够快速启动一个 http server
并在不同的访问路径设置不同的处理函数，详细语法可参考<a
href="http://flask.pocoo.org/">官网教程</a>。</p>
<p>本文的例子很简单，如下代码所示（对应源文件
<code>server.py</code>)，首先把模型 load 进内存，然后设置了访问路径为
<code>/api</code> 时调用模型进行
predict，为了简单起见这里没做输入数据的检查和异常处理；最后
<code>app.run</code> 启动了一个 server 并默认监听在 5000 端口。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, request, jsonify</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">model = pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;model.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">labels = &#123;</span><br><span class="line">  <span class="number">0</span>: <span class="string">&quot;versicolor&quot;</span>,   </span><br><span class="line">  <span class="number">1</span>: <span class="string">&quot;setosa&quot;</span>,</span><br><span class="line">  <span class="number">2</span>: <span class="string">&quot;virginica&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/api&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>():</span><br><span class="line">    <span class="comment"># Get the data from the POST request.</span></span><br><span class="line">    data = request.get_json(force = <span class="literal">True</span>)</span><br><span class="line">    predict = model.predict(data[<span class="string">&#x27;feature&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> jsonify(predict[<span class="number">0</span>].tolist())</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(debug = <span class="literal">True</span>, host = <span class="string">&#x27;0.0.0.0&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>利用以上两个文件，通过命令
<code>python train_model.py &amp;&amp; python server.py</code>
便可训练出一个模型并通过 http server 提供访问 api。</p>
<p>客户端要进行预测时可通过如下代码（见源文件 <code>client.py</code>),
这里的 <code>192.168.31.78</code> 是我的实验环境里面启动 httpserver
的机器ip（<code>client.py</code> 里面使用的是 8000 端口，因为利用了
docker 进行了端口映射，后文会对这一点进行讲解）</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># Change the value of experience that you want to test</span></span><br><span class="line">url = <span class="string">&#x27;http://192.168.31.78:5000/api&#x27;</span></span><br><span class="line">feature = [[<span class="number">5.8</span>, <span class="number">4.0</span>, <span class="number">1.2</span>, <span class="number">0.2</span>]]</span><br><span class="line">labels =&#123;</span><br><span class="line">  <span class="number">0</span>: <span class="string">&quot;setosa&quot;</span>,</span><br><span class="line">  <span class="number">1</span>: <span class="string">&quot;versicolor&quot;</span>,</span><br><span class="line">  <span class="number">2</span>: <span class="string">&quot;virginica&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">r = requests.post(url,json=&#123;<span class="string">&#x27;feature&#x27;</span>: feature&#125;)</span><br><span class="line"><span class="built_in">print</span>(labels[r.json()])</span><br></pre></td></tr></table></figure>
<p>在同一局域网的机器运行上面的代码便能输出 <code>setosa</code>
这个预测结果</p>
<h2 id="docker-打包和运行程序">Docker 打包和运行程序</h2>
<p>Docker 的安装参考 <a
href="https://docs.docker.com/install/linux/docker-ce/ubuntu/">Get
Docker CE for Ubuntu</a>， 这里不再赘述</p>
<h3 id="打包">打包</h3>
<p>利用 Docker 可以将上述部署的环境打包成一个
image，便于部署、迁移和弹性扩展（配合 Kubernets
使用），因此下文主要描述如何通过 Dockerfile 构建 image，关于 Dockerfile
的详细语法可参考 <a
href="https://docs.docker.com/engine/reference/builder/">文档</a>，这里只列出本文用到的一些语法。</p>
<p>类似 shell 脚本，Dockerfile 里面是一系列的指令，作用是让 Docker 通过
Dockerfile 和 <code>docker build</code> 命令自动构建出目标 image。</p>
<p>在执行 docker build 命令时通过 -t 指定生成的 image 的
tag，能够保存生成的 image，如
<code>docker build -t shykes/myapp .</code>，最后的 <code>.</code> 表示
Dockerfile 的目录，即这条命令是在 Dockerfile 所在目录下执行</p>
<p>Dockerfile 的基本原理是首先通过 <code>FROM</code> 命令获取一个基本的
image，然后在这个 image
基础上通过各种命令配置好我们运行程序需要的环境，接着把我们的源文件复制到
image 里，进行构建和运行。</p>
<p>Dockerfile 中值得注意事项如下，为了保持原意这里不进行翻译</p>
<ul>
<li>each instruction is run independently, so <code>RUN cd /tmp</code>
will not have any effect on the next instructions</li>
<li>basic syntax is <code>INSTRUCTION arguments</code>， the
<strong>instruction is not case-sensitive</strong>. However,
<strong>convention is for them to be UPPERCASE</strong> to distinguish
them from arguments more easily.</li>
<li><strong>A Dockerfile must start with a <code>FROM</code>
instruction</strong>. The FROM instruction specifies the Base Image from
which you are building</li>
<li><code>FROM</code> can appear multiple times within a single
Dockerfile to create multiple images or use one build stage as a
dependency for another</li>
<li>Docker treats lines that begin with # as a comment</li>
<li><code>RUN &lt;command&gt;</code> (the command is run in a shell,
which by default is <code>/bin/sh -c</code> on Linux or
<code>cmd /S /C</code> on Windows</li>
<li><strong>There can only be one <code>CMD</code> instruction in a
Dockerfile</strong>. If you list more than one CMD then only the last
CMD will take effect.</li>
<li><strong><code>RUN</code> v.s <code>CMD</code>. <code>RUN</code>
actually runs a command and commits the result; <code>CMD</code> does
not execute anything at build time, but specifies the intended command
for the image.</strong></li>
<li>The <code>WORKDIR</code> instruction sets the working directory for
any <code>RUN, CMD, ENTRYPOINT, COPY</code> and <code>ADD</code>
instructions that follow it in the Dockerfile. If the
<code>WORKDIR</code> doesn’t exist, it will be created even if it’s not
used in any subsequent Dockerfile instruction</li>
<li><code>COPY &lt;src&gt;... &lt;dest&gt;</code>; <strong>The
<code>COPY</code> instruction copies new files or directories from
<code>&lt;src&gt;</code> and adds them to the filesystem of the
container at the path <code>&lt;dest&gt;</code>;The
<code>&lt;dest&gt;</code> is an absolute path, or a path relative to
<code>WORKDIR</code>, If <code>&lt;dest&gt;</code> doesn’t exist, it is
created along with all missing directories in its path.</strong></li>
<li><code>ADD &lt;src&gt; &lt;dest&gt;</code>; The <code>ADD</code>
instruction copies new files, directories or <strong>remote file
URLs</strong> from <code>&lt;src&gt;</code> and adds them to the
filesystem of the image at the path <code>&lt;dest&gt;</code></li>
<li><code>COPY</code> v.s <code>ADD</code>. <code>COPY</code> only lets
you copy in a <strong>local</strong> file or directory from your host
(the machine building the Docker image) into the Docker image itself.
<code>ADD</code> lets you do that too, but it also supports 2 other
sources. First, with <code>ADD</code> you can use a <strong>remote
URL</strong> instead of a local file / directory<strong>. Secondly, you
can </strong>extract a tar file** from the source directly into the
destination.</li>
<li>Environment variables (declared with the <code>ENV</code> statement)
can also be used in certain instructions as variables to be interpreted
by the Dockerfile; Environment variables are notated in the Dockerfile
either with <code>$variable_name</code> or
<code>$&#123;variable_name&#125;</code></li>
</ul>
<p>因此，构建上述的环境的 Dockerfile 如下所示, 参考链接中的 Dockerfile
中有两个 FROM 语句，分别表示 ubuntu 环境和 python 环境，且需要安装 pip
等工具，这里直接通过 <code>nitincypher/docker-ubuntu-python-pip</code>
提供这些功能</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># train and run the model with RESTful api</span></span><br><span class="line"><span class="keyword">FROM</span> nitincypher/docker-ubuntu-python-pip</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> ./requirements.txt /app/requirements.txt</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . /app</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> python /app/train_model.py &amp;&amp; python /app/server.py</span></span><br></pre></td></tr></table></figure>
<p>实验的项目路径为 <code>/opt/src/DeployMachineLearningModel</code>,
则构建 image 的命令为 <code>docker build -t deploy_ml_model .</code>,
其过程如下所示,可以看到</p>
<p>1)构建前系统的 docker images
情况，由于之前已经运行过这条命令，因此依赖的
<code>nitincypher/docker-ubuntu-python-pip</code> 也已经 pull
到本地了。如果是第一次运行，则下载
<code>nitincypher/docker-ubuntu-python-pip</code> 需要一定的时间 2)
Dockerfile 中每条命令都是运行时的一个 step，在构建时不会运行
<code>CMD</code> 的命令，而是通过 <code>docker run</code> 时才执行</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_build_image.png"
alt="build" />
<figcaption aria-hidden="true">build</figcaption>
</figure>
<p>构建完成后可以看到系统中的多了 <code>deploy_ml_model</code> 这个
image</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_images_after_built.png"
alt="after build" />
<figcaption aria-hidden="true">after build</figcaption>
</figure>
<h3 id="运行">运行</h3>
<p>接着需要运行这个 image，运行的 container 内部 Flask 在监听 5000
端口，因此需要通过端口映射为外部机器可见的端口，通过命令
<code>docker run -p 8000:5000 deploy_ml_model</code> 可通过运行 docker
的机器的 8000 端口访问 container 内部提供的 api，如下所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_run_container.png"
alt="run container" />
<figcaption aria-hidden="true">run container</figcaption>
</figure>
<p>将上面的客户端的代码的端口改成 8000 便是 <code>client.py</code>
源文件了，运行 <code>client.py</code> 结果如下所示，</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_client_response.png"
alt="response" />
<figcaption aria-hidden="true">response</figcaption>
</figure>
<p>此时的 server 接收到一个 POST 请求，输出的日志如下</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_server_log.png"
alt="server log" />
<figcaption aria-hidden="true">server log</figcaption>
</figure>
<p>如果需要停止运行的 container，通过 <code>docker stop</code> 并指定
container 的 id 即可， container id
并不需要全输入，只需要输入能系统能区分不同 container
的程度即可。该过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_stop_container.png"
alt="stop container" />
<figcaption aria-hidden="true">stop container</figcaption>
</figure>
<h2
id="jenkins或自定义脚本触发自动构建">Jenkins或自定义脚本触发自动构建</h2>
<p>上面的构建流程中，只要每次代码或模型有更新便需要重新手动执行
<code>docker build</code> 和 <code>docker run</code>, 而通过 jenkins
或自定义的脚本便能让这个流程自动化，这个过程需要结合 Github
实现，即当代码仓库有更新时，便自动构建新的 image。</p>
<p>其基本原理是 Github 在 repository 发生变化时，会向指定的 url 发送一个
POST 请求告知 repository 有更新，只要我们监听这个 url 并在收到这个 POST
请求时进行更新即可，这个机制在 Github 中被称为 <a
href="https://developer.github.com/webhooks/">WebHooks</a>。Github
提供的 WebHooks 中涵盖了多种更新情况，不同的更新对应于不同的
event，可以在 Github 中自定义需要触发的事件，默认触发的是 PUSH
事件（如commit、PR 等）。</p>
<h3 id="jenkins-自动构建">Jenkins 自动构建</h3>
<p>Jenkins 在 Ubuntu 下的安装参考 <a
href="https://jenkins.io/doc/book/installing/#debianubuntu">Installing
Jenkins</a>，这里不再赘述</p>
<p>Jenkins 是一个功能齐全的自动化构建工具，类似 Docker 通过 Dockerfile
定义 image 的构建过程，jenkins 也能通过 Jenkinsfile
定义工程的构建过程。</p>
<p>但是本文只用到其接收到 Github 发送的 POST
请求并触发其重新构建的功能，其配置流程如下，首先新建一个自由风格的项目，并配置其为
Github 项目，管理源码的方式为 git，如下所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_jenkins_git_config.png"
alt="configure" />
<figcaption aria-hidden="true">configure</figcaption>
</figure>
<p>然后配置触发方式和构建的命令如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_jenkins_trigger.png"
alt="configure" />
<figcaption aria-hidden="true">configure</figcaption>
</figure>
<p>配置并保存后便可直接 “立即构建” 进行项目的构建，jenkins
会自动下载仓库并进行构建，通过控制台输出可以看到构建过程，该过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_build_with_jenkins.png"
alt="build" />
<figcaption aria-hidden="true">build</figcaption>
</figure>
<p>点击控制台输出后显示的日志</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_jenkins_log.png"
alt="log" />
<figcaption aria-hidden="true">log</figcaption>
</figure>
<p>上面提到了触发 jenkins 自动构建的原理，即当代码仓库有更新时，github
会发送 POST 请求给 jenkins，然后 jenkins 会进行自动构建，这种情况下
jenkins 首先需要有一个能够接受 github 的 POST 请求的 url，但是 jenkins
当前是部署在局域网内部的，这时便需要借助 <a
href="https://ngrok.com/">ngrok</a> 这个工具来生成一个 github 能够访问的
url 了</p>
<p>ngrok 的作用就是为局域网内部的机器生成一个 public
url，从而使得内部的服务能够被其他机器访问，其基本原理就是 ngrok
在这个访问过程中提供了中转。ngrok 的下载和安装都很简单，可参考上面上面的
ngrok 的官网，这里不再赘述。</p>
<p>由于 jenkins 在本地的端口是8080，因此通过 ngrok 为 jenkins 生成
public url 如下所示，可以看到生成了 http 和 https
两个类型的地址；最下面显示的是最近的请求情况，可以看到 github
发送了3个更新的 POST 请求</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_ngrok_public_address.png"
alt="ngrok" />
<figcaption aria-hidden="true">ngrok</figcaption>
</figure>
<p>得到 public url 后，需要将其配置到 github 项目的 webhook 中，打开
github 项目的地址，点击 setting 进行设置，设置如下所示，Payload URL
为通过 ngrok 得到的 public url 加上 <code>/github-webhook/</code>
路径，注意不能省略最后的斜杆，否则会出现 <a
href="https://github.com/spinnaker/spinnaker/issues/2067">403 No valid
crumb was included in the request</a> 的错误</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_github_webhook.png"
alt="webhook" />
<figcaption aria-hidden="true">webhook</figcaption>
</figure>
<p>点击 update webhook 后（第一次是 save）后，github 便会向 payload url
发送一个 POST 请求，就是在上上一张图最下方显示的 POST 请求。</p>
<p>这样当 github 的仓库有更新时就会自动触发 jenkins
进行自动构建，但是由于前一个构建任务会一直运行 http server
接受，因此会出现如下图的 already in progress 的问题，新的 build
会被挂起，直到前一个build 被终止（通过 <code>docker stop</code>)
关掉服务</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_rebuild_block.png"
alt="trigger build" />
<figcaption aria-hidden="true">trigger build</figcaption>
</figure>
<p>针对这个问题，这个 issue <a
href="https://github.com/jenkinsci/ghprb-plugin/issues/379">Pushing new
commit to existing PR does not stop previous build</a> 给出了通过配置
jenkins
的解决方法，但是我在我配置的环境中找不到这个设置选项，试了几遍后却依然找不到这个配置选项，所以就有了下面的自定义脚本进行自动构建。</p>
<p>而针对这个问题，令一种解决方法是在构建命令时只写
<code>docker build</code>, 每次都只是生成最新的 image；而
<code>docker run</code>
留给人工去启动，但是这样可能就显得不那么自动化了。</p>
<h3 id="自定义脚本进行自动构建">自定义脚本进行自动构建</h3>
<p>细想一下上面的触发构建过程，本地需要做的是 jenkins 接受 github
发过来的 POST 请求然后启动 <code>docker build</code> 和
<code>docker run</code>, 然后由于已经有 container
在跑了，因此无法决定启动新的构建过程。</p>
<p>那其实我们也可以<strong>自己建立一个 http server 接受 github 的 POST
请求，在接受到请求后通过 <code>docker stop</code> 停掉当前正在运行的
container 并开始新的构建过程</strong>，而借助前文描述的
Flask，我们可以很容易建立一个接受 POST 请求的 http
server，代码如下所示(见源文件 <code>hook_server.py</code>)</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, jsonify</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/github_webhook&#x27;</span>, methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rebuild</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;new commits to github repository&#x27;</span>)</span><br><span class="line">    <span class="comment">## subprocess.run can just deal with the first change</span></span><br><span class="line">    <span class="comment">## since it stuck in it, use popen instead</span></span><br><span class="line">    <span class="comment"># subprocess.run([&#x27;sh&#x27;, &#x27;build_and_run.sh&#x27;])</span></span><br><span class="line">    subprocess.Popen([<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;build_and_run.sh&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> jsonify(<span class="string">&#x27;got it&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run(debug=<span class="literal">True</span>, host=<span class="string">&#x27;0.0.0.0&#x27;</span>, port=<span class="number">8081</span>)</span><br></pre></td></tr></table></figure>
<p>为了保持一致性，这里的路径也选择为 <code>/github_webhook</code>,
为了简单起见，处理的函数只是接受请求，没有对 POST
请求做进一步的解析，接收到命令后通过 subprocess
新创建一个进程执行重新构建并运行 docker image 的脚本
<code>build_and_run.sh</code>, 注意这里要<strong>使用
<code>subprocess.Popen</code> 而不是
<code>subprocess.run</code></strong>, 因为 <code>subprocess.run</code>
要等命令执行返回才能继续往下执行，而我们启动的服务也是一个 http
server。如果使用 <code>subprocess.run</code>
只能在第一次的更新时触发自动构建，之后会一直保持在新创建的进程中而无法处理
github 发过来的新的请求，因此要使用 <code>subprocess.Popen</code>
避免这个问题，两者更详细的区别可参考 <a
href="https://stackoverflow.com/questions/39187886/what-is-the-difference-between-subprocess-popen-and-subprocess-run">What
is the difference between subprocess.popen and subprocess.run</a></p>
<p>上面执行的脚本 <code>build_and_run.sh</code> 的具体内容如下, 首先通过
git pull 更新代码，这里项目的代码的本地路径为
"/opt/src/DeployMachineLearningModel/"，然后判断当前是否有正在运行的
container，如果有则先 stop，然后再执行构建过程，在构建和运行之间通过
<code>docker image rm</code>（等价于 <code>docker rmi</code>）删除
docker 的 <code>&lt;none&gt;:&lt;none&gt;</code> images, 这些 images
也被称为 dangling images, 是被覆盖的原来的
image，会占用额外的磁盘空间，详细信息可参考 <a
href="https://www.projectatomic.io/blog/2015/07/what-are-docker-none-none-images/">What
are Docker <code>&lt;none&gt;:&lt;none&gt;</code> images?</a>。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># update code</span></span><br><span class="line">project_dir=<span class="string">&quot;/opt/src/DeployMachineLearningModel/&quot;</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$project_dir</span> &amp;&amp; git pull</span><br><span class="line"></span><br><span class="line"><span class="comment"># build and run with new code</span></span><br><span class="line">running_container=$(docker ps | grep deploy_ml_model | awk  -F <span class="string">&#x27; &#x27;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$running_container</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;container id not empty, stop it firstly&quot;</span></span><br><span class="line">    docker stop <span class="variable">$running_container</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;empty container id&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">docker build -t deploy_ml_model .</span><br><span class="line">docker image <span class="built_in">rm</span> -f $(docker images -f <span class="string">&quot;dangling=true&quot;</span> -q)</span><br><span class="line">docker run -p 8000:5000 deploy_ml_model</span><br></pre></td></tr></table></figure>
<p>同样需要通过 ngrok 映射本地的 http server 到一个 public url 并将
public url 添加到 github 项目的 webhook 中，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_ngrok_script.png"
alt="ngrok script" />
<figcaption aria-hidden="true">ngrok script</figcaption>
</figure>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_script_github_webhook.png"
alt="script github webhook" />
<figcaption aria-hidden="true">script github webhook</figcaption>
</figure>
<p>通过 <code>python hook_server.py</code> 运行脚本监听指定的 repository
是否有新的 commit，如果有，则触发运行 <code>build_and_run.sh</code>
脚本，其过程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_trigger_with_script.png"
alt="script trigger run" />
<figcaption aria-hidden="true">script trigger run</figcaption>
</figure>
<h2 id="kubernets">Kubernets</h2>
<p>通过上面的三个步骤，已经基本能够形成一个自动化的部署方案了，个人的自娱自乐基本也够了，但是上面还只是单点的服务，缺乏高可用性和伸缩性。</p>
<p>针对这一点，Docker 会经常与 Kubernets 配合使用，Kubernets
是专门为容器化应用的自动部署、拓展和管理的一个分布式系统。Kubernets
的前身是 Google 内部的系统 Brog，而 google 也参与了 Kubernets
的设计，Kubernets + 容器的部署方式应该会是未来的发展趋势，这里主要根据
<a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Learn
Kubernetes Basics</a> 总结 Kubernets
的一些经典的使用方式。包括应用的部署，拓展，滚动更新等。</p>
<p>由于实验环境需要多台机器，虽然 <a
href="https://kubernetes.io/docs/setup/minikube/">Minikube</a>
能够在单机上实现 Kubernets sigle-node 集群，但是根据 <a
href="https://kubernetes.io/docs/tasks/tools/install-minikube/">Install
Minikube</a> ，virtual box 中的虚拟机似乎不支持 VT-x or AMD-v
virtualization，因此，这里直接使用 <a
href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Learn
Kubernetes Basics</a> 提供的 shell 环境。</p>
<h3 id="基本架构">基本架构</h3>
<p>Kubernets cluster
是经典主从架构（master-nodes)，主（master）负责管理集群，如调度、拓展、更新等，从（nodes)则负责计算或提供服务，每个
node 通过 <strong>Kubelet</strong> 这个 agent 与 master
通信，除此之外，node 中还要有容器运行环境如 Docker 或
rkt。基本架构如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_structure.png"
alt="basic structure" />
<figcaption aria-hidden="true">basic structure</figcaption>
</figure>
<p>Kubernets 提供的命令行程序 <strong>Kubectl</strong>（注意与node的
Kubelet 区分）能够获取与集群通信，获取集群信息，部署应用等，如下图是通过
kubectl 获取通过 Minikube 启动的 Kubernets 集群的一些信息</p>
<ul>
<li>kubectl cluster-info：提供 web 界面查看应用的具体信息</li>
<li>kubectl nodes：显示所有的 nodes 的信息</li>
</ul>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_info.png"
alt="basic info" />
<figcaption aria-hidden="true">basic info</figcaption>
</figure>
<h3 id="部署deployment">部署(deployment)</h3>
<p>部署应用到 Kubernets 集群时，需要构建好要运行的 docker image
的路径，部署使用的也是命令行程序 kubectl，命令是
<code>kubectl run NAME --image=image_url</code>, NAME
是指定的应用的名称，--image 则是指定的 image 的 url，通过
<code>kubectl get deployments</code>
可以看到当前部署的应用，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_deploy.png"
alt="deploy with run" />
<figcaption aria-hidden="true">deploy with run</figcaption>
</figure>
<p>在 Kubernets cluser
中启动了应用后，外部网络是无法直接访问这个应用的，这点跟 Docker
有点相似，需要做映射，但是为了调试的便利性，kubectl 提供了
<code>kubectl proxy</code>
这个命令，相当于把Cluster内部的地址映射到本地机器，启动之后可通过本机访问
Kubernets cluser 内部 的应用。如下图所示是访问上面启动的应用</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_proxy.png"
alt="kubectl proxy" />
<figcaption aria-hidden="true">kubectl proxy</figcaption>
</figure>
<h4 id="pods">Pods</h4>
<p><strong>上面通过 kubectl 进行部署后，Kubernets 会在 node 中创建了 Pod
来容纳 container，一个 node 中可能有多个 pod，Kubernetes 的 master
会根据 node 的资源情况在不同 node 中分配 pod</strong>；pod 是 container
和 其所包含的资源的机器，其定义如下，</p>
<blockquote>
<p>A Pod is a Kubernetes abstraction that represents a group of one or
more application <strong>containers</strong> (such as Docker or rkt),
and some <strong>shared resources</strong> for those containers. Those
resources include:</p>
<ul>
<li>Shared storage, as Volumes</li>
<li>Networking, as a unique cluster IP address</li>
<li>Information about how to run each container, such as the container
image version or specific ports to use</li>
</ul>
</blockquote>
<p><strong>Pod 相当于应用的“逻辑主机”</strong>，而 a group of containers
值得是一个应用中有若干个联系紧密的 container 协作，这些 containers
具有相同的IP。</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_pod.png"
alt="pod" />
<figcaption aria-hidden="true">pod</figcaption>
</figure>
<p>除了 <code>kubectl run</code>, kubectl 常用的命令一下这些</p>
<ul>
<li>kubectl get：列出当前系统的资源（pods、nodes等），后面跟着</li>
<li>kubectl describe：列出资源的详细信息</li>
</ul>
<p>如下是通过这两条命令获取前面部署的应用的 pod 信息</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_pod_info.png"
alt="pod info" />
<figcaption aria-hidden="true">pod info</figcaption>
</figure>
<p>下面的命令则是查看 pod 的日志信息在 pod 中的 container
执行命令，通过命令
<code>export POD_NAME=$(kubectl get pods -o go-template --template '&#123; &#123;range .items&#125; &#125;&#123; &#123;.metadata.name&#125;&#125;&#123; &#123;"\n"&#125;&#125;&#123; &#123;end&#125;&#125;')</code>
能够获取当前的 pod name</p>
<ul>
<li><code>kubectl logs $POD_NAME</code>：打印 pod 中的 container
的日志信息</li>
<li><strong><code>kubectl exec $POD_NAME</code>: 在 pod 中的 container
执行命令</strong></li>
</ul>
<p>下面首先通过命令获取了 pod 的名称，然后通过 pod
的名称查看其日志并执行命令，执行效果如下所示</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_pod_log_exec.png"
alt="log exec" />
<figcaption aria-hidden="true">log exec</figcaption>
</figure>
<h4 id="service">Service</h4>
<p>Service 可以说是比 Pod 更高一级的概念，假设部署某个应用时指定其
replicas 的数量是 3，那么就会有 3 个相互独立的 pods，每个 pod 都有自己的
ip，，而 service 就是这些 pods 的集合。Service 管理着这些 pod
的失败重启等，从而向上提供 Pod 的抽象；service 的概念如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_service.png"
alt="service" />
<figcaption aria-hidden="true">service</figcaption>
</figure>
<p>关于 service 的定义如下</p>
<blockquote>
<p>A Service in Kubernetes is an abstraction which defines a logical set
of <strong>Pods</strong> and a <strong>policy</strong> by which to
access them</p>
</blockquote>
<p>除了 pods，service 中还有一项是 policy，指的是让 cluster 内部的 pod
供外界进行访问的方式，service 可设置的访问方式有下面四种</p>
<blockquote>
<ol type="1">
<li><strong>ClusterIP</strong> (default) - Exposes the Service on an
internal IP in the cluster. This type makes the Service only reachable
from within the cluster.</li>
<li><strong>NodePort</strong> - Exposes the Service on the same port of
each selected Node in the cluster using NAT. Makes a Service accessible
from outside the cluster using
<code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code>. Superset of
ClusterIP.</li>
<li><strong>LoadBalancer</strong> - Creates an external load balancer in
the current cloud (if supported) and assigns a fixed, external IP to the
Service. Superset of NodePort.</li>
<li><strong>ExternalName</strong> - Exposes the Service using an
arbitrary name (specified by externalName in the spec) by returning a
CNAME record with the name. No proxy is used. This type requires v1.7 or
higher of kube-dns.</li>
</ol>
</blockquote>
<p>通过 <code>kubectl expose</code> 能够让集群内部的 service
供外界访问，如下指定的访问方式是 <code>NodePort</code>, kubernets
默认会启动一个 keubernets 服务，就是第一条
<code>kubectl get services</code> 所显示的内容, 而经过
<code>kubectl expose</code> 的服务也会出现在其中，内部端口 8080
被映射为了外部的 32066 端口，通过外部ip（命令中的 minikube ip） 和 32066
端口便能访问内部的服务。</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_exopse_service.png"
alt="expose" />
<figcaption aria-hidden="true">expose</figcaption>
</figure>
<p>Service 通过 <a
href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">Labels
和 Selectors</a> 来区分同一个 service 中的不同 pod，label 就是一系列的
key-value 对，<strong>label
可结合具体的应用场景进行使用，如区分开发、测试和生产环境的
pod；区分同一个 pod 的不同版本等。</strong></p>
<p>部署时每个 pod 会被自动分配一个 label；通过
<code>kubectl describe deployment</code> 查看其对应的 label，也可以在
<code>kubectl get</code> 查看 pod 或 services 的信息时通过
<code>-l</code> 参数指定具体的 pod 或 service，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_pod_label.png"
alt="see label" />
<figcaption aria-hidden="true">see label</figcaption>
</figure>
<p>通过 <code>kubectl label</code> 可更改 pod 的 label，如下图所示</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_change_pod_label.png"
alt="change label" />
<figcaption aria-hidden="true">change label</figcaption>
</figure>
<p>可以根据 label 删除 service，此时虽然外部无法访问 pod，但是集群内部的
pod 仍然在运行，如下图所示</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_delete_service.png"
alt="delete service" />
<figcaption aria-hidden="true">delete service</figcaption>
</figure>
<h3 id="伸缩性scaling">伸缩性(scaling)</h3>
<p>伸缩性就是改变运行同一个 image 的 pods 的数量，如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_scale.png"
alt="pod" />
<figcaption aria-hidden="true">pod</figcaption>
</figure>
<p>可以通过 <code>kubectl scale</code> 命令指定 replica 的数量，也可以<a
href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">自动伸缩</a>，如下图所示是将原来只有一个
pod 的 deployment 拓展到 4 个 pod， 从
<code>kubectl get deployments</code> 可以看到当前 deployment 可用的 pod
的数量</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_scale_pods.png"
alt="scale pod" />
<figcaption aria-hidden="true">scale pod</figcaption>
</figure>
<p>而有了多个 pod, service 就要决定如何分配访问这些 pods
的流量，上面提到的 service 设置的访问方式 LoadBalancer
就是在这里使用(需要注意的是 NodePort 和 LoadBalancer
是可以共存)，通过下面访问多次的结果，可以看到每次访问的 pod
都不一样，从而实现了负载均衡</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_load_balance.png"
alt="load balance" />
<figcaption aria-hidden="true">load balance</figcaption>
</figure>
<h3 id="滚动更新rolling-updates">滚动更新(rolling updates)</h3>
<p>有了多个 pods，在更新 images 时便可以进行 rolling
update，即不是一次性地 stop 所有 pods 然后同时进行更新，而是先停掉部分的
pods，然后进行更新，并根据这个方法更新所有的 pods。如下图所示</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_rolling_update.png"
alt="rolling update" />
<figcaption aria-hidden="true">rolling update</figcaption>
</figure>
<p>这样的好处是在更新时不会让服务停止，如下图所示是更新前 pod
的一些信息，可以看到此时 image 的版本均为 v1</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_before_update.png"
alt="before update" />
<figcaption aria-hidden="true">before update</figcaption>
</figure>
<p>下面通过 <code>kubectl set</code> 更新上图所示的 deployment，使用了
v2 版本的 image，在 <code>kubectl set</code> 后，可以看到原来的 pod 处于
terminating 的状态，且多了四个新的 pod（可通过 AGE 区分），随着 update
完成，只有新的 pods 在运行，image 版本均变为了 v2，通过
<code>kubectl rollout status</code> 可以查看更新的情况。</p>
<figure>
<img
src="https://wulc.me/imgs/deploy_ml_model_kubernets_after_update.png"
alt="after update" />
<figcaption aria-hidden="true">after update</figcaption>
</figure>
<p>除此之外，
Kubernets中的每次更新都有版本记录，可进行回滚，如下图更新了一个不存在的
image，从 <code>kubectl get pods</code> 可以看到新的 pod 的状态是
ErrImagePull，通过 <code>kubectl rollout undo</code>
即可进行版本的回滚，最后所有 pods 的状态均恢复正常，image 版本均为
v2，如果再进行一次 <code>kubectl rollout undo</code>，那么 image
版本就变为 v1 了。</p>
<figure>
<img src="https://wulc.me/imgs/deploy_ml_model_kubernets_rollback.png"
alt="rollback" />
<figcaption aria-hidden="true">rollback</figcaption>
</figure>
<h2 id="总结">总结</h2>
<p>本文主要介绍了部署机器学习模型的一种方式，通过 Flask，Docker，Jenkins
和 Kubernets 共同构建。Flask 负责加载模型并提供 RESTful api，Docker
负责把程序及其依赖的环境打包成镜像，Jenkins
则可以在代码仓库有更新时触发自动构建，生成最新的
image，本文也通过自定义脚本的方式来实现了这一简单功能，但是 Jenkins
是一个功能非常丰富的工具，在项目更大更复杂时，采用 Jenkins
会更加方便。</p>
<p>通过 Flask，Docker 和 Jenkins
可以实现基本的自动化部署，但是此时的服务是单点的，不具备容灾性和伸缩性，通过
Kubernets 则可以较好地解决这个问题，只需要提供打包好的镜像，Kubernets
便能够提供伸缩性服务，滚动更新，回滚等操作。</p>
]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 python 发送邮件提醒网站的新评论</title>
    <url>/2016/01/17/%E9%80%9A%E8%BF%87%20python%20%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E6%8F%90%E9%86%92%E7%BD%91%E7%AB%99%E7%9A%84%E6%96%B0%E8%AF%84%E8%AE%BA/</url>
    <content><![CDATA[<p>这篇文章是当时在新浪云上搭建博客的时候写的，后来因为新浪云收费了，把网站迁移到了github上。这里还是把文章贴出来，做个记录。</p>
<p>最近在写本站的评论提醒功能的时候，需要通过 python
发送邮件提醒具体哪些文章有了新评论，采用邮件的方式便于在特定时间处理所有的评论，比如说在第二天早上7点检查网站昨天是否有新的评论，假如有就会发送邮件显示那些有新评论的文章。</p>
<span id="more"></span>
<p>实现思路如下：<strong>先检查数据库中是否有新的评论，假如有新的评论就发送邮件，否则不发送。</strong></p>
<p>如何检查新评论？在存储评论的表中有一个字段表示添加该评论的时间（datetime类型），利用这个字段能够在今天判断昨天是否有新的评论，现假设评论表为<code>comment</code>,表示评论添加时间的字段为<code>created_date</code>,采用的SQL语句如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> comment  <span class="keyword">where</span> <span class="type">date</span>(created_date) <span class="operator">=</span>( <span class="keyword">select</span> date_sub(curdate(),<span class="type">interval</span> <span class="number">1</span> <span class="keyword">day</span>)</span><br></pre></td></tr></table></figure>
<p>假如查询的语句不为空，那么说明有了新的评论，可以将关于评论的具体内容以邮件形式发送给管理员。下面是python发送邮件的实现方法之一：</p>
<p>PS：虽然新浪云提供了用于发送邮件的Mail服务，当时对于普通用户每天好像会限定发送的次数，而且最严重的问题是<strong>邮件的延迟非常严重</strong>，建议还是使用smtplib模块。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> smtplib <span class="comment">#用于发送邮件</span></span><br><span class="line"><span class="keyword">import</span> string  <span class="comment">#用于将要发送的内容格式化成邮件标准格式</span></span><br><span class="line"><span class="keyword">from</span> email.mime.text <span class="keyword">import</span> MIMEText</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_email</span>(<span class="params">content</span>): <span class="comment">#content为发送邮件的正文内容，这里只涉及到文本</span></span><br><span class="line">    HOST=<span class="string">&quot;smtp.XXX.com&quot;</span><span class="comment">#发送邮件smtp服务器</span></span><br><span class="line">    FROM=<span class="string">&quot;XXX@XXX.com&quot;</span> <span class="comment">#发送邮件的邮箱</span></span><br><span class="line">    PASSWORD=<span class="string">&quot;&quot;</span>        <span class="comment">#发送邮件的邮箱的密码</span></span><br><span class="line">    TO=<span class="string">&quot;XXX@XXX.com&quot;</span>   <span class="comment">#接收邮件的邮箱</span></span><br><span class="line">    SUBJECT=<span class="string">&quot;New Comments on your Website&quot;</span> <span class="comment">#邮件主题</span></span><br><span class="line">    </span><br><span class="line">    msg=MIMEText(content,<span class="string">&#x27;plain&#x27;</span>,<span class="string">&#x27;utf-8&#x27;</span>)  <span class="comment">#邮件内容及编码方式</span></span><br><span class="line">    msg[<span class="string">&#x27;Subject&#x27;</span>]=SUBJECT</span><br><span class="line">    msg[<span class="string">&#x27;From&#x27;</span>]=FROM</span><br><span class="line">    msg[<span class="string">&#x27;To&#x27;</span>]=TO</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        s=smtplib.SMTP()</span><br><span class="line">        s.connect(HOST)</span><br><span class="line">        s.login(FROM,PASSWORD)</span><br><span class="line">        s.sendmail(FROM,[TO],msg.as_string())</span><br><span class="line">        s.quit()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> EXception,e:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>下面提到的几点有助于更好地理解上面的代码</p>
<ol type="1">
<li><p>通过免费提供的邮箱（如163邮箱，新浪邮箱）发送邮件的过程是先将邮件发送到对应邮箱的smtp服务器，然后由smtp服务器将邮件帮你发送到你要发送的邮箱。一般来说，邮箱对应的服务器都跟其名称有关，如163邮箱对应的是smtp服务器是<code>smtp.163.com</code>,新浪邮箱对应的smtp服务器是<code>smtp.sina.com</code>；其他的邮箱相应可以从设置中找到。</p></li>
<li><p><code>smtplib</code>和<code>MIMEText</code>是python自带的库，不用另外安装，比较方便，其中smtplib负责发送邮件，MIMEText则负责将要发送的<strong>文本内容</strong>统一成邮件的标准模式，加入要加入一些附件，需要<code>MIMEMultipart</code>这个模块。</p></li>
</ol>
<p>需要注意的是<strong>发送邮件的邮箱需要开启smtp服务</strong>,一般能够在邮箱的设置中开启。因为有些有些邮箱是不开启这个功能的，比如说新浪邮箱。</p>
<p>发送邮件的效果图如下所示：</p>
<p><img src="https://wulc.me/imgs/2016-01-17_200124.png" /></p>
<p>能够发送邮件后，要考虑的问题就是如何自动化执行了，总不能每天手动执行一遍脚本吧，在Linux下可通过crontab来设置计划任务，同样新浪云也提供了类似的cron的服务，这样便可在每天的早上检查昨天是否有新评论在决定是否要发送邮件了。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 sklearn 进行大规模机器学习</title>
    <url>/2017/08/08/%E9%80%9A%E8%BF%87%20sklearn%20%E8%BF%9B%E8%A1%8C%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>sklearn 是 python
中一个非常著名的机器学习库，但是一般都是在单机上使用而不支持分布式计算，因此往往跟大规模的机器学习扯不上关系。这里通过
sklearn
进行的大规模机器学习指的也不是分布式机器学习，而是指<strong>当数据量比内存要大时怎么通过
sklearn 进行机器学习，更准确来说是 out-of-core learning</strong>，
这里涉及到的一个核心思想是<strong>将数据转化为流式输入，然后通过 SGD
更新模型的参数，</strong>当然其中还涉及到一些其他的细节和trick，下面会详细描述。</p>
<span id="more"></span>
<h2 id="out-of-core-learning">out-of-core learning</h2>
<p>上面的问题也称为 out-of-core learning，
指的是机器的内存无法容纳训练的数据集，
但是硬盘可容纳这些数据，这种情况在数据集较大的时候比较常见，一般有两种解决方法：<strong>sampling
与 mini-batch learning</strong>。</p>
<p>第一种方法是 sampling（采样），采样
可以针对样本数目或样本特征，能够减少样本的数量或者feature的数目，两者均能减小整个数据集所占内存，但是采样无可避免地会丢失掉原来数据集中的一些信息（当数据没有冗余的时候），这会导致
variance inflation
问题，也就是进行若干次采样，每次训练得出的模型之间差异都比较大。用
bias-variance 来解释就是出现了high
variance，原因是每次采样得到的数据中都有随机噪声，而模型拟合了这些没有规律的噪声，从而导致了每次得到的模型都不一样。</p>
<p><strong>解决采样带来的 high-variance
问题，可以通过训练多个采样模型，然后将其进行集成，采用这种思路典型的方法有
bagging。</strong></p>
<p>第二种方法是 mini-batch learning，这种方法不同于 sampling，
利用了全部的数据，
只是每次只用一部分样本（可以是一个样本，也可以是多个样本）来训练模型，通过增加迭代的次数可以近似用全部数据集训练的效果，这种方法需要训练的算法的支持，SGD
恰好就能够提供这种模式的训练，因此 SGD
是这种模式训练的核心。下面也主要针对这种方法进行讲述。</p>
<p>通过 SGD
进行训练时，需要流式（streaming）读取训练样本，同时注意的是要将样本的顺序随机打乱,以消除样本顺序带来的信息，如先用正样本训练，再用负样本训练，模型会偏向于将样本预测为负。下面主要讲述如何将磁盘上的数据流式化并送入到模型中进行训练。</p>
<h2 id="流式读取数据">流式读取数据</h2>
<h3 id="文件读取">文件读取</h3>
<p>这里读取的数据的格式是每行存储一个样本。最简单的方法就是通过 python
读取文件的 <code>readline</code> 方法实现</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(source_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    line = f.readline()</span><br><span class="line">    <span class="keyword">while</span> line:</span><br><span class="line">        <span class="comment"># data processing</span></span><br><span class="line">        <span class="comment"># training</span></span><br><span class="line">        line = f.readline()</span><br></pre></td></tr></table></figure>
<p>而往往训练文件都是 csv 格式的，此时需要丢弃第一行，同时可通过
<code>csv</code>
模块进行读取，下面以这个数据文件为例说明：https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">SEP = <span class="string">&#x27;,&#x27;</span> </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(source_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    iterator = csv.reader(f, delimiter = SEP)</span><br><span class="line">    <span class="keyword">for</span> n, row <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterator):</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">            header = row</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># data processing</span></span><br><span class="line">            <span class="comment"># training</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Total rows: %i&#x27;</span> % (n+<span class="number">1</span>))</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Header: %s&#x27;</span> % <span class="string">&#x27;, &#x27;</span>.join(header))</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Sample values: %s&#x27;</span> % <span class="string">&#x27;, &#x27;</span>.join(row))</span><br></pre></td></tr></table></figure>
<p>输出为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Total rows: 17380</span><br><span class="line">Header: instant, dteday, season, yr, mnth, hr, holiday, weekday, workingday, weathersit, temp, atemp, hum, windspeed, casual, registered, cnt</span><br><span class="line">Sample values: 17379, 2012-12-31, 1, 1, 12, 23, 0, 1, 1, 1, 0.26, 0.2727, 0.65, 0.1343, 12, 37, 49</span><br></pre></td></tr></table></figure>
<p>在上面的例子中，每个样本是就是一个 row（list 类型），样本的 feature
只能通过 <code>row[index]</code> 方式获取，假如要通过
<code>header</code> 中的名称获取， 可以修改上面获取
<code>iterator</code> 的代码，用
<code>csv.DictReader(f, delimiter = SEP)</code> 来获取
<code>iterator</code>，此时得到的 <code>row</code> 会是一个
dictionary，key 为 <code>header</code> 中的列名，value 为对应的值;
对应的代码为</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(source_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> R:</span><br><span class="line">    iterator = csv.DictReader(R, delimiter=SEP)</span><br><span class="line">    <span class="keyword">for</span> n, row <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterator):</span><br><span class="line">        <span class="comment"># data processing</span></span><br><span class="line">        <span class="comment"># training</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Total rows: %i&#x27;</span> % (n+<span class="number">1</span>))</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Sample values: %s&#x27;</span> % row)</span><br></pre></td></tr></table></figure>
<p>输出为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Total rows: 17379</span><br><span class="line">Sample values: &#123;&#x27;mnth&#x27;: &#x27;12&#x27;, &#x27;cnt&#x27;: &#x27;49&#x27;, &#x27;holiday&#x27;: &#x27;0&#x27;, &#x27;instant&#x27;: &#x27;17379&#x27;, &#x27;temp&#x27;: &#x27;0.26&#x27;, &#x27;dteday&#x27;: &#x27;2012-12-31&#x27;, &#x27;hr&#x27;: &#x27;23&#x27;, &#x27;season&#x27;: &#x27;1&#x27;, &#x27;registered&#x27;: &#x27;37&#x27;, &#x27;windspeed&#x27;: &#x27;0.1343&#x27;, &#x27;atemp&#x27;: &#x27;0.2727&#x27;, &#x27;workingday&#x27;: &#x27;1&#x27;, &#x27;weathersit&#x27;: &#x27;1&#x27;, &#x27;weekday&#x27;: &#x27;1&#x27;, &#x27;hum&#x27;: &#x27;0.65&#x27;, &#x27;yr&#x27;: &#x27;1&#x27;, &#x27;casual&#x27;: &#x27;12&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>除了通过 <code>csv</code> 模块进行读取，还可以通过
<code>pandas</code> 模块进行读取，pandas 模块可以说是处理 csv
文件的神器，<code>csv</code> 每次只能读取一条数据，而
<code>pandas</code> 可以指定每次读取的数据的数目，如下所示</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">CHUNK_SIZE = <span class="number">1000</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(source_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> R:</span><br><span class="line">    iterator = pd.read_csv(R, chunksize=CHUNK_SIZE) </span><br><span class="line">    <span class="keyword">for</span> n, data_chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterator):</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;Size of uploaded chunk: %i instances, %i features&#x27;</span> % (data_chunk.shape))</span><br><span class="line">        <span class="comment"># data processing</span></span><br><span class="line">        <span class="comment"># training</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Sample values: \n%s&#x27;</span> % <span class="built_in">str</span>(data_chunk.iloc[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<p>对应的输出为 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 1000 instances, 17 features</span><br><span class="line">Size of uploaded chunk: 379 instances, 17 features</span><br><span class="line">Sample values: </span><br><span class="line">instant            17001</span><br><span class="line">dteday        2012-12-16</span><br><span class="line">season                 4</span><br><span class="line">yr                     1</span><br><span class="line">mnth                  12</span><br><span class="line">hr                     3</span><br><span class="line">holiday                0</span><br><span class="line">weekday                0</span><br><span class="line">workingday             0</span><br><span class="line">weathersit             2</span><br><span class="line">temp                0.34</span><br><span class="line">atemp             0.3333</span><br><span class="line">hum                 0.87</span><br><span class="line">windspeed          0.194</span><br><span class="line">casual                 1</span><br><span class="line">registered            37</span><br><span class="line">cnt                   38</span><br><span class="line">Name: 17000, dtype: object</span><br></pre></td></tr></table></figure></p>
<h3 id="数据库读取">数据库读取</h3>
<p>上面的是直接从文件中读取的数据，但是数据也可能存在数据库中，因为通过数据库不经能够有效进行增删查改等操作，而且通过
<a href="https://en.wikipedia.org/wiki/Database_normalization">Database
Normalization</a> 能够在不丢失信息的基础上减少数据冗余性。</p>
<p>假设上面的数据已经存储在 <code>SQLite</code>
数据库中，则流式读取的方法如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">DB_NAME = <span class="string">&#x27;bikesharing.sqlite&#x27;</span></span><br><span class="line">CHUNK_SIZE = <span class="number">2500</span></span><br><span class="line"></span><br><span class="line">conn = sqlite3.connect(DB_NAME)</span><br><span class="line">conn.text_factory = <span class="built_in">str</span>  <span class="comment"># allows utf-8 data to be stored     </span></span><br><span class="line">sql = <span class="string">&quot;SELECT H.*, D.cnt AS day_cnt FROM hour AS H INNER JOIN day as D ON (H.dteday = D.dteday)&quot;</span></span><br><span class="line">DB_stream = pd.io.sql.read_sql(sql, conn, chunksize=CHUNK_SIZE)</span><br><span class="line"><span class="keyword">for</span> j,data_chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(DB_stream):</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Chunk %i -&#x27;</span> % (j+<span class="number">1</span>)),</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Size of uploaded chunk: %i istances, %i features&#x27;</span> % (data_chunk.shape))</span><br><span class="line">    <span class="comment"># data processing</span></span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>输出为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Chunk 1 - Size of uploaded chunk: 2500 istances, 18 features</span><br><span class="line">Chunk 2 - Size of uploaded chunk: 2500 istances, 18 features</span><br><span class="line">Chunk 3 - Size of uploaded chunk: 2500 istances, 18 features</span><br><span class="line">Chunk 4 - Size of uploaded chunk: 2500 istances, 18 features</span><br><span class="line">Chunk 5 - Size of uploaded chunk: 2500 istances, 18 features</span><br><span class="line">Chunk 6 - Size of uploaded chunk: 2500 istances, 18 features</span><br><span class="line">Chunk 7 - Size of uploaded chunk: 2379 istances, 18 features</span><br></pre></td></tr></table></figure>
<h3 id="样本的读取顺序">样本的读取顺序</h3>
<p>上面简单提到了通过 SGD
训练模型的时候，需要注意样本的顺序必须要是随机打乱的。</p>
<p><strong>假如给定一批样本，然后用整批的样本来更新，那么就不存在样本的读取顺序问题；但是由于像
SGD 这种 online learning
的训练模式，越是后面才读取的样本，模型一般会拟合得更好，因为这是模型最近看到了这些样本且针对这些样本进行了调整。</strong></p>
<p>这样的特性有其好处，如处理时间序列的数据时，由于对最近时间的数据拟合得更好，因此不会受到时间太久远的数据的影响，但是在更多的情况下，这种由样本顺序带来的是有弊无益的，如上面提到的先用全部的正样本训练，再用全部的负样本训练。因此有必要对数据先进行
shuffle ，然后再通过 SGD 来进行训练。</p>
<p>假如内存能够容纳这些数据， 那么所有的数据可以在内存中进行一次
shuffle；假如无法容纳，则可以将整个大的数据文件分为若干个小的文件，分别进行
shuffle ，然后再拼接起来，拼接时也不按照原来的顺序，而是进行 shuffle
后再拼接， 下面是这两种 shuffle 方法的实现代码。</p>
<p>在内存中进行 shuffle 之前可以通过 <code>zlib</code>
对样本先进行压缩，从而让内存可以容纳更多的样本，实现代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> zlib</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ram_shuffle</span>(<span class="params">filename_in, filename_out, header=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename_in, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        zlines = [zlib.compress(line, <span class="number">9</span>) <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line">        <span class="keyword">if</span> header:</span><br><span class="line">            first_row = zlines.pop(<span class="number">0</span>)</span><br><span class="line">    shuffle(zlines)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename_out, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">if</span> header:</span><br><span class="line">            f.write(zlib.decompress(first_row))</span><br><span class="line">        <span class="keyword">for</span> zline <span class="keyword">in</span> zlines:</span><br><span class="line">            f.write(zlib.decompress(zline))</span><br></pre></td></tr></table></figure>
<p>基于磁盘的 shuffle 方法首先将整个文件划分为若干个小文件，然后再进行
shuffle， 为了能够实现整个数据集更彻底的 shuffle
，可以将上面的过程重复几遍，同时每次都改变划分的文件的大小，实现的代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disk_shuffle</span>(<span class="params">filename_in, filename_out, header=<span class="literal">True</span>, iterations = <span class="number">3</span>, CHUNK_SIZE = <span class="number">2500</span>, SEP=<span class="string">&#x27;,&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename_in, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> R:</span><br><span class="line">            iterator = pd.read_csv(R, chunksize=CHUNK_SIZE) </span><br><span class="line">            <span class="keyword">for</span> n, df <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterator):</span><br><span class="line">                <span class="keyword">if</span> n==<span class="number">0</span> <span class="keyword">and</span> header:</span><br><span class="line">                    header_cols =SEP.join(df.columns)+<span class="string">&#x27;\n&#x27;</span></span><br><span class="line">                df.iloc[np.random.permutation(<span class="built_in">len</span>(df))].to_csv(<span class="built_in">str</span>(n)+<span class="string">&#x27;_chunk.csv&#x27;</span>, index=<span class="literal">False</span>, header=<span class="literal">False</span>, sep=SEP)</span><br><span class="line">        ordering = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>,n+<span class="number">1</span>))</span><br><span class="line">        shuffle(ordering)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename_out, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> W:</span><br><span class="line">            <span class="keyword">if</span> header:</span><br><span class="line">                W.write(header_cols)</span><br><span class="line">            <span class="keyword">for</span> f <span class="keyword">in</span> ordering:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(<span class="built_in">str</span>(f)+<span class="string">&#x27;_chunk.csv&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> R:</span><br><span class="line">                    <span class="keyword">for</span> line <span class="keyword">in</span> R:</span><br><span class="line">                        W.write(line)</span><br><span class="line">                os.remove(<span class="built_in">str</span>(f)+<span class="string">&#x27;_chunk.csv&#x27;</span>)</span><br><span class="line">        filename_in = filename_out</span><br><span class="line">        CHUNK_SIZE = <span class="built_in">int</span>(CHUNK_SIZE / <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h2 id="sklearn-中的-sgd">sklearn 中的 SGD</h2>
<p>通过前面的步骤可以将数据以流式输入，下面接着就是要通过 SGD
进行训练，在 sklearn 中，
<code>sklearn.linear_model.SGDClassifier</code> 和
<code>sklearn.linear_model.SGDRegressor</code> 均是通过 SGD
实现，只是一个用于分类，一个用于回归。下面以
<code>sklearn.linear_model.SGDClassifier</code>
为例进行简单说明，更详细的内容可参考其<a
href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html">官方文档</a>。这里仅对其几个参数和方法进行简单的讲解。</p>
<p>需要注意的参数有：</p>
<ul>
<li><code>loss</code> : 表示具体的分类器，可选的值为
<strong>hinge、log、modified_huber、squared_hinge、perceptron</strong>；如
hinge 表示 SVM 分类器，log 表示logistics regression等</li>
<li><code>penalty</code>：正则项，用于防止过拟合(默认为 L2 正则项)</li>
<li><code>learning_rate</code>:
表示选择哪种学习速率方案，共有三种：<strong>constant、optimal、invscaling</strong>，各种详细含义可参考官方文档</li>
</ul>
<p>需要注意的方法主要就是 <code>partial_fit(X, y, classes)</code>,
<code>X</code> 和 <code>y</code> 是每次流式输入的数据，而
<code>classes</code> 则是具体的分类数目, 若 <code>classes</code>
数目大于2，则会根据 <code>one-vs-rest</code> 规则训练多个分类器。</p>
<p>需要注意的是 <code>partial_fit</code>
只会对数据遍历一次，需要自己显式指定遍历的次数，如下是使用 sklearn 中的
<code>SGDClassfier</code> 的一个简单例子。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">CHUNK_SIZE = <span class="number">1000</span></span><br><span class="line">n_iter = <span class="number">10</span>  <span class="comment"># number of iteration over the whole dataset</span></span><br><span class="line">n_class = <span class="number">7</span></span><br><span class="line"></span><br><span class="line">model = linear_model.SGDClassifier(loss = <span class="string">&#x27;hinge&#x27;</span>, penalty =<span class="string">&#x27;l1&#x27;</span>,)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_iter): </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(source_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> R:</span><br><span class="line">        iterator = pd.read_csv(R, chunksize=CHUNK_SIZE) </span><br><span class="line">        <span class="keyword">for</span> n, data_chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterator):</span><br><span class="line">            model.partial_fit(data_chunk.x, data_chunk.y, classes = np.array(<span class="built_in">range</span>(<span class="number">0</span>, n_class)))</span><br></pre></td></tr></table></figure>
<h2 id="流式数据中的特征工程">流式数据中的特征工程</h2>
<h3 id="feature-scaling">feature scaling</h3>
<p>对于 SGD 算法，特征的 scaling
会影响其优化过程，也就是只有将特征标准化（均值为0，方差为1）或归一化（处于
[0,1]
内）才能加快算法收敛的速度，但是由于数据不能一次读入内存，如果需要标准化或归一化，需要对数据遍历
2
次，第一次遍历是为了求特征的均值和方差（标准化需要）或最大最小值（归一化需要），第二次遍历便可以用上面的均值、方差、最大值，最小值等值进行标准化。</p>
<p>由于数据是流式输入的，求解均值、最大值、最小值都没有什么问题，但是求解方差的公式为(
<span class="math inline">\(\mu\)</span> 为均值）</p>
<p><span class="math display">\[\sigma^2 = \frac{1}{n}
\sum_x(x-\mu)^2\]</span></p>
<p>只有知道均值才能求解， 这意味着只有遍历一次求得 <span
class="math inline">\(\mu\)</span> 后才能求 <span
class="math inline">\(\sigma^2\)</span>,
这无疑会增加求解的时间，下面对这个公式进行简单的变换，使得 <span
class="math inline">\(\mu\)</span> 和 <span
class="math inline">\(\sigma^2\)</span> 能够同时求出</p>
<p>假如当前有 <span class="math inline">\(n\)</span> 个样本，当前的均值
<span class="math inline">\(\mu&#39;\)</span> 可以简单求出，而当前的方差
<span class="math inline">\(\sigma&#39;^2\)</span> 可通以下公式求解</p>
<p><span class="math display">\[\sigma&#39;^2 = \frac{1}{n} \sum\_x(x^2
- 2x\mu&#39; + \mu&#39;^2) = \frac{1}{n} \sum\_x(x^2) -
\frac{1}{n}(2n\mu&#39;^2 - n\mu&#39;^2) = \frac{1}{n} \sum\_x(x^2) -
\mu&#39;^2\]</span></p>
<p>通过这个公式，可以遍历一次便求出任意个样本的方差，下面通过这个公式求解均值和方差随着样本数量变化而变化的情况，并比较进行
shuffle 前后两者在均值和方差上的区别。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># calculate the running mean,standard deviation, and range reporting the final result</span></span><br><span class="line"><span class="keyword">import</span> os, csv</span><br><span class="line">raw_source = <span class="string">&#x27;bikesharing/hour.csv&#x27;</span> <span class="comment"># unshuffle</span></span><br><span class="line">shuffle_source = <span class="string">&#x27;bikesharing/shuffled_hour.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">running_statistic</span>(<span class="params">source</span>):</span><br><span class="line">    SEP=<span class="string">&#x27;,&#x27;</span></span><br><span class="line">    running_mean = <span class="built_in">list</span>()</span><br><span class="line">    running_std = <span class="built_in">list</span>()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(local_path+<span class="string">&#x27;/&#x27;</span>+source, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> R:</span><br><span class="line">        iterator = csv.DictReader(R, delimiter=SEP)</span><br><span class="line">        x = <span class="number">0.0</span></span><br><span class="line">        x_squared = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> n, row <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterator):</span><br><span class="line">            temp = <span class="built_in">float</span>(row[<span class="string">&#x27;temp&#x27;</span>])</span><br><span class="line">            <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">                max_x, min_x = temp, temp</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                max_x, min_x = <span class="built_in">max</span>(temp, max_x),<span class="built_in">min</span>(temp, min_x)</span><br><span class="line">            x += temp</span><br><span class="line">            x_squared += temp**<span class="number">2</span></span><br><span class="line">            running_mean.append(x / (n+<span class="number">1</span>))</span><br><span class="line">            running_std.append(((x_squared - (x**<span class="number">2</span>)/(n+<span class="number">1</span>))/(n+<span class="number">1</span>))**<span class="number">0.5</span>)</span><br><span class="line">            <span class="comment"># DATA PROCESSING placeholder</span></span><br><span class="line">            <span class="comment"># MACHINE LEARNING placeholder</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;Total rows: %i&#x27;</span> % (n+<span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;Feature \&#x27;temp\&#x27;: mean=%0.3f, max=%0.3f, min=%0.3f,sd=%0.3f&#x27;</span> \</span><br><span class="line">               % (running_mean[-<span class="number">1</span>], max_x, min_x, running_std[-<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">return</span> running_mean, running_std</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;===========raw data file===========&#x27;</span></span><br><span class="line">raw_running_mean, raw_running_std = running_statistic(raw_source)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;===========shuffle data file===========&#x27;</span></span><br><span class="line">shuffle_running_mean, shuffle_running_std = running_statistic(shuffle_source)</span><br></pre></td></tr></table></figure>
<p>输出如下 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===========raw data file===========</span><br><span class="line">Total rows: 17379</span><br><span class="line">Feature &#x27;temp&#x27;: mean=0.497, max=1.000, min=0.020,sd=0.193</span><br><span class="line">===========shuffle data file===========</span><br><span class="line">Total rows: 17379</span><br><span class="line">Feature &#x27;temp&#x27;: mean=0.497, max=1.000, min=0.020,sd=0.193</span><br></pre></td></tr></table></figure></p>
<p>两者的统计数据一致，符合要求，下面再看看两者的均值和方差随着时间如何变化，也就是将上面得到的
<code>running_mean</code> 和 <code>running_std</code> 进行可视化</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># plot how such stats changed as data was streamed from disk</span></span><br><span class="line"><span class="comment"># get an idea about how many instances are required before getting a stable mean and standard deviation estimate</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">for</span> mean, std <span class="keyword">in</span> ((raw_running_mean, raw_running_std), (shuffle_running_mean, shuffle_running_std)):</span><br><span class="line">    plt.plot(mean,<span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">    plt.plot(std,<span class="string">&#x27;b-&#x27;</span>, label=<span class="string">&#x27;standard deviation&#x27;</span>)</span><br><span class="line">    plt.ylim(<span class="number">0.0</span>,<span class="number">0.6</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Number of training examples&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Value&#x27;</span>) </span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;lower right&#x27;</span>, numpoints= <span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># The difference in the two charts reminds us of the importance of randomizing the order of the observations. </span></span><br></pre></td></tr></table></figure>
<p>得到的结果如下</p>
<p>原始的文件 <img
src="https://wulc.me/imgs/image_1botg5pjo18qluja1gjrl46sc29.png"
alt="unshuffle" /></p>
<p>shuffle 后的文件 <img
src="https://wulc.me/imgs/image_1botg6tsg18e04d0vpvcip6q0m.png"
alt="shuffle" /></p>
<p>可以看到，经过 shuffle
后的数据的均值和方差很快就达到了稳定的状态，可以让 SGD
算法更快地收敛，这也从另一个角度验证了 shuffle 的必要性。</p>
<h3 id="hasing-trick">hasing trick</h3>
<p>对于 categorial feature， 往往要对其进行 one-hot 编码，但是进行
one-hot 编码需要知道这个 feature
所有可能的取值的数量，对于流式输入的数据，可以先遍历一遍数据得到
categorial feature 所有可能取值的数目。除此之外，还可以利用接下来要讲的
hashing trick 对categorical feature 进行 one-hot
编码，这种方法对只能遍历一遍的数据有效。</p>
<p>hahsing trick 利用了 hash
函数，通过hash后取模，将样本的值映射到预先定义好的固定长度的槽列中的某个槽中，这种方法需要对
categorical feature
的所有可能取值有大概的估计，而且可能会出现冲突的情况，但是如果对categorical
feature 的所有可能取值有较准确的估计时，冲突的概率会比较低。下面是利用
sklearn 中的 <code>HashingVectorizer</code> 进行这种编码的一个例子</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> HashingVectorizer</span><br><span class="line">h = HashingVectorizer(n_features=<span class="number">1000</span>, binary=<span class="literal">True</span>, norm=<span class="literal">None</span>)</span><br><span class="line">sparse_vector = h.transform([<span class="string">&#x27;A simple toy example will make clear how it works.&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(sparse_vector)</span><br></pre></td></tr></table></figure>
<p>输出如下 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(0, 61)	1.0</span><br><span class="line">(0, 271)	1.0</span><br><span class="line">(0, 287)	1.0</span><br><span class="line">(0, 452)	1.0</span><br><span class="line">(0, 462)	1.0</span><br><span class="line">(0, 539)	1.0</span><br><span class="line">(0, 605)	1.0</span><br><span class="line">(0, 726)	1.0</span><br><span class="line">(0, 918)	1.0</span><br></pre></td></tr></table></figure></p>
<p>这里定义的槽列的长度为1000，即假设字典中的单词数目为 1000，
然后将文本映射到这个槽列中，1 表示有这个单词，0表示没有。</p>
<h2 id="总结">总结</h2>
<p>本文主要介绍了如何进行 out-of-core
learning，主要思想就是将数据以流式方式读入，然后通过 SGD
算法进行更新，在读入数据之前，首先需要对数据进行 shuffle
操作，消除数据本来的顺序信息等，同时可以让样本的特征的方差和均值更快达到稳定状态。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>通过 word2vec 与 CNN/RNN 对动作序列建模</title>
    <url>/2018/01/15/%E9%80%9A%E8%BF%87%20word2vec%20%E4%B8%8E%20CNN-RNN%20%E5%AF%B9%E5%8A%A8%E4%BD%9C%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1/</url>
    <content><![CDATA[<p>本文主要讲述如何通过 word2vec 和 CNN/RNN
对动作序列建模，在最近的一个比赛中验证了这个思路，的确有一定效果，在二分类的准确率上能达到0.87.本文主要介绍这个方法的具体步骤，并以比赛和代码为例进行说明。</p>
<span id="more"></span>
<p>这里提到的比赛是目前正在进行的<a
href="http://www.dcjingsai.com/common/cmpt/%E7%B2%BE%E5%93%81%E6%97%85%E8%A1%8C%E6%9C%8D%E5%8A%A1%E6%88%90%E5%8D%95%E9%A2%84%E6%B5%8B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html">精品旅行服务成单预测</a>,
该比赛就是要根据用户的个人信息，行为信息和订单信息来预测用户的下一个订单是否是精品服务。本文提到的方法是仅利用用户的行为信息，主要的思路是：<strong>将每个动作通过
word2vec 转化为 embedding 表示，然后将动作序列转化为 embedding
序列并作为 CNN/RNN 的输入。</strong> 下面依次介绍通过 word2vec 获得动作
embedding，将 embedding
作为CNN的输入和将embedding作为RNN的输入这三部分内容。</p>
<h2 id="word2vec-获取动作-embedding">word2vec 获取动作 embedding</h2>
<p>word2vec
是一个很著名的无监督算法了，这个算法最初在NLP领域提出，可以通过词语间的关系构建词向量，进而通过词向量可获取词语的语义信息，如词语意思相近度等。而将
word2vec 应用到动作序列中，主要是受到了知乎上<a
href="https://www.zhihu.com/question/25269336/answer/49188284">这个答案</a>的启发。因为
word2vec
能够挖掘序列中各个元素之间的关系信息，这里如果将每个动作看成是一个单词，然后通过
word2vec 得出每个动作的 embedding 表示，那么这些 embedding
之间会存在一定的关联程度，再将动作序列转为 embedding 序列，作为 CNN 或
RNN 的输入便可挖掘整个序列的信息。</p>
<p>这里训练动作 embedding 的方法跟训练 word embedding
的方法一致，将每个户的每个动作看做一个单词、动作序列看做一篇文章即可。训练时采用的是
<code>gensim</code>, 训练的代码很简单，embedding 的维度设为 300,
<code>filter_texts</code>中每一行是一各用户的行为序列，行为之间用空格隔开。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line">vector_length = <span class="number">300</span></span><br><span class="line">model = word2vec.Word2Vec(filter_texts, size = vector_length, window=<span class="number">2</span>, workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>由于动作类型只有9种（1~9），也就是共有 9 个不同的单词，因此可将这 9
个动作的 embedding 存在一个 <code>np.ndarray</code> 中，然后作为后面
CNN/RNN 前的 embedding layer 的初始化权重。注意这里还添加了一个动作 0
，原因是 CNN
的输入要求长度一致，因此对于长度达不到要求长度的序列，需要在前面补
0（补其他的不是已知的动作也可以）。代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">embedding_matrix = np.zeros((<span class="number">10</span>, vector_length))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">    embedding_matrix[i] = model.wv[<span class="built_in">str</span>(i)]</span><br></pre></td></tr></table></figure>
<h2 id="cnn-对动作序列建模">CNN 对动作序列建模</h2>
<p>CNN 采用的模型是经典的 TextCNN, 模型结构如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1c4hpceut1nt04dsh2e1cj4m1g9.png"
alt="TextCNN" />
<figcaption aria-hidden="true">TextCNN</figcaption>
</figure>
<p>这里通过 Keras 实现，具体代码如下</p>
<p>首先需要处理序列，使得所有序列长度一致，这里选择的长度是
50，具体代码如下，代码中的 <code>x_original</code> 是一个
<code>list[list[int]]</code>
类型，表示所有用户的所有动作序列，对于长度比 <code>max_len</code>
长的，从后往前截取50个最近时间的动作，而短的则在前面补0.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line">max_len = <span class="number">50</span></span><br><span class="line">x_train = sequence.pad_sequences(x_original, maxlen=max_len)</span><br><span class="line">y_train = np.array(y_original)</span><br><span class="line"><span class="built_in">print</span>(x_train.shape, y_train.shape)</span><br></pre></td></tr></table></figure>
<p>然后通过前面得到的 <code>embedding_matrix</code> 初始化 embedding
层</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding, BatchNormalization, Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> Concatenate</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">embedding_layer = Embedding(input_dim=embedding_matrix.shape[<span class="number">0</span>],</span><br><span class="line">                            output_dim = embedding_dim,</span><br><span class="line">                            weights=[embedding_matrix],</span><br><span class="line">                            input_length=max_len,</span><br><span class="line">                            trainable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>然后建立模型并训练, 这里用了四种不同步长的卷积核，分别是
2、3、5、8，比起原始的 TextCNN,
用了两层的卷积层(在这个任务上经过测试比一层的要好),
后面的全连接层也拓展到了三层，具体代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line">BATCH_SIZE = <span class="number">64</span></span><br><span class="line">DROP_PORB = (<span class="number">0.5</span>, <span class="number">0.8</span>)</span><br><span class="line">NUM_FILTERS = (<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">FILTER_SIZES = (<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">8</span>)</span><br><span class="line">HIDDEN_DIMS = <span class="number">1024</span></span><br><span class="line">FEATURE_DIMS = <span class="number">256</span></span><br><span class="line">ACTIVE_FUNC = <span class="string">&#x27;relu&#x27;</span></span><br><span class="line"></span><br><span class="line">sequence_input = Input(shape=(max_len, ), dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">embedded_seq = embedding_layer(sequence_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convolutional block</span></span><br><span class="line">conv_blocks = []</span><br><span class="line"><span class="keyword">for</span> size <span class="keyword">in</span> FILTER_SIZES:</span><br><span class="line">    conv = Convolution1D(filters=NUM_FILTERS[<span class="number">0</span>],</span><br><span class="line">                         kernel_size=size,</span><br><span class="line">                         padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">                         activation=ACTIVE_FUNC,</span><br><span class="line">                         strides=<span class="number">1</span>)(embedded_seq)</span><br><span class="line">    conv = Convolution1D(filters=NUM_FILTERS[<span class="number">1</span>],</span><br><span class="line">                         kernel_size=<span class="number">2</span>,</span><br><span class="line">                         padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">                         activation=ACTIVE_FUNC,</span><br><span class="line">                         strides=<span class="number">1</span>)(conv)</span><br><span class="line">    conv = Flatten()(conv)</span><br><span class="line">    conv_blocks.append(conv)</span><br><span class="line"></span><br><span class="line">model_tmp = Concatenate()(conv_blocks) <span class="keyword">if</span> <span class="built_in">len</span>(conv_blocks) &gt; <span class="number">1</span> <span class="keyword">else</span> conv_blocks[<span class="number">0</span>]</span><br><span class="line">model_tmp = Dropout(DROP_PORB[<span class="number">1</span>])(model_tmp)</span><br><span class="line">model_tmp = Dense(HIDDEN_DIMS, activation=ACTIVE_FUNC)(model_tmp)</span><br><span class="line">model_tmp = Dropout(DROP_PORB[<span class="number">0</span>])(model_tmp)</span><br><span class="line">model_tmp = Dense(FEATURE_DIMS, activation=ACTIVE_FUNC)(model_tmp)</span><br><span class="line">model_tmp = Dropout(DROP_PORB[<span class="number">0</span>])(model_tmp)</span><br><span class="line">model_output = Dense(<span class="number">1</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)(model_tmp)</span><br><span class="line">model = Model(sequence_input, model_output)</span><br><span class="line"></span><br><span class="line">opti = optimizers.SGD(lr = <span class="number">0.01</span>, momentum=<span class="number">0.8</span>, decay=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer = opti,</span><br><span class="line">              metrics=[<span class="string">&#x27;binary_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_tra, y_tra, batch_size = BATCH_SIZE, validation_data = (x_val, y_val))</span><br></pre></td></tr></table></figure>
<p>由于最后要求的是 auc 指标，但是 Keras 中并没有提供，而 accuracy 与
auc 还是存在一定差距的，因此可以在每个epoch后通过 sklearn
计算auc，具体代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    model.fit(x_tra, y_tra, batch_size = BATCH_SIZE, validation_data = (x_val, y_val))</span><br><span class="line">    y_pred = model.predict(x_val)</span><br><span class="line">    val_auc = metrics.roc_auc_score(y_val, y_pred)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;val_auc:&#123;0:5f&#125;&#x27;</span>.<span class="built_in">format</span>(val_auc))</span><br></pre></td></tr></table></figure>
<p>这种方法最终的准确率约为 0.86，auc 约为0.84</p>
<h2 id="rnn-对动作序列建模">RNN 对动作序列建模</h2>
<p>通过 RNN 进行建模与 CNN 类似，不同的是 RNN
可接受不同长度的输入，但是根据<a
href="https://github.com/keras-team/keras/issues/40">这里</a>的说明，对于输入也需要
padding 的操作，只是RNN 会将其自动忽略。</p>
<p>因此，数据的预处理和构建 embedding 层的代码与 CNN
中基本一致，这里只给出建立模型的代码，模型比较简单，首先是将输入通过
embedding 层的映射后，作为以 LSMT/GRU 为基础单元构建的 RNN 的输入,
最后通过 sigmoid 进行分类，具体代码如下</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># RNNs are tricky. Choice of batch size is important,</span></span><br><span class="line"><span class="comment"># choice of loss and optimizer is critical, etc.</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(embedding_layer)</span><br><span class="line">model.add(Bidirectional(LSTM(<span class="number">256</span>, dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>)))</span><br><span class="line"><span class="comment"># model.add(LSTM(256))</span></span><br><span class="line"><span class="comment"># model.add(Bidirectional(GRU(256)))</span></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">opti = optimizers.SGD(lr = <span class="number">0.01</span>, momentum=<span class="number">0.8</span>, decay=<span class="number">0.0001</span>)</span><br><span class="line"><span class="comment"># try using different optimizers and different optimizer configs</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>通过 RNN 得出的最终效果比 CNN 要好一点，准确率约为 0.87，auc
约为0.85。但是训练起来非常慢，且参数非常的
tricky，需要精调，这里我没有细调参数，模型也没有搞得很复杂，应该还有提升空间。</p>
<p>综上，本文提供了一种对动态序列建模的思路：将动作序列通过
word2vec，得到每个动作的 embedding 表示，然后将动作序列转化为 embedding
序列并作为 CNN/RNN
的输入。希望能够起到抛砖引玉的作用，如果您有更好的想法，欢迎交流。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>通过Selenium和PhantomJS抓取带JS的网页</title>
    <url>/2016/08/10/%E9%80%9A%E8%BF%87Selenium%E5%92%8CPhantomJS%E6%8A%93%E5%8F%96%E5%B8%A6JS%E7%9A%84%E7%BD%91%E9%A1%B5/</url>
    <content><![CDATA[<p>爬虫一般通过获取网页的源码，然后通过正则表达式或html解释器获取所需的信息，但是有的网页，不能直接通过
linux下的 <code>wget</code> 命令、或者使用 Python
中的<code>requests.get</code>这样的函数库来直接获取其真正展现给用户的信息，<strong>因为里面包含有JavaScript脚本,而该JS和页面数据的生成相关，需要通过Firefox、Chrome等浏览器渲染后才能得到想要看的结果。</strong></p>
<span id="more"></span>
<p>如亚马逊的商品列表
https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&amp;field-keywords=lightning+cable
通过上面提到的方法直接获取其网页源码是无法获取每个商品的标题信息的。</p>
<p>一般来说，对于这种网页如下两种方案： 1.
<strong>通过Selenium启动真正的浏览器</strong>（如：IE、Firefox）来打开该网页，然后调用webdriver获取想要的页面元素。
2.
<strong>通过浏览器渲染引擎解释网页</strong>，能够让其解析网页并执行网页中需要初始化JS，然后将JS、CSS等执行后的HTML代码输出出来。</p>
<p><strong>启动真正的浏览器，可能带来两个问题：一个是需要的时间较长，另一个是UI自动化易受干扰、不够稳定。</strong>因此本文主要讲述通过第二种方法，也就是不启动浏览器进行获取这种网页上的信息。</p>
<p>主要用到的库是<a
href="http://www.seleniumhq.org/">Selenium</a>，通过selenium 中的
<code>PhantomJS</code>
作为webdriver能够不启动浏览器来解释js文件并获取其解释后的源码。下面以上面的亚马逊商品列表页作为例子，通过<code>PhantomJS</code>来获取其页面上的商品标题。</p>
<p>首先需要在<a
href="http://phantomjs.org/download.html">官网</a>下载<code>PhantomJS</code>的可执行文件。</p>
<p>然后获取页面
https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&amp;field-keywords=lightning+cable
上的商品列表的python代码如下： <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author: LC</span></span><br><span class="line"><span class="comment"># @Date:   2016-07-30 10:08:31</span></span><br><span class="line"><span class="comment"># @Last modified by:   LC</span></span><br><span class="line"><span class="comment"># @Last Modified time: 2016-08-22 17:08:46</span></span><br><span class="line"><span class="comment"># @Email: liangchaowu5@gmail.com</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">target_url = <span class="string">r&#x27;https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&amp;field-keywords=lightning+cable&#x27;</span></span><br><span class="line">driver = webdriver.PhantomJS(executable_path = <span class="string">r&#x27;H:/PythonModule/phantomjs/phantomjs-2.1.1-windows/bin/phantomjs.exe&#x27;</span>)</span><br><span class="line">driver.get(target_url)</span><br><span class="line">text = driver.page_source <span class="comment"># 获取解释后的网页源码</span></span><br><span class="line">soup = BeautifulSoup(text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">titles = soup.find_all(<span class="string">&#x27;h2&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> titles:</span><br><span class="line">    <span class="built_in">print</span> title.get(<span class="string">&#x27;data-attribute&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">driver.quit()</span><br></pre></td></tr></table></figure></p>
<p>上面的代码首先通过指定本地的<code>PhantomJS</code>的可执行文件可解释目标url，获取其网页html代码，然后通过BeautifulSoup提取网页代码中的商品标题</p>
<hr />
<p>参考：http://smilejay.com/2013/12/try-phantomjs-with-selenium/</p>
]]></content>
      <categories>
        <category>python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>通配符与正则表达式</title>
    <url>/2016/01/01/%E9%80%9A%E9%85%8D%E7%AC%A6%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<p>通配符与正则表达式均可以匹配符合某些格式的字符串，但是通配符一般用于Linux的shell下，而正则表达式适用范围则更广，不仅Linux的shell下支持（grep、awk、sed等工具），而且很多程序语言也支持（Java，Python等）。</p>
<span id="more"></span>
<h2 id="通配符">通配符</h2>
<ul>
<li>通配符 <code>?</code> 匹配文件名中的单个字符，而通配符
<code>*</code> 匹配零个或多个字符。像 <code>data?.dat</code>
这样的模式将查找下列文件：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data1.dat</span><br><span class="line">data2.dat</span><br><span class="line">datax.dat</span><br><span class="line">dataN.dat</span><br></pre></td></tr></table></figure>
<p>使用 <code>*</code> 字符代替 <code>?</code>
字符扩大了找到的文件的数量。<code>data*.dat</code>
匹配下列所有文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data.dat</span><br><span class="line">data1.dat</span><br><span class="line">data2.dat</span><br><span class="line">data12.dat</span><br><span class="line">datax.dat</span><br><span class="line">dataXYZ.dat</span><br></pre></td></tr></table></figure>
<h2 id="正则表达式regular-expression">正则表达式(regular
expression)</h2>
<h3 id="特殊字符">特殊字符</h3>
<p>特殊字符就是有特殊含义的字符，下面的表格将列出一些常用的特殊字符，如果要匹配这些特殊字符可以在其之前加上反斜杠<code>\</code></p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">特殊字符</th>
<th style="text-align: center;">含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">.</td>
<td
style="text-align: center;">匹配除了<code>\n</code>以外的任何单个字符，与通配符中的<code>?</code>作用相同</td>
</tr>
<tr class="even">
<td style="text-align: center;">？</td>
<td
style="text-align: center;">匹配前面的子表达式零次或一次，如<code>.?</code>表示没有字符或一个任意字符，<code>he(hee)?</code>表示<code>he</code>或<code>hehee</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">+</td>
<td
style="text-align: center;">匹配前面的子表达式一次或多次，如<code>.+</code>表示一个或一个以上的任意字符</td>
</tr>
<tr class="even">
<td style="text-align: center;">*</td>
<td
style="text-align: center;">匹配前面的子表达式零次或多次，如<code>.*</code>表示一个或一个以上的任意字符</td>
</tr>
<tr class="odd">
<td style="text-align: center;">[ ]</td>
<td
style="text-align: center;">匹配中括号内<strong>任意一个字符</strong>，如<code>[Pp]ython</code>表示Python或python,[a-z]匹配任何一个小写字母，[a-zA-Z0-9]匹配任何一个字母或数字</td>
</tr>
<tr class="even">
<td style="text-align: center;">( )</td>
<td style="text-align: center;">标记一个字表达式的开始和结束</td>
</tr>
<tr class="odd">
<td style="text-align: center;">{ }</td>
<td
style="text-align: center;">花括号里面放的是<strong>限定符表达式</strong>，用来匹配前面指定的表达式重复的次数，如<code>？</code>等价于<code>&#123;0,1&#125;</code>，<code>+</code>等价于<code>&#123;1,&#125;</code></td>
</tr>
<tr class="even">
<td style="text-align: center;">^</td>
<td
style="text-align: center;">在方括号<code>[]</code>内使用表示不包含方括号内任意元素，其余情况均表示匹配输入字符串的起始位置</td>
</tr>
<tr class="odd">
<td style="text-align: center;">$</td>
<td style="text-align: center;">匹配输入字符串的末尾</td>
</tr>
<tr class="even">
<td
style="text-align: center;">表示字符和空格间的位置（也叫作字边界）</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">任何其他非字边界的位置</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td
style="text-align: center;">匹配包括下划线的任何单词字符。等价于'[A-Za-z0-9_
]'</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">匹配任何非单词字符。等价于 '[^A-Za-z0-9_
]</td>
</tr>
<tr class="even">
<td style="text-align: center;">匹配一个数字字符。等价于 [0-9]</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;">匹配一个非数字字符。等价于 [^0-9]</td>
</tr>
</tbody>
</table>
<h3 id="贪婪匹配和非贪婪匹配">贪婪匹配和非贪婪匹配</h3>
<p>对于字符串<code>&lt;H1&gt;Chapter 1 – Introduction to Regular Expressions&lt;/H1&gt;</code></p>
<ul>
<li>如果匹配的正则表达式为<code>&lt;(.*)&gt;</code>，则为贪婪匹配，匹配出来的内容为<code>H1&gt;Chapter 1 – Introduction to Regular Expressions&lt;/H1</code>，正则表达式没有括号时(即为<code>&lt;.*&gt;</code>)，匹配的内容为<code>&lt;H1&gt;Chapter 1 – Introduction to Regular Expressions&lt;/H1&gt;</code></li>
<li>如果匹配的正则表达式为<code>&lt;(.*?)&gt;</code>，则为非贪婪匹配，匹配出来的内容为<code>H1</code>和<code>/H1</code></li>
</ul>
<p>这样应该可以看出非贪婪匹配（又称最小匹配）和贪婪匹配的区别了，贪婪匹配就是匹配符合正则表达式的尽可能多的内容，而非贪婪匹配则是匹配符合正则表达式的第一个子串（如果有多个符合）。</p>
<h3 id="一些例子">一些例子</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">正则表达式</th>
<th style="text-align: center;">匹配内容</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">[^\\\/\^]</td>
<td style="text-align: center;">除了(\)(/)(^)之外的所有字符</td>
</tr>
<tr class="even">
<td style="text-align: center;">[^\"\']</td>
<td
style="text-align: center;">除了双引号(")和单引号(')之外的所有字符</td>
</tr>
<tr class="odd">
<td style="text-align: center;">.{2}</td>
<td style="text-align: center;">所有的两个字符</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">两个制表符</td>
</tr>
<tr class="odd">
<td style="text-align: center;">^a{2,}$</td>
<td style="text-align: center;">以两个或两个以上的a开头的字符串</td>
</tr>
<tr class="even">
<td style="text-align: center;">^a{2,4}$</td>
<td style="text-align: center;">aa,aaa或aaaa</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a>{1,}$</td>
<td style="text-align: center;">所有的正数</td>
</tr>
<tr class="even">
<td style="text-align: center;">^\-{0,1}[0-9]{1,}$</td>
<td style="text-align: center;">所有的整数</td>
</tr>
<tr class="odd">
<td style="text-align: center;">^\-?[0-9]*\.?[0-9]+$</td>
<td style="text-align: center;">所有小数</td>
</tr>
</tbody>
</table>
<p>关于正则表达式的一些基本概念就是上面这些，当然正则表达式的功能比上面所说的还要强大得多。只是无需记住所有的特性，在需要用到的时候google一下即可。</p>
<aside id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>0-9<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>隐马尔可夫模型的三大问题及求解方法</title>
    <url>/2017/07/14/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%89%E5%A4%A7%E9%97%AE%E9%A2%98%E5%8F%8A%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>本文主要介绍隐马尔可夫模型以及该模型中的三大问题的解决方法。</p>
<span id="more"></span>
<p>隐马尔可夫模型的是处理序列问题的统计学模型，描述的过程为：由隐马尔科夫链随机生成<strong>不可观测的状态随机序列</strong>，然后各个状态分别生成一个观测，从而产生观测随机序列。</p>
<p>在这个过程中，不可观测的序列称为状态序列(state sequence),
由此产生的序列称为观测序列(observation sequence).</p>
<p>该过程可通过下图描述</p>
<figure>
<img src="https://wulc.me/imgs/image_1bkhejilo1dm0pgqbbj5c113vf9.png"
alt="隐马尔可夫模型" />
<figcaption aria-hidden="true">隐马尔可夫模型</figcaption>
</figure>
<p>上图中， <span class="math inline">\(X\_1,X\_2,...X\_T\)</span>
是隐含序列，而 <span class="math inline">\(O\_1, O\_2,..O\_T\)</span>
是观察序列</p>
<p>隐马尔可夫模型由三个概率确定</p>
<ol type="1">
<li><strong>初始概率分布</strong>，即初始的隐含状态的概率分布，记为
<span class="math inline">\(\pi\)</span></li>
<li><strong>状态转移概率分布</strong>，即隐含状态间的转移概率分布, 记为
<span class="math inline">\(A\)</span></li>
<li><strong>观测概率分布</strong>，即由隐含状态生成观测状态的概率分布,
记为 <span class="math inline">\(B\)</span></li>
</ol>
<p>以上的三个概率分布可以说就是隐马尔可夫模型的参数，而根据这三个概率，能够确定一个隐马尔可夫模型
<span class="math inline">\(\lambda = (A, B, \pi)\)</span></p>
<p>而隐马尔科夫链的三个基本问题为</p>
<ol type="1">
<li><strong>概率计算问题</strong>。即给定模型 <span
class="math inline">\(\lambda = (A, B, \pi)\)</span> 和观测序列 <span
class="math inline">\(O\)</span>，计算在模型 <span
class="math inline">\(\lambda\)</span> 下观测序列出现的最大概率 <span
class="math inline">\(P(O|\lambda)\)</span></li>
<li><strong>学习问题</strong>。即给定观测序列 <span
class="math inline">\(O\)</span>，估计模型的参数 <span
class="math inline">\(\lambda\)</span>,
使得在该参数下观测序列出现的概率最大，即 <span
class="math inline">\(P(O|\lambda)\)</span> 最大</li>
<li><strong>解码问题</strong>。给定模型 <span
class="math inline">\(\lambda = (A, B, \pi)\)</span> 和观测序列 <span
class="math inline">\(O\)</span>，计算最有可能产生这个观测序列的隐含序列
<span class="math inline">\(X\)</span>, 即使得概率 <span
class="math inline">\(P(X|O, \lambda)\)</span> 最大的隐含序列 <span
class="math inline">\(X\)</span></li>
</ol>
<h2 id="概率计算问题">概率计算问题</h2>
<p>概率计算问题理论上可通过穷举法来解决，即穷举所有可能的隐含状态序列，然后计算所有可能的隐含序列生成观测序列的概率，假设观测序列的长度为
<span class="math inline">\(n\)</span>,
且每个观测状态对应的可能的隐含状态长度为 <span
class="math inline">\(m\)</span>, 则这种方法的时间复杂度就是 <span
class="math inline">\(O(m^n)\)</span>,
这样的时间复杂度显然是无法接受的，因此在实际中往往不采用这种方法，而是采用前向算法和后向算法,
前向算法和后向算法都是通过动态规划来减少计算的时间复杂度，两者的不同点就是计算的方向不同。</p>
<h3 id="前向算法">前向算法</h3>
<p>前向算法需要先定义前向概率</p>
<blockquote>
<p>前向概率定义为到时刻 <span class="math inline">\(t\)</span>
为止观测序列为 <span
class="math inline">\(o\_1,o\_2,o\_3...o\_t\)</span>，且时刻 <span
class="math inline">\(t\)</span> 的隐含状态为所有的隐含状态中的第 <span
class="math inline">\(i\)</span> 个（记为 <span
class="math inline">\(q\_i\)</span>），则前向概率可记为 <span
class="math display">\[\alpha\_t(i) = P(o\_1,o\_2,o\_3...o\_t,x\_t =
q\_i|\lambda)\]</span></p>
</blockquote>
<p>定义了前向概率，便可递归地求解前向概率和观测序列的概率 <span
class="math inline">\(P(o\_1,o\_2,o\_3...o\_t|\lambda)\)</span></p>
<p>初始的状态为</p>
<p><span class="math display">\[\alpha\_1(i) =
\pi\_ib\_i(o\_1)~~i=1,..m\]</span></p>
<p>上式中的 <span class="math inline">\(m\)</span> 表示隐含状态的数目，
<span class="math inline">\(\pi\_i\)</span> 表示各个隐含状态的初始概率，
<span class="math inline">\(b\_i(o\_1)\)</span> 表示第 <span
class="math inline">\(i\)</span> 个隐含状态生成观测状态 <span
class="math inline">\(o\_1\)</span> 的概率</p>
<p>则递推的公式为</p>
<p><span class="math display">\[\alpha\_{t+1}(i) = (\sum\_{j=1}^N
\alpha\_t(j) a\_{ji} )b\_i(o\_{t+1})~~i=1,..m\]</span></p>
<p>上式中的 <span class="math inline">\(a\_{ji}\)</span> 表示从隐含状态
<span class="math inline">\(j\)</span> 转移到隐含状态 <span
class="math inline">\(i\)</span>
的状态转移概率。通过下图可较直观地看到前向递推公式的过程</p>
<figure>
<img src="https://wulc.me/imgs/image_1bkmitsfj1i3ga0c1d2c14gp566m.png"
alt="前向算法" />
<figcaption aria-hidden="true">前向算法</figcaption>
</figure>
<p>最终计算得到的概率为（其中 <span class="math inline">\(T\)</span>
为观测序列的长度）</p>
<p><span class="math display">\[P(O|\lambda) =
\sum\_{i=1}^{m}\alpha\_T(i)\]</span></p>
<h3 id="后向算法">后向算法</h3>
<p>类似前向算法，后向算法也可用于求解这个问题，只是方向是从后到前的。同样的，需要先定义后向概率</p>
<blockquote>
<p>后向概率指时刻 <span class="math inline">\(t\)</span>
的隐含状态为所有隐含状态中的第 <span class="math inline">\(i\)</span>
个(记为 <span class="math inline">\(q\_i\)</span>), 且时刻<span
class="math inline">\(t+1\)</span> 到 <span
class="math inline">\(T\)</span> 的观测序列为 <span
class="math inline">\(o\_{t+1},
o\_{t+2},....o\_T\)</span>的概率,记为<span
class="math display">\[\beta\_t(i) = P(o\_{t+1}, o\_{t+2},....o\_T, x\_t
= q\_i|\lambda)\]</span></p>
</blockquote>
<p>初始状态定义为</p>
<p><span class="math display">\[ \beta\_T(i) = 1~~i=1,2,...m
\]</span></p>
<p>这里概率为 1 的原因是概率为1的原因是本来还需要看看时刻 <span
class="math inline">\(T\)</span> 后面有什么东西，但因为最后一个时刻
<span class="math inline">\(T\)</span>
后面已经没有时刻，即不需要再观测某个东西，所以随便给个什么状态都可以</p>
<p>递推公式为</p>
<p><span class="math display">\[\beta\_t(i) =
\sum\_{j=1}^ma\_{ij}b\_j(o\_{t+1})\beta\_{t+1}(j)~~i=1,2,...m\]</span></p>
<p>上面的式子中的符号与前向算法中的一致，其过程可通过下图更直观理解</p>
<figure>
<img src="https://wulc.me/imgs/image_1bkmiuj7c1dii1lu2efijaomu113.png"
alt="后向算法" />
<figcaption aria-hidden="true">后向算法</figcaption>
</figure>
<p>最终计算得到的概率为</p>
<p><span class="math display">\[P(O|\lambda) = \sum\_{i=1}^m
\pi\_ib\_i(o\_1)\beta\_1(i)\]</span></p>
<p>分析可知，前向算法和后向算法的时间复杂度均是 <span
class="math inline">\(O(m^2T)\)</span>, <span
class="math inline">\(m\)</span> 为隐含状态的个数，<span
class="math inline">\(T\)</span> 为序列长度</p>
<h2 id="学习问题">学习问题</h2>
<p>学习问题要根据观测序列来推导模型参数，这一类的问题对应到概率论中的极大似估计问题。但是这里是有隐含变量的极大似然估计，因此直接无法通过直接求导进行求解，而要通过
<strong>EM 算法</strong> 来求解这一类问题。</p>
<p>EM
算法是一类算法，用于解决有隐含变量的概率模型参数的极大似然估计，具体到隐马尔可夫模型中的具体算法是
<a
href="https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm">Baum-Welch
算法</a>。</p>
<p>注：这里采用 EM
算法的前提是问题仅给出了观测序列，假如同时给出了观测序列和隐含序列，可直接通过最大似然估计求解。</p>
<p>问题的描述如下：给定的训练数据只包含 S 个长度为 T 的观测序列 <span
class="math inline">\(O = \lbrace O\_1, O\_2, O\_3...O\_T
\rbrace\)</span> 而没有对应的状态序列 <span
class="math inline">\(X\)</span>，目标是学习隐马尔可夫模型 <span
class="math inline">\(\lambda = (A,B,\pi)\)</span>
的参数，则隐马尔可夫模型此时变为了一个含有隐含变量的概率模型，表示为<span
class="math display">\[P(O|\lambda) = \sum\_I
P(O|I,\lambda)P(I|\lambda)\]</span></p>
<p>这里只给出 Baum-Welch 算法的流程，而省去其推导过程</p>
<p>1.初始化模型参数：选取 <span class="math inline">\(a\_{ij}^{(0)},
b\_j^{(0)}, \pi\_i^{(0)}\)</span>, 得到模型 <span
class="math inline">\(\pi^{(0)} = (A^{(0)}, B^{(0)}, \pi^{(0)})\)</span>
2.E 步，求解两个中间变量 <span class="math inline">\(\gamma\_t(i),
\xi\_t(i,j)\)</span>,两者的含义如下 <span
class="math inline">\(\gamma\_t(i)\)</span>：给定模型 <span
class="math inline">\(\lambda\)</span> 和观测序列 <span
class="math inline">\(O\)</span>，在时刻 <span
class="math inline">\(t\)</span> 的隐含状态为 <span
class="math inline">\(q\_i\)</span> 的概率, 即 <span
class="math inline">\(\gamma\_t(i) = P(x\_t = q\_i | O,
\lambda)\)</span> <span
class="math inline">\(\xi\_t(i,j)\)</span>：给定模型 <span
class="math inline">\(\lambda\)</span> 和观测序列 <span
class="math inline">\(O\)</span>，在时刻 <span
class="math inline">\(t\)</span> 的隐含状态为 <span
class="math inline">\(q\_i\)</span> , 时刻 <span
class="math inline">\(t+1\)</span> 的隐含状态为 <span
class="math inline">\(q\_j\)</span> 的概率, 即 <span
class="math inline">\(\xi\_t(i,j) = P(x\_t = q\_i, x\_{t+1} = q\_j | O,
\lambda)\)</span></p>
<p>结合前面的前向概率和后向概率的定义，计算这两个中间变量的公式如下(<span
class="math inline">\(m\)</span> 表示隐含状态的总个数)</p>
<p><span class="math display">\[\gamma\_t(i) = \frac{\alpha\_t(i)
\beta\_t(i)}{\sum\_{j=1}^m \alpha\_t(j) \beta\_t(j)}\]</span></p>
<p><span class="math display">\[\xi\_t(i,j) = \frac{\alpha\_t(i) a\_{ij}
b\_j(o\_{t+1})\beta\_{t+1}(j)}{\sum\_{p=1}^m \sum\_{q=1}^m \alpha\_t(p)
a\_{pq} b\_q(o\_{t+1})\beta\_{t+1}(q)}\]</span></p>
<p>3.M 步，同时 E
步求解出的两个中间变量来求解模型的参数，求解公式如下</p>
<p><span class="math display">\[a\_{ij} = \frac{\sum\_{t=1}^T
\xi\_t(i,j)}{\sum\_{t=1}^T \gamma\_t(i)} \]</span></p>
<p><span class="math display">\[b\_j(k) = \frac{\sum\_{t=1}^T
\gamma\_t(j)I(o\_t = v\_k)}{\sum\_{t=1}^T \gamma\_t(j)}\]</span></p>
<p><span class="math display">\[\pi\_i = \gamma\_1(i)\]</span></p>
<p>上式中的 <span class="math inline">\(I(o\_t = v\_k)\)</span> 表示时刻
<span class="math inline">\(t\)</span> 的观察状态为 <span
class="math inline">\(v\_k\)</span> 时, <span
class="math inline">\(I(o\_t = v\_k)\)</span> 才为1，否则为0</p>
<p>迭代进行 E 步骤和 M 步，将最终收敛的结果作为模型的参数</p>
<h2 id="解码问题">解码问题</h2>
<p>解码问题理论上也可以通过穷举法来解决，就是穷举所有可能的隐含序列并计算在这个隐含序列下观测序列的概率，并选择概率最大的那个隐含序列，但是穷举所有可能的隐含序列的时间复杂度也是指数级别的，跟第一个问题一样，在实际中往往也是不常用的。</p>
<p>实际中，解码问题通过动态规划来降低时间复杂度，并且已经有了成熟的解决方法，就是著名的维特比算法，具体的算法流程可参考这篇文章：<a
href="http://wulc.me/2017/03/02/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/">维特比算法</a>。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>遗传算法简介</title>
    <url>/2017/04/10/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<p>最近由于课程需要去调研了一下遗传算法，本文是调研结果的总结，主要介绍遗传算法的背景、基本流程、理论基础、变种及其应用。</p>
<span id="more"></span>
<h2 id="连续优化与组合优化">连续优化与组合优化</h2>
<h3 id="连续优化">连续优化</h3>
<p><a
href="https://en.wikipedia.org/wiki/Continuous_optimization">连续优化(continuous
optimization)</a>
在某些教材中也被称为函数优化，其特点是变量的取值是连续的，或者说是变量的范围是实数域(绝大多数情况)。对于一个可行域，其中包含着无数个可行解，这类问题一般利用目标函数可导的性质，通过如梯度，海塞矩阵等进行求解（如常见的梯度下降法，牛顿法等）。更详细的关于连续优化的方法可参考<a
href="http://wulc.me/2017/02/01/%E6%9C%80%E4%BC%98%E5%8C%96%E8%AE%A1%E7%AE%97%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/">这篇文章</a></p>
<h3 id="组合优化">组合优化</h3>
<p>相对于连续优化的另外一种优化是<a
href="https://en.wikipedia.org/wiki/Combinatorial_optimization">组合优化</a>，组合优化的变量是离散的，也就是变量的空间只有有限多个的可行解。比如说经典的背包问题就是一个组合优化问题</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdg4f1vg1h34mb1qq18p063p9.png"
alt="背包问题" />
<figcaption aria-hidden="true">背包问题</figcaption>
</figure>
<p>既然只有有限多个解，那么最直接想到的求解方法就是通过穷举这些解(exhaustive
search)找到最优解，然而分析可知，穷举所需要的时间复杂度一般是指数级别的，比如说对于背包问题，有
<span class="math inline">\(n\)</span>个物品的时候，共有 <span
class="math inline">\(n^2\)</span> 种可能性，时间复杂度是 <span
class="math inline">\(O(2^n)\)</span>。这样的问题已经是一个 <a
href="https://zh.wikipedia.org/zh-hans/NP%E5%9B%B0%E9%9A%BE">NP-hard</a>
问题了，这里先简单介绍一下P问题，NP问题和NP-hard问题的区别。</p>
<p>一般来说，P 问题指的是能够在多项式时间复杂度内找到解的问题，而 NP
问题指的是无法在多项式时间复杂度内找到答案的问题，但是能够在多项式时间复杂度内验证一个解是否正确的问题（如大素数的判断问题）；而
NP-hard 问题则是指那种不仅无法在多项式时间复杂度内找到答案,
甚至无法在多项式时间复杂度内验证一个解是否正确的问题（如背包问题，如果要找到最优，就必须对所有的可能进行比较，这样的时间复杂度就是指数级别了）。</p>
<p>实际上，大多数的组合优化问题都是 NP-hard
问题，虽然存在着某些特殊问题可以用多项式时间的方法来解决，如<a
href="http://wulc.me/2017/03/02/%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95/">通过维特比算法求解
HMM
中最大概率的隐含状态转移路径</a>。但是更多的情况下组合优化问题仍然是一个
NP-hard 问题。</p>
<p>于是为了解决这类得到最优解就需要耗时非常长的问题，人们退而求其次，去找一个接近最优解但是耗时在可接受范围内的解。进而诞生了一类方法:
元启发式方法(Metaheuristic)。</p>
<h3 id="元启发式方法metaheuristic">元启发式方法(Metaheuristic)</h3>
<p><a
href="https://en.wikipedia.org/wiki/Metaheuristic">元启发式方法(Metaheuristic)</a>
是一类方法， 维基上对的定义如下 &gt;a metaheuristic is a higher-level
procedure or heuristic designed to find, generate, or select a heuristic
(partial search algorithm) that may <strong>provide a sufficiently good
solution to an optimization problem</strong></p>
<p>元启发式方法的定义中已经说得很清楚了，这一类方法不确定能够提供最优解，但是会提供一个足够好的解，当然这个足够好好到什么程度也是与具体算法相关的，需要通过数学证明。但是这类方法能够在可接受时间内返回这个解。</p>
<p>我们经常听到的一些算法都属于这种元启发式算法，包括：</p>
<ul>
<li>遗传算法(Genetic Algorithms，GA)</li>
<li>模拟退火(Simulated Annealing，SA)</li>
<li>蚁群算法(Ant Colony Optimization，ACO)</li>
<li>粒子群算法(Particle Swarm Optimization，PSO) ......</li>
</ul>
<p>这一类算法都是从自然现象中得到启发的，如遗传算法就是从进化论中得到启发的，认为“物竞天择，适者生存”，一代代进化的基因是逐渐往好的方向发展的，对应到优化问题中就是逐渐收敛到比较好的解；模拟退火则是从金属加热后再冷却，金属中的分子最终有可能会到达一个内能比原来更低的位置，表示为一个更优解；蚁群算法和粒子群算法则是通过一个群体去搜索最优解，如对于非凸的优化，往往具有多个局部最优解，通过一个群体去搜索能够扩大搜索范围，从而以更大的概率收敛于全局最优解。</p>
<p>关于元启发式方法在组合优化中的更详细的应用可这篇文献： <a
href="http://dl.acm.org/citation.cfm?id=937505">Metaheuristics in
Combinatorial Optimization: Overview and Conceptual Comparison</a></p>
<h2 id="遗传算法">遗传算法</h2>
<p>从前面可知，<a
href="https://en.wikipedia.org/wiki/Genetic_algorithm">遗传算法</a>是元启发式方法的一种，维基上对其的定义如下:</p>
<blockquote>
<p>Genetic algorithms are commonly used to generate high-quality
solutions to optimization and search problems by relying on bio-inspired
operators such as mutation, crossover and selection。</p>
</blockquote>
<p>从维基的描述可知，遗传算法是收生物进化论的影响，因此遗传算法中的很多概念跟生物进化中的很多概念类似，而遗传算法主要的三个操作就是选择(selection)，交叉(crossover)和编译(mutataion).</p>
<p>下面先介绍遗传算法中的基本概念：</p>
<h3 id="基本概念">基本概念</h3>
<ul>
<li>个体（individual） : 一个候选解</li>
<li>种群（generation） : 一组候选解，代表某一代的所有个体</li>
<li>染色体（chromosomes） :
候选解的染色体表示，常见的用01字符串表示</li>
<li>适应度（fitness） :
个体的适应度，一般与优化问题中的目标函数值相关</li>
<li>选择（selection）: 根据个体适应性从一个 generation 中选出
适应性好的进入下一代</li>
<li>交叉（crossover） : 类似于生物中两个个体进行杂交，两个 chromosomes
进行相应的交叉</li>
<li>变异（mutation）: chromosomes
的某一位进行突变，如从0变到1或从1变到0</li>
</ul>
<p>在执行遗传算法前，有两个东西必须先定义好</p>
<ol type="1">
<li>可行解的表示方法，也就是常说的编码方式，上面说到了常用的有 01
编码，除此之外，根据问题的不同，还存在其他的一些编码方式</li>
<li>适应度函数，也就是计算上面适应度的函数，这个函数一般yong就是用目标函数，如要最大化某个函数，则将这个函数作为目标函数即可，反之最小化的时候加个负号即可。</li>
</ol>
<p>遗传算法是一个迭代算法，在进行初始化后按照 “选择，交叉，变异”
的顺序进行迭代，当满足设定的结束条件(例如达到一定的代数)，便将得到的解作为问题的解。其流程如下所示</p>
<figure>
<img src="https://wulc.me/imgs/4.jpg" alt="算法流程" />
<figcaption aria-hidden="true">算法流程</figcaption>
</figure>
<h3 id="算法流程">算法流程</h3>
<h4 id="初始化initialization">初始化(Initialization)</h4>
<p>初始化主要是<strong>确定编码方式以及初始种群的数目</strong>，初始种群的数目由人为设定然后随机产生，设定的数目如果太小，可能会一开始就限制了搜索域较小，而如果设定的数目太大，计算量会比较大。</p>
<p>编码方式则根据问题的约束条件和希望得到的解的精度确定，后面会给出一个详细的例子说明这个问题。</p>
<h4 id="选择selection">选择(Selection)</h4>
<p>选择模拟了生物进化中的“适者生存”，根据当代的个体的适应度按概率选出下一代，适应度越高，则被选择的概率也越大。</p>
<p>之所以不直接将适应度最大的若干个个体作为下一代，是因为这样可能会导致算法过早陷入局部最优解。在遗传算法里面这种现象称为"早熟（premature）"。</p>
<p>假如当代的个体总数是 <span class="math inline">\(M\)</span>，而个体
<span class="math inline">\(a\_i\)</span> 的适应度是 <span
class="math inline">\(f\_i\)</span>，则个体 <span
class="math inline">\(a\_i\)</span>被选择到下一代的概率是 <span
class="math display">\[p\_i = \frac{f\_i}{\sum\_{j=1}^{M}
f\_j}\]</span></p>
<h4 id="交叉crossover">交叉(crossover)</h4>
<p>交叉跟生物上的杂交是一样的，只是生物中是双螺旋结构，而遗传算法中只有一条链。原始的遗传算法只会选择一个点进行交叉，如下如所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bcv2juh21eff12veprb1m3pdjh9.png"
alt="Single-point crossover" />
<figcaption aria-hidden="true">Single-point crossover</figcaption>
</figure>
<p>而假如对遗传算法进行改进，也可以在多个点进行交叉的操作</p>
<figure>
<img src="https://wulc.me/imgs/image_1bcv2m08s8vh10efqmli9s1v9bm.png"
alt="Two-point crossover" />
<figcaption aria-hidden="true">Two-point crossover</figcaption>
</figure>
<p>交叉（<a
href="https://en.wikipedia.org/wiki/Crossover_%28genetic_algorithm%29#Three_parent_crossover">crossover</a>）的目的是从目前的所有解中组合出更优的解，但是尝试获得更优解的同时，也可能丢掉目前得到的最优解。而这也是传统的遗传算法无法收敛到全局最优的一个原因（详见后面的理论证明，对其进行了简单改进后可以收敛到全局最优）。</p>
<p>交叉是按照一定的概率进行的，这个概率也需要人为设定，假如设得过大边很容易将当前的最优解破坏掉，并且容易陷入早熟(premature)，而设得过小时则很难从当前的可行解中组合出更优的解。</p>
<h4 id="变异mutation">变异(mutation)</h4>
<p>变异（<a
href="https://en.wikipedia.org/wiki/Mutation_%28genetic_algorithm%29">mutation</a>）跟生物中的变异也一样，随机改变染色体中的某一位，如下所示就是一个变异的示例</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdglnnd9r1j1h1r1lsc714am5p.png"
alt="mutation.jpg" />
<figcaption aria-hidden="true">mutation.jpg</figcaption>
</figure>
<p>变异也是按照一定的概率进行的，这个概率也需要人为设定，而且这个概率一般会设置得比较小，如果设得较大时，就变成了类似随机搜索（random
search）的方法；但是如果设得太小的时候，就会造成生物中的基因漂变(genetic
drift)的现象，从而导致收敛到一个局部最优。</p>
<p>变异的主要作用是为了防止算法收敛到一个局部最优解。假如将找到最优解比作在多座山峰中找到最高的那一座，那么交叉就类似同一座山峰下的多个基因合力爬上山顶，而变异就类似于从一座山峰调到另外一座山峰，目的就是为了防止当前的山峰是一个局部最优解而将算法其作为一个全局最优解。</p>
<h4 id="终止termination">终止(termination)</h4>
<p>算法的终止条件由人为设定，一般是限制迭代的最大次数，或能够使用的最大的计算资源，或者是两次的解小于某个设定的阈值，下面是从维基百科中摘录的终止条件</p>
<blockquote>
<ul>
<li>A solution is found that satisfies minimum criteria</li>
<li>Fixed number of generations reached</li>
<li>Allocated budget (computation time/money) reached</li>
<li>The highest ranking solution's fitness is reaching or has reached a
plateau such that successive iterations no longer produce better
results</li>
<li>Manual inspection</li>
<li>Combinations of the above</li>
</ul>
</blockquote>
<h3 id="例子">例子</h3>
<p>下面给出两个例子：分别是遗传算法解决背包问题和一个连续优化问题。</p>
<h4 id="遗传算法解决背包问题">遗传算法解决背包问题</h4>
<p><a
href="https://zh.wikipedia.org/zh-hans/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98">背包问题</a>是一个很经典的组合优化问题，通过遗传算法可以求解，但是目前求解这类问题的最优方法是动态规划，是一个<a
href="https://zh.wikipedia.org/wiki/%E4%BC%AA%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%97%B6%E9%97%B4">伪多项式时间复杂度问题</a>。这里采用背包问题为例子是因为这个例子的编码方式有较好的解释。</p>
<p>假设现在背包的容量为 <span class="math inline">\(W\)</span>, 共有 15
个物品，每个物品的大小为 <span class="math inline">\(w\_i\)</span>,
价值为 <span class="math inline">\(v\_i\)</span>,
则可以得到下面的最优化问题</p>
<p><span class="math display">\[max \sum\_{i=1}^{15} x\_iv\_i\\
s.t. \sum\_{i}w\_ix\_i \le W\\
x\_i \in \lbrace 0,1 \rbrace\]</span></p>
<p><span class="math inline">\(x\_i \in \lbrace 0,1 \rbrace\)</span>
表示是否将第 <span class="math inline">\(i\)</span>
件物品放到背包中。</p>
<p>则通过遗传算法解决这个问题的流程如下</p>
<p><strong>初始化</strong>
由于有15个物品，而每个物品只有两个状态，因此用一个长度为15的01字符串表示一个解，0表示不拿该物品，1表示那该物品。随机产生10个候选解如下所示，这里要注意每个候选解必须要满足约束条件</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdgqufc4nnn1gqt1g431jm11gp1i.png"
alt="initialize" />
<figcaption aria-hidden="true">initialize</figcaption>
</figure>
<p>由于没有给出每个物品具体的价值，这里用 <span
class="math inline">\(V\_i\)</span> 表示第 <span
class="math inline">\(i\)</span> 个候选解通过公式 <span
class="math inline">\(\sum\_{j=1}^{15}x\_jv\_j\)</span>求得的总价值。</p>
<p><strong>选择</strong></p>
<p>由于每个个体被选择到下一代的概率与其适应度成正比，因此第 <span
class="math inline">\(i\)</span> 个候选解被选择到下一代的概率为<span
class="math display">\[p\_i =
\frac{V\_i}{\sum\_{j=1}^{15}V\_j}\]</span></p>
<p>如下为模拟的过程，注意一个个体可能会被选择多次</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdgqvll710hjeh190011vt1r8a1v.png"
alt="selection" />
<figcaption aria-hidden="true">selection</figcaption>
</figure>
<p><strong>交叉</strong></p>
<p>对选择出来的个体重新进行编号，然后进行交叉的操作，按照设定的交叉概率选择个体进行交叉的操作，交叉的位置也是随机产生的，如下所示是设定交叉概率为
0.5 后的交叉结果</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdgr0g2dd7mig01mki1qom12g22c.png"
alt="crossover" />
<figcaption aria-hidden="true">crossover</figcaption>
</figure>
<p><strong>变异</strong></p>
<p>变异也是按照变异概率选择个体来进行的，被选中的个体变异的位数可以是一位也可以是多位，如下图所示是设定变异概率为0.2的编译过程</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdgsa177is3q4i1rs114kvl436.png"
alt="mutation" />
<figcaption aria-hidden="true">mutation</figcaption>
</figure>
<p><strong>终止</strong></p>
<p>设定一个终止条件，如最大的迭代次数，当满足这个条件时边终止算法，将当前得到的最优解作为问题的最优解；没满足时便按照
"选择-&gt;交叉-&gt;编译"进行迭代。</p>
<p>利用遗传算法求解背包问题更详细的信息可参考这篇文献：<a
href="http://download.springer.com/static/pdf/710/art%253A10.1023%252FA%253A1009642405419.pdf?originUrl=http://link.springer.com/article/10.1023/A:1009642405419&amp;token2=exp=1491993908~acl=/static/pdf/710/art%25253A10.1023%25252FA%25253A1009642405419.pdf?originUrl=http%253A%252F%252Flink.springer.com%252Farticle%252F10.1023%252FA%253A1009642405419*~hmac=0a9e73167d1e4cfa3ddcd4ccea91c56da95955d24b1b138e965904173c398935">A
genetic algorithm for the multidimensional knapsack problem</a></p>
<h4 id="遗传算法解决连续优化问题">遗传算法解决连续优化问题</h4>
<p>该例子来源于<a
href="https://www.zhihu.com/question/23293449/answer/120220974">知乎</a>，
优化的问题如下所示</p>
<p><span class="math display">\[\max f(x) = x + 10sin(5x) + 7cos(4x)， x
\in [0,9]\]</span></p>
<p>这个函数的图像如下所示</p>
<figure>
<img src="https://wulc.me/imgs/image_1bdgsl05t1qu513751btg2mh1v133j.png"
alt="连续优化例子" />
<figcaption aria-hidden="true">连续优化例子</figcaption>
</figure>
<p>显然这已经不是一个凸函数了，通过遗传算法解决这个问题的步骤跟背包问题的一样，最主要也是最重要的区别在于编码方式的不同。</p>
<p>由于现在可行解是实数域了，仍旧采用01编码，则要解决的问题就是如何用01串表示一个实数。假设现在希望解精确到小数点的后四位，</p>
<p>假如设定求解的精度为小数点后4位，可以将x的解空间划分为 <span
class="math inline">\((9-0)×10^4=90000\)</span> 个等分。</p>
<p>由于 <span
class="math inline">\(2^{16}&lt;90000&lt;2^{17}\)</span>，则需要17位二进制数来表示这些解。换句话说，一个解的编码就是一个17位的二进制串。</p>
<p>一开始，这些二进制串是随机生成的。一个这样的二进制串代表一条染色体串，这里染色体串的长度为17。对于任何一条这样的染色体chromosome，如何将它复原(解码)到
[0,9] 这个区间中的数值呢？对于本问题，我们可以采用以下公式来解码：</p>
<p><code>x = 0 + decimal(chromosome)×(9-0)/(2^17-1)</code></p>
<p><code>decimal( )</code>: 将二进制数转化为十进制数</p>
<p>更一般化的解码公式：</p>
<p><code>f(x), x∈[lower_bound, upper_bound] x = lower_bound + decimal(chromosome)×(upper_bound-lower_bound)/(2^chromosome_size-1)</code></p>
<p><code>lower_bound</code>: 函数定义域的下限 <code>upper_bound</code>:
函数定义域的上限 <code>chromosome_size</code>:
染色体的长度通过上述公式，我们就可以成功地将二进制染色体串解码成[0,9]区间中的十进制实数解。</p>
<p>后面的选择，交叉，变异的过程与上面的背包问题一样，这里不在给出，在经过
100
次迭代后，最终选出的最优个体为00011111011111011，其适应度，也就是目标函数的值为24.8554，对应的
<span class="math inline">\(x\)</span>
为7.8569,从图像来看，已经是在最优解的位置了。</p>
<h2 id="理论基础">理论基础</h2>
<p>上面介绍的内容仅仅是遗传算法的基本流程，但是经过这些仿生的操作能确保最终收敛吗？如果收敛的话能够收敛到全局最优还是局部最优？收敛到全局最优的概率是多少？</p>
<p>在遗传算法刚提出来的时候为不少问题找到了一个较好的解，对于很多问题都能找到一个比较好的解，但是缺乏数学理论基础的保证，往往会让人产生上面这些问题。</p>
<p>很多时候，实践的发展往往是超前于理论的，于是在遗传算法提出 5
年后，它的提出者便发表了模式定理(Schema
Theory)来说明遗传算法中发生“优胜劣汰”的原因。而后又有人通过马氏链证明了算法的收敛性，结果是原始的遗传算法并不能收敛到全局最优，但是经过简单改进的遗传算法能够收敛到全局最优。</p>
<h3 id="模式定理schema-theory">模式定理(Schema Theory)</h3>
<h4 id="基本概念-1">基本概念</h4>
<p>问题引入： 求解方程 <span class="math inline">\(F(x) = x^2\)</span>
在 [0,31]
上的最大值，使用固定长度二进制编码对种群中的个体进行编码，在计算适应度值时会发现一个规律，当个体编码的最左边为1时，适应度普遍较大，可以记为
<code>1***1</code>，同理 <code>0****</code>
的个体适应度偏低。由此可以引入以下一些基本概念：</p>
<p><strong>模式(Schema)</strong>：编码的字符串中具有类似特征的子集。
例如上述五位二进制字符串中，模式 <code>*111*</code>
可代表4个个体。个体和模式的一个区别就是，个体是由<code>&#123;0，1&#125;</code>组成的编码串，模式是由<code>&#123;0，1，*&#125;</code>组成，<code>*</code>
为通配符。</p>
<p><strong>模式阶(Schema
Order)</strong>：表示模式中已有明确含义的字符个数，记为o(s)，s代表模式。例如o(<em>111</em>)=3;
阶数越低，说明模式的概括性越强，所代表的编码串个体数也越多。其中阶数为零的模式概括性最强。</p>
<p><strong>模式定义长度(Schema Defining
Length)</strong>：指第一个和最后一个具有含义的字符之间的距离，其可表示该模式在今后遗传操作中被破坏的可能性，越短则越小，长度为0最难被破坏。</p>
<p>下面就是模式定理的具体定义：
&gt;适应度高于群体平均适应度的，长度较短，低阶的模式在遗传算法的迭代过程中将按指数规律增长。</p>
<p>下面将推导经过选择，交叉和变异后如何得到上面的模式定理</p>
<h4 id="选择">选择</h4>
<p>假设当前是第 <span class="math inline">\(t\)</span> 代， 这一代中模式
<span class="math inline">\(s\)</span> 的个体数记为 <span
class="math inline">\(m(s,t)\)</span>，整个种群的数目为 <span
class="math inline">\(M\)</span>，个体 <span
class="math inline">\(a\_i\)</span> 的适应度为 <span
class="math inline">\(f\_i\)</span></p>
<p>则个体 <span class="math inline">\(a\_i\)</span> 被选择的概率为 <span
class="math display">\[p\_i = \frac{f\_i}{\sum\_{j=1}^{M}
f\_j}\]</span></p>
<p>因此经过选择后， 模式 <span class="math inline">\(s\)</span>
在下一代的数目为</p>
<p><span class="math display">\[m(s, t+1) = M\frac{m(s,t) \overline
{f(s)}}{\sum\_{j=1}^{M} f\_j} = m(s,t) \frac{\overline {f(s)}}{\overline
{f}}\]</span></p>
<p>其中 <span class="math inline">\(\overline {f(s)}\)</span>表示模式
<span class="math inline">\(s\)</span> 中个体的平均适应度, <span
class="math inline">\(\overline
f\)</span>表示整个种群的平均适应度，也就是 <span
class="math display">\[\overline f = \frac{\sum\_{j=1}^{M}
f\_j}{M}\]</span></p>
<p>可知只有当<span class="math inline">\(\overline {f(s)} &gt; \overline
f\)</span>, 模式 <span class="math inline">\(s\)</span>
中的个体才能增长, 将上面的公式做简单的变化，则有</p>
<p><span class="math display">\[m(s, t+1) = m(s,t) \frac{\overline
{f(s)}}{\overline {f}} = m(s,t) \frac{(1+c)\overline f }{\overline {f}}
= m(s,t)(1+c) \]</span></p>
<p>则从开始到第 <span class="math inline">\(t+1\)</span> 代，模式 <span
class="math inline">\(s\)</span> 的个体的数目为: <span
class="math display">\[m(s, t+1) = m(s, t)(1+c)^t\]</span></p>
<p>可以看到当<strong>模式平均适应度高于种群是适应度时，模式中的个体会呈指数形式增长。</strong></p>
<h4 id="交叉">交叉</h4>
<p>记模式定义长度(schema defining length)为 <span
class="math inline">\(\delta(s)\)</span>，染色体的长度记为 <span
class="math inline">\(\lambda\)</span></p>
<p>则模式被破坏，也就是在定义长度内进行交叉的概率为 <span
class="math inline">\(p\_d = \frac{\delta(s)}{\lambda - 1}\)</span></p>
<p>因此模式存活的概率为 <span class="math inline">\(p\_s = 1 - p\_d = 1
- \frac{\delta(s)}{\lambda - 1}\)</span></p>
<p>假设交叉概率为 <span
class="math inline">\(p\_c\)</span>，则存活概率为 <span
class="math inline">\(p\_s = 1 - p\_c \frac{\delta(s)}{\lambda -
1}\)</span></p>
<p>在经过选择，交叉后，模式 <span class="math inline">\(s\)</span>
在下一代数目为</p>
<p><span class="math display">\[m(s, t+1) = m(s,t) \frac{\overline
{f(s)}}{\overline {f}}[1 - p\_c \frac{\delta(s)}{\lambda -
1}]\]</span></p>
<p>从这里可以看到，<strong>模式的定义长度(schema defining length)
越小，则其存活的概率越大</strong></p>
<h4 id="变异">变异</h4>
<p>记模式的阶(Schema Order) 为 <span
class="math inline">\(o(s)\)</span>，变异的概率为 <span
class="math inline">\(p\_m\)</span></p>
<p>则原来的基因存活，也就是那些确定的位置都不发生变异的概率为 <span
class="math display">\[p\_s = (1-p\_m)^{o(s)} \approx 1 -
p\_mo(s)\]</span></p>
<p>上式最后做了泰勒展开，因此经过选择，交叉和变异后，模式 <span
class="math inline">\(s\)</span> 在下一代种群的数目为</p>
<p><span class="math display">\[m(s, t+1) = m(s,t) \frac{\overline
{f(s)}}{\overline {f}}[1 - p\_c \frac{\delta(s)}{\lambda - 1} -
p\_mo(s)]\]</span></p>
<p>从上式也可以看到，<strong>模式的阶越低，模式约容易存活</strong>。</p>
<p>因此经过上面的分析，可以得到模式定理的定义</p>
<blockquote>
<p>适应度高于群体平均适应度的，长度较短，低阶的模式在遗传算法的迭代过程中将按指数规律增长。</p>
</blockquote>
<p>该定理阐明了遗传算法中发生“优胜劣汰”的原因。在遗传过程中能存活的模式都是定义长度短、阶次低、平均适应度高于群体平均适应度的优良模式。遗传算法正是利用这些优良模式逐步进化到最优解。</p>
<h3 id="收敛性分析">收敛性分析</h3>
<p>虽然上面的模式定理说明了遗传算法有“优胜劣汰”的趋势，但是对于其收敛性并没有给出一个证明，这篇文献
<a
href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265964">Convergence
Analysis of Canonical Genetic Algorithms</a>
对遗传算法的收敛性进行了证明。</p>
<p>证明利用了<strong>有限状态的时齐马氏链的遍历性和平稳分布的性质</strong>，因为遗传算法可以被描述成一个有限状态的时齐马氏链，假如种群大小为
<span class="math inline">\(M\)</span>, 染色体的长度为 <span
class="math inline">\(\lambda\)</span>,采用01编码方式，将所有个体的染色体连起来作为一个状态，则种群的所有状态数目为
<span
class="math inline">\(2^{M\lambda}\)</span>。同时选择概率，变异概率和交叉概率可作为状态转移概率。</p>
<p>由于证明的定义和引理较多，因此这里不详细描述证明过程，只给出最后的结论。</p>
<p>证明给出的主要结论有两个： &gt;1. 传统的遗传算法不能收敛到全局最优
&gt;2.
在传统的遗传算法基础上每次选择的时候保留前面所有迭代里面的最优个体，最终能收敛到全局最优。</p>
<p>从证明最终给出的结论可知，传统的遗传算法并不能收敛到全局最优，证明过程指出的是收敛到全局最优的概率小于1，原因就是选择、交叉和变异中都带有一定的随机性，这种随机性导致了最优解可能会被抛弃；而改进后的遗传算法每一代都会保留着前面所有代数的最优解，因此最终会以概率1收敛到全局最优。</p>
<h2 id="改进方案variants">改进方案(Variants)</h2>
<p>下面介绍的是对原始的遗传算法进行改进后得到的变种，改进主要有三大方向：编码方式(Chromosome
representation), 精英选择(Elitism)和参数自适应（Adaptive）。</p>
<h3 id="编码方式">编码方式</h3>
<p>我们前面采用的均是01编码方式，但是实际上根据不同问题可以选择不同的编码方式，如格雷码（Gray
Code）、浮点数编码都是可选的编码方式。</p>
<p>二进制编码的缺点是：对于一些连续函数的优化问题，由于其随机性使得其局部搜索能力较差，如对于一些高精度的问题（如上题），当解迫近于最优解后，由于其变异后表现型变化很大，不连续，所以会远离最优解，达不到稳定。</p>
<p>而格雷码能有效地防止这类现象，当一个染色体变异后，它原来的表现现和现在的表现型是连续的。主要优点有：</p>
<ul>
<li>便于提高遗传算法的局部搜索能力</li>
<li>交叉、变异等遗传操作便于实现</li>
<li>符合最小字符集编码原则</li>
<li>便于利用模式定理对算法进行理论分析</li>
</ul>
<p>这篇文献 <a
href="http://onlinelibrary.wiley.com/doi/10.1029/95WR02917/full">An
Improved Genetic Algorithm for Pipe Network Optimization</a>
就适用了格雷码作为其编码方式。</p>
<p>而使用浮点数编码的原因往往是对连续函数优化时二进制编码精度不够。</p>
<h3 id="精英选择">精英选择</h3>
<p>精英选择实际上就是在前面收敛性证明中改进遗传算法使得其以概率1收敛到全局最优的改进方案，在这篇文献中
<a
href="http://www.ri.cmu.edu/pub_files/pub2/baluja_shumeet_1995_1/baluja_shumeet_1995_1.pdf">Removing
the Genetics from the Standard Genetic Algorithm</a>
对其做了详细的描述。</p>
<h3 id="参数自适应">参数自适应</h3>
<p>前面我们说到了变异的概率和交叉的概率都是人为设定的固定值，但是实际上这个概率在不同的种群下应该会有其对应的最优值。因此这篇文献
<a
href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=286385">Adaptive
probabilities of crossover and mutation in genetic
algorithms</a>，将两个概率设定为下面的两个公式</p>
<p><span class="math display">\[ P\_c=
\begin{cases}
\frac{k\_1(f\_{max}-f&#39;)}{f\_{max}-f\_{avg}}&amp;&amp; {f&#39;
\geq   f\_{avg}}\\\
k\_2  &amp;&amp; {f&#39; &lt; f\_{avg}}
\end{cases}\]</span></p>
<p><span class="math display">\[ P\_m=
\begin{cases}
\frac{k\_3(f\_{max}-f&#39;)}{f\_{max}-f\_{avg}}  &amp;&amp; {f&#39; \geq
f\_{avg}}\\\
k\_4 &amp;&amp; {f&#39; &lt; f\_{avg}}
\end{cases}
\]</span></p>
<p>上面的公式表明，交叉率和变异率随着个体的适应度在种群平均适应度和最大适应度之间进行线性调整。上面的公式中
<span class="math inline">\(f\_{max}\)</span> 表示种群的最大适应度,
<span class="math inline">\(f\_{avg}\)</span> 表示种群的平均适应度,
<span class="math inline">\(f&#39;\)</span>
表示参与交叉的两个个体中较大的适应度。</p>
<p>由上面的公式可知，当适应度越接近最大适应度时．交叉率和变异率越小，好处是降低了最优解被破坏的概率，坏处是当前的最优适应度等于最大适应度时，交叉率和变异率为零。这使得AGA在演化初期并不理想。因为在进化初期的群体中，较优个体几乎处于一种不发生变化的状态，而此时的优良个体不一定是全局最优解，这容易使演化走向局部收敛的可能性增加。</p>
<p>因此这篇文献<a
href="http://www.cqvip.com/qk/91690x/200612/21781597.html">自适应遗传算法交叉变异算子的改进</a>对上面的公式进行了如下的改进</p>
<p><span class="math display">\[ P\_c=
\begin{cases}
p\_{cmin}-\frac{（p\_{cmax}-p\_{cmin}）(f&#39;-f\_{avg})}{f\_{max}-f\_{avg}}&amp;&amp;
{f&#39; \geq   f\_{avg}}\\\
p\_{cmax}  &amp;&amp; {f&#39; &lt; f\_{avg}}
\end{cases}\]</span></p>
<p><span class="math display">\[ P\_m=
\begin{cases}
p\_{mmin}-\frac{（p\_{mmax}-p\_{mmin}）(f&#39;-f\_{avg})}{f\_{max}-f\_{avg}}&amp;&amp;
{f&#39; \geq   f\_{avg}}\\\
p\_{mmax}  &amp;&amp; {f&#39; &lt; f\_{avg}}
\end{cases}
\]</span></p>
<p><span class="math inline">\(p\_{cmin}\)</span>, <span
class="math inline">\(p\_{cmax}\)</span>
分别表示交叉率取值的下限和上限；而<span
class="math inline">\(p\_{mmin}\)</span>, <span
class="math inline">\(p\_{mmax}\)</span>
分别表示变异率取值的下限和上限,这样就避免了前面的概率出现0的情况。</p>
<h2 id="参考文献">参考文献</h2>
<p>这些文献在上面已经在不同部分给出其相应的链接了，这里再次统一列出</p>
<p>Blum C, Roli A. Metaheuristics in combinatorial optimization:
Overview and conceptual comparison[J]. ACM Computing Surveys (CSUR),
2003, 35(3): 268-308.</p>
<p>Chu P C, Beasley J E. A genetic algorithm for the multidimensional
knapsack problem[J]. Journal of heuristics, 1998, 4(1): 63-86.</p>
<p>Goldberg, David .Genetic Algorithms in Search, Optimization and
Machine Learning[M].MA: Addison-Wesley Professional, 1989:ISBN
978-0201157673</p>
<p>Rudolph G. Convergence analysis of canonical genetic algorithms[J].
IEEE transactions on neural networks, 1994, 5(1): 96-101</p>
<p>Srinivas M, Patnaik L M. Adaptive probabilities of crossover and
mutation in genetic algorithms[J]. IEEE Transactions on Systems, Man,
and Cybernetics, 1994, 24(4): 656-667.</p>
<p>Dandy G C, Simpson A R, Murphy L J. An improved genetic algorithm for
pipe network optimization[J]. Water resources research, 1996, 32(2):
449-458.</p>
<p>Baluja S, Caruana R. Removing the genetics from the standard genetic
algorithm[C].Machine Learning: Proceedings of the Twelfth International
Conference. 1995: 38-46.</p>
<p>Srinivas M, Patnaik L M. Adaptive probabilities of crossover and
mutation in genetic algorithms[J]. IEEE Transactions on Systems, Man,
and Cybernetics, 1994, 24(4): 656-667.</p>
<p>邝航宇, 金晶, 苏勇. 自适应遗传算法交叉变异算子的改进[J].
计算机工程与应用, 2006, 42(12): 93-96.</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
</search>
