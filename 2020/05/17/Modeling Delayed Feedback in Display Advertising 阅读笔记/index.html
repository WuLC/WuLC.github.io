<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">

<script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id: "JmI6QmP3fMkLet6B",ck: "JmI6QmP3fMkLet6B"})</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/imgs/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/imgs/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/imgs/favicon.ico">
  <link rel="mask-icon" href="/imgs/favicon.ico" color="#222">
  <meta name="google-site-verification" content="VcC-PHB4Om9SIR3Roqm7k1N-SHiBtQ6c3LJLVMKgU4U">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wulc.me","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="在计算广告中，转化是有延迟的，即在点击发生后过一段时间用户可能才会发生转化，且往往转化漏斗越深，延迟的时间越长；因此在训练 cvr&#x2F;deepcvr 模型时，会有两种情况出现（1）过早把样本送入模型，把最终会转化但是还没回传 label 的事件当做负例，导致模型低估（2）过晚把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，导致模型没能及时更新 因此在建模时需要对转化的回传延时进行建模，">
<meta property="og:type" content="article">
<meta property="og:title" content="《Modeling Delayed Feedback in Display Advertising》 阅读笔记">
<meta property="og:url" content="https://wulc.me/2020/05/17/Modeling%20Delayed%20Feedback%20in%20Display%20Advertising%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="吴良超的学习笔记">
<meta property="og:description" content="在计算广告中，转化是有延迟的，即在点击发生后过一段时间用户可能才会发生转化，且往往转化漏斗越深，延迟的时间越长；因此在训练 cvr&#x2F;deepcvr 模型时，会有两种情况出现（1）过早把样本送入模型，把最终会转化但是还没回传 label 的事件当做负例，导致模型低估（2）过晚把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，导致模型没能及时更新 因此在建模时需要对转化的回传延时进行建模，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wulc.me/imgs/WhyNeedModelDelay.jpg">
<meta property="og:image" content="https://wulc.me/imgs/ExpProbDenFunc.jpg">
<meta property="og:image" content="https://wulc.me/imgs/EM_algorithm.jpg">
<meta property="og:image" content="https://wulc.me/imgs/gradient_formula.jpg">
<meta property="og:image" content="https://wulc.me/imgs/DelayFeedBackExp.jpg">
<meta property="article:published_time" content="2020-05-17T13:37:39.000Z">
<meta property="article:modified_time" content="2023-04-30T05:12:49.055Z">
<meta property="article:author" content="良超">
<meta property="article:tag" content="计算广告">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wulc.me/imgs/WhyNeedModelDelay.jpg">

<link rel="canonical" href="https://wulc.me/2020/05/17/Modeling%20Delayed%20Feedback%20in%20Display%20Advertising%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>《Modeling Delayed Feedback in Display Advertising》 阅读笔记 | 吴良超的学习笔记</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">吴良超的学习笔记</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wulc.me/2020/05/17/Modeling%20Delayed%20Feedback%20in%20Display%20Advertising%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/files/profile.jpg">
      <meta itemprop="name" content="良超">
      <meta itemprop="description" content="盈亏同源，享受生活的随机性">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴良超的学习笔记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《Modeling Delayed Feedback in Display Advertising》 阅读笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-17 21:37:39" itemprop="dateCreated datePublished" datetime="2020-05-17T21:37:39+08:00">2020-05-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/" itemprop="url" rel="index"><span itemprop="name">计算广告</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在计算广告中，转化是有延迟的，即在点击发生后过一段时间用户可能才会发生转化，且往往转化漏斗越深，延迟的时间越长；因此在训练
cvr/deepcvr
模型时，会有两种情况出现（1）过早把样本送入模型，把最终会转化但是还没回传
label
的事件当做负例，导致模型低估（2）过晚把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，导致模型没能及时更新</p>
<p>因此在建模时需要对转化的回传延时进行建模，这篇 paper 《<a
target="_blank" rel="noopener" href="http://olivier.chapelle.cc/pub/delayedConv.pdf">Modeling Delayed
Feedback in Display Advertising</a>》是 <a
target="_blank" rel="noopener" href="https://www.criteo.com/">criteo</a>
针对这个问题提供的一个解决方法，主要思想就是<strong>对于还未观察到
conversion 的样本，不直接将其当做负样本，而是当前考虑 click
已发生的时间长短给模型不同大小的 gradient</strong>；paper 里称在 criteo
的真实的数据上验证了该方法的有效性。此外，文章从问题的建模到求解的思路不错，值得一看。</p>
<span id="more"></span>
<h2 id="为什么要对延迟建模">为什么要对延迟建模</h2>
<p>与转化的回传紧密相关的一个话题就是归因（attribution），即将转化归到哪一个
click 上，paper 中用了常用的 last-click 归因，归因窗口固定在 30
天内，即在点击后30天以内回传的转化才认为是有效的。</p>
<p>对回传延迟建模往往要先分析延迟的分布，且对于不同的广告主、行业等，这个值的差异往往还是比较大的，在paper中统计结果如下图一所示，结果显示约35%的转化会在一小时内回传，50%
会在24小时内回传。</p>
<p>此外，paper
中还提到了新计划的问题，主要的观点是每天都会有大量的新计划被创建（如下图二所示），如果不能尽快将这些新计划对应的样本喂给模型，会导致模型在这些新计划上预估得不好</p>
<figure>
<img src="https://wulc.me/imgs/WhyNeedModelDelay.jpg" alt="graph" />
<figcaption aria-hidden="true">graph</figcaption>
</figure>
<p>上面这两张图正好对应着文章开头说的要对 delayed conversion
进行建模的原因；图一表明如果样本不延迟做归因，会把最终会转化但是还没回传
label
的事件当做负例，导致模型低估，图二则表明如果等待过长时间才把样本送入模型，即让所有样本都等待一个足够长的时间才送入模型，会导致模型没能及时更新</p>
<h2 id="问题建模">问题建模</h2>
<p>下面的建模采用到的一些符号及其含义如下所示</p>
<ul>
<li><span class="math inline">\(X\)</span>: 特征</li>
<li><span class="math inline">\(Y \in \lbrace 0, 1\rbrace\)</span>:
当前时刻 conversion 是否已经发生了</li>
<li><span class="math inline">\(C \in \lbrace 0,
1\rbrace\)</span>：conversion 最终是否会发生</li>
<li><span class="math inline">\(D\)</span>：回传延迟的真正时间</li>
<li><span class="math inline">\(E\)</span>：当前已过去的时间</li>
</ul>
<p>则当前如果</p>
<ul>
<li>观察到转化还没发生即 <span
class="math inline">\(Y=0\)</span>，有两种可能
<ul>
<li><ol type="1">
<li>转化最终不会发生 <span class="math inline">\(C=0\)</span></li>
</ol></li>
<li><ol start="2" type="1">
<li>转化最终会发生，但是 <span
class="math inline">\(D&gt;E\)</span></li>
</ol></li>
</ul></li>
<li>观察到转化已发生即 <span class="math inline">\(Y=1\)</span>,
则肯定有 <span class="math inline">\(C=1\)</span>；即 <span
class="math inline">\(Y=1\)</span> 是 <span
class="math inline">\(C=1\)</span> 的充分条件</li>
</ul>
<p>且 paper 中做了如下的假设，<strong>当前已过去的时间 <span
class="math inline">\(E\)</span>
与最终是否的转化时间以及是否会转化无关</strong>，即</p>
<p><span class="math display">\[P(C,D|X,E) = P(C,D|X)\]</span></p>
<p>这个假设也是比较合理的，因为最终是否转化及转化的延迟时间与当前已经过去的时间长短无关。</p>
<p>paper 中对将问题分为两部分来建模，第一部分是常见的 ctr
预估模型，如下公式(1) 所示，第二部分是通过指数分布来建模回传延迟 <span
class="math inline">\(D\)</span>, 如下公式(2)所示；除了指数分布，<a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Weibull_distribution">weibull
分布</a>、<a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma
分布</a>、<a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal
分布</a> 也常被用来建模事件发生的时间间隔，这些分布是 <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Survival_analysis#General_formulation">Survival
analysis</a> 这个研究领域里常用的分布。</p>
<p><span class="math display">\[P(C=1|X=x)=p(x)=\frac{1}{1+\exp(-w\_cx)}
\tag{1}\]</span></p>
<p><span class="math display">\[P(D=d|X=x,
C=1)=\lambda(x)\exp(-\lambda(x)d) \tag{2}\]</span></p>
<p>其中 <span class="math inline">\(\lambda(x)\)</span> 在 survival
analysis 中被称为 <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function">hazard
function</a>，其含义表示的是<strong>事件发生的频率/强度</strong>;
如对于指数分布，如果这个值越大，表示事件发生频率越大，事件间的时间间隔越短，则概率密度函数会越陡峭，如下图所示。此外，为了保证
<span class="math inline">\(\lambda(x) \gt 0\)</span>, 这里令 <span
class="math inline">\(\lambda(x) = \exp(w\_dx)\)</span></p>
<figure>
<img src="https://wulc.me/imgs/ExpProbDenFunc.jpg"
alt="exp prob density" />
<figcaption aria-hidden="true">exp prob density</figcaption>
</figure>
<p>此外，指数分布用来建模两个事件发生的时间间隔，而泊松分布则用来建模某段时间里事件发生的次数，详细的讲解可参考知乎上的这个回答
<a
target="_blank" rel="noopener" href="https://www.zhihu.com/question/24796044/answer/673838656">指数分布公式的含义是什么？</a></p>
<p>有了公式(1)和公式(2) 后，我们就可以推导在考虑回传延迟下 pvr
预估问题了；下面可<strong>分两种情况写出样本的似然：即已观察到
conversion 的样本和未观察到 conversion 的样本</strong></p>
<h3 id="已观察到-conversion-的样本的似然">已观察到 conversion
的样本的似然</h3>
<p>即当前观察到 conversion 的概率可写成</p>
<p><span class="math display">\[
\begin{split}
p\_1&amp;=p(Y=1, D=d\_i|X = x\_i, E=e\_i) \\\
&amp;= p(Y=1,D=d\_i|X = x\_i) \\\
&amp;= p(C=1,D=d\_i|X = x\_i) \\\
&amp;= p(D=d\_i|X=x\_i, C=1)*p(C=1|X=x\_i)
\end{split}
\]</span></p>
<p>上面的推导的三步主要利用了以下三点</p>
<ul>
<li>针对该问题的假设：当前已过去的时间 <span
class="math inline">\(E\)</span>
与最终是否会转化无关，同时与转化时间无关</li>
<li><span class="math inline">\(Y=1\)</span> 是 <span
class="math inline">\(C=1\)</span> 的充分条件</li>
<li>条件概率公式 <span class="math inline">\(p(a|b,c) * p(b|c) =
p(a,b|c)\)</span></li>
</ul>
<p>最后可将概率表示成公式(1) 和公式（2）的乘积，则</p>
<p><span class="math display">\[p\_1=p(Y=1, D=d\_i|X = x\_i,
E=e\_i)=\lambda(x\_i)\exp(-\lambda(x\_i)d\_i) * p(x\_i)
\tag{3}\]</span></p>
<h3 id="未观察到-conversion-的样本的似然">未观察到 conversion
的样本的似然</h3>
<p>同理，可写出当前还没观察到 conversion 的样本的概率 <span
class="math inline">\(p\_0\)</span> 为</p>
<p><span class="math display">\[
\begin{split}
p\_0&amp;=p(Y=0|X = x\_i, E=e\_i) \\\
&amp;=p(Y=0|C=0, X = x\_i, E=e\_i)p(C=0|X=x\_i) +\\\
&amp;p(Y=0|C=1, X = x\_i, E=e\_i)p(C=1|X=x\_i) \\\
&amp;=p(C=0|X=x\_i) + p(Y=0|C=1, X = x\_i, E=e\_i)p(C=1|X=x\_i)
\end{split}
\]</span></p>
<p>上面的推导的两步主要利用了以下两点</p>
<ul>
<li>全概率公式 + 条件概率
<ul>
<li><span
class="math inline">\(p(a|c)=\sum\_{b\_i}p(ab\_i)\)</span></li>
<li><span class="math inline">\(p(ab\_i|c)=\sum\_{b\_i}p(a|b\_i,
c)p(b\_i|c)\)</span></li>
</ul></li>
<li><span class="math inline">\(p(Y=0|C=0, X = x\_i,
E=e\_i)=1\)</span></li>
</ul>
<p>则上面的推导关键点在于求出条件概率 <span
class="math inline">\(p(Y=0|C=1, X = x\_i, E=e\_i)\)</span>,
该条件概率的含义是<strong>当前未观察到 conversion
的样本最终会转化的概率，换种描述就是最终的延时<span
class="math inline">\(D\)</span>大于当前已过去时间<span
class="math inline">\(E\)</span>的概率</strong>，即可表示成如下公式</p>
<p><span class="math display">\[
\begin{split}
&amp;p(Y=0|C=1, X = x\_i, E=e\_i) \\
&amp;=p(D&gt;E|C=1,X=x\_i, E=e\_i) \\
&amp;=\int\_{e\_i}^{\infty} \lambda(x)\exp(\lambda(x)t)dt \\
&amp;=\exp(-\lambda(x)e\_i)
\end{split}
\]</span></p>
<p>即最终有 <span class="math display">\[p\_0=p(Y=0|X = x\_i,
E=e\_i)=1-p(x\_i) + p(x\_i) * \exp(-\lambda(x\_i)e\_i)
\tag{4}\]</span></p>
<h3 id="小结">小结</h3>
<p>综上</p>
<ul>
<li>对于当前观察到conversion的样本，其似然函数为公式(3)即,</li>
</ul>
<p><span
class="math display">\[p\_1=\lambda(x\_i)\exp(-\lambda(x\_i)d\_i) *
p(x\_i) \]</span></p>
<ul>
<li>对于当前未观察到conversion的样本，其似然函数为公式(4)即</li>
</ul>
<p><span class="math display">\[p\_0=1-p(x\_i) + p(x\_i) *
\exp(-\lambda(x\_i)e\_i) \]</span></p>
<p>可以看到，这里 <span class="math inline">\(p\_0 + p\_1 \ne
1\)</span>, 跟我们常见的建模方式不一样</p>
<h2 id="问题求解">问题求解</h2>
<p>上面的问题的解法的基本原理是
MLE(极大似然估计)，但是根据是否显式地写出变量 <span
class="math inline">\(C\)</span> 的条件概率有两种解法，第一种是将 <span
class="math inline">\(C\)</span> 当做隐变量，通过 EM
算法求解；<strong>第二种没有直接写出隐变量 <span
class="math inline">\(C\)</span> 的概率密度函数，而是直接写出样本集的
likelihood，因为从上面的问题建模中已经基于当前观察到的 <span
class="math inline">\(y\_i\)</span> 写出对应的似然函数了。</strong></p>
<h3 id="em-算法">EM 算法</h3>
<p>关于 EM 算法的推导，CS229 的讲义 <a
target="_blank" rel="noopener" href="http://cs229.stanford.edu/notes/cs229-notes8.pdf">EM algorithm</a>
里讲得比较详细了，证明的基本流程就是</p>
<ol type="1">
<li>在似然函数中通过全概率公式引入隐变量</li>
<li>通过 Jensen’s inequality 把隐变量提出来</li>
<li>优化目标转转为最大化 Jensen’s inequality 的下界，让 Jensen’s
inequality 取等号得到隐变量的概率密度函数(E-step)</li>
<li>将隐变量的概率密度函数带入似然函数中做MLE即可(M-step)</li>
</ol>
<p>知乎上也有一个比较通俗的回答<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/36331115">人人都懂EM算法</a>，因此证明过程这里就不再展开赘述了</p>
<p>简单来说，EM 算法中的 <strong>E-step是为了通过条件概率 <span
class="math inline">\(p(z|x;\theta)\)</span> 来表示隐变量 <span
class="math inline">\(H\)</span>，从而替换掉似然函数中的隐变量；进而在
M-step 中只针对 <span class="math inline">\(\theta\)</span>
来进行进行极大似然即可</strong>.如下图所示是 CS229
讲义里的一次迭代的流程, 里面的 <span class="math inline">\(i\)</span>
表示隐变量可能的状态</p>
<figure>
<img src="https://wulc.me/imgs/EM_algorithm.jpg" alt="EM" />
<figcaption aria-hidden="true">EM</figcaption>
</figure>
<p>EM 算法的证明中通过证明了算法会随着 E-step + M-step
逐步收敛的，但是不能保证收敛到全局最优，如果我们的优化目标是凸的，则EM算法可以保证收敛到全局最优，因为对于凸函数局部最优即全局最优。</p>
<p>回到这个问题，由于 <span class="math inline">\(C\)</span>
是隐变量，则 E-step 和 M-step 的过程分别如下</p>
<p><strong>E-step</strong></p>
<p>给定一个样本 <span class="math inline">\((x\_i, y\_i, e\_i)\)</span>,
令隐变量的条件概率为</p>
<p><span class="math display">\[p(C=1|X=x\_i, Y=y\_i) :=
w\_i\]</span></p>
<p>相比于上面的 EM 算法的流程，我们这还多了一个 <span
class="math inline">\(y\_i\)</span>, 因此还要对 <span
class="math inline">\(y\_i\)</span> 的值进行分类讨论</p>
<ul>
<li>当 <span class="math inline">\(y\_i=1\)</span> 时，可知 <span
class="math inline">\(w\_i=1\)</span>（因为 <span
class="math inline">\(Y=1\)</span> 是 <span
class="math inline">\(C=1\)</span> 的充分条件）</li>
<li>当 <span class="math inline">\(y\_i=0\)</span> 时，其计算方法如下,
即</li>
</ul>
<p><span class="math display">\[
\begin{split}
w\_i&amp;=p(C=1|Y=0,X=x\_i,E=e\_i) \\\
&amp;=p(Y=0|C=1, X = x\_i, E=e\_i)p(C=1|X=x\_i) \\\
&amp;=p(x\_i) * \exp(-\lambda(x\_i)e\_i)
\end{split}
\]</span></p>
<p>计算出 <span class="math inline">\(w\_i=p(C=1|X=x\_i,
Y=y\_i)\)</span> 后，<span class="math inline">\(p(C=0|X=x\_i, Y=y\_i) =
1-w\_i\)</span></p>
<p><strong>M-step</strong></p>
<p>M step 最大化的似然函数根据<span class="math inline">\(Y\)</span> 和
<span class="math inline">\(C\)</span> 的值可分为四项，分别对应与上图中
M-step 中的两层 <span class="math inline">\(\sum\)</span> 嵌套，且在
<span class="math inline">\(Y=1\)</span> 的情况下 <span
class="math inline">\(C=0\)</span> 的概率为0，最终M-step
的似然函数如下所示</p>
<p><span class="math display">\[
\begin{split}
L&amp;=\sum\_{i,y\_i=1}w\_i \* \log p(Y=1,D=d\_i|X=x\_i,E=e\_i) + \\\
&amp;\sum\_{i,y\_i=0}[ w\_i \* \log p(Y=0,C=1|X=x\_i,E=e\_i) + \\\
&amp;(1-w\_i) \* \log p(Y=0,C=0|X=x\_i,E=e\_i)]
\end{split}
\]</span></p>
<p>且由前面可知，<span class="math inline">\(w\_i\)</span> 取值为</p>
<p><span class="math display">\[
w_i = \begin{cases}
1 &amp; &amp;y_i =1 \\\
p(x_i) * \exp(-\lambda(x_i)e_i) &amp; &amp;y_i =0
\end{cases}
\]</span></p>
<p>因此，利用公式(3)和公式(4)的推导，导入上式最终化简得到结果为</p>
<p><span class="math display">\[
\begin{split}
L&amp;=\sum\_{i}w\_i \log p(x\_i) + (1-w\_i) \log(1-p(x\_i)) \\\
&amp;+\sum\_{i} \log(\lambda(x\_i))y\_i - \lambda(x\_i)t\_iw\_i
\end{split}\tag{5}
\]</span></p>
<p>除了 <span class="math inline">\(w\_i\)</span> 的值要根据 <span
class="math inline">\(y\_i\)</span> 的值变化外，公式 (5) 中的 <span
class="math inline">\(t\_i\)</span> 也需要根据 <span
class="math inline">\(y\_i\)</span> 的值变化，即如下所示</p>
<p><span class="math display">\[
t_i = \begin{cases}
e_i &amp;y_i =1 \\\
d_i &amp;y_i =0
\end{cases}
\]</span></p>
<p>至此，可通过公式(5)对 <span class="math inline">\(p\)</span> 和 <span
class="math inline">\(\lambda\)</span> 进行 MLE
了，且从公式(5)中可看到，<strong>对 <span
class="math inline">\(p\)</span> 执行的优化是一个 weighted logistics
regression 的过程，而对 <span class="math inline">\(\lambda\)</span>
执行的优化构成则是一个 exponential regression</strong></p>
<h3 id="joint-optimization">Joint Optimization</h3>
<p>在上面的问题建模中，基于当前观察到的 <span
class="math inline">\(y\_i\)</span>
已经能写出样本对应的似然函数了，因此虽然问题中包含隐变量 <span
class="math inline">\(C\)</span>, 但是不一定要显示的将 <span
class="math inline">\(C\)</span>
的条件概率写出来（<strong>当无法写出样本对应的似然函数了需要这一步，这个时候就一定要通过
EM 算法求解了</strong>）</p>
<p>根据MLE，求解的问题可表示成如下形式</p>
<p><span class="math display">\[\arg \min\_{w\_c,w\_d}
L(w\_c,w\_d)+\frac{\mu}{2}(||w\_c||\_2^2 + ||w\_d||\_2^2)\]</span></p>
<p>上面的公式中加入了 L2 regularization，要求教的 <span
class="math inline">\(w\_c,w\_d\)</span> 分别是 <span
class="math inline">\(p\)</span> 和 <span
class="math inline">\(\lambda\)</span> 的参数；根据公式 (3) 和 (4),
可写出 <span class="math inline">\(L(w\_c,w\_d)\)</span> 为</p>
<p><span class="math display">\[
L(w\_c,w\_d) = -\sum\_{i, y\_i=1} \log(p(x\_i)+ \log
\lambda(x\_i)-\lambda(x\_i)d\_i  - \\\
\sum\_{i, y\_i=0} \log[1-p(x\_i) + p(x\_i) \exp(-\lambda(x\_i)e\_i)]
\]</span></p>
<p>其中，<span
class="math inline">\(p(x)=\frac{1}{1+\exp(-w\_cx)}\)</span> , <span
class="math inline">\(\lambda(x) = \exp(w\_dx)\)</span></p>
<p>则对 <span class="math inline">\(w\_c\)</span> 和 <span
class="math inline">\(w\_d\)</span> 的导数如下图所示</p>
<figure>
<img src="https://wulc.me/imgs/gradient_formula.jpg" alt="gradient" />
<figcaption aria-hidden="true">gradient</figcaption>
</figure>
<p>从上面的求导的表达式可知，对于当前 <span
class="math inline">\(y\_i=0\)</span> 即label还没回传的样本，其对 <span
class="math inline">\(w\_c\)</span> 的影响可从下面两方面去了解</p>
<p>(1)当 <span class="math inline">\(\lambda(x\_i)e\_i \ll 1\)</span>,
即当前已经过去的时间 <span class="math inline">\(e\_i\)</span>
远小于平均的回传时间 <span
class="math inline">\(\lambda(x\_i)^{-1}\)</span> 时，<strong><span
class="math inline">\(\sum\_{i, y\_i}\)</span>
这一项几乎为0，表示click发生的时间还很短，没法完全确认最终是没有
conversion 的</strong> (2)<span class="math inline">\(\lambda(x\_i)e\_i
\gg 1\)</span>, 即当前已经过去的时间 <span
class="math inline">\(e\_i\)</span> 远大于平均的回传时间 <span
class="math inline">\(\lambda(x\_i)^{-1}\)</span> 时，<strong>对 <span
class="math inline">\(w\_c\)</span> 贡献的梯度是 <span
class="math inline">\(1/(1-p(x\_i))\)</span>, 相当于在 logistics
regression
中的一个负样本的梯度，表示已经过了较长时间还没观察到conversion，可认为这个样本是负样本了</strong></p>
<h3 id="小结-1">小结</h3>
<p>前面主要讲了求解建模好的问题的两种解法，第一种方法是显式地写出了隐变量
<span class="math inline">\(C\)</span> 的条件概率，并通过 EM
算法求解；第二种方法则是直接写出所有样本的似然函数直接求解。值得注意的是，<strong>在serving的时候只使用ctr预估模型，而不用建模延时的指数回归模型，因为在做反向传播过程中已经考虑了回传延迟对参数进行了修正</strong></p>
<h2 id="实验">实验</h2>
<p>实验数据：实验数据使用了 criteo 里的真实数据（但是 paper
里附的实验数据链接打不开了）；7天测试数据，每天的测试数据对应的训练数据是其前3周的数据（约600w条样本）</p>
<p>实验设置：为了与实验提出来的 DFM
模型作对比，对照组里提供了若干个模型</p>
<ul>
<li>Short Term Conversion(STC): 采用了两个模型
<ul>
<li>第1个模型用来预估样本在某段时间内转化的概率，即<span
class="math inline">\(p(C=1,D \le 1 day|X=x)\)</span></li>
<li>第2个模型用来预估在这段时间内转化的样本占所有转化样本的比例，即
<span class="math inline">\(p(D \le 1 day|C=1, X=x) = p(C=1,D \le 1
day|X=x)/p(C=1|X=x)\)</span></li>
<li>则最终预估的概率是 <span class="math inline">\(p(C=1|X=x)=\)</span>,
即是上面两个模型预估值之比</li>
</ul></li>
<li>NAIVE: 不考虑样本的转化的回传延迟</li>
<li>SHIFTED：所有样本都等待30天后，确认每个样本的 label
都是准确后才把模型送入样本进行训练</li>
<li>ORACLE:
拥有上帝视角的模型，即在样本送入模型时就能知道这个样本最终是否会转化</li>
<li>RESCALE：与 NAIVE 一样，但是预估的 cvr 会除以一个常数，</li>
</ul>
<p>实验结果如下图所示，<strong>评估指标是平均 <a
target="_blank" rel="noopener" href="https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/">negative
log-likelihood</a>(NLL)，因为 NLL 比起AUC等指标更能反映预估 cvr
值的准确性</strong>。</p>
<figure>
<img src="https://wulc.me/imgs/DelayFeedBackExp.jpg" alt="exp" />
<figcaption aria-hidden="true">exp</figcaption>
</figure>
<p>实验中提供了两套评估数据集，overall 和
recent，前者是全集，后者则是专门针对新计划的，从实验结果来看，DFM
模型的预估结果次优于有上帝视角的 ORACLE 模型。</p>
<h2 id="小结-2">小结</h2>
<p>综上，paper
针对转化回传有延迟的问题提出了一种建模方法，建模的思想是不把还没观察到
conversion 的样本直接当做负样本去处理，而是考虑其距离当前 click
发生的时间长短给予模型不同权重的梯度。</p>
<p>除了之外，这个问题另一种思路就是直接用regression model
来建模回传延迟的时间。而转化回传的延迟除了会影响cvr模型的预估，<strong>还会影响以保成本为目标的
bidding 方式</strong>，即当前 conversion
还没回传时，不能直接认为没有conversion，而是要考虑一种更为平滑的 pacing
策略。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/" rel="tag"># 计算广告</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/01/Distillation%20%E7%AE%80%E4%BB%8B/" rel="prev" title="Distillation 简介">
      <i class="fa fa-chevron-left"></i> Distillation 简介
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/05/30/%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A1%A8%E7%A4%BA%E3%80%81%E8%BD%AC%E6%8D%A2%E4%B8%8E%E9%93%BE%E6%8E%A5-week1/" rel="next" title="程序的表示、转换与链接-week1">
      程序的表示、转换与链接-week1 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E5%BB%B6%E8%BF%9F%E5%BB%BA%E6%A8%A1"><span class="nav-number">1.</span> <span class="nav-text">为什么要对延迟建模</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E5%BB%BA%E6%A8%A1"><span class="nav-number">2.</span> <span class="nav-text">问题建模</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%B2%E8%A7%82%E5%AF%9F%E5%88%B0-conversion-%E7%9A%84%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BC%BC%E7%84%B6"><span class="nav-number">2.1.</span> <span class="nav-text">已观察到 conversion
的样本的似然</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AA%E8%A7%82%E5%AF%9F%E5%88%B0-conversion-%E7%9A%84%E6%A0%B7%E6%9C%AC%E7%9A%84%E4%BC%BC%E7%84%B6"><span class="nav-number">2.2.</span> <span class="nav-text">未观察到 conversion
的样本的似然</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">2.3.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A3"><span class="nav-number">3.</span> <span class="nav-text">问题求解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#em-%E7%AE%97%E6%B3%95"><span class="nav-number">3.1.</span> <span class="nav-text">EM 算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#joint-optimization"><span class="nav-number">3.2.</span> <span class="nav-text">Joint Optimization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93-1"><span class="nav-number">3.3.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93-2"><span class="nav-number">5.</span> <span class="nav-text">小结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="良超"
      src="/files/profile.jpg">
  <p class="site-author-name" itemprop="name">良超</p>
  <div class="site-description" itemprop="description">盈亏同源，享受生活的随机性</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">248</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">45</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/WuLC" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WuLC" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/wuliangchao/" title="LinkedIn → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;wuliangchao&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>LinkedIn</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liangchaowu5@gmail.com" title="E-Mail → mailto:liangchaowu5@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">良超</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
