<!doctypehtml><html lang=zh-CN><meta charset=UTF-8><meta content=width=device-width name=viewport><meta content=#222 name=theme-color><meta content="Hexo 7.3.0" name=generator><script charset=UTF-8 id=LA_COLLECT src=https://sdk.51.la/js-sdk-pro.min.js></script><script>LA.init({id: "JmI6QmP3fMkLet6B",ck: "JmI6QmP3fMkLet6B"})</script><link href=/imgs/favicon.ico rel=apple-touch-icon sizes=180x180><link href=/imgs/favicon.ico rel=icon sizes=32x32 type=image/png><link href=/imgs/favicon.ico rel=icon sizes=16x16 type=image/png><link color=#222 href=/imgs/favicon.ico rel=mask-icon><meta content=VcC-PHB4Om9SIR3Roqm7k1N-SHiBtQ6c3LJLVMKgU4U name=google-site-verification><meta content=cc79d2405dbf4293a4d12323dfb8ef24 name=msvalidate.01><meta content=z0l07oey8Mtx46FB name=baidu-site-verification><style>:root{--body-bg-color:#f5f7f9;--content-bg-color:#fff;--card-bg-color:#f5f5f5;--text-color:#555;--blockquote-color:#666;--link-color:#555;--link-hover-color:#222;--brand-color:#fff;--brand-hover-color:#fff;--table-row-odd-bg-color:#f9f9f9;--table-row-hover-bg-color:#f5f5f5;--menu-item-bg-color:#f5f5f5;--theme-color:#222;--btn-default-bg:#fff;--btn-default-color:#555;--btn-default-border-color:#555;--btn-default-hover-bg:#222;--btn-default-hover-color:#fff;--btn-default-hover-border-color:#222;--highlight-background:#f3f3f3;--highlight-foreground:#444;--highlight-gutter-background:#e1e1e1;--highlight-gutter-foreground:#555;color-scheme:light}html{line-height:1.15;-webkit-text-size-adjust:100%}details,main{display:block}pre{font-size:1em;overflow:auto;padding:10px}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:ButtonText dotted 1px}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}.table-container,textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}summary{display:list-item}[hidden],template{display:none}::selection{background:#262a30;color:#eee}body,html{height:100%}body{margin:0;background:var(--body-bg-color);box-sizing:border-box;color:var(--text-color);font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:1em;line-height:2;min-height:100%;position:relative;transition:padding .2s ease-in-out}h1,h2,h3,h4,h5,h6{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-weight:700;line-height:1.5;margin:30px 0 15px}h1{font-size:1.5em}h2{font-size:1.375em}h3{font-size:1.25em}h4{font-size:1.125em}h5{font-size:1em}h6{font-size:.875em}p{margin:0 0 20px}a{background:0 0;border-bottom:1px solid #999;color:var(--link-color);cursor:pointer;outline:0;text-decoration:none;overflow-wrap:break-word}a:hover{border-bottom-color:var(--link-hover-color);color:var(--link-hover-color)}embed,iframe,img,video{display:block;margin-left:auto;margin-right:auto;max-width:100%}hr{box-sizing:content-box;overflow:visible;background-image:repeating-linear-gradient(-45deg,#ddd,#ddd 4px,transparent 4px,transparent 8px);border:0;height:3px;margin:40px 0}blockquote{border-left:4px solid #ddd;color:var(--blockquote-color);margin:0;padding:0 15px}blockquote cite::before{content:'-';padding:0 5px}dt{font-weight:700}dd{margin:0;padding:0}table{border-collapse:collapse;border-spacing:0;font-size:.875em;margin:0 0 20px;width:100%}tbody tr:nth-of-type(odd){background:var(--table-row-odd-bg-color)}tbody tr:hover{background:var(--table-row-hover-bg-color)}caption,td,th{padding:8px}td,th{border:1px solid #ddd;border-bottom:3px solid #ddd}th{font-weight:700;padding-bottom:10px}td{border-bottom-width:1px}.btn{background:var(--btn-default-bg);border:2px solid var(--btn-default-border-color);border-radius:2px;color:var(--btn-default-color);display:inline-block;font-size:.875em;line-height:2;padding:0 20px;transition:background-color .2s ease-in-out}.btn:hover{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.btn+.btn{margin:0 0 8px 8px}.btn .fa-fw{text-align:left;width:1.285714285714286em}.toggle{line-height:0}.toggle .toggle-line{background:#fff;display:block;height:2px;left:0;position:relative;top:0;transition:.4s;width:100%}.toggle .toggle-line:first-child{margin-top:1px}.toggle .toggle-line:not(:first-child){margin-top:4px}.toggle.toggle-arrow :first-child{left:50%;top:2px;transform:rotate(45deg);width:50%}.toggle.toggle-arrow :last-child{left:50%;top:-2px;transform:rotate(-45deg);width:50%}.toggle.toggle-close :nth-child(2){opacity:0}.toggle.toggle-close :first-child{top:6px;transform:rotate(45deg)}.toggle.toggle-close :last-child{top:-6px;transform:rotate(-45deg)}/*!
  Theme: Default
  Description: Original highlight.js style
  Author: (c) Ivan Sagalaev <maniac@softwaremaniacs.org>
  Maintainer: @highlightjs/core-team
  Website: https://highlightjs.org/
  License: see project LICENSE
  Touched: 2021
*/pre code.hljs{display:block;overflow-x:auto;padding:1em}code.hljs{padding:3px 5px}.hljs{background:#f3f3f3;color:#444}.hljs-comment{color:#697070}.hljs-punctuation,.hljs-tag{color:#444a}.hljs-tag .hljs-attr,.hljs-tag .hljs-name{color:#444}.hljs-attribute,.hljs-doctag,.hljs-keyword,.hljs-meta .hljs-keyword,.hljs-name,.hljs-selector-tag{font-weight:700}.hljs-deletion,.hljs-number,.hljs-quote,.hljs-selector-class,.hljs-selector-id,.hljs-string,.hljs-template-tag,.hljs-type{color:#800}.hljs-section,.hljs-title{color:#800;font-weight:700}.hljs-link,.hljs-operator,.hljs-regexp,.hljs-selector-attr,.hljs-selector-pseudo,.hljs-symbol,.hljs-template-variable,.hljs-variable{color:#ab5656}.hljs-literal{color:#695}.hljs-addition,.hljs-built_in,.hljs-bullet,.hljs-code{color:#397300}.hljs-meta{color:#1f7199}.hljs-meta .hljs-string{color:#38a}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}.code-container:hover .copy-btn,.highlight:hover .copy-btn{opacity:1}.code-container{position:relative}.copy-btn{color:#333;cursor:pointer;line-height:1.6;opacity:0;padding:2px 6px;position:absolute;transition:opacity .2s ease-in-out;background:#fff;border:0;font-size:.8125em;right:0;top:0}code,figure.highlight,kbd,pre{background:var(--highlight-background);color:var(--highlight-foreground)}figure.highlight,pre{line-height:1.6;margin:0 auto 20px}figure.highlight figcaption,pre .caption,pre figcaption{background:var(--highlight-gutter-background);color:var(--highlight-foreground);display:flow-root;font-size:.875em;line-height:1.2;padding:.5em}figure.highlight figcaption a,pre .caption a,pre figcaption a{color:var(--highlight-foreground);float:right}figure.highlight figcaption a:hover,pre .caption a:hover,pre figcaption a:hover{border-bottom-color:var(--highlight-foreground)}code,pre{font-family:consolas,Menlo,monospace,'PingFang SC','Microsoft YaHei'}code{border-radius:3px;font-size:.875em;padding:2px 4px;overflow-wrap:break-word}kbd{border:2px solid #ccc;border-radius:.2em;box-shadow:.1em .1em .2em rgba(0,0,0,.1);font-family:inherit;padding:.1em .3em;white-space:nowrap}figure.highlight{overflow:auto;position:relative}figure.highlight pre{border:0;margin:0;padding:10px 0}figure.highlight table{border:0;margin:0;width:auto}figure.highlight td{border:0;padding:0}figure.highlight .gutter{-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;user-select:none}figure.highlight .gutter pre{background:var(--highlight-gutter-background);color:var(--highlight-gutter-foreground);padding-left:10px;padding-right:10px;text-align:right}figure.highlight .code pre{padding-left:10px;width:100%}figure.highlight .marked{background:rgba(0,0,0,.3)}pre .caption,pre figcaption{margin-bottom:10px}.gist table{width:auto}.gist table td{border:0}pre code{background:0 0;padding:0;text-shadow:none}.blockquote-center{border-left:0;margin:40px 0;padding:0;position:relative;text-align:center}.blockquote-center::after,.blockquote-center::before{left:0;line-height:1;opacity:.6;position:absolute;width:100%}.blockquote-center::before{border-top:1px solid #ccc;text-align:left;top:-20px;content:'\f10d';font-family:'Font Awesome 6 Free';font-weight:900}.blockquote-center::after{border-bottom:1px solid #ccc;bottom:-20px;text-align:right;content:'\f10e';font-family:'Font Awesome 6 Free';font-weight:900}.blockquote-center div,.blockquote-center p{text-align:center}.group-picture{margin-bottom:20px}.group-picture .group-picture-row{display:flex;gap:3px;margin-bottom:3px}.group-picture .group-picture-column{flex:1}.group-picture .group-picture-column img{height:100%;margin:0;object-fit:cover;width:100%}.post-body .label{color:#555;padding:0 2px}.post-body .label.default{background:#f0f0f0}.post-body .label.primary{background:#efe6f7}.post-body .label.info{background:#e5f2f8}.post-body .label.success{background:#e7f4e9}.post-body .label.warning{background:#fcf6e1}.post-body .label.danger{background:#fae8eb}.post-body .link-grid{display:grid;grid-gap:1.5rem;gap:1.5rem;grid-template-columns:1fr 1fr;margin-bottom:20px;padding:1rem}.post-body .link-grid .link-grid-container{border:solid #ddd;box-shadow:1rem 1rem .5rem rgba(0,0,0,.5);min-height:5rem;min-width:0;padding:.5rem;position:relative;transition:background .3s}.post-body .link-grid .link-grid-container:hover{animation:.5s next-shake;background:var(--card-bg-color)}.post-body .link-grid .link-grid-container:active{box-shadow:.5rem .5rem .25rem rgba(0,0,0,.5);transform:translate(.2rem,.2rem)}.post-body .link-grid .link-grid-container .link-grid-image{border:1px solid #ddd;border-radius:50%;box-sizing:border-box;height:5rem;padding:3px;position:absolute;width:5rem}.post-body .link-grid .link-grid-container p{margin:0 1rem 0 6rem}.post-body .link-grid .link-grid-container p:first-of-type{font-size:1.2em}.post-body .link-grid .link-grid-container p:last-of-type{font-size:.8em;line-height:1.3rem;opacity:.7}.post-body .link-grid .link-grid-container a{border:0;height:100%;left:0;position:absolute;top:0;width:100%}@keyframes next-shake{0%{transform:translate(1pt,1pt) rotate(0)}10%{transform:translate(-1pt,-2pt) rotate(-1deg)}20%{transform:translate(-3pt,0) rotate(1deg)}30%{transform:translate(3pt,2pt) rotate(0)}40%{transform:translate(1pt,-1pt) rotate(1deg)}50%{transform:translate(-1pt,2pt) rotate(-1deg)}60%{transform:translate(-3pt,1pt) rotate(0)}70%{transform:translate(3pt,1pt) rotate(-1deg)}80%{transform:translate(-1pt,-1pt) rotate(1deg)}90%{transform:translate(1pt,2pt) rotate(0)}100%{transform:translate(1pt,-2pt) rotate(-1deg)}}.post-body .note{border-radius:3px;margin-bottom:20px;padding:1em;position:relative;border:1px solid #eee;border-left-width:5px}.post-body .note summary{cursor:pointer;outline:0}.post-body .note summary p{display:inline}.post-body .note h2,.post-body .note h3,.post-body .note h4,.post-body .note h5,.post-body .note h6{border-bottom:initial;margin:0;padding-top:0}.post-body .note :first-child{margin-top:0}.post-body .note :last-child{margin-bottom:0}.post-body .note.default{border-left-color:#777}.post-body .note.default h2,.post-body .note.default h3,.post-body .note.default h4,.post-body .note.default h5,.post-body .note.default h6{color:#777}.post-body .note.primary{border-left-color:#6f42c1}.post-body .note.primary h2,.post-body .note.primary h3,.post-body .note.primary h4,.post-body .note.primary h5,.post-body .note.primary h6{color:#6f42c1}.post-body .note.info{border-left-color:#428bca}.post-body .note.info h2,.post-body .note.info h3,.post-body .note.info h4,.post-body .note.info h5,.post-body .note.info h6{color:#428bca}.post-body .note.success{border-left-color:#5cb85c}.post-body .note.success h2,.post-body .note.success h3,.post-body .note.success h4,.post-body .note.success h5,.post-body .note.success h6{color:#5cb85c}.post-body .note.warning{border-left-color:#f0ad4e}.post-body .note.warning h2,.post-body .note.warning h3,.post-body .note.warning h4,.post-body .note.warning h5,.post-body .note.warning h6{color:#f0ad4e}.post-body .note.danger{border-left-color:#d9534f}.post-body .note.danger h2,.post-body .note.danger h3,.post-body .note.danger h4,.post-body .note.danger h5,.post-body .note.danger h6{color:#d9534f}.post-body .tabs{margin-bottom:20px}.post-body .tabs,.tabs-comment{padding-top:10px}.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{background:var(--content-bg-color);display:flex;display:flex;flex-wrap:wrap;justify-content:center;margin:0;padding:0;position:-webkit-sticky;position:sticky;top:0;z-index:5}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border-bottom:1px solid #ddd;border-left:1px solid transparent;border-right:1px solid transparent;border-radius:0;border-top:3px solid transparent;flex-grow:1;list-style-type:none}@media (max-width:413px){.post-body .tabs ul.nav-tabs,.tabs-comment ul.nav-tabs{display:block;margin-bottom:5px}.post-body .tabs ul.nav-tabs li.tab,.tabs-comment ul.nav-tabs li.tab{border-bottom:1px solid transparent;border-left:3px solid transparent;border-right:1px solid transparent;border-top:1px solid transparent;border-radius:0}}.post-body .tabs ul.nav-tabs li.tab a,.tabs-comment ul.nav-tabs li.tab a{border-bottom:initial;display:block;line-height:1.8;padding:.25em .75em;text-align:center;transition:.2s ease-out}.post-body .tabs ul.nav-tabs li.tab a i[class^=fa],.tabs-comment ul.nav-tabs li.tab a i[class^=fa]{width:1.285714285714286em}.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#fc6423 #ddd transparent}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab.active,.tabs-comment ul.nav-tabs li.tab.active{border-color:#ddd #ddd #ddd #fc6423}}.post-body .tabs ul.nav-tabs li.tab.active a,.tabs-comment ul.nav-tabs li.tab.active a{cursor:default}.post-body .tabs .tab-content,.tabs-comment .tab-content{border:1px solid #ddd;border-radius:0;border-top-color:transparent}@media (max-width:413px){.post-body .tabs .tab-content,.tabs-comment .tab-content{border-radius:0;border-top-color:#ddd}}.post-body .tabs .tab-content .tab-pane,.tabs-comment .tab-content .tab-pane{padding:20px 20px 0}.post-body .tabs .tab-content .tab-pane:not(.active),.tabs-comment .tab-content .tab-pane:not(.active){display:none}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{display:inline-block;margin:-1px 10px 0;padding:0 10px}.pagination .page-number.current{background:#ccc;border-color:#ccc;color:var(--content-bg-color)}.pagination{border-top:1px solid #eee;margin:120px 0 0;text-align:center}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:0;border-top:1px solid #eee;transition:border-color .2s ease-in-out}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-top-color:var(--link-hover-color)}@media (max-width:767px){.post-body .link-grid{grid-template-columns:1fr}.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:0 5px}.pagination{border-top:0}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:1px solid #eee;border-top:0}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-bottom-color:var(--link-hover-color)}.site-meta{text-align:center}}.pagination .space{margin:0;padding:0}.comments{margin-top:60px;overflow:hidden}.comment-button-group{display:flex;display:flex;flex-wrap:wrap;justify-content:center;justify-content:center;margin:1em 0}.comment-button-group .comment-button{margin:.1em .2em}.comment-button-group .comment-button.active{background:var(--btn-default-hover-bg);border-color:var(--btn-default-hover-border-color);color:var(--btn-default-hover-color)}.comment-position{display:none}.comment-position.active{display:block}.tabs-comment{margin-top:4em;padding-top:0}.tabs-comment .comments{margin-top:0;padding-top:0}.headband{background:var(--theme-color);height:3px}@media (max-width:991px){.headband{display:none}}.site-brand-container{display:flex;flex-shrink:0;padding:0 10px}.use-motion .column,.use-motion .site-brand-container .toggle{opacity:0}.site-meta{flex-grow:1;text-align:center}.custom-logo-image{margin-top:20px}@media (max-width:991px){.custom-logo-image{display:none}}.brand{border-bottom:0;color:var(--brand-color);display:inline-block;padding:0}.brand:hover{color:var(--brand-hover-color)}.site-title{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:1.375em;font-weight:400;line-height:1.5;margin:0}.site-subtitle{color:#ddd;font-size:.8125em;margin:10px 10px 0}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:0;position:relative;top:-10px}.site-nav-right,.site-nav-toggle{display:none}.site-nav-right .toggle,.site-nav-toggle .toggle{color:var(--text-color);padding:10px;width:22px}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:var(--text-color);border-radius:1px}@media (max-width:767px){.site-nav-right,.site-nav-toggle{display:flex;flex-direction:column;justify-content:center}.site-nav{--scroll-height:0;height:0;overflow:hidden;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu{margin:0;padding:1em 0;text-align:center}.menu-item{display:inline-block;list-style:none;margin:0 10px}@media (max-width:767px){.menu-item{display:block;margin-top:10px}.menu-item.menu-item-search{display:none}}.menu-item a{border-bottom:0;display:block;font-size:.8125em;transition:border-color .2s ease-in-out}.menu-item a.menu-item-active,.menu-item a:hover{background:var(--menu-item-bg-color)}.menu-item i[class^=fa]{margin-right:8px}.menu-item .badge{background:#ccc;border-radius:10px;color:var(--content-bg-color);font-weight:700;line-height:1;margin-left:.35em;padding:2px 5px;text-shadow:1px 1px 0 rgba(0,0,0,.1)}.use-motion .menu-item{visibility:hidden}@media (max-width:991px){.sidebar{left:-320px;background:#222;bottom:0;box-shadow:inset 0 2px 6px #000;max-height:100vh;overflow-y:auto;position:fixed;top:0;transition:.2s ease-out;width:320px;z-index:20}.sidebar-active .sidebar{left:0}.sidebar a{border-bottom-color:#555;color:#999}.sidebar a:hover{border-bottom-color:#eee;color:#eee}.links-of-author:not(:first-child){margin-top:15px}.links-of-author a{border-bottom-color:#555;display:inline-block;margin-bottom:10px;margin-right:10px;vertical-align:middle}.links-of-author a::before{background:#ffff4f;display:inline-block;margin-right:3px;transform:translateY(-2px);border-radius:50%;content:' ';height:4px;width:4px}.links-of-blogroll-item{padding:2px 10px}.links-of-blogroll-item a{box-sizing:border-box;display:inline-block;max-width:280px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.popular-posts .popular-posts-item .popular-posts-link:hover{background:0 0}.sidebar-dimmer{background:#000;height:100%;left:0;opacity:0;position:fixed;top:0;transition:visibility .4s,opacity .4s;visibility:hidden;width:100%;z-index:10}.sidebar-active .sidebar-dimmer{opacity:.7;visibility:visible}}.sidebar-inner{color:#999;padding:18px 10px;text-align:center;display:flex;flex-direction:column;justify-content:center}.cc-license .cc-opacity{border-bottom:0;opacity:.7}.cc-license .cc-opacity:hover{opacity:.9}.cc-license img{display:inline-block}.site-author-image{border:1px solid #eee;max-width:120px;padding:2px}.site-author-name{color:var(--text-color);font-weight:600;margin:0}.site-description{color:#999;font-size:.8125em;margin-top:0}.links-of-author a{font-size:.8125em}.links-of-author i[class^=fa]{margin-right:2px}.sidebar .sidebar-button:not(:first-child){margin-top:15px}.sidebar .sidebar-button button{background:0 0;color:#fc6423;cursor:pointer;line-height:2;padding:0 15px;border:1px solid #fc6423;border-radius:4px}.sidebar .sidebar-button button:hover{background:#fc6423;color:#fff}.sidebar .sidebar-button button i[class^=fa]{margin-right:5px}.links-of-blogroll{font-size:.8125em}.links-of-blogroll-title{font-size:.875em;font-weight:600}.links-of-blogroll-list{list-style:none;margin:0;padding:0}.sidebar-nav{font-size:.875em;height:0;margin:0;overflow:hidden;padding-left:0;pointer-events:none;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}.sidebar-nav-active .sidebar-nav{height:calc(2em + 1px);pointer-events:unset;visibility:unset}.sidebar-nav li{border-bottom:1px solid transparent;color:var(--text-color);cursor:pointer;display:inline-block;transition:border-bottom-color .2s ease-in-out,color .2s ease-in-out}.sidebar-nav li.sidebar-nav-overview{margin-left:10px}.sidebar-nav li:hover{color:#fc6423}.sidebar-overview-active .sidebar-nav-overview,.sidebar-toc-active .sidebar-nav-toc{border-bottom-color:#fc6423;color:#fc6423;transition-delay:0.2s}.sidebar-overview-active .sidebar-nav-overview:hover,.sidebar-toc-active .sidebar-nav-toc:hover{color:#fc6423}.sidebar-panel-container{align-items:start;display:grid;flex:1;overflow-x:hidden;overflow-y:auto;padding-top:0;transition:padding-top .2s ease-in-out}.sidebar-nav-active .sidebar-panel-container{padding-top:20px}.sidebar-panel{animation:.2s ease-in-out deactivate-sidebar-panel;grid-area:1/1;height:0;opacity:0;overflow:hidden;pointer-events:none;transform:translateY(0);transition:.2s ease-in-out;transition-property:opacity,transform,visibility;visibility:hidden}.sidebar-nav-active .sidebar-panel,.sidebar-overview-active .sidebar-panel.post-toc-wrap{transform:translateY(-20px)}.sidebar-overview-active:not(.sidebar-nav-active) .sidebar-panel.post-toc-wrap{transition-delay:0s,0.2s,0s}.sidebar-overview-active .sidebar-panel.site-overview-wrap,.sidebar-toc-active .sidebar-panel.post-toc-wrap{animation-name:activate-sidebar-panel;height:auto;opacity:1;pointer-events:unset;transform:translateY(0);transition-delay:0.2s,0.2s,0s;visibility:unset}.sidebar-panel.site-overview-wrap{display:flex;flex-direction:column;justify-content:center;gap:10px;justify-content:flex-start}@keyframes deactivate-sidebar-panel{from{height:var(--inactive-panel-height,0)}to{height:var(--active-panel-height,0)}}@keyframes activate-sidebar-panel{from{height:var(--inactive-panel-height,auto)}to{height:var(--active-panel-height,auto)}}.sidebar-toggle{bottom:61px;height:16px;padding:5px;width:16px;background:#222;cursor:pointer;opacity:.6;position:fixed;z-index:30;left:30px}.sidebar-toggle:hover{opacity:.8}@media (max-width:991px){.sidebar-toggle{left:20px;opacity:.8}}.sidebar-toggle:hover .toggle-line{background:#fc6423}@media (any-hover:hover){body:not(.sidebar-active) .sidebar-toggle:hover :first-child{left:50%;top:2px;transform:rotate(45deg);width:50%}body:not(.sidebar-active) .sidebar-toggle:hover :last-child{left:50%;top:-2px;transform:rotate(-45deg);width:50%}}.sidebar-active .sidebar-toggle :nth-child(2){opacity:0}.sidebar-active .sidebar-toggle :first-child{top:6px;transform:rotate(45deg)}.sidebar-active .sidebar-toggle :last-child{top:-6px;transform:rotate(-45deg)}.post-toc{font-size:.875em}.post-toc ol{list-style:none;margin:0;padding:0 2px 0 10px;text-align:left}.post-toc ol>:last-child{margin-bottom:5px}.post-toc ol>ol{padding-left:0}.post-toc ol a{transition:.2s ease-in-out}.post-toc .nav-item{line-height:1.8;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.post-toc .nav .nav-child{--height:0;height:0;opacity:0;overflow:hidden;transition:.2s ease-in-out;visibility:hidden}.post-toc .nav .active>.nav-child{height:var(--height,auto);opacity:1;visibility:unset}.post-toc .nav .active>a{border-bottom-color:#fc6423;color:#fc6423}.post-toc .nav .active-current>a,.post-toc .nav .active-current>a:hover{color:#fc6423}.site-state{display:flex;flex-wrap:wrap;justify-content:center;line-height:1.4}.site-state-item{padding:0 15px}.site-state-item a{border-bottom:0;display:block}.site-state-item-count{display:block;font-size:1em;font-weight:600}.site-state-item-name{color:#999;font-size:.8125em}.footer{color:#999;font-size:.875em;padding:20px 0;transition:left .2s ease-in-out,right .2s ease-in-out}.footer.footer-fixed{bottom:0;left:0;position:absolute;right:0}.footer-inner{box-sizing:border-box;text-align:center;display:flex;flex-direction:column;justify-content:center;margin:0 auto;width:calc(100% - 20px)}@media (max-width:767px){.footer-inner{width:auto}}@media (min-width:1200px){.footer-inner{width:1160px}}@media (min-width:1600px){.footer-inner{width:73%}}.use-motion .footer{opacity:0}.languages{display:inline-block;font-size:1.125em;position:relative}.languages .lang-select-label span{margin:0 .5em}.languages .lang-select{height:100%;left:0;opacity:0;position:absolute;top:0;width:100%}.with-love{display:inline-block;margin:0 5px}@keyframes icon-animate{0%,100%{transform:scale(1)}10%,30%{transform:scale(.9)}20%,40%,50%,60%,70%,80%{transform:scale(1.1)}}.back-to-top{font-size:12px;align-items:center;bottom:-100px;color:#fff;display:flex;height:26px;transition:bottom .2s ease-in-out;background:#222;cursor:pointer;opacity:.6;position:fixed;z-index:30;left:30px}.back-to-top span{margin-right:8px}.back-to-top .fa{text-align:center;width:26px}.back-to-top:hover{opacity:.8;color:#fc6423}@media (max-width:991px){.back-to-top{left:20px;opacity:.8}}.back-to-top.back-to-top-on{bottom:30px}.reading-progress-bar{--progress:0;background:#37c6c0;height:3px;position:fixed;z-index:50;width:var(--progress);left:0;top:0}.rtl.post-body a,.rtl.post-body h1,.rtl.post-body h2,.rtl.post-body h3,.rtl.post-body h4,.rtl.post-body h5,.rtl.post-body h6,.rtl.post-body li,.rtl.post-body ol,.rtl.post-body p,.rtl.post-body ul{direction:rtl;font-family:UKIJ Ekran}.rtl.post-title{font-family:UKIJ Ekran}.post-button{margin-top:40px;text-align:center}.use-motion .collection-header,.use-motion .comments,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{visibility:hidden}.posts-collapse .post-content{margin-bottom:35px;margin-left:35px;position:relative}@media (max-width:767px){.posts-collapse .post-content{margin-left:0;margin-right:0}}.posts-collapse .post-content .collection-title{font-size:1.125em;position:relative}.posts-collapse .post-content .collection-title::before{background:#999;border:1px solid #fff;margin-left:-6px;margin-top:-4px;position:absolute;top:50%;border-radius:50%;content:' ';height:10px;width:10px}.posts-collapse .post-content .collection-year{font-size:1.5em;font-weight:700;margin:60px 0;position:relative}.posts-collapse .post-content .collection-year .collection-year-count{font-size:.75em;background:#ccc;border-radius:10px;color:var(--content-bg-color);font-weight:700;line-height:1;margin-left:.35em;padding:2px 5px;text-shadow:1px 1px 0 rgba(0,0,0,.1)}.posts-collapse .post-content .collection-year::before{background:#bbb;margin-left:-4px;margin-top:-4px;position:absolute;top:50%;border-radius:50%;content:' ';height:8px;width:8px}.posts-collapse .post-content .collection-header{display:block;margin-left:20px}.posts-collapse .post-content .collection-header small{color:#bbb;margin-left:5px}.posts-collapse .post-content .post-header{border-bottom:1px dashed #ccc;margin:30px 2px 0;padding-left:15px;position:relative;transition:border .2s ease-in-out}.posts-collapse .post-content .post-header::before{background:#bbb;border:1px solid #fff;left:-6px;position:absolute;top:.75em;transition:background .2s ease-in-out;border-radius:50%;content:' ';height:6px;width:6px}.posts-collapse .post-content .post-header:hover{border-bottom-color:#666}.posts-collapse .post-content .post-header:hover::before{background:#222}.posts-collapse .post-content .post-meta-container{display:inline;font-size:.75em;margin-right:10px}.posts-collapse .post-content .post-title{display:inline}.posts-collapse .post-content .post-title a{border-bottom:0;color:var(--link-color)}.posts-collapse .post-content .post-title .fa{font-size:.875em;margin-left:5px}.posts-collapse .post-content::before{background:#f5f5f5;content:' ';height:100%;margin-left:-2px;position:absolute;top:1.25em;width:4px}.post-body{font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;overflow-wrap:break-word}@media (min-width:1200px){.post-body{font-size:1.125em}}@media (min-width:992px){.post-body{text-align:justify}}.post-body h1 .header-anchor,.post-body h1 .headerlink,.post-body h2 .header-anchor,.post-body h2 .headerlink,.post-body h3 .header-anchor,.post-body h3 .headerlink,.post-body h4 .header-anchor,.post-body h4 .headerlink,.post-body h5 .header-anchor,.post-body h5 .headerlink,.post-body h6 .header-anchor,.post-body h6 .headerlink{border-bottom-style:none;color:inherit;float:right;font-size:.875em;margin-left:10px;opacity:0}.post-body h1 .header-anchor::before,.post-body h1 .headerlink::before,.post-body h2 .header-anchor::before,.post-body h2 .headerlink::before,.post-body h3 .header-anchor::before,.post-body h3 .headerlink::before,.post-body h4 .header-anchor::before,.post-body h4 .headerlink::before,.post-body h5 .header-anchor::before,.post-body h5 .headerlink::before,.post-body h6 .header-anchor::before,.post-body h6 .headerlink::before{content:'\f0c1';font-family:'Font Awesome 6 Free';font-weight:900}.post-body h1:hover .header-anchor,.post-body h1:hover .headerlink,.post-body h2:hover .header-anchor,.post-body h2:hover .headerlink,.post-body h3:hover .header-anchor,.post-body h3:hover .headerlink,.post-body h4:hover .header-anchor,.post-body h4:hover .headerlink,.post-body h5:hover .header-anchor,.post-body h5:hover .headerlink,.post-body h6:hover .header-anchor,.post-body h6:hover .headerlink{opacity:.5}.post-body h1:hover .header-anchor:hover,.post-body h1:hover .headerlink:hover,.post-body h2:hover .header-anchor:hover,.post-body h2:hover .headerlink:hover,.post-body h3:hover .header-anchor:hover,.post-body h3:hover .headerlink:hover,.post-body h4:hover .header-anchor:hover,.post-body h4:hover .headerlink:hover,.post-body h5:hover .header-anchor:hover,.post-body h5:hover .headerlink:hover,.post-body h6:hover .header-anchor:hover,.post-body h6:hover .headerlink:hover{opacity:1}.post-body .exturl .fa{font-size:.875em;margin-left:4px}.post-body .fancybox+figcaption,.post-body img+figcaption{color:#999;font-size:.875em;font-weight:700;line-height:1;margin:-15px auto 15px;text-align:center}.post-body embed,.post-body iframe,.post-body img,.post-body video{margin-bottom:20px}.post-body .video-container{height:0;margin-bottom:20px;overflow:hidden;padding-top:75%;position:relative;width:100%}.post-body .video-container embed,.post-body .video-container iframe,.post-body .video-container object{height:100%;left:0;margin:0;position:absolute;top:0;width:100%}.post-gallery{display:flex;min-height:200px}.post-gallery .post-gallery-image{flex:1}.post-gallery .post-gallery-image:not(:first-child){clip-path:polygon(40px 0,100% 0,100% 100%,0 100%);margin-left:-20px}.post-gallery .post-gallery-image:not(:last-child){margin-right:-20px}.post-gallery .post-gallery-image img{height:100%;object-fit:cover;opacity:1;width:100%}.posts-expand .post-gallery{margin-bottom:60px}.posts-collapse .post-gallery{margin:15px 0}.posts-expand .post-header{font-size:1.125em;margin-bottom:60px;text-align:center}.posts-expand .post-title{font-size:1.5em;font-weight:400;margin:initial;overflow-wrap:break-word}.posts-expand .post-title-link{border-bottom:0;color:var(--link-color);display:inline-block;position:relative}.posts-expand .post-title-link::before{background:var(--link-color);bottom:0;content:'';height:2px;left:0;position:absolute;transform:scaleX(0);transition:transform .2s ease-in-out;width:100%}.posts-expand .post-title-link:hover::before{transform:scaleX(1)}.posts-expand .post-title-link .fa{font-size:.875em;margin-left:5px}.post-sticky-flag{display:inline-block;margin-right:8px;transform:rotate(30deg)}.posts-expand .post-meta-container{color:#999;font-family:Lato,'PingFang SC','Microsoft YaHei',sans-serif;font-size:.75em;margin-top:3px}.posts-expand .post-meta-container .post-description{font-size:.875em;margin-top:2px}.posts-expand .post-meta-container time{border-bottom:1px dashed #999}.post-meta{display:flex;flex-wrap:wrap;justify-content:center}:not(.post-meta-break)+.post-meta-item::before{content:'|';margin:0 .5em}.post-meta-item-icon{margin-right:3px}@media (max-width:991px){.post-body{text-align:justify}.post-meta-item-text{display:none}}.post-meta-break{flex-basis:100%;height:0}.post-nav{border-top:1px solid #eee;display:flex;gap:30px;justify-content:space-between;margin-top:1em;padding:10px 5px 0}.post-nav-item{flex:1}.post-nav-item a{border-bottom:0;display:block;font-size:.875em;line-height:1.6}.post-nav-item a:active{top:2px}.post-nav-item .fa{font-size:.75em}.post-nav-item:first-child .fa{margin-right:5px}.post-nav-item:last-child{text-align:right}.post-nav-item:last-child .fa{margin-left:5px}.post-footer{display:flex;flex-direction:column;justify-content:center}.post-eof{background:#ccc;height:1px;margin:80px auto 60px;width:8%}.post-block:last-of-type .post-eof{display:none}.post-copyright ul{list-style:none;overflow:hidden;padding:.5em 1em;position:relative;background:var(--card-bg-color);border-left:3px solid #ff2a2a;margin:1em 0 0}.post-copyright ul::after{content:'\f25e';font-family:'Font Awesome 6 Brands';font-size:200px;opacity:.1;position:absolute;right:-50px;top:-150px}.post-tags{margin-top:40px;text-align:center}.post-tags a{display:inline-block;font-size:.8125em}.post-tags a:not(:last-child){margin-right:10px}.social-like{border-top:1px solid #eee;font-size:.875em;margin-top:1em;padding-top:1em;display:flex;flex-wrap:wrap;justify-content:center}.social-like a{border-bottom:none}.reward-container{margin:1em 0 0;padding:1em 0;text-align:center}.reward-container button{background:0 0;color:#fc6423;cursor:pointer;line-height:2;padding:0 15px;border:2px solid #fc6423;border-radius:2px;outline:0;transition:.2s ease-in-out;vertical-align:text-top}.reward-container button:hover{background:#fc6423;color:#fff}.post-reward{display:none;padding-top:20px}.post-reward.active{display:block}.post-reward div{display:inline-block}.post-reward div span{display:block}.post-reward img{display:inline-block;margin:.8em 2em 0;max-width:100%;width:180px}@keyframes next-roll{from{transform:rotateZ(30deg)}to{transform:rotateZ(-30deg)}}.category-all-page .category-all-title{text-align:center}.category-all-page .category-all{margin-top:20px}.category-all-page .category-list{list-style:none;margin:0;padding:0}.category-all-page .category-list-item{margin:5px 10px}.category-all-page .category-list-count{font-size:.75em;background:#ccc;border-radius:10px;color:var(--content-bg-color);font-weight:700;line-height:1;margin-left:.35em;padding:2px 5px;text-shadow:1px 1px 0 rgba(0,0,0,.1)}.category-all-page .category-list-child{padding-left:10px}.event-list hr{background:#222;margin:20px 0 45px}.event-list hr::after{background:#222;color:#fff;content:'NOW';display:inline-block;font-weight:700;padding:0 5px}.event-list .event{--event-background:#222;--event-foreground:#bbb;--event-title:#fff;background:var(--event-background);padding:15px}.event-list .event .event-summary{border-bottom:0;color:var(--event-title);margin:0;padding:0 0 0 35px;position:relative}.event-list .event .event-summary::before{animation:1s ease-in-out infinite alternate dot-flash;background:var(--event-title);left:0;margin-top:-6px;position:absolute;top:50%;border-radius:50%;content:' ';height:12px;width:12px}.event-list .event:nth-of-type(odd) .event-summary::before{animation-delay:.5s}.event-list .event:not(:last-child){margin-bottom:20px}.event-list .event .event-relative-time{color:var(--event-foreground);display:inline-block;font-size:12px;font-weight:400;padding-left:12px}.event-list .event .event-details{color:var(--event-foreground);display:block;line-height:18px;padding:6px 0 6px 35px}.event-list .event .event-details::before{color:var(--event-foreground);display:inline-block;margin-right:9px;width:14px;font-family:'Font Awesome 6 Free';font-weight:900}.event-list .event .event-details.event-location::before{content:'\f041'}.event-list .event .event-details.event-duration::before{content:'\f017'}.event-list .event .event-details.event-description::before{content:'\f024'}.event-list .event-past{--event-background:#f5f5f5;--event-foreground:#999;--event-title:#222}@keyframes dot-flash{from{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}ul.breadcrumb{font-size:.75em;list-style:none;margin:1em 0;padding:0 2em;text-align:center}ul.breadcrumb li{display:inline}ul.breadcrumb li:not(:first-child)::before{content:'/\00a0';font-weight:400;padding:.5em}ul.breadcrumb li:last-child{font-weight:700}.tag-cloud{text-align:center}.tag-cloud a{display:inline-block;margin:10px}.tag-cloud-0{border-bottom-color:#aaa;color:#aaa}.tag-cloud-1{border-bottom-color:#9a9a9a;color:#9a9a9a}.tag-cloud-2{border-bottom-color:#8b8b8b;color:#8b8b8b}.tag-cloud-3{border-bottom-color:#7c7c7c;color:#7c7c7c}.tag-cloud-4{border-bottom-color:#6c6c6c;color:#6c6c6c}.tag-cloud-5{border-bottom-color:#5d5d5d;color:#5d5d5d}.tag-cloud-6{border-bottom-color:#4e4e4e;color:#4e4e4e}.tag-cloud-7{border-bottom-color:#3e3e3e;color:#3e3e3e}.tag-cloud-8{border-bottom-color:#2f2f2f;color:#2f2f2f}.tag-cloud-9{border-bottom-color:#202020;color:#202020}.tag-cloud-10{border-bottom-color:#111;color:#111}.search-active{overflow:hidden}.search-pop-overlay{background:rgba(0,0,0,0);display:flex;height:100%;left:0;position:fixed;top:0;transition:visibility .4s,background .4s;visibility:hidden;width:100%;z-index:40}.search-active .search-pop-overlay{background:rgba(0,0,0,.3);visibility:visible}.search-popup{background:var(--card-bg-color);border-radius:5px;height:80%;margin:auto;transform:scale(0);transition:transform .4s;width:700px}.search-active .search-popup{transform:scale(1)}@media (max-width:767px){.search-popup{border-radius:0;height:100%;width:100%}}.search-popup .popup-btn-close,.search-popup .search-icon{color:#999;font-size:18px;padding:0 10px}.search-popup .popup-btn-close{cursor:pointer}.search-popup .popup-btn-close:hover .fa{color:#222}.search-popup .search-header{background:#eee;border-top-left-radius:5px;border-top-right-radius:5px;display:flex;padding:5px}.search-popup input.search-input{background:0 0;border:0;outline:0;width:100%}.search-popup input.search-input::-webkit-search-cancel-button{display:none}.search-popup .search-result-container{height:calc(100% - 55px);overflow:auto;padding:5px 25px}.search-popup .search-result-container hr{margin:5px 0 10px}.search-popup .search-result-container hr:first-child{display:none}.search-popup .search-result-list{margin:0 5px;padding:0;width:100%}.search-popup a.search-result-title{font-weight:700}.search-popup p.search-result{border-bottom:1px dashed #ccc;padding:5px 0}.search-popup .search-input-container{flex-grow:1;padding:2px}.search-popup .no-result{display:flex}.search-popup .search-result-icon{color:#ccc;margin:auto}mark.search-keyword{background:0 0;border-bottom:1px dashed #ff2a2a;color:#ff2a2a;font-weight:700}.has-jax,mjx-container[jax=CHTML][display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}.use-motion .animated{animation-fill-mode:none;visibility:inherit}.use-motion .sidebar .animated{animation-fill-mode:both}header.header{background:var(--content-bg-color);border-radius:initial;box-shadow:initial}.main{align-items:stretch;display:flex;justify-content:space-between;margin:0 auto;width:calc(100% - 20px)}@media (max-width:767px){.main{width:auto}}@media (min-width:1200px){.main{width:1160px}}@media (min-width:1600px){.main{width:73%}}@media (max-width:991px){header.header{border-radius:initial}.main{display:block;width:auto}}.main-inner{border-radius:initial;box-sizing:border-box;width:calc(100% - 252px)}.footer-inner{padding-left:252px}@media (max-width:991px){.main-inner{border-radius:initial;width:100%}.footer-inner{padding-left:0;padding-right:0;width:auto}}.column{width:240px}.site-brand-container{background:var(--theme-color)}.site-meta{padding:20px 0}.site-nav-right .toggle,.site-nav-toggle .toggle{color:#fff}.site-nav-right .toggle .toggle-line,.site-nav-toggle .toggle .toggle-line{background:#fff}@media (min-width:768px) and (max-width:991px){.site-nav-right,.site-nav-toggle{display:flex;flex-direction:column;justify-content:center}.site-nav{--scroll-height:0;height:0;overflow:hidden;transition:height .2s ease-in-out,visibility .2s ease-in-out;visibility:hidden}body:not(.site-nav-on) .site-nav .animated{animation:none}body.site-nav-on .site-nav{height:var(--scroll-height);visibility:unset}}.menu .menu-item{display:block;margin:0}.menu .menu-item a{padding:5px 20px;transition-property:background-color;display:flex;align-items:center}.menu .menu-item a .badge{margin-left:auto}@media (max-width:991px){.column{width:auto}.site-nav-on .site-brand-container{box-shadow:0 0 16px rgba(0,0,0,.5)}.menu .menu-item.menu-item-search{display:none}}.main-menu .menu-item-active::after{background:#bbb;border-radius:50%;content:' ';height:6px;margin-top:-3px;position:absolute;right:15px;top:50%;width:6px}.sub-menu{margin:0;padding:6px 0}.sub-menu .menu-item{display:inline-block}.sub-menu .menu-item a{background:0 0;margin:5px 10px;padding:initial}.sub-menu .menu-item a:hover{background:0 0;color:#fc6423}.sub-menu .menu-item-active{border-bottom-color:#fc6423;color:#fc6423}.sub-menu .menu-item-active:hover{border-bottom-color:#fc6423}@media (min-width:992px){.sidebar{position:-webkit-sticky;position:sticky;top:12px}.sidebar-toggle{display:none}.sidebar-inner{background:var(--content-bg-color);border-radius:initial;box-shadow:initial;box-sizing:border-box;color:var(--text-color);margin-top:12px;max-height:calc(100vh - 24px);visibility:hidden}.site-state-item{padding:0 10px}.sidebar .sidebar-button{border-bottom:1px dotted #ccc;border-top:1px dotted #ccc}.sidebar .sidebar-button button{border:0;color:#fc6423;display:block;width:100%}.sidebar .sidebar-button button:hover{background:0 0;border:0;color:#e34603}.links-of-author{display:flex;flex-wrap:wrap;justify-content:center}.links-of-author-item{margin:5px 0 0;width:50%}.links-of-author-item a{box-sizing:border-box;max-width:100%;overflow:hidden;padding:0 5px;text-overflow:ellipsis;white-space:nowrap;border-bottom:0;border-radius:4px;display:block}.links-of-author-item a:hover{background:var(--body-bg-color)}}.main-inner{background:var(--content-bg-color);box-shadow:initial;padding:40px}@media (max-width:991px){.main-inner{padding:20px}}.sub-menu{border-bottom:1px solid #ddd}.post-block:first-of-type{padding-top:40px}@media (max-width:767px){.pagination{margin-bottom:10px}}@media (min-width:992px) and (max-width:991px){.sidebar{display:none}}</style><link crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css integrity=sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA= rel=stylesheet><link crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css integrity=sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE= rel=stylesheet><link crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css integrity=sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w= rel=stylesheet><script class=next-config data-name=main type=application/json>{"hostname":"wulc.me","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":true,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src=/js/config.js></script><meta content="本文主要介绍 CTR 预估中常用的一些模型，主要是非深度学习模型，包括 LR、GBDT+LR、FM/FFM、MLR。每个模型会简单介绍其原理、论文出处以及其一些开源实现。" name=description><meta content=article property=og:type><meta content="CTR 预估模型简介 -- 非深度学习篇" property=og:title><meta content=https://wulc.me/2018/07/15/CTR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B--%E9%9D%9E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/index.html property=og:url><meta content=吴良超的学习笔记 property=og:site_name><meta content="本文主要介绍 CTR 预估中常用的一些模型，主要是非深度学习模型，包括 LR、GBDT+LR、FM/FFM、MLR。每个模型会简单介绍其原理、论文出处以及其一些开源实现。" property=og:description><meta content=zh_CN property=og:locale><meta content=https://wulc.me/imgs/image_1cdhkuov7q2413hf3n14ecse0c.png property=og:image><meta content=https://wulc.me/imgs/gbdt.png property=og:image><meta content=https://wulc.me/imgs/image_1cdjf062nsovu4v1d3bbsn1rk49.png property=og:image><meta content=https://wulc.me/imgs/image_1cdk1jok51p5u13mgv2d1p6d1hll4c.png property=og:image><meta content=https://wulc.me/imgs/image_1cdjtahckkop2e81umc1l651lgi32.png property=og:image><meta content=https://wulc.me/imgs/image_1cdkhqh8gpjrb9n1mi11o6b16tj56.png property=og:image><meta content=https://wulc.me/imgs/image_1cdkb5qkk2ie1njv17ekj5s131k4p.png property=og:image><meta content=2018-07-15T13:53:19.000Z property=article:published_time><meta content=2025-05-06T14:10:51.966Z property=article:modified_time><meta content=良超 property=article:author><meta content=计算广告 property=article:tag><meta content=机器学习 property=article:tag><meta content=summary name=twitter:card><meta content=https://wulc.me/imgs/image_1cdhkuov7q2413hf3n14ecse0c.png name=twitter:image><link href=https://wulc.me/2018/07/15/CTR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B--%E9%9D%9E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/ rel=canonical><script class=next-config data-name=page type=application/json>{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://wulc.me/2018/07/15/CTR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B--%E9%9D%9E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/","path":"2018/07/15/CTR 预估模型简介--非深度学习篇/","title":"CTR 预估模型简介 -- 非深度学习篇"}</script><script class=next-config data-name=calendar type=application/json>""</script><title>CTR 预估模型简介 -- 非深度学习篇 | 吴良超的学习笔记</title><noscript><link href=/css/noscript.css rel=stylesheet></noscript><link href=/atom.xml rel=alternate title=吴良超的学习笔记 type=application/atom+xml><body class=use-motion itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><div class=column><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=site-brand-container><div class=site-nav-toggle><div aria-label=切换导航栏 class=toggle role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div></div><div class=site-meta><a class=brand href=/ rel=start> <i class=logo-line></i> <p class=site-title>吴良超的学习笔记</p> <i class=logo-line></i> </a></div><div class=site-nav-right><div class="toggle popup-trigger" aria-label=搜索 role=button><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ rel=section><i class="fa fa-home fa-fw"></i>首页</a><li class="menu-item menu-item-tags"><a href=/tags/ rel=section><i class="fa fa-tags fa-fw"></i>标签</a><li class="menu-item menu-item-archives"><a href=/archives/ rel=section><i class="fa fa-archive fa-fw"></i>归档</a><li class="menu-item menu-item-search"><a class=popup-trigger role=button><i class="fa fa-search fa-fw"></i>搜索 </a></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon> <i class="fa fa-search"></i> </span><div class=search-input-container><input autocapitalize=off autocomplete=off class=search-input maxlength=80 placeholder=搜索... spellcheck=false type=search></div><span class=popup-btn-close role=button> <i class="fa fa-times-circle"></i> </span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录<li class=sidebar-nav-overview>站点概览</ul><div class=sidebar-panel-container><!--noindex--><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class=nav><li class="nav-item nav-level-2"><a class=nav-link href=#lrlogistic-regerssion><span class=nav-number>1.</span> <span class=nav-text>LR(Logistic Regerssion)</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%8E%9F%E7%90%86><span class=nav-number>1.1.</span> <span class=nav-text>原理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98><span class=nav-number>1.2.</span> <span class=nav-text>一些问题</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0><span class=nav-number>1.3.</span> <span class=nav-text>开源实现</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#ls-plmlarge-scale-piece-wise-linear-model><span class=nav-number>2.</span> <span class=nav-text>LS-PLM(Large Scale Piece-wise Linear Model)</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%8E%9F%E7%90%86-1><span class=nav-number>2.1.</span> <span class=nav-text>原理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0-1><span class=nav-number>2.2.</span> <span class=nav-text>开源实现</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#gbdtlrgradient-boost-decision-tree-logistic-regression><span class=nav-number>3.</span> <span class=nav-text>GBDT+LR(Gradient Boost Decision Tree + Logistic Regression)</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%8E%9F%E7%90%86-2><span class=nav-number>3.1.</span> <span class=nav-text>原理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98-1><span class=nav-number>3.2.</span> <span class=nav-text>一些问题</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0-2><span class=nav-number>3.3.</span> <span class=nav-text>开源实现</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#fmfactorization-machine><span class=nav-number>4.</span> <span class=nav-text>FM(Factorization Machine)</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%8E%9F%E7%90%86-3><span class=nav-number>4.1.</span> <span class=nav-text>原理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0-3><span class=nav-number>4.2.</span> <span class=nav-text>开源实现</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#ffmfield-aware-factorization-machine><span class=nav-number>5.</span> <span class=nav-text>FFM(Field-aware Factorization Machine)</span></a><ol class=nav-child><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%8E%9F%E7%90%86-4><span class=nav-number>5.1.</span> <span class=nav-text>原理</span></a><li class="nav-item nav-level-3"><a class=nav-link href=#%E5%BC%80%E6%BA%90%E5%AE%9E%E7%8E%B0-4><span class=nav-number>5.2.</span> <span class=nav-text>开源实现</span></a></ol><li class="nav-item nav-level-2"><a class=nav-link href=#%E5%B0%8F%E7%BB%93><span class=nav-number>6.</span> <span class=nav-text>小结</span></a></ol></div></div><!--/noindex--><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop=author itemscope itemtype=http://schema.org/Person><img alt=良超 class=site-author-image itemprop=image src=/files/profile.jpg><p class=site-author-name itemprop=name>良超<div class=site-description itemprop=description>盈亏同源，享受生活的随机性</div></div><div class="site-state-wrap animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/> <span class=site-state-item-count>264</span> <span class=site-state-item-name>日志</span> </a></div><div class="site-state-item site-state-categories"><span class=site-state-item-count>33</span><span class=site-state-item-name>分类</span></div><div class="site-state-item site-state-tags"><a href=/tags/> <span class=site-state-item-count>49</span> <span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-author animated"><span class=links-of-author-item> <span title="GitHub → https://github.com/WuLC" class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL1d1TEM=><i class="fab fa-github fa-fw"></i>GitHub</span> </span><span class=links-of-author-item> <span title="E-Mail → mailto:liangchaowu5@gmail.com" class=exturl data-url=bWFpbHRvOmxpYW5nY2hhb3d1NUBnbWFpbC5jb20=><i class="fa fa-envelope fa-fw"></i>E-Mail</span> </span><span class=links-of-author-item> <a rel="noopener me" title="RSS → /atom.xml" href=/atom.xml><i class="fa fa-rss fa-fw"></i>RSS</a> </span></div><div class="cc-license animated" itemprop=license><span class="exturl cc-opacity" data-url=aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8=><img alt="Creative Commons" src=https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg></span></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class=post-block><article class=post-content itemscope itemtype=http://schema.org/Article lang=zh-CN><link href=https://wulc.me/2018/07/15/CTR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B--%E9%9D%9E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/ itemprop=mainEntityOfPage><span hidden itemprop=author itemscope itemtype=http://schema.org/Person> <meta content=/files/profile.jpg itemprop=image> <meta content=良超 itemprop=name> </span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization> <meta content=吴良超的学习笔记 itemprop=name> <meta content=盈亏同源，享受生活的随机性 itemprop=description> </span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork> <meta content="CTR 预估模型简介 -- 非深度学习篇 | 吴良超的学习笔记" itemprop=name> <meta itemprop=description> </span><header class=post-header><h1 itemprop="name headline" class=post-title>CTR 预估模型简介 -- 非深度学习篇</h1><div class=post-meta-container><div class=post-meta><span class=post-meta-item> <span class=post-meta-item-icon> <i class="far fa-calendar"></i> </span> <span class=post-meta-item-text>发表于</span> <time itemprop="dateCreated datePublished" title="创建时间：2018-07-15 21:53:19" datetime=2018-07-15T21:53:19+08:00>2018-07-15</time> </span><span class=post-meta-item> <span class=post-meta-item-icon> <i class="fa fa-tags"></i> </span> <span class=post-meta-item-text>标签</span> <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/ itemprop=url rel=index><span itemprop=name>计算广告</span></a> </span> ， <span itemprop=about itemscope itemtype=http://schema.org/Thing> <a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ itemprop=url rel=index><span itemprop=name>机器学习</span></a> </span> </span></div></div></header><div class=post-body itemprop=articleBody><p>本文主要介绍 CTR 预估中常用的一些模型，主要是非深度学习模型，包括 LR、GBDT+LR、FM/FFM、MLR。每个模型会简单介绍其原理、论文出处以及其一些开源实现。</p><span id=more></span><h2 id=lrlogistic-regerssion>LR(Logistic Regerssion)</h2><p><strong>LR + 海量人工特征</strong> 是业界流传已久的做法，这个方法由于简单、可解释性强，因此在工业界得到广泛应用，但是这种做法依赖于特征工程的有效性，也就是需要对具体的业务场景有深刻的认识才能提取出好的特征。<h3 id=原理><strong>原理</strong></h3><p>LR 是一个很简单的线性模型，其输出的值可认为是事件发生 (<span class="math inline">\(y=1\)</span>) 的概率，即输出值如下式所示<p><span class="math display">\[\begin{align} h(x) = p(y=1|x) = \sigma(w^Tx+b) \end{align}\]</span><p>其中<span class="math inline"> \(w\)</span> 为模型参数，<span class="math inline">\(x\)</span> 为提取的样本特征，两者均为向量，<span class="math inline">\(b\)</span> 是偏置项。<span class="math inline">\(\sigma\)</span> 为 sigmoid 函数，即 <span class="math inline">\(\sigma(x) = 1/(1+e^{-x})\)</span><p>有了事件发生的概率，则事件不发生的概率为 <span class="math inline">\(p(y=0|x) = 1-h(x)\)</span>, 将这两个概率通过如下一条公式表示为<p><span class="math display">\[\begin{align} p(y|x) = h(x)^y(1-h(x))^{1-y} \end{align}\]</span><p>有了这个概率值，则给定 <span class="math inline">\(n\)</span> 个样本，便可通过极大似然估计来估算模型参数，即目标函数为<p><span class="math display">\[\begin{align} \max \prod_{i=1}^np(y_i|x_i) \end{align}\]</span><p>通常我们还会对概率取 log，同时添加负号将 max 改成 min，则可将目标函数改写成如下的形式<p><span class="math display">\[\begin{align} \min -\sum_{i=1}^ny_i\log h(x_i)+(1-y_i)\log (1-h(x_i)) \end{align}\]</span><p>上面的损失函数也叫作 <strong>log loss</strong>，实际上多分类的 <strong>cross entropy</strong> 也同以通过极大似然估计推导出来。<p>有了损失函数，便可通过优化算法来求出最优的参数，由于这是个无约束的最优化问题，可选用的方法很多，最常用的就是 gradient descent，除此之外，另外还有基于二阶导数的牛顿法系列，适用于分布式中的 ADMM，以及由 Google 在论文 <span class=exturl data-url=aHR0cHM6Ly9zdGF0aWMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL21lZGlhL3Jlc2VhcmNoLmdvb2dsZS5jb20vemgtQ04vL3B1YnMvYXJjaGl2ZS80MTE1OS5wZGY=>Ad Click Prediction: a View from the Trenches<i class="fa fa-external-link-alt"></i></span> 中提出的 FTRL 算法，目前也是业界普遍采用的方法，该算法具有 online learning 和稀疏性的良好特性，online learning 指的是其更新方式与 SGD (stochastic gradient descent) 相似，稀疏性指的是该算法能够解决带非光滑的 L1 正则项的优化问题。由于这里这篇文章主要讲述各种 CTR 预估模型，因此这里不对优化算法做展开了。<p>上面提到了 L1 正则项，就是在原来的损失函数基础上加上了 <span class="math inline">\(C\sum_{i=1}^m |w_i|\)</span> 这一项， 表示各个参数的绝对值的和乘上常数 <span class="math inline">\(C\)</span>；加上这一项后能够使得最终的求解出来的参数中大部分的 <span class="math inline">\(|w_i|\)</span> 为 0，这也是稀疏性的名称来源。稀疏性使得模型的复杂度下降，缓解了过拟合的问题，同时具有有特征筛选的能力。因为 LR 模型可以理解为对各个特征进行加权求和，如果某些特征的权重即 <span class="math inline">\(w_i\)</span> 为 0，则可认为这些特征的重要性不高。在 CTR 预估中输入的是海量人工特征，因此添加 L1 正则化就更有必要了。<p>由于 L1 正则项不再是处处光滑可导的函数，因此在优化损失函数时。原来的 gradient descent 不能够直接使用，而是要通过 <span class=exturl data-url=aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU3ViZ3JhZGllbnRfbWV0aG9k>subgradient<i class="fa fa-external-link-alt"></i></span> 的方法或前面提到的 FTRL 算法进行优化。<p>上面涵盖了 LR 模型的基本原理。而<strong>在 CTR 预估中，应用 LR 模型的重点在于特征工程。LR 模型适用于高维稀疏特征</strong>。对于 categorical 特征，可以通过 one-hot 编码使其变得高纬且稀疏。而对于 continious 特征，可以先通过区间划分为 categorical 特征再进行 one-hot 编码。同时还需要进行特征的组合 / 交叉，以获取更有效的特征。<h3 id=一些问题><strong>一些问题</strong></h3><p>上面介绍过程中有一些结论我们直接就使用了，下面对于上面提到的某些结论做出一些解释<p><strong>1. LR 的输出为什么可以被当做是概率值？</strong><p>这部分涉及到广义线性模型 (GLM，<span class=exturl data-url=aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvR2VuZXJhbGl6ZWRfbGluZWFyX21vZGVs>Generalized linear model<i class="fa fa-external-link-alt"></i></span>) 的知识，这里略过复杂的推导，直接给出结论。简单来说，LR 实际上是一个广义线性模型，其假设是二分类中 <span class="math inline">\((y|x,\theta)\)</span> 服从伯努利分布 (二项分布)，即给定输入样本 <span class="math inline">\(x\)</span> 和模型参数 <span class="math inline">\(\theta\)</span>, 事件是否发生服从伯努利分布。假设伯努利分布的参数 <span class="math inline">\(\phi\)</span> ，则 <span class="math inline">\(\phi\)</span> 可作为点击率。通过 广义线性模型的推导，能够推出 <span class="math inline">\(\phi\)</span> 的表示形式如下<p><span class="math display">\[\begin{align} \phi = 1/(1+e^{-\eta}) \end{align}\]</span><p>从上面的式子可知，<strong>LR 中的 sigmoid 函数并不是凭空来的</strong>，而式子中的 <span class="math inline">\(\eta\)</span> 也被称为连接函数（Link function), 是确定一个 GLM 的重要部分，在 LR 中为简单的线性加权。<p>另外，如果将输出值与真实值的误差的分布假设为高斯分布，那么从 GLM 可推导出 Linear Regression，关于 GLM 详细的推导可参考这篇文章 <span class=exturl data-url=aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vZHJlYW12aWJlL3AvNDI1OTQ2MC5odG1s>广义线性模型（GLM）<i class="fa fa-external-link-alt"></i></span>。<p><strong>2. 为什么 L1 正则项能够带来稀疏性？</strong><p>这里有个很直观的回答，<span class=exturl data-url=aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM3MDk2OTMzL2Fuc3dlci83MDQyNjY1Mw==>l1 相比于 l2 为什么容易获得稀疏解？<i class="fa fa-external-link-alt"></i></span>，简单来说，就是<strong>当不带正则项的损失函数对于某个参数 <span class="math inline">\(w_i\)</span> 的导数的绝对值小于 l1 正则项中的常数 <span class="math inline">\(C\)</span> 时，这个参数 <span class="math inline">\(w_i\)</span> 的最优解就是 0</strong>。<p>因为求解某个参数 <span class="math inline">\(w_i\)</span> 使得损失函数取极小值时可分两种情况讨论 (下面的 <span class="math inline">\(L\)</span> 为不带正则项的损失函数) 1）<span class="math inline">\(w_i&LT0\)</span> 时，<span class="math inline">\(L+C|w_i|\)</span> 的导数为 <span class="math inline">\(L'- C\)</span> 2) <span class="math inline">\(w_i>0\)</span> 时，<span class="math inline">\(L+C|w_i|\)</span> 的导数为 <span class="math inline">\(L'+C\)</span><p>当 <span class="math inline">\(w_i&LT0\)</span> 时，令 <span class="math inline">\(L'- C < 0\)</span>, 函数在递减；而当<span class="math inline"> \(w_i>0\)</span> 时，令 <span class="math inline">\(L'+C > 0\)</span>, 函数在递增，则 <span class="math inline">\(w_i=0\)</span> 便是使得损失函数最小的最优解，且结合 <span class="math inline">\(L'- C < 0\)</span> 和 <span class="math inline">\(L'+C > 0\)</span>，可得 <span class="math inline">\(C > |L'|\)</span>。这便是我们上面得到的结论，上面是针对某一个参数，实际上也可以推广到所有参数上。事实上，通过 subgradient descent 求解这个问题时也能够得到相同的结论。<p><strong>3. 连续特征为什么需要离散化？</strong><p>参考这个问题：<span class=exturl data-url=aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzMxOTg5OTUyL2Fuc3dlci81NDE4NDU4Mg==>连续特征的离散化：在什么情况下将连续的特征离散化之后可以获得更好的效果？<i class="fa fa-external-link-alt"></i></span><p>离散化后有以下几个好处：<ol type=1><li>稀疏向量内积乘法运算速度快，计算结果方便存储<li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄 > 30 是 1，否则 0。如果特征没有离散化，一个异常数据 “年龄 300 岁” 会给模型造成很大的干扰；<li>逻辑回归属于广义线性模型，表达能力受限；单变量离散化为 N 个后，<strong>可以通过 one-hot 编码为每个变量设置单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合</strong>；<li>离散化后可以进行<strong>特征交叉</strong>，由 M+N 个变量变为 M*N 个变量，进一步引入非线性，提升表达能力；<li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30 作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间要取决于具体的场景</ol><p><strong>4.1 为什么要对 categorical 特征做 One-hot 编码后再输入 LR？</strong><p>参考这篇文章 <span class=exturl data-url=aHR0cDovL3d3dy5qaWVodW96aGUuY29tL2FydGljbGUvMw==>One-Hot 编码与哑变量<i class="fa fa-external-link-alt"></i></span>，简单来说，就是 LR 建模时，要求特征具有线性关系，而实际应用中很少有满足这个假设关系的，因此 LR 模型效果很难达到应用要求。但是通过对离散特征进行 one-hot 编码，LR 可以为某个特征中所有可能的值设置一个权重，这样就能够更准确的建模，也就能够获得更精准的模型。而 one-hot 编码后特征实际上也是做了一个 min-max 归一化，能够克服不同特征的量纲差异，同时使模型收敛更快。<h3 id=开源实现><strong>开源实现</strong></h3><p>由于 LR 模型的广泛性，基本上每个机器学习库或者框架都有相关实现，如 sklearn 提供了<span class=exturl data-url=aHR0cDovL3NjaWtpdC1sZWFybi5vcmcvc3RhYmxlL21vZHVsZXMvZ2VuZXJhdGVkL3NrbGVhcm4ubGluZWFyX21vZGVsLkxvZ2lzdGljUmVncmVzc2lvbi5odG1s>单机版的实现<i class="fa fa-external-link-alt"></i></span>，spark 提供了<span class=exturl data-url=aHR0cHM6Ly9zcGFyay5hcGFjaGUub3JnL2RvY3MvMi4zLjAvbWxsaWItbGluZWFyLW1ldGhvZHMuaHRtbA==>分布式版本的实现<i class="fa fa-external-link-alt"></i></span>，腾讯开源的 Parameter Server <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL1RlbmNlbnQvYW5nZWw=>Angel<i class="fa fa-external-link-alt"></i></span> 中也提供了 <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL1RlbmNlbnQvYW5nZWwvYmxvYi9tYXN0ZXIvZG9jcy9hbGdvL3NvbmEvc3BhcnNlbHJfZnRybC5tZA==>LR+FTRL<i class="fa fa-external-link-alt"></i></span> 的实现，Angel 支持 Spark，目前也还在开发中 。除此之外，Github 上也有很多个人开源的实现，这里不再列举。<h2 id=ls-plmlarge-scale-piece-wise-linear-model>LS-PLM(Large Scale Piece-wise Linear Model)</h2><p>LS-PLM (也叫作 MLR, Mixture of Logistics Regression) 是阿里妈妈在 2017 年在论文 <span class=exturl data-url=aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE3MDQuMDUxOTQ=>Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction<i class="fa fa-external-link-alt"></i></span> 中公开的，但是模型早在 2012 年就在阿里妈妈内部使用。这个模型在 LR 基础上进行了拓展，目的是为了解决单个 LR 无法进行非线性分割的问题。<h3 id=原理-1><strong>原理</strong></h3><p>LR 是一个线性模型，模型会在数据空间中生成一个线性分割平面，但是对于非线性可分的数据，这一个线性分割面显然无法正确分割这些数据。以下图为例（摘自上面的论文），A）为一组非线性训练数据的正负样本分布；对于该问题，LR 会生成 B）中的分割平面，C) 图展示的 LS-PLM 模型 则取得了较好的效果。<figure><img alt=LS-PIC data-src=https://wulc.me/imgs/image_1cdhkuov7q2413hf3n14ecse0c.png><figcaption aria-hidden=true>LS-PIC</figcaption></figure><p>在 CTR 问题中，<strong>划分场景分别建模</strong>是一种常见的手法。例如，同一产品的 PC/APP 端，其用户的使用时间和习惯差异可能很大；比如 PC 可能更多是办公时间在看，而手机则是通勤时间或者临睡前使用更多。假设有 hour 作为特征，那么 “hour=23” 对于 APP 端更加有信息量，而对于 PC 可能意义不大。因此，区分 PC/APP 端分别建模可能提升效果。<p>LS-PLM 也是采用这个思想的，不够这里不是划分场景，而是划分数据，通过将数据划分不同的 region、然后每个 region 分别建立 LR。<p>这里需要注意的是这里一个样本并不是被唯一分到了一个 region，而是按权重分到了不同的 region。其思想有点像 LDA (Latent Dirichlet allocation) 中一个单词会按照概率分到多个 topic 上。<p>论文中的公式如下<p><span class="math display">\[\begin{align} p(y=1|x) = g ( \sum_{j=1}^m \sigma(\mu_j^T x)\eta(w_j^Tx)) \end{align}\]</span><p>公式中的符号定义如下：<p>参数定义如下：<ul><li><span class="math inline">\(m\)</span> : region 的个数 (超参数：一般是 10~100)<li><span class="math inline">\(\Theta=\{\mu_1,\dots,\mu_m, w_1,\dots,w_m \}\)</span>: 表示模型的参数，需要训练<li><span class="math inline"> \(g(\cdot)\)</span>：为了让模型符合概率定义 (概率和为 1) 的函数<li><span class="math inline"> \(\sigma(\cdot)\)</span>：将样本分到 region 的函数<li><span class="math inline"> \(\eta(\cdot)\)</span>：在 region 中划分样本的函数</ul><p>前面提出的公式更像个框架，在论文中，只讨论了 <span class="math inline">\(g(x) = x\)</span>, <span class="math inline">\(\sigma\)</span> = softmax ，<span class="math inline">\(\eta\)</span> = sigmoid 的情形，而且因此，上面的公式可写成如下的形式<p><span class="math display">\[\begin{align} p(y=1|x) = \sum_{i=1}^m \frac{e^{\mu_i^Tx}}{\sum_{j=1}^m e^{\mu_j^Tx}}\frac{1}{1+e^{-w_i^Tx}} \end{align}\]</span><p>这个公式其实已经变成了通过多个 LR 模型进行加权求和的 bagging 模式，只是这里每个模型的权重是学习出来而不是事先确定的。<p>写出了概率函数，后面的推导跟前面的 LR 其实是一样的，也是先通过极大似然估计得到 <span class="math inline">\(\max\)</span> 问题，添加负号后转为损失函数求 <span class="math inline">\(\min\)</span> 问题。这里不做详细的推导了。<p>在 LS-PLM 中也是需要添加正则项的，除了在 LR 中提到的 L1 正则化，论文还提出了 <span class="math inline">\(L_{2,1}\)</span> 正则项，表示如下<p><span class="math display">\[\begin{align} ||\Theta||_{2,1} = \sum_{i=1}^d \sqrt {\sum_{j=1}^m(\mu_{ij}^2+w_{ij}^2)} \end{align}\]</span><p>上式中的 <span class="math inline">\(d\)</span> 表示特征的维数，其中 <span class="math inline">\(\sqrt {\sum_{j=1}^m(\mu_{ij}^2+w_{ij}^2)}\)</span> 表示对某一维特征的所有参数进行 L2 正则化，而外侧的 <span class="math inline">\(\sum_{i=1}^d\)</span> 表示对所有的 feature 进行 L1 正则化，由于开方后的值必为正，因此这里也不用添加绝对值了。由于结合了 L1 和 L2 正则项，所以论文也将这个叫做<span class="math inline"> \(L_{2,1}\)</span> 正则项。<p>由于损失函数和正则项都是光滑可导的，因此优化方面比带 L1 正则的 LR 更加简单，可选的优化方法也更多。<p>MLR 适用的场景跟 LR 一样，也是适用于高纬稀疏特征作为输入。<h3 id=开源实现-1><strong>开源实现</strong></h3><p>前面提到的腾讯的 PS Angel 实现了这个算法，具体可参考<span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL1RlbmNlbnQvYW5nZWwvYmxvYi9tYXN0ZXIvZG9jcy9hbGdvL21scl9vbl9hbmdlbC5tZA==>这里<i class="fa fa-external-link-alt"></i></span>；Angel 是用 Scala 开发的。也有一些个人开源的版本如 <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL0Nhc3RlbGxhblpoYW5nL2FscGhhUExN>alphaPLM<i class="fa fa-external-link-alt"></i></span>，这个版本是用 C++ 写的，如果需要实现可以参考以上资料。<h2 id=gbdtlrgradient-boost-decision-tree-logistic-regression>GBDT+LR(Gradient Boost Decision Tree + Logistic Regression)</h2><p>GBDT + LR 是 FaceBook 在这篇论文 <span class=exturl data-url=aHR0cDovL3F1aW5vbmVyby5uZXQvUHVibGljYXRpb25zL3ByZWRpY3RpbmctY2xpY2tzLWZhY2Vib29rLnBkZg==>Practical Lessons from Predicting Clicks on Ads at Facebook<i class="fa fa-external-link-alt"></i></span> 中提出的，其思想是借助 GBDT 帮我们做部分特征工程，然后将 GBDT 的 输出作为 LR 的输入。<h3 id=原理-2><strong>原理</strong></h3><p>我们前面提到的无论 LR 还是 MLR，都避免不了要做大量的特征工程。比如说构思可能的特征，将连续特征离散化，并对离散化的特征进行 One-Hot 编码，最后对特征进行二阶或者三阶的特征组合 / 交叉，这样做的目的是为了得到非线性的特征。但是特征工程存在几个难题：<ol type=1><li>连续变量切分点如何选取？<li>离散化为多少份合理？<li>选择哪些特征交叉？<li>多少阶交叉，二阶，三阶或更多？</ol><p>而 GBDT + LR 这个模型中，GBDT 担任了特征工程的工作，下面首先介绍一下 GBDT。<p>GBDT 最早在这篇论文 <span class=exturl data-url=aHR0cHM6Ly9zdGF0d2ViLnN0YW5mb3JkLmVkdS9+amhmL2Z0cC90cmVic3QucGRm>Greedy Function Approximation：A Gradient Boosting Machine<i class="fa fa-external-link-alt"></i></span> 中提出； GBDT 中主要有两个概念：GB (<span class=exturl data-url=aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvR3JhZGllbnRfYm9vc3Rpbmc=>Gradient Boosting<i class="fa fa-external-link-alt"></i></span>) 和 DT (Decision Tree)，Gradient Boosting 是集成学习中 boosting 的一种形式，Decision Tree 则是机器学习中的一类模型，这里不对这两者展开，只讲述在 GBDT 中用到的内容。关于决策树的介绍可参考这篇文章 <span class=exturl data-url=aHR0cDovL3d3dy5jbmJsb2dzLmNvbS93eHF1YXJlL3AvNTM3OTk3MC5odG1s>决策树模型 ID3/C4.5/CART 算法比较<i class="fa fa-external-link-alt"></i></span>。<p>在 GBDT 中采用的决策树是 CART (Classification And Regression Tree)，将其当做回归树使用，这里的回归树是一棵在每个树节点进行分裂的时候，给节点设定其在某个特征的的值，若样本对应的特征的值大于这个给定的值的属于一个子树，小于这个给定的值的属于另一个子树。<p>那么，构建 CART 回归树是 的关键问题就在于选择具体的特征还有这个特征上具体的值了。选择的指标是<strong>平方误差最小化准则</strong>。对于任意一个切分，其平方误差计算方式如下<ol type=1><li>假设切分后左子树有 <span class="math inline">\(m\)</span> 个样本，右子树有 <span class="math inline">\(n\)</span> 个<li>计算左子树样本的目标值的均值为 <span class="math inline">\(y_m = \frac{1}{m}\sum_{i=1}^{m}y_i\)</span>, 同样计算右子树样本的目标值的均值为 <span class="math inline">\(y_n = \frac{1}{n}\sum_{j=1}^{n}y_j\)</span><li>平方误差和为 <span class="math inline">\(L = \sum_{i=1}^m(y_i - y_m)^2 + \sum_{j=1}^n(y_j - y_n)^2\)</span><li>对于每一个可能的切分值，我们都可计算其平方误差和 <span class="math inline">\(L\)</span>，选择使得 <span class="math inline">\(L\)</span> 最小的切分点即可。</ol><p>上面便是 GBDT 中的 “DT” 部分，用于解决一个回归问题，也就是给定一组样本，我们可以通过上面的方式来构建出一棵 CART 来拟合这组样本。下面我们来讲一下 GBDT 中的 “GB” 部分。<p>简单来说，<strong>gradient boosting 就是将若干个模型的输出进行叠加作为最终模型的输出。</strong>如下图是一个简单的例子 (图片来源于提出 xgb 的论文：<span class=exturl data-url=aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE2MDMuMDI3NTQucGRm>XGBoost: A Scalable Tree Boosting System<i class="fa fa-external-link-alt"></i></span>)<figure><img alt=xgboost data-src=https://wulc.me/imgs/gbdt.png><figcaption aria-hidden=true>xgboost</figcaption></figure><p>下式就是叠加了 <span class="math inline">\(T\)</span> 个 <span class="math inline">\(f_t(x)\)</span> 模型作为最终的模型，<span class="math inline">\(f_t(x)\)</span> 在 GBDT 中就是一棵 CART，当然 <span class="math inline">\(f_t(x)\)</span> 不限于树模型。<p><span class="math display">\[\begin{align} F(x) = \sum_{t=1}^Tf_t(x) \end{align}\]</span><p>在构建每棵树的时候，输入的样本不同的地方在于每个样本的目标值 <span class="math inline">\(y\)</span>；如构建第 <span class="math inline">\(k\)</span> 棵树，对于原始样本 <span class="math inline">\((x_i, y_i)\)</span>, 其目标值变为<p><span class="math display">\[\begin{align} y_{ik} = y_i - \sum_{t=1}^{k-1}f_t(x_i) \end{align}\]</span><p>即输入第 <span class="math inline">\(k\)</span> 棵树的样本变为 <span class="math inline">\((x_i, y_{ik})\)</span>，所以在<strong>构建第 <span class="math inline">\(k\)</span> 棵树的时候，实际上是在拟合前 <span class="math inline">\(k-1\)</span> 棵树的输出值的和与样本真实值的残差。</strong><p>回到我们的 GBDT + LR 模型，首先通过前面提到的 GBDT 训练出一批树模型，然后样本输入每棵树后最终都会落到一个具体的叶子节点上，那我们就将这个节点标为 1，其他叶子节点标为 0，<strong>这样每棵树输出的就相当于是一个 one-hot 编码的特征</strong>。如下图是摘自 FaceBook 原始论文的图，里面有两棵树，假如输入 <span class="math inline">\(x\)</span> 在第一棵树中落入第一个叶子节点，在第二棵树种落入第二个叶子节点，那么输入 LR 的特征为 [1, 0, 0, 0, 1].<figure><img alt="GBDT + LR" data-src=https://wulc.me/imgs/image_1cdjf062nsovu4v1d3bbsn1rk49.png><figcaption aria-hidden=true>GBDT + LR</figcaption></figure><p>GBDT+LR 方案中每棵决策树从根节点到叶节点的路径，会经过不同的特征，此路径就是特征组合，而且包含了二阶，三阶甚至更多，因此输出的 one-hot 特征是原始特征进行交叉后的结果。而且每一维的特征其实还是可以追溯出其含义的，因为从根节点到叶子节点的路径是唯一的，因此落入到某个叶子节点表示这个特征满足了这个路径中所有节点判断条件。<p><strong>GBDT 适用的问题刚好与 LR 相反，GBDT 不适用于高纬稀疏特征，因为这样很容易导致训练出来的树的数量和深度都比较大从而导致过拟合。因此一般输入 GBDT 的特征都是连续特征。</strong><p>在 CTR 预估中，会存在大量的 id 特征，对于这种离散特征，一般有两种做法 1) <strong>离散特征不直接输入到 GBDT 中进行编码</strong>，而是做 one-hot 编码后直接输入到 LR 中即可；对于连续特征，先通过 GBDT 进行离散化和特征组合输出 one-hot 编码的特征，最后结合这两种 one-hot 特征直接输入到 LR。大致框架如下所示<figure><img alt="Real GBDT" data-src=https://wulc.me/imgs/image_1cdk1jok51p5u13mgv2d1p6d1hll4c.png><figcaption aria-hidden=true>Real GBDT</figcaption></figure><ol start=2 type=1><li><strong> 将离散的特征也输入 GBDT 进行编码</strong>，但是只保留那些出现频率高的离散特征，这样输入 GBDT 中的 one-hot 特征的维度会遍地，同时通过 GBDT 也对原始的 one-hot 特征进行了组合和交叉。</ol><h3 id=一些问题-1><strong>一些问题</strong></h3><p><strong>1. GBDT 中的 gradient 在哪里体现了？</strong><p>推导到现在，好像也没有提及到 gradient，其实前面<strong>拟合残差时已经用到了 gradient 的信息</strong>。<p>首先，我们要转换一下思维，我们一般在优化中使用的 gradient descent 都是对某个参数进行的，或者说是在参数空间中进行的，但是除了参数空间，还可以在函数空间中进行。如下图所示对比了两种方式 (下面两张图均摘自<span class=exturl data-url=aHR0cDovL3dlcG9uLm1lL2ZpbGVzL2diZHQucGRm> GBDT 算法原理与系统设计简介<i class="fa fa-external-link-alt"></i></span>)<figure><img alt="gredient descent v.s. gradient boosting" data-src=https://wulc.me/imgs/image_1cdjtahckkop2e81umc1l651lgi32.png><figcaption aria-hidden=true>gredient descent v.s. gradient boosting</figcaption></figure><p>在函数空间中，是对函数直接进行求导的，因此 GBDT 算法的流程如下<figure><img alt=GBDT data-src=https://wulc.me/imgs/image_1cdkhqh8gpjrb9n1mi11o6b16tj56.png><figcaption aria-hidden=true>GBDT</figcaption></figure><p>上图中的 <span class="math inline">\(\tilde{y_i}\)</span> 就是我们前面说的第 <span class="math inline">\(i\)</span> 个样本的残差，当损失函数为平方损失即 <span class="math display">\[L(y,F(x)) = \frac{1}{2}(y-F(x))^2\]</span><p>对 <span class="math inline">\(F(x)\)</span> 求导得出的残差为<p><span class="math display">\[\begin{align} \tilde{y_i} = y_i - F(x_i) \end{align}\]</span><p>这正是我们前面说的样本的真实值与前面建的树的输出和的差。<strong>如果损失函数改变，这个残差值也会进行相应的改变。</strong><p><strong>2. GBDT 怎么处理分类问题？</strong><p>上面我们讲的 GBDT 是处理回归问题的，但是对于 CTR 预估这一类问题，从大分类上其实还是一个分类问题。那 GBDT 是怎么处理这个问题？<p>在回归问题中，GBDT 每一轮迭代都构建了一棵树，实质是构建了一个函数 <span class="math inline">\(f\)</span>，当输入为 x 时，树的输出为 <span class="math inline">\(f(x)\)</span>。<p>在多分类问题中，假设有 <span class="math inline">\(k\)</span> 个类别，那么每一轮迭代实质是构建了 <span class="math inline">\(k\)</span> 棵树，对某个样本 <span class="math inline">\(x\)</span> 的预测值为 <span class="math inline">\(f_{1}(x), f_{2}(x), ..., f_{k}(x)\)</span>,<p>在这里我们仿照多分类的逻辑回归，使用 softmax 来产生概率，则属于某个类别 <span class="math inline">\(j\)</span> 的概率为<p><span class="math display">\[\begin{align} p_{c} = \frac{\exp(f_{j}(x))}{ \sum_{i=1}^{k}{exp(f_{k}(x))}} \end{align}\]</span><p>通过上面的概率值，可以分别计算出样本在各个分类下的 log loss，根据上面 GBDT 在函数空间的求导，对 <span class="math inline">\(f_1\)</span> 到 <span class="math inline">\(f_k\)</span> 都可以算出一个梯度，也就是当前轮的残差，供下一轮迭代学习。也就是每一轮的迭代会同时产生 k 棵树。<p>最终做预测时，输入的 <span class="math inline">\(x\)</span> 会得到 <span class="math inline">\(k\)</span> 个输出值，然后通过 softmax 获得其属于各类别的概率即可。<p>更详细的推导可参考这篇文章：<span class=exturl data-url=aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8yNTI1Nzg1Ng==>当我们在谈论 GBDT：Gradient Boosting 用于分类与回归<i class="fa fa-external-link-alt"></i></span><h3 id=开源实现-2><strong>开源实现</strong></h3><p>直接实现 GBDT + LR 的开源方案不多，但是由于两者的耦合关系并不强，因此可以先训练 GBDT，然后将原始特征通过 GBDT 转换后送入到 LR 中，GBDT 有多个高效的实现，如 <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL2RtbGMveGdib29zdA==>xgboost<i class="fa fa-external-link-alt"></i></span>，<span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL01pY3Jvc29mdC9MaWdodEdCTQ==>LightGBM<i class="fa fa-external-link-alt"></i></span>。<h2 id=fmfactorization-machine>FM(Factorization Machine)</h2><p>FM（Factorization Machine）是于 2010 年在论文 <span class=exturl data-url=aHR0cDovL3d3dy5hbGdvLnVuaS1rb25zdGFuei5kZS9tZW1iZXJzL3JlbmRsZS9wZGYvUmVuZGxlMjAxMEZNLnBkZg==>Factorization Machines<i class="fa fa-external-link-alt"></i></span> 中提出，旨在解决稀疏数据下的特征组合问题。其思想是对组合特征的参数所构成的参数矩阵进行矩阵分解，从而得到每个原始特征的隐向量表示，更新特征的隐向量对数据的稀疏性具有鲁棒性。关于 FM 和 FFM ，美团点评这篇文章：<span class=exturl data-url=aHR0cHM6Ly90ZWNoLm1laXR1YW4uY29tL2RlZXAtdW5kZXJzdGFuZGluZy1vZi1mZm0tcHJpbmNpcGxlcy1hbmQtcHJhY3RpY2VzLmh0bWw=>深入 FFM 原理与实践<i class="fa fa-external-link-alt"></i></span> 其实已经写得很详细了，本文主要参考该文章进行修改。<h3 id=原理-3><strong>原理</strong></h3><p>FM 可以认为是在 LR 的基础上加入特征的二阶组合，即最多有两个特征相乘，则模型可表示成如下形式<p><span class="math display">\[\begin{align} y(\mathbf{x}) = w_0+ \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n w_{ij} x_i x_j \end{align}\]</span><p>从模型也可以看出，其实 FM 是在 LR 基础上增加了最后的二阶交叉项。<p>从上面的公式可以看出，组合特征的参数一共有 <span class="math inline">\(\frac{n(n−1)}{2}\)</span> 个，任意两个参数都是独立的。然而，在数据稀疏性普遍存在的实际应用场景中，<strong>二次项参数的训练是很困难的，原因是每个参数 <span class="math inline">\(w_{ij}\)</span> 的训练需要大量 <span class="math inline">\(x_i\)</span> 和 <span class="math inline">\(x_j\)</span> 都非零的样本</strong>；由于样本数据本来就比较稀疏，满足 <span class="math inline">\(x_i\)</span> 和 <span class="math inline">\(x_j\)</span> 都非零的样本将会非常少。训练样本的不足，则会导致参数 <span class="math inline">\(w_{ij}\)</span> 不准确，最终将严重影响模型的性能。<p>如何解决这个问题？FM 中借鉴了矩阵分解的思想，在推荐系统中，会对 user-item 矩阵进行矩阵分解，从而每个 user 和每个 item 都会得到一个隐向量。如下图所示<figure><img alt=matrix data-src=https://wulc.me/imgs/image_1cdkb5qkk2ie1njv17ekj5s131k4p.png><figcaption aria-hidden=true>matrix</figcaption></figure><p>类似地，所有二次项参数 <span class="math inline">\(w_{ij}\)</span> 可以组成一个对称阵 <span class="math inline">\(W\)</span>，那么这个矩阵就可以分解为 <span class="math inline">\(W=V^TV\)</span>，<span class="math inline">\(V\)</span> 的第 <span class="math inline">\(j\)</span> 列便是第 <span class="math inline">\(j\)</span> 维特征的隐向量。换句话说，每个参数可表示成两个隐向量的内积的形式。即 <span class="math inline">\(w_{ij}=&LTv_i,v_j>\)</span>，<span class="math inline">\(v_i\)</span> 表示第 <span class="math inline">\(i\)</span> 维特征的隐向量，这就是 FM 模型的核心思想。因此，可以将上面的方程改写成如下形式<p><span class="math display">\[\begin{align}y(\mathbf{x}) = w_0+ \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n &LTv_i, v_j>x_i x_j \end{align}\]</span><p>假设隐向量的长度为 <span class="math inline">\(k(k<&LTn)\)</span>，二次项的参数数量减少为 <span class="math inline">\(kn\)</span> 个，远少于多项式模型的参数数量。另外，参数因子化使得 <span class="math inline">\(x_hx_i\)</span> 的参数和 <span class="math inline">\(x_ix_j\)</span> 的参数不再是相互独立的，因此我们可以在样本稀疏的情况下相对合理地估计 FM 的二次项参数。<p>具体来说，<span class="math inline">\(x_hx_i\)</span> 和 <span class="math inline">\(x_ix_j\)</span> 的系数分别为 <span class="math inline">\(&LTv_h,v_i>\)</span> 和 <span class="math inline">\(&LTv_i,v_j>\)</span>，它们之间有共同项 <span class="math inline">\(v_i\)</span>。也就是说，<strong>所有包含 <span class="math inline">\(x_i\)</span> 的非零组合特征（即存在某个<span class="math inline"> \(j≠i\)</span>，使得 <span class="math inline">\(x_ix_j≠0\)</span>）的样本都可以用来学习隐向量 <span class="math inline">\(v_i\)</span>，这很大程度上避免了数据稀疏性造成的影响</strong>。而在多项式模型中，<span class="math inline">\(w_{hi}\)</span> 和 <span class="math inline">\(w_{ij}\)</span> 是相互独立的。<p>另外，原始论文还对特征交叉项计算的时间复杂度做了优化，具体见如下公式<p><span class="math display">\[\begin{align} \sum_{i=1}^n \sum_{j=i+1}^n \langle \mathbf{v}_i, \mathbf{v}_j \rangle x_i x_j = \frac{1}{2} \sum_{f=1}^k \left(\left( \sum_{i=1}^n v_{i, f} x_i \right)^2 - \sum_{i=1}^n v_{i, f}^2 x_i^2 \right) \end{align}\]</span><p>从公式可知，原来的计算复杂度为 <span class="math inline">\(O(kn^2)\)</span>，而改进后的时间复杂度为 <span class="math inline">\(O(kn)\)</span><p>在 CTR 预估中，对 FM 的输出进行 sigmoid 变换后与 Logistics Regression 是一致的，因此损失函数的求解方法以及优化算法都基本一致，这里不再详细展开。<p>由于 FM 可以看做是 LR 基础上加上二阶特征组合的模型，同时模型本身对稀疏性有较好的鲁棒性，因此 FM 适用范围跟 LR 一样，都<strong>适用于输入的特征是高纬度稀疏特征</strong>。<h3 id=开源实现-3><strong>开源实现</strong></h3><p>FM 在 github 上有单机版本的开源实现 <span class=exturl data-url=aHR0cDovL2liYXllci5naXRodWIuaW8vZmFzdEZNLw==>fastFM<i class="fa fa-external-link-alt"></i></span>和<span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL2NvcmV5bHluY2gvcHlGTQ==> pyFM<i class="fa fa-external-link-alt"></i></span>， fastFM 是一个学术项目，发表了相关论文 <span class=exturl data-url=aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE1MDUuMDA2NDE=>fastFM: A Library for Factorization Machines<i class="fa fa-external-link-alt"></i></span>, 对 FM 进行了拓展；同时我们前面提到的腾讯的 PS Angel 中也实现了这个算法，可参考<span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL1RlbmNlbnQvYW5nZWwvYmxvYi9tYXN0ZXIvZG9jcy9hbGdvL2ZtX29uX2FuZ2VsLm1k>这里<i class="fa fa-external-link-alt"></i></span>。<h2 id=ffmfield-aware-factorization-machine>FFM(Field-aware Factorization Machine)</h2><p>FFM 发表于论文 <span class=exturl data-url=aHR0cHM6Ly93d3cuY3NpZS5udHUuZWR1LnR3L35jamxpbi8vcGFwZXJzL2ZmbS5wZGY=>Field-aware Factorization Machines for CTR Prediction<i class="fa fa-external-link-alt"></i></span>， 是台大的学生在参加 2012 KDD Cup 时提出的，这个论文借鉴了论文 <span class=exturl data-url=aHR0cHM6Ly9rYWdnbGUyLmJsb2IuY29yZS53aW5kb3dzLm5ldC9jb21wZXRpdGlvbnMva2RkY3VwMjAxMi8yNzQ4L21lZGlhL09wZXJhLnBkZg==>Ensemble of Collaborative Filtering and Feature Engineered Models for Click Through Rate Prediction<i class="fa fa-external-link-alt"></i></span> 中的 field 的 概念，从而提出了 FM 的升级版模型 FFM。<h3 id=原理-4><strong>原理</strong></h3><p><strong>通过引入 field 的概念，FFM 把相同性质的特征归于同一个 field。简单来说，同一个 categorical 特征经过 One-Hot 编码生成的数值特征都可以放到同一个 field</strong>，包括用户性别、职业、品类偏好等。<p>在 FFM 中，每一维特征 <span class="math inline">\(x_i\)</span>，针对其它特征的每一种 field <span class="math inline">\(f_j\)</span>，都会学习一个隐向量 <span class="math inline">\(v_{i,f_j}\)</span>。因此，<strong>隐向量不仅与特征相关，也与 field 相关。也就是说，假设有 <span class="math inline">\(f\)</span> 个 field，那么每个特征就有 <span class="math inline">\(f\)</span> 个隐向量，与不同的 field 的特征组合时使用不同的隐向量</strong>，而原来的 FM 中每个特征只有一个隐向量。<p>实际上，FM 可以看作 FFM 的特例，是把所有特征都归属到一个 field 时的 FFM 模型。根据 FFM 的 field 敏感特性，同样可以导出其模型方程如下<p><span class="math display">\[\begin{align} y(\mathbf{x}) = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n \langle \mathbf{v}_{i, f_j}, \mathbf{v}_{j, f_i} \rangle x_i x_j \end{align}\]</span><p>其中，<span class="math inline">\(f_j\)</span> 是第 <span class="math inline">\(j\)</span> 个特征所属的 field。如果隐向量的长度为 <span class="math inline">\(k\)</span>，那么 FFM 的二次参数有 <span class="math inline">\(nfk\)</span> 个，远多于 FM 模型的 <span class="math inline">\(nk\)</span> 个。此外，由于隐向量与 field 相关，FFM 二次项并不能够化简，其预测复杂度是 <span class="math inline">\(O(kn^2)\)</span>。<p>其实，FFM 是在 FM 的基础上进行了更细致的分类，增加了参数的个数使得模型更复杂，能够拟合更复杂的数据分布。但是损失函数的推导以及优化的算法跟前面的 FM 还有 LR 都是一样的，因此这里不再赘述。<p>FFM 适用的场景跟 FM 和 LR 一样，<strong>适用于输入的特征是高维稀疏特征</strong>。<h3 id=开源实现-4><strong>开源实现</strong></h3><p>FFM 最早的开源实现是台大提供的 <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL2d1ZXN0d2Fsay9saWJmZm0=>libffm<i class="fa fa-external-link-alt"></i></span>，去年开源的 <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL2Frc256aHkveGxlYXJu>xlearn<i class="fa fa-external-link-alt"></i></span> 中也提供了该算法的实现，提供的 api 比 libffm 更加友好。<p>另外，由于 FM/FFM 可以看做是 LR 加了特征交叉的增强版本，对输入的特征的特点要求一致，因此上面的 GBDT+LR 也可以直接套到 GBDT+FM/FFM 上，值得一提的是，还是台大的学生，在 2014 由 Criteo 举办的比赛上，通过 GBDT+FFM 的方案夺冠，其实现细节可参考 <span class=exturl data-url=aHR0cHM6Ly9naXRodWIuY29tL2d1ZXN0d2Fsay9rYWdnbGUtMjAxNC1jcml0ZW8=>kaggle-2014-criteo<i class="fa fa-external-link-alt"></i></span>。<h2 id=小结>小结</h2><p>在非深度学习中，可以看到主流的几个模型基本都是基于 LR 进行的拓展或将 LR 与其他模型结合。原因是 LR 模型简单，具有良好的理论基础，可解释性强，能够获取各个特征的重要性，且能够直接输出概率值。但是应用 LR 过程中无法避免且最为重要的一点就是人工特征工程，特征决定了上限，虽然 FM/FMM 和 GBDT+LR 在一定程度上起到了自动特征工程的作用，但是需要人工特征还是占主要部分。<p>后面要讲的深度学习的方法在一定程度上能够缓解这个问题，因为深度学习能够通过模型自动学习出有效特征，因此，深度学习也被归类为表示学习 ( Representation Learning) 的一种；但是，没有免费午餐的，特征工程的便利性带来的是特征的不可解释性，所以怎么选取还是要根据具体的需求和业务场景。</div><footer class=post-footer><div class=post-copyright><ul><li class=post-copyright-author><strong>本文作者： </strong>良超<li class=post-copyright-link><strong>本文链接：</strong> <a title="CTR 预估模型简介 -- 非深度学习篇" href=https://wulc.me/2018/07/15/CTR%20%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B--%E9%9D%9E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/>https://wulc.me/2018/07/15/CTR 预估模型简介--非深度学习篇/</a><li class=post-copyright-license><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class=exturl data-url=aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8=><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！</ul></div><div class=post-tags><a href=/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/ rel=tag><i class="fa fa-tag"></i> 计算广告</a><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ rel=tag><i class="fa fa-tag"></i> 机器学习</a></div><div class=post-nav><div class=post-nav-item><a title="ROC 曲线与 PR 曲线" href=/2018/06/16/ROC%20%E6%9B%B2%E7%BA%BF%E4%B8%8E%20PR%20%E6%9B%B2%E7%BA%BF/ rel=prev> <i class="fa fa-angle-left"></i> ROC 曲线与 PR 曲线 </a></div><div class=post-nav-item><a title="CTR 预估模型简介 -- 深度学习篇" href=/2018/07/16/CTR%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AF%87/ rel=next> CTR 预估模型简介 -- 深度学习篇 <i class="fa fa-angle-right"></i> </a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>© 2015 – <span itemprop=copyrightYear>2025</span><span class=with-love> <i class="fa fa-pen"></i> </span><span class=author itemprop=copyrightHolder>良超</span></div><div class=powered-by>由 <span class=exturl data-url=aHR0cHM6Ly9oZXhvLmlv>Hexo</span> & <span class=exturl data-url=aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9waXNjZXMv>NexT.Pisces</span> 强力驱动</div></div></footer><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span><span class=toggle-line></span><span class=toggle-line></span></div><div class=sidebar-dimmer></div><div aria-label=返回顶部 class=back-to-top role=button><i class="fa fa-arrow-up fa-lg"></i><span>0%</span></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><script crossorigin=anonymous integrity=sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY= src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js></script><script crossorigin=anonymous integrity=sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8= src=https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js></script><script crossorigin=anonymous integrity=sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc= src=https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js></script><script crossorigin=anonymous integrity=sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I= src=https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js></script><script src=/js/comments.js></script><script src=/js/utils.js></script><script src=/js/motion.js></script><script src=/js/sidebar.js></script><script src=/js/next-boot.js></script><script crossorigin=anonymous integrity=sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc= src=https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js></script><script src=/js/third-party/search/local-search.js></script><script src=/js/third-party/fancybox.js></script><script class=next-config data-name=enableMath type=application/json>true</script><script class=next-config data-name=mathjax type=application/json>{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src=/js/third-party/math/mathjax.js></script>