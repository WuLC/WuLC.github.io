<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">

<script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
<script>LA.init({id: "JmI6QmP3fMkLet6B",ck: "JmI6QmP3fMkLet6B"})</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/imgs/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/imgs/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/imgs/favicon.ico">
  <link rel="mask-icon" href="/imgs/favicon.ico" color="#222">
  <meta name="google-site-verification" content="VcC-PHB4Om9SIR3Roqm7k1N-SHiBtQ6c3LJLVMKgU4U">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wulc.me","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为 positive、negative、neutral 三种，细分可以分为 neutral, angry, surprise, disgust, fear, happy, sad 7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习在表情识别中的应用">
<meta property="og:url" content="https://wulc.me/2017/09/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%A1%A8%E6%83%85%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E6%8E%A2%E7%B4%A2/index.html">
<meta property="og:site_name" content="吴良超的学习笔记">
<meta property="og:description" content="本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为 positive、negative、neutral 三种，细分可以分为 neutral, angry, surprise, disgust, fear, happy, sad 7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wulc.me/imgs/image_1bqkulor8935til84914bc3ar9.png">
<meta property="og:image" content="https://wulc.me/imgs/image_1bqkuvvjd5qp1383rtm1qnu1kic1g.png">
<meta property="og:image" content="https://wulc.me/imgs/image_1bqkvqgl5rojlbnodhtsg89e37.png">
<meta property="og:image" content="https://wulc.me/imgs/image_1bqkvpc901ufv189f19r6h4q1h1p2q.png">
<meta property="og:image" content="https://wulc.me/imgs/image_1bql06cuj1ket1mhveme1l4fvsu3k.png">
<meta property="og:image" content="https://wulc.me/imgs/image_1bqmnubbv1pvf68s1cemeqa1plo41.png">
<meta property="og:image" content="https://wulc.me/imgs/image_1bqmosh7oqcsbfa1ksp56de2d4e.png">
<meta property="article:published_time" content="2017-09-03T13:37:39.000Z">
<meta property="article:modified_time" content="2023-04-30T05:12:49.145Z">
<meta property="article:author" content="良超">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wulc.me/imgs/image_1bqkulor8935til84914bc3ar9.png">

<link rel="canonical" href="https://wulc.me/2017/09/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%A1%A8%E6%83%85%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E6%8E%A2%E7%B4%A2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>深度学习在表情识别中的应用 | 吴良超的学习笔记</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">吴良超的学习笔记</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wulc.me/2017/09/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%A1%A8%E6%83%85%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E6%8E%A2%E7%B4%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/files/profile.jpg">
      <meta itemprop="name" content="良超">
      <meta itemprop="description" content="盈亏同源，享受生活的随机性">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴良超的学习笔记">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习在表情识别中的应用
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-09-03 21:37:39" itemprop="dateCreated datePublished" datetime="2017-09-03T21:37:39+08:00">2017-09-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本文的表情识别指的是给出一张图片，检测其中人脸的表情（如果含有人脸的话）。所有可能的表情种类往往事先约定好,粗分可以分为
<code>positive</code>、<code>negative</code>、<code>neutral</code>
三种，细分可以分为 <code>neutral</code>, <code>angry</code>,
<code>surprise</code>, <code>disgust</code>, <code>fear</code>,
<code>happy</code>, <code>sad</code>
7种或者更多种，这里的类别可根据具体采用的数据集进行调整，从机器学习的角度来说，这实际上就是一个多分类问题。</p>
<p>本文主要讲述如何将深度学习应用在表情识别中，以及在图像分类中深度学习一些常用方法，如采用预训练的模型进行特征的提取，用数据集对预训练的模型进行
Fine-tunning，而这实际上又牵涉到了迁移学习。</p>
<span id="more"></span>
<p>之所以采用深度学习的方法，是因为深度学习中的网络（尤其是CNN）对图像具有较好的提取特征的能力，从而避免了人工提取特征的繁琐，人脸的人工特征包括常用的
68 个 <a
target="_blank" rel="noopener" href="http://www.learnopencv.com/facial-landmark-detection/">Facial
landmarks</a>
等其他的特征，而深度学习除了预测外，往往还扮演着特征工程的角色，从而省去了人工提取特征的步骤。下面首先讲述深度学习中常用的网络类型，然后讲述通过预训练的网络(经过ImageNet进行预训练)对图像提取特征，以及对预训练的网络采用自己的数据进行微调的
Fine-Tunning。</p>
<h2 id="数据集">数据集</h2>
<p>表情识别中常用的数据集有 <a
target="_blank" rel="noopener" href="http://www.consortium.ri.cmu.edu/ckagree/">CK+</a>， <a
target="_blank" rel="noopener" href="https://mmifacedb.eu/">MMI</a>， <a
target="_blank" rel="noopener" href="http://www.kasrl.org/jaffe.html">JAFFE</a>， <a
target="_blank" rel="noopener" href="http://www.emotionlab.se/resources/kdef">KDEF</a>等，这些数据有些是短视频，有些是图片序列（记录一个表情的若干张图片），有些则是单张表情图片。</p>
<p>在训练时，需要根据实际的应用场景以及采用的模型的输入格式将这些数据集处理成相关格式，这里不在详细说明。</p>
<h2 id="网络类型">网络类型</h2>
<p>假如采用深度学习中常用的网络层 cnn，rnn， fully-connect
等层组合成网络，那么具有非常多种的选择，这些网络的性能需要在实际任务中检验，而经过实践发现，某些网络结构往往在图像分类上具有较好的结果，如ImgeNet比赛中提出的一些列模型：AlexNet，GoogleNet（Inception),
VGG， ResNet 等。这些网络已经经过了 ImageNet
这个数据集的考验，因此在图像分类问题中也常被采用。</p>
<p>至于网络的结构，往往是先通过若干层 CNN
进行图像特征的提取，然后通过全连接层进行非线性分类，这时的全连接层就类似与MLP，只是还加入了
dropout 等机制防止过拟合等，最后一层有几个分类就连接几个神经元，并且通过
softmax 变换得到样本属于各个分类的概率分布。如下是 AlexNet
的网络结构图</p>
<h3 id="alexnet">AlexNet</h3>
<figure>
<img src="https://wulc.me/imgs/image_1bqkulor8935til84914bc3ar9.png"
alt="AlexNet" />
<figcaption aria-hidden="true">AlexNet</figcaption>
</figure>
<p>关于AlexNet 更详细的介绍可参考<a
href="http://wulc.me/2017/05/15/ImageNet%20Classification%20with%20Deep%20Convolutional%20Neural%20Networks%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">这篇文章</a>。</p>
<h3 id="inception">Inception</h3>
<p>而 Inception 是 Google 研发的一个深度神经网络，经历了四个版本
（也叫GoogLeNet），各个版本及其对应的论文如下，各个版本</p>
<p>[v1] Going Deeper with Convolutions, 6.67% test error,
http://arxiv.org/abs/1409.4842 [v2] Batch Normalization: Accelerating
Deep Network Training by Reducing Internal Covariate Shift, 4.8% test
error, http://arxiv.org/abs/1502.03167 [v3] Rethinking the Inception
Architecture for Computer Vision, 3.5% test error,
http://arxiv.org/abs/1512.00567 [v4] Inception-v4, Inception-ResNet and
the Impact of Residual Connections on Learning, 3.08% test error,
http://arxiv.org/abs/1602.07261</p>
<p>Inception 的结构与前面的 AlexNet 的大同小异，其核心是多了 Inception
模块，而 Inception 模块的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqkuvvjd5qp1383rtm1qnu1kic1g.png"
alt="Inception moule" />
<figcaption aria-hidden="true">Inception moule</figcaption>
</figure>
<p>Inception
模块使得网络的当前层可以通过多种方式从前一层网络提取特征，如上图通过了三种不同大小的卷积层以及一个池化层，然后将这些特征进行
concate 送到下一层。</p>
<p>如下是 Inception V3 的结构</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqkvqgl5rojlbnodhtsg89e37.png"
alt="Inception V3" />
<figcaption aria-hidden="true">Inception V3</figcaption>
</figure>
<h3 id="vgg">VGG</h3>
<p>VGG 并没有采用很新颖的结构，整个网络只是采用了 3X3 的卷积层以及 2X2
的池化层，但是层数比较深，就是这么一个靠两种简单网络层堆叠起来的网络，却在
ImageNet 比赛上取得了非常好的结果。VGG
主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能，越深的网络能够容纳更多数据的信息，对于更大的数据具有更好的效果，VGG整个网络的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqkvpc901ufv189f19r6h4q1h1p2q.png"
alt="VGG" />
<figcaption aria-hidden="true">VGG</figcaption>
</figure>
<h3 id="resnet">ResNet</h3>
<p>前面 VGG
提到了网络的深度（层数）起到了一个非常重要的作用，但是如果只是简单地将层堆叠在一起，增加网络的深度并不会起太大作用。这是由于梯度消失和爆炸（vanishing/exploding
gradient）问题，深层的网络很难训练。因为梯度反向传播到前一层，重复相乘可能使梯度无穷小。结果就是，随着网络的层数更深，其性能趋于饱和，甚至开始迅速下降。</p>
<p>而为了解决因深度增加而产生的性能下降问题， ResNet
引入一个“身份捷径连接”（identity shortcut
connection），直接跳过一层或多层，如下图所示：</p>
<figure>
<img src="https://wulc.me/imgs/image_1bql06cuj1ket1mhveme1l4fvsu3k.png"
alt="ResNet" />
<figcaption aria-hidden="true">ResNet</figcaption>
</figure>
<p><a
target="_blank" rel="noopener" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">提出
ReNet 的这篇论文</a>指出，假设目标映射为 <span
class="math inline">\(H(x)\)</span>，这个模块并不是让 stacked layers
去直接拟合这个目标映射，而是去拟合残差 <span class="math inline">\(F(x)
:= H(x)-x\)</span>，则拟合的 <span class="math inline">\(H(x)\)</span>
则变为了 <span class="math inline">\(F(x) + x\)</span>, 论文假设优化残差
<span class="math inline">\(F(x)\)</span> 比优化 H(x) 更容易。</p>
<p>上面这段话基本翻译自提出 ResNet
这篇论文，更直观的理解就是每一层不仅仅只是能从前一层获取信息了，而是还可以从更前面的几层获取，而
ResNet 最开始的只是建单地将更前面几层的 x 直接加到当前层的输出，也就是
<span class="math inline">\(F(x) + x\)</span>， 而 ResNet
的若干变体则对这部分直接传递的 <span class="math inline">\(x\)</span>
进行了处理，如通过卷积层等操作，但是其核心思想还是跨层连接从而获得更多的信息。</p>
<p>最开始提出的 ResNet 的结构如下</p>
<figure>
<img src="https://wulc.me/imgs/image_1bqmnubbv1pvf68s1cemeqa1plo41.png"
alt="ResNet" />
<figcaption aria-hidden="true">ResNet</figcaption>
</figure>
<h3 id="cnn-lstm">CNN-LSTM</h3>
<p>上面的模型均是对单张图像进行处理，但是还有一种模型是对连续图片
sequence 进行处理的，由于连续图片 sequence 包含了时序信息，因此通过将
CNN 与 RNN 进行结合对时序图片列进行预测。在表情识别中</p>
<p>CNN-LSTM 是将 CNN 与 LSTM
结合起来的一种模型，其基本结构如下，图片出自<a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/1411.4389v4.pdf">该论文</a></p>
<figure>
<img src="https://wulc.me/imgs/image_1bqmosh7oqcsbfa1ksp56de2d4e.png"
alt="cnn-lstm" />
<figcaption aria-hidden="true">cnn-lstm</figcaption>
</figure>
<p>其思想就是首先通过 cnn 提取每张图片的特征，然后将这些带时序的特征传入
LSTM 中，可以取每一个 LSTM 的输出进行平均后连接 softmax
进行输出，也可以直接取最后一个 LSTM 的输出连接 softmax 作为输出。</p>
<p>上面这些网络训练的时候均是通过 SGD 进行反向传播，某些会加入 momentum
等其他改进。</p>
<p>这些网络理解起来可能问题不大，但是如果要代码实现起来的话工作量并不小，好在已经有了若干框架实现了这些模型，在使用时直接调用即可，这里以最简单的框架
<a target="_blank" rel="noopener" href="https://github.com/fchollet/keras">Keras</a> 为例说明，Kreas
已经在<a
target="_blank" rel="noopener" href="https://github.com/fchollet/deep-learning-models">这里</a>列出了一些实现的网络，可以参考其文档直接进行调用。</p>
<h2 id="预训练模型提取特征">预训练模型提取特征</h2>
<p>上面提到的这些模型少则十几层，多则上百层，其参数数目也达到了百万级别，要训练这么庞大的一个网络，如果数据量不足，很容易会会导致整个网络过拟合（当然，如果训练epoch次数少，也会直接导致欠拟合）。</p>
<p>而在实际中，像 ImageNet
这种庞大的数据集很少，而且某些只是归少数大公司所有，假如个人或缺乏数据的小公司需要用到上面提到的网络时，那就是无米之炊了，因此在实际中使用时，往往不是从头开始训练一个很大的模型，而是采用下面提到的通过模型提取特征以及对模型进行
Fine-Tunning 的方法。</p>
<p>深度学习中的网络的一个好处就是，经过大规模数据集训练过后的，网络具有了抽取图像特征的特性，而抽取出来的图像的特征，跟实际要处理任务没有关系，也就是说经过
ImageNet
训练过后的网络，也可以用于表情识别中抽取人脸的特征，然后用这些特征再训练一个小一点的模型，如
Logistics Regression，
SVM等，这时候的网络完全就是在扮演着一个自动特征工程的角色。</p>
<p>这里“通过网络提取的特征”往往指的是网络最后的某个全连接层的输出值，具体采用哪一层取决于后续处理所需的特征维数。</p>
<p>Keras 也提供了经过 ImageNet
预训练的一些模型，通过这些模型抽取图像特征的样例代码如下</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">base_model = VGG19(weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">model = Model(<span class="built_in">input</span>=base_model.<span class="built_in">input</span>, output=base_model.get_layer(<span class="string">&#x27;block4_pool&#x27;</span>).output)</span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&#x27;elephant.jpg&#x27;</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">block4_pool_features = model.predict(x)</span><br></pre></td></tr></table></figure>
<p>在实际测试时，用 VGG16 抽取图像的特征后再经过带 L1 正则化的Logistics
Regression，再CK+上进行10-fold cross validation， 得到的准确率约为85%,
也说明了这种方法的有效性。</p>
<h2
id="对预训练模型进行微调fine-tunning">对预训练模型进行微调(Fine-Tunning)</h2>
<p>上面通过预训练的网络提取特征的确有效果，但是这些经过预训练的网络基本都是在
ImageNet 数据集上进行训练的，而实际中的各种任务是千差万别的，光凭
ImageNet 是难以涵盖各个领域的需求的。</p>
<p>因此很自然会想到在预训练的网络基础上，用涉及到的具体任务中的数据集再次训练这个网络，从而让这个网络能够学习到这个数据集内的信息，这种方法也称为
Fine-Tunning。</p>
<p>Keras 的官方blog也写了一篇文章专门阐述这种方法，文章链接为
https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</p>
<p>在这篇文章中，并没有调整整个网络的参数，而是只调整了最后的几层卷积层和全连接层，文章称原因是越底层的卷积层所提取到的图像的特性越是有共性的特征，而越上层的卷积层提取的特征则越是跟具体的领域相关的，当然，到底要调整多少层，还取决于所拥有的数据量，另外，往往还会去掉网络最后的若干层，并根据实际的图像分类数目构建最后一层大小。</p>
<p>通过 Keras 进行 Fine-Tunning 的样例代码如下</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br><span class="line"></span><br><span class="line">height, width, categoriees = <span class="number">128</span>, <span class="number">128</span>, <span class="number">7</span></span><br><span class="line"></span><br><span class="line">model_vgg19_conv = VGG19(weights = <span class="string">&#x27;imagenet&#x27;</span>, include_top = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># just fine-tune the top five convulutional layers</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model_vgg19_conv.layers[:-<span class="number">5</span>]: </span><br><span class="line">    layer.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Create your own input format (here 128x128X3)</span></span><br><span class="line"><span class="built_in">input</span> = Input(shape=(height, width, <span class="number">3</span>),name = <span class="string">&#x27;image_input&#x27;</span>)</span><br><span class="line"><span class="comment">#Use the generated model </span></span><br><span class="line">output_vgg19_conv = model_vgg19_conv(<span class="built_in">input</span>)</span><br><span class="line"><span class="comment">#Add the fully-connected layers </span></span><br><span class="line">x = Flatten(name=<span class="string">&#x27;flatten&#x27;</span>)(output_vgg19_conv)</span><br><span class="line">x = Dense(feature_dim, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;fc1&#x27;</span>)(x)</span><br><span class="line"><span class="comment"># x = Dense(feature_dim, activation=&#x27;relu&#x27;, name=&#x27;fc2&#x27;)(x)</span></span><br><span class="line">x = Dense(categories, activation=<span class="string">&#x27;softmax&#x27;</span>, name=<span class="string">&#x27;predictions&#x27;</span>)(x)</span><br><span class="line"><span class="comment">#Create your own model </span></span><br><span class="line">model = Model(inputs = <span class="built_in">input</span>, outputs = x)</span><br></pre></td></tr></table></figure>
<p>最后讲的利用了预训练模型的两部分实际上可以归入到迁移学习的范畴了，原因是我们利用了模型在
ImageNet
上学到的知识，迁移到了一个新的领域(表情识别），同理，也可以将其推广至医学影像等领域，当然，迁移学习远不止这点内容，有兴趣的可以去查找相关资料，这里不在论述。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/08/28/python%20%E4%B8%AD%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%8E%E7%BC%96%E7%A0%81/" rel="prev" title="python 中的字符串与编码">
      <i class="fa fa-chevron-left"></i> python 中的字符串与编码
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/09/13/Spark%20%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%92%8C%20Jupyter%20Notebook%20%E9%85%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/" rel="next" title="Spark 集群部署和 Jupyter Notebook 配置注意事项">
      Spark 集群部署和 Jupyter Notebook 配置注意事项 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">网络类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#alexnet"><span class="nav-number">2.1.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inception"><span class="nav-number">2.2.</span> <span class="nav-text">Inception</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vgg"><span class="nav-number">2.3.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#resnet"><span class="nav-number">2.4.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cnn-lstm"><span class="nav-number">2.5.</span> <span class="nav-text">CNN-LSTM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81"><span class="nav-number">3.</span> <span class="nav-text">预训练模型提取特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83fine-tunning"><span class="nav-number">4.</span> <span class="nav-text">对预训练模型进行微调(Fine-Tunning)</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="良超"
      src="/files/profile.jpg">
  <p class="site-author-name" itemprop="name">良超</p>
  <div class="site-description" itemprop="description">盈亏同源，享受生活的随机性</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">248</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">45</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/WuLC" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;WuLC" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/in/wuliangchao/" title="LinkedIn → https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;wuliangchao&#x2F;" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i>LinkedIn</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liangchaowu5@gmail.com" title="E-Mail → mailto:liangchaowu5@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">良超</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
